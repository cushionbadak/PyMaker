<div class="post-text" itemprop="text">
<p>I needed to write a weighted version of random.choice (each element in the list has a different probability for being selected).  This is what I came up with:</p>
<pre><code>def weightedChoice(choices):
    """Like random.choice, but each element can have a different chance of
    being selected.

    choices can be any iterable containing iterables with two items each.
    Technically, they can have more than two items, the rest will just be
    ignored.  The first item is the thing being chosen, the second item is
    its weight.  The weights can be any numeric values, what matters is the
    relative differences between them.
    """
    space = {}
    current = 0
    for choice, weight in choices:
        if weight &gt; 0:
            space[current] = choice
            current += weight
    rand = random.uniform(0, current)
    for key in sorted(space.keys() + [current]):
        if rand &lt; key:
            return choice
        choice = space[key]
    return None
</code></pre>
<p>This function seems overly complex to me, and ugly.  I'm hoping everyone here can offer some suggestions on improving it or alternate ways of doing this.  Efficiency isn't as important to me as code cleanliness and readability.</p>
</div>
<div class="post-text" itemprop="text">
<p>Since version 1.7.0, NumPy has a <a href="https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.choice.html" rel="noreferrer"><code>choice</code></a> function that supports probability distributions.</p>
<pre><code>from numpy.random import choice
draw = choice(list_of_candidates, number_of_items_to_pick,
              p=probability_distribution)
</code></pre>
<p>Note that <code>probability_distribution</code> is a sequence in the same order of <code>list_of_candidates</code>. You can also use the keyword <code>replace=False</code> to change the behavior so that drawn items are not replaced.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>def weighted_choice(choices):
   total = sum(w for c, w in choices)
   r = random.uniform(0, total)
   upto = 0
   for c, w in choices:
      if upto + w &gt;= r:
         return c
      upto += w
   assert False, "Shouldn't get here"
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Since <em>Python3.6</em> there is a method <a href="https://docs.python.org/dev/library/random.html#random.choices" rel="noreferrer"><code>choices</code></a> from <a href="https://docs.python.org/dev/library/random.html#module-random" rel="noreferrer"><code>random</code></a> module.</p>
<pre><code>Python 3.6.1 (v3.6.1:69c0db5050, Mar 21 2017, 01:21:04)
Type 'copyright', 'credits' or 'license' for more information
IPython 6.0.0 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import random

In [2]: random.choices(
...:     population=[['a','b'], ['b','a'], ['c','b']],
...:     weights=[0.2, 0.2, 0.6],
...:     k=10
...: )

Out[2]:
[['c', 'b'],
 ['c', 'b'],
 ['b', 'a'],
 ['c', 'b'],
 ['c', 'b'],
 ['b', 'a'],
 ['c', 'b'],
 ['b', 'a'],
 ['c', 'b'],
 ['c', 'b']]
</code></pre>
<p>And people also mentioned that there is <a href="http://docs.scipy.org/doc/numpy-dev/reference/generated/numpy.random.choice.html" rel="noreferrer"><code>numpy.random.choice</code></a> which support weights, <strong>BUT</strong> it don't support <em>2d arrays</em>, and so on. </p>
<p>So, <strike>basically you can get whatever you like</strike> (see <strong>update</strong>) with builtin <code>random.choices</code> if you have <em>3.6.x Python</em>.</p>
<p><strong>UPDATE</strong>: 
As <a href="https://stackoverflow.com/posts/comments/89648500">@roganjosh</a> kindly mentioned, <code>random.choices</code> cannot return values without replacement, as it mentioned in the <a href="https://docs.python.org/dev/library/random.html#random.choices" rel="noreferrer">docs</a>:</p>
<blockquote>
<p>Return a <code>k</code> sized list of elements chosen from the population <strong>with replacement</strong>.</p>
</blockquote>
<p>And <a href="https://stackoverflow.com/a/26196078/3124746">@ronan-paixão</a>'s brilliant answer states that <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html" rel="noreferrer"><code>numpy.choice</code></a> has <code>replace</code> argument, that controls such behaviour.</p>
</div>
<div class="post-text" itemprop="text">
<ol>
<li>Arrange the weights into a
cumulative distribution.</li>
<li>Use <strong>random.random()</strong> to pick a random
float <code>0.0 &lt;= x &lt; total</code>. </li>
<li>Search the
distribution using <strong>bisect.bisect</strong> as
shown in the example at <a href="http://docs.python.org/dev/library/bisect.html#other-examples" rel="noreferrer">http://docs.python.org/dev/library/bisect.html#other-examples</a>.</li>
</ol>
<pre><code>from random import random
from bisect import bisect

def weighted_choice(choices):
    values, weights = zip(*choices)
    total = 0
    cum_weights = []
    for w in weights:
        total += w
        cum_weights.append(total)
    x = random() * total
    i = bisect(cum_weights, x)
    return values[i]

&gt;&gt;&gt; weighted_choice([("WHITE",90), ("RED",8), ("GREEN",2)])
'WHITE'
</code></pre>
<p>If you need to make more than one choice, split this into two functions, one to build the cumulative weights and another to bisect to a random point.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you don't mind using numpy, you can use <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html#numpy.random.choice">numpy.random.choice</a>. </p>
<p>For example:</p>
<pre><code>import numpy

items  = [["item1", 0.2], ["item2", 0.3], ["item3", 0.45], ["item4", 0.05]
elems = [i[0] for i in items]
probs = [i[1] for i in items]

trials = 1000
results = [0] * len(items)
for i in range(trials):
    res = numpy.random.choice(items, p=probs)  #This is where the item is selected!
    results[items.index(res)] += 1
results = [r / float(trials) for r in results]
print "item\texpected\tactual"
for i in range(len(probs)):
    print "%s\t%0.4f\t%0.4f" % (items[i], probs[i], results[i])
</code></pre>
<p>If you know how many selections you need to make in advance, you can do it without a loop like this:</p>
<pre><code>numpy.random.choice(items, trials, p=probs)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Crude, but may be sufficient:</p>
<pre><code>import random
weighted_choice = lambda s : random.choice(sum(([v]*wt for v,wt in s),[]))
</code></pre>
<p>Does it work?</p>
<pre><code># define choices and relative weights
choices = [("WHITE",90), ("RED",8), ("GREEN",2)]

# initialize tally dict
tally = dict.fromkeys(choices, 0)

# tally up 1000 weighted choices
for i in xrange(1000):
    tally[weighted_choice(choices)] += 1

print tally.items()
</code></pre>
<p>Prints:</p>
<pre><code>[('WHITE', 904), ('GREEN', 22), ('RED', 74)]
</code></pre>
<p>Assumes that all weights are integers.  They don't have to add up to 100, I just did that to make the test results easier to interpret. (If weights are floating point numbers, multiply them all by 10 repeatedly until all weights &gt;= 1.)</p>
<pre><code>weights = [.6, .2, .001, .199]
while any(w &lt; 1.0 for w in weights):
    weights = [w*10 for w in weights]
weights = map(int, weights)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you have a weighted dictionary instead of a list you can write this</p>
<pre><code>items = { "a": 10, "b": 5, "c": 1 } 
random.choice([k for k in items for dummy in range(items[k])])
</code></pre>
<p>Note that <code>[k for k in items for dummy in range(items[k])]</code> produces this list <code>['a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'c', 'b', 'b', 'b', 'b', 'b']</code></p>
</div>
<div class="post-text" itemprop="text">
<p>As of Python <code>v3.6</code>, <a href="https://docs.python.org/3/library/random.html#random.choices" rel="noreferrer"><code>random.choices</code></a> could be used to return a <code>list</code> of elements of specified size from the given population with optional weights.</p>
<blockquote>
<p><code>random.choices(population, weights=None, *, cum_weights=None, k=1)</code></p>
</blockquote>
<ul>
<li><p><em>population</em> : <code>list</code> containing unique observations. (If empty, raises <code>IndexError</code>)</p></li>
<li><p><em>weights</em> : More precisely relative weights required to make selections.</p></li>
<li><p><em>cum_weights</em> : cumulative weights required to make selections.</p></li>
<li><p><em>k</em> : size(<code>len</code>) of the <code>list</code> to be outputted. (Default <code>len()=1</code>)</p></li>
</ul>
<hr/>
<p><strong><em>Few Caveats:</em></strong></p>
<p>1) It makes use of weighted sampling with replacement so the drawn items would be later replaced. The values in the weights sequence in itself do not matter, but their relative ratio does.</p>
<p>Unlike <code>np.random.choice</code> which can only take on probabilities as weights and also which must ensure summation of individual probabilities upto 1 criteria, there are no such regulations here. As long as they belong to numeric types (<code>int/float/fraction</code> except <code>Decimal</code> type) , these would still perform.</p>
<pre><code>&gt;&gt;&gt; import random
# weights being integers
&gt;&gt;&gt; random.choices(["white", "green", "red"], [12, 12, 4], k=10)
['green', 'red', 'green', 'white', 'white', 'white', 'green', 'white', 'red', 'white']
# weights being floats
&gt;&gt;&gt; random.choices(["white", "green", "red"], [.12, .12, .04], k=10)
['white', 'white', 'green', 'green', 'red', 'red', 'white', 'green', 'white', 'green']
# weights being fractions
&gt;&gt;&gt; random.choices(["white", "green", "red"], [12/100, 12/100, 4/100], k=10)
['green', 'green', 'white', 'red', 'green', 'red', 'white', 'green', 'green', 'green']
</code></pre>
<p>2) If neither <em>weights</em> nor <em>cum_weights</em> are specified, selections are made with equal probability.  If a <em>weights</em> sequence is supplied, it must be the same length as the <em>population</em> sequence. </p>
<p>Specifying both <em>weights</em> and <em>cum_weights</em> raises a <code>TypeError</code>.</p>
<pre><code>&gt;&gt;&gt; random.choices(["white", "green", "red"], k=10)
['white', 'white', 'green', 'red', 'red', 'red', 'white', 'white', 'white', 'green']
</code></pre>
<p>3) <em>cum_weights</em> are typically a result of <a href="https://docs.python.org/3/library/itertools.html#itertools.accumulate" rel="noreferrer"><code>itertools.accumulate</code></a> function which are really handy in such situations. </p>
<blockquote>
<p><sub> From the documentation linked: </sub></p>
<p>Internally, the relative weights are converted to cumulative weights
  before making selections, so supplying the cumulative weights saves
  work.</p>
</blockquote>
<p>So, either supplying <code>weights=[12, 12, 4]</code> or <code>cum_weights=[12, 24, 28]</code> for our contrived case produces the same outcome and the latter seems to be more faster / efficient.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here's is the version that is being included in the standard library for Python 3.6:</p>
<pre><code>import itertools as _itertools
import bisect as _bisect

class Random36(random.Random):
    "Show the code included in the Python 3.6 version of the Random class"

    def choices(self, population, weights=None, *, cum_weights=None, k=1):
        """Return a k sized list of population elements chosen with replacement.

        If the relative weights or cumulative weights are not specified,
        the selections are made with equal probability.

        """
        random = self.random
        if cum_weights is None:
            if weights is None:
                _int = int
                total = len(population)
                return [population[_int(random() * total)] for i in range(k)]
            cum_weights = list(_itertools.accumulate(weights))
        elif weights is not None:
            raise TypeError('Cannot specify both weights and cumulative weights')
        if len(cum_weights) != len(population):
            raise ValueError('The number of weights does not match the population')
        bisect = _bisect.bisect
        total = cum_weights[-1]
        return [population[bisect(cum_weights, random() * total)] for i in range(k)]
</code></pre>
<p>Source:  <a href="https://hg.python.org/cpython/file/tip/Lib/random.py#l340" rel="noreferrer">https://hg.python.org/cpython/file/tip/Lib/random.py#l340</a></p>
</div>
<div class="post-text" itemprop="text">
<p>I'd require the sum of choices is 1, but this works anyway</p>
<pre><code>def weightedChoice(choices):
    # Safety check, you can remove it
    for c,w in choices:
        assert w &gt;= 0


    tmp = random.uniform(0, sum(c for c,w in choices))
    for choice,weight in choices:
        if tmp &lt; weight:
            return choice
        else:
            tmp -= weight
     raise ValueError('Negative values in input')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import numpy as np
w=np.array([ 0.4,  0.8,  1.6,  0.8,  0.4])
np.random.choice(w, p=w/sum(w))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I'm probably too late to contribute anything useful, but here's a simple, short, and very efficient snippet:</p>
<pre><code>def choose_index(probabilies):
    cmf = probabilies[0]
    choice = random.random()
    for k in xrange(len(probabilies)):
        if choice &lt;= cmf:
            return k
        else:
            cmf += probabilies[k+1]
</code></pre>
<p>No need to sort your probabilities or create a vector with your cmf, and it terminates once it finds its choice. Memory: O(1), time: O(N), with average running time ~ N/2. </p>
<p>If you have weights, simply add one line:</p>
<pre><code>def choose_index(weights):
    probabilities = weights / sum(weights)
    cmf = probabilies[0]
    choice = random.random()
    for k in xrange(len(probabilies)):
        if choice &lt;= cmf:
            return k
        else:
            cmf += probabilies[k+1]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A general solution:</p>
<pre><code>import random
def weighted_choice(choices, weights):
    total = sum(weights)
    treshold = random.uniform(0, total)
    for k, weight in enumerate(weights):
        total -= weight
        if total &lt; treshold:
            return choices[k]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If your list of weighted choices is relatively static, and you want frequent sampling, you can do one O(N) preprocessing step, and then do the selection in O(1), using the functions in <a href="https://stackoverflow.com/a/29722230/10396">this related answer</a>.</p>
<pre><code># run only when `choices` changes.
preprocessed_data = prep(weight for _,weight in choices)

# O(1) selection
value = choices[sample(preprocessed_data)][0]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It depends on how many times you want to sample the distribution. </p>
<p>Suppose you want to sample the distribution K times. Then, the time complexity using <code>np.random.choice()</code> each time is <code>O(K(n + log(n)))</code> when <code>n</code> is the number of items in the distribution. </p>
<p>In my case, I needed to sample the same distribution multiple times of the order of 10^3 where n is of the order of 10^6. I used the below code, which precomputes the cumulative distribution and samples it in <code>O(log(n))</code>. Overall time complexity is <code>O(n+K*log(n))</code>.</p>
<pre><code>import numpy as np

n,k = 10**6,10**3

# Create dummy distribution
a = np.array([i+1 for i in range(n)])
p = np.array([1.0/n]*n)

cfd = p.cumsum()
for _ in range(k):
    x = np.random.uniform()
    idx = cfd.searchsorted(x, side='right')
    sampled_element = a[idx]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I looked the pointed other thread and came up with this variation in my coding style, this returns the index of choice for purpose of tallying, but it is simple to return the string ( commented return alternative):</p>
<pre><code>import random
import bisect

try:
    range = xrange
except:
    pass

def weighted_choice(choices):
    total, cumulative = 0, []
    for c,w in choices:
        total += w
        cumulative.append((total, c))
    r = random.uniform(0, total)
    # return index
    return bisect.bisect(cumulative, (r,))
    # return item string
    #return choices[bisect.bisect(cumulative, (r,))][0]

# define choices and relative weights
choices = [("WHITE",90), ("RED",8), ("GREEN",2)]

tally = [0 for item in choices]

n = 100000
# tally up n weighted choices
for i in range(n):
    tally[weighted_choice(choices)] += 1

print([t/sum(tally)*100 for t in tally])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is another version of weighted_choice that uses numpy. Pass in the weights vector and it will return an array of 0's containing a 1 indicating which bin was chosen. The code defaults to just making a single draw but you can pass in the number of draws to be made and the counts per bin drawn will be returned.</p>
<p>If the weights vector does not sum to 1, it will be normalized so that it does. </p>
<pre><code>import numpy as np

def weighted_choice(weights, n=1):
    if np.sum(weights)!=1:
        weights = weights/np.sum(weights)

    draws = np.random.random_sample(size=n)

    weights = np.cumsum(weights)
    weights = np.insert(weights,0,0.0)

    counts = np.histogram(draws, bins=weights)
    return(counts[0])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>One way is to randomize on the total of all the weights and then use the values as the limit points for each var. Here is a crude implementation as a generator.</p>
<pre><code>def rand_weighted(weights):
    """
    Generator which uses the weights to generate a
    weighted random values
    """
    sum_weights = sum(weights.values())
    cum_weights = {}
    current_weight = 0
    for key, value in sorted(weights.iteritems()):
        current_weight += value
        cum_weights[key] = current_weight
    while True:
        sel = int(random.uniform(0, 1) * sum_weights)
        for key, value in sorted(cum_weights.iteritems()):
            if sel &lt; value:
                break
        yield key
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using numpy</p>
<pre><code>def choice(items, weights):
    return items[np.argmin((np.cumsum(weights) / sum(weights)) &lt; np.random.rand())]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I needed to do something like this really fast really simple, from searching for ideas i finally built this template. The idea is receive the weighted values in a form of a json from the api, which here is simulated by the dict.</p>
<p>Then translate it into a list in which each value repeats proportionally to it's weight, and just use random.choice to select a value from the list.</p>
<p>I tried it running with 10, 100 and 1000 iterations. The distribution seems pretty solid.</p>
<pre><code>def weighted_choice(weighted_dict):
    """Input example: dict(apples=60, oranges=30, pineapples=10)"""
    weight_list = []
    for key in weighted_dict.keys():
        weight_list += [key] * weighted_dict[key]
    return random.choice(weight_list)
</code></pre>
</div>
<span class="comment-copy">This question is different, since it's got explicit weights rather than based on the length of the dict keys.</span>
<span class="comment-copy">I actually like your solution because it is quite readable and has a feature of traversing the input only once.</span>
<span class="comment-copy">As of 2014 <code>random.choice</code> <a href="http://stackoverflow.com/a/26196078/2075003">can do that</a> too.</span>
<span class="comment-copy">@n1000: That's <code>numpy.random.choice</code>, not <code>random.choice</code>.</span>
<span class="comment-copy">but <code>random.choices</code> (note the plural) can be passed weights (<a href="https://docs.python.org/3/library/random.html#random.choices" rel="nofollow noreferrer">doc</a>)</span>
<span class="comment-copy">Dear SO, as of 2014 this is the right answer... I wish there were an official way to update questions on such occasions.</span>
<span class="comment-copy">This is indeed a nice answer but I still appreciate the alternatives w/o numpy.</span>
<span class="comment-copy">It seems a little harsh to install <code>numpy</code> just for that one function…</span>
<span class="comment-copy">Look down for 2017+ correct answer using Python 3.6</span>
<span class="comment-copy">By my testing, this is an order of magnitude slower than <code>random.choices</code> for individual calls. If you need a lot of random results, it's really important to pick them all at once by adjusting <code>number_of_items_to_pick</code>. If you do so, it's an order of magnitude faster.</span>
<span class="comment-copy">You can drop an operation and save a sliver of time by reversing the statements inside the for loop: <code>upto +=w; if upto &gt; r</code></span>
<span class="comment-copy">@knite, Please don't suggest that. Did you even test that? It completely breaks the distribution. Running <code>weighted_choice([('a',1.0),('b',2.0),('c',3.0)])</code> with your modification causes b to never get picked...</span>
<span class="comment-copy">@rsk, You're correct, although that's a very rare occurrence. Changing the <code>&gt; r</code> to <code>&gt;= r</code> fixes that problem for me.</span>
<span class="comment-copy">save a variable by deleting upto and just decrementing r by the weight each time. The comparison is then <code>if r &lt; 0</code></span>
<span class="comment-copy">you could you a <code>for ... else</code> construction instead of your false assertion</span>
<span class="comment-copy">This is a nice up to date answer, python 3.6 does indeed have a weighted <code>choices</code> function. Excellent.</span>
<span class="comment-copy">should be accepted answer, I think.</span>
<span class="comment-copy">Great choice (pun intended).</span>
<span class="comment-copy">This can select with weights, but it doesn't appear to be able to stop replacement, which <code>np.random.choice</code> can do.</span>
<span class="comment-copy">@roganjosh true, thank you, i will mention that in updated answer.</span>
<span class="comment-copy">This is more efficient than Ned's answer. Basically, instead of doing a linear (O(n)) search through the choices, he's doing a binary search (O(log n)). +1!</span>
<span class="comment-copy">tuple index out of range if random() happens to return 1.0</span>
<span class="comment-copy">This still runs in <code>O(n)</code> because of the cumulative distribution calculation.</span>
<span class="comment-copy">I like this solution better. Cleaner and easier to understand code.</span>
<span class="comment-copy">This solution is better in the case where multiple calls to weighted_choice are needed for the same set of choices.  In that case you can create the cumulative sum once and do a binary search on each call.</span>
<span class="comment-copy">Nice, I'm not sure I can assume all weights are integers, though.</span>
<span class="comment-copy">Seems like your objects would be duplicated in this example. That'd be inefficient (and so is the function for converting weights to integers). Nevertheless, this solution is a good one-liner if the integer weights are small.</span>
<span class="comment-copy">Primitives will be duplicated, but objects will only have references duplicated, not the objects themselves.  (this is why you can't create a list of  lists using <code>[[]]*10</code> - all the elements in the outer list point to the same list.</span>
<span class="comment-copy">This works for small total population values, but not for large datasets (e.g. US population by state would end up creating a working list with 300 million items in it).</span>
<span class="comment-copy">Does the job, Kudos</span>
<span class="comment-copy">It's Raymond Hettinger!</span>
<span class="comment-copy">Out of curiosity, is there a reason you prefer random.random() * total instead of random.uniform(0, total)?</span>
<span class="comment-copy">@Colin No, not at all. Updated.</span>
<span class="comment-copy">You traverse three times over iterable. This might be not supported by iterable.</span>
<span class="comment-copy">I think it is actually possible. <a href="http://utopia.duth.gr/~pefraimi/research/data/2007EncOfAlg.pdf" rel="nofollow noreferrer">utopia.duth.gr/~pefraimi/research/data/2007EncOfAlg.pdf</a> It is actually pretty simple... But who cares...</span>
<span class="comment-copy">@liori I do care, and you're right: weightedChoice <i>can</i> be computed with one iterator pass only. However, this seems to require more than 1 call to the pseudo random generator.</span>
