<div class="post-text" itemprop="text">
<p>Is there a way to do a regex across multiple files (in this case, log files) where the regular expression might be matching starting conditions in one file, and ending conditions in the next file in filename order?</p>
<p>I need to match events out of log files where the start of the event can theoretically be towards the end of one file, and the end of the event can be towards the beginning of the next.</p>
<p>So far, I have been reading all the files and concatenating them into a string and regexing across that -- however, I've finally run into a situation where doing this is causing a <code>MemoryError</code> (this appears to be somewhere around total of 800MB of log files for a day).</p>
<p>I'm wondering if there is a way to do this across the files directly, so I don't have to maintain all contents in a variable in memory? Or, if there is another way to do this that is more memory efficient?</p>
<p>Note: OS is Windows 7</p>
</div>
<div class="post-text" itemprop="text">
<p>If you are on Unix-like OS (Linux, macOS), you could use system tools. <code>cat *.log | grep 'REGEX'</code>. If necessary, you can run that from a Python script using <code>subprocess.run()</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Process the files one at a time in order, but when you find an event start line, make note of the file and line where you saw it.  When you find the event end line, you'll know everything you need to.</p>
</div>
<span class="comment-copy">My current, slower workaround is to iterate through the log files and only pass 2 files at a a time to the function performing the regex. So, in first loop, pass <code>logfiles[0]</code> and <code>logfiles[1]</code>, then in second loop, pass <code>logfiles[1]</code> and <code>logfiles[2]</code> etc. But yes, this is much slower than passing the entire contents and running the regex over it all at once.</span>
<span class="comment-copy">Those data that have 800MB do you mean more .log files? Or is it just one 800MB .log file ? Why not use Python <code>re</code> module ? <a href="https://docs.python.org/3/library/re.html" rel="nofollow noreferrer">docs.python.org/3/library/re.html</a> I personally would try through <code>re.findall(regex, str)</code>. However, it requires some experience with the regex. You can also read part by part from the file. You don't have to load full 800MB into RAM (if it is one file).</span>
<span class="comment-copy">Not one log file -- 40 files of approx 20MB each. I am using <code>re</code>. I am running out of memory during a concatenation operation to create a single variable with all of the log file contents concatenated. Currently, I read each file and append the content to a list. When all files in the temp directory are read and in the list, I do a <code>''.join(log_files)</code> operation. Up to approx 780MB cumulative file size this is fine. Somewhere around the 800MB mark, the join fails with a <code>MemoryError</code>. I suspect at this point in time the code is doubling memory usage (list + variable) and running out.</span>
<span class="comment-copy">Which platform, operating system, processor, RAM size? First, you can use a smaller buffer in RAM, and secondly you can write the output directly into a file (separated blocks by bufer size), so you do not have to use memory almost at all. Of course, if you use a buffer, you need to think about it when writing the algorithm. If I know what the log data looks like, I'll write the algorithm and test it too. Then there are a few details, such as that a question mark in a regex slows the execution of a search regex, the <code>re.sub()</code> is slow compared to <code>re.findall()</code>, etc. .</span>
<span class="comment-copy">Unfortunately, on Windows 7.</span>
<span class="comment-copy">To 'know' that the event took place, the one regex has to find two related entries in the logs, separated by a variable number of lines (and, as in question text, theoretically existing in two different log files). It's possible I could run these as two different regexes and put the results in a list along with line numbers, so I could 'match' entries where they exist, but I think that would be a lot more code (of course, there may be no alternative).</span>
<span class="comment-copy">Can these events overlap?  If not, you just need one start-marker.  If so, it's more complicated (list or hash of start candidates).</span>
<span class="comment-copy">I haven't seen them overlap so far. But there will be hundreds if not thousands of the events in the logs for a day. Basically, to explain -- the start entry tells me what was done, the end entry tells me who did it, and there can be hundreds of lines in between.</span>
