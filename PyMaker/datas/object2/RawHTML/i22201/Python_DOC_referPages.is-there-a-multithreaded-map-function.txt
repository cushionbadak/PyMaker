<div class="post-text" itemprop="text">
<p>I have a function that is side-effect free. I would like to run it for every element in an array and return an array with all of the results.</p>
<p>Does Python have something to generate all of the values?</p>
</div>
<div class="post-text" itemprop="text">
<p>Try the Pool.map function from multiprocessing:</p>
<p><a href="http://docs.python.org/library/multiprocessing.html#using-a-pool-of-workers" rel="noreferrer">http://docs.python.org/library/multiprocessing.html#using-a-pool-of-workers</a></p>
<p>It's not multithreaded per-se, but that's actually good since multithreading is severely crippled in Python by the GIL.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use the multiprocessing python package (<a href="http://docs.python.org/library/multiprocessing.html" rel="nofollow noreferrer">http://docs.python.org/library/multiprocessing.html</a>). The cloud python package, available from PiCloud (<a href="http://www.picloud.com" rel="nofollow noreferrer">http://www.picloud.com</a>), offers a multi-processing map() function as well, which can offload your map to the cloud.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python now has the concurrent.futures module, which is the simplest way of getting map to work with either multiple threads or multiple processes. </p>
<p><a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow">https://docs.python.org/3/library/concurrent.futures.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Below is my <code>map_parallel</code> function. It works just like <code>map</code>, except it can run each element in parallel in a separate thread (but see note below). This answer builds upon <a href="https://stackoverflow.com/a/36198739/234270">another SO answer</a>.</p>
<pre><code>import threading
import logging
def map_parallel(f, iter, max_parallel = 10):
    """Just like map(f, iter) but each is done in a separate thread."""
    # Put all of the items in the queue, keep track of order.
    from queue import Queue, Empty
    total_items = 0
    queue = Queue()
    for i, arg in enumerate(iter):
        queue.put((i, arg))
        total_items += 1
    # No point in creating more thread objects than necessary.
    if max_parallel &gt; total_items:
        max_parallel = total_items

    # The worker thread.
    res = {}
    errors = {}
    class Worker(threading.Thread):
        def run(self):
            while not errors:
                try:
                    num, arg = queue.get(block = False)
                    try:
                        res[num] = f(arg)
                    except Exception as e:
                        errors[num] = sys.exc_info()
                except Empty:
                    break

    # Create the threads.
    threads = [Worker() for _ in range(max_parallel)]
    # Start the threads.
    [t.start() for t in threads]
    # Wait for the threads to finish.
    [t.join() for t in threads]

    if errors:
        if len(errors) &gt; 1:
            logging.warning("map_parallel multiple errors: %d:\n%s"%(
                len(errors), errors))
        # Just raise the first one.
        item_i = min(errors.keys())
        type, value, tb = errors[item_i]
        # Print the original traceback
        logging.info("map_parallel exception on item %s/%s:\n%s"%(
            item_i, total_items, "\n".join(traceback.format_tb(tb))))
        raise value
    return [res[i] for i in range(len(res))]
</code></pre>
<p><strong>NOTE</strong>: One thing to be careful of is Exceptions. Like normal <code>map</code>, the above function raises an exception if one of it's sub-thread raises an exception, and will stop iteration. However, due to the parallel nature, there's no guarantee that the earliest element will raise the first exception.</p>
</div>
<div class="post-text" itemprop="text">
<p>Maybe try the <a href="http://www.python.org/dev/peps/pep-3146/" rel="nofollow noreferrer">Unladen Swallow Python 3</a> implementation?  That might be a major project, and not guaranteed to be stable, but if you're inclined it could work.  Then <a href="http://docs.python.org/py3k/tutorial/datastructures.html#tut-listcomps" rel="nofollow noreferrer">list or set comprehensions</a> seem like the proper functional structure to use.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map" rel="nofollow noreferrer">concurrent.futures.ThreadPoolExecutor.map</a> in Python Standard Library (New in version 3.2).</p>
<blockquote>
<p>Similar to <a href="https://docs.python.org/3/library/functions.html#map" rel="nofollow noreferrer">map(func, *iterables)</a> except:</p>
<ul>
<li>the iterables are collected immediately rather than lazily;</li>
<li>func is executed asynchronously and several calls to func may be made concurrently.</li>
</ul>
</blockquote>
<p>A simple example (modified from <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="nofollow noreferrer">ThreadPoolExecutor Example</a>):</p>
<pre><code>import concurrent.futures
import urllib.request

URLS = [
  'http://www.foxnews.com/',
  'http://www.cnn.com/',
  'http://europe.wsj.com/',
  'http://www.bbc.co.uk/',
]

# Retrieve a single page and report the URL and contents
def load_url(url, timeout):
    # Do something here
    # For example
    with urllib.request.urlopen(url, timeout=timeout) as conn:
      try:
        data = conn.read()
      except Exception as e:
        # You may need a better error handler.
        return b''
      else:
        return data

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:
    # map
    l = list(executor.map(lambda url: load_url(url, 60), URLS))

print('Done.')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I would think there would be no reason to have such a function.  All Python threads have to execute on the same CPU.  Assuming your map function has no I/O component, you would not see any speedup in processing (and would probably see a slowdown due to context switching).</p>
<p>Other posters have mentioned multiprocessing - that is probably a better idea.</p>
</div>
<div class="post-text" itemprop="text">
<p>This functionality is not built in. However, <a href="http://honeypot.net/multi-processing-map-python" rel="nofollow noreferrer">someone has already implemented it</a>.</p>
</div>
<span class="comment-copy">do you mean map as in map-reduce?  can you give an example of an input and an output row?</span>
<span class="comment-copy">No, I do not mean map reduce. Since I want all of the data from each individual function returned. It's just that each value can be calculated independently of one another.  Although, since I think that I want the max of the set, maybe I can use map reduce here...</span>
<span class="comment-copy">map() would do what you say, operate on each element independently (with the GIL caveats mentioned below)</span>
<span class="comment-copy">Very cool, that last line sold me. I saw this multiprocessing library before but I thought that it was too heavy weight for my needs. I think that I see the light now :) Thank you.</span>
<span class="comment-copy">Is this answer up to date/still relevant in regards to multithreading/GIL?</span>
<span class="comment-copy">Yes, for some values of "severe."  I think it's a matter of opinion how bad it is, but I still prefer multiple processes on Linux where processes aren't too heavy.</span>
<span class="comment-copy">So is python multithreading really that bad? Do you have any sources on this info?</span>
<span class="comment-copy">It is not a question of "bad" vs "good" - I have mentioned something specific and concrete, which is that the Python interpreter will not allow threads to execute simultaneously on multiple processors.  The result, given that a processor can only be doing one thing at a time, is that CPU operations from different threads must be interleaved on a single processor.  Executing all of the instructions from one thread followed by all of the instructions from another thread can be no slower than executing instructions in round-robin fashion (and will indeed be faster, as in the first case there</span>
<span class="comment-copy">would only be a single context switch).</span>
<span class="comment-copy">I think your assumption (no I/O in the function) is unreasonable. You could warn the OP, warning them about the GIL, but saying "there would be no reason to have such a function" is <i>far</i> too broad.</span>
<span class="comment-copy">Whilst this may theoretically answer the question, <a href="//meta.stackoverflow.com/q/8259">it would be preferable</a> to include the essential parts of the answer here, and provide the link for reference.</span>
