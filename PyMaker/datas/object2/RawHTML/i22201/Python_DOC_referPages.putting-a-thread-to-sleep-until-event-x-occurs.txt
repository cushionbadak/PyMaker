<div class="post-text" itemprop="text">
<p>I'm writing to many files in a threaded app and I'm creating one handler per file. I have HandlerFactory class that manages the distribution of these handlers. What I'd like to do is that</p>
<p>thread A requests and gets foo.txt's file handle from the HandlerFactory class</p>
<p>thread B requests foo.txt's file handler</p>
<p>handler class recognizes that this file handle has been checked out</p>
<p>handler class puts thread A to sleep</p>
<p>thread B closes file handle using a wrapper method from HandlerFactory</p>
<p>HandlerFactory notifies sleeping threads</p>
<p>thread B wakes and successfully gets foo.txt's file handle</p>
<p>This is what I have so far, </p>
<pre><code>def get_handler(self, file_path, type):
    self.lock.acquire()
    if file_path not in self.handlers:
        self.handlers[file_path] = open(file_path, type)
    elif not self.handlers[file_path].closed:
        time.sleep(1)
    self.lock.release()
    return self.handlers[file_path][type]
</code></pre>
<p>I believe this covers the sleeping and handler retrieval successfully, but I am unsure how to wake up all threads, or even better wake up a specific thread.</p>
</div>
<div class="post-text" itemprop="text">
<p>What you're looking for is known as a condition variable.</p>
<p><a href="http://en.wikipedia.org/wiki/Monitor_%28synchronization%29#Blocking_condition_variables" rel="nofollow noreferrer">Condition Variables</a></p>
<p><a href="https://docs.python.org/2.0/lib/condition-objects.html" rel="nofollow noreferrer">Here</a> is the Python 2 library reference.<br/>
For Python 3 it can be found <a href="https://docs.python.org/3/library/threading.html#condition-objects" rel="nofollow noreferrer">here</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Looks like you want a  <a href="http://docs.python.org/library/threading.html?highlight=threading%20event#semaphore-objects" rel="nofollow noreferrer">threading.Semaphore</a> associated with each handler (other synchronization objects like Events and Conditions are also possible, but a Semaphore seems simplest for your needs).  (Specifically, use a <a href="http://docs.python.org/library/threading.html?highlight=threading%20event#threading.BoundedSemaphore" rel="nofollow noreferrer">BoundedSemaphore</a>: for your use case, that will raise an exception immediately for programming errors that erroneously release the semaphone more times than they acquire it -- and that's exactly the reason for being of the <em>bounded</em> version of semaphones;-).</p>
<p>Initialize each semaphore to a value of <code>1</code> when you build it (so that means the handler is available).  Each using-thread calls <code>acquire</code> on the semaphore to get the handler (that may block it), and <code>release</code> on it when it's done with the handler (that will unblock exactly one of the waiting threads).  That's simpler than the acquire/wait/notify/release lifecycle of a Condition, and more future-proof too, since as the docs for Condition say:</p>
<blockquote>
<p>The current implementation wakes up
  exactly one thread, if any are
  waiting. However, itâ€™s not safe to
  rely on this behavior. A future,
  optimized implementation may
  occasionally wake up more than one
  thread.</p>
</blockquote>
<p>while with a Semaphore you're playing it safe (the semantics whereof <em>are</em> safe to rely on: if a semaphore is initialized to N, there are at all times between 0 and N-1 [[included]] threads that have successfully acquired the semaphore and not yet released it).</p>
</div>
<div class="post-text" itemprop="text">
<p>You do realize that Python has a giant lock, so that most of the benefits of multi-threading you do not get, right?</p>
<p>Unless there is some reason for the master thread to do something with the results of each worker, you may wish to consider just forking off another process for each request. You won't have to deal with locking issues then. Have the children do what they need to do, then die. If they do need to communicate back, do it over a pipe, with XMLRPC, or through a sqlite database (which is threadsafe).</p>
</div>
<span class="comment-copy">This ended up solving my problem, thanks.</span>
<span class="comment-copy">The GIL does not significantly degrade I/O performance, only processing performance (see <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow noreferrer">wiki.python.org/moin/GlobalInterpreterLock</a>). Since the OP seems to be using threads to parallelise I/O, your assertion that he is losing most of the benefits of multi-threading is unwarranted.</span>
<span class="comment-copy">I suggest you look at page 38 of the referenced PDF file at <a href="http://www.dabeaz.com/python/GIL.pdf" rel="nofollow noreferrer">dabeaz.com/python/GIL.pdf</a>. Even with 1 CPU the GIL degrades response time of I/O bound threads on a multi-core system (and sometimes on a single-core system), if you are using multiple python threads, due to the overhead of checking the GIL.</span>
