<div class="post-text" itemprop="text">
<p>I'm trying to scrape from a non-English website using Scrapy. The scraped results as JSON look something like this:</p>
<pre><code>{"price": "13,000", "name": "\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02\u7528\u2605 \u30c6\u30ec\u30d3\u672c\u4f53 20v\u578b \u767d \u9001\u6599\u8fbc"},
</code></pre>
<p>This is the code I'm using:</p>
<pre><code>def parse(self, response):
    for sel in response.xpath('//section[@class="items-box"]'):
      item = ShopItem()
      item['name'] = sel.xpath('a/div/h3/text()').extract()
      item['price'] = sel.xpath('a/div/div/div[1]/text()').extract().replace("$", "")
      yield item
</code></pre>
<p>How would I output unescaped Unicode characters onto the JSON?</p>
</div>
<div class="post-text" itemprop="text">
<p><strong>Edit</strong> (2016-10-19):</p>
<p>With Scrapy 1.2+, you can use the <a href="https://docs.scrapy.org/en/latest/topics/feed-exports.html#std:setting-FEED_EXPORT_ENCODING" rel="nofollow"><code>FEED_EXPORT_ENCODING</code></a> set to the character encoding you need for the output JSON file, e.g <code>FEED_EXPORT_ENCODING = 'utf-8'</code> (the default value being <code>None</code>, which means <code>\uXXXX</code> escaping)</p>
<hr/>
<p>Note: I'm adapting <a href="https://github.com/scrapy/scrapy/issues/1963#issuecomment-215784229" rel="nofollow">what I wrote on GitHub for a similar issue</a> I linked to in the question's comments.</p>
<p>Note that there's an open issue on Scrapy to make the output encoding a parameter: <a href="https://github.com/scrapy/scrapy/issues/1965" rel="nofollow">https://github.com/scrapy/scrapy/issues/1965</a></p>
<hr/>
<p><a href="https://github.com/scrapy/scrapy/blob/ebef6d7c6dd8922210db8a4a44f48fe27ee0cd16/scrapy/utils/serialize.py#L11" rel="nofollow">Scrapy's default JSON exporter</a> uses (the default) <code>ensure_ascii=True</code> argument, so it outputs Unicode characters as <code>\uXXXX</code> sequences before writing to file. (This is what is used when doing <code>-o somefile.json</code>)</p>
<p>Setting <code>ensure_ascii=False</code> in the exporter will output Unicode strings, <a href="https://github.com/scrapy/scrapy/blob/cf716ea200b4e7056a570434b8ab46a61aa20240/scrapy/exporters.py#L114" rel="nofollow">which will end up as UTF-8 encoded on file</a>. See custom exporter code at the bottom here.</p>
<p>To illustrate, let's read your input JSON string back into some data to work on:</p>
<pre><code>&gt;&gt;&gt; import json
&gt;&gt;&gt; test = r'''{"price": "13,000", "name": "\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02\u7528\u2605 \u30c6\u30ec\u30d3\u672c\u4f53 20v\u578b \u767d \u9001\u6599\u8fbc"}'''
&gt;&gt;&gt; json.loads(test)
{u'price': u'13,000', u'name': u'\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02\u7528\u2605 \u30c6\u30ec\u30d3\u672c\u4f53 20v\u578b \u767d \u9001\u6599\u8fbc'}
</code></pre>
<p>The input with <code>\uXXXX</code> sequences is valid JSON for Python (as it should), and <code>loads()</code> produces a valid Python <code>dict</code>.</p>
<p>Now let's serialize to JSON again:</p>
<pre><code>&gt;&gt;&gt; # dumping the dict back to JSON, with default ensure_ascii=True
&gt;&gt;&gt; json.dumps(json.loads(test))
'{"price": "13,000", "name": "\\u58c1\\u6bb4\\u308a\\u4ee3\\u884c\\u69d8\\u5c02\\u7528\\u2605 \\u30c6\\u30ec\\u30d3\\u672c\\u4f53 20v\\u578b \\u767d \\u9001\\u6599\\u8fbc"}'
&gt;&gt;&gt; 
</code></pre>
<p>And now with <code>ensure_ascii=False</code></p>
<pre><code>&gt;&gt;&gt; # now dumping with ensure_ascii=False, you get a Unicode string
&gt;&gt;&gt; json.dumps(json.loads(test), ensure_ascii=False)
u'{"price": "13,000", "name": "\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02\u7528\u2605 \u30c6\u30ec\u30d3\u672c\u4f53 20v\u578b \u767d \u9001\u6599\u8fbc"}'
&gt;&gt;&gt;
</code></pre>
<p>Let's print to see the difference:</p>
<pre><code>&gt;&gt;&gt; print json.dumps(json.loads(test))
{"price": "13,000", "name": "\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02\u7528\u2605 \u30c6\u30ec\u30d3\u672c\u4f53 20v\u578b \u767d \u9001\u6599\u8fbc"}

&gt;&gt;&gt; print json.dumps(json.loads(test), ensure_ascii=False)
{"price": "13,000", "name": "壁殴り代行様専用★ テレビ本体 20v型 白 送料込"}
</code></pre>
<p>If you want to write JSON items as UTF-8, you can do it like this:</p>
<p>1.. define a custom item exporter, e.g. in an <code>exporters.py</code> file in your project</p>
<pre><code>$ cat myproject/exporters.py 
from scrapy.exporters import JsonItemExporter


class Utf8JsonItemExporter(JsonItemExporter):

    def __init__(self, file, **kwargs):
        super(Utf8JsonItemExporter, self).__init__(
            file, ensure_ascii=False, **kwargs)
</code></pre>
<p>2.. replace the default JSON item exporter in your <code>settings.py</code></p>
<pre><code>FEED_EXPORTERS = {
    'json': 'myproject.exporters.Utf8JsonItemExporter',
}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Use <a href="https://docs.python.org/3/library/codecs.html#text-encodings" rel="nofollow">the <code>codecs</code> module</a> for <a href="https://docs.python.org/3/library/codecs.html#text-encodings" rel="nofollow">text -&gt; text decoding</a> (In Python 2 it's not strictly necessary, but in Python 3 <code>str</code> doesn't have a <code>decode</code> method, because the methods are for <code>str</code> -&gt; <code>bytes</code> and back, not <code>str</code> -&gt; <code>str</code>). Using the <code>unicode_escape</code> codec for decoding will get you the correct data back:</p>
<pre><code>import codecs

somestr = codecs.decode(strwithescapes, 'unicode-escape')
</code></pre>
<p>So to fix the names you're getting, you'd do:</p>
<pre><code>item['name'] = codecs.decode(sel.xpath('a/div/h3/text()').extract(), 'unicode-escape')
</code></pre>
<p>If the problem is in JSON you're producing, you'd want to just make sure the <code>json</code> module isn't forcing strings to be ASCII with character encodings; it does so by default because not all JSON parsers can handle true Unicode characters (they often assume data is sent as ASCII bytes with escapes). So wherever you call <code>json.dump</code>/<code>json.dumps</code> (or create a <code>json.JSONEncoder</code>), make sure to explicitly pass <code>ensure_ascii=False</code>.</p>
</div>
<span class="comment-copy">There was an issue the other day about just this: <a href="https://github.com/scrapy/scrapy/issues/1963" rel="nofollow noreferrer">github.com/scrapy/scrapy/issues/1963</a>. Check how to use a <a href="https://github.com/scrapy/scrapy/issues/1963#issuecomment-215797219" rel="nofollow noreferrer">custom items exporter</a> <b>without</b> <code>ensure_ascii=True</code> (the default with scrapy)</span>
<span class="comment-copy">The example is valid json (almost - it has a comma at the end) and could be converted to python with <code>json.loads</code>. But your question is still very confusing. Where is this json exactly? Is it embedded in an html page? If <code>name</code> is in the json, how would it also be accessed with the <code>'a/div/h3/text()'</code> xpath?</span>
<span class="comment-copy">@tdelaney The json is outputted by adding the <code>-o</code> option to <code>scrapy crawl spider</code></span>
<span class="comment-copy"><code>\uXXXX</code> encoding is valid for JSON. OP already has a valid JSON string and there is no need to do a unicode-escape. <code>json.loads</code> will convert the string to python.</span>
<span class="comment-copy">@tdelaney: Agreed it's valid, but it's also perfectly reasonable to want to avoid doing so, either because the receiver is not a proper JSON parser (many implementations omit parts of the spec, or it's not even a proper JSON parser because some jerk rolled their own parsing code), or to reduce size (typically JSON is UTF-8 encoded, and UTF-8 for non-ASCII characters will be 2-4 bytes, usually 3 for East Asian languages, vs. a fixed 6 bytes for the ASCII escape code). It looks like the OP may be using JSON to format data scraped and organized in their script, not parsing JSON from the site.</span>
<span class="comment-copy">@tdelaney: I think the idea is that they're parsing XML/HTML to pull specific bits of data out, then storing them in some object that they can JSON encode (which makes it easier to use or transmit later, avoiding XML/HTML parsing costs). So the HTML has these escapes in it, and they end up in the JSON encoded output (or they're not using <code>ensure_ascii=False</code> and the JSON encoding is creating them), so my approaches cover both sides; removing the encoding from the data pulled from the HTML and avoiding readding it on JSON serialization.</span>
<span class="comment-copy">Okay, that makes sense. if the text node at <code>a/div/h3/text()</code> is literally <code>\u58c1\u6bb4\u308a\u4ee3\u884c\u69d8\u5c02...</code>, then unicode-escape makes sense. You may have to unescape XML entities also. But if that's the case, why didn't OP say so?!</span>
<span class="comment-copy">Upon implementing the suggestion by @ShadowRanger, the following error occurred: <code>UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-18: ordinal not in range(128)</code> Also @tdelaney, I'm quite a noob and can't figure what you're saying about XML entities? I prefer to unescape for the sake of legibility.</span>
