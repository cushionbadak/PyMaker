<div class="post-text" itemprop="text">
<p>I am working in the following code using sklearn and python to vectorize this text:</p>
<p><a href="https://gist.github.com/adolfo255/be2bc75327e288d4d090659e231fa487" rel="nofollow">https://gist.github.com/adolfo255/be2bc75327e288d4d090659e231fa487</a></p>
<p>My code is this:</p>
<pre><code>#!/usr/bin/env python
# -*- coding: utf-8
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
f = open('text.txt')
corpus= []
for line in f:
        corpus.append( line ),
print(corpus)      
vectorizer = TfidfVectorizer(min_df=1,ngram_range=(1, 5),analyzer='char')
X = vectorizer.fit_transform(corpus)
idf = vectorizer.idf_
#print dict(zip(vectorizer.get_feature_names(), idf))
print (vectorizer.get_feature_names())
output= vectorizer.get_feature_names()
target = open("output.txt", 'w')
for line in output: 
    target.write(line),
target.close()
print(target)
</code></pre>
<p>Everything goes well, until the part when i try to write the output, i would like to write on disk the output of the last print, I mean this:</p>
<pre><code>print (vectorizer.get_feature_names())
</code></pre>
<p>I tried the following:</p>
<pre><code>output= vectorizer.get_feature_names()
target = open("output.txt", 'w')
for line in output: 
    target.write(line),
target.close()
print(target)
</code></pre>
<p>but this approach did not work.
I got:</p>
<pre><code>'ascii' codec can't encode character u'\xfa' in position 4: ordinal not in range(128)
UnicodeEncodeError Traceback (most recent call last)
main.py in &lt;module&gt;()
     16 target = open("output.txt", 'w')
     17 for line in output:
---&gt; 18     target.write(line),
     19 target.close()
     20 print(target)
UnicodeEncodeError: 'ascii' codec can't encode character u'\xfa' in position 4: ordinal not in range(128)
File written
output.txt
</code></pre>
<p>I would appreciate any suggestion of how to achieve this, since i want to analyze the output later, the problem is related with the encoding but i donÂ´t know how to fix it, i would appreciate any suggestion.</p>
</div>
<div class="post-text" itemprop="text">
<p>In order to convert your <code>str</code> (aka unicode) object into bytes to be written to the file, Python needs to encode it using some encoding. For some reason (either due to your system's default encoding or because of some code you haven't pasted here), Python is using the ASCII encoding, which cannot handle some of the code points in your object.</p>
<p>Because of the <code>print(...)</code> statements without any <code>from __future__ import print_function</code>, I assume this is Python 3. One fix is to ensure that the encoding used to write to a file is UTF-8. On my system that's the default:</p>
<pre><code>&gt;&gt;&gt; import locale
&gt;&gt;&gt; locale.getpreferredencoding(False)
'UTF-8'
</code></pre>
<p>Therefore, on my machine, the code you pasted works fine. You can specify the encoding and override the default in your <code>open</code> calls, e.g. <code>open('text.txt', encoding='utf-8')</code> and <code>open('output.txt', 'w', encoding='utf-8')</code> (<a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow">docs</a>).</p>
<p>A good reference for understanding these issues can be found <a href="https://docs.python.org/3/howto/unicode.html#reading-and-writing-unicode-data" rel="nofollow">in the Unicode HOWTO</a>.</p>
<p>If you're in fact using Python 2, you probably want to use <code>codecs.open</code> as described <a href="https://docs.python.org/2/howto/unicode.html#reading-and-writing-unicode-data" rel="nofollow">here</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Since this code is written on python 2.7.10 the problem was fixed using codecs, and the library called: chardet to see the encoding of the data, as follows</p>
<pre><code>#!/usr/bin/env python
# -*- coding: utf-8
import codecs
from sklearn.feature_extraction.text import TfidfVectorizer
f = codecs.open('text.txt', encoding='utf-8')
print type(f)
import chardet 
rawdata=open('text.txt',"r").read()
print(chardet.detect(rawdata))
corpus= []
for line in f:
        corpus.append( line ),
vectorizer = TfidfVectorizer(min_df=1,ngram_range=(1, 5),analyzer='char')
X = vectorizer.fit_transform(corpus)
idf = vectorizer.idf_
print (vectorizer.get_feature_names())
output= vectorizer.get_feature_names()
print type(output)
target= codecs.open('output.txt', encoding='utf-8',mode='w+')
for line in output: 
    target.write(line),
target.close()
print(target)
</code></pre>
</div>
<span class="comment-copy">Hello, sorry about the version I am working on python 2.7.10, when i put the line: f = open('text.txt', encoding='utf-8'), i get the following error: 'encoding' is an invalid keyword argument for this function,  I don't know if this is related to the fact that I am working on this version.</span>
<span class="comment-copy">Yes, in Python 2.7.10, <code>open</code> doesn't take an <code>encoding</code> argument; that's why the HOWTO suggests you use <code>codecs.open</code> instead, as I mentioned.</span>
