<div class="post-text" itemprop="text">
<p>I'm using python 3.5 and I'm checking the performance of urllib module Vs requests module.
I wrote two clients in python the first one is using the urllib module and the second one is using the request module.
they both generate a binary data, which I send to a server which is based on flask and from the flask server I also return a binary data to the client.
I found that time took to send the data from the client to the server took same time for both modules (urllib, requests) but the time it took to return data from the server to the client is more then twice faster in urllib compare to request.
I'm working on localhost.<br/>
<strong>my question is why?<br/>
what I'm doing wrong with request module which make it to be slower?</strong> </p>
<p><strong>this is the server code :</strong></p>
<pre><code>from flask import Flask, request
app = Flask(__name__)
from timeit import default_timer as timer
import os

@app.route('/onStringSend', methods=['GET', 'POST'])
def onStringSend():
    return data

if __name__ == '__main__':
    data_size = int(1e7)
    data = os.urandom(data_size)    
    app.run(host="0.0.0.0", port=8080)
</code></pre>
<p><strong>this is the client code based on urllib :</strong></p>
<pre><code>import urllib.request as urllib2
import urllib.parse
from timeit import default_timer as timer
import os

data_size = int(1e7)
num_of_runs = 20
url = 'http://127.0.0.1:8080/onStringSend'

def send_binary_data():
    data = os.urandom(data_size)
    headers = {'User-Agent': 'Mozilla/5.0 (compatible; Chrome/22.0.1229.94;  Windows NT)', 'Content-Length': '%d' % len(data), 'Content-Type':  'application/octet-stream'}
    req = urllib2.Request(url, data, headers)
    round_trip_time_msec = [0] * num_of_runs
    for i in range(0,num_of_runs):
        t1 = timer()
        resp = urllib.request.urlopen(req)
        response_data = resp.read()
        t2 = timer()
        round_trip_time_msec[i] = (t2 - t1) * 1000

    t_max = max(round_trip_time_msec)
    t_min = min(round_trip_time_msec)
    t_average = sum(round_trip_time_msec)/len(round_trip_time_msec)

    print('max round trip time [msec]: ', t_max)
    print('min round trip time [msec]: ', t_min)
    print('average round trip time [msec]: ', t_average)


send_binary_data()
</code></pre>
<p><strong>this is the client code based on requests :</strong></p>
<pre><code>import requests
import os
from timeit import default_timer as timer


url = 'http://127.0.0.1:8080/onStringSend'
data_size = int(1e7)
num_of_runs = 20


def send_binary_data():
    data = os.urandom(data_size)
    s = requests.Session()
    s.headers['User-Agent'] = 'Mozilla/5.0 (compatible; Chrome/22.0.1229.94;Windows NT)'
    s.headers['Content-Type'] = 'application/octet-stream'
    s.headers['Content-Length'] = '%d' % len(data)

    round_trip_time_msec = [0] * num_of_runs
    for i in range(0,num_of_runs):
        t1 = timer()
        response_data = s.post(url=url, data=data, stream=False, verify=False)
        t2 = timer()
        round_trip_time_msec[i] = (t2 - t1) * 1000

    t_max = max(round_trip_time_msec)
    t_min = min(round_trip_time_msec)
    t_average = sum(round_trip_time_msec)/len(round_trip_time_msec)

    print('max round trip time [msec]: ', t_max)
    print('min round trip time [msec]: ', t_min)
    print('average round trip time [msec]: ', t_average)

send_binary_data()
</code></pre>
<p>thanks very much</p>
</div>
<div class="post-text" itemprop="text">
<p>First of all, to reproduce the problem, I had to add the following line to your <code>onStringSend</code> function:</p>
<pre><code>request.get_data()
</code></pre>
<p>Otherwise, I was getting “connection reset by peer” errors because the server’s receive buffer kept filling up.</p>
<p>Now, the immediate reason for this problem is that <code>Response.content</code> (which is called implicitly when <code>stream=False</code>) <a href="https://github.com/kennethreitz/requests/blob/87704105af65b382b86f168f6a54192eab91faf2/requests/models.py#L741" rel="noreferrer">iterates over the response data in chunks of 10240 bytes</a>:</p>
<pre><code>self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()
</code></pre>
<p>Therefore, the easiest way to solve the problem is to use <code>stream=True</code>, thus telling Requests that you will be reading the data at your own pace:</p>
<pre><code>response_data = s.post(url=url, data=data, stream=True, verify=False).raw.read()
</code></pre>
<p>With this change, the performance of the Requests version becomes more or less the same as that of the urllib version.</p>
<p>Please also see the “<a href="http://requests.readthedocs.io/en/master/user/quickstart/#raw-response-content" rel="noreferrer">Raw Response Content</a>” section in the Requests docs for useful advice.</p>
<p>Now, the interesting question remains: why is <code>Response.content</code> iterating in such small chunks? After <a href="https://botbot.me/freenode/python-requests/2016-05-11/?msg=65874287&amp;page=1" rel="noreferrer">talking to Cory Benfield</a>, a core developer of Requests, it looks like there may be no particular reason. I filed <a href="https://github.com/kennethreitz/requests/issues/3186" rel="noreferrer">issue #3186</a> in Requests to look further into this.</p>
</div>
<span class="comment-copy">If I'm not wrong, <code>requests</code> is built on top of Python's <code>urllib</code>. Hence, <code>requests</code> must be processing the data which it receives. And that extra time goes in processing it.</span>
<span class="comment-copy">@JRodDynamite No, Requests is built on top of <a href="http://urllib3.readthedocs.io/en/latest/" rel="nofollow noreferrer">urllib3</a>, which has nothing to do with the standard library’s <a href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request" rel="nofollow noreferrer">urllib.request</a>. They are, however, both built on top of the standard library’s <a href="https://docs.python.org/3/library/http.client.html" rel="nofollow noreferrer">http.client</a>.</span>
<span class="comment-copy">@VasiliyFaronov - Oh okay. Thanks for the info! :)</span>
<span class="comment-copy">What local server are you using? Does your server support re-using connections? That's the most obvious performance benefit you'll get over using the standard library's urllib. Also multi-threading support if you're into that.</span>
<span class="comment-copy">More specifically, if you put your flask app behind gunicorn or uwsgi or similar, you might see more of a difference.</span>
