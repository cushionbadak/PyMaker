<div class="post-text" itemprop="text">
<p>To improve my code which has one heavy loop I need a speed up. How can I implement multiprocessing for a code like this? (a is typical of size 2 and l up to 10)</p>
<pre><code>for x1 in range(a**l):
    for x2 in range(a**l):
        for x3 in range(a**l):
            output[x1,x2,x3] = HeavyComputationThatIsThreadSafe1(x1,x2,x3)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the <code>HeavyComputationThatIsThreadSafe1</code> function only uses arrays and not python objects, I would using a <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow">concurrent futures</a> (or the <a href="https://pypi.python.org/pypi/futures" rel="nofollow">python2 backport</a>) <code>ThreadPoolExecutor</code> along with <a href="http://numba.pydata.org/" rel="nofollow">Numba</a> (or <a href="http://cython.org/" rel="nofollow">cython</a>) with the GIL released. Otherwise use a <code>ProcessPoolExecutor</code>. </p>
<p>See:</p>
<p><a href="http://numba.pydata.org/numba-doc/latest/user/examples.html#multi-threading" rel="nofollow">http://numba.pydata.org/numba-doc/latest/user/examples.html#multi-threading</a></p>
<p>You'd want to parallelize the calculation at the level of the outermost loop and and then fill <code>output</code> from the chunks resulting from each thread/process. This assumes the cost of doing so is much cheaper than the computation, which should be the case.</p>
</div>
<span class="comment-copy">ShadowRanger's comment on <a href="http://stackoverflow.com/q/37081288/1461210">your other question</a> still stands - all the threads in the world are not going to make much of a dent if you're committed to calling <code>HeavyComputationThatIsThreadSafe1</code> <i>over a billion times</i>. How many seconds does a single call to <code>HeavyComputationThatIsThreadSafe1</code> take? Take that number, multiply it by 1073741824 and divide by the number of cores you have. That gives you the absolute best-case scenario runtime you could achieve with multiprocessing.</span>
<span class="comment-copy">I addressed the performance problems with the <code>HeavyComputationThatiIsThreadSafe</code> in <a href="http://stackoverflow.com/a/37100607/392949">the original question</a> you linked to. Even with the data size you mention, it only takes ~8GB of memory and 45s to go over all three nested loops, if you take some reasonable optimization sets.</span>
