<div class="post-text" itemprop="text">
<p>I want to display some samples of augmented training images.</p>
<p>My transform includes the standard ImageNet <code>transforms.Normalize</code> like this:</p>
<pre><code>train_transforms = transforms.Compose([transforms.RandomRotation(30),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406],
                                                            [0.229, 0.224, 0.225])])
</code></pre>
<p>However, because of the <code>Normalise</code>, the images display in weird colours.</p>
<p><a href="https://stackoverflow.com/questions/52785599/un-normalizing-pytorch-data">This answer</a> says I'd need access to the original image, which is difficult when the transforms are applied at load time:</p>
<pre><code>image_datasets['train'] = datasets.ImageFolder(train_dir, transform=train_transforms)
</code></pre>
<p>How would I go about displaying a few sample augmented images in their usual colours while using the normalised ones for calculation?</p>
</div>
<div class="post-text" itemprop="text">
<p>I suggest two options:</p>
<ol>
<li>Create a separate "transformation" stage that displays image and passes it further without a change.  A free bonus is that you can insert in at any stage in the transformation list.</li>
</ol>
<pre><code>    import cv2
    import numpy as np
    def TransformShow(name="img", wait=100):
        def transform_show(img):
            cv2.imshow(name, np.array(img))
            cv2.waitKey(wait)
            return img
        return transform_show
</code></pre>
<p>Insert this "transformer" before <code>ToTensor()</code>:</p>
<pre><code>                                       transforms.RandomHorizontalFlip(),
                                       TransformShow("window_name", delay_in_ms),
                                       transforms.ToTensor(),
</code></pre>
<p>Use zero <code>delay_in_ms</code> to wait for a keypress.</p>
<p>I use <strong>OpenCV</strong> here to display images. It can also be done with just Pillow/PIL, but I didn't like how it handles it.</p>
<ol start="2">
<li>Undo normalization and display image.</li>
</ol>
<pre><code>def show_image(img, name="img", wait=100):
    mean = np.array([0.485, 0.456, 0.406])
    std =  np.array([0.229, 0.224, 0.225])
    cv2.imshow(name, img.cpu().numpy().transpose((1,2,0)) * std + mean)
    cv2.waitKey(wait)
</code></pre>
<p>and then call it as</p>
<pre><code>        show_image(data[0], "unaug", 1)
</code></pre>
<ol start="3">
<li>The last approach can be approximated with a quick two-liner, but with somewhat distorted colors:</li>
</ol>
<pre><code>    cv2.imshow("approx", data[0].cpu().numpy().transpose((1,2,0)) * 0.225 + 0.45)
    cv2.waitKey(10)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I already faced the same issue. My solution was to create a different <code>torch.Dataset</code> with data augmentation but without normalization.</p>
<p><a href="https://github.com/fabioperez/skin-data-augmentation/blob/a96ee0c70c8907a05a19cee96710116659685ee1/train.py#L169-L171" rel="nofollow noreferrer">Here</a> I create the <code>Dataset</code>. <a href="https://github.com/fabioperez/skin-data-augmentation/blob/a96ee0c70c8907a05a19cee96710116659685ee1/auglib/augmentation/augmentations.py#L70" rel="nofollow noreferrer">Here</a> I have a class that implements the augmentations. I have two members: <code>self.tf_augment</code> and <code>self.tf_transform</code>. The former only applies data augmentation while the latter applies data augmentation plus normalization.</p>
</div>
<div class="post-text" itemprop="text">
<p>Just undo the normalization operation i.e. multiply by standard deviation and add 
the mean. </p>
<p>Please see the imshow method in the pytorch tutorials:
<a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#visualize-a-few-images" rel="nofollow noreferrer">https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#visualize-a-few-images</a> </p>
</div>
<div class="post-text" itemprop="text">
<p>To answer my own question, I came up with the following:</p>
<p><img alt="Example output" src="https://i.imgur.com/wBNJk9J.png"/></p>
<pre><code># Undo transforms.Normalize
def denormalise(image):
    image = image.numpy().transpose(1, 2, 0)  # PIL images have channel last
    mean = [0.485, 0.456, 0.406]
    stdd = [0.229, 0.224, 0.225]
    image = (image * stdd + mean).clip(0, 1)
    return image


example_rows = 2
example_cols = 5

sampler = torch.utils.data.RandomSampler(image_datasets['train'],
                                         num_samples=example_rows * example_cols)

# Get a batch of images and labels  
images, indices = next(iter(sampler)) 

plt.rcParams['figure.dpi'] = 120  # Increase size of pyplot plots

# Show a grid of example images    
fig, axes = plt.subplots(example_rows, example_cols, figsize=(9, 5)) #  sharex=True, sharey=True)
axes = axes.flatten()
for ax, image, index in zip(axes, images, indices):
    ax.imshow(denormalise(image))
    ax.set_axis_off()
    ax.set_title(class_names[index], fontsize=7)

fig.subplots_adjust(wspace=0.02, hspace=0)
fig.suptitle('Augmented training set images', fontsize=20)
plt.show()
</code></pre>
<p>This is based on <a href="https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#visualize-a-few-images" rel="nofollow noreferrer">PyTorch's Transfer Learning Tutorial's code</a> but displays the title above each image and generally looks much nicer.</p>
</div>
<span class="comment-copy">Thanks for the suggestions but I find them too high-level to be useful. Given my code, how would you go about (2)?</span>
