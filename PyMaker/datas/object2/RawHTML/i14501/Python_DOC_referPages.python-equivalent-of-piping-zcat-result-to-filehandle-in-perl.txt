<div class="post-text" itemprop="text">
<p>I have a huge pipeline written in Python that uses very large .gz files (~14GB compressed), but need a better way to send certain lines to an external software (<a href="http://141.80.164.19/bioinf_dokus/blastall/README_db.htm" rel="nofollow">formatdb from blast-legacy/2.2.26</a>).  I have a Perl script someone wrote for me a long time ago that does this extremely fast, but I need to do that same thing in Python given that the rest of the pipeline is written in Python and I have to keep it that way.  The Perl script uses two file handles, one to hold zcat of .gz file and the other to store the lines the software needs (2 of every 4) and use it as the input. It involves bioinformatics, but no experience is needed.  The file is in fastq format and the software needs it in fasta format.  Every 4 lines is a fastq record, take the 1st and 3rd line and add '&gt;' to the beginning of the 1st line and that is the fasta equivalent the formatdb software will use for each record.</p>
<p>The perl script is as follows:</p>
<pre><code>#!/usr/bin/perl 
my $SRG = $ARGV[0]; # reads.fastq.gz

open($fh, sprintf("zcat %s |", $SRG)) or die "Broken gunzip $!\n";

# -i: input -n: db name -p: program 
open ($fh2, "| formatdb -i stdin -n $SRG -p F") or die "no piping formatdb!, $!\n";

#Fastq =&gt; Fasta sub
my $localcounter = 0;
while (my $line = &lt;$fh&gt;){
        if ($. % 4==1){
                print $fh2 "\&gt;" . substr($line, 1);
                $localcounter++;
        }
        elsif ($localcounter == 1){
                print $fh2 "$line";
                $localcounter = 0;
        }
        else{
        }
}
close $fh;
close $fh2;
exit;
</code></pre>
<p>It works really well.  How could I do this same thing in Python?  I like how Perl can use those file handles, but I'm not sure how to do that in Python without creating an actual file.  All I can think of is to gzip.open the file and write the two lines of every record I need to a new file and use that with "formatdb", but it is way too slow.  Any ideas?  I need to work it into the python pipeline, so I can't just rely on the perl script and I would also like to know how to do this in general.  I assume I need to use some form of the subprocess module.</p>
<p>Here is my Python code, but again it is way to slow and speed is the issue here (HUGE FILES):</p>
<pre><code>#!/usr/bin/env python

import gzip
from Bio import SeqIO # can recognize fasta/fastq records
import subprocess as sp
import os,sys

filename = sys.argv[1] # reads.fastq.gz

tempFile = filename + ".temp.fasta"

outFile = open(tempFile, "w")

handle = gzip.open(filename, "r")
# parses each fastq record
# r.id and r.seq are the 1st and 3rd lines of each record
for r in SeqIO.parse(handle, "fastq"):
    outFile.write("&gt;" + str(r.id) + "\n")
    outFile.write(str(r.seq) + "\n")

handle.close()
outFile.close()

    cmd = 'formatdb -i ' + str(tempFile) + ' -n ' + filename + ' -p F '
    sp.call(cmd, shell=True)

    cmd = 'rm ' + tempFile
    sp.call(cmd, shell=True)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First, there's a much better solution in both Perl and Python: just use a <code>gzip</code> library. In Python, there's one <a href="https://docs.python.org/3/library/gzip.html">in the stdlib</a>; in Perl, you can find one on CPAN. For example:</p>
<pre><code>with gzip.open(path, 'r', encoding='utf-8') as f:
    for line in f:
        do_stuff(line)
</code></pre>
<p>Much simpler, and more efficient, and more portable, than shelling out to <code>zcat</code>.</p>
<hr/>
<p>But if you really do want to launch a subprocess and control its pipes in Python, you can do it with the <a href="https://docs.python.org/3/library/subprocess.html"><code>subprocess</code></a> module. And, unlike perl, Python can do this without having to stick a shell in the middle. There's even a nice section in the docs on <a href="https://docs.python.org/3/library/subprocess.html#replacing-older-functions-with-the-subprocess-module">Replacing Older Functions with the <code>subprocess</code> Module</a> that gives you recipes.</p>
<p>So:</p>
<pre><code>zcat = subprocess.Popen(['zcat', path], stdout=subprocess.PIPE)
</code></pre>
<p>Now, <code>zcat.stdout</code> is a file-like object, with the usual <code>read</code> methods and so on, wrapping the pipe to the <code>zcat</code> subprocess.</p>
<p>So, for example, to read a binary file 8K at a time in Python 3.x:</p>
<pre><code>zcat = subprocess.Popen(['zcat', path], stdout=subprocess.PIPE)
for chunk in iter(functools.partial(zcat.stdout.read, 8192), b''):
    do_stuff(chunk)
zcat.wait()
</code></pre>
<p>(If you want to do this in Python 2.x, or read a text file one line at a time instead of a binary file 8K at a time, or whatever, the changes are the same as they'd be for any other file-handling coding.)</p>
</div>
<div class="post-text" itemprop="text">
<p>You can parse the whole file and load it as a list of lines using this function:</p>
<pre><code>    def convert_gz_to_list_of_lines(filepath):
     """Parse gz file and convert it into a list of lines."""
     file_as_list = list()
     with gzip.open(filepath, 'rt', encoding='utf-8') as f:
      try:
       for line in f:
        file_as_list.append(line)
      except EOFError:
        file_as_list = file_as_list
      return file_as_list
</code></pre>
</div>
<span class="comment-copy">You want every second line from the file written to a temp file?</span>
<span class="comment-copy">Optimizing your new program is really a separate question from getting a file handle for a subprocess; you should probably create it as a separate question. But if you read the <code>subprocess</code> docs (or my answer), it should be pretty clear how you can pipe data in to <code>formatdb -i stdin</code> instead of writing it to a file first and then running <code>formatdb</code> on the file.</span>
<span class="comment-copy">what is <code>partial</code>?</span>
<span class="comment-copy">@PadraicCunningham <a href="https://docs.python.org/3/library/functools.html#functools.partial" rel="nofollow noreferrer"><code>partial</code></a>: <code>functools.partial(zcat.read, 8192)</code> is effectively the same as <code>lambda: zcat.read(8192)</code>, but possibly more efficient and definitely more introspectable.</span>
<span class="comment-copy">@abarnet, I thought it was I just did not see any import, do you need iter?</span>
<span class="comment-copy">I am not really sure if I necessarily "want" to launch a subprocess, I just need it to go faster than how I am doing it with Python, although I thought subprocess might be an option.  I know that Perl script above works really nice as I have used it plenty of times, so it must be doing something right.  The gzip.open and parse seems too slow, but maybe it just needs tweaking? Still not sure how I can then take the two lines I need, make a slight alteration, and use it as the stdin for the software as if it was just its own file (without creating a file).</span>
<span class="comment-copy">@PadraicCunningham: Well, I didn't include the <code>import subprocess</code> either. This isn't meant to be a complete program, just enough to show the OP how to do what he wants. Meanwhile, of course you don't really <i>need</i> <code>iter</code> (although you do need <code>.stdout.</code> in there, which I missed… fixed…), you could just do a <code>while True:</code>, <code>buf = zcat.stdout.read(8192)</code>, <code>if not buf: break</code>, etc., but why be more verbose? Especially since the point isn't the particular code, it's just that any file-reading code works on <code>zcat.stdout</code>, just as any perl file-reading code works on his <code>$fh</code>.</span>
