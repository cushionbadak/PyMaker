<div class="post-text" itemprop="text">
<p>I want to compress files and compute the checksum of the compressed file using python. My first naive attempt was to use 2 functions:</p>
<pre><code>def compress_file(input_filename, output_filename):
    f_in = open(input_filename, 'rb')
    f_out = gzip.open(output_filename, 'wb')
    f_out.writelines(f_in)
    f_out.close()
    f_in.close()


def md5sum(filename):
    with open(filename) as f:
        md5 = hashlib.md5(f.read()).hexdigest()
    return md5
</code></pre>
<p>However, it leads to the compressed file being written and then re-read. With many files (&gt; 10 000), each several MB when compressed, in a NFS mounted drive, it is slow.</p>
<p>How can I compress the file in a buffer and then compute the checksum from this buffer before writing the output file?</p>
<p>The file are not that big so I can afford to store everything in memory. However, a nice incremental version could be nice too.</p>
<p>The last requirement is that it should work with multiprocessing (in order to compress several files in parallel).</p>
<p>I have tried to use <code>zlib.compress</code> but the returned string miss the header of a gzip file.</p>
<p>Edit: following <a href="https://stackoverflow.com/a/30113267/848475">@abarnert sggestion</a>, I used python3 <code>gzip.compress</code>:</p>
<pre><code>def compress_md5(input_filename, output_filename):
    f_in = open(input_filename, 'rb')
    # Read in buffer
    buff = f_in.read()
    f_in.close()
    # Compress this buffer
    c_buff = gzip.compress(buff)
    # Compute MD5
    md5 = hashlib.md5(c_buff).hexdigest()
    # Write compressed buffer
    f_out = open(output_filename, 'wb')
    f_out.write(c_buff)
    f_out.close()

    return md5
</code></pre>
<p>This produce a correct gzip file but the output is different at each run (the md5 is different):</p>
<pre><code>&gt;&gt;&gt; compress_md5('4327_010.pdf', '4327_010.pdf.gz')
'0d0eb6a5f3fe2c1f3201bc3360201f71'
&gt;&gt;&gt; compress_md5('4327_010.pdf', '4327_010.pdf.gz')
'8e4954ab5914a1dd0d8d0deb114640e5'
</code></pre>
<p>The <code>gzip</code> program doesn't have this problem:</p>
<pre><code> $ gzip -c 4327_010.pdf | md5sum
 8965184bc4dace5325c41cc75c5837f1  -
 $ gzip -c 4327_010.pdf | md5sum
 8965184bc4dace5325c41cc75c5837f1  -
</code></pre>
<p>I guess it's because the <code>gzip</code> module use the current time by default when creating a file (the <code>gzip</code> program use the modification of the input file I guess). There is no way to change that with <code>gzip.compress</code>.</p>
<p>I was thinking to create a <code>gzip.GzipFile</code> in read/write mode, controlling the mtime but there is no such mode for <code>gzip.GzipFile</code>.</p>
<p>Inspired by <a href="https://stackoverflow.com/a/30113172/848475">@zwol suggestion</a> I wrote the following function which correctly sets the filename and the OS (Unix) in the header:</p>
<pre><code>def compress_md5(input_filename, output_filename):
    f_in = open(input_filename, 'rb')    
    # Read data in buffer
    buff = f_in.read()
    # Create output buffer
    c_buff = cStringIO.StringIO()
    # Create gzip file
    input_file_stat = os.stat(input_filename)
    mtime = input_file_stat[8]
    gzip_obj = gzip.GzipFile(input_filename, mode="wb", fileobj=c_buff, mtime=mtime)
    # Compress data in memory
    gzip_obj.write(buff)
    # Close files
    f_in.close()
    gzip_obj.close()
    # Retrieve compressed data
    c_data = c_buff.getvalue()
    # Change OS value
    c_data = c_data[0:9] + '\003' + c_data[10:]
    # Really write compressed data
    f_out = open(output_filename, "wb")
    f_out.write(c_data)
    # Compute MD5
    md5 = hashlib.md5(c_data).hexdigest()
    return md5
</code></pre>
<p>The output is the same at different run. Moreover the output of <code>file</code> is the same than <code>gzip</code>:</p>
<pre><code>$ gzip -9 -c 4327_010.pdf &gt; ref_max/4327_010.pdf.gz
$ file ref_max/4327_010.pdf.gz 
ref_max/4327_010.pdf.gz: gzip compressed data, was "4327_010.pdf", from Unix, last modified: Tue May  5 14:28:16 2015, max compression
$ file 4327_010.pdf.gz 
4327_010.pdf.gz: gzip compressed data, was "4327_010.pdf", from Unix, last modified: Tue May  5 14:28:16 2015, max compression
</code></pre>
<p>However, md5 is different:</p>
<pre><code>$ md5sum 4327_010.pdf.gz ref_max/4327_010.pdf.gz 
39dc3e5a52c71a25c53fcbc02e2702d5  4327_010.pdf.gz
213a599a382cd887f3c4f963e1d3dec4  ref_max/4327_010.pdf.gz
</code></pre>
<p><code>gzip -l</code> is also different:</p>
<pre><code>$ gzip -l ref_max/4327_010.pdf.gz 4327_010.pdf.gz 
     compressed        uncompressed  ratio uncompressed_name
        7286404             7600522   4.1% ref_max/4327_010.pdf
        7297310             7600522   4.0% 4327_010.pdf
</code></pre>
<p>I guess it's because the <code>gzip</code> program and the python <code>gzip</code> module (which is based on the C library <code>zlib</code>) have a slightly different algorithm.</p>
</div>
<div class="post-text" itemprop="text">
<p>Wrap a <a href="https://docs.python.org/3/library/gzip.html#gzip.GzipFile" rel="nofollow"><code>gzip.GzipFile</code></a> object around an <a href="https://docs.python.org/3/library/io.html#io.BytesIO" rel="nofollow"><code>io.BytesIO</code></a> object.  (In Python 2, use <code>cStringIO.StringIO</code> instead.)  After you close the <code>GzipFile</code>, you can retrieve the compressed data from the <code>BytesIO</code> object (using <code>getvalue</code>), hash it, and write it out to a real file.</p>
<p>Incidentally, you <a href="https://www.kb.cert.org/vuls/id/836068" rel="nofollow">really shouldn't be using MD5 at all anymore.</a></p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>I have tried to use <code>zlib.compress</code> but the returned string miss the header of a gzip file.</p>
</blockquote>
<p>Of course. That's the whole difference between the <a href="https://docs.python.org/3/library/zlib.html" rel="nofollow"><code>zlib</code></a> module and the <a href="https://docs.python.org/3/library/gzip.html" rel="nofollow"><code>gzip</code></a> module; <code>zlib</code> just deals with zlib-deflate compression without gzip headers, <code>gzip</code> deals with zlib-deflate data <em>with</em> gzip headers.</p>
<p>So, just call <a href="https://docs.python.org/3/library/gzip.html#gzip.compress" rel="nofollow"><code>gzip.compress</code></a> instead, and the code you wrote but didn't show us should just work.</p>
<hr/>
<p>As a side note:</p>
<pre><code>with open(filename) as f:
    md5 = hashlib.md5(f.read()).hexdigest()
</code></pre>
<p>You almost certainly want to open the file in <code>'rb'</code> mode here. You don't want to convert <code>'\r\n'</code> into <code>'\n'</code> (if on Windows), or decode the binary data as <code>sys.getdefaultencoding()</code> text (if on Python 3), so open it in binary mode.</p>
<hr/>
<p>Another side note:</p>
<p>Don't use line-based APIs on binary files. Instead of this:</p>
<pre><code>f_out.writelines(f_in)
</code></pre>
<p>â€¦ do this:</p>
<pre><code>f_out.write(f_in.read())
</code></pre>
<p>Or, if the files are too large to read into memory all at once:</p>
<pre><code>for buf in iter(partial(f_in.read, 8192), b''):
    f_out.write(buf)
</code></pre>
<hr/>
<p>And one last point:</p>
<blockquote>
<p>With many files (&gt; 10 000), each several MB when compressed, in a NFS mounted drive, it is slow.</p>
</blockquote>
<p>Does your system not have a tmp directory mounted on a faster drive?</p>
<p>In most cases, you don't need a real file. Either there's a string-based API (<code>zlib.compress</code>, <code>gzip.compress</code>, <code>json.dumps</code>, etc.), or the file-based API only requires a file-like object, like a <code>BytesIO</code>.</p>
<p>But when you <em>do</em> need a real temporary file, with a real file descriptor and everything, you almost always want to create it in the temporary directory.<sup>*</sup> In Python, you do this with the <a href="https://docs.python.org/3/library/tempfile.html" rel="nofollow"><code>tempfile</code></a> module. </p>
<p>For example:</p>
<pre><code>def compress_and_md5(filename):
    with tempfile.NamedTemporaryFile() as f_out:
        with open(filename, 'rb') as f_in:
            g_out = gzip.open(f_out)
            g_out.write(f_in.read())
        f_out.seek(0)
        md5 = hashlib.md5(f_out.read()).hexdigest()
</code></pre>
<p>If you need an actual filename, rather than a file object, you can use <code>f_in.name</code>.</p>
<p><sub>* The one exception is when you only want the temporary file to eventually <code>rename</code> it to a permanent location. In that case, of course, you usually want the temporary file to be in the same directory as the permanent location. But you can do that with <code>tempfile</code> just as easily. Just remember to pass <code>delete=False</code>.</sub></p>
</div>
<span class="comment-copy">The reason <a href="https://docs.python.org/3/library/zlib.html#zlib.compress" rel="nofollow noreferrer"><code>zlib.compress</code></a> doesn't have the header of a gzip file is that you use the <code>gzip</code> module for that, not the <code>zlib</code> module. That's explained in the docs.</span>
<span class="comment-copy">Yes, I understood that. I simply mean that I didn't find a way to write the gzip file correctly without <code>gzip</code>.</span>
<span class="comment-copy">OK, now I'm puzzled what you want the MD5 for. The whole point is (usually) to be able to verify that you have the same data as expected. If that means exactly this specific file, compressed at this specific time, then anything you compress on the fly will never match. If it just means the decompressed bytes will be the same, why not either MD5 the bytes without compressing, or MD5 just the zlib deflate data instead of the whole gzip file?</span>
<span class="comment-copy">You're right about the usage. While working on the solution you suggested I realized the problem of non-reproducibility and that the simple command-line solution did not suffer from that.</span>
<span class="comment-copy">This is overcomplicating it. You don't need to use a <code>GzipFile</code>; you can just call <code>compress</code> directly on the bytes to get the compressed bytes.</span>
<span class="comment-copy">I agree for signature hashes. But for a simple internal integrity check, md5 is still fine. However, using sha256+ is not different to use.</span>
<span class="comment-copy">I have added a program inspired by your idea.</span>
<span class="comment-copy">Thanks for you very detailed answer. You're right about the tmp directory. I must confess I also wanted to know that for the sake of knowing. I was using python 2.7 for which <code>gzip</code> has not <code>compress</code> method. I have written a function that almost work. See the edit on the question.</span>
<span class="comment-copy">@MathieuDubois: I don't see an edit to the question in the past 23 hours. But meanwhile, if you're morphing this into a new question, like "why doesn't my custom backport of <code>gzip.compress</code> work?", don't do that; write a new question, and paste links (from the "share" button) between the two.</span>
<span class="comment-copy">@MathieuDubois: Meanwhile, if you're not sure your question is Python-version-independent, it's usually worth also tagging <code>python-2.7</code> or <code>python-3.x</code> tag. There are large segments of the Python community that assume everyone is using 2.7, or that everyone is using 3.4; even those of us who try to keep in mind both possibilities and try to guess which is relevant to a question aren't always going to guess right. (In this case, I didn't remember that <code>zlib.compress</code> was added way back around 2.1, but <code>gzip.compress</code> not until 3.2; if you'd said 2.7, I would have looked in the 2.7 docs.)</span>
<span class="comment-copy">@MathieuDubois: Finally, to head off your backporting <code>gzip.compress</code> question: Notice that the <a href="https://docs.python.org/2/library/gzip.html" rel="nofollow noreferrer"><code>gzip</code></a> docs, like many other modules, start with a link to the source code. That generally means the source is intended to be useful as sample code as well as useful directly. So switch to 3.2 or dev in the top-left corner, then click on the source, and you'll see how the stdlib does <code>gzip.compress</code>. It may not always be easy to backport new features, but often it's trivial.</span>
<span class="comment-copy">Totally my bad. <code>python</code> keyword was suggested and I haven't suspected a difference in those modules (most of the time, standard modules in 2.7 and 3.x are almost similar).</span>
