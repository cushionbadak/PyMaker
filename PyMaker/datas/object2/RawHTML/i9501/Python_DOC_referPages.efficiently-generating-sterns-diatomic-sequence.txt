<div class="post-text" itemprop="text">
<p>Stern's Diatomic Sequence can be read about in more details <a href="http://mathworld.wolfram.com/SternsDiatomicSeries.html" rel="nofollow noreferrer">over here</a>; however, for my purpose I will define it now.</p>
<hr/>
<h3>Definition of Stern's Diatomic Sequence</h3>
<p>Let <code>n</code> be a number to generate the <code>fusc</code> function out of. Denoted <code>fusc(n)</code>.</p>
<p>If <code>n</code> is 0 then the returned value is 0.<br/>
If <code>n</code> is 1 then the returned value is 1.</p>
<p>If <code>n</code> is even then the returned value is <code>fusc(n / 2)</code>.<br/>
If <code>n</code> is odd then the returned value is <code>fusc((n - 1) / 2) + fusc((n + 1) / 2)</code>.</p>
<hr/>
<p>Currently, my Python code brute forces through most of the generation, other than the dividing by two part since it will always yield no change.</p>
<pre><code>def fusc (n):
    if n &lt;= 1:
        return n

    while n &gt; 2 and n % 2 == 0:
        n /= 2

    return fusc((n - 1) / 2) + fusc((n + 1) / 2)
</code></pre>
<p>However, my code must be able to handle digits in the magnitude of <del>1000s</del> millions of bits, and recursively running through the function <del>thousands</del> millions of times does not seem very efficient or practical.</p>
<p>Is there any way I could algorithmically improve my code such that massive numbers can be passed through without having to recursively call the function so many times?</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow noreferrer">lru_cache</a> works wonders in your case. make sure <code>maxsize</code> is a power of 2. may need to fiddle a bit with that size for your application. <code>cache_info()</code> will help with that.</p>
<p>also use <code>//</code> instead of <code>/</code> for integer division.</p>
<pre><code>from functools import lru_cache


@lru_cache(maxsize=512, typed=False)
def fusc(n):

    if n &lt;= 1:
        return n

    while n &gt; 2 and n % 2 == 0:
        n //= 2

    return fusc((n - 1) // 2) + fusc((n + 1) // 2)

print(fusc(1000000000078093254329870980000043298))
print(fusc.cache_info())
</code></pre>
<p>and yes, this is just meomization as proposed by Filip Malczak.</p>
<p>you might gain an additional <em>tiny</em> speedup using bit-operations in the while loop:</p>
<pre><code>while not n &amp; 1:  # as long as the lowest bit is not 1
    n &gt;&gt;= 1       # shift n right by one
</code></pre>
<hr/>
<p><strong>UPDATE</strong>:</p>
<p>here is a simple way of doing meomzation 'by hand':</p>
<pre><code>def fusc(n, _mem={}):  # _mem will be the cache of the values 
                       # that have been calculated before
    if n in _mem:      # if we know that one: just return the value
        return _mem[n]

    if n &lt;= 1:
        return n

    while not n &amp; 1:
        n &gt;&gt;= 1
    if n == 1:
        return 1    

    ret = fusc((n - 1) // 2) + fusc((n + 1) // 2)
    _mem[n] = ret  # store the value for next time
    return ret
</code></pre>
<hr/>
<p><strong>UPDATE</strong></p>
<p>after reading a <a href="https://www.cs.utexas.edu/users/EWD/transcriptions/EWD05xx/EWD578.html" rel="nofollow noreferrer">short article by dijkstra himself</a> a minor update.</p>
<p>the article states, that <code>f(n) = f(m)</code> if the fist and last bit of <code>m</code> are the same as those of <code>n</code> and the bits in between are inverted. the idea is to get <code>n</code> as small as possible.</p>
<p>that is what the bitmask <code>(1&lt;&lt;n.bit_length()-1)-2</code> is for (first and last bits are <code>0</code>; those in the middle <code>1</code>; <code>xor</code>ing <code>n</code> with that gives <code>m</code> as described above).</p>
<p>i was only able to do small benchmarks; i'm interested if this is any help at all for the magitude of your input... this will reduce the memory for the cache and hopefully bring some speedup.</p>
<pre><code>def fusc_ed(n, _mem={}):

    if n &lt;= 1:
        return n

    while not n &amp; 1:
        n &gt;&gt;= 1
    if n == 1:
        return 1

    # https://www.cs.utexas.edu/users/EWD/transcriptions/EWD05xx/EWD578.html
    # bit invert the middle bits and check if this is smaller than n
    m = n ^ (1&lt;&lt;n.bit_length()-1)-2
    n = m if m &lt; n else n

    if n in _mem:
        return _mem[n]

    ret = fusc(n &gt;&gt; 1) + fusc((n &gt;&gt; 1) + 1)
    _mem[n] = ret
    return ret
</code></pre>
<p>i had to increase the recursion limit:</p>
<pre><code>import sys
sys.setrecursionlimit(10000)  # default limit was 1000
</code></pre>
<p>benchmarking gave strange results; using the code below and making sure that i always started a fresh interperter (having an empty <code>_mem</code>) i sometimes got significantly better runtimes; on other occasions the new code was slower...</p>
<p>benchmarking code:</p>
<pre><code>print(n.bit_length())

ti = timeit('fusc(n)', setup='from __main__ import fusc, n', number=1)
print(ti)

ti = timeit('fusc_ed(n)', setup='from __main__ import fusc_ed, n', number=1)
print(ti)
</code></pre>
<p>and these are three random results i got:</p>
<pre><code>6959
24.117448464001427
0.013900151001507766

6989
23.92404893300045
0.013844672999766772

7038
24.33894686200074
24.685758719999285
</code></pre>
<p>that is where i stopped...</p>
</div>
<div class="post-text" itemprop="text">
<p>With memoization for a million bits, the recursion stack would be extremely large. We can first try to look at a sufficiently large number which we can work by hand, <code>fusc(71)</code> in this case:</p>
<blockquote>
<p>fusc(71) = fusc(35) + fusc(36)</p>
<blockquote>
<p>fusc(35) = fusc(17) + fusc(18)<br/>
    fusc(36) = fusc(18)  </p>
</blockquote>
<p>fusc(71) = 1 * fusc(17) + 2 * fusc(18)  </p>
<blockquote>
<p>fusc(17) = fusc(8) + fusc(9)<br/>
    fusc(18) = fusc(9)</p>
</blockquote>
<p>fusc(71) = 1 * fusc(8) + 3 * fusc(9)</p>
<blockquote>
<p>fusc(8) = fusc(4)<br/>
    fusc(9) = fusc(4) + fusc(5)</p>
</blockquote>
<p>fusc(71) = 4 * fusc(4) + 3 * fusc(5)</p>
<blockquote>
<p>fusc(4) = fusc(2)<br/>
    fusc(3) = fusc(1) + fusc(2)</p>
</blockquote>
<p>fusc(71) = 7 * fusc(2) + 3 * fusc(3)</p>
<blockquote>
<p>fusc(2) = fusc(1)<br/>
    fusc(3) = fusc(1) + fusc(2)</p>
</blockquote>
<p>fusc(71) = 11 * fusc(1) + 3 * fusc(2)</p>
<blockquote>
<p>fusc(2) = fusc(1)</p>
</blockquote>
<p>fusc(71) = 14 * fusc(1) = 14</p>
</blockquote>
<p>We realize that we can avoid recursion completely in this case as we can always express <code>fusc(n)</code> in the form <code>a * fusc(m) + b * fusc(m+1)</code> while reducing the value of m to 0. From the example above, you may find the following pattern:</p>
<blockquote>
<p>if m is odd:<br/>
<code>a * fusc(m) + b * fusc(m+1)</code> = <code>a * fusc((m-1)/2) + (b+a) * fusc((m+1)/2)</code><br/>
  if m is even:<br/>
<code>a * fusc(m) + b * fusc(m+1)</code> = <code>(a+b) * fusc(m/2) + b * fusc((m/2)+1)</code></p>
</blockquote>
<p>Therefore, you may use a simple loop function to solve the problem in O(lg(n)) time</p>
<pre><code>def fusc(n):
  if n == 0: return 0
  a = 1
  b = 0
  while n &gt; 0:
    if n%2:
      b = b + a
      n = (n-1)/2
    else:
      a = a + b
      n = n/2
  return b
</code></pre>
</div>
<span class="comment-copy">Read about memoization: <a href="https://en.wikipedia.org/wiki/Memoization" rel="nofollow noreferrer">en.wikipedia.org/wiki/Memoization</a> It can be wonderfuly done with python, but right now I am not sure whether it is a good solution here, as you won't calculate same thing too many times...</span>
<span class="comment-copy">Memoization might help slightly once descending into smaller numbers, but I need to be able to compute large numbers off the bat incredibly quickly, although implementing something like this would definitely improve long-time performance, it is not really what I am looking for.</span>
<span class="comment-copy">That's why it became a comment instead of an answer. Good luck.</span>
<span class="comment-copy">Unfortunately, I am using Python2.7, for which <code>lru_cache</code> is not available. I should have added Python2.7 in the tags.</span>
<span class="comment-copy"><a href="http://stackoverflow.com/a/11861795/4954037">stackoverflow.com/a/11861795/4954037</a> might help there... or you could roll your own.</span>
<span class="comment-copy">Cannot use any external libraries either. I think the solution needs to be nearly completely algorithmic.</span>
<span class="comment-copy">added a meomized version without using <code>lru_cache</code>. please try it before discarding the idea of caching values. the speedup is enormous!</span>
<span class="comment-copy">I think <a href="https://stackoverflow.com/a/44557597/1400793">stackoverflow.com/a/44557597/1400793</a> should be the accepted answer. The code in the other answer contains no recursion, is clearly O(log n), and greatly simpler.</span>
