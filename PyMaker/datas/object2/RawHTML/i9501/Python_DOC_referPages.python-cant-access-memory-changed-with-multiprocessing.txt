<div class="post-text" itemprop="text">
<p>Here's a python module in a python package:</p>
<pre><code>import multiprocessing as mp

class Test(object):
    def __init__(self):
        self.dict = dict()

    def fill_dict(self):
        self.dict = {'testing': 123}
        print self.dict

if __name__ == "__main__":
    tests = [Test() for i in xrange(3)]
    jobs = [mp.Process(target=test.fill_dict, args=()) for test in tests]
    for job in jobs:
        job.start()
    for job in jobs:
        job.join()

    print "RESULTS:"
    for test in tests:
        print test.dict
</code></pre>
<p>I run the module and get the results as follows:</p>
<pre><code>C:\path\to\package&gt;python -m package.path.to.module
{'testing': 123}
{'testing': 123}
{'testing': 123}
RESULTS:
{}
{}
{}
</code></pre>
<p>From the printout, it seems that each <code>test.dict</code> was filled in parallel by <code>multiprocessing</code>. However, when I try to recover the results, the <code>test.dict</code>s seems to be empty. Can someone explain why this is happening and what I can do to recover the nonempty <code>test.dict</code>s?</p>
<p><strong>EDIT:</strong>
@Valentin Lorentz, @Moinuddin Quadri, @zstewart</p>
<p>Even if I change the latter part of the module to</p>
<pre><code>if __name__ == "__main__":
    test0 = Test()
    test1 = Test()
    test2 = Test()

    jobs = list()
    jobs.append(mp.Process(target=test0.fill_dict, args=()))
    jobs.append(mp.Process(target=test1.fill_dict, args=()))
    jobs.append(mp.Process(target=test2.fill_dict, args=()))

    for job in jobs:
        job.start()
    for job in jobs:
        job.join()

    print "RESULTS:"
    print test0.dict
    print test1.dict
    print test2.dict
</code></pre>
<p>I get the same results. Each process is completely independent of the others (they don't share memory and don't need to). So when answers speak of sharing memory between processes, does this mean between the main module and the multiprocessing processes?</p>
</div>
<div class="post-text" itemprop="text">
<p>You can not transmit data between threads using built-in types. You need to use <a href="https://docs.python.org/2/library/queue.html#Queue.Queue" rel="nofollow noreferrer"><code>multiprocessing.Queue</code></a> or <a href="https://docs.python.org/2/library/multiprocessing.html#multiprocessing.Pipe" rel="nofollow noreferrer"><code>mutiprocess.Pipes</code></a> to perform that. Check: 
<a href="https://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes" rel="nofollow noreferrer">Exchanging objects between processes</a>.</p>
<p>You may refer: <a href="https://stackoverflow.com/questions/40536287/running-multiple-asynchronous-function-and-get-the-returned-value-of-each-functi">Running multiple asynchronous function and get the returned value of each function</a>. It is having the example on how to use <code>Queue()</code> instead of <code>list</code>. </p>
</div>
<div class="post-text" itemprop="text">
<p>Processes do not share memory by default. That's on purpose, because sharing memory between execution threads is a very complicated topic (synchronization between threads, communications, ...)</p>
<p>The most direct solution to your problem is to explicitely share this object: <a href="https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes" rel="nofollow noreferrer">https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes</a></p>
<p>However, a cleaner way is to make your function return a result, and use <code>multiprocessing.Pool.map</code> to call the function in multiple processes.</p>
</div>
<span class="comment-copy">Multiprocessing launches separate python processes. You have to use a multiprocessing.queue to send data between the processes.</span>
