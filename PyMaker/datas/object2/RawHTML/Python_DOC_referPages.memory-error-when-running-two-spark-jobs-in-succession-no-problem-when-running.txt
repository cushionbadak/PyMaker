<div class="post-text" itemprop="text">
<p>I have the following Spark SQL code that checks the absence of certain dates in large tables (several billion rows):</p>
<pre><code>spark = SparkSession.builder \
    .master("yarn") \
    .appName("minimal_example") \
    .config('spark.submit.deployMode', 'client') \
    .getOrCreate()

SQL = '''
select distinct
  substr(entrydate, 1, 10) as datum,
  1 as in_table
from {table}
where entrydate &gt;= '{datum}'
'''

print("RUN1")
df1 = spark.sql(SQL.format(datum='2017-01-01', table='table1'))
c1 = df1.count()
print("count1: ", c1)

print("RUN2")
df2 = spark.sql(SQL.format(datum='2017-01-01', table='table2'))
c2 = df2.count()
print("count2: ", c2)
</code></pre>
<p>Essentially, the function is simply getting the distinct dates from a table column.</p>
<p>Now the part I can't wrap my head around:</p>
<ul>
<li>Each call to <code>count()</code> on its own runs fine</li>
<li>When I run each call as a separate <code>spark-submit</code> job, it works fine</li>
<li>But if run them in succession like above, the second run produces the following error:</li>
</ul>
<pre><code>py4j.protocol.Py4JJavaError: An error occurred while calling o150.sql.
: java.util.concurrent.ExecutionException: java.io.IOException: com.google.protobuf.ServiceException: java.lang.OutOfMemoryError: GC overhead limit exceeded
</code></pre>
<p>My interpretation is that the garbage collection from the first run kicks in during the second run.</p>
<p>What I have tried:</p>
<ol>
<li>Call spark.clearCache() at the beginning of each iteration</li>
<li>Call <code>spark._jvm.SparkSession.clearDefaultSession()</code>, <code>spark._jvm.SparkSession.clearActiveSession()</code> at the beginning of each iteration</li>
<li>Look at the Spark web UI and try to get sense out of the DAG and Storage tabs (the latter one does not display anything) to no avail</li>
<li>Change the order of the two <code>count</code>s. This results in a different error: <code>java.io.IOException: Connection reset by peer</code> (see <a href="https://stackoverflow.com/questions/39347392/how-to-fix-connection-reset-by-peer-message-from-apache-spark">here</a> for a similar error)</li>
</ol>
<p>One last observation: The first call spins up &gt;100 Spark/YARN executors, maybe Spark's dynamic allocation mechanism does not like that the second call is effectively a new job that has different requirements for executors?</p>
<p>Any help is much appreciated!</p>
<p>Environment: Spark 2.3 on Cloudera CDH 6.1 cluster.</p>
<h3>Edit: Some more details</h3>
<ul>
<li>The tables are persisted as Parquet files in HDFS, stats:</li>
</ul>
<pre><code>   +--------+------------+-------+--------+--------------+
   | table  |   # rows   |# cols |# files |   raw size   |
   +--------+------------+-------+--------+--------------+
   | table1 | 5660970439 |    46 |  49167 | 228876171398 |
   | table2 | 5656000217 |    52 |  80000 | 518996700170 |
   +--------+------------+-------+--------+--------------+
</code></pre>
<ul>
<li>Memory settings: Spark on YARN with dynamic allocation, min executor memory is 1GB, max is 72 GB, total cluster memory is ~300GB.</li>
<li>The first <code>count()</code> spins up about 150 executors, fully utilizing the currently available memory resources</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>After letting the problem sink in for a few days, I just tried increasing the <em>driver</em> memory:</p>
<p><code>spark2-submit --master yarn --deploy-mode client --driver-memory 4G minimal_example.py</code></p>
<p>Maybe the deciding factor was that my application is started in <code>client</code> mode. Apparently, the management of a large number of executors (and their removal) costs quite a lot of memory, even though the driver itself only receives the result of a simple <code>df.count()</code>.</p>
</div>
<span class="comment-copy">Could you try to persist after edates after join with dates? Also one more thing, how big can date_whitelist be?</span>
<span class="comment-copy">Hi @AlexandrosBiratsis, I reduced my question to a minimal example, where no join is needed. The <code>whitelist</code> parameter in the previous version of my question was of size 1-3, so I don't think that had any effect.</span>
<span class="comment-copy">What are the rough size of the tables you are acting on and what is the memory settings you are placing on driver and executor?</span>
<span class="comment-copy">@afeldman I've added some meta info. Memory is requested dynamically by Spark and managed by YARN.</span>
