<div class="post-text" itemprop="text">
<p>I'd like to work with a dict in python, but limit the number of key/value pairs to X. In other words, if the dict is currently storing X key/value pairs and I perform an insertion, I would like one of the existing pairs to be dropped. It would be nice if it was the least recently inserted/accesses key but that's not completely necessary.</p>
<p>If this exists in the standard library please save me some time and point it out!</p>
</div>
<div class="post-text" itemprop="text">
<p>Python 2.7 and 3.1 have <a href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" rel="nofollow noreferrer">OrderedDict</a> and there are pure-Python implementations for earlier Pythons.</p>
<pre><code>from collections import OrderedDict

class LimitedSizeDict(OrderedDict):
    def __init__(self, *args, **kwds):
        self.size_limit = kwds.pop("size_limit", None)
        OrderedDict.__init__(self, *args, **kwds)
        self._check_size_limit()

    def __setitem__(self, key, value):
        OrderedDict.__setitem__(self, key, value)
        self._check_size_limit()

    def _check_size_limit(self):
        if self.size_limit is not None:
            while len(self) &gt; self.size_limit:
                self.popitem(last=False)
</code></pre>
<p>You would also have to override other methods that can insert items, such as <code>update</code>.  The primary use of <code>OrderedDict</code> is so you can control what gets popped easily, otherwise a normal <code>dict</code> would work.</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://pypi.python.org/pypi/cachetools" rel="noreferrer">cachetools</a> will provide you nice implementation of Mapping Hashes that does this (and it works on python 2 and 3).</p>
<p>Excerpt of the documentation:</p>
<blockquote>
<p>For the purpose of this module, a cache is a mutable mapping of a fixed
  maximum size. When the cache is full, i.e. by adding another item the
  cache would exceed its maximum size, the cache must choose which item(s) 
  to discard based on a suitable cache algorithm.</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>Here's a simple, no-LRU Python 2.6+ solution (in older Pythons you could do something similar with <code>UserDict.DictMixin</code>, but in 2.6 and better that's not recommended, and the ABCs from <code>collections</code> are preferable anyway...):</p>
<pre><code>import collections

class MyDict(collections.MutableMapping):
    def __init__(self, maxlen, *a, **k):
        self.maxlen = maxlen
        self.d = dict(*a, **k)
        while len(self) &gt; maxlen:
            self.popitem()
    def __iter__(self):
        return iter(self.d)
    def __len__(self):
        return len(self.d)
    def __getitem__(self, k):
        return self.d[k]
    def __delitem__(self, k):
        del self.d[k]
    def __setitem__(self, k, v):
        if k not in self and len(self) == self.maxlen:
            self.popitem()
        self.d[k] = v

d = MyDict(5)
for i in range(10):
    d[i] = i
    print(sorted(d))
</code></pre>
<p>As other answers mentioned, you probably don't want to subclass dict -- the explicit delegation to <code>self.d</code> is unfortunately boilerplatey but it does <em>guarantee</em> that every other method is properly supplied by <code>collections.MutableMapping</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a simple and efficient LRU cache written with dirt simple Python code that runs on any python version 1.5.2 or later:</p>
<pre><code>class LRU_Cache:

    def __init__(self, original_function, maxsize=1000):
        self.original_function = original_function
        self.maxsize = maxsize
        self.mapping = {}

        PREV, NEXT, KEY, VALUE = 0, 1, 2, 3         # link fields
        self.head = [None, None, None, None]        # oldest
        self.tail = [self.head, None, None, None]   # newest
        self.head[NEXT] = self.tail

    def __call__(self, *key):
        PREV, NEXT = 0, 1
        mapping, head, tail = self.mapping, self.head, self.tail

        link = mapping.get(key, head)
        if link is head:
            value = self.original_function(*key)
            if len(mapping) &gt;= self.maxsize:
                old_prev, old_next, old_key, old_value = head[NEXT]
                head[NEXT] = old_next
                old_next[PREV] = head
                del mapping[old_key]
            last = tail[PREV]
            link = [last, tail, key, value]
            mapping[key] = last[NEXT] = tail[PREV] = link
        else:
            link_prev, link_next, key, value = link
            link_prev[NEXT] = link_next
            link_next[PREV] = link_prev
            last = tail[PREV]
            last[NEXT] = tail[PREV] = link
            link[PREV] = last
            link[NEXT] = tail
        return value

if __name__ == '__main__':
    p = LRU_Cache(pow, maxsize=3)
    for i in [1,2,3,4,5,3,1,5,1,1]:
        print(i, p(i, 2))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A dict does not have this behavior. You could make your own class that does this, for example something like</p>
<pre><code>class MaxSizeDict(object):
    def __init__(self, max_size):
        self.max_size = max_size
        self.dict = {}
    def __setitem__(self, key, value):
        if key in self.dict:
            self.dict[key] = value    
            return

        if len(self.dict) &gt;= self.max_size:
      ...
</code></pre>
<p>A few notes about this</p>
<ul>
<li>It would be tempting for some to subclass <code>dict</code> here. You can technically do this, but it is bug-prone because the methods do not depend on each other. You can use <code>UserDict.DictMixin</code> to save having to define all methods. There are few methods you would be able re-use if you subclass <code>dict</code>.</li>
<li>A dict does not know what the least recently added key is, since dicts are unordered. 

<ul>
<li>2.7 will introduce <code>collections.OrderedDict</code>, but for now keeping the keys in order separately should work fine (use a <code>collections.deque</code> as a queue).</li>
<li>If getting the oldest isn't all that imporant, you can just use the <code>popitem</code> method to delete one arbitrary item.</li>
</ul></li>
<li>I interprettered oldest to mean first insertion, approximately. You would have to do something a bit different to eliminate the LRU items. The most obvious efficient strategy would involve keeping a doubly-linked list of keys with references to the nodes themselves stored as dict values (along with the real values). This gets more complicated and implementing it in pure Python carries a lot of overhead.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>You can create a custom dictionary class by subclassing dict. In your case, you would have to override <code>__setitem__</code> to have check your own length and delete something if the limit is recahed. The following example would print the current lenght after every insertion:</p>
<pre><code>class mydict(dict):
    def __setitem__(self, k, v):
        dict.__setitem__(self, k, v)
        print len(self)

d = mydict()
d['foo'] = 'bar'
d['bar'] = 'baz'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There have been many good answers, but I want to point out a simple, pythonic implementation for LRU cache. It's similar to Alex Martelli's answer.</p>
<pre><code>from collections import OrderedDict, MutableMapping

class Cache(MutableMapping):
    def __init__(self, maxlen, items=None):
        self._maxlen = maxlen
        self.d = OrderedDict()
        if items:
            for k, v in items:
                self[k] = v

    @property
    def maxlen(self):
        return self._maxlen

    def __getitem__(self, key):
        self.d.move_to_end(key)
        return self.d[key]

    def __setitem__(self, key, value):
        if key in self.d:
            self.d.move_to_end(key)
        elif len(self.d) == self.maxlen:
            self.d.popitem(last=False)
        self.d[key] = value

    def __delitem__(self, key):
        del self.d[key]

    def __iter__(self):
        return self.d.__iter__()

    def __len__(self):
        return len(self.d)
</code></pre>
</div>
<span class="comment-copy">duplicate: <a href="http://stackoverflow.com/questions/1756992/removing-the-oldest-element-from-a-dictionary-in-python" title="removing the oldest element from a dictionary in python">stackoverflow.com/questions/1756992/â€¦</a></span>
<span class="comment-copy">good find. i'd like to keep this around though since i don't specifically need lru.</span>
<span class="comment-copy">@Nick: Limiting the size seems enough of a distinction to be a different question, but yes, that question is half of this.</span>
<span class="comment-copy">@Mike: <code>(self, size_limit=None, *args, **kwds)</code> is wrong and keyword-only parameters (<code>(self, *args, size_limit=None, **kwds)</code>) aren't in current 2.x.  (Are they being considered for 2.7?  Regardless they aren't 2.6.)  This code works with just about any version the OP is likely to use, makes <i>size_limit</i> effectively a keyword-only parameter, and maintains the same interface as dicts.</span>
<span class="comment-copy">Have you tested your code on Python 2.7? <code>dict.pop</code> requires at least 1 argument. <code>dict.popitem()</code> works, but it removed the recent item.</span>
<span class="comment-copy">Also, <b>setitem</b> should check for size limit <i>before</i> actually setting the item, lest you end up losing the very item your are setting!</span>
<span class="comment-copy">@Sridhar: Looking at it now, months later, I'm not sure what I was thinking; but popitem makes more sense.</span>
<span class="comment-copy">To be accurate, this is not really an LRU implementation. This is FIFO with deletion due to dict size limitation. In order to have a full LRU implementation, one needs to override <code>__contains__</code> method to move the last item "used" or queried to the top of the dict linked list. [I understand though, this is not the main objective of the question]</span>
<span class="comment-copy">wow, you write pretty much LRU in such a short period for various user cases, it is always a joy to read your Python code from whether python cookbook(activestate), python standard lib, blog, twitter, or pycon lectures, and now on stackoverflow too.</span>
<span class="comment-copy">This implementation looks non-pythonic. Why not use <code>OrderedDict</code> and <code>MutableMapping</code> to do this...</span>
<span class="comment-copy">It's perfectly Pythonic -- a simple class with straight-forward use of dictionaries, lists, basic assignments an unpacking.  The logic is self-contained and there are no external dependencies.  This code is also very fast and is easily optimized further by PyPy.  An OrderedDict adds space overhead (it uses two dicts internally while this only uses one) and it does unnecessary work that isn't needed for this use.  MutableMapping doesn't provide any useful capabilities in this context.</span>
<span class="comment-copy">What's the point of the class-level definitions of <code>PREV</code>, <code>NEXT</code>, <code>KEY</code>, and <code>VALUE</code> since they're not used in any of the methods?</span>
<span class="comment-copy">@martineau It is there to just show the structure of the link.</span>
<span class="comment-copy">You actually need something much more complex than a dict+deque if you want O(1) get-/set-/delitem, though of course this only really matters for larger sizes.</span>
<span class="comment-copy">You can directly reuse about half of the methods from the dict, OrderedDict, or other base even without using DictMixin.  It really doesn't seem that bugprone to write forwarding methods for the others, certainly no more bugprone than having to write them all yourself, as you have here.</span>
<span class="comment-copy">I am trying to get at what hopefully solves the problem at hand. dict+deque gives you O(1) get, set, and delitem if you only care a little about the orderedness of the keys and you don't fall into the pathological case where there are many deletions and re-setting of the same keys, leading to the deque being polluted by keys not in the dict.</span>
<span class="comment-copy">No, for delitem you have to search the deque for the deleted item, and that's O(n).  Check out one of the pure-Python OrderedDict implementations.</span>
<span class="comment-copy">The majority of the times I've seen <code>dict</code> subclassed in the wild, the coder forgot to override all the appropriate methods. This means that errors stemming from this have the opportunity to pass silently, which is really bad. I really don't see much to be gained from subclassing in a case like this.</span>
<span class="comment-copy">Subclassing builtins like <code>dict</code> is often fruitless. In normal circumstances with subclassing, methods like <code>update</code> and <code>setdefault</code> would rely on the overrided <code>__getitem__</code>, but this is not how it works here. Subclassing builtins makes it easy to introduce difficult-to-see bugs. When you eliminate all such bugs, you really haven't saved any work by subclassing.</span>
<span class="comment-copy">Interesting. Could you show an example of such an bug?</span>
