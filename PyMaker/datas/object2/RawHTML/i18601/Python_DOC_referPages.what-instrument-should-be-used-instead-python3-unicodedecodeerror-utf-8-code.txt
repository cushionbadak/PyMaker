<div class="post-text" itemprop="text">
<pre><code>$ python3 utf8.py                                             
/usr/bin/torsocks /usr/bin/wget -q -O - --user-agent="Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20
100101 Firefox/17.0" http://xiwayy2kn32bo3ko.onion/test/read.cgi/tor/1371355627/978n                
Traceback (most recent call last):
  File "utf8.py", line 13, in &lt;module&gt;
    data = subprocess.getoutput( cmd )
  File "/usr/lib/python3.3/subprocess.py", line 707, in getoutput
    return getstatusoutput(cmd)[1]
  File "/usr/lib/python3.3/subprocess.py", line 683, in getstatusoutput
    text = pipe.read()
  File "/usr/lib/python3.3/codecs.py", line 300, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x83 in position 1674: invalid start byte
</code></pre>
<p>I migrate to python3, specially to get parse international internet, pages of Chinese etc.
But there i meet this trouble.</p>
<p>My simple code is a python wrapper around wget, because it is easiest way on my sight to dodge the ban. </p>
<pre><code>$ cat utf8.py 
#!/usr/bin/python3

import subprocess
from bs4 import BeautifulSoup

url = 'http://xiwayy2kn32bo3ko.onion/test/read.cgi/tor/1371355627/978n'
user_agent = "Mozilla/5.0 (Windows NT 6.1; rv:17.0) Gecko/20100101 Firefox/17.0"
wget_cmd = '/usr/bin/wget -q -O - --user-agent="' + user_agent + '" '
torsocks_cmd = '/usr/bin/torsocks '
cmd = torsocks_cmd + wget_cmd + url

print( cmd )
data = subprocess.getoutput( cmd )
print( "Fetch complete" )
print( data )
</code></pre>
<p><a href="http://xiwayy2kn32bo3ko.onion/test/read.cgi/tor/1371355627/978n" rel="nofollow">http://xiwayy2kn32bo3ko.onion/test/read.cgi/tor/1371355627/978n</a></p>
<p>Is an example, it is onion-web. </p>
<p>Why codecs.py of python3.3 did not understand everything whatever exist?</p>
<p>subprocess crashed with out any chance to restore fetched data.</p>
<p>Is there universal international way to fetch and parse html pages on any language? I were sure that utf-8 developed for this task.</p>
<p>Target page is: Shift_JIS encoded</p>
<pre><code>&lt;META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=Shift_JIS"&gt;
</code></pre>
<p>My main question is:
How it should be done for any encoding, any language, universally. What language better to take for that task, how should html be parsed?</p>
<p>What instrument shall i use for such task? </p>
</div>
<div class="post-text" itemprop="text">
<p>Don't use <code>subprocess.getoutput()</code>; it assumes that whatever output was produced by the command is decodable with the same encoding as <code>sys.stdout</code> uses.</p>
<p>Try <a href="http://docs.python.org/3/library/subprocess.html#subprocess.check_output" rel="nofollow"><code>subprocess.check_output()</code></a> instead; it returns bytes.</p>
</div>
<span class="comment-copy">Whatever you are tying to decode is not valid UTF-8.</span>
<span class="comment-copy">But me need to parse output. I do import BeautifulSoup, do you see?</span>
<span class="comment-copy">@stackkeeper: what makes you think BeautifulSoup won't be able to handle this? Just pass the <code>bytes</code> output to BeautifulSoup <i>directly</i>.</span>
