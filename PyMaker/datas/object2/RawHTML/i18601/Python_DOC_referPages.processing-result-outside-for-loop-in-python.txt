<div class="post-text" itemprop="text">
<p>I have this simple code which fetches page via <code>urllib</code>:</p>
<pre><code>browser_list= ['Chrome','Mozilla','Safari','Internet Explorer','Opera']
user_string_url="http://www.useragentstring.com/pages/"
for eachBrowser in browser_list:
    result= urllib2.urlopen(urljoin(user_string_url,eachBrowser))
</code></pre>
<p>Now I can read the result via <code>result.read()</code> but I was wondering if all this functionality can be done outside the <code>for</code> loop. Because other URLs to be fetched will wait until all the result has been processed.</p>
<p>I want to process <code>result</code> outside the <code>for</code> loop. Can this be done?</p>
</div>
<div class="post-text" itemprop="text">
<p>One of the ways to do this maybe to have result as a dictionary. What you can do is:
result = {}</p>
<pre><code>for eachBrowser in browser_list:
result[eachBrowser]= urllib2.urlopen(urljoin(user_string_url,eachBrowser))
</code></pre>
<p>and use result[BrowserName] outside the loop.
Hope this helps.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you simply wants to access all results outside the loop just append all results to a array or dictionary as above answer.</p>
<p>Or if you trying to speed up your task try <a href="http://docs.python.org/library/threading.html%E2%80%8E" rel="nofollow">multithreading</a>.</p>
<pre><code>import threading
class myThread (threading.Thread):
    def __init__(self, result):
        threading.Thread.__init__(self)
        self.result=result
    def run(self):
       // process your result(as self.result) here

browser_list= ['Chrome','Mozilla','Safari','Internet Explorer','Opera']
user_string_url="http://www.useragentstring.com/pages/"
for eachBrowser in browser_list:
    result= urllib2.urlopen(urljoin(user_string_url,eachBrowser))
    myThread(result).start() // it will start processing result on another thread and continue loop without any waiting
</code></pre>
<p>Its a simple way of multithrading. It may break depending on your result processing. Consider reading the <a href="http://docs.python.org/library/threading.html%E2%80%8E" rel="nofollow">documentation</a> and some <a href="http://www.tutorialspoint.com/python/python_multithreading.htm" rel="nofollow">examples</a> before you try.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use threads for this:</p>
<pre><code>import threading
import urllib2
from urlparse import urljoin

def worker(url):
    res = urllib2.urlopen(url)
    data = res.read()
    res.close()

browser_list = ['Chrome', 'Mozilla', 'Safari', 'Internet Explorer', 'Opera']
user_string_url='http://www.useragentstring.com/'
for browser in browser_list:
    url = urljoin(user_string_url, browser)
    threading.Thread(target=worker,args=[url]).start()

 # wait for everyone to complete
 for thread in threading.enumerate():
     if thread == threading.current_thread(): continue
     thread.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Are you using python3?, if so, you can use <a href="http://docs.python.org/3/library/concurrent.futures.html" rel="nofollow">futures</a> for this task:</p>
<pre><code>from urllib.request import urlopen
from urllib.parse import urljoin
from concurrent.futures import ThreadPoolExecutor

browser_list = ['Chrome','Mozilla','Safari','Internet+Explorer','Opera']
user_string_url = "http://www.useragentstring.com/pages/"

def process_request(url, future):
    print("Processing:", url)
    print("Reading data")
    print(future.result().read())

with ThreadPoolExecutor(max_workers=10) as executor:
    submit = executor.submit
    for browser in browser_list:
        url = urljoin(user_string_url, browser) + '/'
        submit(process_request, url, submit(urlopen, url))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could also do this with yield:</p>
<pre><code>def collect_browsers():
    browser_list= ['Chrome','Mozilla','Safari','Internet Explorer','Opera']
    user_string_url="http://www.useragentstring.com/pages/"
    for eachBrowser in browser_list:
        yield eachBrowser, urllib2.urlopen(urljoin(user_string_url,eachBrowser))


def process_browsers():
   for browser, result in collect_browsers():
       do_something (result)
</code></pre>
<p>This is still a synchronous call (browser 2 will not fire until browser 1 is processed) but you can keep the logic for dealing with the results separate from the logic managing the connections.  You could of course also use threads to handle the processing asynchronously with or without <em>yield</em></p>
<p><strong>Edit</strong></p>
<p>Just re-read OP and should repeat that yield doesn't provide multi-threaded, asynchronous execution in case that was not clear in my first answer!</p>
</div>
<span class="comment-copy">Thanks but still i have to wait until the For loop is done. I thought to use it asynchronously</span>
<span class="comment-copy">Can i do it using Tornado?</span>
<span class="comment-copy">Im not familiar with the library, but a quick look at the docs made it look like the they use yield to do couroutines:  <a href="http://www.tornadoweb.org/en/stable/gen.html" rel="nofollow noreferrer">tornadoweb.org/en/stable/gen.html</a></span>
<span class="comment-copy">Thanks. I figured it out.</span>
