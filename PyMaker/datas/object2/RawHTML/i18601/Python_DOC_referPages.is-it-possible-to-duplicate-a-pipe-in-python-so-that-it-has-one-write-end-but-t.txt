<div class="post-text" itemprop="text">
<p>Suppose I have a process that generates some data, and this data is consumed by two different processes which are independent of one another. </p>
<p>One way to solve this problem would be to have the generated data written to a file, and then have the other two processes read from the file. This will work fine if the size of the file is not big, but IO becomes expensive if there is a lot of data.</p>
<p>If I had only one process consuming the data, I can just connect the two processes using <code>os.pipe()</code> and funnel data from the output of one into the input of the other.</p>
<p>However, since I have two consumer processes, I'm not sure if there's a way I can duplicate the read side of the pipe so that both consumers can read from it.</p>
</div>
<div class="post-text" itemprop="text">
<p>Data from a pipe can only be read once.  You can, however, use an intermediate process that simply copies the data and writes it to two different file descriptors.  On Unix systems, this is done by the standard tool <code>tee</code>.  An example in POSIX shell:</p>
<pre><code>$ exec 4&gt; a
$ seq 3 | tee /dev/fd/4 &gt; b
</code></pre>
<p>This will write the output of <code>seq 3</code> to both files, <code>a</code> and <code>b</code>.</p>
<p>You can do the same thing in Python, using a combination od one call to <code>os.pipe()</code> and a call to <code>subprocess.Popen()</code> for the <code>tee</code> process, and one call to <code>subprocess.Popen()</code> for each of the processes you want to connect.</p>
<pre><code>producer = subprocess.Popen(["seq", "3"], stdout=subprocess.PIPE)
pipe_r, pipe_w = os.pipe()
tee = subprocess.Popen(["tee", "/dev/fd/{}".format(pipe_w)],
                       stdin=producer.stdout, stdout=subprocess.PIPE)
consumer1 = subprocess.Popen(["cat"], stdin=tee.stdout)
consumer2 = subprocess.Popen(["cat"], stdin=pipe_r)
producer.wait()
tee.wait()
consumer1.wait()
consumer2.wait()
os.close(pipe_r)
os.close(pipe_w)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>So since it's a file descriptor that's returned by a Pipe I regret to say you can't go back; An idea though would be to have either reader process add the data to a <code>multiprocessing.Queue</code> where both can read out of and later drop the data. </p>
<p>You can always have a pipe from the writer process to each of the readers as well. also there are other things such as <code>shared memory</code> or <code>dbus</code> that you could use to ferry around data.</p>
<p>Could you describe your problem more in depth?</p>
<p>Depending on the platform you can also just have the process use multiple streams - e.g. stdout and a 4th one - but this isn't portable between OS's.</p>
</div>
<span class="comment-copy">Couldn't the producer just output the same data to two different output pipes?</span>
<span class="comment-copy">What platform(s) are you targetting?</span>
<span class="comment-copy">Both processes want all the data? I think you'll have to send the data twice. An advantage of a file or mmap file is that you don't risk your program stalling out because one of the processes is slow at reading the data.</span>
<span class="comment-copy">@SvenMarnach, I am targeting only CentOS 5/6, so OS-specific solutions are fine.</span>
<span class="comment-copy">I have copy pasted this code but I get: tee: /dev/fd/5: No such file or directory, and 1 2 3 as output, then it deadlocks. Any advice?</span>
<span class="comment-copy">Perhaps it's because <a href="https://docs.python.org/3/library/os.html" rel="nofollow noreferrer">os.pipe returned file descriptors are non-inheritable</a>?</span>
<span class="comment-copy">@gospes This doesn't seem to work in Python 3 â€“ I currently don't have time to work out why.</span>
<span class="comment-copy">I thought <code>os.pipe()</code> returns a file descriptor and not a file object.</span>
<span class="comment-copy">sorry you're right - a file object actually refers to a file descriptor as well; but they're both streams since they rely on &lt;stdio&gt;</span>
