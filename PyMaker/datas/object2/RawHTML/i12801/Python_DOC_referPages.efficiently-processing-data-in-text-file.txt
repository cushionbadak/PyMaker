<div class="post-text" itemprop="text">
<p>Lets assume I have a (text) file with the following structure (name, score):</p>
<pre><code> a         0
 a         1
 b         0
 c         0
 d         3
 b         2
</code></pre>
<p>And so on. My aim is to sum the scores for every name and order them from highest score to lowest score. So in this case, I want the following output:</p>
<pre><code> d         3
 b         2
 a         1
 c         0
</code></pre>
<p>In advance I do not know what names will be in the file.</p>
<p>I was wondering if there is an efficient way to do this. My text file can contain up to 50,000 entries.</p>
<p>The only way I can think of is just start at line 1, remember that name and then go over the whole file to look for that name and sum. This looks horribly inefficient, so I was wondering if there is a better way to do this.</p>
</div>
<div class="post-text" itemprop="text">
<p>Read all data into a dictionary:</p>
<pre><code>from collections import defaultdict
from operator import itemgetter

scores = defaultdict(int)
with open('my_file.txt') as fobj:
    for line in fobj:
        name, score = line.split()
        scores[name] += int(score)
</code></pre>
<p>and the sorting:</p>
<pre><code>for name, score in sorted(scores.items(), key=itemgetter(1), reverse=True):
    print(name, score)
</code></pre>
<p>prints:</p>
<pre><code>d 3
b 2
a 1
c 0
</code></pre>
<h1>Performance</h1>
<p>To check the performance of this answer vs. the one from @SvenMarnach, I put both approaches into a function.  Here <code>fobj</code> is a file opened for reading.
I use <code>io.StringIO</code> so IO delays should, hopefully, not be measured:</p>
<pre><code>from collections import Counter

def counter(fobj):
    scores = Counter()
    fobj.seek(0)
    for line in fobj:
        key, score = line.split()
        scores.update({key: int(score)})
    return scores.most_common()

from collections import defaultdict
from operator import itemgetter

def default(fobj):
    scores = defaultdict(int)
    fobj.seek(0)
    for line in fobj:
        name, score = line.split()
        scores[name] += int(score)
    return sorted(scores.items(), key=itemgetter(1), reverse=True)
</code></pre>
<p>Results for <code>collections.Counter</code>:</p>
<pre><code>%timeit counter(fobj)
10000 loops, best of 3: 59.1 µs per loop
</code></pre>
<p>Results for <code>collections.defaultdict</code>:</p>
<pre><code>%timeit default(fobj)
10000 loops, best of 3: 15.8 µs per loop
</code></pre>
<p>Looks like <code>defaultdict</code>is four times faster. I would not have guessed this. But when it comes to performance you <strong>need</strong> to measure. </p>
</div>
<div class="post-text" itemprop="text">
<p>This is a good use case for <code>collections.Counter</code>:</p>
<pre><code>from collections import Counter

scores = Counter()
with open('my_file') as f:
    for line in f:
        key, score = line.split()
        scores.update({key: int(score)})

for key, score in scores.most_common():
    print(key, score)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Pandas can do this fairly easily:</p>
<pre><code>import pandas as pd
data = pd.read_csv('filename.txt', names=['Name','Score'])
sorted = data.groupby('Name').sum().sort_values('Score', ascending=False)
print sorted
</code></pre>
</div>
<span class="comment-copy">Any attempts from your side?</span>
<span class="comment-copy">@AvinashRaj As stated in the question, I know a way to do it, but I was more looking for a better solution. I can add some pseudocode into my question, if you want me to.</span>
<span class="comment-copy">You can use <code>sorted(split)</code> with the same <code>key</code> (being the letters)</span>
<span class="comment-copy">You could use a <code>dict</code> with the name as the key and the score as the value. That can be made slightly neater by using <a href="https://docs.python.org/3/library/collections.html#defaultdict-examples" rel="nofollow noreferrer"><code>defaultdict(int)</code></a>.</span>
<span class="comment-copy">@caiohamamura: Nigel <i>did</i> clearly describe the only approach he could think of, and that he felt that it was too inefficient (which it is). Surely he doesn't need to specifically show us the code for that inefficient O(n^2) algorithm?</span>
<span class="comment-copy">@caiohamamura: Fair enough, deleted my comment. Didn't see that Mike is using <code>defaultdict(int)</code> (My solution was put them in a list and then use <code>sum()</code>).</span>
<span class="comment-copy">@Kevin That list-based strategy would be slower and (temporarily) consume more RAM than Mike's approach of simply accumulating the data as it's seen.</span>
<span class="comment-copy">@PM2Ring: Yep, Because it'll create some lists. Forgot that we can use <code>defaultdict(int)</code>.</span>
<span class="comment-copy">@Mike ... just to confirm this, you could replace <code>key=itemgetter(1)</code> with <code>key=lambda s:s[1]</code> ...and still you will get the same output...couldn't you?</span>
<span class="comment-copy">@IronFist Yes, that is what <code>itemgetter</code> does. The name is a bit more intuitive than reading the <code>lambda</code> function.</span>
<span class="comment-copy">I guess this would be a little slower than using <code>defaultdict</code>, since you need to put each data item into a <code>dict</code> to add it to the <code>Counter</code>. OTOH, it does make it simple to get the sorted list of accumulated scores.</span>
<span class="comment-copy">@PM2Ring: Probably, and <code>defaultdict</code> will be far slower than using a plain <code>dict</code>. Speed only matters for this use case if the file is really huge, and if it is, the bottleneck will be I/O, not CPU.</span>
