<div class="post-text" itemprop="text">
<p>I have a Python script which takes as input a list of integers, which I need to work with four integers at a time.  Unfortunately, I don't have control of the input, or I'd have it passed in as a list of four-element tuples.  Currently, I'm iterating over it this way:</p>
<pre><code>for i in xrange(0, len(ints), 4):
    # dummy op for example code
    foo += ints[i] * ints[i + 1] + ints[i + 2] * ints[i + 3]
</code></pre>
<p>It looks a lot like "C-think", though, which makes me suspect there's a more pythonic way of dealing with this situation.  The list is discarded after iterating, so it needn't be preserved.  Perhaps something like this would be better?</p>
<pre><code>while ints:
    foo += ints[0] * ints[1] + ints[2] * ints[3]
    ints[0:4] = []
</code></pre>
<p>Still doesn't quite "feel" right, though.  :-/</p>
<p>Related question: <a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python">How do you split a list into evenly sized chunks in Python?</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Modified from the <a href="https://docs.python.org/library/itertools.html#itertools-recipes" rel="nofollow noreferrer">recipes</a> section of Python's <a href="http://docs.python.org/library/itertools.html" rel="nofollow noreferrer">itertools</a> docs:</p>
<pre><code>from itertools import zip_longest

def grouper(iterable, n, fillvalue=None):
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)
</code></pre>
<p><strong>Example</strong><br/>
In pseudocode to keep the example terse.</p>
<pre><code>grouper('ABCDEFG', 3, 'x') --&gt; 'ABC' 'DEF' 'Gxx'
</code></pre>
<p><strong>Note:</strong> on Python 2 use <code>izip_longest</code> instead of <code>zip_longest</code>.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>def chunker(seq, size):
    return (seq[pos:pos + size] for pos in range(0, len(seq), size))
# (in python 2 use xrange() instead of range() to avoid allocating a list)
</code></pre>
<p>Simple. Easy. Fast. Works with any sequence:</p>
<pre><code>text = "I am a very, very helpful text"

for group in chunker(text, 7):
   print repr(group),
# 'I am a ' 'very, v' 'ery hel' 'pful te' 'xt'

print '|'.join(chunker(text, 10))
# I am a ver|y, very he|lpful text

animals = ['cat', 'dog', 'rabbit', 'duck', 'bird', 'cow', 'gnu', 'fish']

for group in chunker(animals, 3):
    print group
# ['cat', 'dog', 'rabbit']
# ['duck', 'bird', 'cow']
# ['gnu', 'fish']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I'm a fan of </p>
<pre><code>chunk_size= 4
for i in range(0, len(ints), chunk_size):
    chunk = ints[i:i+chunk_size]
    # process chunk of size &lt;= chunk_size
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import itertools
def chunks(iterable,size):
    it = iter(iterable)
    chunk = tuple(itertools.islice(it,size))
    while chunk:
        yield chunk
        chunk = tuple(itertools.islice(it,size))

# though this will throw ValueError if the length of ints
# isn't a multiple of four:
for x1,x2,x3,x4 in chunks(ints,4):
    foo += x1 + x2 + x3 + x4

for chunk in chunks(ints,4):
    foo += sum(chunk)
</code></pre>
<p>Another way:</p>
<pre><code>import itertools
def chunks2(iterable,size,filler=None):
    it = itertools.chain(iterable,itertools.repeat(filler,size-1))
    chunk = tuple(itertools.islice(it,size))
    while len(chunk) == size:
        yield chunk
        chunk = tuple(itertools.islice(it,size))

# x2, x3 and x4 could get the value 0 if the length is not
# a multiple of 4.
for x1,x2,x3,x4 in chunks2(ints,4,0):
    foo += x1 + x2 + x3 + x4
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>from itertools import izip_longest

def chunker(iterable, chunksize, filler):
    return izip_longest(*[iter(iterable)]*chunksize, fillvalue=filler)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I needed a solution that would also work with sets and generators. I couldn't come up with anything very short and pretty, but it's quite readable at least.</p>
<pre><code>def chunker(seq, size):
    res = []
    for el in seq:
        res.append(el)
        if len(res) == size:
            yield res
            res = []
    if res:
        yield res
</code></pre>
<p>List:</p>
<pre><code>&gt;&gt;&gt; list(chunker([i for i in range(10)], 3))
[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
</code></pre>
<p>Set:</p>
<pre><code>&gt;&gt;&gt; list(chunker(set([i for i in range(10)]), 3))
[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
</code></pre>
<p>Generator:</p>
<pre><code>&gt;&gt;&gt; list(chunker((i for i in range(10)), 3))
[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The ideal solution for this problem works with iterators (not just sequences). It should also be fast.</p>
<p>This is the solution provided by the documentation for itertools:</p>
<pre><code>def grouper(n, iterable, fillvalue=None):
    #"grouper(3, 'ABCDEFG', 'x') --&gt; ABC DEF Gxx"
    args = [iter(iterable)] * n
    return itertools.izip_longest(fillvalue=fillvalue, *args)
</code></pre>
<p>Using ipython's <code>%timeit</code> on my mac book air, I get 47.5 us per loop.</p>
<p>However, this really doesn't work for me since the results are padded to be even sized groups. A solution without the padding is slightly more complicated. The most naive solution might be:</p>
<pre><code>def grouper(size, iterable):
    i = iter(iterable)
    while True:
        out = []
        try:
            for _ in range(size):
                out.append(i.next())
        except StopIteration:
            yield out
            break

        yield out
</code></pre>
<p>Simple, but pretty slow: 693 us per loop</p>
<p>The best solution I could come up with uses <code>islice</code> for the inner loop:</p>
<pre><code>def grouper(size, iterable):
    it = iter(iterable)
    while True:
        group = tuple(itertools.islice(it, None, size))
        if not group:
            break
        yield group
</code></pre>
<p>With the same dataset, I get 305 us per loop.</p>
<p>Unable to get a pure solution any faster than that, I provide the following solution with an important caveat: If your input data has instances of <code>filldata</code> in it, you could get wrong answer.</p>
<pre><code>def grouper(n, iterable, fillvalue=None):
    #"grouper(3, 'ABCDEFG', 'x') --&gt; ABC DEF Gxx"
    args = [iter(iterable)] * n
    for i in itertools.izip_longest(fillvalue=fillvalue, *args):
        if tuple(i)[-1] == fillvalue:
            yield tuple(v for v in i if v != fillvalue)
        else:
            yield i
</code></pre>
<p>I really don't like this answer, but it is significantly faster. 124 us per loop</p>
</div>
<div class="post-text" itemprop="text">
<p>Similar to other proposals, but not exactly identical, I like doing it this way, because it's simple and easy to read:</p>
<pre><code>it = iter([1, 2, 3, 4, 5, 6, 7, 8, 9])
for chunk in zip(it, it, it, it):
    print chunk

&gt;&gt;&gt; (1, 2, 3, 4)
&gt;&gt;&gt; (5, 6, 7, 8)
</code></pre>
<p>This way you won't get the last partial chunk. If you want to get <code>(9, None, None, None)</code> as last chunk, just use <code>izip_longest</code> from <code>itertools</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Using map() instead of zip() fixes the padding issue in J.F. Sebastian's answer:</p>
<pre><code>&gt;&gt;&gt; def chunker(iterable, chunksize):
...   return map(None,*[iter(iterable)]*chunksize)
</code></pre>
<p>Example:</p>
<pre><code>&gt;&gt;&gt; s = '1234567890'
&gt;&gt;&gt; chunker(s, 3)
[('1', '2', '3'), ('4', '5', '6'), ('7', '8', '9'), ('0', None, None)]
&gt;&gt;&gt; chunker(s, 4)
[('1', '2', '3', '4'), ('5', '6', '7', '8'), ('9', '0', None, None)]
&gt;&gt;&gt; chunker(s, 5)
[('1', '2', '3', '4', '5'), ('6', '7', '8', '9', '0')]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Since nobody's mentioned it yet here's a <code>zip()</code> solution:</p>
<pre><code>&gt;&gt;&gt; def chunker(iterable, chunksize):
...     return zip(*[iter(iterable)]*chunksize)
</code></pre>
<p>It works only if your sequence's length is always divisible by the chunk size or you don't care about a trailing chunk if it isn't.</p>
<p>Example:</p>
<pre><code>&gt;&gt;&gt; s = '1234567890'
&gt;&gt;&gt; chunker(s, 3)
[('1', '2', '3'), ('4', '5', '6'), ('7', '8', '9')]
&gt;&gt;&gt; chunker(s, 4)
[('1', '2', '3', '4'), ('5', '6', '7', '8')]
&gt;&gt;&gt; chunker(s, 5)
[('1', '2', '3', '4', '5'), ('6', '7', '8', '9', '0')]
</code></pre>
<p>Or using <a href="http://docs.python.org/library/itertools.html" rel="nofollow noreferrer">itertools.izip</a> to return an iterator instead of a list:</p>
<pre><code>&gt;&gt;&gt; from itertools import izip
&gt;&gt;&gt; def chunker(iterable, chunksize):
...     return izip(*[iter(iterable)]*chunksize)
</code></pre>
<p>Padding can be fixed using <a href="https://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python#312644">@ΤΖΩΤΖΙΟΥ's answer</a>:</p>
<pre><code>&gt;&gt;&gt; from itertools import chain, izip, repeat
&gt;&gt;&gt; def chunker(iterable, chunksize, fillvalue=None):
...     it   = chain(iterable, repeat(fillvalue, chunksize-1))
...     args = [it] * chunksize
...     return izip(*args)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you don't mind using an external package you could use <a href="https://iteration-utilities.readthedocs.io/en/latest/generated/grouper.html" rel="nofollow noreferrer"><code>iteration_utilities.grouper</code></a> from <a href="https://iteration-utilities.readthedocs.io/en/latest/installation.html" rel="nofollow noreferrer"><code>iteration_utilties</code></a> <sup>1</sup>. It supports all iterables (not just sequences):</p>
<pre><code>from iteration_utilities import grouper
seq = list(range(20))
for group in grouper(seq, 4):
    print(group)
</code></pre>
<p>which prints:</p>
<pre><code>(0, 1, 2, 3)
(4, 5, 6, 7)
(8, 9, 10, 11)
(12, 13, 14, 15)
(16, 17, 18, 19)
</code></pre>
<p>In case the length isn't a multiple of the groupsize it also supports filling (the incomplete last group) or truncating (discarding the incomplete last group) the last one:</p>
<pre><code>from iteration_utilities import grouper
seq = list(range(17))
for group in grouper(seq, 4):
    print(group)
# (0, 1, 2, 3)
# (4, 5, 6, 7)
# (8, 9, 10, 11)
# (12, 13, 14, 15)
# (16,)

for group in grouper(seq, 4, fillvalue=None):
    print(group)
# (0, 1, 2, 3)
# (4, 5, 6, 7)
# (8, 9, 10, 11)
# (12, 13, 14, 15)
# (16, None, None, None)

for group in grouper(seq, 4, truncate=True):
    print(group)
# (0, 1, 2, 3)
# (4, 5, 6, 7)
# (8, 9, 10, 11)
# (12, 13, 14, 15)
</code></pre>
<hr/>
<p><sup>1</sup> Disclaimer: I'm the author of that package.</p>
</div>
<div class="post-text" itemprop="text">
<p>If the list is large, the highest-performing way to do this will be to use a generator:</p>
<pre><code>def get_chunk(iterable, chunk_size):
    result = []
    for item in iterable:
        result.append(item)
        if len(result) == chunk_size:
            yield tuple(result)
            result = []
    if len(result) &gt; 0:
        yield tuple(result)

for x in get_chunk([1,2,3,4,5,6,7,8,9,10], 3):
    print x

(1, 2, 3)
(4, 5, 6)
(7, 8, 9)
(10,)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using little functions and things really doesn't appeal to me; I prefer to just use slices:</p>
<pre><code>data = [...]
chunk_size = 10000 # or whatever
chunks = [data[i:i+chunk_size] for i in xrange(0,len(data),chunk_size)]
for chunk in chunks:
    ...
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Another approach would be to use the two-argument form of <code>iter</code>: </p>
<pre><code>from itertools import islice

def group(it, size):
    it = iter(it)
    return iter(lambda: tuple(islice(it, size)), ())
</code></pre>
<p>This can be adapted easily to use padding (this is similar to <a href="https://stackoverflow.com/a/434314/577088">Markus Jarderot</a>’s answer):</p>
<pre><code>from itertools import islice, chain, repeat

def group_pad(it, size, pad=None):
    it = chain(iter(it), repeat(pad))
    return iter(lambda: tuple(islice(it, size)), (pad,) * size)
</code></pre>
<p>These can even be combined for optional padding:</p>
<pre><code>_no_pad = object()
def group(it, size, pad=_no_pad):
    if pad == _no_pad:
        it = iter(it)
        sentinel = ()
    else:
        it = chain(iter(it), repeat(pad))
        sentinel = (pad,) * size
    return iter(lambda: tuple(islice(it, size)), sentinel)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>With NumPy it's simple:</p>
<pre><code>ints = array([1, 2, 3, 4, 5, 6, 7, 8])
for int1, int2 in ints.reshape(-1, 2):
    print(int1, int2)
</code></pre>
<p>output:</p>
<pre><code>1 2
3 4
5 6
7 8
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>In your second method, I would advance to the next group of 4 by doing this:</p>
<pre><code>ints = ints[4:]
</code></pre>
<p>However, I haven't done any performance measurement so I don't know which one might be more efficient.</p>
<p>Having said that, I would usually choose the first method. It's not pretty, but that's often a consequence of interfacing with the outside world.</p>
</div>
<div class="post-text" itemprop="text">
<p>Yet another answer, the advantages of which are:</p>
<p>1) Easily understandable<br/>
2) Works on any iterable, not just sequences (some of the above answers will choke on filehandles)<br/>
3) Does not load the chunk into memory all at once<br/>
4) Does not make a chunk-long list of references to the same iterator in memory<br/>
5) No padding of fill values at the end of the list</p>
<p>That being said, I haven't timed it so it might be slower than some of the more clever methods, and some of the advantages may be irrelevant given the use case.</p>
<pre><code>def chunkiter(iterable, size):
  def inneriter(first, iterator, size):
    yield first
    for _ in xrange(size - 1): 
      yield iterator.next()
  it = iter(iterable)
  while True:
    yield inneriter(it.next(), it, size)

In [2]: i = chunkiter('abcdefgh', 3)
In [3]: for ii in i:                                                
          for c in ii:
            print c,
          print ''
        ...:     
        a b c 
        d e f 
        g h 
</code></pre>
<p><strong>Update:</strong><br/>
A couple of drawbacks due to the fact the inner and outer loops are pulling values from the same iterator:<br/>
1) continue doesn't work as expected in the outer loop - it just continues on to the next item rather than skipping a chunk. However, this doesn't seem like a problem as there's nothing to test in the outer loop.<br/>
2) break doesn't work as expected in the inner loop - control will wind up in the inner loop again with the next item in the iterator. To skip whole chunks, either wrap the inner iterator (ii above) in a tuple, e.g. <code>for c in tuple(ii)</code>, or set a flag and exhaust the iterator.<br/></p>
</div>
<div class="post-text" itemprop="text">
<pre><code>def group_by(iterable, size):
    """Group an iterable into lists that don't exceed the size given.

    &gt;&gt;&gt; group_by([1,2,3,4,5], 2)
    [[1, 2], [3, 4], [5]]

    """
    sublist = []

    for index, item in enumerate(iterable):
        if index &gt; 0 and index % size == 0:
            yield sublist
            sublist = []

        sublist.append(item)

    if sublist:
        yield sublist
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="http://funcy.readthedocs.org/en/latest/seqs.html#partition" rel="nofollow">partition</a> or <a href="http://funcy.readthedocs.org/en/latest/seqs.html#chunks" rel="nofollow">chunks</a> function from <a href="https://github.com/Suor/funcy" rel="nofollow">funcy</a> library:</p>
<pre><code>from funcy import partition

for a, b, c, d in partition(4, ints):
    foo += a * b * c * d
</code></pre>
<p>These functions also has iterator versions <code>ipartition</code> and <code>ichunks</code>, which will be more efficient in this case.</p>
<p>You can also peek at <a href="https://github.com/Suor/funcy/blob/1.0.0/funcy/seqs.py#L316" rel="nofollow">their implementation</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>To avoid all conversions to a list <code>import itertools</code> and:</p>
<pre><code>&gt;&gt;&gt; for k, g in itertools.groupby(xrange(35), lambda x: x/10):
...     list(g)
</code></pre>
<p>Produces:</p>
<pre><code>... 
0 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
1 [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
2 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]
3 [30, 31, 32, 33, 34]
&gt;&gt;&gt; 
</code></pre>
<p>I checked <code>groupby</code> and it doesn't convert to list or use <code>len</code> so I (think) this will delay resolution of each value until it is actually used.  Sadly none of the available answers (at this time) seemed to offer this variation.</p>
<p>Obviously if you need to handle each item in turn nest a for loop over g:</p>
<pre><code>for k,g in itertools.groupby(xrange(35), lambda x: x/10):
    for i in g:
       # do what you need to do with individual items
    # now do what you need to do with the whole group
</code></pre>
<p>My specific interest in this was the need to consume a generator to submit changes in batches of up to 1000 to the gmail API:</p>
<pre><code>    messages = a_generator_which_would_not_be_smart_as_a_list
    for idx, batch in groupby(messages, lambda x: x/1000):
        batch_request = BatchHttpRequest()
        for message in batch:
            batch_request.add(self.service.users().messages().modify(userId='me', id=message['id'], body=msg_labels))
        http = httplib2.Http()
        self.credentials.authorize(http)
        batch_request.execute(http=http)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>About solution gave by <code>J.F. Sebastian</code> <a href="https://stackoverflow.com/a/435712/3821804">here</a>:</p>
<pre><code>def chunker(iterable, chunksize):
    return zip(*[iter(iterable)]*chunksize)
</code></pre>
<p>It's clever, but has one disadvantage - always return tuple. How to get string instead?<br/>
Of course you can write <code>''.join(chunker(...))</code>, but the temporary tuple is constructed anyway.</p>
<p>You can get rid of the temporary tuple by writing own <code>zip</code>, like this:</p>
<pre><code>class IteratorExhausted(Exception):
    pass

def translate_StopIteration(iterable, to=IteratorExhausted):
    for i in iterable:
        yield i
    raise to # StopIteration would get ignored because this is generator,
             # but custom exception can leave the generator.

def custom_zip(*iterables, reductor=tuple):
    iterators = tuple(map(translate_StopIteration, iterables))
    while True:
        try:
            yield reductor(next(i) for i in iterators)
        except IteratorExhausted: # when any of iterators get exhausted.
            break
</code></pre>
<p>Then</p>
<pre><code>def chunker(data, size, reductor=tuple):
    return custom_zip(*[iter(data)]*size, reductor=reductor)
</code></pre>
<p>Example usage:</p>
<pre><code>&gt;&gt;&gt; for i in chunker('12345', 2):
...     print(repr(i))
...
('1', '2')
('3', '4')
&gt;&gt;&gt; for i in chunker('12345', 2, ''.join):
...     print(repr(i))
...
'12'
'34'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I like this approach. It feels simple and not magical and supports all iterable types and doesn't require imports.</p>
<pre><code>def chunk_iter(iterable, chunk_size):
it = iter(iterable)
while True:
    chunk = tuple(next(it) for _ in range(chunk_size))
    if not chunk:
        break
    yield chunk
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I never want my chunks padded, so that requirement is essential.  I find that the ability to work on any iterable is also requirement.  Given that, I decided to extend on the accepted answer, <a href="https://stackoverflow.com/a/434411/1074659">https://stackoverflow.com/a/434411/1074659</a>.  </p>
<p>Performance takes a slight hit in this approach if padding is not wanted due to the need to compare and filter the padded values.  However, for large chunk sizes, this utility is very performant.</p>
<pre><code>#!/usr/bin/env python3
from itertools import zip_longest


_UNDEFINED = object()


def chunker(iterable, chunksize, fillvalue=_UNDEFINED):
    """
    Collect data into chunks and optionally pad it.

    Performance worsens as `chunksize` approaches 1.

    Inspired by:
        https://docs.python.org/3/library/itertools.html#itertools-recipes

    """
    args = [iter(iterable)] * chunksize
    chunks = zip_longest(*args, fillvalue=fillvalue)
    yield from (
        filter(lambda val: val is not _UNDEFINED, chunk)
        if chunk[-1] is _UNDEFINED
        else chunk
        for chunk in chunks
    ) if fillvalue is _UNDEFINED else chunks
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>def chunker(iterable, n):
    """Yield iterable in chunk sizes.

    &gt;&gt;&gt; chunks = chunker('ABCDEF', n=4)
    &gt;&gt;&gt; chunks.next()
    ['A', 'B', 'C', 'D']
    &gt;&gt;&gt; chunks.next()
    ['E', 'F']
    """
    it = iter(iterable)
    while True:
        chunk = []
        for i in range(n):
            try:
                chunk.append(next(it))
            except StopIteration:
                yield chunk
                raise StopIteration
        yield chunk

if __name__ == '__main__':
    import doctest

    doctest.testmod()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is a chunker without imports that supports generators:</p>
<pre><code>def chunks(seq, size):
    it = iter(seq)
    while True:
        ret = tuple(next(it) for _ in range(size))
        if len(ret) == size:
            yield ret
        else:
            raise StopIteration()
</code></pre>
<p>Example of use:</p>
<pre><code>&gt;&gt;&gt; def foo():
...     i = 0
...     while True:
...         i += 1
...         yield i
...
&gt;&gt;&gt; c = chunks(foo(), 3)
&gt;&gt;&gt; c.next()
(1, 2, 3)
&gt;&gt;&gt; c.next()
(4, 5, 6)
&gt;&gt;&gt; list(chunks('abcdefg', 2))
[('a', 'b'), ('c', 'd'), ('e', 'f')]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There doesn't seem to be a pretty way to do this.  <a href="http://code.activestate.com/recipes/425397/" rel="nofollow noreferrer">Here</a> is a page that has a number of methods, including:</p>
<pre><code>def split_seq(seq, size):
    newseq = []
    splitsize = 1.0/size*len(seq)
    for i in range(size):
        newseq.append(seq[int(round(i*splitsize)):int(round((i+1)*splitsize))])
    return newseq
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the lists are the same size, you can combine them into lists of 4-tuples with <code>zip()</code>. For example:</p>
<pre><code># Four lists of four elements each.

l1 = range(0, 4)
l2 = range(4, 8)
l3 = range(8, 12)
l4 = range(12, 16)

for i1, i2, i3, i4 in zip(l1, l2, l3, l4):
    ...
</code></pre>
<p>Here's what the <code>zip()</code> function produces:</p>
<pre><code>&gt;&gt;&gt; print l1
[0, 1, 2, 3]
&gt;&gt;&gt; print l2
[4, 5, 6, 7]
&gt;&gt;&gt; print l3
[8, 9, 10, 11]
&gt;&gt;&gt; print l4
[12, 13, 14, 15]
&gt;&gt;&gt; print zip(l1, l2, l3, l4)
[(0, 4, 8, 12), (1, 5, 9, 13), (2, 6, 10, 14), (3, 7, 11, 15)]
</code></pre>
<p>If the lists are large, and you don't want to combine them into a bigger list, use <code>itertools.izip()</code>, which produces an iterator, rather than a list.</p>
<pre><code>from itertools import izip

for i1, i2, i3, i4 in izip(l1, l2, l3, l4):
    ...
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>One-liner, adhoc solution to iterate over a list <code>x</code> in chunks of size <code>4</code> -</p>
<pre><code>for a, b, c, d in zip(x[0::4], x[1::4], x[2::4], x[3::4]):
    ... do something with a, b, c and d ...
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>At first, I designed it to split strings into substrings to parse string containing hex.<br/>
Today I turned it into complex, but still simple generator.</p>
<pre><code>def chunker(iterable, size, reductor, condition):
    it = iter(iterable)
    def chunk_generator():
        return (next(it) for _ in range(size))
    chunk = reductor(chunk_generator())
    while condition(chunk):
        yield chunk
        chunk = reductor(chunk_generator())
</code></pre>
<h1>Arguments:</h1>
<h3>Obvious ones</h3>
<ul>
<li><code>iterable</code> is any iterable / iterator / generator containg / generating / iterating over input data,</li>
<li><code>size</code> is, of course, size of chunk you want get,</li>
</ul>
<h3>More interesting</h3>
<ul>
<li><p><code>reductor</code> is a callable, which receives generator iterating over content of chunk.<br/>
I'd expect it to return sequence or string, but I don't demand that.</p>
<p>You can pass as this argument for example <code>list</code>, <code>tuple</code>, <code>set</code>, <code>frozenset</code>,<br/>
or anything fancier. I'd pass this function, returning string<br/>
(provided that <code>iterable</code> contains / generates / iterates over strings):</p>
<pre><code>def concatenate(iterable):
    return ''.join(iterable)
</code></pre>
<p><sup>Note that <code>reductor</code> can cause closing generator by raising exception.</sup></p></li>
<li><p><code>condition</code> is a callable which receives anything what <code>reductor</code> returned.<br/>
It decides to approve &amp; yield it (by returning anything evaluating to <code>True</code>),<br/>
or to decline it &amp; finish generator's work (by returning anything other or raising exception).</p>
<p>When number of elements in <code>iterable</code> is not divisible by <code>size</code>, when <code>it</code> gets exhausted, <code>reductor</code> will receive generator generating less elements than <code>size</code>.<br/>
Let's call these elements <em>lasts elements</em>.</p>
<p>I invited two functions to pass as this argument:  </p>
<ul>
<li><p><code>lambda x:x</code> - the <em>lasts elements</em> will be yielded.</p></li>
<li><p><code>lambda x: len(x)==&lt;size&gt;</code> - the <em>lasts elements</em> will be rejected.<br/>
<sup>replace <code>&lt;size&gt;</code> using number equal to <code>size</code></sup></p></li>
</ul></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>It is easy to make <code>itertools.groupby</code> work for you to get an iterable of iterables, without creating any temporary lists:</p>
<pre><code>groupby(iterable, (lambda x,y: (lambda z: x.next()/y))(count(),100))
</code></pre>
<p>Don't get put off by the nested lambdas, outer lambda runs just once to put <code>count()</code> generator and the constant <code>100</code> into the scope of the inner lambda.</p>
<p>I use this to send chunks of rows to mysql.</p>
<pre><code>for k,v in groupby(bigdata, (lambda x,y: (lambda z: x.next()/y))(count(),100))):
    cursor.executemany(sql, v)
</code></pre>
</div>
<span class="comment-copy">Your code does not work if the list size is not a multiple of four.</span>
<span class="comment-copy">I'm extend()ing the list so that it's length is a multiple of four before it gets this far.</span>
<span class="comment-copy">@ΤΖΩΤΖΙΟΥ — The questions are very similar, but not quite duplicate.  It's "split into any number of chunks of size N" vs. "split into N chunks of any size".  :-)</span>
<span class="comment-copy">possible duplicate of <a href="http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python">How do you split a list into evenly sized chunks in Python?</a></span>
<span class="comment-copy">Possible duplicate of <a href="http://stackoverflow.com/questions/3992735/python-generator-that-groups-another-iterable-into-groups-of-n">Python generator that groups another iterable into groups of N</a></span>
<span class="comment-copy">I know it is taken literally from documentation but I'd change the order of parameters: <code>grouper(iterable, chunksize)</code> and <code>izip_longest(*args, fillvalue=fillvalue)</code></span>
<span class="comment-copy">Finally got a chance to play around with this in a python session. For those who are as confused as I was, this is feeding the same iterator to izip_longest multiple times, causing it to consume successive values of the same sequence rather than striped values from separate sequences. I love it!</span>
<span class="comment-copy">What's the best way to filter back out the fillvalue? ([item for item in items if item is not fillvalue] for items in grouper(iterable))?</span>
<span class="comment-copy">I suspect that the performance of this grouper recipe for 256k sized chunks will be very poor, because <code>izip_longest</code> will be fed 256k arguments.</span>
<span class="comment-copy">In several places commenters say "when I finally worked out how this worked...." Maybe a bit of explanation is required. Particularly the list of iterators aspect.</span>
<span class="comment-copy">@Carlos Crasborn's version works for any iterable (not just sequences as the above code); it is concise and probably just as fast or even faster. Though it might be a bit obscure (unclear) for people unfamiliar with <code>itertools</code> module.</span>
<span class="comment-copy">With 3.x I only had to replace <code>xrange</code> with <code>range</code>. See: <a href="http://stackoverflow.com/a/15014576/671013">stackoverflow.com/a/15014576/671013</a></span>
<span class="comment-copy">Note that <code>chunker</code> returns a <code>generator</code>. Replace the return to: <code>return [...]</code> to get a list.</span>
<span class="comment-copy">Instead of writing a function building and then returning a generator, you could also write a generator directly, using <code>yield</code>: <code>for pos in xrange(0, len(seq), size): yield seq[pos:pos + size]</code>.  I'm not sure if internally this would be handled any differently in any relevant aspect, but it might be even a tiny bit clearer.</span>
<span class="comment-copy">Note this works only for sequences that support items access by index and won't work for generic iterators, because they may not support <code>__getitem__</code> method.</span>
<span class="comment-copy">How does it behave if len(ints) is not a multiple of the chunkSize?</span>
<span class="comment-copy">@AnnaVopureta <code>chunk</code> will have 1, 2 or 3 elements for the last batch of elements. See this question about why <a href="https://stackoverflow.com/questions/9490058/why-substring-slicing-index-out-of-range-works-in-python">slice indices can be out of bounds</a>.</span>
<span class="comment-copy">+1 for using generators, seams like the most "pythonic" out of all suggested solutions</span>
<span class="comment-copy">It's rather long and clumsy for something so easy, which isn't very pythonic at all. I prefer S. Lott's version</span>
<span class="comment-copy">@zenazn: this will work on generator instances, slicing won't</span>
<span class="comment-copy">In addition to working properly with generators and other non-sliceable iterators, the first solution also doesn't require a "filler" value if the final chunk is smaller than <code>size</code>, which is sometimes desirable.</span>
<span class="comment-copy">Also +1 for generators. Other solutions require a <code>len</code> call and so don't work on other generators.</span>
<span class="comment-copy">A readable way to do it is <a href="http://stackoverflow.com/questions/434287/what-is-the-most-pythonic-way-to-iterate-over-a-list-in-chunks#434411" title="what is the most pythonic way to iterate over a list in chunks%23434411">stackoverflow.com/questions/434287/…</a></span>
<span class="comment-copy">+1 it omits padding ; very similar to answer <a href="http://stackoverflow.com/users/509706/wilfred-hughes">of</a> Wilfred Hughes</span>
<span class="comment-copy">You can reduce runtime for recipe #3 by ~10-15% by moving it to the C layer (omitting <code>itertools</code> imports; <code>map</code> must be Py3 <code>map</code> or <code>imap</code>): <code>def grouper(n, it): return takewhile(bool, map(tuple, starmap(islice, repeat((iter(it), n)))))</code>. Your final function can be made less brittle by using a sentinel: get rid of the <code>fillvalue</code> argument; add a first line <code>fillvalue = object()</code>, then change the <code>if</code> check to <code>if i[-1] is fillvalue:</code> and the line it controls to <code>yield tuple(v for v in i if v is not fillvalue)</code>. Guarantees no value in <code>iterable</code> can be mistaken for the filler value.</span>
<span class="comment-copy">BTW, big thumbs up on #4. I was about to post my optimization of #3 as a better answer (performance-wise) than what had been posted so far, but with the tweak to make it reliable, resilient #4 runs over twice as fast as optimized #3; I did not expect a solution with Python level loops (and no theoretical algorithmic differences AFAICT) to win. I assume #3 loses due to the expense of constructing/iterating <code>islice</code> objects (#3 wins if <code>n</code> is relatively large, e.g. number of groups is small, but that's optimizing for an uncommon case), but I didn't expect it to be quite that extreme.</span>
<span class="comment-copy">For #4, the first branch of the conditional is only ever taken on the last iteration (the final tuple).  Instead of reconstituting the final tuple all over again, cache the modulo of the length of the original iterable at the top and use that to slice off the unwanted padding from <code>izip_longest</code> on the final tuple: <code>yield i[:modulo]</code>.  Also, for the <code>args</code> variable, tuple it instead of a list: <code>args = (iter(iterable),) * n</code>.  Shaves a few more clock cycles off.  Last, if we ignore fillvalue and assume <code>None</code>, the conditional can become <code>if None in i</code> for even more clock cycles.</span>
<span class="comment-copy">@Kumba: Your first suggestion assumes the input has known length. If it's an iterator/generator, not a collection with known length, there is nothing to cache. There's no real reason to use such an optimization anyway; you're optimizing the uncommon case (the last <code>yield</code>), while the common case is unaffected.</span>
<span class="comment-copy">I find this a lot more readable than the other answers.</span>
<span class="comment-copy">can be improved with <code>zip(*([it]*4))</code></span>
<span class="comment-copy">@Jean-François Fabre: from a readability point of view I do not see it as an improvement. And it's also marginally slower. It's an improvement if you are golfing, which I'm not.</span>
<span class="comment-copy">no I'm not golfing, but what if you have 10 arguments? I read that construct in some official page.but of course I can't seem to find it right now :)</span>
<span class="comment-copy">@Jean-François Fabre: if I have 10 arguments, or a variable number of arguments, it's an option, but I'd rather write: zip(*(it,)*10)</span>
<span class="comment-copy">This is better handled with <code>itertools.izip_longest</code> (Py2)/<code>itertools.zip_longest</code> (Py3); this use of <code>map</code> is doubly-deprecated, and not available in Py3 (you can't pass <code>None</code> as the mapper function, and it stops when the shortest iterable is exhausted, not the longest; it doesn't pad).</span>
<span class="comment-copy">(I think that MizardX's itertools suggestion is functionally equivalent to this.)</span>
<span class="comment-copy">(Actually, on reflection, no I don't.  itertools.islice returns an iterator, but it doesn't use an existing one.)</span>
<span class="comment-copy">It is nice and simple, but for some reason even without conversion to tuple 4-7 times slower than the accepted grouper method on <code>iterable = range(100000000)</code> &amp; <code>chunksize</code> up to 10000.</span>
<span class="comment-copy">However, in general I would recommend this method, because the accepted one can be extremely slow when checking for last item is slow <a href="https://docs.python.org/3/library/itertools.html#itertools.zip_longest" rel="nofollow noreferrer">docs.python.org/3/library/itertools.html#itertools.zip_longest</a></span>
<span class="comment-copy">nice but no good for an indefinite stream which has no known <code>len</code>. you can do a test with <code>itertools.repeat</code> or <code>itertools.cycle</code>.</span>
<span class="comment-copy">Also, eats up memory because of using a <code>[...for...]</code> <a href="https://docs.python.org/2/reference/expressions.html#list-displays" rel="nofollow noreferrer">list comprehension</a> to physically  build a list instead of using a <code>(...for...)</code> <a href="https://docs.python.org/2/reference/expressions.html#generator-expressions" rel="nofollow noreferrer">generator expression</a> which would just care about the next element and spare memory</span>
<span class="comment-copy">preferable because you have the option to omit the padding!</span>
<span class="comment-copy">+1 it omits padding ; yours and bcoughlan<a href="http://stackoverflow.com/a/18243990/611007">'s</a> is very similar</span>
<span class="comment-copy">What if the list you are chunking is something other than a sequence of ascending integers?</span>
<span class="comment-copy">@PaulMcGuire see <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer">groupby</a>; given a function to describe order then elements of the iterable can be anything, right?</span>
<span class="comment-copy">Yes, I'm familiar with groupby. But if messages were the letters "ABCDEFG", then <code>groupby(messages, lambda x: x/3)</code> would give you a TypeError (for trying to divide a string by an int), not 3-letter groupings. Now if you did <code>groupby(enumerate(messages), lambda x: x[0]/3)</code> you might have something.  But you didn't say that in your post.</span>
<span class="comment-copy">Not a critique meant for you to change your answer, but rather a comment:  Code is a liability.  The more code you write the more space you create for bugs to hide.  From this point of view, rewriting <code>zip</code> instead of using the existing one seems not to be the best idea.</span>
