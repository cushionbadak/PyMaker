<div class="post-text" itemprop="text">
<p>I just stumbled upon the following odd situation:</p>
<pre><code>&gt;&gt;&gt; class Test:
        µ = 'foo'

&gt;&gt;&gt; Test.µ
'foo'
&gt;&gt;&gt; getattr(Test, 'µ')
Traceback (most recent call last):
  File "&lt;pyshell#4&gt;", line 1, in &lt;module&gt;
    getattr(Test, 'µ')
AttributeError: type object 'Test' has no attribute 'µ'
&gt;&gt;&gt; 'µ'.encode(), dir(Test)[-1].encode()
(b'\xc2\xb5', b'\xce\xbc')
</code></pre>
<p>The character I entered is always the µ sign on the keyboard, but for some reason it gets converted. Why does this happen?</p>
</div>
<div class="post-text" itemprop="text">
<p>There are two different characters involved here. One is the <a href="http://www.fileformat.info/info/unicode/char/00b5/index.htm">MICRO SIGN</a>, which is the one on the keyboard, and the other is <a href="http://www.fileformat.info/info/unicode/char/03bc/index.htm">GREEK SMALL LETTER MU</a>.</p>
<p>To understand what’s going on, we should take a look at how Python defines identifiers in the <a href="https://docs.python.org/3/reference/lexical_analysis.html#identifiers">language reference</a>:</p>
<pre><code>identifier   ::=  xid_start xid_continue*
id_start     ::=  &lt;all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, and characters with the Other_ID_Start property&gt;
id_continue  ::=  &lt;all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc and others with the Other_ID_Continue property&gt;
xid_start    ::=  &lt;all characters in id_start whose NFKC normalization is in "id_start xid_continue*"&gt;
xid_continue ::=  &lt;all characters in id_continue whose NFKC normalization is in "id_continue*"&gt;
</code></pre>
<p>Both our characters, MICRO SIGN and GREEK SMALL LETTER MU, are part of the <code>Ll</code> unicode group (lowercase letters), so both of them can be used at any position in an identifier. Now note that the definition of <code>identifier</code> actually refers to <code>xid_start</code> and <code>xid_continue</code>, and those are defined as all characters in the respective non-x definition whose NFKC normalization results in a valid character sequence for an identifier.</p>
<p>Python apparently only cares about the <em>normalized</em> form of identifiers. This is confirmed a bit below:</p>
<blockquote>
<p>All identifiers are converted into the normal form NFKC while parsing; comparison of identifiers is based on NFKC.</p>
</blockquote>
<p>NFKC is a <a href="http://unicode.org/reports/tr15/">Unicode normalization</a> that decomposes characters into individual parts. The MICRO SIGN decomposes into GREEK SMALL LETTER MU, and that’s exactly what’s going on there.</p>
<p>There are a lot other characters that are also affected by this normalization. One other example is <a href="http://www.fileformat.info/info/unicode/char/2126/index.htm">OHM SIGN</a> which decomposes into <a href="http://www.fileformat.info/info/unicode/char/03a9/index.htm">GREEK CAPITAL LETTER OMEGA</a>. Using that as an identifier gives a similar result, here shown using locals:</p>
<pre><code>&gt;&gt;&gt; Ω = 'bar'
&gt;&gt;&gt; locals()['Ω']
Traceback (most recent call last):
  File "&lt;pyshell#1&gt;", line 1, in &lt;module&gt;
    locals()['Ω']
KeyError: 'Ω'
&gt;&gt;&gt; [k for k, v in locals().items() if v == 'bar'][0].encode()
b'\xce\xa9'
&gt;&gt;&gt; 'Ω'.encode()
b'\xe2\x84\xa6'
</code></pre>
<p>So in the end, this is just something that Python does. Unfortunately, there isn’t really a good way to detect this behavior, causing errors such as the one shown. Usually, when the identifier is only referred to as an identifier, i.e. it’s used like a real variable or attribute, then everything will be fine: The normalization runs every time, and the identifier is found.</p>
<p>The only problem is with string-based access. Strings are just strings, of course there is no normalization happening (that would be just a bad idea). And the two ways shown here, <a href="https://docs.python.org/3/library/functions.html#getattr"><code>getattr</code></a> and <a href="https://docs.python.org/3/library/functions.html#locals"><code>locals</code></a>, both operate on dictionaries. <code>getattr()</code> accesses an object’s attribute via the object’s <code>__dict__</code>, and <code>locals()</code> returns a dictionary. And in dictionaries, keys can be any string, so it’s perfectly fine to have a MICRO SIGN or a OHM SIGN in there.</p>
<p>In those cases, you need to remember to perform a normalization yourself. We can utilize <a href="https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize"><code>unicodedata.normalize</code></a> for this, which then also allows us to correctly get our value from inside <code>locals()</code> (or using <code>getattr</code>):</p>
<pre><code>&gt;&gt;&gt; normalized_ohm = unicodedata.normalize('NFKC', 'Ω')
&gt;&gt;&gt; locals()[normalized_ohm]
'bar'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/3/reference/lexical_analysis.html#identifiers" rel="nofollow noreferrer">What Python does here</a> is based on <a href="http://unicode.org/reports/tr31/#normalization_and_case" rel="nofollow noreferrer">Unicode Standard Annex #31</a>:</p>
<blockquote>
<p>Implementations that take normalization and case into account have two choices: to treat variants as equivalent, or to disallow variants.</p>
</blockquote>
<p>The rest of the section gives further details, but basically, this means that if a language allows you to have an identifier named <code>µ</code> at all, it should treat the two <code>µ</code> characters MICRO SIGN and GREEK SMALL LETTER MU the same, and it should do so by treating them both as GREEK SMALL LETTER MU.</p>
<hr/>
<p>Most other languages that allow non-ASCII identifiers follow the same standard;<sup>1</sup> only a few languages invented their own.<sup>2</sup> So, this rule has the advantage of being the same across a wide variety of languages (and potentially being supported by IDEs and other tools).</p>
<p>A case could be made that it really doesn't work as well in a language as reflection-heavy as Python, where strings can be used as identifiers as easily as writing <code>getattr(Test, 'µ')</code>. But if you can read <a href="https://mail.python.org/pipermail/python-3000/2007-June/008161.html" rel="nofollow noreferrer">the python-3000 mailing list discussions</a>, around <a href="https://www.python.org/dev/peps/pep-3131/" rel="nofollow noreferrer">PEP 3131</a>; the only options seriously considered were sticking with ASCII, UAX-31, or Java's minor variation on UAX-31; nobody wanted to invent a new standard just for Python.</p>
<p>The other way to solve this problem would be to add a <code>collections.identifierdict</code> type that's documented to apply the exact same rules for lookup that the compiler applies for identifiers in source, and to use that type in mappings intended to be used as namespaces (e.g., object, module, locals, class definitions). I vaguely remember someone suggesting that, but not having any good motivating examples. If anyone thinks this is a good enough example to revive the idea, they could post it on <a href="https://bugs.python.org/" rel="nofollow noreferrer">bugs.python.org</a> or <a href="https://mail.python.org/mailman/listinfo/python-ideas" rel="nofollow noreferrer">the python-ideas list</a>.</p>
<hr/>
<p><sub>1. Some languages, like ECMAScript and C#, use the "Java standard" instead, which is based on an early form of UAX-31 and adds some minor extensions, like ignoring RTL control codes—but that's close enough.</sub></p>
<p><sub>2. For example, <a href="https://docs.julialang.org/en/stable/manual/variables/#Allowed-Variable-Names-1" rel="nofollow noreferrer">Julia</a> allows Unicode currency and math symbols, and also has rules for mapping between LaTeX and Unicode identifiers—but they explicitly added rules to normalize <code>ɛ</code> and <code>µ</code> to the Greek latters…</sub></p>
</div>
<span class="comment-copy">That was very clear and thorough. I still try to avoid non-ASCII characters even in string literals, let alone variable names. Normalizing is just one issue, things can also get mangled by some editors, copy &amp; paste changing the encoding, etc. <code>class Test: mu = 'foo'</code></span>
<span class="comment-copy">As long as your using UTF-8 for your source files (which you really should), you’re fine in most of the cases with Python 3, especially in string literals. If you have an editor that can mess this up, you should get a better editor ;) And as for identifiers, you can be creative there too, except for the shown issue which might cause problems for some or go completely unnoticed for others :)</span>
