<div class="post-text" itemprop="text">
<p>I'm pulling data from an API with the following:</p>
<pre><code>url = "http://sitename"
response = requests.get(url)
data = response.text
print (data)
</code></pre>
<p>I get the output of raw xml, below is the browser output:</p>
<pre><code>&lt;projects count="8" href="/httpAuth/app/rest/projects/"&gt;
&lt;project id="_Root" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root1" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root2" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root3" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root4" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root5" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root6" name="" description="" href="" webUrl=""/&gt;
&lt;project id="_Root7" name="" description="" href="" webUrl=""/&gt;
&lt;/projects&gt;
</code></pre>
<p>How do I get each rows information into usable form, such as looping through the list for each project id I pull the id/name/desc/href of each and store it?</p>
<p>I tried doing an conversion to json in the accept headers section for requests.get() but it still spit back xml data so I think I'm stuck working with this content structure.</p>
</div>
<div class="post-text" itemprop="text">
<p>I'd use <code>lxml</code>.</p>
<pre><code>import requests
from lxml import etree

url = "http://sitename"
response = requests.get(url)
data = response.text
tree = etree.fromstring(data)
for leaf in tree:
    print(leaf.tag, leaf.attrib['id'], leaf.attrib['name'],
          leaf.attrib['description'], leaf.attrib['href'],
          leaf.attrib['webUrl'])
</code></pre>
<p>Which gives you:</p>
<pre><code>project _Root
project _Root1
project _Root2
project _Root3
project _Root4
project _Root5
project _Root6
project _Root7
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>For well-structured xml files, you can use (@Adam Smith) <code>lxml</code>, which is a quite famous library for parsing xml data.</p>
<p>For example, parsing the data you mention will take a snippet like the following:</p>
<pre><code>&gt;&gt; from lxml import etree
&gt;&gt; root = etree.fromstring(s) # your input string in question
&gt;&gt; for element in root.getchildren(): print element.items() # dict-like
[('id', '_Root'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root1'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root2'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root3'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root4'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root5'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root6'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
[('id', '_Root7'), ('name', ''), ('description', ''), ('href', ''), ('webUrl', '')]
</code></pre>
<p>Now, it is a known problem(?) that if your xml file is somehow corrupted, like missing a character in closing tag and whatnot, then <code>lxml</code> doesn't work. Well, it is not supposed to.</p>
<p>In that case you need to relay on regular expression (regex), i.e. Python's <code>re</code> module. Corrupted data will force you to man up and compile your own regular expression. For example, given the data you have, you can use the following regex:</p>
<pre><code>(?:\&lt;project id="(\w*?)" name="(\w*?)" description="(\w*?)" href="(\w*?)" webUrl="(\w*?)"\/\&gt;)
</code></pre>
<p>This will extract out five groups per match, each match contains one line while each group corresponds to an attribute, which can be empty strings. For more details, check out the <a href="https://docs.python.org/3/library/re.html" rel="nofollow">Python Doc</a>. Also <a href="http://pythex.org/" rel="nofollow">this site</a> is a good tool for prototyping/testing regex.</p>
</div>
<span class="comment-copy">use the <a href="https://pypi.python.org/pypi/lxml/3.5.0" rel="nofollow noreferrer"><code>lxml</code> module</a></span>
<span class="comment-copy">I'm using python 3.5.x , and I don't see lxml being available for it.</span>
<span class="comment-copy">I'm running it on 3.5 now but it was a bit of a pain to get compiled iirc. Try grabbing <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml" rel="nofollow noreferrer">it from the unofficial windows package list</a></span>
<span class="comment-copy">You can have BeautifulSoup,  or other parser - working with this cutting edge Python.</span>
<span class="comment-copy">but yes, BeautifulSoup works as well</span>
<span class="comment-copy">And god forbid you have to do that, because <a href="http://stackoverflow.com/a/1732454/3058609">as famously mentioned ad nauseum</a> parsing XML with regular expressions can drive a man to madness.</span>
<span class="comment-copy">@AdamSmith If <code>lxml</code> works, no one will want to reinvent the wheel. The latter parts describe cases when <code>lxml</code> and other libraries give parsing errors. You will be surprise how many archived datasets are corrupted here and there...<code>re</code>, necessary evil I'd say (god punching me in the face).</span>
<span class="comment-copy">Oh I'll never debate that, I'm just praying for his mortal soul! :)</span>
