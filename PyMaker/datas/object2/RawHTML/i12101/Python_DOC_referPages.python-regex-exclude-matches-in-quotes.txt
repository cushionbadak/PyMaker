<div class="post-text" itemprop="text">
<p>I have this string:</p>
<pre><code>s = MY_FUNC(AVG, WFC US EQUITY, WFC US EQUITY, "&gt;+3%", 1,1,7)
</code></pre>
<p>And this regex that searches for parens, commas, and simple operators. I need exclude any matches inside double quotes and be able to split on the matches. Note that the solution must still search for parens, commas and operators in the rest of the string. 
Current version of the regex is:</p>
<pre><code>tokenize_regex = re.compile(r'([\[\]\(\)\+\-\*/&lt;&gt;=!,])')
</code></pre>
<p>Matches for <code>s</code> are:</p>
<pre><code>Match 1
1.  (
Match 2
1.  ,
Match 3
1.  ,
Match 4
1.  ,
Match 5
1.  &gt;
Match 6
1.  +
Match 7
1.  ,
Match 8
1.  ,
Match 9
1.  ,
Match 10
1.  )
</code></pre>
<p>And when I do:</p>
<pre><code>    tokens = Formula.tokenize_regex.split(self.formula)
    print 'tokens: ' + str(tokens)
</code></pre>
<p>It returns:</p>
<pre><code>tokens: [u'MY_FUNC', u'(', u'AVG', u',', u' WFC US EQUITY', u',', u' WFC US EQUITY', u',', u' "', u'&gt;', u'', u'+', u'3%"', u',', u' 1', u',', u'1', u',', u'7', u')', u'']
</code></pre>
<p>But I need it to exclude the quantity in quotes, so matches should be:</p>
<pre><code>Match 1
1.  (
Match 2
1.  ,
Match 3
1.  ,
Match 4
1.  ,
Match 5
1.  ,
Match 6
1.  ,
Match 7
1.  ,
Match 8
1.  )
</code></pre>
<p>And tokens should be:</p>
<pre><code>tokens: [u'MY_FUNC', u'(', u'AVG', u',', u' WFC US EQUITY', u',', u' WFC US EQUITY', u',', u'"&gt;+3%"', u',', u' 1', u',', u'1', u',', u'7', u')', u'']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><code>re.split</code> is not a clean way to do tokenizing. There is a <a href="https://docs.python.org/3/library/re.html#writing-a-tokenizer" rel="nofollow">recipe</a> in the documentation of <code>re</code> which will serve you better. Basically, you first write a regex for each lexical type. For example:</p>
<pre><code>lexical_types = [
    ('QUOTED_CONTENT', r'"[^"]*?"'),
    ('PAREN', r'[()]'),
    ('OPERATOR', r'[-+&lt;&gt;]'),
    ('COMMA', r','),
    ('IDENTIFIER', r'[A-Z_][ A-Z_]*'),  # our identifier can have spaces in it
    # ...
]
</code></pre>
<p>Then you make a master regex out of these:</p>
<pre><code>groups = ('(?P&lt;{}&gt;{})'.format(ltype, regex) for ltype, regex in lexical_types)
tokenizer = re.compile('|'.join(groups))
</code></pre>
<p>Then you pass the string you want to tokenize to <code>tokenizer.finditer</code>:</p>
<pre><code>s = 'MY_FUNC(AVG, WFC US EQUITY, WFC US EQUITY, "&gt;+3%", 1,1,7)'
token_iter = tokenizer.finditer(s)  # an iterator
</code></pre>
<p>Now if you iterate over <code>token_iter</code>, you will get a stream of match objects which contain everything you could possibly want to know about the string (lexical-wise, that is). What you probably want to do is to process each match object based on its lexical type. For demo, let's print out the lexical type, the string matched, and the position of the string matched:</p>
<pre><code>for token in token_iter:
    ltype = token.lastgroup  # lexical type of the token
    print(ltype, token.group(ltype), token.span(ltype), sep='   ')
</code></pre>
<p>Output</p>
<pre><code>IDENTIFIER   MY_FUNC   (0, 7)
PAREN   (   (7, 8)
IDENTIFIER   AVG   (8, 11)
COMMA   ,   (11, 12)
IDENTIFIER   WFC US EQUITY   (13, 26)
COMMA   ,   (26, 27)
IDENTIFIER   WFC US EQUITY   (28, 41)
COMMA   ,   (41, 42)
QUOTED_CONTENT   "&gt;+3%"   (43, 49)
COMMA   ,   (49, 50)
COMMA   ,   (52, 53)
COMMA   ,   (54, 55)
PAREN   )   (56, 57)
</code></pre>
<p>NB: when compiling the master regex, you must make sure that higher-precedence patterns come before lower-precedence ones. So quotes should come before everything else. And operators made up of two characters (like <code>!=</code>) should come before those made up of one characters.</p>
<p>And this pattern will deal with single quotes as well as double quotes:</p>
<pre><code>r"""(?:'[^']*?'|"[^"]*?")"""  # grouped for readability
</code></pre>
</div>
<span class="comment-copy">Determining what is "inside" quotes is very hard with regex. Your best bet might be to use a regex to successively removing everything within quotes in a preprocessing step, but even then nested quotes might pose a problem.</span>
<span class="comment-copy">Don't try to use the <code>re.split</code> in this case, try to build a pattern for <code>re.findall</code>, it's more easy and more efficient.</span>
<span class="comment-copy">It's ok if it breaks on nested quotes.</span>
<span class="comment-copy">But then I can't really do split on it</span>
<span class="comment-copy">@user1387717 Oh you need to <i>keep</i> the quoted string as a token? Sorry I missed that. Then you probably need <code>finditer</code>. I will edit the answer.</span>
<span class="comment-copy">The identifier doesn't seem to include numbers? Why does that work on my example?</span>
<span class="comment-copy">@user1387717 I was just demonstrating an approach, which I'm sure you can easily implement. You can easily modify the definition of <code>IDENTIFIER</code> to include numbers. You can modify the definition of <code>OPERATOR</code> if you have more operators, etc, etc. You certainly know your needs (are numbers all ints? in exponential notation?) better than I do.</span>
