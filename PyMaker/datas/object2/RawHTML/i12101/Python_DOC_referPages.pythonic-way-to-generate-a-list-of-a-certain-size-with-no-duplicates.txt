<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/30610885/generate-a-large-list-of-points-with-no-duplicates">Generate a large list of points with no duplicates</a>
<span class="question-originals-answer-count">
                    4 answers
                </span>
</li>
</ul>
</div>
<p>I'm trying to generate a list of <code>(x, y)</code> tuples of size <code>num_cities</code> with the constraint that no two tuples are the same. Is there a shorter, Pythonic way to do this using a set comprehension or <code>itertools</code>? I currently have:</p>
<pre><code>def make_random_cities(num_cities, max_x, max_y):    
    cities = set()
    while len(cities) &lt; num_cities:
        x, y = randint(0, max_x), randint(0, max_y)
        cities.add((x, y))
    return list(cities)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the maximum values aren't too large to store the complete set of possibilities in memory (and it won't take forever to generate them), <a href="https://docs.python.org/3/library/random.html#random.sample" rel="nofollow"><code>random.sample</code></a> and <a href="https://docs.python.org/3/library/itertools.html#itertools.product" rel="nofollow"><code>itertools.product</code></a> can be used effectively here:</p>
<pre><code>import itertools
import random

def make_random_cities(num_cities, max_x, max_y):
    return random.sample(list(itertools.product(range(max_x+1), range(max_y+1))), num_cities)
</code></pre>
<p>If the <code>product</code> of the inputs gets too large though, you could easily exceed main memory; in that case, your approach of looping until you get sufficient unique results is probably the best approach.</p>
<p>You could do samples of each <code>range</code> independently and then combine them together, but that would add uniqueness constraints to each axis, which I'm guessing you don't want.</p>
<p>For this specific case (unique numbers following a predictable pattern), you could use a trick to make this memory friendly while still avoiding the issue of arbitrarily long loops. Instead of taking the <code>product</code> of two <code>range</code>s, you'd generate a single <code>range</code> (or in Py2, <code>xrange</code>) that encodes both unique values from the <code>product</code> in a single value:</p>
<pre><code>def make_random_cities(num_cities, max_x, max_y):
    max_xy = (max_x+1) * (max_y+1)
    xys = random.sample(range(max_xy), num_cities)
    return [divmod(xy, max_y+1) for xy in xys]
</code></pre>
<p>This means you have no large intermediate data to store (because Py3 <code>range</code>/Py2 <code>xrange</code> are "virtual" sequences, with storage requirements unrelated to the range of values they represent, and <code>random.sample</code> produces samples without needing to read all the values of the underlying sequence).</p>
</div>
<div class="post-text" itemprop="text">
<p>Your current code is probably good if the number of cities is much smaller than <code>max_x * max_y</code>. If they're closer together though, it may waste a lot of time generating duplicate coordinates.</p>
<p>An alternative approach would be to generate all possible coordinates and then sample from them:</p>
<pre><code>possible_coords = list(itertools.product(range(max_x), range(max_y))
sample = random.sample(possible_coords, len(cities))
</code></pre>
<p>Generating the list of will always take <code>O(max_x * max_y)</code>, but it won't get worse if the number of cities increases.</p>
</div>
