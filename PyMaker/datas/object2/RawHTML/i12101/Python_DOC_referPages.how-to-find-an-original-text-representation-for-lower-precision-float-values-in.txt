<div class="post-text" itemprop="text">
<p>I've run into an issue displaying <code>float</code> values in Python, loaded from an external data-source<br/><em>(they're 32bit floats, but this would apply to lower precision floats too)</em>.</p>
<p>(In case its important - These values were typed in by humans in C/C++, so unlike arbitrary calculated values, deviations from <em>round</em> numbers is likely <em>not</em> intended, though can't be ignored since the values may be constants such as <code>M_PI</code> or multiplied by constants).</p>
<p>Since CPython uses higher precision, (64bit typically), a value entered in as a lower precision float may <code>repr()</code> showing precision loss from being a 32bit-float, where the 64bit-float would show round values.</p>
<p>eg:</p>
<pre><code># Examples of 32bit float's displayed as 64bit floats in CPython.
0.0005 -&gt; 0.0005000000237487257
0.025  -&gt; 0.02500000037252903
0.04   -&gt; 0.03999999910593033
0.05   -&gt; 0.05000000074505806
0.3    -&gt; 0.30000001192092896
0.98   -&gt; 0.9800000190734863
1.2    -&gt; 1.2000000476837158
4096.3 -&gt; 4096.2998046875
</code></pre>
<p>Simply rounding the values to some arbitrary precision works in most cases, but may be incorrect since it could loose significant values with eg: <code>0.00000001</code>.</p>
<p>An example of this can be shown by printing a float converted to a 32bit float.</p>
<pre><code>def as_float_32(f):
    from struct import pack, unpack
    return unpack("f", pack("f", f))[0]

print(0.025)               #  --&gt; 0.025
print(as_float_32(0.025))  #  --&gt; 0.02500000037252903
</code></pre>
<hr/>
<p>So my question is:</p>
<p><strong>Whats the most efficient &amp; straightforward way to get the original representation for a 32bit float, without making assumptions or loosing precision?</strong></p>
<p>Put differently, if I have a data-source containing of 32bit floats, These were originally entered in by a human as round values, (examples above), but having them represented as higher precision values exposes that the value as a 32bit float is an approximation of the original value.</p>
<p>I would like to reverse this process, and get the <em>round</em> number back from the 32bit float data, but without loosing the precision which a 32bit float gives us. (which is why simply rounding isn't a good option).</p>
<hr/>
<p>Examples of why you might want to do this:</p>
<ul>
<li>Generating API documentation where Python extracts values from a C-API that uses single precision floats internally.</li>
<li>When people need to read/review values of data generated which happens to be provided as single precision floats.</li>
</ul>
<p>In both cases it's important not to loose significant precision, or show values which can't be easily read by humans at a glance.</p>
<hr/>
<ul>
<li><p><em>Update, I've made a solution which I'll include as an answer (for reference and to show its possible), but highly doubt its an efficient or elegant solution.</em></p></li>
<li><p><em>Of course you can't know the notation used: <code>0.1f</code>, <code>0.1F</code> or <code>1e-1f</code> where entered, that's not the purpose of this question.</em></p></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>You're looking to solve essentially the same problem that Python's <code>repr</code> solves, namely, finding the shortest decimal string that rounds to a given float. Except that in your case, the float isn't an IEEE 754 binary64 ("double precision") float, but an IEEE 754 binary32 ("single precision") float.</p>
<p>Just for the record, I should of course point out that retrieving the original string representation is impossible, since for example the strings <code>'0.10'</code>, <code>'0.1'</code>, <code>'1e-1'</code> and <code>'10e-2'</code> all get converted to the same float (or in this case <code>float32</code>). But under suitable conditions we can still hope to produce a string that has the same decimal value as the original string, and that's what I'll do below.</p>
<p>The approach you outline in your answer more-or-less works, but it can be streamlined a bit.</p>
<p>First, some bounds: when it comes to decimal representations of single-precision floats, there are two magic numbers: <code>6</code> and <code>9</code>. The significance of <code>6</code> is that any (not-too-large, not-too-small) decimal numeric string with 6 or fewer significant decimal digits will round-trip correctly through a single-precision IEEE 754 float: that is, converting that string to the nearest <code>float32</code>, and then converting <em>that</em> value back to the nearest <code>6</code>-digit decimal string, will produce a string with the same value as the original. For example:</p>
<pre><code>&gt;&gt;&gt; x = "634278e13"
&gt;&gt;&gt; y = float(np.float32(x))
&gt;&gt;&gt; y
6.342780214942106e+18
&gt;&gt;&gt; "{:.6g}".format(y)
'6.34278e+18'
</code></pre>
<p>(Here, by "not-too-large, not-too-small" I just mean that the underflow and overflow ranges of <code>float32</code> should be avoided. The property above applies for all normal values.)</p>
<p>This means that for your problem, if the <em>original</em> string had 6 or fewer digits, we can recover it by simply formatting the value to 6 significant digits. So if you only care about recovering strings that had 6 or fewer significant decimal digits in the first place, you can stop reading here: a simple <code>'{:.6g}'.format(x)</code> is enough. If you want to solve the problem more generally, read on.</p>
<p>For roundtripping in the other direction, we have the opposite property: given any single-precision float <code>x</code>, converting that float to a 9-digit decimal string (rounding to nearest, as always), and then converting that string back to a single-precision float, will always exactly recover the value of that float.</p>
<pre><code>&gt;&gt;&gt; x = np.float32(3.14159265358979)
&gt;&gt;&gt; x
3.1415927
&gt;&gt;&gt; np.float32('{:.9g}'.format(x)) == x
True
</code></pre>
<p>The relevance to your problem is there's <em>always</em> at least one 9-digit string that rounds to <code>x</code>, so we never have to look beyond 9 digits.</p>
<p>Now we can follow the same approach that you used in your answer: first try for a 6-digit string, then a 7-digit, then an 8-digit. If none of those work, the 9-digit string surely will, by the above. Here's some code.</p>
<pre><code>def original_string(x):
    for places in range(6, 10):  # try 6, 7, 8, 9
        s = '{:.{}g}'.format(x, places)
        y = np.float32(s)
        if x == y:
            return s
    # If x was genuinely a float32, we should never get here.
    raise RuntimeError("We should never get here")
</code></pre>
<p>Example outputs:</p>
<pre><code>&gt;&gt;&gt; original_string(0.02500000037252903)
'0.025'
&gt;&gt;&gt; original_string(0.03999999910593033)
'0.04'
&gt;&gt;&gt; original_string(0.05000000074505806)
'0.05'
&gt;&gt;&gt; original_string(0.30000001192092896)
'0.3'
&gt;&gt;&gt; original_string(0.9800000190734863)
'0.98'
</code></pre>
<p>However, the above comes with several caveats.</p>
<ul>
<li><p>First, for the key properties we're using to be true, we have to assume that <code>np.float32</code> always does <em>correct rounding</em>. That may or may not be the case, depending on the operating system. (Even in cases where the relevant operating system calls claim to be correctly rounded, there may still be corner cases where that claim fails to be true.) In practice, it's likely that <code>np.float32</code> is close enough to correctly rounded not to cause issues, but for complete confidence you'd want to know that it was correctly rounded.</p></li>
<li><p>Second, the above won't work for values in the subnormal range (so for <code>float32</code>, anything smaller than <code>2**-126</code>). In the subnormal range, it's no longer true that a 6-digit decimal numeric string will roundtrip correctly through a single-precision float. If you care about subnormals, you'd need to do something more sophisticated there.</p></li>
<li><p>Third, there's a really subtle (and interesting!) error in the above that <em>almost</em> doesn't matter at all. The string formatting we're using always rounds <code>x</code> to the <em>nearest</em> <code>places</code>-digit decimal string to the true value of <code>x</code>. However, we want to know simply whether there's <em>any</em> <code>places</code>-digit decimal string that rounds back to <code>x</code>. We're implicitly assuming the (seemingly obvious) fact that if there's <em>any</em> <code>places</code>-digit decimal string that rounds to <code>x</code>, then the <em>closest</em> <code>places</code>-digit decimal string rounds to <code>x</code>. And that's <em>almost</em> true: it follows from the property that the interval of all real numbers that rounds to <code>x</code> is symmetric around <code>x</code>. But that symmetry property fails in one particular case, namely when <code>x</code> is a power of <code>2</code>.</p></li>
</ul>
<p>So when <code>x</code> is an exact power of <code>2</code>, it's <em>possible</em> (but fairly unlikely) that (for example) the closest 8-digit decimal string to <code>x</code> <em>doesn't</em> round to <code>x</code>, but nevertheless there is an 8-digit decimal string that does round to <code>x</code>. You can do an exhaustive search for cases where this happens within the range of a <code>float32</code>, and it turns out that there are exactly three values of <code>x</code> for which this occurs, namely <code>x = 2**-96</code>, <code>x = 2**87</code> and <code>x = 2**90</code>. For 7 digits, there are no such values. (And for 6 and 9 digits, this can never happen.) Let's take a closer look at the case <code>x = 2**87</code>:</p>
<pre><code>&gt;&gt;&gt; x = 2.0**87
&gt;&gt;&gt; x
1.5474250491067253e+26
</code></pre>
<p>Let's take the closest 8-digit decimal value to <code>x</code>:</p>
<pre><code>&gt;&gt;&gt; s = '{:.8g}'.format(x)
&gt;&gt;&gt; s
'1.547425e+26'
</code></pre>
<p>It turns out that this value <em>doesn't</em> round back to <code>x</code>:</p>
<pre><code>&gt;&gt;&gt; np.float32(s) == x
False
</code></pre>
<p>But the next 8-digit decimal string up from it does:</p>
<pre><code>&gt;&gt;&gt; np.float32('1.5474251e+26') == x
True
</code></pre>
<p>Similarly, here's the case <code>x = 2**-96</code>:</p>
<pre><code>&gt;&gt;&gt; x = 2**-96.
&gt;&gt;&gt; x
1.262177448353619e-29
&gt;&gt;&gt; s = '{:.8g}'.format(x)
&gt;&gt;&gt; s
'1.2621774e-29'
&gt;&gt;&gt; np.float32(s) == x
False
&gt;&gt;&gt; np.float32('1.2621775e-29') == x
True
</code></pre>
<p>So ignoring subnormals and overflows, out of all 2 billion or so positive normal single-precision values, there are precisely <em>three</em> values <code>x</code> for which the above code doesn't work. (Note: I originally thought there was just one; thanks to @RickRegan for pointing out the error in comments.) So here's our (slightly tongue-in-cheek) fixed code:</p>
<pre><code>def original_string(x):
    """
    Given a single-precision positive normal value x,
    return the shortest decimal numeric string which produces x.
    """
    # Deal with the three awkward cases.
    if x == 2**-96.:
        return '1.2621775e-29'
    elif x == 2**87:
        return '1.5474251e+26'
    elif x == 2**90:
        return '1.2379401e+27'

    for places in range(6, 10):  # try 6, 7, 8, 9
        s = '{:.{}g}'.format(x, places)
        y = np.float32(s)
        if x == y:
            return s
    # If x was genuinely a float32, we should never get here.
    raise RuntimeError("We should never get here")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think <a href="https://docs.python.org/3/library/decimal.html#decimal.Decimal.quantize" rel="nofollow"><code>Decimal.quantize()</code></a> (to round to a given number of decimal digits) and <a href="https://docs.python.org/3/library/decimal.html#decimal.Decimal.normalize" rel="nofollow"><code>.normalize()</code></a> (to strip trailing 0's) is what you need.</p>
<pre><code>#!/usr/bin/env python
# -*- coding: utf-8 -*-

from decimal import Decimal

data = (
    0.02500000037252903,
    0.03999999910593033,
    0.05000000074505806,
    0.30000001192092896,
    0.9800000190734863,
    )

for f in data:
    dec = Decimal(f).quantize(Decimal('1.0000000')).normalize()
    print("Original %s -&gt; %s" % (f, dec))
</code></pre>
<p>Result:</p>
<pre><code>Original 0.0250000003725 -&gt; 0.025
Original 0.0399999991059 -&gt; 0.04
Original 0.0500000007451 -&gt; 0.05
Original 0.300000011921 -&gt; 0.3
Original 0.980000019073 -&gt; 0.98
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Heres a solution I've come up with which works (<em>perfectly</em> as far as I can tell) but isn't efficient.</p>
<p>It works by rounding at increasing decimal places, and returning the string when the rounded and non-rounded inputs match (when compared as values converted to lower precision).</p>
<p>Code:</p>
<pre><code>def round_float_32(f):
    from struct import pack, unpack
    return unpack("f", pack("f", f))[0]


def as_float_low_precision_repr(f, round_fn):
    f_round = round_fn(f)
    f_str = repr(f)
    f_str_frac = f_str.partition(".")[2]
    if not f_str_frac:
        return f_str
    for i in range(1, len(f_str_frac)):
        f_test = round(f, i)
        f_test_round = round_fn(f_test)
        if f_test_round == f_round:
            return "%.*f" % (i, f_test)
    return f_str

# ----

data = (
    0.02500000037252903,
    0.03999999910593033,
    0.05000000074505806,
    0.30000001192092896,
    0.9800000190734863,
    1.2000000476837158,
    4096.2998046875,
    )

for f in data:
    f_as_float_32 = as_float_low_precision_repr(f, round_float_32)
    print("%s -&gt; %s" % (f, f_as_float_32))
</code></pre>
<p>Outputs:</p>
<pre><code>0.02500000037252903 -&gt; 0.025
0.03999999910593033 -&gt; 0.04
0.05000000074505806 -&gt; 0.05
0.30000001192092896 -&gt; 0.3
0.9800000190734863 -&gt; 0.98
1.2000000476837158 -&gt; 1.2
4096.2998046875 -&gt; 4096.3
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you have at least NumPy 1.14.0, you can just use <code>repr(numpy.float32(your_value))</code>. Quoting the <a href="https://docs.scipy.org/doc/numpy/release.html#float-printing-now-uses-dragon4-algorithm-for-shortest-decimal-representation" rel="nofollow noreferrer">release notes</a>:</p>
<blockquote>
<p><strong>Float printing now uses “dragon4” algorithm for shortest decimal representation</strong></p>
<p>The str and repr of floating-point values (16, 32, 64 and 128 bit) are now printed to give the shortest decimal representation which uniquely identifies the value from others of the same type. Previously this was only true for float64 values. The remaining float types will now often be shorter than in numpy 1.13.</p>
</blockquote>
<p>Here's a demo running against a few of your example values:</p>
<pre><code>&gt;&gt;&gt; repr(numpy.float32(0.0005000000237487257))
'0.0005'
&gt;&gt;&gt; repr(numpy.float32(0.02500000037252903))
'0.025'
&gt;&gt;&gt; repr(numpy.float32(0.03999999910593033))
'0.04'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Probably what you are looking for is <a href="https://docs.python.org/2/library/decimal.html" rel="nofollow"><code>decimal</code></a>:</p>
<blockquote>
<p>Decimal “is based on a floating-point model which was designed with people in mind, and necessarily has a paramount guiding principle – computers must provide an arithmetic that works in the same way as the arithmetic that people learn at school.”</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>At least in python3 you can use <code>.as_integer_ratio</code>. That's not exactly a string but the floating point definition as such is not really well suited for giving an exact representation in "finite" strings.</p>
<pre><code>a = 0.1
a.as_integer_ratio()
(3602879701896397, 36028797018963968)
</code></pre>
<p>So by saving these two numbers you'll never lose precision because these two exactly represent the saved floating point number. (Just divide the first by the second to get the value).</p>
<hr/>
<p>As an example using numpy dtypes (very similar to c dtypes):</p>
<pre><code># A value in python floating point precision
a = 0.1
# The value as ratio of integers
b = a.as_integer_ratio()

import numpy as np
# Force the result to have some precision:
res = np.array([0], dtype=np.float16)
np.true_divide(b[0], b[1], res)
print(res)
# Compare that two the wanted result when inputting 0.01
np.true_divide(1, 10, res)
print(res)

# Other precisions:
res = np.array([0], dtype=np.float32)
np.true_divide(b[0], b[1], res)
print(res)
res = np.array([0], dtype=np.float64)
np.true_divide(b[0], b[1], res)
print(res)
</code></pre>
<p>The result of all these calculations is:</p>
<pre><code>[ 0.09997559] # Float16 with integer-ratio
[ 0.09997559] # Float16 reference
[ 0.1] # Float32
[ 0.1] # Float64
</code></pre>
</div>
<span class="comment-copy">You'd probably want a modified version of <code>dtoa.c</code>, which is part of the Python source code, but is also found in a number of other projects.  This is the code that prints 0.1 as 0.1 instead of 0.1000000000000000055511151231257827021181583404541015625.</span>
<span class="comment-copy">@DietrichEpp, good to know, however for existing Python-only scripts, including C code isn't always an attractive option (assuming the project doesn't already use C-extensions).</span>
<span class="comment-copy">Just pointing out the possibilities.  The <code>dtoa.c</code> file has been copied to many projects and extensively tested, it will generally be easier to modify it than to try to kludge together your own solution, which probably won't handle edge cases properly.  There are <i>lots</i> of edge cases.</span>
<span class="comment-copy">You could even port <code>dtoa.c</code> to Python, if you like.</span>
<span class="comment-copy">Why so many downvotes (3 at the moment) on this question?</span>
<span class="comment-copy">Mark, great answer (just got around to reading it). Do you have an example where this happens for double-precision (to 16 digits)? (I could check myself but wanted to know if you've done it already.) I'll have to go back and look at the Steele &amp; White, David Gay, etc. papers to see if they talk about this.</span>
<span class="comment-copy">@RickRegan: No, I hadn't checked, but I have now! I count 54 powers of two <code>x</code> within the binary64 normal range for which the closest 16-digit decimal doesn't round to <code>x</code>, but there is nevertheless a 16-digit decimal value which <i>does</i> round to <code>x</code>. Of those 54, 8 have a 15-digit representation, leaving 46 "problem" numbers. The smallest is <code>2**-1017</code>, the largest <code>2**976</code>, and the one with smallest exponent size is <code>2**-24</code>. I did the calculation two different ways (one using fractions, one using Python's float machinery), but independent confirmation would be great.</span>
<span class="comment-copy">I wrote a C program using David Gay's routines that also found 46 cases: smallest negative power: 2^-1017; largest negative power: 2^-24; smallest positive power: 2^89; largest positive power: 2^976. (This was interesting -- thanks.)</span>
<span class="comment-copy">Mark, intuitively I can see why this can only happen for the "middle" digit counts (7, 8 for single and 16 for double), but is there a (simple) proof? It seems that at least a necessary condition is that the decimal gap size around a given power of two be between the binary gap sizes on either side of the power of two.</span>
<span class="comment-copy">@RickRegan: It follows directly from the two roundtrip results (and there's a simple proof of those that works without modification for power-of-two edge cases, but it's a bit long for a comment). For a given float <code>x</code>, we're looking for cases where there's an n-digit decimal that rounds to <code>x</code>, but the <i>closest</i> n-digit decimal doesn't round to <code>x</code>. For 6 digits that can't happen because all 6-digit decimals round to <i>different</i> <code>float</code>s (else roundtripping wouldn't work). For 9 digits it can't happen because the closest 9-digit decimal <i>always</i> rounds to x (from the roundtripping, again).</span>
<span class="comment-copy">Whats not clear from this answer (and the documentation links). is how you would use these functions to perform this operation ensuring significant values supported by 32bit precision would not be lost.</span>
<span class="comment-copy">@ideasman42 true, my answer would fail for numbers that are much larger or smaller than your example.</span>
<span class="comment-copy">I think this can be fixed by calculating the quantize value to give the right number of decimal places of precision - approximately 6 - see <a href="http://stackoverflow.com/questions/10484332/how-to-calculate-decimal-digits-of-precision-based-on-the-number-of-bits" title="how to calculate decimal digits of precision based on the number of bits">stackoverflow.com/questions/10484332/…</a> Note that special handling will be needed for very large numbers, since the floating point imprecision will be before the decimal point.</span>
<span class="comment-copy">Tested and while this works well for small numbers, it fails for <code>4096.2998047</code> for example.</span>
<span class="comment-copy">How would decimal's be applied to this problem? (assuming I already have the data in an array which needs to be represented as strings).</span>
<span class="comment-copy">@ideasman42 you can use <code>quantize()</code> and <code>normalize()</code> methods to achieve that</span>
<span class="comment-copy">@therefromhere's answer shows how this can be used. However it's not reliable and fails for some float values.</span>
<span class="comment-copy">How would you would use this to get a rounded, lower precision float representational?</span>
<span class="comment-copy">Just evaluate the division of these two numbers with the wanted precision (data-type)? I'm not sure anymore if I understand your question: Do you want to round the value as precise as possible (how would you go about it given that you are doing the calculations with the same precision) or do you want an exact representation of your number?</span>
<span class="comment-copy">Updated my question, and added my own answer to show its possible. Your answer looks helpful though it relies on numpy, and I'f rather use vanilla Python if possible.</span>
<span class="comment-copy">Numpy is just to demonstrate different dtypes, in python itself you cannot change it so any difference would be lost. And about your question: With these two numbers you can compare the order of magnitude (let say 1 / 100) to get the first significant digit. If that still does not give you an appropriate answer just comment and I'll delete the question. I think there were a few misunderstandings on my part. :-)</span>
