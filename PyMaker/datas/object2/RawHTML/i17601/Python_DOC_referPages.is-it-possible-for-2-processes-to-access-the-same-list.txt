<div class="post-text" itemprop="text">
<p>Im design a python module that I want to run 2 methods(method1 and method2) in 2 different processes is it possible to have a global list that both processes read and write to? Or will this cause issues later on in my project?</p>
<p>Heres an example: </p>
<pre><code>from multiprocessing import Process, Queue
data =[]

def method1():
  global data
  data += [10,14,5]

def method2():
  global data
  data = [1,3,4]
  proc = Process(target=method1)
  proc.start()
  print data 

if __name__ == '__main__':
  method2()
</code></pre>
<p>This needs to be cross platform, windows, linux and OS X, in Python 2.7. </p>
</div>
<div class="post-text" itemprop="text">
<p>If this needs to be cross-platform, then no, you cannot share a list like this. (On Unix, if you're careful, you sometimes can, but never on Windows.)</p>
<p>If you read <a href="http://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes" rel="nofollow">Sharing state between processes</a> in the documentation, it explains what you can share and how, but basically, it's just simple values, <code>Array</code>s of other shareable types, and anything you can define as a <code>ctypes.Structure</code>, and that's it.</p>
<p>The <a href="http://docs.python.org/3/library/multiprocessing.html#programming-guidelines" rel="nofollow">Programming guidelines</a>, especially the Windows section, explains why this is true, and how you can deal with it. But basically, the problem is that, on Windows, the new process is not a fork of the old one, it's a brand-new process.</p>
<p>There are many alternatives.</p>
<p>The best is usually to redesign your algorithm around passing immutable values to the child and having it return new immutable values, instead of mutating shared values.</p>
<p>If you can't go that far, you can usually rewrite things in terms of passing messages over, e.g., a <code>Queue</code> or a <code>Pipe</code>. In the worst case, the messages can be <code>(list.append, data, [10, 14, 5])</code>, but usually you can come up with something higher-level and more meaningful than that.</p>
</div>
<div class="post-text" itemprop="text">
<p>From help docs:
<a href="http://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes" rel="nofollow">http://docs.python.org/2/library/multiprocessing.html#exchanging-objects-between-processes</a></p>
<pre><code>from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print q.get()    # prints "[42, None, 'hello']"
    p.join()
</code></pre>
<p>You're already importing Queue. Now you just have to use it :)</p>
<p>put adds items, get gets items, from the queue.</p>
</div>
<span class="comment-copy">Do you need this to be cross-platform and guaranteed safe, or just safe for some particular Python implementation and version and platform? (And, if so, which ones?)</span>
<span class="comment-copy">@abarnert See edit.</span>
<span class="comment-copy">You've tagged this with <code>python-multithreading</code> (which "usually refers to <code>threading</code> module"), but you're actually asking about <code>multiprocessing</code>. And the answers are actually different for the two. (With <code>threading</code>, the answer is "You probably shouldn't want to, but if you really want to, you canâ€¦"; with <code>multiprocessing</code>, it's "You definitely shouldn't want to, and you can't either.")</span>
<span class="comment-copy">But adding a list in a queue only allows to retrieve that list once in the other process; I think what the OP wanted is to have a list object that can be accessed and modified from the two processes at the same time.</span>
<span class="comment-copy">Yes i'm currently on track to develop using a queue, but I was wondering if i could do this with a global list.</span>
