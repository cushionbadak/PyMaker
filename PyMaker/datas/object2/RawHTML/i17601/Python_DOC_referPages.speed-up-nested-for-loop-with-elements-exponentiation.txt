<div class="post-text" itemprop="text">
<p>I'm working on a large code and I find myself in the need to speed up a specific bit of it. I've created a <code>MWE</code> shown below:</p>
<pre><code>import numpy as np
import time

def random_data(N):
    # Generate some random data.
    return np.random.uniform(0., 10., N).tolist()

# Lists that contain all the data.
list1 = [random_data(10) for _ in range(1000)]
list2 = [random_data(1000), random_data(1000)]

# Start taking the time.
tik = time.time()

list4 = []
# Loop through all elements in list1.
for elem in list1:

    list3 = []
    # Loop through elements in list2.
    for elem2 in zip(*list2):

        A = np.exp(-0.5*((elem[0]-elem2[0])/elem[3])**2)
        B = np.exp(-0.5*((elem[1]-elem2[1])/elem[3])**2)
        list3.append(A*B)

    # Sum elements in list3 and append result to list4.
    sum_list3 = sum(list3) if sum(list3)&gt;0. else 1e-06
    list4.append(sum_list3)

# Print the elapsed time.
print time.time()-tik
</code></pre>
<p>The weird format of <code>list1</code> and <code>list2</code> is because that's how this block of code receives them.</p>
<p>The obvious part where most of the time is spent is in the recursive calculation of the <code>A</code> and <code>B</code> terms.</p>
<p>Is there any way I could speed up this block of code without having to parallelize it (I've tried it before and it gave me <a href="https://stackoverflow.com/questions/18538790/speed-up-sampling-of-kernel-estimate">a lot of troubles</a>)? I'm open to use any package, <code>numpy</code>, <code>scipy</code>, etc..</p>
<hr/>
<p><strong>Add</strong></p>
<p>This is the result of applying abarnert's optimizations and also Jaime's advise to make only one exponentiation. The optimized function is on average ~60x faster on my system.</p>
<pre><code>import numpy as np
import timeit

def random_data(N):
    return np.random.uniform(0., 10., N).tolist()

# Lists that contain all the data.
list1 = [random_data(10) for _ in range(1000)]
list2 = [random_data(1000), random_data(1000)]

array1 = np.array(list1)
array2 = np.array(zip(*list2))


# Old non-optimezed function.
def func1():
    list4 = []
    # Process all elements in list1.
    for elem in list1:
        # Process all elements in list2.
        list3 = []
        for elem2 in zip(*list2):
            A = np.exp(-0.5*((elem[0]-elem2[0])/elem[3])**2)
            B = np.exp(-0.5*((elem[1]-elem2[1])/elem[3])**2)
            list3.append(A*B)
        # Sum elements in list3 and append result to list4.
        sum_list3 = sum(list3) if sum(list3)&gt;0. else 1e-06
        list4.append(sum_list3)

# New optimized function.
def func2():
    list4 = []
    # Process all elements in list1.
    for elem in array1:

        # Broadcast over elements in array2.
        A = -0.5*((elem[0]-array2[:,0])/elem[3])**2
        B = -0.5*((elem[1]-array2[:,1])/elem[3])**2
        array3 = np.exp(A+B)

        # Sum elements in array3 and append result to list4.
        sum_list3 = max(array3.sum(), 1e-10)
        list4.append(sum_list3)


# Get time for both functions.
func1_time = timeit.timeit(func1, number=10)
func2_time = timeit.timeit(func2, number=10)

# Print hom many times faster func2 is versus func1.
print func1_time/func2_time
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You want to gradually convert this over from using lists and loops to using arrays and broadcasting, grabbing the easiest and/or most time-critical parts first until it's fast enough.</p>
<p>The first step is to not do that <code>zip(*list2)</code> over and over (especially if this is Python 2.x). While we're at it, we might as well store it in an array, and do the same with <code>list1</code>—you can still iterate over them for now. So:</p>
<pre><code>array1 = np.array(list1)
array2 = np.array(zip(*list2))
# …
for elem in array1:
    # …
    for elem2 in array2:
</code></pre>
<p>This won't speed things up much—on my machine, it takes us from 14.1 seconds to 12.9—but it gives us somewhere to start working.</p>
<p>You should also remove the double calculation of <code>sum(list3)</code>:</p>
<pre><code>sum_list3 = sum(list3)
sum_list3 = sum_list3 if sum_list3&gt;0. else 1e-06
</code></pre>
<p>Meanwhile, it's a bit odd that you want <code>value &lt;= 0</code> to go to <code>1e-6</code>, but <code>0 &lt; value &lt; 1e-6</code> to be left alone. Is that really intentional? If not, you can fix that, and simplify the code at the same time, by just doing this:</p>
<pre><code>sum_list3 = max(array3.sum(), 1e-06)
</code></pre>
<p>Now, let's broadcast the <code>A</code> and <code>B</code> calculations:</p>
<pre><code># Broadcast over elements in list2.
A = np.exp(-0.5*((elem[0]-array2[:,0])/elem[3])**2)
B = np.exp(-0.5*((elem[1]-array2[:, 1])/elem[3])**2)
array3 = A*B

# Sum elements in list3 and append result to list4.
sum_list3 = max(array3.sum(), 1e-06)

list4.append(sum_list3)
</code></pre>
<p>And this gets us down from 12.9 seconds to 0.12. You could go a step further by also broadcasting over <code>array1</code>, and replacing <code>list4</code> with a pre-allocated array, and so forth, but this is probably already fast enough.</p>
</div>
<span class="comment-copy">Why is this code all list-based when you have a NumPy dependency right at the top?</span>
<span class="comment-copy">No particular reason, that's just how this code receives <code>list1</code> and <code>list2</code> from another piece of code. About <code>list3</code> and <code>list4</code>, that's the best way I could figure out how to fill them. They can all be converted to numpy arrays if you think that would make a difference.</span>
<span class="comment-copy">@Gabriel: Of course it would make a difference. That's the whole point of using <code>numpy</code>—if you can broadcast a computation over an array, you replace a Python loop with a C loop, and remove all the boxing/unboxing around each arithmetic computation, meaning your code typically gets anywhere from 4-400x faster.</span>
<span class="comment-copy">+1 for posting a good MWE. A great example of putting in the work on asking a question and getting a fantastic answer as a result. Bookmarked so I can link to it in the future.</span>
<span class="comment-copy">One last side note: You shouldn't try to time things yourself using <code>time.time</code>. The <a href="http://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer"><code>timeit</code></a> module (or, if you're using IPython, the <code>%timeit</code> magic statement) makes sure to pick the right timer, takes care of a bunch of issues you wouldn't have even thought up, lets you repeat the tests and summarize them properly, and makes things simpler to boot. (When your code is taking 100x longer than you expected, it's usually not that big a deal, but it's worth getting in the habit of always reaching for <code>timeit</code>.)</span>
<span class="comment-copy">Exponentiation is expensive: instead of taking <code>np.exp</code> twice and then multiply, add the two values together and then take <code>np.exp</code>.</span>
<span class="comment-copy">@Jaime: We've already got a 99% speedup, and I doubt he needs a further 10%. (I estimated that quickly—skipping the <code>exp</code> cuts the time to .79x, so doing one instead of two is probably about .9x.) But I'll bet you could get a whole lot more improvement by moving it out a level (broadcast <code>exp</code> over all the rows at once, then <code>sum</code> all the rows, instead of doing it once per row), so I think if the existing improvement isn't enough, broadcasting over <code>array1</code> and <code>array4</code> should be the first step, then look to optimizing the math within them.</span>
<span class="comment-copy">If you vectorize the full thing that gains you about an extra 20%, which is, I have to agree, negligible over the first 99%. But this is one of my pet peeves, like not taking the square root of a distance if having it squared is enough for what you are doing, I just couldn't resist, sorry for the noise...</span>
<span class="comment-copy">@Jaime: It's not noise; it's worth having additional optimizations in the comments—in case the OP needs them, and also just for the OP to learn from. I was just explaining why I didn't think it needed to go into the answer, it's probably good enough as a comment.</span>
<span class="comment-copy">@Gabriel: People often say that without thinking, but consider this: Is it worth 2 hours of work to speed up your code for, say, a gain of 180 microseconds per run? Do that 10000 times, and you've saved at best a total of negative 3598.2 seconds—and you've increased the chances of it being incorrect, and the amount of time it will take you to debug it (especially if you find the new version harder to understand).</span>
