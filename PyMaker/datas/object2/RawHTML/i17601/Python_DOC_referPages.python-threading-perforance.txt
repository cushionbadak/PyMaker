<div class="post-text" itemprop="text">
<p>I would like to use <code>python</code> <code>multiple threading</code> capability for my app, but had some performance issue (my guess). The site is hosted on <code>GAE</code> and it talks to a <code>REST</code> server based on <code>EC2</code> to do some calculations. The <code>REST</code> server is powered by <code>bottlepy</code>.</p>
<p>My question is:
On the GAE side, I have a loop which calls the REST server multiple times to do the calculation. To improve performance, I use <code>threading</code> library. But I found some of the calculations are missing. Usually, I do not have this issue if only twenty jobs are fired, but I do have this issue when 200 jobs are fired. I appreciate any suggestions.</p>
<p>Here is my code:</p>
<pre><code>def my_function():
    ...
    response = urlfetch.fetch(url=url, payload=data, method=urlfetch.POST, headers=http_headers, deadline=60)

#In this loop, I use the Thread to enable multiple threading
def loop_fun():
    for i in range(100):
        p=Thread(target = my_function)
        all_threads.append(p)
    # Start all threads
    [x.start() for x in all_threads]
    # Wait for all of them to finish
    [x.join() for x in all_threads]
</code></pre>
<p>Below is the error message for one job (usually I receive sever this type error message):</p>
<pre><code>Exception in thread Thread-12:

Traceback (most recent call last):

  File "C:\Program Files (x86)\Google\google_appengine\google\appengine\dist27\threading.py", line 569, in __bootstrap_inner

    self.run()

  File "C:\Program Files (x86)\Google\google_appengine\google\appengine\dist27\threading.py", line 522, in run

    self.__target(*self.__args, **self.__kwargs)

  File "D:\Dropbox\ubertool_src\genee\genee_model.py", line 102, in __init__

    response = urlfetch.fetch(url=url, payload=data, method=urlfetch.POST, headers=http_headers, deadline=60)

  File "C:\Program Files (x86)\Google\google_appengine\google\appengine\api\urlfetch.py", line 270, in fetch

    return rpc.get_result()

  File "C:\Program Files (x86)\Google\google_appengine\google\appengine\api\apiproxy_stub_map.py", line 612, in get_result

    return self.__get_result_hook(self)

  File "C:\Program Files (x86)\Google\google_appengine\google\appengine\api\urlfetch.py", line 403, in _get_fetch_result

    raise DownloadError("Unable to fetch URL: " + url + error_detail)

DownloadError: Unable to fetch URL: http://url_20140122160100678000 Error: [Errno 10061] No connection could be made because the target machine actively refused it
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the problem is one of overload, this problem might benefit from a "pool of workers" strategy.</p>
<pre><code>import threading
import Queue    

def worker( jobs ):
    while True:
        url = jobs.get()
        if url is None:
            break

        # do stuff with the URL


if __name__ == '__main__':
    thread_count = 30

    job_q = Queue.Queue()

    pool = [ threading.Thread(target=worker,args=(job_q,))
             for i in range(thread_count) ]
    for p in pool:
        p.start()

    for url in urls_to_get:
        job_q.put(url)

    # Signal each thread that there are no more jobs.
    for p in pool:
        job_q.put(None)

    for p in pool:
        p.join()
</code></pre>
<p>This way, you can control how many simultaneous requests are taking place by limiting the quantity of threads.</p>
<p>FYI: Python is not really good at threading (depending on the interpreter). Some interpreters have a <a href="http://docs.python.org/3/glossary.html#term-global-interpreter-lock" rel="nofollow">Global Interpreter Lock</a> that prevent multiple threads from running at once. Threading works OK for I/O bound tasks, but not for making efficient use of the CPU. For simultaneity, use <a href="http://docs.python.org/3/library/multiprocessing.html" rel="nofollow">multiprocessing</a>. The changes to my (untested) sample code above would be to use <code>multiprocessing</code> instead of <code>threading</code> and create a <code>Process</code> instead of a <code>Thread</code>.</p>
</div>
<span class="comment-copy">Is it possible that the web server is refusing the connection because it's overloaded? What you've described doesn't sound like a Python/threading problem. You could <code>try:</code> the fetch and complain when an exception occurred. That way, you'd be able to tell how many of the fetch attempts succeeded and how many failed. If some succeed and some fail, the problem is likely not with Python.</span>
<span class="comment-copy">@mojo: That sounds reasonable. I am using bottlepy. Any suggestions on how to find that out?</span>
<span class="comment-copy">@mojo: Thanks. If the bottle neck is on the REST server side, should I reduce the number of tasks fired at a time?</span>
<span class="comment-copy">Have you tried performing these requests using async fetches rather than threads.  I would suggest you might find it simpler and potentially better performing. In your case you are spending all your time waiting on the remote server and async requests will do that fine.</span>
<span class="comment-copy">Thanks for the detailed answer! Is the sequence of <code>job_q.put(url) loop</code> and <code>p.start() loop</code> correct? Sorry, this is my first time using python multiple-threading.</span>
<span class="comment-copy">I always start the (thread/process) listeners before I put jobs in the queue so that any startup overhead takes place while the main thread is preparing the jobs. The order isn't otherwise important.</span>
<span class="comment-copy">Last question. You can have any number of threads and they all process jobs from the same job queue? Also <code>threading.Queue()</code> should be <code>Queue.Queue()</code></span>
<span class="comment-copy">Thanks for pointing out the errors. I wasn't in a position to actually test the code when I wrote it. Yes, any number of threads all use the <i>same</i> queue.</span>
<span class="comment-copy">Sure, but it is <code>import Queue</code>.</span>
