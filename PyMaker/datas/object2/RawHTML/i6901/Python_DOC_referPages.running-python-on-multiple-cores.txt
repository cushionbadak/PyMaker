<div class="post-text" itemprop="text">
<p>I have created a (rather large) program that takes quite a long time to finish, and I started looking into ways to speed up the program.</p>
<p>I found that if I open task manager while the program is running only one core is being used.</p>
<p>After some research, I found this website: 
<a href="https://stackoverflow.com/questions/15639779/why-does-multiprocessing-use-only-a-single-core-after-i-import-numpy">Why does multiprocessing use only a single core after I import numpy?</a> which gives a solution of <code>os.system("taskset -p 0xff %d" % os.getpid())</code>, 
however this doesn't work for me, and my program continues to run on a single core.</p>
<p>I then found this: 
<a href="https://stackoverflow.com/questions/7542957/is-python-capable-of-running-on-multiple-cores">is python capable of running on multiple cores?</a>, 
which pointed towards using multiprocessing.</p>
<p>So after looking into multiprocessing, I came across this documentary on how to use it <a href="https://docs.python.org/3/library/multiprocessing.html#examples" rel="nofollow noreferrer">https://docs.python.org/3/library/multiprocessing.html#examples</a></p>
<p>I tried the code:</p>
<pre><code>from multiprocessing import Process

def f(name):
    print('hello', name)

if __name__ == '__main__':
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()

a = input("Finished")
</code></pre>
<p>After running the code (not in IDLE) It said this: </p>
<pre><code>Finished
hello bob
Finished
</code></pre>
<p>Note: after it said Finished the first time I pressed enter</p>
<p>So after this I am now even more confused and I have two questions</p>
<p>First: It still doesn't run with multiple cores (I have an 8 core Intel i7)</p>
<p>Second: Why does it input "Finished" before its even run the if statement code (and it's not even finished yet!)</p>
</div>
<div class="post-text" itemprop="text">
<p>To answer your second question first, "Finished" is printed to the terminal because <code>a = input("Finished")</code> is outside of your <code>if __name__ == '__main__':</code> code block.  It is thus a module level constant which gets assigned when the module is first loaded and will execute before any code in the module runs.</p>
<p>To answer the first question, you only created one process which you run and then wait to complete before continuing.  This gives you zero benefits of multiprocessing and incurs overhead of creating the new process.</p>
<p>Because you want to create several processes, you need to create a pool via a collection of some sort (e.g. a python list) and then start all of the processes.</p>
<p>In practice, you need to be concerned with more than the number of processors (such as the amount of available memory, the ability to restart workers that crash, etc.).  However, here is a simple example that completes your task above.</p>
<pre><code>import datetime as dt
from multiprocessing import Process, current_process
import sys

def f(name):
    print('{}: hello {} from {}'.format(
        dt.datetime.now(), name, current_process().name))
    sys.stdout.flush()

if __name__ == '__main__':
    worker_count = 8
    worker_pool = []
    for _ in range(worker_count):
        p = Process(target=f, args=('bob',))
        p.start()
        worker_pool.append(p)
    for p in worker_pool:
        p.join()  # Wait for all of the workers to finish.

    # Allow time to view results before program terminates.
    a = input("Finished")  # raw_input(...) in Python 2.
</code></pre>
<p>Also note that if you join workers immediately after starting them, you are waiting for each worker to complete its task before starting the next worker.  This is generally undesirable unless the ordering of the tasks must be sequential.</p>
<p><em>Typically Wrong</em></p>
<pre><code>worker_1.start()
worker_1.join()

worker_2.start()  # Must wait for worker_1 to complete before starting worker_2.
worker_2.join()
</code></pre>
<p><em>Usually Desired</em></p>
<pre><code>worker_1.start()
worker_2.start()  # Start all workers.

worker_1.join()
worker_2.join()   # Wait for all workers to finish.
</code></pre>
<p>For more information, please refer to the following links:</p>
<ul>
<li><a href="https://docs.python.org/3/library/multiprocessing.html" rel="noreferrer">https://docs.python.org/3/library/multiprocessing.html</a></li>
<li><a href="https://stackoverflow.com/questions/20887555/dead-simple-example-of-using-multiprocessing-queue-pool-and-locking">Dead simple example of using Multiprocessing Queue, Pool and Locking</a></li>
<li><a href="https://pymotw.com/2/multiprocessing/basics.html" rel="noreferrer">https://pymotw.com/2/multiprocessing/basics.html</a></li>
<li><a href="https://pymotw.com/2/multiprocessing/communication.html" rel="noreferrer">https://pymotw.com/2/multiprocessing/communication.html</a></li>
<li><a href="https://pymotw.com/2/multiprocessing/mapreduce.html" rel="noreferrer">https://pymotw.com/2/multiprocessing/mapreduce.html</a></li>
</ul>
</div>
<span class="comment-copy">Yes, because you only have a single process, so it will only use a single core.</span>
<span class="comment-copy">Also, are you using <code>numpy</code>? Because then that link doesn't seem relevant.</span>
<span class="comment-copy">So how would I use multiple cores in the situation of having to do lots of multiplying / subtracting in a for statement? e.g. <code>for each in range(1000): a = a*each</code></span>
<span class="comment-copy">How are you testing/verifying that is running on multiple cores?</span>
<span class="comment-copy">@juanpa.arrivillaga no I'm not using numpy but I was saying that it didn't work in my scenario</span>
<span class="comment-copy">Amazing answer. +99999 ;)</span>
