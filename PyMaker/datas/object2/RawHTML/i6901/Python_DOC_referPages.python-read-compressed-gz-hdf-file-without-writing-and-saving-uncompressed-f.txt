<div class="post-text" itemprop="text">
<p>I have a large number of compressed HDF files, which I need to read. </p>
<pre><code>file1.HDF.gz
file2.HDF.gz
file3.HDF.gz
...
</code></pre>
<p>I can read in uncompressed HDF files with the following method</p>
<pre><code>from pyhdf.SD import SD, SDC
import os

os.system('gunzip &lt; file1.HDF.gz &gt;  file1.HDF')
HDF = SD('file1.HDF')
</code></pre>
<p>and repeat this for each file. However, this is more time consuming than I want.</p>
<p>I'm thinking its possible that most of the time overhang comes from writing the compressed file to a new uncompressed version, and that I could speed it up if I simply was able to read an uncompressed version of the file into the <code>SD</code> function in one step.</p>
<p>Am I correct in this thinking? And if so, is there a way to do what I want?</p>
</div>
<div class="post-text" itemprop="text">
<p>According to the pyhdf <a href="http://pysclint.sourceforge.net/pyhdf/pyhdf.SD.html#SD" rel="nofollow noreferrer">package documentation</a>, this is not possible.</p>
<pre><code>__init__(self, path, mode=1)
  SD constructor. Initialize an SD interface on an HDF file,
  creating the file if necessary.
</code></pre>
<p>There is no other way to instantiate an SD object that takes a file-like object. This is likely because they are conforming to an external interface (NCSA HDF). The HDF format also normally handles massive files that are impractical to store in memory at one time.</p>
<p>Unzipping it as a file is likely your most performant option.</p>
<p>If you would like stay in Python, use the gzip module <a href="https://docs.python.org/3/library/gzip.html" rel="nofollow noreferrer">(docs)</a>:</p>
<pre><code>import gzip
import shutil
with gzip.open('file1.HDF.gz', 'wb') as f_in, open('file1.HDF', 'rb') as f_out:
    shutil.copyfileobj(f_in, f_out)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>sascha is correct that hdf transparent compression is more adequate than gzipping, nonetheless if you can't control how the hdf files are stored you're looking for the <code>gzip</code> python modulue <a href="https://docs.python.org/3/library/gzip.html#module-gzip" rel="nofollow noreferrer">(docs)</a> it can get the data from these files.</p>
</div>
<span class="comment-copy">That's awkward. The correct usage would be transparent-compression within hdf (so you don't have to care during writing and reading)! This setup you describe is usable for archival-only (as compression is an extra-layer hdf does not know about). You did not specify your use-case, but in some cases (you want to read many iterations from these): transform each to a new hdf with compression on (or just decompress if memory is not a problem)! <b>Remark</b> python also supports many decompression-tools without your a file-based pipeline.</span>
<span class="comment-copy">One would really have to look at the details of <code>pyhdf</code> to have a good answer here -- one can get a file-like object corresponding to a gzipped stream in Python, but would need to know if a file-like object is good enough or if the pyhdf library requires a real file (or, worse, a filename so it can open the file itself).</span>
<span class="comment-copy">(even if it really does want a filename, one could play tricks with FIFOs <i>if</i> pyhdf doesn't need its input files to be seekable, but again, that's a bit of investigation one would have to do into the details of that library's implementation).</span>
<span class="comment-copy">Can you give me an example of how to use the gzip module in this case?</span>
<span class="comment-copy">@hm8 What's wrong with the official docs?</span>
<span class="comment-copy">An answer is expected to <i>answer the question</i>, not point someone to where they can find an answer. Links should be supplemental, not core to the answer itself.</span>
<span class="comment-copy">More to the point -- if the <code>gzip</code> module returns a file-like object, then the answer is only an acceptable one if the pyhdf library can actually use that object. This is a fact-intensive investigation, and an answer that hasn't had code written presumably hasn't had such investigation performed.</span>
<span class="comment-copy">As @kevin-mcdonough demonstrated above the hdf c api does not make it simple to pass python file-like objects to it and both <code>pydhf</code> and <code>pytables</code> do not allow it at this time. Sorry for not noticing this before posting.</span>
