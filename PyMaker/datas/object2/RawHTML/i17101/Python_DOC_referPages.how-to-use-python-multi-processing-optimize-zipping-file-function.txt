<div class="post-text" itemprop="text">
<p>I got a working function for compressing multiple files into one zip file </p>
<pre><code>targetzipfile = os.path.normpath(targetfolder) + '.zip' 
zipf = zipfile.ZipFile(targetzipfile,'w', zipfile.ZIP_DEFLATED, allowZip64=True)

for root, dirs, files in os.walk(targetfolder):
    for f in files:
        #use relative path zipfile.write(absfilename, archivename), the archive name is the name to be shown in the zip file
        print "compressing: %s" % os.path.join(root,f)
        zipf.write(os.path.join(root,f),os.path.relpath(os.path.join(root,f), os.path.dirname(os.path.normpath(targetfolder)))) #Note here maybe a problem, root/f must 
zipf.close()
</code></pre>
<p>But it is very slow to run since I got lots of file. So I'm looking for a way to optimize this loop with multi-processing capability in python, like OpenMP.</p>
<p>Thanks for any advice.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>import multiprocessing
import time

data = (
    List_of_files
)
targetfolder = "targetFolder"
def mp_worker((inputs, targetfolder)):
    print "compressing: %s" % os.path.join(root,f)
    zipf.write(os.path.join(root,inputs),os.path.relpath(os.path.join(root,inputs), os.path.dirname(os.path.normpath(targetfolder)))) #Note here maybe a problem, root/f must 
zipf.close()
    print " Process %s\tDONE" % inputs

def mp_handler():
    p = multiprocessing.Pool(2)
    p.map(mp_worker, data)

if __name__ == '__main__':
    mp_handler()
</code></pre>
<p>You can refer - <a href="http://pymotw.com/2/multiprocessing/basics.html" rel="nofollow">Python Module of the Week</a></p>
</div>
<div class="post-text" itemprop="text">
<p>I doubt that multiprocessing would help here.</p>
<p><strong>The <code>zipfile</code> module in the Python stdlib is not thread safe!!!</strong></p>
<p>Thus, how shall we optimize your code?</p>
<p><strong>ALWAYS profile before and while performing optimizations.</strong></p>
<p>Because I don't know your file structures. I take the python source code for example.</p>
<pre><code>$ time python singleprocess.py
python singleprocess.py  2.31s user 0.22s system 100% cpu 2.525 total
</code></pre>
<p>Then, let's try the zip command shipped with Ubuntu.(<a href="http://www.info-zip.org/" rel="nofollow">info-zip</a>).</p>
<p>Your can specify the compression level for the zip command. -1 indicates the fastest compression speed (less compression) and -9 indicates the slowest compression speed. The default compression level is -6.</p>
<pre><code>$ time zip python.zip Python-2.7.6 -r -q
zip python.zip Python-2.7.6 -r -q  2.02s user 0.11s system 99% cpu 2.130 total

$ time zip python.zip Python-2.7.6 -r -q  -1
zip python.zip Python-2.7.6 -r -q -1  1.00s user 0.11s system 99% cpu 1.114 total

$ time zip python.zip Python-2.7.6 -r -q  -9
zip python.zip Python-2.7.6 -r -q -9  4.92s user 0.11s system 99% cpu 5.034 total
</code></pre>
<p>You see, the performance of python's zlib module is very competitive. But there are some professional zip tools could give you more control on the compression strategy.</p>
<p>You can call those external command with the subprocess modules in python.</p>
<p>Besides, when you use the python code above to zip a directory, You'll lose the metadata (permission bits, last access time, last modification time ...)of the directory and its subdirectories.</p>
</div>
<span class="comment-copy"><code>multiprocessing.Pool</code> should do what you're looking for. Read about it <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">here</a></span>
<span class="comment-copy">Thanks!!! I'll try it now.</span>
<span class="comment-copy">Why down vote? ?</span>
<span class="comment-copy">@tomriddle_1234 This answer is totally misleading. zipfile module is not thread safe. Besides, there are too many logic errors in this answer.</span>
