<div class="post-text" itemprop="text">
<p>I have a function to simultaneously retrieve the min and max values of a list:</p>
<pre><code>def min_max(iterable, key=None):
    """Retrieve the min and max values of `iterable` simultaneously."""
    if key is None: key = lambda x: x
    if not iterable:
        return None, None
    min_ = max_ = key(iterable[0])
    for i in iterable[1:]:
        if key(i) &gt; key(max_): max_ = i
        if key(i) &lt; key(min_): min_ = i
    return min_, max_
</code></pre>
<p>But it got me wondering, since I do two comparisons in the for loop anyways, would it not be faster to simply use <code>min</code> and <code>max</code> separately? If it is, how could I edit this function to make it more efficient?</p>
</div>
<div class="post-text" itemprop="text">
<p>The expensive part in finding out the minimum or maximum value in a list is not the comparison. Comparing values is pretty fast, and won’t make a problem here. Instead, what impacts the run time is the loop.</p>
<p>When you are using <code>min()</code> or <code>max()</code>, then each of those will have to iterate over the iterable once. They do that separately, so when you need both the minimum and the maximum value, by using the built-in functions, you are iterating twice.</p>
<p>Your function just iterates once over it, so its theoretical run time is shorter. Now as chepter mentioned in the comments, <code>min</code> and <code>max</code> are implemented <a href="http://hg.python.org/cpython/file/95d8ca61cdbf/Python/bltinmodule.c#l1321" rel="nofollow">in native code</a>, so they are most certainly faster than when implementing it in Python code yourself.</p>
<p>Now, it depends a lot on your iterable whether the two native loops will be faster than your Python function. For longer lists, where iterating it is already expensive, iterating it once will definitely be better, but for shorter ones, you probably get better results with the native code. I can’t tell where the exact threshold is, but you can easily test out for your actual data what’s faster. In most cases though, it rarely matters as a min/max won’t be the bottleneck of your application, so you just shouldn’t worry about it until it becomes a problem.</p>
<hr/>
<p>Btw. your implementation has a few problems right now, which you should fix if you want to use it:</p>
<ul>
<li>It requires <code>iterable</code> to be a <em>sequence</em>, and not an <em>iterable</em> (as you use indexes on it)</li>
<li>You also require it to have at least one item—which technically isn’t required either. While you do check for <code>not iterable</code>, that won’t necessarily tell you something about the length of the sequence/iterable. Custom types can easily provide their own boolean value and/or sequence behavior.</li>
<li>Finally, you initialize your <code>_min</code> and <code>_max</code> with the keyed values of the iterable item, but later you (correctly) just assign the original item from the iterable.</li>
</ul>
<p>So I would suggest you to use iterators instead, and fix that key thing—you can also store the key results to save some computation for more complex key functions:</p>
<pre><code>it = iter(iterable)
try:
    min_ = max_ = next(it)
    minv = maxv = key(min_)
except StopIteration:
    return None, None

for i in it:
    k = key(i)
    if k &gt; maxv:
        max_, maxv = i, k
    elif k &lt; minv:
        min_, minv = i, k
</code></pre>
<hr/>
<p>I did some testing on this, and it turns out that—without a custom key function—using the built-in max/min is kind-of impossible to beat. Even for very large lists, the purce C implementation is just way too fast. However, as soon as you add in a key function (which is written in Python code), the situation is completely reversed. With a key function, you get pretty much the same timing result for a single <code>min</code> or <code>max</code> call as for the full function doing both. So using the solution written in Python is <em>a lot</em> faster.</p>
<p>So this lead to the idea that, maybe, the implementation in Python wasn’t the actual problem, but instead the <code>key</code> function that is used. And indeed, the actual key function is what makes the Python implementation expensive. And it makes a lot of sense too. Even with an identity-lamba, you still have the overhead of function calls; <code>len(iterable)</code> many function calls (with my optimized variant above). And function calls are quite expensive.</p>
<p>In my tests, with support for the key function taken out, the <em>actually expected</em> results appeared: Iterating just once is faster than twice. But for non very-large iterables, the difference is really small. So unless iterating the iterable is very expensive (although you could then use <a href="http://docs.python.org/3/library/itertools.html#itertools.tee" rel="nofollow"><code>tee</code></a> and still iterate twice) or you want to loop over it anyway (in which case you would combine that with the min/max check), using the built-in <code>max()</code> and <code>min()</code> functions separately will be faster and also a lot easier to use. And, they both come with the internal optimization that they skip key functions if you don’t specify one.</p>
<p>Finally though, how could you add that key function optimization into your code? Well, unfortunately, there’s only one way to do this and that involves duplicating code. You essentially have to check whether or not a key function is specified and skip the function call when it wasn’t. So, something like this:</p>
<pre><code>def min_max(iterable, key=None):
    if key:
        # do it with a key function
    else:
        # do it without
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Please check here:</p>
<p>This is not exactly what you are looking but, I can reduce the loop:</p>
<pre><code>def min_max(iterable):
    if not iterable:
        raise Exception('Required iterable object')
    _min = _max = iterable[0]
    ind = 0
    if len(iterable) &amp; 1:
        ind = 1
    for elm in iterable[1::2]:
        ind += 2
        try:
            if iterable[ind] &lt; iterable[ind + 1]:
                if _min &gt; iterable[ind]:
                    _min = iterable[ind]
                if _max &lt; iterable[ind + 1]:
                    _max = iterable[ind + 1]
            else:
                if _min &gt; iterable[ind + 1]:
                    _min = iterable[ind + 1]
                if _max &lt; iterable[ind]:
                    _max = iterable[ind]
        except:
            pass
    return _min, _max

print min_max([11,2,3,5,0,1000,14,5,100,1,999])
</code></pre>
<p>Output:</p>
<pre><code>(0, 1000)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>use this code:</p>
<pre><code>for i in iterable[1:]:
    if key(i) &gt; key(max_): 
        max_ = i
    elif key(i) &lt; key(min_):
        min_ = i
</code></pre>
</div>
<span class="comment-copy">You're assuming that <code>iterable</code> has at least one key in it. Else this will die on the <code>min_ = max_...</code> call.</span>
<span class="comment-copy">Why are you accessing the values with a function which simply returns its parameter?</span>
<span class="comment-copy">The trade off is between one pass over the list at the Python level versus two passes at the C level. Which approach is faster probably depends on the length of the list, but I suspect the latter will be faster for all but extremely large lists. Profile it and see.</span>
<span class="comment-copy">Couldn't you make the second check for min an <code>elif</code>?</span>
<span class="comment-copy">A one-pass algorithm could have the considerable advantage of working for arbitrary iterables, but the use of <code>iterable[0]</code> and <code>iterable[1:]</code> negates that.</span>
<span class="comment-copy">Why the downvote?</span>
<span class="comment-copy">I'm not the downvoter, but I wanted to point out that the idea that iterating just once should be faster for longer lists than iterating twice is misleading. Both algorithms being considered are <code>O(N)</code>, so their relative speeds should stay the same regardless of the size of the input. This might only be true once the input is fairly large (to get past any constant overheads that may differ), but going from say 10000 items to 1000000 items should not make a big difference in their relative performance.</span>
<span class="comment-copy">@Blckknght Sure, they are considered equal in O-notation, but they still have a different execution time which often matters when you’re optimizing your code. If you compute the minimum and maximum over and over in your application, then you likely want to micro-optimize this a bit and choose the one that’s faster even if both are <code>O(n)</code>. And if you read my answer, you will see that, while I point out the differences, I actually suggest using the individual functions anyway because micro-optimization is often just not necessary.</span>
<span class="comment-copy">-1; doesn’t answer the question. Also not sure what you are even doing there…</span>
<span class="comment-copy">Ok i was providing a better solution, i will remove it if the owner doesn't like. I am reducing the number of loop to n/2,</span>
<span class="comment-copy">@user3398620 let me know if you don't like :) i will remove it.</span>
<span class="comment-copy">Well, I can always do loop unrolling to remove iterations; that won’t change the complexity though (I would argue that it makes your function even more complex). Also, your solution does not support a key function, and also builds on sequences not iterables (even more so than OP).</span>
<span class="comment-copy">Ok thank you for the suggestion.</span>
<span class="comment-copy">-1; doesn’t answer the question.</span>
