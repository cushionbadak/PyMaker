<div class="post-text" itemprop="text">
<pre><code>item_list = [("a", 10, 20), ("b", 25, 40), ("c", 40, 100), ("d", 45, 90),
             ("e", 35, 65), ("f", 50, 110)] #weight/value
results = [("", 0, 0)]  #an empty string and a 2-tupel to compare with the new
                        #values

class Rucksack(object):
    def __init__(self, B):
        self.B = B   #B=maximum weight
        self.pack(item_list, 0, ("", 0, 0))

    def pack(self, items, n, current):  
        n += 1   #n is incremented, to stop the recursion, if all
        if n &gt;= len(items) - 1:
            if current[2] &gt; results[0][2]:
                #substitutes the result, if current is bigger and starts no
                #new recursion
                results[0] = current
        else:
            for i in items:
                if current[1] + i[1] &lt;= self.B and i[0] not in current[0]:
                    #first condition: current + the new value is not bigger
                    #than B; 2nd condition: the new value is not the same as
                    #current
                    i = (current[0] + " " + i[0], current[1] + i[1],
                         current[2] + i[2])
                    self.pack(items, n, i)
                else:
                    #substitutes the result, if current is bigger and starts no
                    #new recursion
                    if current[2] &gt; results[0][2]:
                        results[0] = current
</code></pre>
<p>rucksack1 = Rucksack(100)</p>
<p>This is a small algo for the knapsack-problem. I have to parallelize the code somehow, but I don't get the thread module so far. I think the only place to work with parallelisation is the for-loop, right? So, I tried this:</p>
<pre><code>def run(self, items, i, n, current):
    global num_threads, thread_started
    lock.acquire()
    num_threads += 1
    thread_started = True
    lock.release()
    if current[1] + i[1] &lt;= self.B and i[0] not in current[0]:
        i = (current[0] + " " + i[0], current[1] + i[1], current[2] + i[2])
        self.pack(items, n, i)
    else:
        if current[2] &gt; results[0][2]:
            results[0] = current
    lock.acquire()
    num_threads -= 1
    lock.release() 
</code></pre>
<p>but the results are strange. Nothing happens and if I make a keyboardinterrupt, the result is correct, but thats definetly not the sense of the implementation. Can you tell me what is wrong with the second code or where else I could use perallelisation soundly. Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>First, since your code is CPU-bound, you will get very little benefit from using threads for parallelism, because of the <a href="http://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">GIL</a>, as bereal explains. Fortunately, there are only a few differences between threads and processes—basically, all shared data must be passed or shared explicitly (see <a href="http://docs.python.org/2/library/multiprocessing.html#sharing-state-between-processes" rel="nofollow">Sharing state between processes</a> for details).</p>
<p>Second, if you want to data-parallelize your code, you have to lock all access to mutable shared objects. From a quick glance, while <code>items</code> and <code>current</code> look immutable, the <code>results</code> object is a shared global that you modify all over the place. If you can change your code to return a value up the chain, that's ideal. If not, if you can accumulate a bunch of separate return values and merge them after processing is finished, that's usually good too. If neither is feasible, you will need to guard all access to <code>results</code> with a lock. See <a href="http://docs.python.org/2/library/multiprocessing.html#synchronization-between-processes" rel="nofollow">Synchronization between processes</a> for details.</p>
<p>Finally, you ask where to put the parallelism. The key is to find the right dividing line between independent tasks.</p>
<p>Ideally you want to find a large number of mid-sized jobs that you can queue up, and just have a pool of processes each picking up the next one. From a quick glance, the obvious places to do that are either at the recursive call to <code>self.pack</code>, or at each iteration of the <code>for i in items:</code> loop. If they actually are independent, just use <a href="http://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor-example" rel="nofollow"><code>concurrent.futures</code></a>, as in the <a href="http://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor-example" rel="nofollow"><code>ProcessPollExecutor</code> example</a>. (If you're on Python 3.1 or earlier, you need the <a href="http://pypi.python.org/pypi/futures" rel="nofollow"><code>futures</code></a> module, because it's not built into the stdlib.)</p>
<p>If there's no easy way to do this, often it's at least possible to create a small number (N or 2N, if you have N cores) of long-running jobs of about equal size, and just give each one its own <a href="http://docs.python.org/2/library/multiprocessing.html#the-process-class" rel="nofollow"><code>multiprocessing.Process</code></a>. For example:</p>
<pre><code>n = 8
procs = [Process(target=rucksack.pack, args=(items[i//n:(i+1)//n],)) for i in range(n)]
</code></pre>
<p>One last note: If you finish your code and it looks like you've gotten away with implicitly sharing globals, what you've actually done is written code that usually-but-not-always works on some platforms, and never on others. See the <a href="http://docs.python.org/2/library/multiprocessing.html#windows" rel="nofollow">Windows</a> section of the <code>multiprocessing</code> docs to see what to avoid—and, if possible, test regularly on Windows, because it's the most restrictive platform.</p>
<hr/>
<p>You also ask a second question:</p>
<blockquote>
<p>Can you tell me what is wrong with the second code.</p>
</blockquote>
<p>It's not entirely clear what you were trying to do here, but there are a few obvious problems (beyond what's mentioned above).</p>
<ul>
<li>You don't create a thread anywhere in the code you showed us. Just creating variables with "thread" in the name doesn't give you parallelism. And neither does adding locks—if you don't have any threads, all locks can do is slow you down for no reason.</li>
<li>From your description, it sounds like you were trying to use the <code>thread</code> module, instead of <code>threading</code>. There's a reason that the very top of the <code>thread</code> documentation tells you to not use it and use <code>threading</code> instead.</li>
<li>You have a lock protecting your thread count (which shouldn't be needed at all), but no lock protecting your <code>results</code>. You will get away with this in most cases in Python (because of the same GIL issue mentioned above—your threads are basically not going to run concurrently, and therefore they're not going to have races), but it's still a very bad idea (especially if you don't understand exactly what those "most cases" are).</li>
</ul>
<p>However, it looks like your <code>run</code> function is based on the body of the <code>for i in items:</code> loop in <code>pack</code>. If that's a good place to parallelize, you're in luck, because creating a parallel task out of each iteration of a loop is exactly what <code>futures</code> and <code>multiprocessing</code> are best at. For example, this code:</p>
<pre><code>results = []
for i in items:
    result = dostuff(i)
    results.append(result)
</code></pre>
<p>… can, of course, be written as:</p>
<pre><code>results = map(dostuff, items)
</code></pre>
<p>And it can be trivially parallelized, without even having to understand what futures are about, as:</p>
<pre><code>pool = concurrent.futures.ProcessPoolExecutor()
results = pool.map(dostuff, items)
</code></pre>
</div>
<span class="comment-copy">It makes absolutely no sense to parallelize a CPU-bound task with threads in Python, due to <a href="http://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow noreferrer">GIL</a>.</span>
<span class="comment-copy">First, are you actually using the <code>thread</code> module? If so, don't, use <code>threading</code> instead, as the very top of the <a href="http://docs.python.org/2/library/thread.html" rel="nofollow noreferrer">docs</a> tells you to. But, more importantly, you're not creating any threads here. Just adding locks to single-threaded code just makes slower single-threaded code for no benefit.</span>
<span class="comment-copy">+1 for @bereal comment, plus I can't be bothered to look at wall-of-gunge array code with i,n,etc. indexes.</span>
