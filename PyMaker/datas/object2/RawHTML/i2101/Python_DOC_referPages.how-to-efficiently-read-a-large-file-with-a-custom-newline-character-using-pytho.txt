<div class="post-text" itemprop="text">
<p>We have a huge <code>.csv</code> file but it doesn't seem to really be a csv.</p>
<p>The line endings are <code>\tl\n</code>.<br/>
The text between this newline character sometimes has "real" newline characters. We don't want to split on those.</p>
<p>We currently do it using <code>awk</code>.  </p>
<pre><code>awk_code = r'BEGIN{ RS="""(\tl\n)"""; FS="\t"} { print "\42"$1"\42,\42"$2"\42,\42\42\42"$3"\42\42\42,\n";}'
bash_command_awk = f"awk '{awk_code}' {input_file_path} &gt; {output_path}"
awk_command_output = subprocess.check_output(bash_command_awk,stderr=subprocess.STDOUT, shell=True)
</code></pre>
<p>I'm trying to find an efficient way of doing it directly in Python and tried passing a custom newline into the <code>.open()</code> command.  </p>
<pre><code>def process_without_putting_file_in_RAM(file_to_process):
    with file_to_process.open(encoding="utf-8", newline="\tl\n") as csv_file:
        for line in csv.reader(csv_file):
</code></pre>
<p>However, I quickly learned newline arg only accepts one of the default characters.</p>
<p>How can I efficiently process this file containing the weird line ending?</p>
</div>
<div class="post-text" itemprop="text">
<p>Here's a function which can handle multi-character newline between chunks correctly</p>
<pre><code>def line_splitter(file, newline, chunk_size=4096):
    tail = ''
    while True:
        chunk = file.read(chunk_size)
        if not chunk:
            if tail:
                yield tail
            break
        lines = (tail + chunk).split(newline)
        tail = lines.pop(0)
        if lines:
            yield tail
            tail = lines.pop()
            yield from lines
</code></pre>
<p>another version which, although it doesn't make copies of whole chunks didn't prove faster. It will be marginally faster for large chunks. Do not use chunk_size less than newline size :)</p>
<pre><code>def line_splitter(file, newline, chunk_size=4096):
    tail = ''
    while True:
        chunk = file.read(chunk_size)
        if not chunk:
            if tail:
                yield tail
            break
        lines = chunk.split(newline)
        tail = (tail + lines[0]).split(newline)
        if len(tail) &gt; 1:
            lines[0] = tail[1]
        else:
            del lines[0]
        tail = tail[0]
        if lines:
            yield tail
            tail = lines.pop()
            yield from lines
</code></pre>
<p>The caller should be like:</p>
<pre><code>with longabstract_file.open() as f:
    for line in line_splitter(f, "\tl\n"):
        if line: # ignore blank lines
            print(line)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming your csv is a comma or space delimited, not tab, what you were looking for is <a href="https://docs.python.org/3/library/csv.html#csv.Dialect.lineterminator" rel="nofollow noreferrer"><code>lineterminator</code> flag</a>, but there's no need for that since it's automatically assumed <code>'\n'</code> is a line break. From the doc:</p>
<blockquote>
<p>Note: The reader is hard-coded to recognise either <code>'\r'</code> or <code>'\n'</code> as
  end-of-line, and ignores <code>lineterminator</code>. This behavior may change in
  the future.</p>
</blockquote>
<p>so what you can do is add string method <code>.replace()</code> to get rid of <code>'\tl'</code> like this</p>
<pre><code>def process_without_putting_file_in_RAM(file_to_process):
    with file_to_process.open(encoding="utf-8") as csv_file:
        for line in csv.reader(csv_file, delimiter=","):
            print(line[-1].replace('\tl', ''))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Why not use <code>pandas</code>. Specifically <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" rel="nofollow noreferrer"><code>pandas.read_csv</code></a> using <code>lineterminator</code> and <code>chunksize</code> parameters:</p>
<pre><code>import pandas as pd

batch_size = 10000
new_line_str = '\tl\n'
iterator_df = pd.read_csv(file_to_process, chunksize=batch_size, lineterminator=new_line_str)
for chunk in iterator_df:
    # process chunk here
</code></pre>
</div>
<span class="comment-copy">Any reason why you just can't ignore the last column?</span>
<span class="comment-copy">Hi Keith. I'm not sure I understand the question. Are you talking about the <code>awk</code> code? I only understand the lineterminator and linebreak sections.  I haven't even paid attention to the rest yet.</span>
<span class="comment-copy">Sorry I was assuming the file is tab delimited. Any reason why you just can't the ignore last two characters in the line as it's read in? line[:-2]</span>
<span class="comment-copy">Thanks @panda-34. I'm going to test these and get back to you. For now I removed the checkmark from my answer.</span>
<span class="comment-copy">Thanks again @panda-34 for catching the bug. You first solution is great. This is now the accepted answer. ðŸŽ‰</span>
<span class="comment-copy">For anyone following along I deleted my original, buggy, answer.</span>
<span class="comment-copy">Thanks @cryptonome.  That made sense for the question as posted.  I added some new information regarding the fact that "real" line terminators may be found inside the custom line terminator.  We don't want to split on those.</span>
<span class="comment-copy">in principle that <code>replace('\tl\n', '\n')</code> method can be used on lines with a file handler instead of list generated by the <code>csv.reader</code>, and to make it more efficient, use a generator (most probably already is a generator). <i>but</i>, depending on how big the file is (or how much files to process), i'd say awk will be faster than pure python. i'll see if i can test a 600+ MB csv later, but you'd want to do your own test on awk timing &amp; include in your post.</span>
<span class="comment-copy">I get an error <code>Only 1-length line terminators supported</code>.</span>
