<div class="post-text" itemprop="text">
<p>I am trying to calculate the std in a non-vectorized and semi-vectorized way. 
the code for non-vectorized version works well, the semi-vectorized version works as well but the results they generate are not the same.<br/>
this is the version 1 :   </p>
<pre><code>import math
#unvectorized version --really slow!
def calc_std_classic(a):
    batch = a.shape[0]
    channel = a.shape[1]
    width = a.shape[2]
    height = a.shape[3]
    mean = calc_mean_classic2(data_train)

    sum = np.zeros((channel))
    for i in range(batch):
        for j in range(channel):
            for w in range(width):
                for h in range(height):
                    sum[j] += (abs(a[i,j,w,h] - mean[j])**2)

    var = (sum/(width*height*batch))
    return [(math.sqrt(x)) for x in var ]
</code></pre>
<p>semi-vectorized :</p>
<pre><code>def calc_std_classic2(a):
    batch = a.shape[0]
    channel = a.shape[1]
    width = a.shape[2]
    height = a.shape[3]
    mean = calc_mean_classic2(data_train)

    sum = np.zeros((channel))
    for i in range(batch):
        for j in range(channel):
            sum[j] += np.sum(abs(a[i,j,:,:] - mean[j])**2)

    var = (sum/(width*height*batch))
    return [(math.sqrt(x)) for x in var ]
</code></pre>
<p>and this is the method for calculating mean if its needed :</p>
<pre><code>def calc_mean_classic2(a):
    #sum all elements in each channel and divide by the number of elements
    batch = a.shape[0]
    channel = a.shape[1]
    width = a.shape[2]
    height = a.shape[3]

    sum = np.zeros((channel))
    for i in range(batch):
        for j in range(channel):
            sum[j] += np.sum(a[i,j,:,:])

    return (sum/(width*height*batch))   
</code></pre>
<p>the output generated using pythons numpy.std() and the two method is as follows:</p>
<pre><code>std = np.std(data_train, axis=(0,2,3))
std2 = calc_std_classic(data_train)
std3 = calc_std_classic2(data_train)
</code></pre>
<p>generates : </p>
<pre><code>std = [ 62.99321928  62.08870764  66.70489964]
std2 = [62.99321927774396, 62.08870764038716, 66.7048996406483]
std3 = [62.99321927813685, 62.088707640014405, 66.70489964063101]
</code></pre>
<p>As you can see, all three generate the same result up to 8 digits. but the 3rd method has different remaining digits. </p>
<p>What am I doing wrong here? </p>
</div>
<div class="post-text" itemprop="text">
<p>There are lots of good ressources on floating point arithmetic error propagation. But one immediate problem is that <code>numpy.ndarray</code> display floats to a different precision that python <code>float</code>s. So to compare your results you should convert to an identical data structure (for example <code>list</code>s):</p>
<pre><code>&gt;&gt;&gt; print(np.std(arr, ....))
[ 0.28921072  0.2898092   0.28961785]
&gt;&gt;&gt; print(np.std(arr, ....).tolist())
[0.28921072085015914, 0.28980920065339233, 0.28961784922639483]
</code></pre>
<hr/>
<p>In your explicit case:</p>
<p>The difference between <code>calc_std_classic</code> and <code>calc_std_classic2</code> is because one uses naive summation <code>a1+a2+....+an</code> while the other uses <code>np.sum</code>. The <code>np.sum</code> could be naive summation but as far as I know it uses <a href="https://en.wikipedia.org/wiki/Pairwise_summation" rel="nofollow noreferrer"><em>pairwise summation</em></a>. If you want even higher accuracy you could implement <a href="https://en.wikipedia.org/wiki/Kahan_summation_algorithm" rel="nofollow noreferrer">Kahan summation</a> or use the python-builtin <a href="https://github.com/python/cpython/blob/403ccddb9598bac6e0e6db4ba5aa2fe494512a98/Lib/statistics.py#L106" rel="nofollow noreferrer"><code>statistics._sum</code></a>.</p>
<p>The difference between <code>np.std</code> and your variants is harder to explain because I don't know what algorithm is used by <code>numpy</code>. There is a whole <a href="https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance" rel="nofollow noreferrer">article about "Algorithms for calculating variance" on wikipedia</a>. Note that any naive implementation may suffer from under-/overflow issues especially because of the <code>item - mean</code> subtraction.</p>
<hr/>
<p>A general advice: </p>
<p>If you want it fast then use <code>numpy</code>, if you want it with highest precision then use <a href="https://docs.python.org/3/library/statistics.html" rel="nofollow noreferrer"><code>statistics</code></a>. NumPy mostly focusses on the performance aspect so they <em>might not</em> implement the most accurate algorithm. Avoid any naive implementations without doing research on the algorithm, because they probably are neither accurate nor fast.</p>
</div>
<span class="comment-copy">Perhaps numpy uses a more stable sum algorithm.</span>
<span class="comment-copy">@WillemVanOnsem: is that all?  Is the procedure I'm doing correct?</span>
<span class="comment-copy">Down vote?!! Why would someone downvote this question?!! whats wrong with it ?</span>
<span class="comment-copy">Well floating point operations are approximative and the "<i>naive</i>" sum algorithm can definitely be improved. Some high quality summation algorithms use an additional floating point to store leftovers and add them in the end. I did not downvote btw.</span>
<span class="comment-copy">Thanks alot, so this really boils down to  the summation and nothing else?! I thought the + operator is used in numpy.sum as well, and nothing else is done thus the result should be the same. by the way is there a way to check the numpy.sum implementation and see what else it is doing ?</span>
<span class="comment-copy">Thank you very much, I really appreciate your nice answer :)</span>
