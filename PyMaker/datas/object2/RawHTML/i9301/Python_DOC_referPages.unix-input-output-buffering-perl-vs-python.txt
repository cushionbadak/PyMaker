<div class="post-text" itemprop="text">
<p>I'm running memcached with the following bash command pattern:</p>
<pre><code>memcached -vv 2&gt;&amp;1 | tee memkeywatch2010098.log 2&gt;&amp;1 | ~/bin/memtracer.py | tee memkeywatchCounts20100908.log
</code></pre>
<p>to try and track down unmatched gets to sets for keys platform wide.</p>
<p>The memtracer script is below and works as desired, with one minor issue.  Watching the intermediate log file size, memtracer.py doesn't start getting input until memkeywatchYMD.log
is about 15-18K in size.  Is there a better way to read in stdin or perhaps a way to cut the buffer size down to under 1k for faster response times?</p>
<pre><code>#!/usr/bin/python

import sys
from collections import defaultdict

if __name__ == "__main__":


    keys = defaultdict(int)
    GET = 1
    SET = 2
    CLIENT = 1
    SERVER = 2

    #if &lt;
    for line in sys.stdin:
        key = None
        components = line.strip().split(" ")
        #newConn = components[0][1:3]
        direction = CLIENT if components[0].startswith("&lt;") else SERVER

        #if lastConn != newConn:        
        #    lastConn = newConn

        if direction == CLIENT:            
            command = SET if components[1] == "set" else GET
            key = components[2]
            if command == SET:                
                keys[key] -= 1                                                                                    
        elif direction == SERVER:
            command = components[1]
            if command == "sending":
                key = components[3] 
                keys[key] += 1

        if key != None:
            print "%s:%s" % ( key, keys[key], )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can completely remove buffering from stdin/stdout by using python's <code>-u</code> flag:</p>
<pre class="lang-none prettyprint-override"><code>-u     : unbuffered binary stdout and stderr (also PYTHONUNBUFFERED=x)
         see man page for details on internal buffering relating to '-u'
</code></pre>
<p>and the man page clarifies:</p>
<pre class="lang-none prettyprint-override"><code>   -u     Force stdin, stdout and stderr to  be  totally  unbuffered.   On
          systems  where  it matters, also put stdin, stdout and stderr in
          binary mode.  Note that there is internal  buffering  in  xread-
          lines(),  readlines()  and  file-object  iterators ("for line in
          sys.stdin") which is not influenced by  this  option.   To  work
          around  this, you will want to use "sys.stdin.readline()" inside
          a "while 1:" loop.
</code></pre>
<p>Beyond this, altering the buffering for an existing file is not supported, but you <em>can</em> make a new file object with the same underlying file descriptor as an existing one, and possibly different buffering, using <a href="http://docs.python.org/library/os.html?highlight=fdopen#os.fdopen" rel="noreferrer">os.fdopen</a>.  I.e.,</p>
<pre><code>import os
import sys
newin = os.fdopen(sys.stdin.fileno(), 'r', 100)
</code></pre>
<p><em>should</em> bind <code>newin</code> to the name of a file object that reads the same FD as standard input, but buffered by only about 100 bytes at a time (and you could continue with <code>sys.stdin = newin</code> to use the new file object as standard input from there onwards).  I say "should" because this area <em>used</em> to have a number of bugs and issues on some platforms (it's pretty hard functionality to provide cross-platform with full generality) -- I'm not sure what its state is now, but I'd definitely recommend thorough testing on all platforms of interest to ensure that everything goes smoothly.  (<code>-u</code>, removing buffering entirely, should work with fewer problems across all platforms, if that might meet your requirements).</p>
</div>
<div class="post-text" itemprop="text">
<p>You can simply use <code>sys.stdin.readline()</code> instead of <code>sys.stdin.__iter__()</code>:</p>
<pre><code>import sys

while True:
    line = sys.stdin.readline()
    if not line: break # EOF

    sys.stdout.write('&gt; ' + line.upper())
</code></pre>
<p>This gives me line-buffered reads using Python 2.7.4 and Python 3.3.1 on Ubuntu 13.04.</p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>sys.stdin.__iter__</code> still being line-buffered, one can have an iterator that behaves mostly identically (stops at EOF, whereas <code>stdin.__iter__</code> won't) by using <a href="https://docs.python.org/2/library/functions.html#iter">the 2-argument form of <code>iter</code></a> to make an iterator of <code>sys.stdin.readline</code>:</p>
<pre><code>import sys

for line in iter(sys.stdin.readline, ''):
    sys.stdout.write('&gt; ' + line.upper())
</code></pre>
<p>Or provide <code>None</code> as the sentinel (but note that then you need to handle the EOF condition yourself).</p>
</div>
<div class="post-text" itemprop="text">
<p>This worked for me in Python 3.4.3:</p>
<pre><code>import os
import sys

unbuffered_stdin = os.fdopen(sys.stdin.fileno(), 'rb', buffering=0)
</code></pre>
<p>The <a href="https://docs.python.org/3/library/os.html#os.fdopen" rel="nofollow">documentation for <code>fdopen()</code></a> says it is just an alias for <code>open()</code>.</p>
<p><a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow"><code>open()</code></a> has an optional <code>buffering</code> parameter:</p>
<blockquote>
<p><em>buffering</em> is an optional integer used to set the buffering policy. Pass 0 to switch buffering off (only allowed in binary mode), 1 to select line buffering (only usable in text mode), and an integer &gt; 1 to indicate the size in bytes of a fixed-size chunk buffer. </p>
</blockquote>
<p>In other words:</p>
<ul>
<li><strong>Fully unbuffered</strong> stdin requires <strong>binary</strong> mode and passing zero as the buffer size.</li>
<li><strong>Line-buffering</strong> requires <strong>text</strong> mode.</li>
<li>Any other buffer size seems to work in both <em>binary</em> and <em>text</em> modes (according to the documentation).</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>The only way I could do it with python 2.7 was:</p>
<pre><code>tty.setcbreak(sys.stdin.fileno())
</code></pre>
<p>from <a href="https://stackoverflow.com/questions/2408560/python-nonblocking-console-input/2409034#2409034">Python nonblocking console input</a> . This completly disable the buffering and also suppress the echo.</p>
<p>EDIT: Regarding Alex's answer, the first proposition (invoking python with <code>-u</code>) is not possible in my case (see <a href="https://stackoverflow.com/questions/16549357/is-it-possible-to-include-command-line-options-in-the-python-shebang">shebang limitation</a>).</p>
<p>The second proposition (duplicating fd with smaller buffer: <code>os.fdopen(sys.stdin.fileno(), 'r', 100)</code>) is not working when I use a buffer of 0 or 1, as it is for an interactive input and I need every character pressed to be processed immediatly.</p>
</div>
<span class="comment-copy">thanks, the -u flag for a linux environment was the winner.  I had previously tried using os.fdopen and ran into the same buffering issue, even if I set the buffer size to 10.</span>
<span class="comment-copy">Unfortunately, Python 3 stubbornly still opens <code>stdin</code> in buffered text mode. Only <code>stdout</code> and <code>stderr</code> are affected by the <code>-u</code> switch now.</span>
<span class="comment-copy">Any work-arounds for Python3? Perhaps an event-driven library/option?</span>
<span class="comment-copy">I tried with gio_channels, and got it working - but the behaviour is exactly the same: no output till <code>enter</code> is pressed</span>
<span class="comment-copy">This worked for me in Python 3.4.3: <code>os.fdopen(sys.stdin.fileno(), 'rb', buffering=0)</code></span>
<span class="comment-copy">This isn't really relevant to the question, did you mean to make this as a comment.</span>
<span class="comment-copy">As I understood, the question was "Is there a better way to read in stdin" [to avoid input buffer issues when using a Python script in a pipeline], and my answer (three years late as it may be) is "Yes, use <code>readline</code> instead of <code>__iter__</code>". But maybe my answer is platform dependent, and you still have buffer issues if you try the above code?</span>
<span class="comment-copy">Ahkey, I understand.  I meant MUCH smaller buffer sizes ( like 80 bytes or less ) for stdin buffering.  For 2.7 you can't effect those buffer sizes without the -U flag Alex mentions in his answer.</span>
<span class="comment-copy">Interesting Alex didn't catch this, <a href="https://github.com/certik/python-2.7/blob/c360290c3c9e55fbd79d6ceacdfc7cd4f393c1eb/Objects/fileobject.c#L1377" rel="nofollow noreferrer">github.com/certik/python-2.7/blob/â€¦</a>  you're correct that readline is likely faster as it uses getc incrementally while file_internext buffers 8192 as defined in source.</span>
<span class="comment-copy">This is pretty important -- I see programs not being interactive enough due to buffering stdin (instead of reacting immediately). I did not know this before.</span>
<span class="comment-copy">This seems like it would have been better as a comment to soren's answer.  Alex Martelli and Soren have provided answers while this is more so an improvement on Soren's input.</span>
<span class="comment-copy">What you propose here here is the best solution I've seen to this horrible problem; I'm about to sweep through all my python code and replace "for line in sys.stdin" with it.  I see it's actually listed in the ref page you referred to.  What's still not clear to me is... why on earth does "for line in sys.stdin" behave differently from "for line in iter(sys.stdin.readline, ''):"?  As far as I can see they are semantically identical except that the former version's behavior is what looks to me like a nasty bug, behavior no one could ever want.  If anyone has a counterexample I'd love to see it.</span>
<span class="comment-copy">@DonHatch when iterating on stdin I agree that the behaviour is weird and bug-like, but when the file is not stdin reading 8k at once will improve performance.</span>
<span class="comment-copy">@SamJacobson Why would it matter whether the input stream in question is stdin or not?  (Perhaps you are meaning to point out some difference among terminals, files, and pipes?  But such differences are independent of whether it's stdin.)  And when you say reading 8k at once will improve performance-- improve performance compared to what?? I don't think I've proposed or advocated any behavior that would ever read less than 8k at once when 8k is available on the input.</span>
<span class="comment-copy">@SamJacobson BTW I filed <a href="https://bugs.python.org/issue26290" rel="nofollow noreferrer">bugs.python.org/issue26290</a> on this a while ago: "fileinput and 'for line in sys.stdin' do strange mockery of input buffering".</span>
<span class="comment-copy">Weird, Alex's answer worked for me back then.  Wonder if a backport update changed/broke something</span>
<span class="comment-copy"><code>tty.setcbreak</code> is not about python buffering but the kernel tty layer buffering input. Thus this does not apply to pipes.</span>
