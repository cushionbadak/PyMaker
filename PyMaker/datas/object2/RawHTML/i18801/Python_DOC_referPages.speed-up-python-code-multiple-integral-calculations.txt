<div class="post-text" itemprop="text">
<p>Is there a way to speed up this code:</p>
<pre><code>import mpmath as mp
import numpy as np
from time import time as epochTime

def func(E):
    f = lambda theta: mp.sin(theta) * mp.exp(E * (mp.cos(theta**2) + \
                                                  mp.cos(theta)**2))
    return f

start = epochTime()
mp.mp.dps = 15
mp.mp.pretty = True

E = np.linspace(0, 10, 200)
ints = [mp.quadgl(func(e), [0, mp.pi]) for e in E] # Main Job
print ('Took:{:.3}s'.format(epochTime() - start))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Running your code, I timed it to 5.84s</p>
<p>using <a href="https://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python"><code>Memoize</code></a> and simplifying expressions:</p>
<pre><code>cos = Memoize(mp.cos)
sin = Memoize(mp.sin)

def func(E):
    def f(t):
        cost = cos(t)
        return sin(t) * mp.exp(E * (cos(t*t) + cost*cost))
    return f
</code></pre>
<p>I got it down to 3.25s first time, and ~2.8s in the next iterations.</p>
<p>(An even better approach might be using <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow noreferrer"><code>lru_cache</code></a> from the standard library, but I did not try to time it).</p>
<p>If you are running similar code many times, it may be sensible to <code>Memoize()</code> both <code>func</code> and <code>f</code>, so the computations become trivial ( ~0.364s ).</p>
<p>Replacing <code>mp</code> with <code>math</code> for cos/sin/exp, I got down to ~1.3s, and now memoizing make the performance worse, for some reason (~1.5s, I guess the lookup time became dominant).</p>
</div>
<div class="post-text" itemprop="text">
<p>In general, you want to avoid calls to transcendent functions like sin, cos, exp, ln as much as possible, especially in a "hot" function like an integrand. </p>
<ul>
<li>Replace x**2 by x*x (often x**2 calls a generic=slow exponentiation function)</li>
<li>use variables for "expensive" intermediate terms which are used more than once</li>
<li>transform your equation to reduce or eliminate transcendent functions</li>
<li>special-case for typical parameter values. Integer exponents are a frequent candidate.</li>
<li>precompute everything that is constant, espc. in parameterized functions</li>
</ul>
<p>For the particular example you can substitute z=cos(theta). It is dz = -sin(theta)dtheta. Your integrand becomes</p>
<pre><code>-exp(E*(z^2 + cos(arccos(z)^2))
</code></pre>
<p>saving you some of the transcendent function calls. The boundaries [0, pi] become [1, -1]. Also avoid x**2, better use x*x.</p>
<p>Complete code:</p>
<pre><code>import mpmath as mp
import numpy as np
from time import time as epochTime

def func(E):
    def f(z):
        acz = mp.acos(z)
        return -mp.exp(E * (mp.cos(acz*acz) + z*z))
    return f

start = epochTime()
mp.mp.dps = 15
mp.mp.pretty = True

E = np.linspace(0, 10, 200)
ints = [mp.quadgl(func(e), [1.0, -1.0]) for e in E] # Main Job
print ('Took:{:.3}s'.format(epochTime() - start))
</code></pre>
</div>
<span class="comment-copy">Do you really need arbitrary-precision math?</span>
<span class="comment-copy">@Zhenya, in fact I was not aware of this fact. I think not. As long as I have few correct digits after the point it is OK.</span>
<span class="comment-copy">The intention was not to change the integrated function. Thanks anyway !</span>
<span class="comment-copy">@rowman but it seems like the best way to improve performance.</span>
<span class="comment-copy">@Elazar, that's true. But this function was just an example. In the real code it would be different from this.</span>
<span class="comment-copy">OK, thought you needed exactly this function. However the generic ideas can be applied to lots of such problems.</span>
