<div class="post-text" itemprop="text">
<p>I am trying to optimize some code, so I thought I would look into exactly where my bottlenecks were. I have four functions that wrap eachother like: </p>
<pre><code>return f1(f2(f3(f4())))
</code></pre>
<p>So I tested each individually as well as a whole. When individually i essentially precomputed the previous function. However, I assumed they would add up to the total time. But they didn't, it grew significantly as I combined them. So I decided to look at it at a smaller scale. I wrote this to test</p>
<pre><code>def f1():
    return 2

def f2(num):
    return num*num

def test():
    for i in range(1000000):
        f1()
def test2():
    for i in range(1000000):
        f2(2)
def test3():
    for i in range(1000000):
        f2(f1())
</code></pre>
<p>I got back test as .085 seconds, test2 as .125 seconds and test3 as .171 seconds. This confounded me in two ways. 1) Why isn't test3 .21 seconds, and 2) Why was it shorter as opposed to my problem of it getting much longer?</p>
</div>
<div class="post-text" itemprop="text">
<p>Since you haven't given us code that reproduces your original problem, it's hard to do anything but guess… but I can make some guesses here.</p>
<hr/>
<p>When you compose two very small functions, the more often you run it, the more likely you are to have the bytecode to both functions, the globals and locals dictionaries, etc. all in your cache.</p>
<p>On the other hand, when you compose two very large functions, you're very likely to push part of the outer function out of cache each time the inner function runs, so you end up spending more time in cache refills than actually interpreting your code.</p>
<hr/>
<p>On top of that, you're forgetting about the cost of calling a function. In Python, that's not just a function call—you normally call functions by their global name, and a <code>LOAD_GLOBAL</code> can be very slow. If you've written toy composition like this:</p>
<pre><code>def test3():
    for i in range(1000000):
        f2(f1())
</code></pre>
<p>… you don't pay for that lookup as often as if you do this:</p>
<pre><code>def f2():
    return 2 * f1()
def test3():
    for i in range(1000000):
        f2()
</code></pre>
<p>… but you can pay almost nothing for it by copying <code>f1</code> into the appropriate <code>locals</code>. For the two examples above:</p>
<pre><code>def test3():
    _f1 = f1
    for i in range(1000000):
        f2(_f1())

def f2(_f1=f1):
    return 2 * _f1()
def test3():
    for i in range(1000000):
        f2()
</code></pre>
<hr/>
<p>Your test functions include setup costs in what you're timing.</p>
<p>For example, if you're using Python 2.x, the <code>range(1000000)</code> could take a significant fraction of the total time. But <code>test1 + test2</code> only does that twice, while <code>test3</code> only does it once. So, it's perfectly reasonable that the savings in <code>test3</code> were enough to be noticeable in the toy test. But in your real-life test, where each loop takes, say, 100x longer, the cost of the <code>range</code> call is insignificant.</p>
<p>It's also worth noting that if you create enough memory, you can end up triggering <code>malloc</code> calls or even VM swapping—which are, respectively, slow and mind-numbingly slow, and which are also both much more variable and unpredictable than the usual costs of running code in a loop. That may not be an issue just creating and destroying a few 1M-item lists (which should be on the order of 20-80MB), but it <em>could</em> be.</p>
<hr/>
<p>Finally, you haven't shown us how you're doing the timing, how you're repeating the tests, how you're aggregating the results, etc., so it's quite possible that your tests just aren't valid.</p>
</div>
<div class="post-text" itemprop="text">
<p>Big amount of time takes list generation "range(1000000)" (assuming you are using python 2.X). In test3 you are creating this list only once. When you sum the time, you are summing 2 times creation of list.</p>
<p>You can use profiler to know what takes the time <a href="http://docs.python.org/2/library/profile.html" rel="nofollow">http://docs.python.org/2/library/profile.html</a></p>
</div>
<span class="comment-copy">How repeatable are these results?</span>
<span class="comment-copy">How'd you test the times (out of curiosity)?</span>
<span class="comment-copy">@recursive, they are always the same, tested many times.</span>
<span class="comment-copy">@g.d.d.c I tried cProfiler as well as just using datetime comparisons.</span>
<span class="comment-copy">@JeremyThiesen: Always use <a href="http://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer"><code>timeit</code></a> to time code, never, ever, ever use <code>datetime</code> or <code>time</code>.</span>
<span class="comment-copy">Thanks for the detail in your explanation. Unfortunately, the code for the other pieces are quite long, and I couldn't think of a good way to condense them.   The actual code does indeed take up some memory, but shouldn't be anything too large. Is there a better way to manage that in order to speed it up. I am experiencing exponential increases in the time it takes right now. Aka if they were additive, it takes 1 sec, but I am getting 4 minutes. :(</span>
<span class="comment-copy">@JeremyThiesen: Unless you can create a small-enough-to-post example that reproduces your problem, it's going to be very hard to debug. Also, are you sure it's actually exponential, and not linear, except with a cliff where it jumps 3 orders of magnitude in a very small range? (The latter behavior is what you expect from cache, VM, etc. issues.) Also, is it possible that you've done something silly and hard to spot, and the way you're composing the functions in your real code is just wrong (e.g., passing <code>array[i:]</code> instead of <code>array[i:i+1]</code> to the inner function)?</span>
<span class="comment-copy">@abarnet I reworked some functions and got something that more resembles my problem. I would be grateful if you took a look. <a href="http://stackoverflow.com/questions/17199108/running-a-function-withing-another-function-is-faster-than-just-the-function-wh" title="running a function withing another function is faster than just the function wh">stackoverflow.com/questions/17199108/…</a></span>
<span class="comment-copy">Is there a good reference for the relative speed of global function calls versus those from imported modules and in-class calls (i.e. <code>self.some_func()</code> calling <code>self.other_func()</code> or something similar)?</span>
<span class="comment-copy">@JAB: Not that I know of. However, it's generally accepted that globals and methods (which are descriptors, and may be inherited, etc.) can be significantly slower than locals, so when you need to squeeze out the last 5%, it's worth testing assigning them to locals and seeing how it affects the timing. Other-module globals and patched-into-the-instance methods may be less slow, but when it matters, I'd still try it and test. If you want more info than that, write a new question and I can give more details and show how to do the tests.</span>
