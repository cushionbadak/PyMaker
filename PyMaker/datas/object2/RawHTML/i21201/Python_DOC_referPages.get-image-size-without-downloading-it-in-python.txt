<div class="post-text" itemprop="text">
<p>How can I get dimensions of image without actually downloading it? Is it even possible?
I have a list of urls of images and I want to assign width and size to it.</p>
<p>I know there is a way of doing it locally (<a href="https://stackoverflow.com/questions/1507084/how-to-check-dimensions-of-all-images-in-a-directory-using-python">How to check dimensions of all images in a directory using python?</a>), but I don't want to download all the images.</p>
<p>Edit:</p>
<p>Following ed. suggestions, I edited the code. I came up with <a href="http://codepad.org/dC1RSwxi" rel="nofollow noreferrer">this code</a>. Not sure weather it downloads whole file or just a part (as I wanted).</p>
</div>
<div class="post-text" itemprop="text">
<p>This is based on ed's answer mixed with other things I found on the web.  I ran into the same issue as grotos with .read(24).  Download getimageinfo.py from <a href="https://gist.github.com/bmamouri/55ac6bfa7ba5eee03da2eb9e4f7469d9" rel="nofollow noreferrer">here</a> and download ReSeekFile.py from <a href="http://www.dalkescientific.com/writings/diary/archive/2005/05/18/updated_reseekfile.html" rel="nofollow noreferrer">here</a>.</p>
<pre><code>import urllib2
imgdata = urllib2.urlopen(href)
image_type,width,height = getimageinfo.getImageInfo(imgdata)
</code></pre>
<p>Modify getimageinfo as such...</p>
<pre><code>import ReseekFile

def getImageInfo(datastream):
    datastream = ReseekFile.ReseekFile(datastream)
    data = str(datastream.read(30))

#Skipping to jpeg

# handle JPEGs
elif (size &gt;= 2) and data.startswith('\377\330'):
    content_type = 'image/jpeg'
    datastream.seek(0)
    datastream.read(2)
    b = datastream.read(1)
    try:
        while (b and ord(b) != 0xDA):
            while (ord(b) != 0xFF): b = datastream.read(1)
            while (ord(b) == 0xFF): b = datastream.read(1)
            if (ord(b) &gt;= 0xC0 and ord(b) &lt;= 0xC3):
                datastream.read(3)
                h, w = struct.unpack("&gt;HH", datastream.read(4))
                break
            else:
                datastream.read(int(struct.unpack("&gt;H", datastream.read(2))[0])-2)
            b = datastream.read(1)
        width = int(w)
        height = int(h)
    except struct.error:
        pass
    except ValueError:
        pass
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I found the solution on <a href="http://effbot.org/zone/pil-image-size.htm" rel="noreferrer">this site</a> to work well:</p>
<pre><code>import urllib
import ImageFile

def getsizes(uri):
    # get file size *and* image size (None if not known)
    file = urllib.urlopen(uri)
    size = file.headers.get("content-length")
    if size: size = int(size)
    p = ImageFile.Parser()
    while 1:
        data = file.read(1024)
        if not data:
            break
        p.feed(data)
        if p.image:
            return size, p.image.size
            break
    file.close()
    return size, None

print getsizes("http://www.pythonware.com/images/small-yoyo.gif")
# (10965, (179, 188))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you're willing to download the first 24 bytes of each file, then <a href="http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py" rel="nofollow">this function</a> (mentioned in johnteslade's answer to the question you mention) will work out the dimensions.</p>
<p>That's probably the least downloading necessary to do the job you want.</p>
<pre><code>import urllib2
start = urllib2.urlopen(image_url).read(24)
</code></pre>
<p>Edit (1):</p>
<p>In the case of jpeg files it seems to need more bytes. You could edit the function so that instead of reading a StringIO.StringIO(data) it instead reads the file handle from urlopen. Then it will read exactly as much of the image as it needs to find out the width and height.</p>
</div>
<div class="post-text" itemprop="text">
<p>Since <a href="http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py" rel="nofollow">getimageinfo.py</a> mentioned above doesn't work in Python3. Pillow is used instead of it.</p>
<p>Pillow can be found in <a href="https://pypi.python.org/pypi/Pillow/2.7.0" rel="nofollow">pypi</a>, or installed by using pip: <code>pip install pillow</code>.</p>
<pre>

from io import BytesIO
from PIL import Image
import requests
hrefs = ['https://farm4.staticflickr.com/3894/15008518202_b016d7d289_m.jpg','https://farm4.staticflickr.com/3920/15008465772_383e697089_m.jpg','https://farm4.staticflickr.com/3902/14985871946_86abb8c56f_m.jpg']
RANGE = 5000
for href in hrefs:
    req  = requests.get(href,headers={'User-Agent':'Mozilla5.0(Google spider)','Range':'bytes=0-{}'.format(RANGE)})
    im = Image.open(BytesIO(req.content))

    print(im.size)
</pre>
</div>
<div class="post-text" itemprop="text">
<p>I like this solution I found, which downloads chunks of the image until it can be recognized as an image file by PIL and then stops downloading. This ensures that enough of the image header gets downloaded to read the dimensions, but no more. (I found this <a href="http://effbot.org/zone/pil-image-size.htm" rel="nofollow">here</a> and <a href="https://pythonadventures.wordpress.com/2013/11/03/determine-the-dimensions-of-an-image-on-the-web-without-downloading-it-entirely/" rel="nofollow">here</a>; I've adapted it for Python 3+.)</p>
<pre><code>import urllib
from PIL import ImageFile

def getsizes(uri):
    # get file size *and* image size (None if not known)
    file = urllib.request.urlopen(uri)
    size = file.headers.get("content-length")
    if size: 
        size = int(size)
    p = ImageFile.Parser()
    while True:
        data = file.read(1024)
        if not data:
            break
        p.feed(data)
        if p.image:
            return size, p.image.size
            break
    file.close()
    return size, None   
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It's not possible to do it directly, but there's a workaround for that. If the files are present on the server, then implement the API endpoint that takes image name as an argument and returns the size.</p>
<p>But if the files are on the different server, you've got no other way but to download the files.</p>
</div>
<div class="post-text" itemprop="text">
<p>Unfortunately I can't comment, so this is as an answer:</p>
<p>Use a get query with the header</p>
<pre><code>"Range": "bytes=0-30"
</code></pre>
<p>And then simply use</p>
<p><a href="http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py" rel="nofollow">http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py</a></p>
<p>If you use python's "requests", it's simply</p>
<pre><code>r = requests.get(image_url, headers={
    "Range": "bytes=0-30"
})
image_info = get_image_info(r.content)
</code></pre>
<p>This fixes ed.'s answer and doesn't have any other dependencies (like ReSeekFile.py).</p>
</div>
<div class="post-text" itemprop="text">
<p>My fixed "getimageInfo.py", work with Python 3.4+, try it, just great!</p>
<pre><code>import io
import struct
import urllib.request as urllib2

def getImageInfo(data):
    data = data
    size = len(data)
    #print(size)
    height = -1
    width = -1
    content_type = ''

    # handle GIFs
    if (size &gt;= 10) and data[:6] in (b'GIF87a', b'GIF89a'):
        # Check to see if content_type is correct
        content_type = 'image/gif'
        w, h = struct.unpack(b"&lt;HH", data[6:10])
        width = int(w)
        height = int(h)

    # See PNG 2. Edition spec (http://www.w3.org/TR/PNG/)
    # Bytes 0-7 are below, 4-byte chunk length, then 'IHDR'
    # and finally the 4-byte width, height
    elif ((size &gt;= 24) and data.startswith(b'\211PNG\r\n\032\n')
          and (data[12:16] == b'IHDR')):
        content_type = 'image/png'
        w, h = struct.unpack(b"&gt;LL", data[16:24])
        width = int(w)
        height = int(h)

    # Maybe this is for an older PNG version.
    elif (size &gt;= 16) and data.startswith(b'\211PNG\r\n\032\n'):
        # Check to see if we have the right content type
        content_type = 'image/png'
        w, h = struct.unpack(b"&gt;LL", data[8:16])
        width = int(w)
        height = int(h)

    # handle JPEGs
    elif (size &gt;= 2) and data.startswith(b'\377\330'):
        content_type = 'image/jpeg'
        jpeg = io.BytesIO(data)
        jpeg.read(2)
        b = jpeg.read(1)
        try:
            while (b and ord(b) != 0xDA):
                while (ord(b) != 0xFF): b = jpeg.read(1)
                while (ord(b) == 0xFF): b = jpeg.read(1)
                if (ord(b) &gt;= 0xC0 and ord(b) &lt;= 0xC3):
                    jpeg.read(3)
                    h, w = struct.unpack(b"&gt;HH", jpeg.read(4))
                    break
                else:
                    jpeg.read(int(struct.unpack(b"&gt;H", jpeg.read(2))[0])-2)
                b = jpeg.read(1)
            width = int(w)
            height = int(h)
        except struct.error:
            pass
        except ValueError:
            pass

    return content_type, width, height



#from PIL import Image
#import requests
#hrefs = ['http://farm4.staticflickr.com/3894/15008518202_b016d7d289_m.jpg','https://farm4.staticflickr.com/3920/15008465772_383e697089_m.jpg','https://farm4.staticflickr.com/3902/14985871946_86abb8c56f_m.jpg']
#RANGE = 5000
#for href in hrefs:
    #req  = requests.get(href,headers={'User-Agent':'Mozilla5.0(Google spider)','Range':'bytes=0-{}'.format(RANGE)})
    #im = getImageInfo(req.content)

    #print(im)
req = urllib2.Request("http://vn-sharing.net/forum/images/smilies/onion/ngai.gif", headers={"Range": "5000"})
r = urllib2.urlopen(req)
#f = open("D:\\Pictures\\1.jpg", "rb")
print(getImageInfo(r.read()))
# Output: &gt;&gt; ('image/gif', 50, 50)
#print(getImageInfo(f.read()))
</code></pre>
<p>Source code: <a href="http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py" rel="nofollow">http://code.google.com/p/bfg-pages/source/browse/trunk/pages/getimageinfo.py</a></p>
</div>
<span class="comment-copy">it's usually some header in the beginning of the file, so you can download only few bytes. e.g. 6 bytes will be enough to get dimensions of jpeg: <a href="http://www.fastgraph.com/help/jpeg_header_format.html" rel="nofollow noreferrer">fastgraph.com/help/jpeg_header_format.html</a></span>
<span class="comment-copy">Nice work.  I also ran into the same issue with the otherwise helpful response from ed</span>
<span class="comment-copy">The source code for <code>getimageinfo.py</code> is not available anymore. Here is the code for anyone who is looking for it in future: <a href="https://gist.github.com/bmamouri/55ac6bfa7ba5eee03da2eb9e4f7469d9" rel="nofollow noreferrer">gist.github.com/bmamouri/55ac6bfa7ba5eee03da2eb9e4f7469d9</a></span>
<span class="comment-copy">Thanks @bman, updated the answer.</span>
<span class="comment-copy">Where does <code>ImageFile</code> comes from?</span>
<span class="comment-copy">PIL -- python imaging library</span>
<span class="comment-copy">Take care with the file descriptor in this code: if the image size is retrieved the file is not closed.</span>
<span class="comment-copy">Can you elaborate @IvanDePazCenteno? Wouldn't a "file.close()" before the return size, p.image.size fix that? And also, is this even a problem?</span>
<span class="comment-copy">@FabianBosler yes, adding a <code>file.close()</code> before that line would do the trick, even though I would recommend using the <code>with</code> keyword to manage it, as it is a <a href="https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files" rel="nofollow noreferrer">good practice</a>. Definitely yes, it is a problem. Not closing allocated resources will potentially become a disaster in certain contexts, for example in big loops. An allocated resource should always be closed, even if the OS or the interpreter itself can get rid of it.</span>
<span class="comment-copy">Using this solution, especially .read(24), breaks that script. All works when I use read().</span>
<span class="comment-copy">It's basically the same as an example in the python docs (<a href="http://docs.python.org/library/urllib2.html" rel="nofollow noreferrer">docs.python.org/library/urllib2.html</a>). What error do you get using (24)? Just using read() (I guess you know) will download the whole file...</span>
<span class="comment-copy">If I run with read(24) ther is some error in getImageInfo function: UnboundLocalError: local variable 'w' referenced before assignment</span>
<span class="comment-copy">Hmm. Try running it with read(50) and see if it works. I think the error must be coming from the jpeg part of the function, so maybe it needs a few more bytes.</span>
<span class="comment-copy">It is the same. I think it only works with read(X), where X is so large that it covers the whole file.</span>
<span class="comment-copy">Doesn't this actually download the image? I believe that's what OP is trying to avoid</span>
<span class="comment-copy">I'd suggest to use requests' session to reuse TCP connection and use plain HTTP instead of HTTPS if possible. It may dramatically increase performance in some cases.</span>
<span class="comment-copy">Based on the other answer for this question this seems to be an incorrect assertion.</span>
<span class="comment-copy">@SlaterTyranus No, all the other answers just suggest downloading the image (or parts of the image). This answer is the <b>most</b> correct, but the others are valid work-arounds.</span>
<span class="comment-copy">The provided url is invalid</span>
<span class="comment-copy">Hey this is very interesting. Just curious what the <code>RANGE</code> variable is doing... does that limit how many bytes get downloaded?</span>
<span class="comment-copy">This wasn't working with many JPEGs for me. I found an alternative function (posted as answer)</span>
