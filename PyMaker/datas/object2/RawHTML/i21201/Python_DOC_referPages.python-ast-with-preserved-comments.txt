<div class="post-text" itemprop="text">
<p>I can get AST without comments using</p>
<pre><code>import ast
module = ast.parse(open('/path/to/module.py').read())
</code></pre>
<p>Could you show an example of getting AST with preserved comments (and whitespace)?</p>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://docs.python.org/3/library/ast.html" rel="nofollow noreferrer"><code>ast</code></a> module doesn't include comments.  The <a href="https://docs.python.org/3/library/tokenize.html" rel="nofollow noreferrer"><code>tokenize</code></a> module can give you comments, but doesn't provide other program structure.</p>
</div>
<div class="post-text" itemprop="text">
<p>An AST that keeps information about formating, comments etc. is called a Full Syntax Tree.</p>
<p><a href="https://redbaron.readthedocs.org/en/latest/" rel="noreferrer">redbaron</a> is able to do this. Install with <code>pip install redbaron</code> and try the following code.</p>
<pre><code>import redbaron

with open("/path/to/module.py", "r") as source_code:
    red = redbaron.RedBaron(source_code.read())

print (red.fst())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This question naturally arises when writing any kind of Python code beautifier, pep-8 checker, etc. In such cases, you <em>are</em> doing a source-to-source transformations, you <em>do</em> expect the input to be written by human and not only want the output to be human-readable, but in addition expect it to:</p>
<ol>
<li>include all comments, exactly where they appear in the original.</li>
<li>output the exact spelling of strings, including docstrings as in the original.</li>
</ol>
<p>This is far from easy to do with the ast module. You could call it a hole in the api, but there seems to be no easy way to extend the api to do 1 and 2 easily.</p>
<p>Andrei's suggestion to use both ast and tokenize together is a brilliant workaround. The idea came to me also when writing a <a href="https://github.com/edreamleo/python-to-coffeescript" rel="noreferrer">Python to Coffeescript converter</a>, but the code is far from trivial.</p>
<p>The <code>TokenSync</code> (ts) class starting at line 1305 in <a href="https://github.com/edreamleo/python-to-coffeescript/blob/master/py2cs.py" rel="noreferrer">py2cs.py</a> coordinates communication between the token-based data and the ast traversal. Given the source string s, the <code>TokenSync</code> class tokenizes s and inits internal data structures that support several interface methods:</p>
<p><code>ts.leading_lines(node)</code>: Returns a list of the preceding comment and blank lines.</p>
<p><code>ts.trailing_comment(node)</code>: Return a string containing the trailing comment for the node, if any.</p>
<p><code>ts.sync_string(node)</code>: Return the spelling of the string at the given node.</p>
<p>It is straightforward, but just a bit clumsy, for the ast visitors to use these methods.  Here are some examples from the <code>CoffeeScriptTraverser</code> (cst) class in py2cs.py:</p>
<pre><code>def do_Str(self, node):
    '''A string constant, including docstrings.'''
    if hasattr(node, 'lineno'):
        return self.sync_string(node)
</code></pre>
<p>This works provided that ast.Str nodes are visited in the order they appear in the sources.  This happens naturally in most traversals.</p>
<p>Here is the ast.If visitor.  It shows how to use <code>ts.leading_lines</code> and <code>ts.trailing_comment</code>:</p>
<pre><code>def do_If(self, node):

    result = self.leading_lines(node)
    tail = self.trailing_comment(node)
    s = 'if %s:%s' % (self.visit(node.test), tail)
    result.append(self.indent(s))
    for z in node.body:
        self.level += 1
        result.append(self.visit(z))
        self.level -= 1
    if node.orelse:
        tail = self.tail_after_body(node.body, node.orelse, result)
        result.append(self.indent('else:' + tail))
        for z in node.orelse:
            self.level += 1
            result.append(self.visit(z))
            self.level -= 1
    return ''.join(result)
</code></pre>
<p>The <code>ts.tail_after_body</code> method compensates for the fact that there are no ast nodes representing 'else' clauses. It's not rocket science, but it isn't pretty:</p>
<pre><code>def tail_after_body(self, body, aList, result):
    '''
    Return the tail of the 'else' or 'finally' statement following the given body.
    aList is the node.orelse or node.finalbody list.
    '''
    node = self.last_node(body)
    if node:
        max_n = node.lineno
        leading = self.leading_lines(aList[0])
        if leading:
            result.extend(leading)
            max_n += len(leading)
        tail = self.trailing_comment_at_lineno(max_n + 1)
    else:
        tail = '\n'
    return tail
</code></pre>
<p>Note that <code>cst.tail_after_body</code> just calls <code>ts.tail_after_body</code>.</p>
<p><strong>Summary</strong></p>
<p>The TokenSync class encapsulates most of the complexities involved in making token-oriented data available to ast traversal code. Using the TokenSync class is straightforward, but the ast visitors for all Python statements (and ast.Str) must include calls to <code>ts.leading_lines</code>, <code>ts.trailing_comment</code> and <code>ts.sync_string</code>. Furthermore, the <code>ts.tail_after_body</code> hack is needed to handle "missing" ast nodes.</p>
<p>In short, the code works well, but is just a bit clumsy.</p>
<p>@Andrei: your short answer might suggest that you know of a more elegant way. If so, I would love to see it.</p>
<p>Edward K. Ream</p>
</div>
<div class="post-text" itemprop="text">
<p>A few people have already mentioned <a href="https://github.com/python/cpython/tree/master/Lib/lib2to3" rel="nofollow noreferrer">lib2to3</a> but I wanted to create a more complete answer, because this tool is an under-appreciated gem. Don't bother with <code>redbaron</code>.</p>
<p><code>lib2to3</code> is comprised of a few parts:</p>
<ul>
<li><strong>the parser</strong>: tokens, grammar, etc</li>
<li><strong>fixers</strong>: library of transformations</li>
<li><strong>refactor tools</strong>: applies fixers to a parsed ast</li>
<li><strong>the command line</strong>: choose fixes to apply and run them in parallel using multiprocessing</li>
</ul>
<p>Below is a brief introduction to using <code>lib2to3</code> for transformations and scraping data (i.e. extraction).</p>
<h2>Transformations</h2>
<p>If you'd like to transform python files (i.e. complex find/replace), the CLI provided by <code>lib2to3</code> is fully featured, and can transform files in parallel.</p>
<p>To use it, create a python package where each sub-module within it contains a single sub-class of <a href="https://github.com/python/cpython/blob/master/Lib/lib2to3/fixer_base.py" rel="nofollow noreferrer"><code>lib2to3.fixer_base.BaseFix</code></a>.  See <a href="https://github.com/python/cpython/tree/master/Lib/lib2to3/fixes" rel="nofollow noreferrer"><code>lib2to3.fixes</code></a> for lots of examples.</p>
<p>Then create your executable script (replacing "myfixes" with the name of your package):</p>
<pre><code>import sys
import lib2to3.main

def main(args=None):
    sys.exit(lib2to3.main.main("myfixes", args=args))

if __name__ == '__main__':
    main()
</code></pre>
<p>Run <code>yourscript -h</code> to see the options.</p>
<h2>Scraping</h2>
<p>If your goal is to gather data, but not transform it, then you need to do a little more work.  Here's a recipe I whipped up to use <code>lib2to3</code> for data scraping:</p>
<pre><code># file: basescraper.py
from __future__ import absolute_import, print_function

from lib2to3.pgen2 import token
from lib2to3.pgen2.parse import ParseError
from lib2to3.pygram import python_grammar
from lib2to3.refactor import RefactoringTool
from lib2to3 import fixer_base


def symbol_name(number):
    """
    Get a human-friendly name from a token or symbol

    Very handy for debugging.
    """
    try:
        return token.tok_name[number]
    except KeyError:
        return python_grammar.number2symbol[number]


class SimpleRefactoringTool(RefactoringTool):
    def __init__(self, scraper_classes, options=None, explicit=None):
        self.fixers = None
        self.scraper_classes = scraper_classes
        # first argument is a list of fixer paths, as strings. we override
        # get_fixers, so we don't need it.
        super(SimpleRefactoringTool, self).__init__(None, options, explicit)

    def get_fixers(self):
        """
        Override base method to get fixers from passed fixers classes instead
        of via dotted-module-paths.
        """
        self.fixers = [cls(self.options, self.fixer_log)
                       for cls in self.scraper_classes]
        return (self.fixers, [])

    def get_results(self):
        """
        Get the scraped results returned from `scraper_classes`
        """
        return {type(fixer): fixer.results for fixer in self.fixers}


class BaseScraper(fixer_base.BaseFix):
    """
    Base class for a fixer that stores results.

    lib2to3 was designed with transformation in mind, but if you just want
    to scrape results, you need a way to pass data back to the caller.
    """
    BM_compatible = True

    def __init__(self, options, log):
        self.results = []
        super(BaseScraper, self).__init__(options, log)

    def scrape(self, node, match):
        raise NotImplementedError

    def transform(self, node, match):
        result = self.scrape(node, match)
        if result is not None:
            self.results.append(result)


def scrape(code, scraper):
    """
    Simple interface when you have a single scraper class.
    """
    tool = SimpleRefactoringTool([scraper])
    tool.refactor_string(code, '&lt;test.py&gt;')
    return tool.get_results()[scraper]
</code></pre>
<p>And here's a simple scraper that finds the first comment after a function def:</p>
<pre><code># file: commentscraper.py
from basescraper import scrape, BaseScraper, ParseError

class FindComments(BaseScraper):

    PATTERN = """ 
    funcdef&lt; 'def' name=any parameters&lt; '(' [any] ')' &gt;
           ['-&gt;' any] ':' suite=any+ &gt;
    """

    def scrape(self, node, results):
        suite = results["suite"]
        name = results["name"]

        if suite[0].children[1].type == token.INDENT:
            indent_node = suite[0].children[1]
            return (str(name), indent_node.prefix.strip())
        else:
            # e.g. "def foo(...): x = 5; y = 7"
            # nothing to save
            return

# example usage:

code = '''\

@decorator
def foobar():
    # type: comment goes here
    """
    docstring
    """
    pass

'''
comments = scrape(code, FindTypeComments)
assert comments == [('foobar', '# type: comment goes here')]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Other experts seem to think the Python AST module strips comments, so that means that route simply won't work for you.</p>
<p>Our <a href="http://www.semanticdesigns.com/Products/DMS/DMSToolkit.html" rel="nofollow noreferrer">DMS Software Reengineering Toolkit</a> with its <a href="http://www.semanticdesigns.com/Products/FrontEnds/PythonFrontEnd.html" rel="nofollow noreferrer">Python front end</a> will parse Python and build ASTs that capture all the comments (<a href="https://stackoverflow.com/a/22118379/120163">see this SO example)</a>.  The Python front end includes a prettyprinter that can regenerate Python code (with the comments!) directly from the AST.  DMS itself provides the low-level parsing machinery, and a source-to-source transformation capability that operate on patterns written using the target language (e.g., Python) surface syntax.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you're using python 3, you can use <code>bowler</code>, which is based on lib2to3, but provides a much nicer API and CLI for creating transformation scripts. </p>
<p><a href="https://pybowler.io/" rel="nofollow noreferrer">https://pybowler.io/</a></p>
</div>
<span class="comment-copy">why don't you just import the module?</span>
<span class="comment-copy">That strips the comments as well. Like most parers do - there simply isn't any value in keeping them unless you're doing source-to-source transformations <i>and</i> expect the input to be written by human and the output to be human-readable. That's rare and it's quite some pain to implement, so it's rarely done.</span>
<span class="comment-copy">I don't want to import the module. It can raise an exception, so I just want to analyze it. Comments may contain some valuable information, therefore I want to get them somehow. I could scan the source using line numbers from AST, but hope that there is a better way. In <a href="http://stackoverflow.com/questions/768634/python-parse-a-py-file-read-the-ast-modify-it-then-write-back-the-modified">another question</a> guys suggest to have a look on <a href="http://svn.python.org/view/sandbox/trunk/2to3/" rel="nofollow noreferrer"><code>lib2to3</code></a></span>
<span class="comment-copy">The AST doesn't include them for a reason. I had some troubles with multiline strings as well since <code>ast.Str</code> has <code>col_offset=-1</code> and <code>lineno</code> is the last line of the string. All these issues can be solved by using <code>ast</code> and <code>tokenize</code> together. Thanks</span>
<span class="comment-copy">Redbaron is awesome on several ways but unfortunately it currently does not support parsing Python3.</span>
<span class="comment-copy">Unfortunately, <code>redbaron</code> and the <code>baron</code> library on which it is based are woefully broken, and at least <code>redbaron</code> seems to be largely unmaintained.  I struggled to get it to do basic transformations, and in the process of fixing it discovered that the tests are not nearly complete enough.  My <a href="https://github.com/PyCQA/redbaron/pull/144" rel="nofollow noreferrer">PR</a> has gone 4 months without a a single response. Once I fixed that issue I then ran into basic source code parsing issues with the lower-level <code>baron</code> library.  At that point I found <code>lib2to3</code> and never looked back.</span>
