<div class="post-text" itemprop="text">
<p>If I specify the character encoding (as suggested by <a href="http://www.python.org/dev/peps/pep-0263/" rel="nofollow">PEP 263</a>) in the "magic line" or shebang of a python module like</p>
<pre><code># -*- coding: utf-8 -*-
</code></pre>
<p>can I retrieve this encoding from within that module?</p>
<p>(Working on Windows 7 x64 with Python 2.7.9)</p>
<hr/>
<p>I tried (without success) to retrieve the default encoding or shebang</p>
<pre><code># -*- coding: utf-8 -*-

import sys
from shebang import shebang

print "sys.getdefaultencoding():", sys.getdefaultencoding()
print "shebang:", shebang( __file__.rstrip("oc"))
</code></pre>
<p>will yield:</p>
<blockquote>
<p>sys.getdefaultencoding(): ascii</p>
<p>shebang: None</p>
</blockquote>
<p>(same for iso-8859-1)</p>
</div>
<div class="post-text" itemprop="text">
<p>I'd borrow the Python 3 <a href="https://hg.python.org/cpython/file/v3.5.2/Lib/tokenize.py#l357" rel="nofollow"><code>tokenize.detect_encoding()</code> function</a> in Python 2, adjusted a little to match Python 2 expectations. I've changed the function signature to accept a filename and dropped the inclusion of the lines read so far; you don't need those for your usecase:</p>
<pre><code>import re
from codecs import lookup, BOM_UTF8

cookie_re = re.compile(r'^[ \t\f]*#.*?coding[:=][ \t]*([-\w.]+)')
blank_re = re.compile(br'^[ \t\f]*(?:[#\r\n]|$)')

def _get_normal_name(orig_enc):
    """Imitates get_normal_name in tokenizer.c."""
    # Only care about the first 12 characters.
    enc = orig_enc[:12].lower().replace("_", "-")
    if enc == "utf-8" or enc.startswith("utf-8-"):
        return "utf-8"
    if enc in ("latin-1", "iso-8859-1", "iso-latin-1") or \
       enc.startswith(("latin-1-", "iso-8859-1-", "iso-latin-1-")):
        return "iso-8859-1"
    return orig_enc

def detect_encoding(filename):
    bom_found = False
    encoding = None
    default = 'ascii'

    def find_cookie(line):
        match = cookie_re.match(line)
        if not match:
            return None
        encoding = _get_normal_name(match.group(1))
        try:
            codec = lookup(encoding)
        except LookupError:
            # This behaviour mimics the Python interpreter
            raise SyntaxError(
                "unknown encoding for {!r}: {}".format(
                    filename, encoding))

        if bom_found:
            if encoding != 'utf-8':
                # This behaviour mimics the Python interpreter
                raise SyntaxError(
                    'encoding problem for {!r}: utf-8'.format(filename))
            encoding += '-sig'
        return encoding

    with open(filename, 'rb') as fileobj:        
        first = next(fileobj, '')
        if first.startswith(BOM_UTF8):
            bom_found = True
            first = first[3:]
            default = 'utf-8-sig'
        if not first:
            return default

        encoding = find_cookie(first)
        if encoding:
            return encoding
        if not blank_re.match(first):
            return default

        second = next(fileobj, '')

    if not second:
        return default    
    return find_cookie(second) or default
</code></pre>
<p>Like the original function, the above function reads two lines <em>max</em> from the source file, and will raise a <code>SyntaxError</code> exception if the encoding in the cookie is invalid or is not UTF-8 while a UTF-8 BOM is present.</p>
<p>Demo:</p>
<pre><code>&gt;&gt;&gt; import tempfile
&gt;&gt;&gt; def test(contents):
...     with tempfile.NamedTemporaryFile() as f:
...         f.write(contents)
...         f.flush()
...         return detect_encoding(f.name)
...
&gt;&gt;&gt; test('# -*- coding: utf-8 -*-\n')
'utf-8'
&gt;&gt;&gt; test('#!/bin/env python\n# -*- coding: latin-1 -*-\n')
'iso-8859-1'
&gt;&gt;&gt; test('import this\n')
'ascii'
&gt;&gt;&gt; import codecs
&gt;&gt;&gt; test(codecs.BOM_UTF8 + 'import this\n')
'utf-8-sig'
&gt;&gt;&gt; test(codecs.BOM_UTF8 + '# encoding: latin-1\n')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 5, in test
  File "&lt;string&gt;", line 37, in detect_encoding
  File "&lt;string&gt;", line 24, in find_cookie
SyntaxError: encoding problem for '/var/folders/w0/nl1bwj6163j2pvxswf84xcsjh2pc5g/T/tmpxsqH8L': utf-8
&gt;&gt;&gt; test('# encoding: foobarbaz\n')
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
  File "&lt;stdin&gt;", line 5, in test
  File "&lt;string&gt;", line 37, in detect_encoding
  File "&lt;string&gt;", line 18, in find_cookie
SyntaxError: unknown encoding for '/var/folders/w0/nl1bwj6163j2pvxswf84xcsjh2pc5g/T/tmpHiHdG3': foobarbaz
</code></pre>
</div>
<span class="comment-copy">It is very likely that the encoding information gets lost after compilation to <code>pyc</code>. You may need to parse the <code>py</code> file directly.</span>
<span class="comment-copy">Note that <code>sys.getdefaultencoding()</code> has <i>nothing</i> to do with how Python source code is decoded.</span>
<span class="comment-copy">Great code, though on Windows it gives me an <code>IOError: [Errno 13] Permission denied: 'c:\\users\\maggyero\\appdata\\local\\temp\\tmp6qsaxo'</code> (on Linux it works fine). I have a related question <a href="https://stackoverflow.com/questions/48984214/python-2-assumes-different-source-code-encodings">here</a> and I think you are one of the most qualified around here to answer.</span>
<span class="comment-copy">@Maggyero: that's a limitation of the <a href="https://docs.python.org/3/library/tempfile.html#tempfile.NamedTemporaryFile" rel="nofollow noreferrer"><code>NamedTemporaryFile</code> class</a> on Windows: <i>Whether the name can be used to open the file a second time, while the named temporary file is still open, varies across platforms (it can be so used on Unix; it cannot on Windows NT or later).</i></span>
