<div class="post-text" itemprop="text">
<p>I am playing around with <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="noreferrer">concurrent.futures</a>.</p>
<p>Currently my future calls <code>time.sleep(secs)</code>.</p>
<p>It seems that <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future.cancel" rel="noreferrer">Future.cancel()</a> does less than I thought.</p>
<p>If the future is already executing, then <code>time.sleep()</code> does not get cancel by it.</p>
<p>The same for the timeout parameter for <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.wait" rel="noreferrer">wait()</a>. It does not cancel my <code>time.sleep()</code>.</p>
<p>How to cancel <code>time.sleep()</code> which gets executed in a concurrent.futures?</p>
<p>For testing I use the <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor" rel="noreferrer">ThreadPoolExecutor</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you submit a function to a <code>ThreadPoolExecutor</code>, the executor will run the function in a thread and store its return value in the <code>Future</code> object. Since the number of concurrent threads is limited, you have the option to <em>cancel</em> the <em>pending</em> execution of a future, but once control in the worker thread has been passed to the callable, there's no way to stop execution.</p>
<p>Consider this code:</p>
<pre><code>import concurrent.futures as f
import time

T = f.ThreadPoolExecutor(1) # Run at most one function concurrently
def block5():
    time.sleep(5)
    return 1
q = T.submit(block5)
m = T.submit(block5)

print q.cancel()  # Will fail, because q is already running
print m.cancel()  # Will work, because q is blocking the only thread, so m is still queued
</code></pre>
<p>In general, whenever you want to have something cancellable you yourself are responsible for making sure that it is.</p>
<p>There are some off-the-shelf options available though. <em>E.g.</em>, consider using <a href="https://docs.python.org/3/library/asyncio.html?highlight=asyncio#module-asyncio" rel="nofollow">asyncio</a>, they also <a href="https://docs.python.org/3/library/asyncio-task.html#example-future-with-run-until-complete" rel="nofollow">have an example using sleep</a>. The concept circumvents the issue by, whenever any potentially blocking operation is to be called, instead returning control to a control loop running in the outer-most context, together with a note that execution should be continued whenever the result is available - or, in your case, after <code>n</code> seconds have passed.</p>
</div>
<div class="post-text" itemprop="text">
<p>I do not know much about concurrent.futures, but you can use this logic to break the time. Use a loop instead of sleep.time() or wait() </p>
<pre><code>for i in range(sec):
    sleep(1)
</code></pre>
<p>interrupt or break can be used to come out of loop. </p>
</div>
<span class="comment-copy">short answer - no way, and most probably usage of sleep in workers means problem with design, long-answer - you always able to implement custom sleep with possibility to break them, however it is not neither pythonic or correct.  as alternative you can check for lock usage.</span>
<span class="comment-copy">Oh what fun :-) I switched from multiprocessing to concurrent.futures (for other reasons). Now I am thinking about switching from concurrent.futures to asyncio ... :-). Nevertheless, Phillip, thank you for your answer!</span>
<span class="comment-copy">You're welcome ðŸ˜‰ Btw, with <code>multiprocessing</code>, interrupting <code>sleep</code> was possible, because you can of course <code>kill</code> the other processes.</span>
<span class="comment-copy">@ I thought I can use <code>kill</code> in <code>concurrent.futures</code>, too. I just need to switch from <code>ThreadPoolExecutor</code> to ProcessPoolExecutor. Or is this wrong?</span>
<span class="comment-copy">In theory, yes, but (a), the <code>_processes</code> attribute isn't documented and thus subject to change, and (b), after you've detected that your future is currently running and not finished, you'd have a race between the future finishing and you killing it -- if you lose, then you kill another (unrelated) task instead of the one you intended.</span>
<span class="comment-copy">AFAIK linux increases the PID for each new process, cycling if it reaches the upper limit. It is very unlikely that this will happen. But you are right: It is a race condition.</span>
<span class="comment-copy">Yes, this could work. It feels like a guy from Finland who just want to read hies mails via a dialup connection... hmmm I need an event-loop .... I need a scheduler ....and  finally its an OS.</span>
