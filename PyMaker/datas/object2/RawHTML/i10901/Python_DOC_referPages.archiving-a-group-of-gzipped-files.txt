<div class="post-text" itemprop="text">
<p>I have a group of about 10 gzipped files that I would like to archive into a single file in order for a user to download. I am wondering what the best approach to this would be.</p>
<ol>
<li>Gunzip everything, then tar-gz the complete set of files into a <code>myfiles.tar.gz</code>?</li>
<li>Tar the set of gz files into a <code>myfiles.tar</code>. </li>
</ol>
<p>Option <strong>1</strong> seems to have unnecessary steps as the original files are already compressed.</p>
<p>Option <strong>2</strong> seems confusing because there is no indication that the files inside the archive are indeed compressed.</p>
<p><strong>How do people usually deal with archiving a group of already compressed files?</strong></p>
<p>I am using Python (if it matters), but I am doing the operations via shell executions.</p>
</div>
<div class="post-text" itemprop="text">
<p>A gzipped tar archive is not an archive of compressed files. It is a compressed archive of files. In contrast, a zip archive is an archive of compressed files.</p>
<p>An archive of compressed files is a better archive format, if you want to be able to extract (or update) individual files. But it is an inferior compression technique; unless the component files are mostly quite large or already compressed, compressing the files individually results in quite a bit more overhead.</p>
<p>Since the primary use case of gzipped tar archives is transmission of complete repositories, and the entire archive is normally decompressed at once, the fact that it is not possible to decompress and extract an individual file [Note 1] is not a huge cost. On the other hand, the improved compression ratio brings a noticeable benefit.</p>
<p>To answer the question, the only way to combine multiple gzipped tar archives is to decompress all of them, combine them into a single tar archive, and then recompress the result; <strong>option 1</strong> in the original post.</p>
<h3>Notes</h3>
<ol>
<li>Of course, you can decompress the entire archive and extract a single file from the decompressed stream; it is not necessary to <em>save</em> the result of the decompression. The <code>tar</code> utility will do that transparently. But under the hood, the archive itself is being decompressed. It is not even possible to list the contents of a gzipped tar archive without decompressing the entire archive.</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>An gzipped archive of uncompressed files is definitely what your users will want.  Since you are using Python, you can skip shelling out and make things a bit cleaner (IMO).  It uses <a href="https://docs.python.org/3/library/tarfile.html#tarfile.open" rel="nofollow">tarfile</a> and <a href="https://docs.python.org/3/library/gzip.html#gzip.GzipFile" rel="nofollow">gzip.GzipFile</a> to handle the archival and compression parts.</p>
<p><em>Editorial Note: while writing this I stumbled across an interesting bug that you might want to be aware of - <a href="https://blog.nelhage.com/2010/02/a-very-subtle-bug/" rel="nofollow">https://blog.nelhage.com/2010/02/a-very-subtle-bug/</a></em></p>
<pre><code>from __future__ import with_statement  # god I hope you don't need this
import gzip
import sys
import tarfile
try:
    import io
except ImportError:  # makes things work before Python 3
    import StringIO as io

with tarfile.open(sys.argv[1], mode='w:gz') as archive:
    for name in sys.argv[2:]:
        with gzip.GzipFile(name) as gzip_file:
            buf = io.StringIO()
            buf.write(gzip_file.read())
            buf.seek(0)

            info = archive.gettarinfo(name)
            if info.name.endswith('.gz'):
                info.name = info.name[:-3]
            info.size = buf.len
            archive.addfile(info, fileobj=buf)
</code></pre>
<p>Now I probably would not do this if the uncompressed files are <em>large</em> since it is going to read each one into memory as a chunk.  This is nice in that it retains the file attributes like perms, times, and what not in the archive file.</p>
</div>
<span class="comment-copy">Option 1 would be better if you want the end-user to untar-gz once and get the required files. Option 2 would be easier method for you but the end-user will have to untar and then gunzip the individual gz files</span>
