<div class="post-text" itemprop="text">
<p>Hey I have some code in Python which is basically a World Object with Player objects. At one point the Players all get the state of the world and need to return an action. The calculations the players do are independent and only use the instance variables of the respective player instance.</p>
<pre><code>while True:
    #do stuff, calculate state with the actions array of last iteration
    for i, player in enumerate(players):
        actions[i] = player.get_action(state)
</code></pre>
<p>What is the easiest way to run the inner <code>for</code> loop parallel? Or is this a bigger task than I am assuming?</p>
</div>
<div class="post-text" itemprop="text">
<p>The most straightforward way is to use <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool.map" rel="nofollow">multiprocessing.Pool.map</a> (which works just like <code>map</code>):</p>
<pre><code>import multiprocessing
pool = multiprocessing.Pool()

def do_stuff(player):
    ...  # whatever you do here is executed in another process

while True:
    pool.map(do_stuff, players)
</code></pre>
<p>Note however that this uses multiple processes. There is no way of doing multithreading in Python due to the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">GIL</a>.</p>
<p>Usually parallelization is done with threads, which can access the same data inside your program (because they run in the same process). To share data between processes one needs to use IPC (inter-process communication) mechanisms like pipes, sockets, files etc. Which costs more resources. Also, spawning processes is much slower than spawning threads.</p>
<p>Other solutions include:</p>
<ul>
<li>vectorization: rewrite your algorithm as computations on vectors and matrices and use hardware accelerated libraries to execute it</li>
<li>using another Python distribution that doesn't have a GIL</li>
<li>implementing your piece of parallel code in another language and calling it from Python</li>
</ul>
<p>A big issue comes when your have to share data between the processes/threads. For example in your code, each task will access <code>actions</code>. If you <em>have</em> to share state, welcome to <a href="https://en.wikipedia.org/wiki/Concurrent_computing" rel="nofollow">concurrent programming</a>, a much bigger task, and one of the hardest thing to do right in software.</p>
</div>
<span class="comment-copy">Other than with <code>multiprocessing</code>?</span>
<span class="comment-copy">@IgnacioVazquez-Abrams I asked about just using the Pool Object and its map function of the multiprocessing module on IRC (freenode #python) and they told me it is not as easy as that. If you'd provide a short working example of how you are imagining that you would really help me</span>
<span class="comment-copy">Anyway -  you should just worry about making this parallel if you have your code already working  and you detect this point is a bottleneck through profiling. otherwise you are just incurring in premature optimization for something you might not need at all.</span>
<span class="comment-copy">have also a look at joblib, it is called very similarly to a simply map <a href="https://pythonhosted.org/joblib/parallel.html" rel="nofollow noreferrer">pythonhosted.org/joblib/parallel.html</a></span>
<span class="comment-copy">Thanks! What is so bad about using multiple processes?</span>
<span class="comment-copy">Multiple process wil lhave to have your global data in that other processes as well - and unless you explicitly synchrnonize that data, it will diverge.  If there is no global data, to be checked by these functions (and no large data structures to be passed into them), multiple processes will work for you.</span>
<span class="comment-copy">And in that case you could even make use of "lelo": <a href="https://pypi.python.org/pypi/lelo/1.0rc3dev" rel="nofollow noreferrer">pypi.python.org/pypi/lelo/1.0rc3dev</a></span>
<span class="comment-copy">@jsbueno Is there a way to prevent each process from copying for example the World Object? Each process actually only needs that exact one Player-Object instance and the arguments passed to get_action, no access to the other Player-Objects or the World-Object is needed and I guess it would be be an overhead if each process just copies the whole environment. Is the only way to prevent that to follow one of your other solutions?</span>
<span class="comment-copy">A nice way to "implementing your piece of parallel code in another language" is to use Cython as the "other language|" - you can write code that is mostly Python and manually free the GIL  - in that case you could use threads and take advantage of parallelism.</span>
