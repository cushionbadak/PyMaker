<div class="post-text" itemprop="text">
<p><a href="https://stackoverflow.com/questions/9518705/big-file-compression-with-python">Big file compression with python</a> gives a very nice example on how to use e.g. bz2 to compress a very large set of files (or a big file) purely in Python.</p>
<p><a href="http://www.zlib.net/pigz" rel="nofollow noreferrer">pigz</a> says you can do better by exploiting parallel compression.
To my knowledge (and Google search) insofar I cannot find a Python equivalent to do so in pure Python code.</p>
<p>Is there a parallel Python implementation for <code>pigz</code> or equivalent?</p>
</div>
<div class="post-text" itemprop="text">
<p>I don't know of a <code>pigz</code> interface for Python off-hand, but it might not be that hard to write if you really need it. <a href="https://docs.python.org/3/library/zlib.html" rel="nofollow noreferrer">Python's <code>zlib</code> module</a> allows compressing arbitrary chunks of bytes, and <a href="http://www.zlib.net/pigz/pigz.pdf" rel="nofollow noreferrer">the <code>pigz</code> man page</a> describes the system for parallelizing the compression and the output format already.</p>
<p>If you really need parallel compression, it should be possible to implement a <code>pigz</code> equivalent using <code>zlib</code> to compress chunks wrapped in <code>multiprocessing.dummy.Pool.imap</code> (<code>multiprocessing.dummy</code> is the thread-backed version of the <code>multiprocessing</code> API, so you wouldn't incur massive IPC costs sending chunks to and from the workers) to parallelize the compression. Since <code>zlib</code> is one of the few built-in modules that releases the GIL during CPU-bound work, you might actually gain a benefit from thread based parallelism.</p>
<p>Note that in practice, when the compression level isn't turned up that high, I/O is often of similar (within order of magnitude or so) cost to the actual <code>zlib</code> compression; if your data source isn't able to actually feed the threads faster than they compress, you won't gain much from parallelizing.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use the <code>flush()</code> operation with <code>Z_SYNC_FLUSH</code> to complete the last deflate block and end it on a byte boundary. You can concatenate those to make a valid deflate stream, so long as the last one you concatenate is flushed with <code>Z_FINISH</code> (which is the default for <code>flush()</code>).</p>
<p>You would also want to compute the CRC-32 in parallel (whether for zip or gzip -- I think you really mean parallel gzip compression). Python does not provide an interface to zlib's <code>crc32_combine()</code> function. However you can copy the code from zlib and convert it to Python. It will be fast enough that way, since it doesn't need to be run often. Also you can pre-build the tables you need to make it faster, or even pre-build a matrix for a fixed block length.</p>
</div>
<span class="comment-copy">The compression modules from the standard library aren't <i>pure python</i>. If you look into them, you'll see that  they're interfaces to shared libraries (which are written in C).</span>
<span class="comment-copy">And it's probably time to retire <code>gzip</code>. The new <code>zstd</code> compression is <a href="http://rsmith.home.xs4all.nl/miscellaneous/evaluating-zstandard-compression.html" rel="nofollow noreferrer">generally faster</a> than gzip and yields smaller compressed files..</span>
<span class="comment-copy">@RolandSmith: Of course, it doesn't have a Python interface either. It does seem faster than <code>gzip</code>, but there are many options for "compress faster". <code>gzip</code> sticks around at least in part thanks to compatibility concerns; you can decompress it on systems with 10+ year old hardware/software, and it's probably installed by default (<code>bz2</code> is almost as widespread, <code>xz</code> is getting there). For distributing data to many parties, portability and compression ratio are more important than speed. For transient compression, speed often beats compression ratio, so <code>lz4</code> or <code>lzo</code> might beat <code>zstd</code>.</span>
<span class="comment-copy">Basically, if you aren't bound by compatibility constraints (you can assume they have the software, and some minimal amount of RAM), you'd distributed packaged data (compressed once, decompressed many times) <code>xz</code> compressed, and use <code>lz4</code>/<code>snappy</code>/<code>lzo</code> for data that's being compressed on demand, where faster compression means the data gets there faster, with "good enough" compression.</span>
<span class="comment-copy">@RolandSmith yes that's true, what I meant was they will be Python code and not e.g. a shellex to some other binary on the filesystem.</span>
<span class="comment-copy">You don't have to send the chunks to the workers. Just let each worker read it's own chunks from the file. Or on UNIX you can create a memory mapped file for the input <i>before</i> creating the pool. The OS's virtual memory system will then do most of the heavy lifting to keep the pages of the input file in memory.</span>
<span class="comment-copy">@RolandSmith: True. I'm a big fan of <code>mmap</code> for all the things, and it looks like <code>zlib.compress</code> is buffer protocol friendly (that is, it can read from a <code>memoryview</code> of an <code>mmap</code> to avoid copying the data). You'd still want <code>imap</code> to coordinate the workers pulling blocks and organize the output (since the size of the compressed block can't be guessed ahead of time, you may as well serialize the writes).</span>
<span class="comment-copy">As for coordination, I would just create a list of  byte offsets for the start of each 128 kB block and <code>imap</code> over that. As for the output, I would probably have each compressed block written to a temporary output file and concatenate them later. Or maybe try <code>mmap</code> for that as well. Passing it back to the parent process <i>feels</i> suboptimal.</span>
<span class="comment-copy">@RolandSmith: That's why I suggested a thread pool, not a process pool. Passing it from a thread worker back to the main thread is fairly cheap, no copies involved.</span>
<span class="comment-copy">It would definitely be interesting to see which of the two approaches is fastest. :-)</span>
