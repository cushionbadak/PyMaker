<div class="post-text" itemprop="text">
<p>I'm trying to get some values(which I get using extract function) from urls which are stored in data.file and there are about 3000000 url links in the file. here is my code snippet,</p>
<pre><code>from multiprocessing import Pool
p = Pool(10)
revenuelist = p.map(extract, data.file )
</code></pre>
<p>But the problem is, due to internet connection, this is code runs again if there connection problem. How do I add fault tolerance to my code(i:e store intermediate result, to avoid repetition of doing same task).</p>
</div>
<div class="post-text" itemprop="text">
<p>A very simple solution is using a file to store your current status.  Use try...finally to handle fails:</p>
<pre><code>with open(FILENAME) as f:
    current = int(f.read() or 0)

if current:
    skip_lines(current)

try:
    with Pool() as pool:
        results = pool.imap(extract, data.file)
        for result in results:
            do_something(result)
            current += 1
finally:
    with open(FILENAME, "w") as f:
        f.write(str(current))
</code></pre>
<p>See also: <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">'concurrent.futures`</a> (much cooler than multiprocessing.Pool).</p>
<p>A better solution would be using a database to completely track your progress, and/or use a better task queue (for example, <a href="http://www.celeryproject.org/" rel="nofollow noreferrer">celery</a>) to execute your jobs.</p>
</div>
<span class="comment-copy">If the job is fetching urls, consider using threads instead of processes.</span>
<span class="comment-copy">This is kinda ugly, and that global state kills the benefits of <code>map</code>. The OP can easily transform <code>extract</code> into a total function with an optional return value and use a recursive <code>map/filter/reduce</code> strategy to separate successful and failed calls to repeat calculations for the failed (empty) cases.</span>
<span class="comment-copy">I agree this is ugly :-) Using a task queue and a database is much neater - however, if this is  some kind of batch process he runs only once, and just needs a "restart where failed" feature, this should be good enough :-)</span>
<span class="comment-copy">What do you mean in <i>"global state kills the benefits of map"?</i> the sole purpose of the map here is to use n processes instead of 1 (for 3000000 jobs), and <code>imap</code> should be good enough here.</span>
<span class="comment-copy"><code>imap</code> is usually several times slower than <code>map</code>. If the target function is relatively light, this might affect performance significantly.</span>
<span class="comment-copy">Well, the question above clearly does not need to use <code>map()</code>, since it considers tasks already run as done :-)</span>
