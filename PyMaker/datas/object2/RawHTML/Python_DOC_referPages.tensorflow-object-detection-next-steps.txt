<div class="post-text" itemprop="text">
<p>Im trying to train a model to check images, identify specified objects and tell me its coodinates (i dont even need to see an square around the object).</p>
<p>For this im using Tensorflow's object detection and most of what I did was looking this tutorial:</p>
<p><a href="https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10" rel="nofollow noreferrer">How To Train an Object Detection Classifier for Multiple Objects Using TensorFlow (GPU) on Windows 10</a></p>
<p>But some things changed, probably because of updates, and then I had to do somethings on my own. I can actually train the model (I guess) but I don't understand the evaluation results. Im used to see loss and current step but this output is unusual for me. Also I don't think the training is being saved.</p>
<h3>Training command line:</h3>
<pre><code>model_main.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_coco.config
</code></pre>
<h3>Config file:</h3>
<pre><code>model {
  faster_rcnn {
    num_classes: 9
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 600
        max_dimension: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_v2'
      first_stage_features_stride: 16
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 14
    maxpool_kernel_size: 2
    maxpool_stride: 2
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 300
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
  }
}

train_config: {
  batch_size: 5
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        manual_step_learning_rate {
          initial_learning_rate: 0.0002
          schedule {
            step: 900000
            learning_rate: .00002
          }
          schedule {
            step: 1200000
            learning_rate: .000002
          }
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: "faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt"
  from_detection_checkpoint: true
  num_steps: 50000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: "C:/tensorflow1/models/research/object_detection/images/train.record"
  }
  label_map_path: "C:/tensorflow1/models/research/object_detection/training/object-detection.pbtxt"
}

eval_config: {
  num_examples: 67
  max_evals: 10
}

eval_input_reader: {
  tf_record_input_reader {
    input_path: "C:/tensorflow1/models/research/object_detection/images/test.record"
  }
  label_map_path: "C:/tensorflow1/models/research/object_detection/training/object-detection.pbtxt"
  shuffle: false
  num_readers: 1
}
</code></pre>
<h3>Output:</h3>
<pre><code>2019-03-16 01:05:23.842424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2019-03-16 01:05:23.842528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-03-16 01:05:23.845561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0
2019-03-16 01:05:23.845777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N
2019-03-16 01:05:23.847854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6390 MB memory) -&gt; physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
creating index...
index created!
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=0.05s).
Accumulating evaluation results...
DONE (t=0.04s).
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.681
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.670
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.542
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.825
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.682
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.689
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.556
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.825
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000
</code></pre>
<p>Also the models inside <code>faster_rcnn_inception_v2_coco_2018_01_28</code> have not been changed since Jan 2018, which probably means that even if it's training, it's not saving the progress.</p>
<p>My questions are:</p>
<ul>
<li>Am I doing something wrong with the config or something else?</li>
<li>Is the training progress being saved ?</li>
<li>How can I understand this output? (IoU? maxDets? area? negative
precision? is it for a single batch or what?)</li>
<li>Should I wait for this stops by itself eventually? I cant see at
which step I am at and just this piece of output that I used as
example here took almost 15 minutes to appear.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>Wow, a lot of questions to answer here.</p>
<p>1 .I think your config file is correct, usually the fields that need to be carefully configured are:</p>
<ul>
<li><code>num_classes:</code> the number of classes of your dataset</li>
<li><code>fine_tune_checkpoint</code>: the checkpoint to start the training with if you adopt tansfer learning, this should be provided if <code>from_detection_checkpoint</code> is set true.</li>
<li><code>label_map_path</code>: path to your label file, the number of classes should be equal to <code>num_classes</code></li>
<li><code>input_path</code> in both <code>train_input_reader</code> and <code>eval_input_reader</code></li>
<li><code>num_examples</code> in <code>eval_config</code>, this is your validation dataset size, e.g. the number of examples in your validation dataset.</li>
<li><code>num_steps</code>: this is the total number of training steps to reach before the model stops training. </li>
</ul>
<p>2 Yes, your training process is being saved, it is saved at <code>train_dir</code> (if you are using the older version api, but <code>model_dir</code> if you are using the latest version), the official description is <a href="https://github.com/tensorflow/models/blob/dadc4a625d273f995f8297968859c252147029ee/research/object_detection/legacy/train.py#L70" rel="nofollow noreferrer">here</a>. You can use <code>tensorbard</code> to visualize your training process.</p>
<p>3 The output if of COCO evaluation format as this is the default evalution metric option. But you can try other evalution metrics by setting <code>metrics_set : oid_challenge_detection_metrics</code> in <code>eval_config</code> in the config file, other options are available <a href="https://github.com/tensorflow/models/blob/dadc4a625d273f995f8297968859c252147029ee/research/object_detection/eval_util.py#L41" rel="nofollow noreferrer">here</a>. For coco metrics, specifically:</p>
<ul>
<li><code>IoU</code> is <strong>Intersection over Union</strong>, this defines how much your detection bounding box overlaps with your groundtruth box. <a href="https://datascience.stackexchange.com/questions/16797/what-does-the-notation-map-5-95-mean">This</a> answer provides more details for you to understand how the precision is calculated on different IoUs.</li>
<li><code>maxDets</code> is <strong><a href="https://github.com/cocodataset/cocoapi/blob/ed842bffd41f6ff38707c4f0968d2cfd91088688/PythonAPI/pycocotools/cocoeval.py#L28" rel="nofollow noreferrer">thresholds on max detections per image</a></strong> (see <a href="https://stackoverflow.com/questions/52839368/understanding-coco-evaluation-maximum-detections">here</a> for better discussion)</li>
<li><code>area</code>, there are three categories of area, it depends the number of pixels the area takes, small, medium and large are all defined <a href="https://github.com/tensorflow/models/blob/dadc4a625d273f995f8297968859c252147029ee/research/object_detection/metrics/coco_tools.py#L210" rel="nofollow noreferrer">here</a>. </li>
<li>As for negative precision, I think this is because this is the default value if no detections are categorized as 'large' (But I cannot confirm this, you may refer to the official coco website <a href="http://cocodataset.org/#home" rel="nofollow noreferrer">http://cocodataset.org/#home</a>)</li>
<li>The evaluation is performed on the whole validation dataset, so all images in your validation set.</li>
<li><a href="http://ttps://github.com/tensorflow/models/blob/master/research/object_detection/metrics/coco_tools.py" rel="nofollow noreferrer">This</a> file provides more details on coco metrics</li>
</ul>
<p>4 The training will stop once the total number of training step is reached to <code>num_steps</code> as set in your cofig file. In your case, every 15 minutes an evaluation session is performed. Also this parameter can also be configured in the config <a href="https://github.com/tensorflow/models/blob/dadc4a625d273f995f8297968859c252147029ee/research/object_detection/protos/eval.proto#L15" rel="nofollow noreferrer">file</a>.</p>
<p>5 Although you followed the tutorial above, but I suggest follow the official API documentation <a href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="nofollow noreferrer">https://github.com/tensorflow/models/tree/master/research/object_detection</a>.</p>
<p><strong>PS: Indeed I can confirm the negative precision score is because of the absence of corresponding category. See reference in the <a href="https://github.com/cocodataset/cocoapi/blob/ed842bffd41f6ff38707c4f0968d2cfd91088688/PythonAPI/pycocotools/cocoeval.py#L335" rel="nofollow noreferrer">cocoapi</a>.</strong> </p>
</div>
<span class="comment-copy">Thanks for all the information Dany. Im going to set your answer as the right one. However, the progress it's not being saved. I defined the <code>--train_dir=training/</code> when I run the model_main.py, but, there's nothing in this folder even after the complete training. Also, is there a "save frequency" parameter in the config file?</span>
<span class="comment-copy">I'm not sure exactly which version of the API you are using. Because with the latest api, the <code>model_main.py</code> doesn't have the option '--train_dir' while the old version (in the legacy folder) does.  But the old version doesn't use 'model_main.py' as the main program, it is named 'train.py'.  Yes there is such a parameter, see <a href="https://github.com/tensorflow/models/issues/5139#issuecomment-418963839" rel="nofollow noreferrer">github.com/tensorflow/models/issues/5139#issuecomment-418963839</a> and <a href="https://github.com/tensorflow/models/issues/4636" rel="nofollow noreferrer">github.com/tensorflow/models/issues/4636</a></span>
<span class="comment-copy">I was reading the <code>model_main.py</code> file and I found out that it's not train_dir, but <code>model_dir</code></span>
