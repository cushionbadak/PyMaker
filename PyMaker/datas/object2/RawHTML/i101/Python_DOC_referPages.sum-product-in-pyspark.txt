<div class="post-text" itemprop="text">
<p>I have a pyspark dataframe like this</p>
<pre><code>data = [(("ID1", 10, 30)), (("ID2", 20, 60))]
df1 = spark.createDataFrame(data, ["ID", "colA", "colB"])
df1.show()

df1: 
+---+-----------+
| ID| colA| colB|
+---+-----------+
|ID1|   10|   30|
|ID2|   20|   60| 
+---+-----------+
</code></pre>
<p>I have Another dataframe like this</p>
<pre><code>data = [(("colA", 2)), (("colB", 5))]
df2 = spark.createDataFrame(data, ["Column", "Value"])
df2.show()

df2:
+-------+------+
| Column| Value|
+-------+------+
|   colA|     2|
|   colB|     5| 
+-------+------+
</code></pre>
<p>I want to divide every column in df1 by the respective value in df2. Hence df3 will look like</p>
<pre><code>df3: 
+---+-------------------------+
| ID|        colA|        colB|
+---+------------+------------+
|ID1|    10/2 = 5|    30/5 = 6|
|ID2|   20/2 = 10|   60/5 = 12| 
+---+------------+------------+
</code></pre>
<p>Ultimately, I want to add colA and colB to get the final df4 per ID</p>
<pre><code>df4: 
+---+---------------+
| ID|       finalSum|
+---+---------------+
|ID1|     5 + 6 = 11|
|ID2|   10 + 12 = 22| 
+---+---------------+
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The idea is to join both the DataFrames together and then apply the <code>division</code> operation. Since, <code>df2</code> contains the column names and the respective value, so we need to <a href="http://spark.apache.org/docs/2.4.0/api/python/pyspark.sql.html#pyspark.sql.GroupedData.pivot" rel="nofollow noreferrer"><code>pivot()</code></a> it first and then join with the main table <code>df1</code>. (Pivoting is an expensive operation, but it should be fine as long as the DataFrame is small.)</p>
<pre><code># Loading the requisite packages
from pyspark.sql.functions import col
from functools import reduce
from operator import add

# Creating the DataFrames
df1 = sqlContext.createDataFrame([('ID1', 10, 30), ('ID2', 20, 60)],('ID','ColA','ColB'))
df2 = sqlContext.createDataFrame([('ColA', 2), ('ColB', 5)],('Column','Value'))
</code></pre>
<p>The code is fairly generic, so that we need not need to specify the column names on our own. We find the column names we need to operate on. Except <code>ID</code> we need all.</p>
<pre><code># This contains the list of columns where we apply mathematical operations
columns_to_be_operated = df1.columns
columns_to_be_operated.remove('ID')
print(columns_to_be_operated)
    ['ColA', 'ColB']
</code></pre>
<p>Pivoting the <code>df2</code>, which we will join to <code>df1</code>.</p>
<pre><code># Pivoting the df2 to get the rows in column form
df2 = df2.groupBy().pivot('Column').sum('Value')
df2.show()
+----+----+ 
|ColA|ColB| 
+----+----+ 
|   2|   5| 
+----+----+
</code></pre>
<p>We can change the column names, so that we don't have a duplicate name for every column. We do so, by adding a suffix <code>_x</code> on all the names.</p>
<pre><code># Dynamically changing the name of the columns in df2
df2 = df2.select([col(c).alias(c+'_x') for c in df2.columns])
df2.show()
+------+------+ 
|ColA_x|ColB_x| 
+------+------+ 
|     2|     5| 
+------+------+
</code></pre>
<p>Next we join the tables with a Cartesian join. (Note that you may run into memory issues if <code>df2</code> is large.)</p>
<pre><code>df = df1.crossJoin(df2)
df.show()
+---+----+----+------+------+ 
| ID|ColA|ColB|ColA_x|ColB_x| 
+---+----+----+------+------+ 
|ID1|  10|  30|     2|     5| 
|ID2|  20|  60|     2|     5| 
+---+----+----+------+------+
</code></pre>
<p>Finally adding the columns by dividing them with the corresponding value first. <a href="https://docs.python.org/3/library/functools.html#functools.reduce" rel="nofollow noreferrer"><code>reduce()</code></a> applies function <a href="https://docs.python.org/2/library/operator.html#operator.add" rel="nofollow noreferrer"><code>add()</code></a> of two arguments, cumulatively, to the items of the sequence.</p>
<pre><code>df = df.withColumn(
    'finalSum', 
    reduce(add, [col(c)/col(c+'_x') for c in columns_to_be_operated])
).select('ID','finalSum')

df.show()
+---+--------+ 
| ID|finalSum| 
+---+--------+ 
|ID1|    11.0| 
|ID2|    22.0| 
+---+--------+
</code></pre>
<p><strong>Note:</strong> OP has to be careful with the division with 0. The snippet just above can be altered to take this condition into account.</p>
</div>
<span class="comment-copy">can you make your examples reproducible please?</span>
<span class="comment-copy">@Sotos - I have added the data</span>
