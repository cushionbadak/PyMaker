<div class="post-text" itemprop="text">
<p>I am attempting to process multiple files at once, wherein each file will generate chunks of data to feed to a queue of a certain size limit simultaneously.
For instance, if there are 5 files, containing 1 million elements each, I would like to feed 100 elements from each of them to another generator which yields 500 elements at a time.</p>
<p>Here is what I have been trying so far, but am running into the <code>can't pickle generator</code> error:</p>
<pre><code>import os
from itertools import islice
import multiprocessing as mp
import numpy as np

class File(object):
    def __init__(self, data_params):
        data_len = 100000
        self.large_data = np.array([data_params + str(i) for i in np.arange(0, data_len)])
    def __iter__(self):
        for i in self.large_data:
            yield i

def parse_file(file_path):
    # differnt filepaths yeild different data obviously
    # here we just emulate with something silly
    if file_path == 'elephant_file':
        p = File(data_params = 'elephant')
    if file_path == 'number_file':
        p = File(data_params = 'number')
    if file_path == 'horse_file':
        p = File(data_params = 'horse')


    yield from p

def parse_dir(user_given_dir, chunksize = 10):
    pool = mp.Pool(4)
    paths = ['elephant_file', 'number_file', 'horse_file'] #[os.path.join(user_given_dir, p) for p in os.listdir(user_given_dir)]

    # Works, but not simultaneously on all paths
#     for path in paths:
#         data_gen = parse_file(path)
#         parsed_data_batch = True
#         while parsed_data_batch:
#             parsed_data_batch = list(islice(data_gen, chunksize))
#             yield parsed_data_batch

    # Doesn't work
    for objs in pool.imap(parse_file, paths, chunksize = chunksize):
        for o in objs:
            yield o

it = parse_dir('.')
for ix, o in enumerate(it):
    print(o) # hopefully just prints 10 elephants, horses and numbers
    if ix&gt;2: break
</code></pre>
<p>Anyone have any idea of how to obtain the desired behavior?</p>
</div>
<div class="post-text" itemprop="text">
<ol>
<li><p>For pickle error:</p>
<p><code>parse_file</code> is a generator, not a regular function, since it uses <code>yield</code> inside.</p>
<p>And <code>multiprocessing</code> requires a function as task to execute. So you should replace <code>yield from p</code> with <code>return p</code> in <code>parse_file()</code></p></li>
<li><p>If you want fetch records in chunks from all files one by one, try using <code>zip</code> in <code>parse_dir()</code>:</p>
<pre><code>iterators = [
    iter(e) for e in pool.imap(parse_file, paths, chunksize=chunksize)
]

while True:
    batch = [
        o for i in iterators
        for _, o in zip(range(100), i)  # e.g., 100
    ]
   if batch:
        yield batch
    else:
        return
</code></pre></li>
</ol>
</div>
<span class="comment-copy">Python objects are transferred between processes through pickling-unpickling. The error says <code>can't pickle generator objects</code>. So I guess you can't transfer generators to another processes. Instead you have to turn generators into regular functions and/or create generators inside processes.</span>
<span class="comment-copy">You can't share generators between processes because they each run in their own memory-space and can't concurrently one in another process. To workaround the limitation, you may be able to derive a custom multiprocessing <code>manager</code> class as described in the multiprocessing documentation section titled <a href="https://docs.python.org/3/library/multiprocessing.html#customized-managers" rel="nofollow noreferrer">Customized managers</a>. The overview section titled <a href="https://docs.python.org/3/library/multiprocessing.html#managers" rel="nofollow noreferrer">Managers</a> says "A manager object controls a server process which manages shared objects".</span>
<span class="comment-copy">P.S. If you provide a <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a> that does nothing but use a single generator, someone may be able to show you an example of how to get one to work.</span>
<span class="comment-copy">Thank you, this is a good workaround for the code I gave. Unfortunately, I made an error in the way I represented my code. The <code>File</code> object has a handle which also cannot be serialized well, which was an oversight on my part.  Instead of simply looping over a for loop, it uses a file handle like this: <code>def __iter__(self):         for event, element in ET.iterparse(self._handle):             if event == "end" and element.tag == "Document":                 self._current_element = element                 yield self._parse_document()</code>   I will continue to try to work around this.</span>
