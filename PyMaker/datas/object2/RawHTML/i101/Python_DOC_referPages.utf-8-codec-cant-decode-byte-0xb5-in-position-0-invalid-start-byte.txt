<div class="post-text" itemprop="text">
<p>i'm trying to combine multiple CSV files into one with this Function :</p>
<pre><code>import glob

path = r'/content/drive/My Drive/DatiAirQuality/MI_Air_Quality/data' 
all_files = glob.glob(path + "/*.csv")

li = []

for filename in all_files:
    df = pd.read_csv(filename, index_col=None, header=0)
    li.append(df)

frame = pd.concat(li, axis=0, ignore_index=True)
</code></pre>
<p>but I get This Error:
'utf-8' codec can't decode byte 0xb5 in position 0: invalid start byte</p>
<p>and Here is The TraceBack:</p>
<pre><code>   8 for filename in all_files:
   ----&gt;  9     df = pd.read_csv(filename, index_col=None, 
   header=0)
   10     li.append(df)
   11 
</code></pre>
<p>Thank U.</p>
</div>
<div class="post-text" itemprop="text">
<p>I'd try: </p>
<pre><code>pd.read_csv(filename, index_col=None, header=0, encoding='utf-8') #OR
pd.read_csv(filename, index_col=None, header=0, encoding='latin1')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First you need to know the type of encoding that your CSV files use. You can try using <a href="https://pypi.org/project/chardet/" rel="nofollow noreferrer">Chardet: The Universal Character Encoding Detector</a> to predict the encoding type used in your CSV file. Chardet can be easily installed using:</p>
<pre><code>pip install chardet
</code></pre>
<p>After installing chardet you can use the command-line to predict your CSV file's encoding using:</p>
<pre><code>chardet file_name.csv
</code></pre>
<p>The output will be something like this:</p>
<pre><code>file_name.csv: UTF-8-SIG with confidence 1.0
</code></pre>
<p>Then check the encoding of your CSV file and then change the following line in your code:</p>
<pre><code>df = pd.read_csv(filename, index_col=None, header=0)
</code></pre>
<p>to:</p>
<pre><code>df = pd.read_csv(filename, index_col=None, header=0, encoding='utf-8')
</code></pre>
<p>You can check the available <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" rel="nofollow noreferrer">encodings supported by python</a>. Hopefully this should solve your issue.</p>
</div>
<div class="post-text" itemprop="text">
<p>try specifying this:</p>
<p><code>df = pd.read_csv(filename, index_col=None, header=0, encoding='latin-1')</code></p>
<p>the <code>latin-1</code> encoding is magical - it never fails. See what you get.
If this is good enough - well there you go.</p>
<p>If not, you'll have to find out what encoding the CSV files actually use. You could just try lots of different encodings until the answer seems OK.</p>
</div>
<span class="comment-copy">It looks like your file is not <code>utf-8</code>. You should find out in which encoding it was saved and decode it. Or perhaps it is not a text file at all...</span>
<span class="comment-copy">in fact it's not a text file , it contains only numerical Data.</span>
<span class="comment-copy">We can't tell you the correct encoding without seeing (a representative, ideally small sample of) the actual contents of the data in an unambiguous representation; a hex dump of the problematic byte(s) with a few bytes of context aon each side is often enough, especially if you can tell us what you think those bytes are suppored to represent. See also <a href="https://meta.stackoverflow.com/questions/379403/problematic-questions-about-decoding-errors" title="problematic questions about decoding errors">meta.stackoverflow.com/questions/379403/…</a></span>
<span class="comment-copy"><a href="https://tripleee.github.io/8bit/#b5" rel="nofollow noreferrer">tripleee.github.io/8bit/#b5</a> shows 25 possible interpretations of this byte value in different 8-bit encodings, but none of them look particularly probable or useful.</span>
<span class="comment-copy">the open() function does not figure out the file's encoding - it uses the default encoding configured for python, which in this case is utf-8.  <i>any</i> file you open will say 'utf-8', but if it's not true, there will be an exception once you try to read the file. Try it out - open some binary file like that and see what happens.</span>
<span class="comment-copy">@YoavKleinberger Thanks for the information. I edited it by adding a way to predict the encoding of the CSV file.</span>
<span class="comment-copy"><code>chardet</code> is not entriely reliable, it uses heuristics and doesn't examine the entire input file.</span>
<span class="comment-copy">@tripleee Agreed. It can just PREDICT with a confidence. So I do not expect it to be 100% accurate. Other than using chardet, we should check all possible encodings manually until we find one that work. I would love to know a robust solution in case you have one.</span>
<span class="comment-copy">There is no way to know the encoding unless you also know what it is supposed to represent. See e.g. <a href="https://stackoverflow.com/questions/436220/how-to-determine-the-encoding-of-text" title="how to determine the encoding of text">stackoverflow.com/questions/436220/…</a></span>
<span class="comment-copy">The problem with this is that it looks like it succeeds even if the results are completely bogus.</span>
<span class="comment-copy">@tripleee you're correct, perhaps I wasn't clear enough in how I described my suggestion. It's supposed to be a work-around, not a true solution</span>
