<div class="post-text" itemprop="text">
<p>I'm running a program which is processing 30,000 similar files. A random number of them are stopping and producing this error...</p>
<pre><code>   File "C:\Importer\src\dfman\importer.py", line 26, in import_chr
     data = pd.read_csv(filepath, names=fields)
   File "C:\Python33\lib\site-packages\pandas\io\parsers.py", line 400, in parser_f
     return _read(filepath_or_buffer, kwds)
   File "C:\Python33\lib\site-packages\pandas\io\parsers.py", line 205, in _read
     return parser.read()
   File "C:\Python33\lib\site-packages\pandas\io\parsers.py", line 608, in read
     ret = self._engine.read(nrows)
   File "C:\Python33\lib\site-packages\pandas\io\parsers.py", line 1028, in read
     data = self._reader.read(nrows)
   File "parser.pyx", line 706, in pandas.parser.TextReader.read (pandas\parser.c:6745)
   File "parser.pyx", line 728, in pandas.parser.TextReader._read_low_memory (pandas\parser.c:6964)
   File "parser.pyx", line 804, in pandas.parser.TextReader._read_rows (pandas\parser.c:7780)
   File "parser.pyx", line 890, in pandas.parser.TextReader._convert_column_data (pandas\parser.c:8793)
   File "parser.pyx", line 950, in pandas.parser.TextReader._convert_tokens (pandas\parser.c:9484)
   File "parser.pyx", line 1026, in pandas.parser.TextReader._convert_with_dtype (pandas\parser.c:10642)
   File "parser.pyx", line 1046, in pandas.parser.TextReader._string_convert (pandas\parser.c:10853)
   File "parser.pyx", line 1278, in pandas.parser._string_box_utf8 (pandas\parser.c:15657)
 UnicodeDecodeError: 'utf-8' codec can't decode byte 0xda in position 6: invalid    continuation byte
</code></pre>
<p>The source/creation of these files all come from the same place. What's the best way to correct this to proceed with the import?</p>
</div>
<div class="post-text" itemprop="text">
<p><code>read_csv</code> takes an <code>encoding</code> option to deal with files in different formats. I mostly use <code>read_csv('file', encoding = "ISO-8859-1")</code>, or alternatively <code>encoding = "utf-8"</code> for reading, and generally <code>utf-8</code> for <code>to_csv</code>.</p>
<p>You can also use one of several <code>alias</code> options like <code>'latin'</code> instead of <code>'ISO-8859-1'</code> (see <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" rel="noreferrer">python docs</a>, also for numerous other encodings you may encounter).</p>
<p>See <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" rel="noreferrer">relevant Pandas documentation</a>,
<a href="http://docs.python.org/3/library/csv.html#examples" rel="noreferrer">python docs examples on csv files</a>, and plenty of related questions here on SO.</p>
<p>To detect the encoding (assuming the file contains non-ascii characters), you can use <code>enca</code> (see <a href="https://linux.die.net/man/1/enconv" rel="noreferrer">man page</a>) or <code>file -i</code> (linux) or <code>file -I</code> (osx) (see <a href="https://linux.die.net/man/1/file" rel="noreferrer">man page</a>). </p>
</div>
<div class="post-text" itemprop="text">
<p><strong>Simplest of all Solutions:</strong></p>
<ul>
<li>Open the csv file in <em>Sublime text editor</em>.</li>
<li>Save the file in utf-8 format.</li>
</ul>
<blockquote>
<p>In sublime, Click File -&gt; Save with encoding -&gt; UTF-8</p>
</blockquote>
<p>Then, you can read your file as usual:</p>
<pre><code>import pandas as pd
data = pd.read_csv('file_name.csv', encoding='utf-8')
</code></pre>
<p><strong>EDIT 1:</strong></p>
<p>If there are many files, then you can skip the sublime step.</p>
<p>Just read the file using</p>
<pre><code>data = pd.read_csv('file_name.csv', encoding='utf-8')
</code></pre>
<p>and the other different encoding types are:</p>
<pre><code>encoding = "cp1252"
encoding = "ISO-8859-1"
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Pandas allows to specify encoding, but does not allow to ignore errors not to automatically replace the offending bytes. So there is no <em>one size fits all</em> method but different ways depending on the actual use case.</p>
<ol>
<li><p>You know the encoding, and there is no encoding error in the file. 
Great: you have just to specify the encoding:</p>
<pre><code>file_encoding = 'cp1252'        # set file_encoding to the file encoding (utf8, latin1, etc.)
pd.read_csv(input_file_and_path, ..., encoding=file_encoding)
</code></pre></li>
<li><p>You do not want to be bothered with encoding questions, and only want that damn file to load, no matter if some text fields contain garbage. Ok, you only have to use <code>Latin1</code> encoding because it accept any possible byte as input (and convert it to the unicode character of same code):</p>
<pre><code>pd.read_csv(input_file_and_path, ..., encoding='latin1')
</code></pre></li>
<li><p>You know that most of the file is written with a specific encoding, but it also contains encoding errors. A real world example is an UTF8 file that has been edited with a non utf8 editor and which contains some lines with a different encoding. Pandas has no provision for a special error processing, but Python <code>open</code> function has (assuming Python3), and <code>read_csv</code> accepts a file like object. Typical errors parameter to use here are <code>'ignore'</code> which just suppresses the offending bytes or (IMHO better) <code>'backslashreplace'</code> which replaces the offending bytes by their Python’s backslashed escape sequence:</p>
<pre><code>file_encoding = 'utf8'        # set file_encoding to the file encoding (utf8, latin1, etc.)
input_fd = open(input_file_and_path, encoding=file_encoding, errors = 'backslashreplace')
pd.read_csv(input_fd, ...)
</code></pre></li>
</ol>
</div>
<div class="post-text" itemprop="text">
<pre><code>with open('filename.csv') as f:
   print(f)
</code></pre>
<p>after executing this code you will find encoding of 'filename.csv' then execute code as following</p>
<pre><code>data=pd.read_csv('filename.csv', encoding="encoding as you found earlier"
</code></pre>
<p>there you go</p>
</div>
<div class="post-text" itemprop="text">
<p>Struggled with this a while and thought I'd post on this question as it's the first search result.  Adding the encoding='iso-8859-1" tag to pandas read_csv didn't work, nor did any other encoding, kept giving a UnicodeDecodeError. </p>
<p>If you're passing a file handle to pd.read_csv(), you need to put the encoding= attribute on the file open, not in read_csv. Obvious in hindsight, but a subtle error to track down.</p>
</div>
<div class="post-text" itemprop="text">
<p>This answer seems to be the catch-all for CSV encoding issues. If you are getting a strange encoding problem with your header like this:</p>
<pre><code>&gt;&gt;&gt; f = open(filename,"r")
&gt;&gt;&gt; reader = DictReader(f)
&gt;&gt;&gt; next(reader)
OrderedDict([('\ufeffid', '1'), ... ])
</code></pre>
<p>Then you have a byte order mark (BOM) character at the beginning of your CSV file. This answer addresses the issue:</p>
<p><a href="https://stackoverflow.com/questions/40310042/python-read-csv-bom-embedded-into-the-first-key">Python read csv - BOM embedded into the first key</a></p>
<p>The solution is to load the CSV with <code>encoding="utf-8-sig"</code>:</p>
<pre><code>&gt;&gt;&gt; f = open(filename,"r", encoding="utf-8-sig")
&gt;&gt;&gt; reader = DictReader(f)
&gt;&gt;&gt; next(reader)
OrderedDict([('id', '1'), ... ])
</code></pre>
<p>Hopefully this helps someone.</p>
</div>
<div class="post-text" itemprop="text">
<p>In my case, a file has "USC-2 LE BOM" encoding, according to Notepad++. 
It is encoding="utf_16_le" for python. </p>
<p>Hope, it helps to find an answer a bit faster for someone.</p>
</div>
<div class="post-text" itemprop="text">
<p>I am posting an update to this old thread. I found one solution that worked, but requires opening each file. I opened my csv file in LibreOffice, chose Save As &gt; edit filter settings. In the drop-down menu I chose UTF8 encoding. Then I added <code>encoding="utf-8-sig"</code> to the <code>data = pd.read_csv(r'C:\fullpathtofile\filename.csv', sep = ',', encoding="utf-8-sig")</code>.</p>
<p>Hope this helps someone.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try specifying the engine='python'. 
It worked for me but I'm still trying to figure out why.</p>
<pre><code>df = pd.read_csv(input_file_path,...engine='python')
</code></pre>
</div>
<span class="comment-copy">Thank you, Stefan! I added <code>encoding = "ISO-8859-1"</code> and they imported perfectly.</span>
<span class="comment-copy">Since this is a Windows issue, <code>cp1252</code> might be preferrable to <code>iso-8859-1</code>.</span>
<span class="comment-copy"><code>Encoding = "ISO-8859-1"</code> worked for me as well. Thanks.</span>
<span class="comment-copy">Thanks <code>pd.read_csv('immigration.csv', encoding = "ISO-8859-1", engine='python')</code> worked for me</span>
<span class="comment-copy">Don't blindly assume a certain encoding is the right one just because no exception is thrown. You need to look at the strings and figure out whether the interpretation makes sense. For example, if you get "hors d’½uvre" instead of "hors d’œuvre" you probably need to switch from ISO-8859-1 to ISO-8859-15.</span>
<span class="comment-copy">The question explains that there are 30,000 such files. Opening each file manually would not be practical.</span>
<span class="comment-copy">well at least for one file, this seemed to work for me!</span>
<span class="comment-copy">Late answer, but targetted at a <a href="https://stackoverflow.com/q/51762885/3545273">duplicate question</a>...</span>
<span class="comment-copy">Nisse, thanks for the edit. Can you please explain what you changed? I don't see a difference.</span>
