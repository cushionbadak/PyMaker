<div class="post-text" itemprop="text">
<p>I've read all of the articles I could find, even understood a few of them but as a Python newb I'm still a little lost and hoping for help :)</p>
<p>I'm working on a script to parse items of interest out of an application specific log file, each line begins with a time stamp which I can match and I can define two things to identify what I want to capture, some partial content and a string that will be the termination of what I want to extract.</p>
<p>My issue is multi-line, in most cases every log line is terminated with a newline but some entries contain SQL that may have new lines within it and therefore creates new lines in the log.</p>
<p>So, in a simple case I may have this:</p>
<pre><code>[8/21/13 11:30:33:557 PDT] 00000488 SystemOut     O 21 Aug 2013 11:30:33:557 [WARN] [MXServerUI01] [CID-UIASYNC-17464] BMXAA6720W - USER = (ABCDEF) SPID = (2526) app (ITEM) object (ITEM) : select * from item  where ((status != 'OBSOLETE' and itemsetid = 'ITEMSET1') and (exists (select 1 from maximo.invvendor where (exists (select 1 from maximo.companies where (( contains(name,'  $AAAA  ') &gt; 0 )) and (company=invvendor.manufacturer and orgid=invvendor.orgid))) and (itemnum = item.itemnum and itemsetid = item.itemsetid)))) and (itemtype in (select value from synonymdomain where domainid='ITEMTYPE' and maxvalue = 'ITEM')) order by itemnum asc  (execution took 2083 milliseconds)
</code></pre>
<p>This all appears as one line which I can match with this:</p>
<pre><code>re.compile('\[(0?[1-9]|[12][0-9]|3[01])(\/)(0?[1-9]|[12][0-9]|3[01])(\/)([0-9]{2}).*(milliseconds)')
</code></pre>
<p>However in some cases there may be line breaks in the SQL, as such I want to still capture it (and potentially replace the line breaks with spaces). I am currently reading the file a line at a time which obviously isn't going to work so...</p>
<ol>
<li>Do I need to process the whole file in one go? They are typically 20mb in size. How do I read the entire file and iterate through it looking for single or multi-line blocks?</li>
<li>How would I write a multi-line RegEx that would match either the whole thing on one line or of it is spread across multiple lines?</li>
</ol>
<p>My overall goal is to parameterize this so I can use it for extracting log entries that match different patterns of the starting string (always the start of a line), the ending string (where I want to capture to) and a value that is between them as an identifier.</p>
<p>Thanks in advance for any help!</p>
<p>Chris.</p>
<pre><code>import sys, getopt, os, re

sourceFolder = 'C:/MaxLogs'
logFileName = sourceFolder + "/Test.log"
lines = []
print "--- START ----"
lineStartsWith = re.compile('\[(0?[1-9]|[12][0-9]|3[01])(\/)(0?[1-9]|[12][0-9]|3[01])(\/)([0-9]{2})(\ )')
lineContains = re.compile('.*BMXAA6720W.*')
lineEndsWith = re.compile('(?:.*milliseconds.*)')

lines = []
with open(logFileName, 'r') as f:
    for line in f:
        if lineStartsWith.match(line) and lineContains.match(line):
            if lineEndsWith.match(line) :
                print 'Full Line Found'
                print line
                print "- Record Separator -"
            else:
                print 'Partial Line Found'
                print line
                print "- Record Separator -"

print "--- DONE ----"
</code></pre>
<p>Next step, for my partial line I'll continue reading until I find lineEndsWith and assemble the lines in to one block.</p>
<p>I'm no expert so suggestions are always welcome!</p>
<p>UPDATE - So I have it working, thanks to all the responses that helped direct things, I realize it isn't pretty and I need to clean up my if / elif mess and make it more efficient but IT's WORKING! Thanks for all the help.</p>
<pre><code>import sys, getopt, os, re

sourceFolder = 'C:/MaxLogs'
logFileName = sourceFolder + "/Test.log"

print "--- START ----"

lineStartsWith = re.compile('\[(0?[1-9]|[12][0-9]|3[01])(\/)(0?[1-9]|[12][0-9]|3[01])(\/)([0-9]{2})(\ )')
lineContains = re.compile('.*BMXAA6720W.*')
lineEndsWith = re.compile('(?:.*milliseconds.*)')

lines = []

multiLine = False

with open(logFileName, 'r') as f:
    for line in f:
        if lineStartsWith.match(line) and lineContains.match(line) and lineEndsWith.match(line):
            lines.append(line.replace("\n", " "))
        elif lineStartsWith.match(line) and lineContains.match(line) and not multiLine:
            #Found the start of a multi-line entry
            multiLineString = line
            multiLine = True
        elif multiLine and not lineEndsWith.match(line):
            multiLineString = multiLineString + line
        elif multiLine and lineEndsWith.match(line):
            multiLineString = multiLineString + line
            multiLineString = multiLineString.replace("\n", " ")
            lines.append(multiLineString)
            multiLine = False

for line in lines:
    print line
</code></pre>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>Do I need to process the whole file in one go? They are typically 20mb in size. How do I read the entire file and iterate through it looking for single or multi-line blocks?</p>
</blockquote>
<p>There are two options here.</p>
<p>You could read the file block by block, making sure to attach any "leftover" bit at the end of each block to the start of the next one, and search each block. Of course you will have to figure out what counts as "leftover" by looking at what your data format is and what your regex can match, and in theory it's possible for multiple blocks to all count as leftover…</p>
<p>Or you could just <a href="http://docs.python.org/3/library/mmap.html" rel="nofollow"><code>mmap</code></a> the file. An mmap acts like a bytes (or like a str in Python 2.x), and leaves it up to the OS to handle paging blocks in and out as necessary. Unless you're trying to deal with absolutely huge files (gigabytes in 32-bit, even more in 64-bit), this is trivial and efficient:</p>
<pre><code>with open('bigfile', 'rb') as f:
    with mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_READ) as m:
        for match in compiled_re.finditer(m):
            do_stuff(match)
</code></pre>
<p>In older versions of Python, <code>mmap</code> isn't a context manager, so you'll need to wrap <code>contextlib.closing</code> around it (or just use an explicit <code>close</code> if you prefer).</p>
<hr/>
<p>How would I write a multi-line RegEx that would match either the whole thing on one line or of it is spread across multiple lines?</p>
<p>You could use the <a href="http://docs.python.org/3/library/re.html#re.DOTALL" rel="nofollow"><code>DOTALL</code></a> flag, which makes the <code>.</code> match newlines. You could instead use the <a href="http://docs.python.org/3/library/re.html#re.MULTILINE" rel="nofollow"><code>MULTILINE</code></a> flag and put appropriate <code>$</code> and/or <code>^</code> characters in, but that makes simple cases a lot harder, and it's rarely necessary. Here's an example with <code>DOTALL</code> (using a simpler regexp to make it more obvious):</p>
<pre><code>&gt;&gt;&gt; s1 = """[8/21/13 11:30:33:557 PDT] 00000488 SystemOut     O 21 Aug 2013 11:30:33:557 [WARN] [MXServerUI01] [CID-UIASYNC-17464] BMXAA6720W - USER = (ABCDEF) SPID = (2526) app (ITEM) object (ITEM) : select * from item  where ((status != 'OBSOLETE' and itemsetid = 'ITEMSET1') and (exists (select 1 from maximo.invvendor where (exists (select 1 from maximo.companies where (( contains(name,'  $AAAA  ') &gt; 0 )) and (company=invvendor.manufacturer and orgid=invvendor.orgid))) and (itemnum = item.itemnum and itemsetid = item.itemsetid)))) and (itemtype in (select value from synonymdomain where domainid='ITEMTYPE' and maxvalue = 'ITEM')) order by itemnum asc  (execution took 2083 milliseconds)"""
&gt;&gt;&gt; s2 = """[8/21/13 11:30:33:557 PDT] 00000488 SystemOut     O 21 Aug 2013 11:30:33:557 [WARN] [MXServerUI01] [CID-UIASYNC-17464] BMXAA6720W - USER = (ABCDEF) SPID = (2526) app (ITEM) object (ITEM) : select * from item  where ((status != 'OBSOLETE' and itemsetid = 'ITEMSET1') and 
    (exists (select 1 from maximo.invvendor where (exists (select 1 from maximo.companies where (( contains(name,'  $AAAA  ') &gt; 0 )) and (company=invvendor.manufacturer and orgid=invvendor.orgid))) and (itemnum = item.itemnum and itemsetid = item.itemsetid)))) and (itemtype in (select value from synonymdomain where domainid='ITEMTYPE' and maxvalue = 'ITEM')) order by itemnum asc  (execution took 2083 milliseconds)"""
&gt;&gt;&gt; r = re.compile(r'\[(.*?)\].*?milliseconds\)', re.DOTALL)
&gt;&gt;&gt; r.findall(s1)
['8/21/13 11:30:33:557 PDF']
&gt;&gt;&gt; r.findall(s2)
['8/21/13 11:30:33:557 PDF']
</code></pre>
<p>As you can see the second <code>.*?</code> matched the newline just as easily as a space.</p>
<p>If you're just trying to treat a newline as whitespace, you don't need either; <code>'\s'</code> already catches newlines.</p>
<p>For example:</p>
<pre><code>&gt;&gt;&gt; s1 = 'abc def\nghi\n'
&gt;&gt;&gt; s2 = 'abc\ndef\nghi\n'
&gt;&gt;&gt; r = re.compile(r'abc\s+def')
&gt;&gt;&gt; r.findall(s1)
['abc def']
&gt;&gt;&gt; r.findall(s2)
['abc\ndef']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can read an entire file into a string and then you can use re.split to make a list of all the entries separated by times. Here's an example:</p>
<pre><code>f = open(...)
allLines = ''.join(f.readlines())
entries = re.split(regex, allLines)
</code></pre>
</div>
<span class="comment-copy">Have you tried using the <code>re.DOTALL</code> flag? You'll have to make the <code>.*</code> part lazy (<code>.*?</code>) as a consequence of this though and since you're reading line by line, it will work if you read the whole file at one go. I'm not sure about the memory/performance implications however.</span>
<span class="comment-copy">You could try reading the whole file and then splitting the text with a regex that matches timestamps directly after newlines. That should get you a list of contiguous single log messages, unless your users are embedding things like <code>"\n[8/21/13 11:30:33:557 PDT]"</code> into their SQL... in which case you've probably got some other problems.</span>
<span class="comment-copy">I'm starting to wonder now whether I'd be better off going back to line by line such that I read a line at a time, if the line matches my "start" and "contains" values I have a match which I then need to check for the "end" marker or, if it isn't there keep reading and appending lines until I find it. I think I'm fortunate in that I know the start and end will always be there, I just have to look for them.</span>
<span class="comment-copy">Well, if you already know how to delimit your entries, writing a simple wrapper that reads from a file and yields entries (or any equivalent design—this is basically what network protocol code does, so you can find all the options in server example code) is pretty easy. See <a href="http://pastebin.com/HNntjpam" rel="nofollow noreferrer">here</a> for an example; just replace the <code>split('\0')</code> with the appropriate code to delimit your chunks. (You can make this briefer, but the way I wrote it is probably easiest to understand for novices.)</span>
<span class="comment-copy">I realize this might not be optimal but this is where I'm headed for the moment, I believe each category of line I'll want to extract can be identified by a starting string, and ending string and some specific pattern within the line (which will always be on the same line as the starting string). As such I'm experimenting (and learning) like this:</span>
<span class="comment-copy">Nice tip about using mmap to memory map huge files</span>
<span class="comment-copy">He's specifically asked how to avoid reading the whole file in as a string. So presumably he already knows that's possible, and wants to know what the alternatives is.</span>
<span class="comment-copy">I don't see that explicitly mentioned anywhere. The files are 20 MB, which is a joke to read in a single go.</span>
