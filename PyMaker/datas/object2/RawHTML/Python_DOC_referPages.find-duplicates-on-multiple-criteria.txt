<div class="post-text" itemprop="text">
<p>I have a set of financial transactions with a <em>Date</em>, <em>Amount</em>, <em>Description</em> and <em>Source</em> and I want to find transactions where the amount is the same, the date is within one day, but the sources are different. The source should be different because the transactions are an import from many sources and each source has unique entries.</p>
<p>For example, I would want to find that row 1 and 3 are duplicates:</p>
<pre><code>'date','amount','description','source'
1/5/2018, 5.28, 'McDonalds', 'BankOfAmerica'
1/6/2018, 8.44, 'Starbucks', 'BankOfAmerica'
1/5/2018, 5.28, 'McDonalds Rest', 'BoA'
2/10/2018, 22.72, 'Chipolte', 'Chase'
3/10/2018, 4.58, 'Wendys', 'BoA'
</code></pre>
<p>I tried in Python and I can find duplicates with:</p>
<pre><code>df_no_dups = df.drop_duplicates(subset=['amount','dates'])
df_dups = df[~df.isin(df_no_dups)].dropna()
</code></pre>
<p>but this is an exact date match and then I have to run another script to make sure the sources were different.</p>
<p>I also tried to <em>groupby</em> amounts and then iterate inside those to find where dates are close and sources are different, but I couldn't figure out the details of groups.</p>
<p>Other approaches could be with SQL or in the spreadsheet (google) where the transactions are.</p>
</div>
<div class="post-text" itemprop="text">
<p>use exists</p>
<pre><code>select t1.* from table_name t1
where exists( select 1 from table_name t2 
             where t2.date=t1.date and t2.amount=t1.amount and t1.source&lt;&gt;t2.source)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Consider the following data(added a row in row 3 for better understanding)</p>
<pre><code>data = pd.compat.StringIO("""5 Jan, 5.28, 'McDonalds', 'BankOfAmerica'
6 Jan, 8.44, 'Starbucks', 'BankOfAmerica'
5 Jan, 5.28, 'McDonalds Rest', 'BoA'
5 Jan, 5.28, 'McDonalds Rest', 'BankOfAmerica'
10 Feb, 22.72, 'Chipolte', 'Chase'""")
df = pd.read_csv(data,header=None)
df.columns=['Date','Amount','Dscription','Source']
print(df)

 Date  Amount         Dscription            Source
0   5 Jan    5.28        'McDonalds'   'BankOfAmerica'
1   6 Jan    8.44        'Starbucks'   'BankOfAmerica'
2   5 Jan    5.28   'McDonalds Rest'             'BoA'
3   5 Jan    5.28   'McDonalds Rest'   'BankOfAmerica'
4  10 Feb   22.72         'Chipolte'           'Chase'
</code></pre>
<p>For duplicates and different sources:</p>
<pre><code>df_dups =df[df.duplicated(['Date','Amount'],keep=False)]
df_dups =df_dups.drop_duplicates(['Date','Amount','Source'],keep=False)
print(df_dups)


    Date  Amount         Dscription            Source
0  5 Jan    5.28        'McDonalds'   'BankOfAmerica'
2  5 Jan    5.28   'McDonalds Rest'             'BoA'
</code></pre>
<hr/>
<p>For no dups( pulling all the other rows basically <code>df</code>-<code>df_dup</code>):</p>
<pre><code>no_dups=df.loc[~df.index.isin(df_dups.index)]
print(no_dups)

     Date    Amount      Dscription            Source
1   6 Jan    8.44        'Starbucks'   'BankOfAmerica'
3   5 Jan    5.28   'McDonalds Rest'   'BankOfAmerica'
4  10 Feb   22.72         'Chipolte'           'Chase'
</code></pre>
</div>
<span class="comment-copy">can you make a <a href="https://stackoverflow.com/questions/20109391/how-to-make-good-reproducible-pandas-examples">reproducible</a> example please, so we can replicate the question. Thanks</span>
<span class="comment-copy">@anky_91 does that help?</span>
<span class="comment-copy">yes, thank you, here the source column is the 3rd or 4th?</span>
<span class="comment-copy">@anky_91 -- fourth -- I'll add headers</span>
<span class="comment-copy">wow -- this is pretty strait forward -- thanks -- and I could use a datediff function or something on that first = if I wanted dates to differ by a day</span>
<span class="comment-copy">any idea about if dates differ by a day?</span>
<span class="comment-copy">I mean if the date is 5-Jan and 6-Jan but the sources are different and the amounts are the same, then it is still a duplicate because the financial records are sometime off by a day.</span>
<span class="comment-copy">wait! this doesn't work. the second step just removes all those with duplicate sources.</span>
<span class="comment-copy">@bonhoffer my bad, missed to insert date while dropping dups: use <code>df_dups =df_dups.drop_duplicates(['Date','Source'])</code> edited the answer</span>
<span class="comment-copy">So the approach is going to remove lots of duplicates just because they share a common source.</span>
