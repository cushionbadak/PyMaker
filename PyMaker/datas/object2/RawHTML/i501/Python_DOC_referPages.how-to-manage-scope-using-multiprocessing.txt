<div class="post-text" itemprop="text">
<p>I'm trying to implement a function that uses python <code>multiprocessing</code> in order to speed-up a calculation. I'm trying to create a pairwise distance matrix but the implementation with for loops takes more than 8 hours.</p>
<p>This code seems to work faster but when I print the matrix is full of zeros. When I print the rows in the function it seems to work. I think is a scope problem but I cannot understand how to deal with it.</p>
<pre><code>import multiprocessing
import time
import numpy as np

def MultiProcessedFunc(i,x):
    for j in range(i,len(x)):
        time.sleep(0.08)
        M[i,j] = (x[i]+x[j])/2
    print(M[i,:]) # Check if the operation works
    print('')

processes = []

v = [x+1 for x in range(8000)]
M = np.zeros((len(v),len(v)))

for i in range(len(v)):
    p = multiprocessing.Process(target = MultiProcessedFunc, args =(i,v))
    processes.append(p)
    p.start()

for process in processes:
    process.join()
end = time.time()

print('Multiprocessing: {}'.format(end-start))
print(M)

</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Unfortunately your code wont work written in that way. Multiprocessing spawn separate <strong>processes</strong>, which means that <em>the memory space are separate</em>! Changes made by one subprocess will not be reflected in the other processes or your parent processes.</p>
<p>Strictly speaking this is not a scoping issue. Scope is something defined inside a single interpreter process.</p>
<p>The module <a href="https://docs.python.org/3/library/multiprocessing.html#shared-ctypes-objects" rel="nofollow noreferrer">does provide means of sharing memory between processes</a> but this comes at a cost (shared memory is way slower due to locking issues and such.</p>
<p>Now, numpy has a nice feature: <a href="https://stackoverflow.com/questions/6200437/numpy-and-global-interpreter-lock">it releases the GIL during computation</a>. This means that using multi <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer"><code>threading</code></a> instead of <code>multiprocessing</code> should give you some benefit with little other changes to your code, simply replace <code>import multiprocessing</code> with <code>import threading</code> and <code>multiprocessing.Process</code> into <code>threading.Thread</code>. The code should produce the correct result. On my machine, removing the print statements and the <code>sleep</code> code it runs in under 8 seconds:</p>
<pre><code>Multiprocessing: 7.48570203781
[[1.000e+00 1.000e+00 2.000e+00 ... 3.999e+03 4.000e+03 4.000e+03]
 [0.000e+00 2.000e+00 2.000e+00 ... 4.000e+03 4.000e+03 4.001e+03]
 [0.000e+00 0.000e+00 3.000e+00 ... 4.000e+03 4.001e+03 4.001e+03]
 ...
 [0.000e+00 0.000e+00 0.000e+00 ... 7.998e+03 7.998e+03 7.999e+03]
 [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 7.999e+03 7.999e+03]
 [0.000e+00 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 8.000e+03]]
</code></pre>
<p>An alternative is to have your subprocesses <em>return</em> the result and then combine the results in your main process.</p>
</div>
<span class="comment-copy">Note that if what you are after is just a pair-wise euclidean distance, <a href="https://stackoverflow.com/a/47775357/42610">stackoverflow.com/a/47775357/42610</a> will give you much faster code.</span>
<span class="comment-copy">Definitely could use a shared memory array from <code>multiprocessing</code>, but this is a classic case for rewrite as a <code>numpy</code> array (as you indicate).</span>
<span class="comment-copy">@MikeMcKerns Yes, the multiprocessing array provides no vector operations, which means it would be <i>way</i> slower.</span>
<span class="comment-copy">The problem is that in the original program I do not have a list with numbers but a list with strings and I cannot use numpy for it</span>
<span class="comment-copy">Also the sleep part is ment to emulate what happen in the real code</span>
<span class="comment-copy">@GiuseppeMinardi Using numbers vs strings almost always require different approaches. Without the details we cannot give you better advice than what I wrote: if you need shared memory you have to use the <code>multiprocessing</code> api, the alternative is to use <code>multiprocessing.Pool</code> methods to return the results and combine them afterwards. Which one works better depends on what you are going to do and you will probably have to profile the two solutions to see which one is better in your case.</span>
