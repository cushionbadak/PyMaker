<div class="post-text" itemprop="text">
<p><em>I have asked this question about a month ago. However, no one gave an answer or even comment.I am repeating the question so that someone would help this time.</em></p>
<p>I have a large Unicode Monolingual corpus consists over 100 million words in a txt file of size 1.7GB. Now I need to find the word frequency of each word in that corpus so that I can find 20 most frequent words and 20 Least frequent words in the corpus. Such as,(the example is given in Swedish instead of Bengali for easy understanding) </p>
<p><strong>Corpus:</strong> </p>
<blockquote>
<p>jag har ett stort hus också jag har ett stort fält jag.</p>
</blockquote>
<p><strong>Word Frequency:</strong></p>
<blockquote>
<p>jag 3</p>
<p>har 2</p>
<p>ett 2</p>
<p>stort 2</p>
<p>hus 1</p>
<p>fält  1</p>
</blockquote>
<p><strong>Desicion:</strong></p>
<blockquote>
<p>most frequent:</p>
<p>jag 3</p>
<p>har 2</p>
<p>Least frequent:</p>
<p>hus 1</p>
<p>fält  1</p>
</blockquote>
<p><strong>BUT,</strong> when I have tried to use a mysql database to store new words from corpus and increase its freqeuncy each time by one. so that finally I can get the words with their frequency. however, it took 2 days to complete even 10% of the corpus. I have tried another way by keeping a txt file to keep a record about the frequency of each word. However it fails due to the system doesn't work for unicode words. Please suggest me a easy and fast way to count to this ( Can be in PHP or PYTHON).</p>
</div>
<div class="post-text" itemprop="text">
<p>In python, the simplest way is to use <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer">collections.Counter</a> to create a counter object. I timed it out using a (very limited) 200,000 word corpus</p>
<pre><code>from collections import Counter

x='jag har ett stort hus också jag har ett stort fält jag cat rat bat cat bar baz cat jag '

x=x*10000

%timeit c=Counter(x.split())

49.4 ms ± 7.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

c.most_common(5)
[('jag', 40000),
 ('cat', 30000),
 ('har', 20000),
 ('ett', 20000),
 ('stort', 20000)]
</code></pre>
<p>That being said, &gt;100 million words is just going to be a very very large task, and I would expect to run into memory and time issues. I would expect that you would have better luck operating on partial chunks of your data at a time.</p>
<p>You may also look into multiprocessing</p>
</div>
