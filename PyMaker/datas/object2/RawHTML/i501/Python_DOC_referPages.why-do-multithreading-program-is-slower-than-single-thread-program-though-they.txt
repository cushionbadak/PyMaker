<div class="post-text" itemprop="text">
<p>I have several txt files which contains CDR information, CDRs are distributed within several files. I need to find phone maches in these files, than check the matches vs xls file. I wrote single thread version, then multithread and found that sometimers multithread is slower than single thread.</p>
<p>Multithread:</p>
<pre><code>import re
import os
import time
import sys
import pandas
import ipaddress
import threading


def improve_view_n(string_to_improve):
    string_to_improve = string_to_improve.split(',')
    improved_string = ""
    for i in string_to_improve:
        if i != "":
            improved_string = improved_string + i + "  "
    return improved_string


def upload_number_list():
    numbers = []
    try:
        with open(file="number_list.txt", mode="r") as f:
            for i in f:
                numbers.append(i.strip("\\\n"))
    except FileNotFoundError:
        print("number_list.txt file does not exist or corrupted.\n\n")
        print("The program will be terminated in 5 seconds")
        time.sleep(5)
        sys.exit()
    return numbers


def search_for_pattern(number, file_name, semaphore, found_ip):
    semaphore.acquire()
    if file_name.startswith("MSK"):
        with open(file=file_name, mode='r') as f:
            text_of_file = f.read()
            results = re.findall(pattern=f",,,,,.*{number}.*,", string=text_of_file)
            if results:
                for element in results:
                    write_searh_results_to_file(file_name, element)
                    element = improve_view_n(element).split()
                    for subeleement in element:
                        try:
                            ipaddress.IPv4Address(subeleement)
                        except ipaddress.AddressValueError:
                            pass
                        else:
                            found_ip.append(subeleement)
            else:
                nothing_was_found(file_name, number)
    semaphore.release()


def write_searh_results_to_file(file_where_match_was_found, element):
    with open(file="found_results.txt", mode='a') as f:
        f.write(f"{file_where_match_was_found}: {improve_view_n(element)} \n")


def nothing_was_found(file_where_match_wasnt_found, number_to_search):
    with open(file="found_results.txt", mode='a') as f:
        f.write(f"NO MATCHES FOUND FOR {number_to_search} IN {file_where_match_wasnt_found}\n\n")


def check_if_ip_in_norma(ip, trunk_names):
    line_which_contains_ip = []
    for line in trunk_names:
        if ip in line:
            line_which_contains_ip.append(line)
    if line_which_contains_ip == []:
        line_which_contains_ip.append(f"Norma does not contain information about {ip}")
    return line_which_contains_ip


def main():
    threads = []
    our_files = ('y.py', "found_results.txt", "number_list.txt", 'norma.xls', 'MultyThread.py')
    list_files = os.listdir()
    for file in our_files:
        if file in list_files:
            list_files.remove(file)
    semaphore = threading.Semaphore(10)
    t1 = int(round(time.time() * 1000))
    found_ip_list = []
    if "norma.xls" not in os.listdir():
        print("norma.xls file was not found in the current directory")
        print("The program will be terminated")
        sys.exit()
        time.sleep(3)
    normafile = pandas.read_excel('norma.xls', skiprows=2, header=None)
    trunk_names = normafile[2]
    numbers_to_search_list = upload_number_list()
    for number in numbers_to_search_list:
        for file_number in range(len(list_files)):
            threads.append(threading.Thread(target=search_for_pattern,
                                            args=(number, list_files[file_number],
                                                  semaphore, found_ip_list,),)
                           )
            threads[file_number].start()
        for file_number in range(len(list_files)):
            threads[file_number].join()
    print(set(found_ip_list))
    for ip in set(found_ip_list):
        x = check_if_ip_in_norma(ip, trunk_names)
        print(f"{x}\n")
        with open('found_results.txt', 'a') as f:
            f.write(f"{x}\n")
    print("The program completed fine!")
    print("Take found_results.txt from the current folder")
    print("If you want to repeat search, remove found_results.txt")
    t2 = int(round(time.time() * 1000))
    print(f"Job is done within {t2 - t1} miliseconds")
    time.sleep(90)
    print("Bye!")
    time.sleep(1)


if __name__ == '__main__':
    try:
        main()
    except Exception as ex:
        print("The following error happened:")
        print(ex)
    time.sleep(20)
</code></pre>
<p>Single Thread:</p>
<pre><code>import re
import os
import time
import sys
import pandas
import ipaddress


def improve_view_n(string_to_improve):
    string_to_improve = string_to_improve.split(',')
    improved_string = ""
    for i in string_to_improve:
        if i != "":
            improved_string = improved_string + i + "  "
    return improved_string


def upload_number_list():
    numbers = []
    try:
        with open(file="number_list.txt", mode="r") as f:
            for i in f:
                numbers.append(i.strip("\\\n"))
    except FileNotFoundError:
        print("number_list.txt file does not exist or corrupted.\n\n")
        print("The program will be terminated in 5 seconds")
        time.sleep(5)
        sys.exit()
    return numbers


def search_for_pattern(number):
    found_ip = []
    our_files = ('y.py', "found_results.txt", "number_list.txt", 'norma.xls')
    list_files = os.listdir()
    for file_name in list_files:
        #if file_name not in our_files:
        if file_name.startswith("MSK"):
            with open(file=file_name, mode='r') as f:
                text_of_file = f.read()
                results = re.findall(pattern=f",,,,,.*{number}.*,", string=text_of_file)
                if results:
                    for element in results:
                        write_searh_results_to_file(file_name, element)
                        element = improve_view_n(element).split()
                        for subeleement in element:
                            try:
                                ipaddress.IPv4Address(subeleement)
                            except ipaddress.AddressValueError:
                                pass
                            else:
                                found_ip.append(subeleement)
                else:
                    nothing_was_found(file_name, number)
    return found_ip


def write_searh_results_to_file(file_where_match_was_found, element):
    with open(file="found_results.txt", mode='a') as f:
        f.write(f"{file_where_match_was_found}: {improve_view_n(element)} \n")


def nothing_was_found(file_where_match_wasnt_found, number_to_search):
    with open(file="found_results.txt", mode='a') as f:
        f.write(f"NO MATCHES FOUND FOR {number_to_search} IN {file_where_match_wasnt_found}\n\n")


def check_if_ip_in_norma(ip, trunk_names):
    line_which_contains_ip = []
    for line in trunk_names:
        if ip in line:
            line_which_contains_ip.append(line)
    if line_which_contains_ip == []:
        line_which_contains_ip.append(f"Norma does not contain information about {ip}")
    return line_which_contains_ip


def main():
    t1 = int(round(time.time() * 1000))
    found_ip_lists = []
    found_ip_list = []
    if "norma.xls" not in os.listdir():
        print("norma.xls file was not found in the current directory")
        print("The program will be terminated")
        sys.exit()
        time.sleep(3)
    normafile = pandas.read_excel('norma.xls', skiprows=2, header=None)
    trunk_names = normafile[2]
    numbers_to_search_list = upload_number_list()
    for i in numbers_to_search_list:
        found_ip_lists.append(search_for_pattern(i))
    for i in found_ip_lists:
        found_ip_list += i
    print(set(found_ip_list))
    for ip in set(found_ip_list):
        x = check_if_ip_in_norma(ip, trunk_names)
        print(f"{x}\n")
        with open('found_results.txt', 'a') as f:
            f.write(f"{x}\n")
    print("The program completed fine!")
    print("Take found_results.txt from the current folder")
    print("If you want to repeat search, remove found_results.txt")
    t2 = int(round(time.time() * 1000))
    print(f"Job is done within {t2 - t1} miliseconds")
    time.sleep(90)
    print("Bye!")
    time.sleep(1)


if __name__ == '__main__':
    try:
        main()
    except Exception as ex:
        print("The following error happened:")
        print(ex)
        time.sleep(20)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Python does not support real multi-threading, you always have the <strong>Global Interpreter Lock</strong> [ <a href="https://realpython.com/python-gil/" rel="nofollow noreferrer">more about GIL</a> ] which allows only for execution of single statement at a time. So there is only really one thread plus the added code for handling threads so it will be slower in most cases.</p>
<p>There can be some speed up in I/O operations but not always. Multi-threading module serves more for a different type of programming style than for example async programming (for which python also has a module <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer">link</a>). If you would like to see real performance improvement you should use python multiprocessing module which does not suffer from <strong>GIL</strong>, however data exchange between two process is more complicated than using threads.</p>
<p><a href="https://docs.python.org/3.7/library/multiprocessing.html" rel="nofollow noreferrer">https://docs.python.org/3.7/library/multiprocessing.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Python uses the Global Interpreter Lock (GIL). It essentially makes the whole process a single threaded app.</p>
<p>Python multithreading is only useful if you are I/O-bound. If you want to parallelize your workload then you should use <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing</a>. It has a similar API as multithreading except the processes do not share memory between them.</p>
</div>
<div class="post-text" itemprop="text">
<p>when it comes to process data with multithreading in python is slower because in fact python it is using one single thread (because of GIL) that switch between some pyhton "threads", check this <a href="https://en.wikibooks.org/wiki/Python_Programming/Threading" rel="nofollow noreferrer">link</a> </p>
<p>it is slower because of the switch time</p>
<p>you should use multiprocessing </p>
</div>
<span class="comment-copy">Please mark an answer as correct if it resolved your issue.</span>
<span class="comment-copy">@mrangry777 I wrote version with multiprocessing module and it work much slower than multithreading and single thread, new script  does not do correctly what i need (do not give found_ip_list correctly - give empty list instead), I'll try to solve the issue, then I'll close the issue if I have no question then. Thank you for support.</span>
<span class="comment-copy">Could you post the result of your tests? Number of iterations, size of files and execution times?</span>
<span class="comment-copy">@mrangry777 yes sure, will provide you with the information as soon as finish with tests</span>
