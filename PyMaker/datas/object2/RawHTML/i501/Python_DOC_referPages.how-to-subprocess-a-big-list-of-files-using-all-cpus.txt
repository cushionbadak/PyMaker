<div class="post-text" itemprop="text">
<p>I need to convert 86,000 TEX files to XML using the LaTeXML library in the command line. I tried to write a Python script to automate this with the <code>subprocess</code> module, utilizing all 4 cores.</p>
<pre><code>def get_outpath(tex_path):
    path_parts = pathlib.Path(tex_path).parts
    arxiv_id = path_parts[2]
    outpath = 'xml/' + arxiv_id + '.xml'
    return outpath

def convert_to_xml(inpath):
    outpath = get_outpath(inpath)

    if os.path.isfile(outpath):
        message = '{}: Already converted.'.format(inpath)
        print(message)
        return

    try:
        process = subprocess.Popen(['latexml', '--dest=' + outpath, inpath], 
                                   stderr=subprocess.PIPE, 
                                   stdout=subprocess.PIPE)
    except Exception as error:
        process.kill()
        message = "error: %s run(*%r, **%r)" % (e, args, kwargs)
        print(message)

    message = '{}: Converted!'.format(inpath)
    print(message)

def start():
    start_time = time.time()
    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count(),
                               maxtasksperchild=1)
    print('Initialized {} threads'.format(multiprocessing.cpu_count()))
    print('Beginning conversion...')
    for _ in pool.imap_unordered(convert_to_xml, preprints, chunksize=5): 
        pass
    pool.close()
    pool.join()
    print("TIME: {}".format(total_time))

start()
</code></pre>
<p>The script results in <code>Too many open files</code> and slows down my computer. From looking at Activity Monitor, it looks like this script is trying to create 86,000 conversion subprocesses at once, and each process is trying to open a file. Maybe this is the result of <code>pool.imap_unordered(convert_to_xml, preprints)</code> -- maybe I need to not use map in conjunction with <code>subprocess.Popen</code>, since I just have too many commands to call? What would be an alternative?</p>
<p>I've spent all day trying to figure out the right way to approach bulk subprocessing. I'm new to this part of Python, so any tips for heading in the right direction would be much appreciated. Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>In <code>convert_to_xml</code>, the <code>process = subprocess.Popen(...)</code> statements spawns a <code>latexml</code> subprocess.
Without a blocking call such as <code>process.communicate()</code>, the <code>convert_to_xml</code> ends even while <code>latexml</code> continues to run in the background.</p>
<p>Since <code>convert_to_xml</code> ends, the Pool sends the associated worker process another task to run and so <code>convert_to_xml</code> is called again.
Once again another <code>latexml</code> process is spawned in the background.
Pretty soon, you are up to your eyeballs in <code>latexml</code> processes and the resource limit on the number of open files is reached.</p>
<p>The fix is easy: add <code>process.communicate()</code> to tell <code>convert_to_xml</code> to wait until the <code>latexml</code> process has finished.</p>
<pre><code>try:
    process = subprocess.Popen(['latexml', '--dest=' + outpath, inpath], 
                               stderr=subprocess.PIPE, 
                               stdout=subprocess.PIPE)
    process.communicate()                                   
except Exception as error:
    process.kill()
    message = "error: %s run(*%r, **%r)" % (e, args, kwargs)
    print(message)

else: # use else so that this won't run if there is an Exception
    message = '{}: Converted!'.format(inpath)
    print(message)
</code></pre>
<hr/>
<p>Regarding <code>if __name__ == '__main__'</code>:</p>
<p>As <a href="https://stackoverflow.com/questions/54728128/how-to-subprocess-a-big-list-of-files-using-all-cpus/54728194#comment96239940_54728128">martineau pointed out</a>, there is a <a href="https://docs.python.org/3/library/multiprocessing.html#programming-guidelines" rel="nofollow noreferrer">warning in the multiprocessing docs</a> that
code that spawns new processes should not be called at the top level of a module.
Instead, the code should be contained inside a <code>if __name__ == '__main__'</code> statement.</p>
<p>In Linux, nothing terrible happens if you disregard this warning.
But in Windows, the code "fork-bombs". Or more accurately, the code
causes an unmitigated chain of subprocesses to be spawned, because on Windows <code>fork</code> is simulated by spawning a new Python process which then imports the calling script. Every import spawns a new Python process. Every Python process tries to import the calling script. The cycle is not broken until all resources are consumed.</p>
<p>So to be nice to our Windows-fork-bereft brethren, use</p>
<pre><code>if __name__ == '__main__:
    start()
</code></pre>
<hr/>
<p>Sometimes processes require a lot of memory. <a href="http://stackoverflow.com/questions/1316767/how-can-i-explicitly-free-memory-in-python/1316799#1316799">The only reliable way</a> to free memory is to terminate the process. <code>maxtasksperchild=1</code> tells the <code>pool</code> to terminate each worker process after it completes 1 task. It then spawns a new worker process to handle another task (if there are any). This frees the (memory) resources the original worker may have allocated which could not otherwise have been freed.</p>
<p>In your situation it does not look like the worker process is going to require much memory, so you probably don't need <code>maxtasksperchild=1</code>.
In <code>convert_to_xml</code>, the <code>process = subprocess.Popen(...)</code> statements spawns a <code>latexml</code> subprocess.
Without a blocking call such as <code>process.communicate()</code>, the <code>convert_to_xml</code> ends even while <code>latexml</code> continues to run in the background.</p>
<p>Since <code>convert_to_xml</code> ends, the Pool sends the associated worker process another task to run and so <code>convert_to_xml</code> is called again.
Once again another <code>latexml</code> process is spawned in the background.
Pretty soon, you are up to your eyeballs in <code>latexml</code> processes and the resource limit on the number of open files is reached.</p>
<p>The fix is easy: add <code>process.communicate()</code> to tell <code>convert_to_xml</code> to wait until the <code>latexml</code> process has finished.</p>
<pre><code>try:
    process = subprocess.Popen(['latexml', '--dest=' + outpath, inpath], 
                               stderr=subprocess.PIPE, 
                               stdout=subprocess.PIPE)
    process.communicate()                                   
except Exception as error:
    process.kill()
    message = "error: %s run(*%r, **%r)" % (e, args, kwargs)
    print(message)

else: # use else so that this won't run if there is an Exception
    message = '{}: Converted!'.format(inpath)
    print(message)
</code></pre>
<hr/>
<p>The <code>chunksize</code> affects how many tasks a worker performs before sending the result back to the main process. 
<a href="https://medium.com/@rvprasad/data-and-chunk-sizes-matter-when-using-multiprocessing-pool-map-in-python-5023c96875ef" rel="nofollow noreferrer">Sometimes</a> this can affect performance, especially if interprocess communication is a signficant portion of overall runtime.</p>
<p>In your situation, <code>convert_to_xml</code> takes a relatively long time (assuming we wait until <code>latexml</code> finishes) and it simply returns <code>None</code>. So interprocess communication probably isn't a significant portion of overall runtime. Therefore, I don't expect you would find a significant change in performance in this case (though it never hurts to experiment!).</p>
<hr/>
<p>In plain Python, <code>map</code> should not be used just to call a function multiple times.</p>
<p>For a similar stylistic reason, I would reserve using the <code>pool.*map*</code> methods for situations where I cared about the return values.</p>
<p>So instead of</p>
<pre><code>for _ in pool.imap_unordered(convert_to_xml, preprints, chunksize=5): 
    pass
</code></pre>
<p>you might consider using</p>
<pre><code>for preprint in preprints:
    pool.apply_async(convert_to_xml, args=(preprint, ))
</code></pre>
<p>instead.</p>
<hr/>
<p>The iterable passed to any of the <code>pool.*map*</code> functions is <strong>consumed
immediately</strong>.  It doesn't matter if the iterable is an iterator. There is no
special memory benefit to using an iterator here. <code>imap_unordered</code> <em>returns</em> an
iterator, but it does not handle its input in any especially iterator-friendly
way. </p>
<p>No matter what type of iterable you pass, upon calling the <code>pool.*map*</code> function the iterable is
consumed and turned into tasks which are put into a task queue.</p>
<p>Here is code which corroborates this claim:</p>
<p>version1.py:</p>
<pre><code>import multiprocessing as mp
import time

def foo(x):
    time.sleep(0.1)
    return x * x


def gen():
    for x in range(1000):
        if x % 100 == 0:
            print('Got here')
        yield x


def start():
    pool = mp.Pool()
    for item in pool.imap_unordered(foo, gen()):
        pass

    pool.close()
    pool.join()

if __name__ == '__main__':
    start()
</code></pre>
<p>version2.py:</p>
<pre><code>import multiprocessing as mp
import time
def foo(x):
    time.sleep(0.1)
    return x * x


def gen():
    for x in range(1000):
        if x % 100 == 0:
            print('Got here')
        yield x


def start():
    pool = mp.Pool()

    for item in gen():
        result = pool.apply_async(foo, args=(item, ))

    pool.close()
    pool.join()

if __name__ == '__main__':
    start()
</code></pre>
<p>Running <code>version1.py</code> and <code>version2.py</code> both produce the same result. </p>
<pre><code>Got here
Got here
Got here
Got here
Got here
Got here
Got here
Got here
Got here
Got here
</code></pre>
<p>Crucially, you will notice that <code>Got here</code> is printed 10 times very quickly at
the beginning of the run, and then there is a long pause (while the calculation
is done) before the program ends.</p>
<p>If the generator <code>gen()</code> were somehow consumed slowly by <code>pool.imap_unordered</code>,
we should expect <code>Got here</code> to be printed slowly as well. Since <code>Got here</code> is
printed 10 times and quickly, we can see that the iterable <code>gen()</code> is being
completely consumed well before the tasks are completed.</p>
<p>Running these programs should hopefully give you confidence that
<code>pool.imap_unordered</code> and <code>pool.apply_async</code> are putting tasks in the queue
essentially in the same way: immediate after the call is made.</p>
</div>
<span class="comment-copy">When <code>if os.path.isfile(outpath)</code> is true and you print the "already converted" message, why do you continue on to call the <code>latexml</code> command?  Wouldn't you want to exit the function instead?</span>
<span class="comment-copy">I had a return there, thanks for catching that. I've edited my question. Same problem.</span>
<span class="comment-copy">Try putting the final call to <code>start()</code> inside an <code>if __name__ == '__main__':</code>,</span>
<span class="comment-copy">It was in that conditional previously, but it makes no difference @martineau</span>
<span class="comment-copy">Regardless, I think it should be there as per the multiprocessing <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming" rel="nofollow noreferrer">Programming Guidelines</a> (see the "Safe importing of main module" section).</span>
<span class="comment-copy">Thanks for your pity. <code>;¬)</code> I know about the Window vs Unixy differences, but believe in promoting portable code.</span>
<span class="comment-copy">Hehe I was up in my eyeballs in processes, indeed. The <code>communicate()</code> call solves my problem. It seems obvious now. My code is also using all 4 cores now that it's not hung up. This is great. Thanks for the additional clarification about <code>__main__</code>! Also just wondering, do you know if in this situation there is any need for the <code>maxtasksperchild</code> or <code>chunksize</code> arguments? I had thought that setting the former to 1 would be sort of a pause.</span>
<span class="comment-copy">pool.apply_sync hangs, it's trying to apply all 86,000 before it executes one</span>
<span class="comment-copy">The <code>for preprint in preprints</code> loop which calls <code>pool.apply_async</code> queues up 86K tasks, but as long as there is a <code>process.communicate()</code> call inside <code>convert_to_xml</code>, they can't all run at the same time. By the way, the <code>pool.*map*</code> commands also queue up all 86K tasks immediately as well.</span>
<span class="comment-copy"><code>pool.apply_async</code>  takes forever to build the queue. I used <code>pool.imap_unordered</code> after reading <a href="https://stackoverflow.com/questions/9874042/using-pythons-multiprocessing-module-to-execute-simultaneous-and-separate-seawa/9874484#9874484" title="using pythons multiprocessing module to execute simultaneous and separate seawa">stackoverflow.com/questions/9874042/…</a></span>
