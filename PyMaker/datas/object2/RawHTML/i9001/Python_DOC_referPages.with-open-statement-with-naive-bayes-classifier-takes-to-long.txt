<div class="post-text" itemprop="text">
<p>I have a csv file with 3483 lines and 460K characters and 65K words, and I'm trying to use this corpus to train a NaiveBayes classifier in Scikit-learn. </p>
<p>The problem is when I use this statement below, takes too long (1 hour and did not finish).</p>
<pre><code>from textblob import TextBlob
from textblob.classifiers import NaiveBayesClassifier 
import csv 

with open('train.csv', 'r') as fp:
    cl = NaiveBayesClassifier(fp, format="csv") 
</code></pre>
<p>Any guesses of what I doing wrong?</p>
<p>Thanks in advance. </p>
</div>
<div class="post-text" itemprop="text">
<p>There's a problem with this lib. </p>
<p>It's documented in the following links:</p>
<p><a href="https://github.com/sloria/TextBlob/pull/136" rel="nofollow noreferrer">https://github.com/sloria/TextBlob/pull/136</a></p>
<p><a href="https://github.com/sloria/TextBlob/issues/77" rel="nofollow noreferrer">https://github.com/sloria/TextBlob/issues/77</a></p>
<p>Small story: The library do not deals well with large datasets. </p>
</div>
<div class="post-text" itemprop="text">
<p>I am not entirely sure of the text blob library but perhaps this may help-</p>
<p>I had written the following code to train a multinomial naive bayes model with raw textual data after vectorizing and transforming the text in my dataset.</p>
<pre><code>from sklearn.feature_extraction.text import TfidfTransformer
import pandas as pd
from sklearn import model_selection
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score

#import dataset
url = ("C:\\Users\\sidharth.m\\Desktop\\Project_sid_35352\\Final.csv")
documents = pd.read_csv(url)

array = documents.values

x = array[0:, 1]

y= array[0:, 0]


count_vect = CountVectorizer()
X_train_counts = count_vect.fit_transform(x)

tfidf_transformer = TfidfTransformer()
X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)

model=MultinomialNB().fit(X_train_tfidf, y)

predicted = model.predict(X_train_tfidf)

acc = accuracy_score(y, predicted)
print(acc)
</code></pre>
</div>
<span class="comment-copy">Is your CSV file formatted like so : <a href="http://textblob.readthedocs.io/en/dev/classifiers.html" rel="nofollow noreferrer">textblob.readthedocs.io/en/dev/classifiers.html</a></span>
<span class="comment-copy">Yes @vendaTrout  This is an example of the file:  <code>instagrama,INSTAGRAM #fb,FACEBOOK facebookio,FACEBOOK facebooktime messenger iphone,FACEBOOK whatsapp com,WHATSSUP facebooko    #fb,FACEBOOK facebookiokio  #fb,FACEBOOK instagramas:  ,INSTAGRAM facebook   https:fb,FACEBOOK facebook  #fb,FACEBOOK</code></span>
<span class="comment-copy">Assuming, each train data and label is separated by a "\n", can you profile the function for a smaller csv, or this. Please have a look at the stdlib <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">profiling</a> module.</span>
<span class="comment-copy">I made a small csv with 200 lines and it takes 3 minutes to load.How can I profile this?</span>
<span class="comment-copy">I am also facing this issue but no luck, any alternative for same work ?</span>
