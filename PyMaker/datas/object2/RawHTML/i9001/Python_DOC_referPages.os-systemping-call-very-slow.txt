<div class="post-text" itemprop="text">
<p>I have the following script:</p>
<pre><code>#!/usr/bin/env python3
import os

i = 1
while i != 255:
    Test = os.system("ping -c 1 10.0.0." + str(i) + " &gt; /dev/null")
    if Test == 0:
        print("Host: 10.0.0." + str(i) + " is up!");
        i = i + 1
    else:
        i = i + 1
</code></pre>
<p>It is an NMap-like python script, that I was bored and decided to make.</p>
<p>Anyway, when I run it, it is SUPER slow, but when I hold CTRL + C, it goes a lot faster... And it works!</p>
<p>Is there a way that I can make this script a lot faster?</p>
</div>
<div class="post-text" itemprop="text">
<p>By default, ping waits 10s for the packet to arrive. Since many addresses will not be in use, or the computers who have these addresses will not answer to ICMP echo (ping) packets, you'll wait up to 2550s seconds, or a little bit less if some addresses elicit a response.</p>
<p>When you type <kbd>Ctrl</kbd>+<kbd>C</kbd>, you send a <code>SIGTERM</code> signal, which aborts the waiting. If you abort ping before it receives the ICMP echo response, you'll get incorrect results. Since local networks are quite fast, you're unlikely to encounter this.</p>
<p>To speed this up, you can modify your approach in two ways:</p>
<ol>
<li>Give up earlier when no response is coming. Pass in the <code>-W</code> parameter. For instance, by running <code>ping -c 1 -W 1 ...</code>, ping will wait just one second, so your whole program will take approximately 250s instead.</li>
<li>Run the pings in parallel. You can do that manually, typically by using a <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow noreferrer"><code>Pool</code></a> of threads/processes (or just one thread/process per ping). Note that your operating system may enforce limits on the number of pings per second. For instance, if you leave the timeout at 10s and manage to run all pings concurrently, your program will take just 10s.</li>
</ol>
<p>Proper code using a pool could look like</p>
<pre><code>import multiprocessing
import subprocess


TIMEOUT = 5  # in seconds
CONCURRENCY = 100  # how many pings in parallel?


def ping(ip):
    """ Returns true iff the host is reachable. """
    # print('ping %s' % ip)  # uncomment to see progress
    ret = subprocess.call(
        ['ping', '-W', str(TIMEOUT), '-c', '1', ip],
        stdout=subprocess.DEVNULL)
    if ret == 0:
        print('%s is reachable' % ip)

ips = ('10.0.0.%d' % i for i in range(1, 255))

with multiprocessing.Pool(CONCURRENCY) as p:
    p.map(ping, ips)
</code></pre>
<p>If you're not toying around, you may also want to use a program instead of ping which does run in parallel. Any port scanner (such as <a href="https://nmap.org/" rel="nofollow noreferrer">nmap</a>) should work fine.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use <a href="http://www.secdev.org/projects/scapy/doc/usage.html" rel="nofollow noreferrer">scapy</a>. There's no need to spawn <strong>ping</strong> commands in Python threads.</p>
</div>
<span class="comment-copy"><code>multiprocessing</code> would be a place to start. BTW, since your <code>i</code> is guaranteed to be numeric this is safe here, but <i>in general</i> using string concatenation to form shell commands is wildly insecure. Passing an array to <code>subprocess.Popen</code> (with your <code>&gt;/dev/null</code> redirection replaced with a non-shell-dependent equivalent, as with <code>stdout=open('/dev/null', 'wb')</code>) is much better form.</span>
<span class="comment-copy">Of course it would be 'super slow' - it takes time to ping a potential host and then wait for response, and do that 255 times. If you have <code>nmap</code> on your system, you can try using: <code>os.system("nmap -sP --max-retries=1 --host-timeout=500ms 10.0.0.{} &gt; /dev/null".format(i))</code> instead to give up after 500ms but, as others suggested, you'll have to use multiprocessing if you want to have everything run in parallel.</span>
<span class="comment-copy">@jersten, ...I'm not sure that the GIL is <i>that</i> big of a problem here, since the work being done is waiting for subprocesses -- the wait itself should be outside the lock; only handling the results when a SIGCHLD comes in should strictly require the lock to be held.</span>
<span class="comment-copy">I'd rather avoid using NMap, the program I am making is supposed to be like NMap, but more lite</span>
<span class="comment-copy">I am pretty new to python, how would I use a Pool? I know it isn't the one you swim in ;)</span>
<span class="comment-copy">@Python Follow the <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow noreferrer">link to the documentation</a>, which explains how to use a pool. If you have any questions after reading the documentation, <a href="http://stackoverflow.com/questions/ask">feel free to ask them on stackoverflow</a>.</span>
<span class="comment-copy">I have the code from the link to the documentation, but where would I put my code? I am very confused XD</span>
<span class="comment-copy">@Python I have added an example for how your code could look like using a pool (and proper subprocess invocation)</span>
<span class="comment-copy">Actually, there might be - any user can ping, but you need superuser privileges to run scapy.</span>
<span class="comment-copy">On Linux, you only need the <b>CAP_NET_RAW</b> capability.</span>
