<div class="post-text" itemprop="text">
<p>I have a flask application which listens for some job to do.  The process is quite long (let us say 1 minute)  and I would like not allow to process two requests at the same time. </p>
<p>I will be great if once I receive a request, I could close the port flask is listening to and open again when finish. Alternatively I could setup a semaphore but I am not sure about how flask is running concurrently.</p>
<p>Any advice?</p>
<pre><code>from flask import Flask, request
app = Flask(__name__)

@app.route("/",methods=['GET'])
def say_hi():
    return "get not allowed"

@app.route("/",methods=['POST'])
def main_process():
    # heavy process here to run alone
    return "Done"

if __name__ == "__main__":
    app.run(debug=True,host='0.0.0.0')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could use a semaphore for this:</p>
<pre><code>import threading
import time
sem = threading.Semaphore()

@app.route("/",methods=['POST'])
def main_process():
    sem.acquire()
    # heavy process here to run alone
    sem.release()
    return "Done"
</code></pre>
<p>The semaphore usage is to control the access to a common resource.</p>
<p>You can see more info about semaphore in <a href="https://en.wikipedia.org/wiki/Semaphore_(programming)" rel="nofollow noreferrer">here</a></p>
<p>This SO question can help you as well <a href="https://stackoverflow.com/questions/31508574/semaphores-on-python">here</a></p>
<p><strong>EDIT:</strong></p>
<p>As Georg Schölly wrote in comment, The above mentioned solution is problematic in a situation of multiple services.</p>
<p>Although, you can use the wsgi in order to accomplish your goal.</p>
<pre><code>@app.route("/",methods=['POST'])
def main_process():
    uwsgi.lock()
    # Critical section
    # heavy process here to run alone
    uwsgi.unlock()
    return "Done"
</code></pre>
<p>uWSGI supports a configurable number of locks you can use to synchronize worker processes</p>
<p>For more info, read <a href="http://uwsgi-docs-additions.readthedocs.io/en/latest/Locks.html" rel="nofollow noreferrer">here</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You could try adding a <a href="https://docs.python.org/3/library/threading.html#threading.Lock" rel="nofollow noreferrer"><code>threading.Lock</code></a> to indicate that some work is already in progress:</p>
<pre><code>import threading
from contextlib import ExitStack

busy = threading.Lock()
@app.route("/",methods=['POST'])
def main_process():
    if not busy.acquire(timeout = 1):
        return 'The application is busy, refresh the page in a few minutes'

    # ensure busy.release() is called even if an exception is thrown
    with ExitStack() as stack:
        stack.callback(busy.release)
        # heavy process here to run alone

    return "Done"
</code></pre>
<p>But Flask by default allows only one request to be processed at a time (more info <a href="https://stackoverflow.com/questions/10938360/how-many-concurrent-requests-does-a-single-flask-process-receive">here</a>), so if you're fine with the fact that during the processing of a single request, all the other users' pages won't load until the process is finished (maybe even get a request timeout error), you don't have to change anything.<br/>
If you want to make other users get a message, like in the above code, increase the amount of workers to 2, so that when one worker processes the request, the other one holds off the others.</p>
</div>
<span class="comment-copy">How are you planing on running flask? Through flask directly or are you runing it as a WSGI module?</span>
<span class="comment-copy">I am using wsgi module</span>
<span class="comment-copy">In this case it might be a bit more complicated. A WSGI server (depending on the configuration) can spawn multiple processes in parallel, but Python's locks only work across threads, not across processes. You need to introduce a shared resource you can lock. That could be the database, a file or a shared lock, for example a <a href="http://stackoverflow.com/q/2798727">named semaphore</a>.</span>
<span class="comment-copy">This does not work if there are multiple processes. The lock here does not work across multiple processes, which is the normal configuration for web servers.</span>
<span class="comment-copy">@GeorgSchölly , Thanks for your comment, i've added an edit section regarding your comment.</span>
<span class="comment-copy">Without locks this is prone to race conditions.</span>
<span class="comment-copy">@GeorgSchölly good point. Edited to use locks</span>
<span class="comment-copy">This does not work if there are multiple processes. The lock here does not work across multiple processes, which is the normal configuration for web servers.</span>
<span class="comment-copy">@GeorgSchölly there's a <code>threaded</code> option you can pass to tell the server that it's supposed to work in threaded mode</span>
<span class="comment-copy">That's true, but that assumes that the application runs through Flask's integrated server. Especially in production mode this is seldom the case. Mosh states in the comments to his question that he uses it through WSGI.</span>
