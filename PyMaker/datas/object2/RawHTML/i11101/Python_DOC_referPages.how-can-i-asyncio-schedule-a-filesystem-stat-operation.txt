<div class="post-text" itemprop="text">
<p>Converting some code to using <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow">asyncio</a>, I'd like to give back control to the <a href="https://docs.python.org/3/library/asyncio-eventloop.html" rel="nofollow"><code>asyncio.BaseEventLoop</code></a> as quickly as possible. This means to avoid blocking waits.</p>
<p>Without asyncio I'd use <a href="https://docs.python.org/3/library/os.html?highlight=stat#os.stat" rel="nofollow"><code>os.stat()</code></a> or <a href="https://docs.python.org/3/library/pathlib.html?highlight=stat#pathlib.Path.stat" rel="nofollow"><code>pathlib.Path.stat()</code></a> to obtain e.g. the filesize. Is there a way to do this efficiently with asyncio?</p>
<p>Can I just wrap the <code>stat()</code> call so it is a future similar to what's <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Future" rel="nofollow">described here</a>?</p>
</div>
<div class="post-text" itemprop="text">
<p><code>os.stat()</code> translates to a <code>stat</code> syscall:</p>
<pre><code>$ strace python3 -c 'import os; os.stat("/")'
[...]
stat("/", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0
[...]
</code></pre>
<p>which is blocking, and there's no way to get a non-blocking <code>stat</code> syscall.</p>
<p><code>asyncio</code> provides non-blocking I/O by using non-blocking system calls, which already exists (see <code>man fcntl</code>, with its <code>O_NONBLOCK</code> flag, or <code>ioctl</code>), so <code>asyncio</code> is not making syscalls asynchronous, it exposes already asynchronous syscalls in a nice way.</p>
<p>It's still possible to use the nice <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor" rel="nofollow">ThreadPoolExecutor</a> abstraction to make your blocking <code>stat</code> calls in parallel using a pool of threads.</p>
<p>But you may first consider some other parameters:</p>
<ul>
<li>According to <code>strace -T</code>, <code>stat</code> is fast: <code>stat("/", {st_mode=S_IFDIR|0755, st_size=4096, ...}) = 0 &lt;0.000007&gt;</code>, probably faster than starting and synchronizing threads.</li>
<li><code>stat</code> is probably in much cases IO bound, so using more CPUs won't help</li>
<li>Doing parallel I/O may break a nice sequential access to a random access, phisical hard drive may be slower in this context.</li>
</ul>
<p>But there's also a lot of possibilities for your <code>stat</code>s to be faster using a thread pool, like if you're hitting a distributed file system.</p>
<p>You may also take a look at <code>functools.lru_cache</code>: if you're doing multiple <code>stat</code> on the same file or directory, and you're sure it has not changed, caching the result avoids a syscall.</p>
<p>To conclude, "keep it simple", "os.stat" <em>is</em> the efficient way to get a filesize.</p>
</div>
<span class="comment-copy">You mean: you want a non-blocking <code>os.stat()</code> so other coroutines can run during it?</span>
<span class="comment-copy">@Julien: Yes, I think so ;-) To have the main code run in parallel, I would be forced to use threads instead of asyncio, wouldn't I?</span>
<span class="comment-copy">Thanks for your good thoughts and observations on this matter! I feared (or hoped?) as much. I have potentially millions of stats, and I indeed do not want to parallelize those (filesystem is a highly parallelized NAS, but on an nfs mount) The idea was to queue/pool the stats, but be able to do python-based other bookkeeping in parallel, so as not to wait for code execution even after the stats. Caching the stats is no option because it's for a tool that's supposed to check for differences on the filesystem (compare to rsync or zfs' scrub mechanism).</span>
<span class="comment-copy">For now I'll leave the stats as they are. Later I might compare to pushing them into one separate thread which communicates to the main thread via queues. It might still be faster to just do the stats inline with the rest of the code. Thanks again!</span>
