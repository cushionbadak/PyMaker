<div class="post-text" itemprop="text">
<p>I am throwing in the towel here. I'm trying to convert a string scraped from the source code of a website with scrapy (injected javascript) to json so I can easily access the data. The problem comes down to a decode error. I tried all kinds of encoding, decoding, escaping, codecs, regular expressions, string manipulations and nothing works. Oh, using Python 3. </p>
<p>I narrowed down the culprit on the string (or at least part of it)</p>
<pre><code>scraped = '{"propertyNotes": [{"title": "Local Description", "text": "\u003Cp\u003EAPPS\u003C/p\u003E\n\n\u003Cp\u003EBig Island Revealed (comes as app or as a printed book)\u003C/p\u003E\n\n\u003Cp\u003EAloha Big Island\u003C/p\u003E\n\n\u003Cp\u003EBig Island\u003C/p\u003E\n\n\u003Cp\u003EBig Island Smart Maps (I like this one a lot)\u003C/p\u003E\n\n\u003Cp\u003EBig Island Adventures (includes videos)\u003C/p\u003E\n\n\u003Cp\u003EThe descriptions of beaches are helpful.  Suitability for swimming, ease of access, etc. is included.  Some beaches are great for picnics and scenic views, while others are suitable for swimming and snorkeling. Check before you go.\u003C/p\u003E"}]}'

scraped_raw = r'{"propertyNotes": [{"title": "Local Description", "text": "\u003Cp\u003EAPPS\u003C/p\u003E\n\n\u003Cp\u003EBig Island Revealed (comes as app or as a printed book)\u003C/p\u003E\n\n\u003Cp\u003EAloha Big Island\u003C/p\u003E\n\n\u003Cp\u003EBig Island\u003C/p\u003E\n\n\u003Cp\u003EBig Island Smart Maps (I like this one a lot)\u003C/p\u003E\n\n\u003Cp\u003EBig Island Adventures (includes videos)\u003C/p\u003E\n\n\u003Cp\u003EThe descriptions of beaches are helpful.  Suitability for swimming, ease of access, etc. is included.  Some beaches are great for picnics and scenic views, while others are suitable for swimming and snorkeling. Check before you go.\u003C/p\u003E"}]}'

data = json.loads(scraped_raw) #&lt;= works
print(data["propertyNotes"])

failed = json.loads(scraped) #no work
print(failed["propertyNotes"])
</code></pre>
<p>Unfortunately, I cannot find a way for scrapy/splash to return the string as raw. So, somehow I need to have python interprets the string as raw while it is loading the json. Please help</p>
<p>Update:</p>
<p>What worked for that string was <code>json.loads(str(data.encode('unicode_escape'), 'utf-8'))</code> However, it didnt work with the larger string. The error I get doing this is <code>JSONDecodeError: Invalid \escape</code> on the larger json string</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem exists because the string you're getting has escaped control characters which when interpreted by python become actual bytes when encoded (while this is not necessarily bad, we know that these escaped characters are control characters that json would not expect). Similar to Turn's answer, you need to interpret the string without interpreting the escaped values which is done using</p>
<p><code>json.loads(scraped.encode('unicode_escape'))</code></p>
<p>This works by encoding the contents as expected by the latin-1 encoding whilst interpreting any <code>\u003</code> like escaped character as literally <code>\u003</code> unless it's some sort of control character.</p>
<p>If my understanding is correct however, you may not want this because you then lose the escaped control characters so the data might not be the same as the original.</p>
<p>You can see this in action by noticing that the control chars disappear after converting the encoded string back to a normal python string:</p>
<p><code>scraped.encode('unicode_escape').decode('utf-8')</code></p>
<p>If you want to keep the control characters you're going to have to attempt to escape the strings before loading them.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you are using Python 3.6 or later I think you can get this to work with</p>
<pre><code> json.loads(scraped.encode('unicode_escape'))
</code></pre>
<p>As per the <a href="https://docs.python.org/3/library/codecs.html#text-encodings" rel="nofollow noreferrer">docs</a>, this will give you an</p>
<blockquote>
<p>Encoding suitable as the contents of a Unicode literal in
  ASCII-encoded Python source code, except that quotes are not escaped.
  Decodes from Latin-1 source code. Beware that Python source code
  actually uses UTF-8 by default.</p>
</blockquote>
<p>Which seems like exactly what you need.</p>
</div>
<div class="post-text" itemprop="text">
<p>Ok. so since I am on windows, I have to set the console to handle special characters. I did this by typing <code>chcp 65001</code> into the terminal. I also use a regular expression and chained the string manipulation functions which is the python way anyways. </p>
<pre><code>usable_json = json.loads(re.search('start_sub_string(.*)end_sub_string', hxs.xpath("//script[contains(., 'some_string')]//text()").extract_first()).group(1))
</code></pre>
<p>Then everything went smoth. I'll sort out the encoding and escaping when writing to database down the line.</p>
</div>
<span class="comment-copy">Raw strings are a <i>syntactic</i> feature of the language, not a runtime feature.  Are you generating Python <i>source</i> from the website?  (Please say no...)</span>
<span class="comment-copy">Raw or not raw is only about string literals.  For data you read from somewhere else, that distinction makes no sense.  You need to show us the failure you are getting with the read data, not the literal data.</span>
<span class="comment-copy">That doesn't work. What worked for that string was <code>json.loads(str(data.encode('unicode_escape'), 'utf-8'))</code> However, it didnt work with the larger string. The error I get doing this is <code>JSONDecodeError: Invalid \escape</code> on the larger json string. <a href="https://repl.it/@dennis_pitt/keep-control-characters" rel="nofollow noreferrer">see it here on repl.it</a></span>
<span class="comment-copy">It's a bit difficult to work with but if I run <code>data_feed = json.loads(data.encode('unicode_escape').decode('utf-8'))</code> it looks like it reads in as invalid json</span>
<span class="comment-copy">if you paste the data the string into jsonlint.com, it is marked as valid. that is before any encoding/decoding.</span>
<span class="comment-copy">But <code>scraped.encode('unicode_escape').decode('unicode_escape')</code> preserves the control characters correctly.</span>
<span class="comment-copy">I appreciate the well written response.I don't mind modifying the string as long as it can be converted back before saved to a db, so you are right. I would rather not.</span>
<span class="comment-copy"><code>scraped.encode('unicode_escape').decode('unicode_escape')</code> returns error too  'json.decoder.JSONDecodeError: Invalid control character at: line 1 column 71 (char 70)'</span>
<span class="comment-copy">@DennisPitt that's expected because as Turn said, that will preserve the control characters.</span>
<span class="comment-copy">@Turn, that doesn't work, please delete.</span>
<span class="comment-copy">Yea. I tried that and got "TypeError: the JSON object must be str, not 'bytes'"</span>
<span class="comment-copy">Ah, I tested with 3.6 which has a more permissive json package: <a href="https://docs.python.org/3/whatsnew/3.6.html#json" rel="nofollow noreferrer">docs.python.org/3/whatsnew/3.6.html#json</a></span>
