<div class="post-text" itemprop="text">
<p>I want create lambda that getting zip file(which may conatained list of csv files)  from S3, unzip it and upload back to s3.
since lambda is limited by memory/disk size, I have to stream it from s3 and back into it.
I use python (boto3)
see my code below (I'm more a java guy, new to the python...)</p>
<pre><code>count = 0
obj = s3.Object( bucket_name, key )
buffer = io.BytesIO(obj.get()["Body"].read())
print (buffer)
z = zipfile.ZipFile(buffer)
for x in z.filelist:
    with z.open(x) as foo2:
        print(sys.getsizeof(foo2))
        line_counter = 0
        out_buffer = io.BytesIO()
        for f in foo2:
            out_buffer.write(f)
            # out_buffer.writelines(f)
            line_counter += 1
        print (line_counter)
        print foo2.name
        s3.Object( bucket_name, "output/"+foo2.name+"_output" ).upload_fileobj(out_buffer)
        out_buffer.close()
z.close()
</code></pre>
<p>result is, creating empty files in the bucket.
for example: if file: input.zip contained files: 1.csv,2.csv
i get in the bucket  2 empty csv files with the corresponding names.
also, i'm not sure it indeed stream the files, or just download all the zip file
thanks</p>
</div>
<div class="post-text" itemprop="text">
<p>You need to <a href="https://docs.python.org/3/library/io.html#io.IOBase.seek" rel="nofollow noreferrer">seek</a> back to the beginning of the ByesIO file before uploading.</p>
<pre><code>out_buffer = io.BytesIO()
for f in foo2:
    out_buffer.write(f)
    # out_buffer.writelines(f)
    line_counter += 1

out_buffer.seek(0) # Change stream position to beginning of file

s3.Object( bucket_name, "output/"+foo2.name+"_output").upload_fileobj(out_buffer)
out_buffer.close()
</code></pre>
</div>
<span class="comment-copy">see edited question</span>
<span class="comment-copy">The boto3 client.get_object() method supports a Range parameter. You can use it to request a range of bytes e.g. "bytes=1024-2048".</span>
