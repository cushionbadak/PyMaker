<div class="post-text" itemprop="text">
<p>I'm fairly new to Python and especially new to working with large amounts of data. I'm working on a little fun project, which is effectively an upscale of something I've done before in another language.</p>
<p>For now, I'm loading a sizeable (100mb+) text document, breaking it up into words and then determining the frequencies of what words follow each prefix (each prefix being one or more words). Fairly simple and fun to implement in Python, I ended up with something along the lines of:</p>
<pre><code>def prefix(symbols):
    relationships = {}

    for i in reversed(range(len(symbols))):
        prefix = seperator.join(symbols[i:i+samples])
        suffix = None

        if i+samples &lt; len(symbols):
            suffix = symbols[i+samples]

        if prefix not in relations:
            relations[prefix] = {}

        if suffix not in relations[prefix]:
            relations[prefix][suffix] = 1
        else:
            relations[prefix][suffix] += 1

    return relations
</code></pre>
<p><em>(the function name, its argument and the use of a global "samples" is just temporary while I work out the kinks)</em></p>
<p>This works well, taking about 20 seconds or so to process a 60mb plaintext dump of top articles from Wikipedia. Stepping up the sample size (the "samples" variable) from 1 to even 4 or 5 however, greatly increases memory usage (as expected -- there are ~10 million words and for each, "samples" many words are sliced and joined into a new string). This quickly approaches and reaches the memory limit of 2 gigabytes.</p>
<p>One method I've applied to alleviate this problem is to delete the initial words from memory as I iterate, as they are no longer needed (the list of words could simply be constructed as part of the function so I'm not modifying anything passed in).</p>
<pre><code>def prefix(symbols):
    relationships = {}

    n = len(symbols)
    for i in range(n):
        prefix = seperator.join(symbols[0:samples])

        suffix = None
        if samples &lt; len(symbols):
            suffix = symbols[samples]

        if prefix not in relationships:
            relationships[prefix] = {}

        if suffix not in relationships[prefix]:
            relationships[prefix][suffix] = 1
        else:
            relationships[prefix][suffix] += 1

        del symbols[0]
    return relationships
</code></pre>
<p>This does help, but not by much, and at the cost of some performance.</p>
<p>So what I'm asking is if this kind of approach is fairly efficient or recommended, and if not, what would be more suitable? I may be missing some method to avoid redundantly creating strings and copying lists, seeing as most of this is new to me.
I'm considering:</p>
<ul>
<li>Chunking the symbols/words list, processing, dumping the relationships to disk and combining them after the fact</li>
<li>Working with something like Redis as opposed to keeping the relationships within Python the whole time at all</li>
</ul>
<p>Cheers for any advice or assistance!</p>
</div>
<div class="post-text" itemprop="text">
<p>The main advice when working with large strings in Python in case you need to do lot of changes, is:</p>
<ol>
<li>Convert string to list</li>
<li>Do all the work with list</li>
<li>When finished, convert to strings back</li>
</ol>
<p>The reason is that string in Python is immutable. Every action as <code>symbols[i:i+samples]</code> for example, forces Python to allocate new memory, copy needed string, and return it as new string object. Because of that, when you need to do many changes to string (change by index, splitting), you better work with lists, which are mutable.</p>
</div>
<div class="post-text" itemprop="text">
<p>Re. speeding up the process, I've found it useful to use try/except blocks to update hashtables. For example:</p>
<pre><code>try:
    relationships[prefix][suffix] += 1
except KeyError:
    relationships[prefix][suffix] = 1
</code></pre>
<p>Rather than using 'in' to check for a key and then updating/creating the key which would require another check for that key, the above code eliminates one check and thus works faster.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use, <code>iterator_of_symbols = iter(list_of_symbols)</code>, and do <code>next()</code> on that iter, i.e. <code>iterator_of_symbols.next()</code></p>
<p>Read more <a href="https://stackoverflow.com/questions/2113216/which-is-more-efficient-a-for-each-loop-or-an-iterator">Which is more efficient, a for-each loop, or an iterator?</a> </p>
<p>Although it's explained with Java, I think the concepts are same.</p>
</div>
<span class="comment-copy">This has nothing to do with your question regarding memory efficiency / performance, but for your <code>relations[prefix]</code> and <code>relations[prefix][suffix]</code> dictionaries you may want to use a <a href="https://docs.python.org/2/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>defaultdict(dict)</code></a> and a <a href="https://docs.python.org/2/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>Counter</code></a> respectively - they should be a perfect fit and make your code even more  succinct.</span>
<span class="comment-copy">if <code>symbols</code> is a <code>list</code>, don't use <code>del symbols[0]</code>, it needs to shift every following element in the list, a <code>collections.deque()</code> should be more efficitent. Ideally you could make <code>symbols</code> a generator yielding <code>samples</code> words while consuming your input file.</span>
<span class="comment-copy">which variable is getting memory increasing here ?</span>
<span class="comment-copy">Would a <code>shelve</code> help here?  <a href="https://docs.python.org/3/library/shelve.html" rel="nofollow noreferrer">docs.python.org/3/library/shelve.html</a> and <a href="http://pymotw.com/2/shelve/" rel="nofollow noreferrer">pymotw.com/2/shelve</a></span>
<span class="comment-copy">@LukasGraf I tried both, in fact it's part of the reason I moved to Python 3.x (better performing Counter), but afterall I found that I got better performance doing it "manually". I'll probably move back to using defaultdict with Counter afterwards, though!</span>
<span class="comment-copy">You definitely have a very good point there, accidentally copying strings around in memory can happen pretty quickly in Python and should be avoided. However, I think in the OP's case <code>symbols</code> is a list (of words).</span>
<span class="comment-copy">Yeah, symbols is a list of strings - I'm fairly sure that means the slices I get from them at least aren't copies. The memory usage issue arises due to the fact that I immediately combine them into a (new?) string <code>prefix = seperator.join(symbols[0:samples])</code> (only just noticed the separator typo, hah!).   I'm not sure how I can get around this, however, as I believe I need to be able to immediately add relationships (via the dict). I've also used a tuple instead as a key before, but this didn't improve memory usage -- I'm fairly sure it also makes copies.</span>
