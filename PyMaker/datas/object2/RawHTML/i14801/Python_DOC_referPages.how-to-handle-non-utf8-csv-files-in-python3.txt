<div class="post-text" itemprop="text">
<p>I need to process bulk of CSV files,</p>
<p>The files are from China, so I guess the encoding is <strong>non-utf8</strong></p>
<p>However the files even can not read in Python 3.</p>
<p>How can I read those files and write into new files with Python 3.</p>
<p>Here's the snippets</p>
<pre><code>with open('20120901_20120915_ACCLOG.csv', 'r')  as f:
    sources = f.readlines()
    print(sources)
</code></pre>
<p>And I got the error <code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb8 in position 3: invalid start byte</code></p>
<p>Here are the XLS file and  sample pyhton script</p>
<p><a href="https://github.com/poc7667/sucks_encoding_problem" rel="nofollow">https://github.com/poc7667/sucks_encoding_problem</a></p>
</div>
<div class="post-text" itemprop="text">
<p>The file seems to be encoded as GB2312. Specify the <code>encoding</code> option to <code>open()</code> like this:</p>
<pre><code>with open('20120901_20120915_ACCLOG.csv', encoding='GB2312') as f:
    sources = f.read()
    print(sources)
</code></pre>
<p>I determined the encoding using the <a href="https://pypi.python.org/pypi/chardet2" rel="nofollow"><code>chardet</code></a> module:</p>
<pre><code>&gt;&gt;&gt; chardet.detect(open('20120901_20120915_ACCLOG.csv','rb').read())
{'encoding': 'GB2312', 'confidence': 0.99}
</code></pre>
<p>It is worth noting that several codecs (encodings) work for this file:
gb2312, gbk, and gb18030 all produce the same result.
big5hkscs works too but produces a different result to the other three codecs. I don't know for sure which one is correct, or if any of them is correct.</p>
<p>BTW, the file does not seem to be a normal CSV file.</p>
</div>
<div class="post-text" itemprop="text">
<p>You need to specify the correct codec when opening the file. What the correct codec <em>is</em> we can only guess at; the GitHub sample you uploaded decodes fine when using one of the <a href="https://en.wikipedia.org/wiki/Chinese_character_encoding" rel="nofollow">Chinese GB* codecs</a>, but those codecs are quite eager (text not encoded with one of those can also be decoded, just with the wrong results).</p>
<p>You'll need to ask the source of those CSV files if a codec is known. That could be in the documentation, or in the HTTP <code>Content-Type</code> header (look for a <code>charset=</code> parameter), or by some other metadata means.</p>
<p>To specify the codec when opening the file, use the <code>encoding</code> argument:</p>
<pre><code>with open('20120901_20120915_ACCLOG.csv', 'r', encoding='gbk')  as f:
</code></pre>
<p>See the <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" rel="nofollow"><em>Standard Encodings</em></a> table for what codecs Python 3 can handle out of the box; there are various Chinese codecs to chose from there.</p>
</div>
<span class="comment-copy">Find out their codec and use that when opening the file: <code>open('20120901_20120915_ACCLOG.csv', 'r', encoding='&lt;codec_for_the_file&gt;')</code>.</span>
<span class="comment-copy">We cannot help with determining the codec used. You could use a tool like <code>chardet</code> to <i>guess</i> (based on statistical information), or you could try and see if the source of those files (where you got them from) has specified what codec was used for them. This is not a Python problem, however.</span>
<span class="comment-copy">The file uploaded to GitHub is <i>probably</i> encoded with one of the <a href="https://en.wikipedia.org/wiki/Chinese_character_encoding" rel="nofollow noreferrer">Chinese GB* codecs</a>.</span>
<span class="comment-copy">Thanks for your useful advice.  you saved me lots of time</span>
<span class="comment-copy">np. You should also take Martijn's advice, especially that about verifying the charset with the author or other meta data.</span>
