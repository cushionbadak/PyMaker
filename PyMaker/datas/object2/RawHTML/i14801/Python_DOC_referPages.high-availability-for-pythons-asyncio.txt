<div class="post-text" itemprop="text">
<p>I am trying to create an asynchronous application using Python's <code>asyncio</code> module. However, all implementations I can find on the documentation is based on a single Event Loop.</p>
<p>Is there any way to launch multiple Event Loops running the same application, so I can achieve high availability and fault tolerance? In other words, I want to scale-out my application by inserting new nodes that would share the execution of coroutines behind a load balancer.</p>
<p>I understand there is an inherent issue between asynchronous programming and thread-safety, perhaps what I have in mind isn't even possible. If so, how to avoid this kind of SPOF on asynchronous architectures?</p>
</div>
<div class="post-text" itemprop="text">
<p>The standard way to deal with this is by starting multiple server processes (each with its own event loop), with a load balancer in front. Each such process typically cannot utilize more than one CPU core, so you might want to have as many processes as you have cores.</p>
</div>
<div class="post-text" itemprop="text">
<p>I've done this before. I even wrote code to monitor the processes I spawned. But it turned out that Python &amp; asyncio are quite stable by themselves, I never saw a critical error that stopped the whole event loop. So I don't recommend spawning multiple processes for the sole purpose of high availability.</p>
<p>The code is here if you are interested: <a href="https://github.com/l04m33/shinpachi" rel="nofollow">https://github.com/l04m33/shinpachi</a></p>
<p>You may want to check out <code>shinpachi/__init__.py</code> and <code>shinpachi/processes.py</code>.</p>
</div>
<span class="comment-copy">Are you talking about abstract network code or specific web server like aiohttp?</span>
<span class="comment-copy">You can run multiple event loops, but I'm guessing that you probably want to run multiple instances of your asyncio program and use nginx or some other webserver to load balance them. If that is what you are looking for, i think you can get help on serverfault</span>
<span class="comment-copy">I believe the recommendation is one event loop per process.  If a single event loop process is compute bound, you could clone it to other processes running on other cores, as @leech suggested, but you might be better off only farming out compute tasks.  I believe asyncio has a multiprocessing interface, which I have not, nowever, looked at.</span>
<span class="comment-copy">@TerryJanReedy The only built-in interface for working with multiple processes is <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor" rel="nofollow noreferrer"><code>BaseEventLoop.run_in_executor</code></a>, using a <code>ProcessPoolExecutor</code> as the executor.</span>
<span class="comment-copy">You may want as least as many processes as cores. A 1:1 ratio assumes each process is completely CPU bound.</span>
<span class="comment-copy">If IO is asynchronous then the process should indeed be CPU bound. Do you have data that shows this not to be the case? (could well be possible, I didn't really verify this in a realistic production scenario)</span>
<span class="comment-copy">Thanks, I agree that's the way to go, specially considering I'm working with micro-services architecture in mind. By using Docker, and having possibly dozens of micro-services containers, a 1:1 ratio is not possible, but I agree with @acjay. We might be CPU bound (considering asynchronous IO), but maybe since each container represents a very small part of the system we might be good to go... well, this certainly is another topic to cover and make some benchmarks. Thanks for your time anyway!</span>
