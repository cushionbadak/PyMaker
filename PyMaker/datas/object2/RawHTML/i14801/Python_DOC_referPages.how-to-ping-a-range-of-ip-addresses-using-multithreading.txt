<div class="post-text" itemprop="text">
<p>Lets say that I have the following ip range "10.0.0.x". I need to loop on this range of ips - "10.0.0.1-255", ping each one, and check the response.  </p>
<p>This is my code:  </p>
<pre><code>for ip in range(1, 256):
  fullIP = '10.0.0' + ip
  if(Ping(fullIP) == True):
    print(fullIP + ' responded')
  else:
    print(fullIP + ' did not respond')
</code></pre>
<p>This code works but unfortunately it is very slow.<br/>
I would like to make it more efficient through multi threading so i did the following:  </p>
<pre><code>def PingRange(start, end):
  for ip in range(start, end):
  fullIP = '10.0.0' + ip
  if(Ping(fullIP) == True):
    print(fullIP + ' responded')
  else:
    print(fullIP + ' did not respond')

try:
  thread.start_new_thread( PingRange, (1, 123))
  thread.start_new_thread( PingRange, (123, 256))
except:
  print "Error: unable to start thread"
</code></pre>
<p>This code also works, but it could work better and more universal.<br/>
If this code was written properly then I wouldn't just constantly create two threads; I would create as many threads as the operating system would allow me.<br/>
Some computers allow 8 threads, others allow only 4, and some don't even allow threading.  </p>
<p>How can I make this program use the maximum amount of threads in Python?</p>
</div>
<div class="post-text" itemprop="text">
<p>This problem is well-suited for using a thread pool. A thread pool runs with a constant number of threads, takes work items (functions or methods), and executes those work items in its pool of threads. It has built-in queuing, so if you give one hundred work items to a pool of five threads, it will execute all one hundred items, but without ever running more than five concurrently.</p>
<p>There are two built-in thread pool options in Python (depending on what version you're using) - <a href="https://docs.python.org/2.7/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow"><code>multiprocessing.dummy.Pool</code></a>, and <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor" rel="nofollow"><code>concurrent.futures.ThreadPoolExecutor</code></a>. <code>ThreadPoolExecutor</code> is only built-in in Python 3.x, though a backport is available from PyPI. <code>multiprocessing.dummy.Pool</code> is available in 2.6+. Using a <code>multiprocessing.dummy.Pool</code>, your code becomes as simple as this:</p>
<pre><code>import multiprocessing.dummy

def ping_range(start, end):
    num_threads = # Number of threads to run in the pool.
    p = multiprocessing.dummy.Pool(num_threads)
    p.map(ping, [10.0.0.x for x in range(start,end)])

if __name__ == "__main__":
    PingRange(0, 255)
</code></pre>
<p>The next question is what to use for <code>num_threads</code>. I think you're <em>slightly</em> misinformed about systems having a max number of allowable threads. You can create as many <code>Thread</code> objects as you want on any system, and nothing will actually stop you, but at a certain point you'll create so many threads that the system won't be able to handle it and performance will start to get <em>worse</em>, rather than better. </p>
<p>The rule of thumb for CPU-bound applications (meaning that it primarily requires the CPU to do work) is to run as many threads as there are CPUs. However, this ping operation is I/O-bound, meaning most of the work is sending the ping requests to external systems and then waiting for a response, which doesn't require the CPU to do anything. In those cases, it's usually ok to use more than the number of CPUs. We can be conservative and use <code>2 * number_of_cpus</code>, though you could experiment with a larger number.</p>
<pre><code>import multiprocessing
num_threads = 2 * multiprocessing.cpu_count()
</code></pre>
<p>Putting it all together:</p>
<pre><code>import multiprocessing.dummy
import multiprocessing

def ping(ip):
   success = # Run the ping command here
   if success:
       print("{} responded".format(ip))
   else:
       print("{} did not respond".format(ip))
   return success

def ping_range(start, end):
    num_threads = 2 * multiprocessing.cpu_count()
    p = multiprocessing.dummy.Pool(num_threads)
    p.map(ping, [10.0.0.x for x in range(start,end)])

if __name__ == "__main__":
    ping_range(0, 255)
</code></pre>
</div>
<span class="comment-copy"><code>Some computers allow 8 threads, others allow only 4, and some don't even allow threading.</code> So what kind of architecture are we talking here?</span>
<span class="comment-copy">Why is the architecture relevant? I want the code to work as efficiently as possible on all architectures.</span>
<span class="comment-copy">Because no system one can realistically encounter may be unable to handle mere 256 threads.</span>
<span class="comment-copy">i would suggest adding a few more details here, firstly what form does your 'Ping' function take? as this isnt a builtin (as far as i can tell) and secondly have you looked at multiprocessing? specifically the pool function? as python uses a global interpreter lock only one thread can run in a process at once, this means that typically using multiple threads actually slows down your task (no speeding it up) to do things simultaneously you need to use multiple processes.</span>
<span class="comment-copy">thanks this code is really simple and it works, but it would be even better if it would have exception handling.sometimes when i run this code on other computers it throws me exceptions. could you add exception handling to this code?</span>
