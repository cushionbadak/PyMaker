<div class="post-text" itemprop="text">
<p>I'm trying to include the weights for training the CNN via the following code :</p>
<pre><code>loss = tf.losses.mean_squared_error(label,x_op, weights = weight_mask);
global_step = tf.Variable(0,trainable=False)
learning_rate = tf.train.exponential_decay(0.0001, global_step, 5000, 0.9, staircase=False)
update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
with tf.control_dependencies(update_ops):
        train_step = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1= 0.9, beta2=0.999, epsilon = 1e-08
        ,use_locking=False).minimize(loss)

sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))
sess.run(tf.global_variables_initializer())
</code></pre>
<p>However, for whatever reason I had the following error code:</p>
<pre><code>ValueError Traceback (most recent call last)
    &lt;ipython-input-105-10c144d08f60&gt; in &lt;module&gt;()
         97 
         98         # Loss
    ---&gt; 99 loss = tf.losses.mean_squared_error(label,x_op, weights = weight_mask);
        100 global_step = tf.Variable(0,trainable=False)
        101 learning_rate = tf.train.exponential_decay(0.0001, global_step, 5000, 0.9, staircase=False)

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py in mean_squared_error(labels, predictions, weights, scope, loss_collection, reduction)
        670     losses = math_ops.squared_difference(predictions, labels)
        671     return compute_weighted_loss(
    --&gt; 672         losses, weights, scope, loss_collection, reduction=reduction)
        673 
        674 

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py in compute_weighted_loss(losses, weights, scope, loss_collection, reduction)
        204 
        205     with ops.control_dependencies((
    --&gt; 206         weights_broadcast_ops.assert_broadcastable(weights, losses),)):
        207       losses = ops.convert_to_tensor(losses)
        208       input_dtype = losses.dtype

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/weights_broadcast_ops.py in assert_broadcastable(weights, values)
        101             " values.shape=%s. weights.shape=%s." % (
        102                 _ASSERT_BROADCASTABLE_ERROR_PREFIX, values_rank_static,
    --&gt; 103                 weights_rank_static, values.shape, weights.shape))
        104       weights_shape_static = tensor_util.constant_value(weights_shape)
        105       values_shape_static = tensor_util.constant_value(values_shape)

    ValueError: weights can not be broadcast to values. values.rank=4. weights.rank=3. values.shape=(?, 256, 256, 3). weights.shape=(256, 256, 3).
</code></pre>
<p>Can anyone tell me what is wrong?</p>
</div>
<div class="post-text" itemprop="text">
<p>As the tensorflow document says that <strong>Tensor whose rank is either 0, or the same rank as labels, and must be broadcastable to labels(i.e., all dimensions must be either 1, or the same as the corresponding losses dimension).</strong></p>
<p>And you can look at the conditions that broadcasting needs to meet in numpy(<a href="https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html" rel="nofollow noreferrer">link</a>), which the same as tensorflow.</p>
<blockquote>
<p>General Broadcasting Rules:</p>
<p>When operating on two arrays, NumPy compares their shapes
  element-wise. It starts with the trailing dimensions, and works its
  way forward. Two dimensions are compatible when</p>
<p>1.they are equal, or</p>
<p>2.one of them is 1</p>
</blockquote>
<p>So you need to change dimension of <code>weight_mask</code> to <code>(1,256,256,3)</code>.</p>
<pre><code>weight_mask = tf.expand_dims(weight_mask,axis=0)
</code></pre>
</div>
<span class="comment-copy">Hi ! Can you post your error code directly on your question instead of a picture ? This will help people to copy it and help you in a more efficient way :-)</span>
<span class="comment-copy">@toshiro92 Fixed it, thank you. :)</span>
