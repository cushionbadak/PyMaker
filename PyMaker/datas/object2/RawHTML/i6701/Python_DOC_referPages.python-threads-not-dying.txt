<div class="post-text" itemprop="text">
<p>I have the following code which spawns 10 threads that copy files from a file list. I am calling this over and over again for different lists of files and I found that the threads don't seem to be dying once the fileQueue has run out... I noticed that the code seemed to slow down with long operations, and then I had a crash within the threads and started to see "Exception in thread Thread-45:"!</p>
<p>Here's my code, from everything I know in reading the manual this is pretty clean and simple:</p>
<pre><code>import Queue, threading
from PyQt4 import QtCore, QtGui
import shutil

fileQueue = Queue.Queue()

class ThreadedCopy:
    totalFiles = 0
    copyCount = 0
    lock = threading.Lock()

    def __init__(self, inputList, progressBar=False):
        self.totalFiles = len(inputList)

        print str(self.totalFiles) + " files to copy."

        if progressBar:
            progressBar = QtGui.QProgressDialog("Copying files...", "Cancel", 0, self.totalFiles)
            progressBar.setMinimumDuration(0)
            progressBar.setWindowModality(QtCore.Qt.WindowModal)
            self.threadWorkerCopy(inputList, progressBar)
        else:
            self.threadWorkerCopy(inputList)


    def CopyWorker(self, progressBar):
        while True:
            fileName = fileQueue.get()
            shutil.copy(fileName[0], fileName[1])
            fileQueue.task_done()
            with self.lock:
                self.copyCount += 1
                if not progressBar:
                    print str(self.copyCount) + "of" + str(self.totalFiles)
                    percent = (self.copyCount * 100) / self.totalFiles
                    print "File copy: " + str(percent) + "%"
                else:
                    progressBar.setValue(self.copyCount)


    def threadWorkerCopy(self, fileNameList, progressBar=False):
        threadCount = 10
        for i in range(threadCount):
            t = threading.Thread(target=self.CopyWorker, args=(progressBar,))
            t.daemon = True
            t.start()
        for fileName in fileNameList:
            fileQueue.put(fileName)

        fileQueue.join()
</code></pre>
<p>Does anyone know why the threads are not just cleanly dying in between calls of this code? From what I understand once the fileQueue has run out then they should just quietly die!</p>
<p>EDIT: Here's the fixed code</p>
<pre><code>import Queue, threading
from PyQt4 import QtCore, QtGui
import shutil


fileQueue = Queue.Queue()

class ThreadedCopy:
    totalFiles = 0
    copyCount = 0
    lock = threading.Lock()

    def __init__(self, inputList, progressBar=False):
        self.totalFiles = len(inputList)

        print str(self.totalFiles) + " files to copy."

        if progressBar:
            progressBar = QtGui.QProgressDialog("Copying files...", "Cancel", 0, self.totalFiles)
            progressBar.setMinimumDuration(0)
            progressBar.setWindowModality(QtCore.Qt.WindowModal)
            self.threadWorkerCopy(inputList, progressBar)
        else:
            self.threadWorkerCopy(inputList)


    def CopyWorker(self, progressBar):
        while True:
            fileName = fileQueue.get()
            if fileName is None:
                fileQueue.task_done()
                break

            shutil.copy(fileName[0], fileName[1])
            fileQueue.task_done()

            with self.lock:
                self.copyCount += 1
                if not progressBar:
                    percent = (self.copyCount * 100) / self.totalFiles
                    print "File copy: " + str(percent) + "%"
                else:
                    progressBar.setValue(self.copyCount)


    def threadWorkerCopy(self, fileNameList, progressBar=False):
        threads = []
        threadCount = 10

        for fileName in fileNameList:
            fileQueue.put(fileName)
        for i in range(threadCount):
            t = threading.Thread(target=self.CopyWorker, args=(progressBar,))
            t.daemon = True
            t.start()
            threads.append(t)
            fileQueue.put(None)
        for t in threads:
            t.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Why do you think the threads will die? There's nothing in <code>CopyWorker</code> that breaks out of the <code>while True</code> loop, so I'd expect the threads to remain alive indefinitely. Once all the items have been consumed, they'll be permanently blocked trying to <code>get</code> another value from the empty queue, but they won't quit or free their resources.</p>
<p>If you want your threads to quit when there's no more work to be done, you will need to tell them to do so. A common way of doing that is to send a sentinel value over the queue, which the consuming thread will recognize as being the signal that there's no more data. You'll need to send one copy of the sentinel for each thread you've started. Here's a quick untested solution based on your current code. I'm using <code>None</code> as the sentinel, since it doesn't look like it could be a normal value for the filename.</p>
<pre><code>def CopyWorker(self, progressBar):
    while True:
        fileName = fileQueue.get()
        if fileName is None:             # check for sentinel value here
            fileQueue.task_done()
            return
        shutil.copy(fileName[0], fileName[1])
        fileQueue.task_done()
        with self.lock:
            self.copyCount += 1
            if not progressBar:
                print str(self.copyCount) + "of" + str(self.totalFiles)
                percent = (self.copyCount * 100) / self.totalFiles
                print "File copy: " + str(percent) + "%"
            else:
                progressBar.setValue(self.copyCount)


def threadWorkerCopy(self, fileNameList, progressBar=False):
    threadCount = 10
    for i in range(threadCount):
        t = threading.Thread(target=self.CopyWorker, args=(progressBar,))
        t.daemon = True
        t.start()
    for fileName in fileNameList:
        fileQueue.put(fileName)
    for i in range(threadCount):     # send sentinel values from here
        fileQueue.put(None)
    fileQueue.join()
</code></pre>
<p>There are a few other things you could do which I've omitted for simplicity. For instance, it might be a good idea to keep a reference to each thread you start and <code>join</code> them all from the main thread to make sure they've all exited. This could be an alternative to <code>join</code>ing the queue, perhaps. There's also no reason for the threads to be daemons if they're exiting properly.</p>
<p>You could also reorder some of the code so that you don't need two <code>for i in range(threadCount)</code> loops. If you <code>put</code> all the values into the queue first, before starting the threads, you could combine the two loops.</p>
</div>
<div class="post-text" itemprop="text">
<p>You probably forgot to call <code>.join</code> for every thread. From <a href="https://docs.python.org/3/library/queue.html#queue.Queue.join" rel="nofollow noreferrer">documentation</a></p>
<p>Need to add code after <code>fileQueue.join()</code>. But you should add all thread to <code>list</code> after <code>t.start()</code>(look to an exemple)</p>
<pre><code>for i in range(threadCount):
    fileQueue.put(None)
for t in threads:
    t.join()
</code></pre>
</div>
<span class="comment-copy">Thanks, this was very helpful! I had the same thought on the while loop never closing, however I assumed it wasn't the problem because I took that from the documentation here <a href="https://docs.python.org/2/library/queue.html" rel="nofollow noreferrer">doc</a>. I've updated my question above with my fixed code.</span>
<span class="comment-copy">The example code you linked works fine as a complete script that exits immediately after the queued up tasks have been completed. But it's a very bad approach for a function within a longer-running program. That design "leaks" the threads, but in a short lived script that is OK because they'll get cleaned up when the interpreter exits (the threads are set as daemons so that they won't prevent the interpreter from shutting down). In your fixed code, you could drop the <code>t.daemon = True</code> line and the <code>task_done</code> calls, since you're not <code>join</code>ing the queue any more.</span>
<span class="comment-copy">I see, there's no reason to make them daemonic and at this point task_done is just redundant. I thought I still needed it for some reason, but I see it's only for the queue.join function. Thanks!</span>
<span class="comment-copy">Thanks AndMar but this doesn't do it, I was joining the queue which basically does the same thing (it waits for the queue to complete before moving on). That said, I agree with you and Blckknght that this is a better idea than joining the queue so I have incorporated it into my code!</span>
