<div class="post-text" itemprop="text">
<p>I am looking to interface with an interactive command line application using Python 3.5. The idea is that I start the process at the beginning of the Python script and leave it open. In a loop, I print a file path, followed by a line return, to <code>stdin</code>, wait for a quarter second or so as it processes, and read from <code>stdout</code> until it reaches a newline.</p>
<p>This is quite similar to the <code>communicate</code> feature of <code>subprocess</code>, but I am waiting for a line return instead of waiting for the process to terminate. Anyone aware of a relatively simple way to do this?</p>
<p>Edit: it would be preferable to use the standard library to do this, rather than third-party libraries such as <code>pexpect</code>, if possible.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use subprocess.Popen for this.</p>
<p>Something like this:</p>
<pre><code>proc = subprocess.Popen(['my-command'], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
</code></pre>
<p>Now <code>proc.stdin</code> and <code>proc.stdout</code> are your ends of pipes that send data to the subprocess stdin and read from the subprocess stdout.</p>
<p>Since you're only interested in reading newline-terminated lines, you can probably get around any problems caused by buffering. Buffering is one of the big gotchas when using subprocess to communicate with interactive processes. Usually I/O is line-buffered, meaning that if the subprocess doesn't terminate a line with newline, you might never see any data on <code>proc.stdout</code>, and vice versa with you writing to <code>proc.stdin</code> - it might  not see it if you're not ending with newline. You can turn buffering off, but that's not so simple, and not platform independent.</p>
<p>Another problem you might have to solve is that you can't determine whether the subprocess is waiting for input or has sent you output except by writing and reading from the pipes. So you might need to start a second thread so you can wait for output on <code>proc.stdout</code> and write to <code>proc.stdin</code> at the same time without running into a deadlock because both processes are blocking on pipe I/O (or, if you're on a Unix which supports select with file handles, use <code>select</code> to determine which pipes are ready to receive or ready to be read from).</p>
</div>
<div class="post-text" itemprop="text">
<p>This sounds like a job for an event loop. The <code>subprocess</code> module starts to show its strain under complex tasks.</p>
<p>I've done this with Twisted, by subclassing the following:</p>
<pre><code>twisted.internet.endpoints.ProcessEndpoint
twisted.protocols.basic.LineOnlyReceiver
</code></pre>
<p>Most documentation for Twisted uses sockets as endpoints, but it's not hard to adjust the code for processes.</p>
</div>
<span class="comment-copy">Have you looked at the <code>pexpect</code> module?</span>
<span class="comment-copy">@JonClements I have used it previously for SSH. I will look into it for this however. Thank you!</span>
<span class="comment-copy">yet ... use <code>pexpect</code>. There are gazillion complications which is why the use of standard library cannot be recommended.</span>
<span class="comment-copy">Well... you could get something going with <a href="https://docs.python.org/3/library/asyncio-subprocess.html" rel="nofollow noreferrer">docs.python.org/3/library/asyncio-subprocess.html</a> if you really wanted...</span>
<span class="comment-copy">@AnttiHaapala Yeah, I guess pexpect seems like the right decision.</span>
