<div class="post-text" itemprop="text">
<p>I was just messing around with numpy arrays when I realized the lesser known behavior of the <code>dtypes</code> parameter.</p>
<p>It seems to change as the input changes. For example,</p>
<pre><code>t = np.array([2, 2])
t.dtype
</code></pre>
<p>gives <code>dtype('int32')</code></p>
<p>However,</p>
<pre><code>t = np.array([2, 22222222222])
t.dtype
</code></pre>
<p>gives <code>dtype('int64')</code></p>
<p><em>So, my first question is: How is this calculated? Does it make the datatype suitable for the maximum element as a datatype for all the elements? If that is the case, don't you think it requires more space because it is unnecessarily storing excess memory to store 2 in the second array as a 64 bit integer?</em> </p>
<p>Now again, if I want to change the zeroth element of <code>array([2, 2])</code> like</p>
<pre><code>t = np.array([2, 2])
t[0] = 222222222222222
</code></pre>
<p>I get <code>OverflowError: Python int too large to convert to C long</code>. </p>
<p><em>My second question is: Why it does not support the same logic it did while creating the array if you change a particular value? Why does it not recompute and reevaluate?</em> </p>
<p>Any help is appreciated. Thanks in advance.</p>
</div>
<div class="post-text" itemprop="text">
<p>Let us try and find the relevant bits in the docs.</p>
<p>from the <code>np.array</code> doc string:</p>
<blockquote>
<p>array(...)</p>
<p>[...]</p>
<h2>Parameters</h2>
<p>[...]</p>
<p>dtype : data-type, optional
      The desired data-type for the array.  If not given, then <strong>the type will
      be determined as the minimum type required to hold the objects in the
      sequence.</strong>  This argument can only be used to 'upcast' the array.  For
      downcasting, use the .astype(t) method.</p>
<p>[...]</p>
</blockquote>
<p>(my emphasis)</p>
<p>It should be noted that this is not entirely accurate, for example for integer arrays the system (C) default integer is preferred over smaller integer types as is evident form your example.</p>
<p>Note that for numpy to be fast it is essential that all elements of an array be of the same size. Otherwise, how would you quickly locate the 1000th element, say? Also, mixing types  wouldn't save all that much space since you would have to store the types of every single element on top of the raw data.</p>
<p>Re your second question. First of all. There are type promotion rules in numpy. The best doc I could find for that is the <code>np.result_type</code> doc string:</p>
<blockquote>
<p>result_type(...) result_type(*arrays_and_dtypes)</p>
<p>Returns the type that results from applying the NumPy type promotion
  rules to the arguments.</p>
<p>Type promotion in NumPy works similarly to the rules in languages like
  C++, with some slight differences.  When both scalars and arrays are
  used, the array's type takes precedence and the actual value of the
  scalar is taken into account.</p>
<p>For example, calculating 3*a, where a is an array of 32-bit floats,
  intuitively should result in a 32-bit float output.  If the 3 is a
  32-bit integer, the NumPy rules indicate it can't convert losslessly
  into a 32-bit float, so a 64-bit float should be the result type. By
  examining the value of the constant, '3', we see that it fits in an
  8-bit integer, which can be cast losslessly into the 32-bit float.</p>
<p>[...]</p>
</blockquote>
<p>I'm not quoting the entire thing here, refer to the doc string for more detail.</p>
<p>The exact way these rules apply are complicated and appear to represent a compromise between being intuitive and efficiency.</p>
<p>For example, the choice is based on inputs, not result</p>
<pre><code>&gt;&gt;&gt; A = np.full((2, 2), 30000, 'i2')
&gt;&gt;&gt; 
&gt;&gt;&gt; A
array([[30000, 30000],
       [30000, 30000]], dtype=int16)
# 1
&gt;&gt;&gt; A + 30000
array([[-5536, -5536],
       [-5536, -5536]], dtype=int16)
# 2
&gt;&gt;&gt; A + 60000
array([[90000, 90000],
       [90000, 90000]], dtype=int32)
</code></pre>
<p>Here efficiency wins. It would arguably be more intuitive to have #1 behave like #2. But this would be expensive.</p>
<p>Also, and more directly related to your question, type promotion only applies out-of-place, not in-place:</p>
<pre><code># out-of-place
&gt;&gt;&gt; A_new = A + 60000
&gt;&gt;&gt; A_new
array([[90000, 90000],
       [90000, 90000]], dtype=int32)
# in-place
&gt;&gt;&gt; A += 60000
&gt;&gt;&gt; A
array([[24464, 24464],
       [24464, 24464]], dtype=int16)
</code></pre>
<p>or</p>
<pre><code># out-of-place
&gt;&gt;&gt; A_new = np.where([[0, 0], [0, 1]], 60000, A)
&gt;&gt;&gt; A_new
array([[30000, 30000],
       [30000, 60000]], dtype=int32)
# in-place
&gt;&gt;&gt; A[1, 1] = 60000
&gt;&gt;&gt; A
array([[30000, 30000],
       [30000, -5536]], dtype=int16)
</code></pre>
<p>Again, this may seem rather non-intuitive. There are, however, compelling reasons for this choice.</p>
<p>And these should answer your second question:</p>
<p>Changing to a larger dtype would require allocating a larger buffer and copying over all the data. Not only would that be expensive for large arrays.</p>
<p>Many idioms in numpy rely on views and the fact that writing to a view directly modifies the base array (and other overlapping views). Therefore an array is not free to change its data buffer whenever it feels like it. To not break the link between views it would be necessary for an array to be aware of all views into its data buffer which would add a lot of admin overhead, and all those views would have to change their data pointers and metadata as well. And if the first array is itself a view (a slice, say) into another array things get even worse.</p>
<p>I suppose we can agree on that not being worth it and that is why types are not promoted in-place.</p>
</div>
<span class="comment-copy">I believe <code>int32</code>  is the default <code>dtype</code> for integers in numpy.  However, <code>22222222222</code> is larger than <code>2**32//2-1</code> (the max value for an <code>int32</code>), so <code>int64</code> is used instead</span>
<span class="comment-copy">Once created the <code>dtype</code> of an array is fixed.  Set values are changed to conform to that dtype, if possible.  <code>view</code> and <code>astype</code> create new arrays.  <code>np.array</code> is a complex function, capable of handling a wide variety of inputs.  It evaluates all input values, and chooses a dtype that will accommodate all.  Most of us accept that choice as a black-box operation - the results are usually logical.</span>
<span class="comment-copy">@hpaulj <i>"Most of us accept that choice as a black-box operation."</i> You just made my day :-)</span>
