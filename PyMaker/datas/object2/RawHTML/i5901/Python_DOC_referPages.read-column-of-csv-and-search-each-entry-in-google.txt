<div class="post-text" itemprop="text">
<p>I have a list of articles which don't contain URLs of the producer (the articles are all from one producer). I would like to add the URLs of the article to each article. </p>
<p>For now I only have this:</p>
<pre><code>import csv

included_cols = [1]
content = list()

with open("preisliste.csv", "rb") as csvfile:
    reader = csv.reader(csvfile, delimiter=";", quotechar="|")
    for row in reader:
        content.append(list(row[i] for i in included_cols))

print(content)
</code></pre>
<p>The output looks like this: </p>
<pre><code>[['Artikelbezeichnung'], ['VM-2N'], ['VM-8H'], ['VM-16H'], ['VM-24HC'], ['VM-4HC'], ['VM-400HDCP'], ['VM-4HN'], ['VM-3HN'], ['VM-214DT/220V'], ['VM-212DT/220V'], ['VM-8HN'],...]
</code></pre>
<p>Now I would like to search each String (for example "VM-2N") in Google an save the URL of a hit in a new column. </p>
<p>Is something like this possible?</p>
</div>
<div class="post-text" itemprop="text">
<p>Each one of your Google searches would give you multiple results, so it not clear how you would want to add this as an extra column.</p>
<p>The following shows how you could extract the first results for each of your search terms. It uses BeautifulSoup to help parse the returned HTML and writes the search term, the heading and the URL for the first page of results to a file:</p>
<pre><code>from bs4 import BeautifulSoup
import csv
import requests
import urllib

with open("preisliste.csv", "r", newline="") as f_input:
    csv_reader = csv.reader(f_input, delimiter=";", quotechar="|")
    header = next(csv_reader)
    items = [row[1] for row in csv_reader]

with open("results.csv", "w", newline="") as f_output:
    csv_writer = csv.writer(f_output, delimiter=";")

    for item in items: 
        search_url = "https://www.google.de/search?&amp;q={}".format(urllib.parse.quote_plus(item, safe='/'))
        google_request = requests.get(search_url)
        soup = BeautifulSoup(google_request.content, "html.parser")    

        for r in soup.find_all('h3', class_='r'):
            if r.find('a', href=True):
                csv_writer.writerow([item, r.a.text, r.a['href'][7:]])
</code></pre>
<p>This would give you an output file starting something like:</p>
<pre class="lang-none prettyprint-override"><code>VM-2N;VM-2N - Kramer Electronics;https://www.kramerav.com/Product/VM-2N&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFggUMAA&amp;usg=AOvVaw0jAAJ88F8a7I3lxDu_MN5q
VM-2N;KRAMER VM-2N DISTRIBUTION AMPLIFIER AV, 1x2, 1x CVBS ...;https://www.canford.co.uk/Products/90-401_KRAMER-VM-2N-DISTRIBUTION-AMPLIFIER-AV-1x2-1x-CVBS-BNC-2x-audio-RCAphono230V-AC-50Hz&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFggaMAE&amp;usg=AOvVaw0llPJeJ9wO6fxPJVLlfxGu
VM-2N;Kramer VM-2N 1x2 Audio/Video Distribution Amplifier VM-2N B&amp;H;https://www.bhphotovideo.com/c/product/262082-REG/Kramer_VM_2N_VM_2N_1x2_Audio_Video_Distribution.html&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFgggMAI&amp;usg=AOvVaw05q42rkuyyZX2DS__UY2Sv
VM-2N;Kramer VM-2N Amplifier - ProAV;https://www.proav.co.uk/vm-2n-amplifier&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFggmMAM&amp;usg=AOvVaw2KoAR4OJhRT6wsIn5uZZEq
VM-2N;Kramer VM-2N - 1:2 Video Audio Distribution Amplifier - Ivojo;http://www.ivojo.co.uk/component.php%3Fpid%3DKramer_VM-2N&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFggrMAQ&amp;usg=AOvVaw2A-Jjg0pxmKXz_TuOOExbz
VM-2N;Kramer VM-2N (VM2N) 1:2 Composite Video &amp; Stereo Audio ...;https://www.tnpbroadcast.co.uk/kramer-vm-2n-vm2n-1-2-composite-video-stereo-audio-distribution-amplifier-p215&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFggwMAU&amp;usg=AOvVaw1a8ST4dljVr326BsO4wmRa
VM-2N;Amazon.com: Kramer Electronics VM-2N 1:2 Composite/SDI Video ...;https://www.amazon.com/Kramer-Electronics-VM-2N-Composite-Distribution/dp/B001N4DFWM&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFgg1MAY&amp;usg=AOvVaw2F2NZ7RoZvKN-ITCgld6l3
VM-2N;Kramer VM-2N distribution amplifier - VM-2N - Audio/Video Switch ...;https://www.cdw.com/shop/products/Kramer-VM-2N-distribution-amplifier/2539932.aspx&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFgg6MAc&amp;usg=AOvVaw3gDb60PFLKCXHkTEoTym8u
VM-2N;Kramer VM2N 1x2 Composite SDI distribution Amp with audio | Full ...;http://www.fullcompass.com/prod/052437-Kramer-VM2N&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFgg_MAg&amp;usg=AOvVaw0616aM6qPT5inaKTcs7xca
VM-2N;Kramer VM-2N 1:2 Composite Video &amp; Stereo Audio Distribution ...;https://www.vartotechnologies.com/1_2_Composite_Video_Stereo_Audio_Dist_Amp_p/vm-2n.htm&amp;sa=U&amp;ved=0ahUKEwj8ruWbld_XAhXLyKQKHRwpBaoQFghEMAk&amp;usg=AOvVaw1k3yzXHmkznJlmKED7K5-4
VM-8H;VM-8H - Kramer Electronics;https://www.kramerav.com/product/VM-8H&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggUMAA&amp;usg=AOvVaw1uxXnx96PtvD0nXDdu9QTJ
VM-8H;1:8 HDMI Distribution Amplifier;https://k.kramerav.com/downloads/pdf/product/1/VM-8H.pdf&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggaMAE&amp;usg=AOvVaw0IVNeBYAHxlIg_uVMrBZ2i
VM-8H;VM-8H (previously VM-8HDMI);https://k.kramerav.com/downloads/pdf/product/1/VM-8H%2520(previously%2520VM-8HDMI).pdf&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggfMAI&amp;usg=AOvVaw089BRCWL-44VnWIXtd1YiZ
VM-8H;Kramer VM-8H 1:8 HDMI Distribution Amplifier VM-8H-NV B&amp;H Photo;https://www.bhphotovideo.com/c/product/904931-REG/kramer_vm_8h_nv_1_8_hdmi_distribution.html&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggkMAM&amp;usg=AOvVaw3jGZ4zLUW-Ac8IjFYNiM3z
VM-8H;Kramer VM-8H - 1:8 HDMI 1.4 Distribution Amplifier - Ivojo;http://www.ivojo.co.uk/component.php%3Fpid%3DKramer_VM-8H&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggrMAQ&amp;usg=AOvVaw37wIQ71tX7EHk0D9ryy11f
VM-8H;Amazon.com: Kramer Electronics HDMI Splitter VM-8H: Electronics;https://www.amazon.com/Kramer-Electronics-HDMI-Splitter-VM-8H/dp/B0052VEB1G&amp;sa=U&amp;ved=0ahUKEwjtsf-bld_XAhUQzqQKHbzzDT8QFggxMAU&amp;usg=AOvVaw0AV3RCtqSezGdt9LiCp0iU
</code></pre>
<p>Note, you should not be accessing Google in this manner. You should instead look into the API.</p>
</div>
<span class="comment-copy">yes... You need to <code>import requests</code> and send a GET request to <code>'https://www.google.com/search?&amp;q=' + example_string</code>. You'd then need to extract the results, with a HTML parser such as BeautifulSoup.</span>
<span class="comment-copy">Welcome to SO. Unfortunately this isn't a discussion forum or tutorial. Please take the time to read <a href="https://stackoverflow.com/questions/how-to-ask">How to Ask</a> and the links it contains.  Invest some time with <a href="https://docs.python.org/3/tutorial/index.html" rel="nofollow noreferrer">the Tutorial</a> practicing the examples. It will give you an idea of the tools Python offers to help you solve your problem.</span>
<span class="comment-copy"><code>for items in content: 	for strings in items: 		print(requests.get("https://www.google.de/search?&amp;q=", strings))</code> Gives me 200, so it seems to work. But how do I save now the results?</span>
<span class="comment-copy">Thank you so much for your help!    But I have following error if I run this code:   <code>[0] #( 28.11.17@15:21 )( dun@Arch64L ):~/_workspace/py/search-articles python3 search3.py   Traceback (most recent call last):     File "search3.py", line 8, in &lt;module&gt;       header = next(csv_reader)     File "/usr/lib/python3.6/codecs.py", line 321, in decode       (result, consumed) = self._buffer_decode(data, self.errors, final)   UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe4 in position 157: invalid continuation byte</code></span>
<span class="comment-copy">It would appear that your CSV file needs to be read in using a different encoding or altered. The header row appears to contain invalid characters for <code>utf-8</code> encoding. You could try using <code>open("preisliste.csv", "r", newline="", encoding="cp1252")</code></span>
<span class="comment-copy">Now it works, thank you so much! :)</span>
<span class="comment-copy">Sorry to bother you, but do you know how I could limit the amount of results to the first two results?</span>
<span class="comment-copy">Just add <code>[:2]</code> as follows: <code>for r in soup.find_all('h3', class_='r')[:2]:</code></span>
