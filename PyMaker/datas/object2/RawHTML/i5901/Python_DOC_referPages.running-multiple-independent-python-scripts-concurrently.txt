<div class="post-text" itemprop="text">
<p>My goal is create one main python script that executes multiple independent python scripts in windows server 2012 at the same time. One of the benefits in my mind is that I can point taskscheduler to one <code>main.py</code> script as opposed to multiple <code>.py</code> scripts. My server has 1 cpu. I have read on <code>multiprocessing</code>,<code>thread</code> &amp; <code>subprocess</code> which only added to my confusion a bit. I am basically running multiple trading scripts for different stock symbols all at the same time after market open at 9:30 EST. Following is my attempt but I have no idea whether this is right. Any direction/feedback is highly appreciated!</p>
<pre><code>import subprocess

subprocess.Popen(["python", '1.py'])
subprocess.Popen(["python", '2.py'])
subprocess.Popen(["python", '3.py'])
subprocess.Popen(["python", '4.py'])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think I'd try to do this like that:</p>
<pre><code>from multiprocessing import Pool

def do_stuff_with_stock_symbol(symbol):
    return _call_api()

if __name__ == '__main__':
    symbols = ["GOOG", "APPL", "TSLA"]
    p = Pool(len(symbols))
    results = p.map(do_stuff_with_stock_symbol, symbols)
    print(results)
</code></pre>
<p>(Modified example from multiprocessing introduction: <a href="https://docs.python.org/3/library/multiprocessing.html#introduction" rel="nofollow noreferrer">https://docs.python.org/3/library/multiprocessing.html#introduction</a>)</p>
<p>Consider using a constant pool size if you deal with a lot of stock symbols, because every python process will use some amount of memory.</p>
<p>Also, please note that using threads might be a lot better if you are dealing with an I/O bound workload (calling an API, writing and reading from disk). Processes really become necessary with python when dealing with compute bound workloads (because of the global interpreter lock).</p>
<p>An example using threads and the concurrent futures library would be:</p>
<pre><code>import concurrent.futures

TIMEOUT = 60

def do_stuff_with_stock_symbol(symbol):
    return _call_api()

if __name__ == '__main__':
    symbols = ["GOOG", "APPL", "TSLA"]

    with concurrent.futures.ThreadPoolExecutor(max_workers=len(symbols)) as executor:
        results = {executor.submit(do_stuff_with_stock_symbol, symbol, TIMEOUT): symbol for symbol in symbols}

        for future in concurrent.futures.as_completed(results):
            symbol = results[future]
            try:
                data = future.result()
            except Exception as exc:
                print('{} generated an exception: {}'.format(symbol, exc))
            else:
                print('stock symbol: {}, result: {}'.format(symbol, data))
</code></pre>
<p>(Modified example from: <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="nofollow noreferrer">https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example</a>)</p>
<p>Note that threads will still use some memory, but less than processes.</p>
<p>You could use asyncio or green threads if you want to reduce memory consumption per stock symbol to a minimum, but at some point you will run into network bandwidth problems because of all the concurrent API calls :)</p>
</div>
<div class="post-text" itemprop="text">
<p>While what you're asking might not be the best way to handle what you're doing, I've wanted to do similar things in the past and it took a while to find what I needed so to answer your question:</p>
<p>I'm not promising this to be the "best" way to do it, but it worked in my use case.</p>
<p>I created a class I wanted to use to extend threading.</p>
<p>thread.py</p>
<pre><code>"""
Extends threading.Thread giving access to a Thread object which will accept
A thread_id, thread name, and a function at the time of instantiation. The
function will be called when the threads start() method is called.
"""

import threading


class Thread(threading.Thread):
    def __init__(self, thread_id, name, func):
        threading.Thread.__init__(self)
        self.threadID = thread_id
        self.name = name

        # the function that should be run in the thread.
        self.func = func

    def run(self):
        return self.func()
</code></pre>
<p>I needed some work done that was part of another package</p>
<p>work_module.py</p>
<pre><code>import...

def func_that_does_work():
    # do some work
    pass

def more_work():
    # do some work
    pass
</code></pre>
<p>Then the main script I wanted to run
main.py</p>
<pre><code>from thread import Thread
import work_module as wm


mythreads = []
mythreads.append(Thread(1, "a_name", wm.func_that_does_work))
mythreads.append(Thread(2, "another_name", wm.more_work))

for t in mythreads:
    t.start()
</code></pre>
<p>The threads die when the run() is returned. Being this extends a Thread from threading there are several options available in the docs here: <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">https://docs.python.org/3/library/threading.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>If all you're looking to do is automate the startup, creating a .bat file is a great and simple alternative to trying to do it with another python script.</p>
<p>the example linked in the comments shows how to do it with bash on unix based machines, but batch files can do a very similar thing with the <code>START</code> command:</p>
<p>start_py.bat:</p>
<pre><code>START "" /B "path\to\python.exe" "path\to\script_1.py"
START "" /B "path\to\python.exe" "path\to\script_2.py"
START "" /B "path\to\python.exe" "path\to\script_3.py"
</code></pre>
<p>the full syntax for <code>START</code> can be found <a href="https://ss64.com/nt/start.html" rel="nofollow noreferrer">here</a>.</p>
</div>
<span class="comment-copy">try using queuing , for example sqs</span>
<span class="comment-copy">I love Python -- but this may be one of those times when bash would be a better tool for you: <a href="https://stackoverflow.com/questions/28549641/run-multiple-python-scripts-concurrently" title="run multiple python scripts concurrently">stackoverflow.com/questions/28549641/â€¦</a></span>
<span class="comment-copy">Are the python scripts related in some way or completely unrelated? If yes, what's the relation?</span>
<span class="comment-copy">Bash?  On Windows Server 2012?</span>
<span class="comment-copy">@SteveJ bash -&gt; batch. pretty much the exact same can be accomplished with <code>START "" "path-to-python" "path-to-script"</code></span>
<span class="comment-copy">Wow, this might be a better approach than the solution I imagined. So do I put all the regular code after the return call within the do_stuff_with_stock_symbol(symbol) method? Any idea how to perform the exact thing with threading as I have only 1GB ram in my server.</span>
<span class="comment-copy">instead of return <code>_call_api()</code> you can do (probably almost) anything you want. I added a threaded example.</span>
<span class="comment-copy">Thank you for the answer! Do you recommend the threaded example given you have a good idea of what I am trying to do which is run multiple trading scripts for different symbols all at the same time after market open at 9:30 EST?</span>
<span class="comment-copy">Not sure if I have enough info to recommend anything, but for I/O bound workloads threads and asyncio make more sense than processes IMO. If this helped you, please mark my answer as accepted :)</span>
<span class="comment-copy">@gibbz00 In other words: If you are not trying to call the API <i>AND</i> compute thousands of prime numbers, use threads or asyncio! :)</span>
