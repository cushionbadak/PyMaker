<div class="post-text" itemprop="text">
<p>I want to join a list of ids to a string, where each id is separated by an 'OR'. In python I can do that with </p>
<pre><code>' OR '.join(list_of_ids)
</code></pre>
<p>I am wondering whether there is a way to prevent this string from becoming too large (in terms of bytes). The reason why this is important for me is that I use that string in an API and that API imposes a max length of 4094 bytes.
My solution is below, I am just wondering whether there is a better one?</p>
<pre><code>list_of_query_strings = []
substring = list_of_ids[0]
list_of_ids.pop(0)
while list_of_ids:
    new_addition = ' OR ' + list_of_ids[0]
    if sys.getsizeof(substring + new_addition) &lt; 4094:
        substring += new_addition
    else:
        list_of_query_strings.append(substring)
        substring = list_of_ids[0]
    list_of_ids.pop(0)
list_of_query_strings.append(substring)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just for fun, an over-engineered solution (that avoids Schlemiel the Painter repeated concatenation algorithms, allowing you to use <code>str.join</code> for efficient combining):</p>
<pre><code>from itertools import count, groupby

class CumulativeLengthGrouper:
    def __init__(self, joiner, maxblocksize):
        self.joinerlen = len(joiner)
        self.maxblocksize = maxblocksize
        self.groupctr = count()
        self.curgrp = next(self.groupctr)
        # Special cases initial case to cancel out treating first element
        # as requiring joiner, without requiring per call special case
        self.accumlen = -self.joinerlen

    def __call__(self, newstr):
        self.accumlen += self.joinerlen + len(newstr)
        # If accumulated length exceeds block limit...
        if self.accumlen &gt; self.maxblocksize:
            # Move to new group
            self.curgrp = next(self.groupctr)
            self.accumlen = len(newstr)
        return self.curgrp
</code></pre>
<p>With this, you <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer">use <code>itertools.groupby</code></a> to break up your iterable into pre-sized groups, then <code>join</code> them without using repeated concatenation:</p>
<pre><code> mystrings = [...]

 myblocks = [' OR '.join(grp) for _, grp in 
             groupby(mystrings, key=CumulativeLengthGrouper(' OR ', 4094)]
</code></pre>
<p>If the goal is to produce strings with a given byte size using a specified encoding, you could tweak the <code>CumulativeLengthGrouper</code> to accept a third constructor argument:</p>
<pre><code>class CumulativeLengthGrouper:
    def __init__(self, joiner, maxblocksize, encoding='utf-8'):
        self.encoding = encoding
        self.joinerlen = len(joiner.encode(encoding))
        self.maxblocksize = maxblocksize
        self.groupctr = count()
        self.curgrp = next(self.groupctr)
        # Special cases initial case to cancel out treating first element
        # as requiring joiner, without requiring per call special case
        self.accumlen = -self.joinerlen

    def __call__(self, newstr):
        newbytes = newstr.encode(encoding)
        self.accumlen += self.joinerlen + len(newbytes)
        # If accumulated length exceeds block limit...
        if self.accumlen &gt; self.maxblocksize:
            # Move to new group
            self.curgrp = next(self.groupctr)
            self.accumlen = len(newbytes)
        return self.curgrp
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is a simpler solution than your current one:</p>
<pre><code>list_of_query_strings = []
one_string = list_of_ids[0]

# Iterate over each id
for id_ in list_of_ids[1:]:
    # Add the id to the substring if it doesn't make it to large
    if len(one_string) + len(id_) + 4 &lt; 4094:
        one_string += ' OR ' + id_
    # Substring too large, so add to the list and reset
    else:
        list_of_query_strings.append(one_string)
        one_string = id_
</code></pre>
</div>
<span class="comment-copy">What is the plan after it's gets to long, create a new string or removing stuff from the beginning?</span>
<span class="comment-copy">Why do you need this?</span>
<span class="comment-copy">For the record, <code>sys.getsizeof</code> has very little to do with the length of the string, especially on Python 3.3+. It's (roughly) the number of bytes used to store the string, including all overhead, but on Py3 in particular, the numbers vary wildly depending on whether it's ASCII, latin-1, BMP or non-BMP, whether it has a cached UTF-8 form (an implementation detail that is fairly unpredictable), etc. It has no useful relationship to the number of characters. When you concatenate the strings, it's often gets smaller than the sum of the original strings thanks to removing object header redundancy.</span>
<span class="comment-copy">hi I clarified my question... first it is a limit on the number of bytes, not characters, sorry for the confusion... second the point why I need this is because of API max request limits.</span>
<span class="comment-copy">@carl: <code>sys.getsizeof</code> is still going to be wrong for number of bytes though. Each <code>str</code> has a Python object header; the joined string collapses <code>n</code> headers down to one (saving memory). Similarly, a dozen ASCII strings joined to a single non-BMP string will end up <i>much</i> larger than the component sizes (because all the ASCII data will end up stored as four bytes per character, when originally it was one byte per character). The only useful way to look at this that isn't totally arbitrary would be the size of the encoded form in a given encoding (e.g. how large is the UTF-8 form in bytes).</span>
<span class="comment-copy">very nice solution... like for other solutions, len() does only count the number of characters, which fails at least for the API I am using. I guess the API expects a utf8 string? but I don't really know. sys.getsizeof() seems to work for me, but you don't seem to like that?</span>
<span class="comment-copy">@carl: <code>sys.getsizeof</code> might "work", but it would also end up producing groups that are much smaller than your API would actually accept (assuming it's not somehow size dependent on the raw <code>PyUnicode_Object</code> size in bytes). For example, <code>sys.getsizeof('a')</code> is 54, even though it's usually one byte when stored to disk or sent over the wire (and never more than four, even encoded as UTF-32); <code>sys.getsizeof(' OR ')</code> is 53 (smaller because weirdness). So if you had an input of <code>['a'] * 100</code>, joined with <code>' OR '</code>, you'd treat it as ~10 KiB, when it's likely transmitted as &lt; 500B.</span>
<span class="comment-copy">so what is your suggestion for how to deal with this? Like I said, if I use len(), the string is too long... so the API does not seem to expect ASCII</span>
<span class="comment-copy">@carl: I can't give you a suggestion without knowing what the API is doing. If the API is encoding as UTF-8, then my second implementation is correct (note: It's assuming you can hit, but not exceed, the max length; you'd change the test to <code>&gt;= self.maxblocksize</code> if the max length was exclusive, not inclusive). But the API might be prefixing it with a byte count, or using UTF-16, or some other approach. You haven't provided sufficient detail.</span>
<span class="comment-copy">@carl: BTW, an example of why <code>sys.getsizeof</code> is so useless for computing the size of the resulting string after concatenation: <code>sys.getsizeof(chr(0x1ffff)) + sys.getsizeof('a' * 4000)</code> is 4129. <code>sys.getsizeof(chr(0x1ffff) + 'a' * 4000)</code> (the concatenation of the two input strings) is 16080 (the non-BMP character means all four thousand <code>a</code>s need to be stored in 4 bytes a piece, instead of the 1 byte a piece they used in a pure ASCII string). If <code>sys.getsizeof</code> is actually important, something is <i>terribly</i> wrong with your API.</span>
<span class="comment-copy">small issue... the string should not start with 'OR'. Like the join command, 'OR' should only appear between ids</span>
<span class="comment-copy">also len() does only check for number of characters, right? While 4094 is the number of bytes</span>
<span class="comment-copy">I corrected that issue. Yes, <code>len</code> returns the number of character. That is the same as the number of bytes if you're only using ASCII. If you need unicode, my answer will answer will fail.</span>
<span class="comment-copy">My algorithm would still work, except you would need to switch out <code>len</code> for some <code>number_of_bytes</code> function.</span>
<span class="comment-copy">you still need to remove the 'OR' in the last line, but I agree that would work</span>
