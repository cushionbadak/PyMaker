<div class="post-text" itemprop="text">
<p><strong>Edit:</strong> Running Apple MBP 2017 Model 14,3 with 2.8GHz i7 4-cores:</p>
<pre><code>multiprocessing.cpu_count()
8
</code></pre>
<p>I have a list of objects I'm performing object methods on in python once for each object.  The process is for a genetic algorithm so I'm interested in speeding it up. Basically, each time I update the environment with data from the data list, the object (genome) performs a little bit of math including taking values from the environment, and referencing it's own internal values.<br/>
I'm doing:</p>
<pre><code>from multiprocessing import Pool

class Individual(object):
    def __init__(self):
    self.parameter1 = None
    self.parameter2 = None

    def update_values():
        # reads the environment variables, does math specific to each instance
        # updates internal parameters
        a, b, c, d = environment_variables
        self.parameter1 = do_math(a, b, c, d, 
                                  self.parameter1, self.parameter2)
        self.parameter2 = do_math(a, b, c, d, 
                                  self.parameter1, self.parameter2) 


data_list = [data1, data2, data3, ..., data1000]
object_list = [object1, object2, object3, ..., object20000]
</code></pre>
<p>If I run this:</p>
<pre><code>for newdataset in data_list:
    update_parameters(newdataset)
    for object in object_list:
        object.update_values()
</code></pre>
<p>It is <strong>much</strong> faster than if I try to split this up using multiprocessing/ map:</p>
<pre><code>def process_object(object):
    object.update_values()

for newdataset in data_list:
    update_parameters(newdataset)
    with Pool(4) as p:
        p.map(process_object, object_list)
</code></pre>
<p>If I run with object_list length of 200 (instead of 20000) the total time is 14.8 seconds in single threaded mode.
If I run with the same in multiprocessing mode the total time is... still waiting... ok... 211 seconds.<br/>
Also it doesn't appear to do what the function says it should at all.  What am I missing here?  When I check the values of each object they do not appear to have been updated at all.</p>
</div>
<div class="post-text" itemprop="text">
<p>When you use multiprocessing, you're serializing and transferring the data both ways. In this case, that includes each object you indend to call update_values on. I'm guessing that you're also iterating on your models, meaning they'll be sent back and forth quite a lot. Furthermore, map() returns a list of results, but process_object just returns None. So you've serialized a model, sent it to another process, had that process run and update the model, then send a None back and toss away the updated model, before tossing away the list of None results. If you were to return the models:</p>
<pre><code>def process_object(object):
    object.update_values()
    return object

...

object_list = p.map(process_object, object_list)
</code></pre>
<p>Your program might actually produce some results, but almost certainly still slower than you wish. In particular your process pool will not have the data_list or similar things (the "environment"?) - it only receives what you passed through Pool.map(). </p>
<p>You may want to consider using other tools such as tensorflow or MPI. At least read up on <a href="https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes" rel="nofollow noreferrer">sharing state between processes</a>. Also, you probably shouldn't be recreating your process pool for every iteration; that's very expensive on some platforms, such as Windows. </p>
</div>
<div class="post-text" itemprop="text">
<p>I would split up the parallelization a little bit differently. It's hard to tell what's happening with <code>update_parameters</code>, but I would parallelize the call to that too. Why leave it out? You could wrap the whole operation you're interested in, in some function, right?</p>
<p><s>Also, this is important: you need to make sure that you only open up the pool if you're in the main process. So add the line</s></p>
<pre><code>if __name__ == '__main__':
     with Pool(multiprocessing.cpu_count()) as p:
</code></pre>
<p></p></div>
<span class="comment-copy">Can you give a bit more detail as to what kind of processing is going on? Also, how many cores do you have? What OS?</span>
<span class="comment-copy">Also, all parameters which are passed to processes must be serialize-able. So, what kind of objects are in object_list (class instances are not serialize-ale by default)?</span>
<span class="comment-copy">multiprocessing uses <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer">pickle</a> to serialize data, and can handle classes as well as recursive structures.</span>
<span class="comment-copy">Wow thanks guys.  I'll just edit my question again to make it clearer.</span>
<span class="comment-copy">I was hoping to update parameters in the list and not return a copy of them.  Didn't realise that multiprocessing was pickling everything.  hmmm</span>
<span class="comment-copy">Thanks for this. I didn't realise that I was "sharing between processes" because my objects are not talking to each other at all. I'll try a couple of things and then get back.</span>
<span class="comment-copy">Sorry that you answered before I was done updating after your comment.  I am not executing the Pool in the main function, but I am not running from windows so, this should be fine right?</span>
<span class="comment-copy">@Notachance in this case, the issue has to do with your program logic and the contents of the functions you're calling - if you could provide more detail I could be able to help you.</span>
<span class="comment-copy">Also this SO post may be helpful - <a href="https://stackoverflow.com/questions/26911882/python-multiprocessing-why-much-slower" title="python multiprocessing why much slower">stackoverflow.com/questions/26911882/â€¦</a>  If you can, you can have each process read from a separate file the data that it should work on, and this would be faster than your main process reading everything in and then distributing the data to its children via IPC.</span>
