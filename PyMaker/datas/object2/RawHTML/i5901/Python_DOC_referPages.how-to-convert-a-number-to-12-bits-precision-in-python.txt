<div class="post-text" itemprop="text">
<p>I need to store a float variable with 12 bits precision in Python</p>
<p>I know that to convert a variable in float there is a float function but how can I specify the size of the float in bits? e.g. (12, 16, ...)</p>
</div>
<div class="post-text" itemprop="text">
<p>As mentioned in other answers, this doesn't really exist 
 in pure python data types, <a href="https://docs.python.org/2.4/lib/typesnumeric.html" rel="nofollow noreferrer">see the docs</a></p>
<p>However, you can use <code>numpy</code> to specify explicit <a href="https://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html" rel="nofollow noreferrer">data types</a> e.g.</p>
<ul>
<li><code>numpy.float16</code></li>
<li><code>numpy.float32</code></li>
<li><code>numpy.float64</code></li>
</ul>
<p>You can also use <a href="https://docs.scipy.org/doc/numpy-dev/user/basics.types.html#extended-precision" rel="nofollow noreferrer">extended precision</a> of <code>numpy.float96</code> which seems to be what you are after as 12 bytes is 96 bits, for example</p>
<pre><code>import numpy as np
high_prec_array = np.array([1,2,3], dtype=np.float96)
</code></pre>
<h2>Caveats</h2>
<p>As pointed out in comments and links, <strong>this isn't true 12 byte accuracy</strong>. Rather, 80 bit (10 byte) padded by 2 zero bytes. This may be sufficient if you just care about compatibility.</p>
<p>This precision <a href="https://docs.scipy.org/doc/numpy-dev/reference/arrays.scalars.html#arrays-scalars-built-in" rel="nofollow noreferrer">may not be available on all platforms</a></p>
<blockquote>
<p>In the tables below, platform? means that the type may not be
  available on all platforms. Compatibility with different C or Python
  types is indicated: two types are compatible if their data is of the
  same size and interpreted in the same way.</p>
</blockquote>
<p>Also read this about the caveats of using such exotic types </p>
<ul>
<li><a href="https://stackoverflow.com/a/17023995/4013571">https://stackoverflow.com/a/17023995/4013571</a></li>
<li><a href="https://mail.scipy.org/pipermail/scipy-dev/2008-March/008562.html" rel="nofollow noreferrer">https://mail.scipy.org/pipermail/scipy-dev/2008-March/008562.html</a></li>
<li><a href="https://www.reddit.com/r/learnpython/comments/3l7f3v/a_sneaky_numpy_feature_for_anyone_interested_in/" rel="nofollow noreferrer">https://www.reddit.com/r/learnpython/comments/3l7f3v/a_sneaky_numpy_feature_for_anyone_interested_in/</a></li>
<li><a href="https://stackoverflow.com/a/18537604/4013571">https://stackoverflow.com/a/18537604/4013571</a></li>
</ul>
<p>I found this quite illuminating. I would conclude that if you want to absolutely guarantee <code>96bit</code> precision then <code>python</code> is not the correct choice as the inherent ambiguity in the available extended precision comes from the ambiguity in your C distribution. Given your physics background I would suggest using <a href="http://fortranwiki.org/fortran/show/Real+precision" rel="nofollow noreferrer"><code>Fortran</code></a> if you want to guarantee stability.</p>
<h1>Define your own type in C++</h1>
<p>For the interested, advanced user, it may be possible to define your own data type. The <code>numpy</code> guide on <a href="https://docs.scipy.org/doc/numpy-1.13.0/user/c-info.beyond-basics.html#user-defined-data-types" rel="nofollow noreferrer">user defined types states</a></p>
<blockquote>
<p>As an example of what I consider a useful application of the ability
  to add data-types is the possibility of adding a data-type of
  arbitrary precision floats to NumPy.</p>
</blockquote>
<p>You can therefore try using <a href="http://www.boost.org/doc/libs/1_62_0/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/cpp_bin_float.html" rel="nofollow noreferrer"><code>boost/multiprecision/cpp_bin_float.hpp</code></a> if you fervently wish to keep your code in <code>python</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>The float type in python is fixed. Often 64 bits, but it is implementation-dependent.</p>
<p>You can use <code>sys.float_info</code> to <em>know</em> the size of floats, but you are not supposed to be able to change it.</p>
<p><a href="https://docs.python.org/3/library/sys.html#sys.float_info" rel="nofollow noreferrer">https://docs.python.org/3/library/sys.html#sys.float_info</a></p>
<p>EDIT:  </p>
<p>If you really need to specify the float size, you can rely on external libraries, such as numpy. See the very informative <a href="https://stackoverflow.com/a/47573898/479251">answer of Alexander McFarlane</a> for lots of details</p>
</div>
<div class="post-text" itemprop="text">
<p>The development version of <code>gmpy2</code> supports the 96-bit IEEE numeric type.</p>
<pre><code>&gt;&gt;&gt; import gmpy2
&gt;&gt;&gt; gmpy2.version()
'2.1.0a1'
&gt;&gt;&gt; gmpy2.set_context(gmpy2.ieee(96))
&gt;&gt;&gt; gmpy2.get_context()
context(precision=83, real_prec=Default, imag_prec=Default,
        round=RoundToNearest, real_round=Default, imag_round=Default,
        emax=4096, emin=-4175,
        subnormalize=True,
        trap_underflow=False, underflow=False,
        trap_overflow=False, overflow=False,
        trap_inexact=False, inexact=False,
        trap_invalid=False, invalid=False,
        trap_erange=False, erange=False,
        trap_divzero=False, divzero=False,
        allow_complex=False,
        rational_division=False)
&gt;&gt;&gt; gmpy2.mpfr(1)/7
mpfr('0.14285714285714285714285714',83)
&gt;&gt;&gt; 
</code></pre>
<p>It is also possible in older versions of <code>gmpy2</code> but requires a bit more effort.</p>
<pre><code>&gt;&gt;&gt; import gmpy2
&gt;&gt;&gt; gmpy2.version()
'2.0.8'
&gt;&gt;&gt; ieee96 = gmpy2.context(precision=83, emax=4096, emin=-4175, subnormalize=True)
&gt;&gt;&gt; gmpy2.set_context(ieee96)
&gt;&gt;&gt; gmpy2.mpfr(1)/7
mpfr('0.14285714285714285714285714',83)
&gt;&gt;&gt; 
</code></pre>
<p>You may need to down to download the source directly from <a href="https://github.com/aleaxit/gmpy" rel="nofollow noreferrer">https://github.com/aleaxit/gmpy</a> . Some very early wheels are available at <a href="https://pypi.python.org/pypi/gmpy2/2.1.0a1" rel="nofollow noreferrer">https://pypi.python.org/pypi/gmpy2/2.1.0a1</a> .</p>
<p>Disclaimer: I maintain <code>gmpy2</code>.</p>
</div>
<span class="comment-copy">That's a rather unusual floating-point format. What is its specification? Are you sure it's not 80 bits, or perhaps 80 bits padded to 128 bits? See <a href="https://en.wikipedia.org/wiki/Extended_precision#x86_extended_precision_format" rel="nofollow noreferrer">en.wikipedia.org/wiki/â€¦</a></span>
<span class="comment-copy">@PM2Ring it is because I am working on an embedded card working in float 12, and I would like to simulate datas of analysis. The simple way to do it would be to directly generate 12 bytes data in my python code.</span>
<span class="comment-copy">I think this is a reasonable question contrary to the close / downvotes although on the surface it looks odd. I initially was tempted to also vote close but checked more closely after realising the OP's background is strong math/physics. As a suggestion for future Qs, maybe put a bit of relevant blurb as you have above / emphasise your own research efforts so readers realise it is a bit more complex.</span>
<span class="comment-copy">Ok, but as I said, that's an unusual format. And it's even more surprising that an embedded system would use such high precision floats. It won't be easy to work with in Python, but you will need to have its exact specification.</span>
<span class="comment-copy">Even if you just want to create random data &amp; don't need to do any actual arithmetic with these numbers you still need the data specification so you don't create invalid bit patterns.</span>
<span class="comment-copy">There's no 12-byte floating-point type supported by NumPy. On some platforms it has a type called <code>float96</code>, but that's the 80-bit (10-byte) IEEE 754-1985 64-bit precision extended format (1 sign bit, 15 exponent bits, 64 significand bits, no hidden bit) used by Intel x87, and padded up to 12 bytes with two zero bytes. I know this information is implicit in your links, but I think this answer is misleading as it stands.</span>
<span class="comment-copy">Yeah I'm still looking at it - hence why the information is slightly contradictory. It seems quite a complex issue! I think the OP just needs the formatting to be 12 byte for compatibility so even if the last two bytes are padded by two zero bytes it shouldn't matter</span>
<span class="comment-copy">The comments (especially the last one by StarBucK) seem to suggest he needs 12 <b>BITS</b> after all. He just mentioned bytes a few times because he did not know the difference between bits and bytes. I don't think there are many implementations of 12 bit floats in any language.</span>
<span class="comment-copy">"float type ... is fixed. Usually 64 bits, but can change" is unclear.  Is it fixed or implementation dependent?</span>
<span class="comment-copy">it is implementation dependant. Within a specific implementation, it won't change. But one implementation could be 64 bits, and another 32 bits. (Edited my answer, thanks for feedback)</span>
<span class="comment-copy">@chux: At least for CPython, it's effectively fixed, in that Python <code>float</code>s use C <code>double</code>s, and the assumption that <code>sizeof(double) == 8</code> is baked into the CPython source. (Which is bad, but doesn't actually seem to have caused any real problems to date.) And IronPython and Jython live on platforms (.NET and Java) that are explicit about Double being IEEE 754 binary64. MicroPython might do something interesting, but I don't know.</span>
