<div class="post-text" itemprop="text">
<p>I have a tensor with shape (1,4,4,1) and I want to repeat the value of each it's pixel and increases the shape to (1,28,28,1). I want to repeat it in each dimension. for example, if the first pixel of it is 0 then produce a new tensor with shape (28,28,1) with value 0 and so on. how can do I this? I appreciate your help. I need sth like the below code to choose the value of wtm in index i,j and then produce a new tensor with this value and shape (1,28,28,1).
suppose wtm is :</p>
<pre><code>0 1 1 0
0 0 0 1
1 0 1 0 
1 1 0 1
</code></pre>
<p>now I need to know what is wtm (i,j) and then produce a new tensor with this value. if wtm(i,j)=1
new tensor is:</p>
<pre><code>1 1 1 ... 1
1 1 1 ... 1
.    ...  1
.    ...  1
1 1 1 ... 1

wtm=Input((28,28,1))
image = Input((28, 28, 1))
conv1 = Conv2D(64, (5, 5), activation='relu', padding='same', name='convl1e',dilation_rate=(2,2))(image)
conv2 = Conv2D(64, (5, 5), activation='relu', padding='same', name='convl2e',dilation_rate=(2,2))(conv1)
conv3 = Conv2D(64, (5, 5), activation='relu', padding='same', name='convl3e',dilation_rate=(2,2))(conv2)
BN=BatchNormalization()(conv3)
encoded =  Conv2D(1, (5, 5), activation='relu', padding='same',name='encoded_I',dilation_rate=(2,2))(BN)

#-----------------------adding w---------------------------------------   

wfill=Kr.layers.Lambda(lambda x:tf.fill([28,28],x))
wtm_Fill=wfill(wtm(i,j))
add_const = Kr.layers.Lambda(lambda x: x[0] + x[1])
encoded_merged = add_const([encoded,wtm_Fill])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Maybe <code>tf.tile</code> will suit. It simply copies specified dimension of a tensor defined number of times. </p>
<pre><code>array = np.random.random_integers(0,1, (1, 4, 4, 1))
tensor = tf.convert_to_tensor(array)
expanded_array = tf.tile(tensor, [1,7,7,1])
</code></pre>
<p>So if one dimension of input array was <code>[1,1,0,0]</code>, then after padding with <code>tf.tile</code> it will look like <code>[1,1,0,0,1,1,0,0...]</code> with length of 28</p>
<p>Edit:
TensorFlow supports tensor indexing the same way numpy does. So you can just slice tensor  </p>
<pre><code>slice = tensor[0,:,:]
</code></pre>
<p>to get the shape <code>[4,4,1]</code> 
If you need to select only one particular value, you can then use <code>tf.fill</code> instead of <code>tile</code></p>
<p>To get specific value from array you need to provide n indexes where n is number of dimensions. To get first element in array with 3 dimensions, like (28,28,1), you need <code>array[0][0][0]</code>.</p>
<p><a href="https://www.tensorflow.org/api_docs/python/tf/tile" rel="nofollow noreferrer">https://www.tensorflow.org/api_docs/python/tf/tile</a></p>
</div>
<span class="comment-copy">Could you provide more concrete example of desired output?  I have one solution in mind but not sure about what you need</span>
<span class="comment-copy">I put the code here and I need sth like this in the code to select the specific index of wtm and then produce a new tensor with shape (1,28,28,1) with this value. but I do not know how can I do this with tensors:((</span>
<span class="comment-copy">this tile the input but I need sth like the mentioned example. could you please consider the example I put here.</span>
<span class="comment-copy">sorry, I am a beginner. for example, if I need wtm (0,0) I can use wtm[0,0,0]?</span>
<span class="comment-copy">for example, when I use this wfill=Kr.layers.Lambda(lambda x:tf.fill([28,28],x)) wtm_Fill=wfill(wtm[:,0,0,:]). it produces this error Shape must be rank 0 but is rank 2 for 'lambda_16/Fill' (op: 'Fill') with input shapes: [2], [?,1].</span>
<span class="comment-copy">Updated answer, also please take a look <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html" rel="nofollow noreferrer">docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html</a> It's the same in TensorFlow</span>
<span class="comment-copy">I could not understand:( I used this wtm[0,0,:] but it produces the same error. how do you write if you want to do the code I put here?</span>
