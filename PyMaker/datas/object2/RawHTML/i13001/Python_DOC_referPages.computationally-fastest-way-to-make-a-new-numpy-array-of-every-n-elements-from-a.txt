<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/25876640/subsampling-every-nth-entry-in-a-numpy-array">subsampling every nth entry in a numpy array</a>
<span class="question-originals-answer-count">
                    1 answer
                </span>
</li>
</ul>
</div>
<p>Suppose a 1-dimensional numpy array. I want to make a new array that contains every <em>n</em> elements. What is the <strong>computationally fastest</strong> way to do this? </p>
<p>Example: </p>
<pre><code>a = numpy.arange(1,10)
b = numpy.fancytricks(a,?)
# b is now [2,4,6,8] if n = 2. 
</code></pre>
<p>Edit: bolded important part of the question. </p>
</div>
<div class="post-text" itemprop="text">
<p>The absolute fastest way to do this is to write an extension module in pure C and use the <a href="https://docs.python.org/3/c-api/buffer.html" rel="nofollow">buffer protocol</a> to access the data directly.  If you use <a href="http://cython.org" rel="nofollow">Cython</a> or another such tool to write the C for you, you may see small amounts of performance lost in automatic reference counting.  Since you still have to do manual reference counting in handwritten C, the difference is likely to be negligible to nonexistent.</p>
<p>This will have marginally less overhead than the slicing syntax NumPy provides out of the box.  However, assuming you use NumPy correctly, the overall performance gain is likely to be small and constant, so it's not clear to me that this is worth the extra effort in any reasonable situation.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>b = a[1::step]
</code></pre>
<hr/>
<pre><code>n = length(a)
</code></pre>
<p><strong>Computational cost</strong> is <code>O(n)</code>, you are "making" a loop with <code>length(a)/step</code></p>
<blockquote>
<p>UPDATE:<br/>
<strong>Computational cost</strong> is <code>O(1)</code>, there is no <code>numpy.array</code> object re-arrangement, just one constant<sub> ... in access-method... </sub> is set / changed. Once deployed, the access-speed is the same as with a value stored there before an update.</p>
</blockquote>
</div>
<span class="comment-copy">@jme That provides a way to accomplish the sampling goal, but makes no guarantees about speed.</span>
<span class="comment-copy">What sort of guarantees about speed do you expect? Slicing in such a way returns a view of the data in <code>a</code> with a doubled stride length, so it takes constant time and incurs very little overhead.</span>
<span class="comment-copy">@jme I am simply curious what the fastest protocol is, since I am working on a time-constrained problem that involves sampling large data.</span>
<span class="comment-copy">@d0rmLife: No, slicing is constant time. Copying a slice isn't constant time, but you usually don't need to make a copy.</span>
<span class="comment-copy">Nope, no downvote from me. The question linked to says "This creates a view of the the original data, so it's constant time." Below it talks about copying the slice, which is linear time. But if you don't copy, no linear time is needed. You can easily verify the claim with a simple <code>%%timeit</code>.</span>
<span class="comment-copy">It is not Omega(n/step)?</span>
<span class="comment-copy">Computational cost is <code>O(1)</code>. Basic slicing returns a view with altered stride length. There is no need to look through the array at all.</span>
<span class="comment-copy">return a view with altered stride length has O(1) cost?</span>
<span class="comment-copy">@juankirr Yes. Returning a view is just making a pointer, which is <code>O(1)</code>. Changing the stride length is also <code>O(1)</code>, since it's just updating a single number. You can time it to be sure... On my machine, <code>b = a[::2]</code> takes about 280 nanoseconds whether <code>a</code> has 100 entries or 100 million.</span>
