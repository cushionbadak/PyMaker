<div class="post-text" itemprop="text">
<p>Is it okay to use the yield statement in an instance method of a class?  For example,</p>
<pre><code># Similar to itertools.islice
class Nth(object):
    def __init__(self, n):
        self.n = n
        self.i = 0
        self.nout = 0

    def itervalues(self, x):
        for xi in x:
            self.i += 1
            if self.i == self.n:
                self.i = 0
                self.nout += 1
                yield self.nout, xi
</code></pre>
<p>Python doesn't complain about this, and simple cases seem to work.  However, I've only seen examples with yield from regular functions.</p>
<p>I start having problems when I try to use it with itertools functions.  For example, suppose I have two large data streams X and Y that are stored across multiple files, and I want to compute their sum and difference with only one loop through the data.  I could use <code>itertools.tee</code> and <code>itertools.izip</code> like in the following diagram</p>
<p><a href="https://i.stack.imgur.com/WYMpz.png" rel="nofollow noreferrer"><img alt="data flow" src="https://i.stack.imgur.com/WYMpz.png"/></a></p>
<p>In code it would be something like this (sorry, it's long)</p>
<pre><code>from itertools import izip_longest, izip, tee
import random

def add(x,y):
    for xi,yi in izip(x,y):
        yield xi + yi

def sub(x,y):
    for xi,yi in izip(x,y):
        yield xi - yi

class NthSumDiff(object):
    def __init__(self, n):
        self.nthsum = Nth(n)
        self.nthdiff = Nth(n)

    def itervalues(self, x, y):
        xadd, xsub = tee(x)
        yadd, ysub = tee(y)
        gen_sum = self.nthsum.itervalues(add(xadd, yadd))
        gen_diff = self.nthdiff.itervalues(sub(xsub, ysub))
        # Have to use izip_longest here, but why?
        #for (i,nthsum), (j,nthdiff) in izip_longest(gen_sum, gen_diff):
        for (i,nthsum), (j,nthdiff) in izip(gen_sum, gen_diff):
            assert i==j, "sum row %d != diff row %d" % (i,j)
            yield nthsum, nthdiff

nskip = 12
ns = Nth(nskip)
nd = Nth(nskip)
nsd = NthSumDiff(nskip)
nfiles = 10
for i in range(nfiles):
    # Generate some data.
    # If the block length is a multiple of nskip there's no problem.
    #n = random.randint(5000, 10000) * nskip
    n = random.randint(50000, 100000)
    print 'file %d n=%d' % (i, n)
    x = range(n)
    y = range(100,n+100)
    # Independent processing is no problem but requires two loops.
    for i, nthsum in ns.itervalues(add(x,y)):
        pass
    for j, nthdiff in nd.itervalues(sub(x,y)):
        pass
    assert i==j
    # Trying to do both with one loops causes problems.
    for nthsum, nthdiff in nsd.itervalues(x,y):
        # If izip_longest is necessary, why don't I ever get a fillvalue?
        assert nthsum is not None
        assert nthdiff is not None
    # After each block of data the two iterators should have the same state.
    assert nsd.nthsum.nout == nsd.nthdiff.nout, \
           "sum nout %d != diff nout %d" % (nsd.nthsum.nout, nsd.nthdiff.nout)
</code></pre>
<p>But this fails unless I swap <code>itertools.izip</code> out for <code>itertools.izip_longest</code> even though the iterators have the same length.  It's the last <code>assert</code> that gets hit, with output like</p>
<pre><code>file 0 n=58581
file 1 n=87978
Traceback (most recent call last):
  File "test.py", line 71, in &lt;module&gt;
    "sum nout %d != diff nout %d" % (nsd.nthsum.nout, nsd.nthdiff.nout)
AssertionError: sum nout 12213 != diff nout 12212 
</code></pre>
<p><strong>Edit</strong>: I guess it's not obvious from the example I wrote, but the input data X and Y are only available in blocks (in my real problem they're chunked in files).  This is important because I need to maintain state between blocks.  In the toy example above, this means <code>Nth</code> needs to yield the equivalent of</p>
<pre><code>&gt;&gt;&gt; x1 = range(0,10)
&gt;&gt;&gt; x2 = range(10,20)
&gt;&gt;&gt; (x1 + x2)[::3]
[0, 3, 6, 9, 12, 15, 18]
</code></pre>
<p>NOT the equivalent of</p>
<pre><code>&gt;&gt;&gt; x1[::3] + x2[::3]
[0, 3, 6, 9, 10, 13, 16, 19]
</code></pre>
<p>I could use <code>itertools.chain</code> to join the blocks ahead of time and then make one call to <code>Nth.itervalues</code>, but I'd like to understand what's wrong with maintaining state in the <code>Nth</code> class between calls (my real app is image processing involving more saved state, not simple Nth/add/subtract).</p>
<p>I don't understand how my <code>Nth</code> instances end up in different states when their lengths are the same.  For example, if I give <code>izip</code> two strings of equal length</p>
<pre><code>&gt;&gt;&gt; [''.join(x) for x in izip('ABCD','abcd')]
['Aa', 'Bb', 'Cc', 'Dd']
</code></pre>
<p>I get a result of the same length; how come my <code>Nth.itervalues</code> generators seem to be getting unequal numbers of <code>next()</code> calls even though each one yields the same number of results?</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://gist.github.com/sr105/694deeca9acb55618434" rel="nofollow"> Gist repo with revisions </a> | 
<a href="https://gist.github.com/sr105/694deeca9acb55618434/f42f2fbd2fe725617c480f0c3f00bf4b2e66e05c#file-nth-py-L12" rel="nofollow"> Quick link to solution </a></p>
<h1>Quick answer</h1>
<p>You never reset <code>self.i</code> and <code>self.nout</code> in <code>class Nth</code>. Also, you should have used something like this:</p>
<pre><code># Similar to itertools.islice
class Nth(object):
    def __init__(self, n):
        self.n = n

    def itervalues(self, x):
        for a,b in enumerate(islice(x, self.n - 1, None, self.n)):
            self.nout = a
            yield a,b
</code></pre>
<p>but since you don't even need <code>nout</code>, you should use this:</p>
<pre><code>def Nth(iterable, step):
    return enumerate(itertools.islice(iterable, step - 1, None, step)) 
</code></pre>
<h1>Long answer</h1>
<p>Your code had an off-by-one smell that led me to this line in NthSumDiff.itervalues():</p>
<pre><code>for (i,nthsum), (j,nthdiff) in izip(gen_sum, gen_diff):
</code></pre>
<p>If you swap <code>gen_sum</code> and <code>gen_diff</code>, you'll see that <code>gen_diff</code> will always be the one with <code>nout</code> greater by one. This is because <code>izip()</code> pulls from <code>gen_sum</code> before pulling from <code>gen_diff</code>. <code>gen_sum</code> raises a StopIteration exception before <code>gen_diff</code> is even tried in the last iteration.</p>
<p>For example, say you pick N samples where N % step == 7. At the end of each iteration, <code>self.i</code> for the Nth instances should equal 0. But on the very last iteration, <code>self.i</code> in <code>gen_sum</code> will increment up to 7 and then there will be no more elements in <code>x</code>. It will raise StopIteration. <code>gen_diff</code> is still sitting at <code>self.i</code> equal to 0, though.</p>
<p>If you add <code>self.i = 0</code> and <code>self.nout = 0</code> to the beginning of Nth.itervalues(), the problem goes away.</p>
<h1>Lesson</h1>
<p>You only had this problem because your code is too complicated and not Pythonic. If you find yourself using lots of counters and indexes in loops, that's a good sign (in Python) to take a step back and see if you can simplify your code. I have a long history of C programming, and consequently, I still catch myself doing the same thing from time to time in Python. </p>
<h1>Simpler implementation</h1>
<p><em>Putting my money where my mouth is...</em></p>
<pre><code>from itertools import izip, islice
import random

def sumdiff(x,y,step):
    # filter for the Nth values of x and y now
    x = islice(x, step-1, None, step)
    y = islice(y, step-1, None, step)
    return ((xi + yi, xi - yi) for xi, yi in izip(x,y))

nskip = 12
nfiles = 10
for i in range(nfiles):
    # Generate some data.
    n = random.randint(50000, 100000)
    print 'file %d n=%d' % (i, n)
    x = range(n)
    y = range(100,n+100)
    for nthsum, nthdiff in sumdiff(x,y,nskip):
        assert nthsum is not None
        assert nthdiff is not None
    assert len(list(sumdiff(x,y,nskip))) == n/nskip
</code></pre>
<h1>More explanation of the problem</h1>
<p>In response to Brian's comment:</p>
<blockquote>
<p>This doesn't do the same thing. Not resetting i and nout is
  intentional. I've basically got a continuous data stream X that's
  split across several files. Slicing the blocks gives a different
  result than slicing the concatenated stream (I commented earlier about
  possibly using itertools.chain). Also my actual program is more
  complicated than mere slicing; it's just a working example. I don't
  understand the explanation about the order of StopIteration. If
  izip('ABCD','abcd') --&gt; Aa Bb Cc Dd then it seems like equal-length
  generators should get an equal number of next calls, no? â€“ Brian
  Hawkins 6 hours ago</p>
</blockquote>
<p>Your problem was so long that I missed the part about the stream coming from multiple files. Let's just look at the code itself. First, we need to be really clear about how <code>itervalues(x)</code> actually works.</p>
<pre><code># Similar to itertools.islice
class Nth(object):
    def __init__(self, n):
        self.n = n
        self.i = 0
        self.nout = 0

    def itervalues(self, x):
        for xi in x:
            # We increment self.i by self.n on every next()
            # call to this generator method unless the
            # number of objects remaining in x is less than
            # self.n. In that case, we increment by that amount
            # before the for loop exits normally.
            self.i += 1
            if self.i == self.n:
                self.i = 0
                self.nout += 1
                # We're yielding, so we're a generator
                yield self.nout, xi
        # Python helpfully raises StopIteration to fulfill the 
        # contract of an iterable. That's how for loops and
        # others know when to stop.
</code></pre>
<p>In <code>itervalues(x)</code> above, for every <code>next()</code> call, it internally increments <code>self.i</code> by <code>self.n</code> and then yields OR it increments <code>self.i</code> by the number of objects remaining in <code>x</code> and then exits the for loop and then exits the generator (itervalues() is a generator because it yields). When the itervalues() generator exits, Python raises a StopIteration exception.</p>
<p>So, for every instance of <code>class Nth</code> initialized with N, the value of <code>self.i</code> after exhausting all elements in <code>itervalues(X)</code> will be:</p>
<pre><code>self.i = value_of_self_i_before_itervalues(X) + len(X) % N
</code></pre>
<p>Now when you iterate over <code>izip(Nth_1, Nth_2)</code>, it will do something like this:</p>
<pre><code>def izip(A, B):
    try:
        while True:
            a = A.next()
            b = B.next()
            yield a,b
    except StopIteration:
        pass
</code></pre>
<p>So, imagine <code>N=10</code> and <code>len(X)=13</code>. On the very last <code>next()</code> call to <code>izip()</code>,
both A and B have <code>self.i==0</code> as their state. <code>A.next()</code> is called, increments <code>self.i += 3</code>, runs out of elements in X, exits the for loop, returns, and then Python raises <code>StopIteration</code>. Now, inside <code>izip()</code> we go directly to the exception block skipping <code>B.next()</code> entirely. So, <code>A.i==3</code> and <code>B.i==0</code> at the end.</p>
<h1>Second try at simplification (with correct requirements)</h1>
<p>Here's another simplified version that treats all file data as one continuous stream. It uses chained, small, re-usable generators. I would highly, highly recommend watching this <a href="https://www.youtube.com/watch?v=5-qadlG7tWo" rel="nofollow">PyCon '14 talk about generators by David Beazley</a>. Guessing from your problem description, it should be 100% applicable.</p>
<pre><code>from itertools import izip, islice
import random

def sumdiff(data):
    return ((x + y, x - y) for x, y in data)

def combined_file_data(files):
    for i,n in files:
        # Generate some data.
        x = range(n)
        y = range(100,n+100)
        for data in izip(x,y):
            yield data

def filelist(nfiles):
    for i in range(nfiles):
        # Generate some data.
        n = random.randint(50000, 100000)
        print 'file %d n=%d' % (i, n)
        yield i, n

def Nth(iterable, step):
    return islice(iterable, step-1, None, step)

nskip = 12
nfiles = 10
filedata = combined_file_data(filelist(nfiles))
nth_data = Nth(filedata, nskip)
for nthsum, nthdiff in sumdiff(nth_data):
    assert nthsum is not None
    assert nthdiff is not None
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Condensing the discussion, there's nothing wrong with using <code>yield</code> in an instance method <em>per se</em>.  You get into trouble with <code>izip</code> if the instance state changes after the last <code>yield</code> because <code>izip</code> stops calling <code>next()</code> on its arguments once any of them stops yielding results.  A clearer example might be</p>
<pre><code>from itertools import izip

class Three(object):
    def __init__(self):
        self.status = 'init'

    def run(self):
        self.status = 'running'
        yield 1
        yield 2
        yield 3
        self.status = 'done'
        raise StopIteration()

it = Three()
for x in it.run():
    assert it.status == 'running'
assert it.status == 'done'

it1, it2 = Three(), Three()
for x, y in izip(it1.run(), it2.run()):
    pass
assert it1.status == 'done'
assert it2.status == 'done', "Expected status=done, got status=%s." % it2.status
</code></pre>
<p>which hits the last assertion,</p>
<pre><code>AssertionError: Expected status=done, got status=running.
</code></pre>
<p>In the original question, the <code>Nth</code> class can consume input data after its last <code>yield</code>, so the sum and difference streams can get out of sync with <code>izip</code>.  Using <code>izip_longest</code> would work since it will try to exhaust each iterator.  A clearer solution might be to refactor to avoid changing state after the last yield.</p>
</div>
<span class="comment-copy">To answer the title question: Yes, <code>yield</code>ing from instance methods is fine. It's actually the simplest most Pythonic way to implement <code>__iter__</code> for a custom <code>Iterable</code> type.</span>
<span class="comment-copy">Couldn't you replace <code>class Nth</code> with <code>def Nth(x, n): return enumerate(x[::n])</code> ? Oh, or do you need the slicing of <code>x</code> to be an iterator, too, for performance reasons?</span>
<span class="comment-copy"><code>def Nth(x, n): return enumerate(xi for i, xi in enumerate(x) if i % n == 0)</code></span>
<span class="comment-copy">@Harvey: <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice</code> is a thing</a>; don't need to reinvent the wheel with custom generator expressions. :-)</span>
<span class="comment-copy">@Harvey: But the OP is actually using <code>izip</code>/<code>izip_longest</code>! It's right there! Why make your life harder? (To be clear not actually upset here, just spouting off for fun).</span>
<span class="comment-copy">This doesn't do the same thing.  Not resetting <code>i</code> and <code>nout</code> is intentional.  I've basically got a continuous data stream X that's split across several files.  Slicing the blocks gives a different result than slicing the concatenated stream (I commented earlier about possibly using <code>itertools.chain</code>).  Also my actual program is more complicated than mere slicing; it's just a working example.  I don't understand the explanation about the order of <code>StopIteration</code>.  If <code>izip('ABCD','abcd')</code> --&gt; Aa Bb Cc Dd then it seems like equal-length generators should get an equal number of <code>next</code> calls, no?</span>
<span class="comment-copy">Thanks for sticking with me. Refactoring Nth/add/sub is not useful to me since the processing in my real app is more complex, and I'd already mentioned <code>itertools.chain</code>ing the input data.  The discussion of <code>izip</code> was what I found most helpful.</span>
