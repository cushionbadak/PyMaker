<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/136168/get-last-n-lines-of-a-file-with-python-similar-to-tail">Get last n lines of a file with Python, similar to tail</a>
<span class="question-originals-answer-count">
                    29 answers
                </span>
</li>
</ul>
</div>
<p>I need to update the last line from a few more than 2GB files made up of lines of text that can not be read with <code>readlines()</code>. Currently, it work fine by looping through line by line. However, I am wondering if there is any compiled library can achieve this more efficiently? Thanks!</p>
<h3>Current approach</h3>
<pre><code>    myfile = open("large.XML")
    for line in myfile:
        do_something()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Update: Use <a href="https://stackoverflow.com/a/33811809/47078">ShadowRanger's answer</a>. It's much shorter and robust. </p>
<p>For posterity:</p>
<p>Read the last N bytes of the file and search backwards for the newline.</p>
<pre><code>#!/usr/bin/env python

with open("test.txt", "wb") as testfile:
    testfile.write('\n'.join(["one", "two", "three"]) + '\n')

with open("test.txt", "r+b") as myfile:
    # Read the last 1kiB of the file
    # we could make this be dynamic, but chances are there's
    # a number like 1kiB that'll work 100% of the time for you
    myfile.seek(0,2)
    filesize = myfile.tell()
    blocksize = min(1024, filesize)
    myfile.seek(-blocksize, 2)
    # search backwards for a newline (excluding very last byte
    # in case the file ends with a newline)
    index = myfile.read().rindex('\n', 0, blocksize - 1)
    # seek to the character just after the newline
    myfile.seek(index + 1 - blocksize, 2)
    # read in the last line of the file
    lastline = myfile.read()
    # modify last_line
    lastline = "Brand New Line!\n"
    # seek back to the start of the last line
    myfile.seek(index + 1 - blocksize, 2)
    # write out new version of the last line
    myfile.write(lastline)
    myfile.truncate()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If this is really something line based (where a true XML parser isn't necessary the best solution), <a href="https://docs.python.org/3/library/mmap.html" rel="nofollow"><code>mmap</code></a> can help here.</p>
<p><code>mmap</code> the file, then call <code>.rfind('\n')</code> on the resulting object (possibly with adjustments to handle the file ending with a newline when you really want the non-empty line before it, not the empty "line" following it). You can then slice out the final line alone. If you need to modify the file in place, you can resize the file to shave off (or add) a number of bytes corresponding to the difference between the line you sliced and the new line, then write back the new line. Avoids reading or writing any more of the file than you need.</p>
<p>Example code (please comment if I made a mistake):</p>
<pre><code>import mmap

# In Python 3.1 and earlier, you'd wrap mmap in contextlib.closing; mmap
# didn't support the context manager protocol natively until 3.2; see example below
with open("large.XML", 'r+b') as myfile, mmap.mmap(myfile.fileno(), 0, access=mmap.ACCESS_WRITE) as mm:
    # len(mm) - 1 handles files ending w/newline by getting the prior line
    # + 1 to avoid catching prior newline (and handle one line file seamlessly)
    startofline = mm.rfind(b'\n', 0, len(mm) - 1) + 1

    # Get the line (with any newline stripped)
    line = mm[startofline:].rstrip(b'\r\n')

    # Do whatever calculates the new line, decoding/encoding to use str
    # in do_something to simplify; this is an XML file, so I'm assuming UTF-8
    new_line = do_something(line.decode('utf-8')).encode('utf-8')

    # Resize to accommodate the new line (or to strip data beyond the new line)
    mm.resize(startofline + len(new_line))  # + 1 if you need to add a trailing newline
    mm[startofline:] = new_line  # Replace contents; add a b"\n" if needed
</code></pre>
<p>Apparently on some systems (e.g. OSX) without <code>mremap</code>, <code>mm.resize</code> won't work, so to support those systems, you'd probably split the <code>with</code> (so the <code>mmap</code> closes before the file object), and use file object based seeks, writes and truncates to fix up the file. The following example includes my previously mentioned Python 3.1 and earlier specific adjustment to use <code>contextlib.closing</code> for completeness:</p>
<pre><code>import mmap
from contextlib import closing

with open("large.XML", 'r+b') as myfile:
    with closing(mmap.mmap(myfile.fileno(), 0, access=mmap.ACCESS_WRITE)) as mm:
        startofline = mm.rfind(b'\n', 0, len(mm) - 1) + 1
        line = mm[startofline:].rstrip(b'\r\n')
        new_line = do_something(line.decode('utf-8')).encode('utf-8')

    myfile.seek(startofline)  # Move to where old line began
    myfile.write(new_line)  # Overwrite existing line with new line
    myfile.truncate()  # If existing line longer than new line, get rid of the excess
</code></pre>
<p>The advantages to <code>mmap</code> over any other approach are:</p>
<ol>
<li>No need to read any more of the file beyond the line itself (meaning 1-2 pages of the file, the rest never gets read or written)</li>
<li>Using <code>rfind</code> means you can let Python do the work of finding the newline quickly at the C layer (in CPython); explicit <code>seek</code>s and <code>read</code>s of a file object could match the "only read a page or so", but you'd have to hand-implement the search for the newline</li>
</ol>
<p><strong>Caveat:</strong> <strong>This approach will not work</strong> (at least, not without modification to avoid mapping more than 2 GB, and to handle resizing when the whole file might not be mapped) <strong>if you're on a 32 bit system and the file is too large to map into memory</strong>. On most 32 bit systems, even in a newly spawned process, you only have 1-2 GB of contiguous address space available; in certain special cases, you might have as much as 3-3.5 GB of user virtual addresses (though you'll lose some of the contiguous space to the heap, stack, executable mapping, etc.). <code>mmap</code> doesn't require much physical RAM, but it needs contiguous address space; one of the huge benefits of a 64 bit OS is that you stop worrying about virtual address space in all but the most ridiculous cases, so <code>mmap</code> can solve problems in the general case that it couldn't handle without added complexity on a 32 bit OS. Most modern computers are 64 bit at this point, but it's definitely something to keep in mind if you're targeting 32 bit systems (and on Windows, even if the OS is 64 bit, they may have installed a 32 bit version of Python by mistake, so the same problems apply). Here's yet one more example that works (assuming the last line isn't 100+ MB long) on 32 bit Python (omitting <code>closing</code> and imports for brevity) even for huge files:</p>
<pre><code>with open("large.XML", 'r+b') as myfile:
    filesize = myfile.seek(0, 2)
    # Get an offset that only grabs the last 100 MB or so of the file aligned properly
    offset = max(0, filesize - 100 * 1024 ** 2) &amp; ~(mmap.ALLOCATIONGRANULARITY - 1)
    with mmap.mmap(myfile.fileno(), 0, access=mmap.ACCESS_WRITE, offset=offset) as mm:
        startofline = mm.rfind(b'\n', 0, len(mm) - 1) + 1
        # If line might be &gt; 100 MB long, probably want to check if startofline
        # follows a newline here
        line = mm[startofline:].rstrip(b'\r\n')
        new_line = do_something(line.decode('utf-8')).encode('utf-8')

    myfile.seek(startofline + offset)  # Move to where old line began, adjusted for offset
    myfile.write(new_line)  # Overwrite existing line with new line
    myfile.truncate()  # If existing line longer than new line, get rid of the excess
</code></pre>
</div>
<span class="comment-copy">If it's XML why aren't you using an XML parser? You should be able to achieve a more efficient  I have used ElementTree and like it.</span>
<span class="comment-copy">@WarrenP Maybe the OP doesn't need to parse the XML? Also, wouldn't that read a big chunk of the file into memory which is what should be avoided?</span>
<span class="comment-copy">related: <a href="http://stackoverflow.com/questions/7171140/using-python-iterparse-for-large-xml-files" title="using python iterparse for large xml files">stackoverflow.com/questions/7171140/â€¦</a></span>
<span class="comment-copy">Not really a duplicate because this person wants to rewrite the end of the file, not load it into ram.</span>
<span class="comment-copy">@Two-BitAlchemist: As you suggested. closed this question. thanks!</span>
<span class="comment-copy">Probably want to use <code>rfind</code>, not <code>rindex</code>, or you'll handle single line files by throwing an exception, when you could just rewrite the single line. Suppose it depends on whether multiple lines are known to exist.</span>
<span class="comment-copy">@ShadowRanger: I started to do that, but you don't know if you really found the start of line or just the beginning of block. I'm recommending your answer while leaving mine around for people to see.</span>
<span class="comment-copy">Ah, right. Forgot about the block read. Big advantage to <code>mmap</code> is that you don't need to worry about that sort of thing. :-)</span>
<span class="comment-copy">This has the catch that you need to establish an <i>n</i> which is guaranteed to be large enough to always include the final newline, or arrange a fallback to some other approach (repeating with bigger and bigger blocks of <i>n</i> is probably not a great fallback strategy).</span>
<span class="comment-copy">@tripleee: agreed. That's why I'm recommending the mmap method. I always forget about mmap.</span>
<span class="comment-copy">Just use <code>mm.rfind(b'\n', 0, len(mm) - 1)</code>. If the last byte is a newline, that will skip it. If It's anything else including a one character line or zero character line, the code will still work.</span>
<span class="comment-copy">Bummer, on OSX: "SystemError: mmap: resizing not available--no mremap()". It looks like the solution is to close the file, reopen, seek to <code>startofline</code> and then write.</span>
<span class="comment-copy">Should be <code>startofline = mm.rfind(b'\n', 0, len(mm) - 1) + 1</code> (note the +1) to preserve the previous newline. It also has the accidental effect of removing the need for testing for not found.</span>
<span class="comment-copy">@Harvey: Thanks! I've provided an alternative bit of code for systems without <code>mmap.resize</code> support, and fixed up the <code>startofline</code> calculation. Damn you off-by-one errors!</span>
<span class="comment-copy">I honestly don't know if this is better, worse, or the same as the accepted answer on the duplicate, but I think you should consider adapting this as an answer to that question (in addition to this). That is, assuming it's not already there. That question has 19 answers and I have not read through them all.</span>
