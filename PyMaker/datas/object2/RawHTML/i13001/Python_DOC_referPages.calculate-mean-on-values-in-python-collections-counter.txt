<div class="post-text" itemprop="text">
<p>I'm profiling some numeric time measurements that cluster extremely closely. I would like to obtain mean, standard deviation, etc. Some inputs are large, so I thought I could avoid creating lists of millions of numbers and instead
use Python collections.Counter objects as a compact representation. </p>
<p>Example: one of my small inputs yields a <code>collection.Counter</code> like <code>[(48, 4082), (49, 1146)]</code> which means 4,082 occurrences of the value 48 and 1,146 occurrences of the value 49. For this data set I manually calculate the mean to be something like 48.2192042846.</p>
<p>Of course if I had a simple list of 4,082 + 1,146 = 5,228 integers I would just feed it to numpy.mean().</p>
<p>My question: how can I calculate descriptive statistics from the values in a <code>collections.Counter</code> object just as if I had a list of numbers? Do I have to create the full list or is there a shortcut?</p>
</div>
<div class="post-text" itemprop="text">
<p>While you can offload everything to <code>numpy</code> after making a list of values, this will be slower than needed. Instead, you can use the actual definitions of what you need. </p>
<p>The mean is just the sum of all numbers divided by their count, so that's very simple:</p>
<pre><code>sum_of_numbers = sum(number*count for number, count in counter)
count = sum(count for n, count in counter)
mean = sum_of_numbers / count
</code></pre>
<p>Standard deviation is a bit more complex. It's the square root of variance, and variance in turn is defined as "mean of squares minus the square of the mean" for your collection. Soooo...</p>
<pre><code>total_squares = sum(number*number * count for number, count in counter)
mean_of_squares = total_squares / count
variance = mean_of_squares - mean * mean
std_dev = math.sqrt(variance)
</code></pre>
<p>A little bit more manual work, but should also be much faster if the number sets have a lot of repetition.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>collections.Counter()</code> is a subclass of <code>dict</code>. Just use <code>Counter().values()</code> to get a list of the counts:</p>
<pre><code>counts = Counter(some_iterable_to_be_counted)
mean = numpy.mean(counts.values())
</code></pre>
<p>Note that I did <em>not</em> call <code>Counter.most_common()</code> here, which would produce the list of <code>(key, count)</code> tuples you posted in your question.</p>
<p>If you must use the output of <code>Counter.most_common()</code> you can filter out just the counts with a list comprehension:</p>
<pre><code>mean = numpy.mean([count for key, count in most_common_list])
</code></pre>
<p>If you are using Python 3 (where <code>dict.values()</code> returns a dictionary view), you could either pass in <code>list(counts.values())</code>, or use the standard library <a href="https://docs.python.org/3/library/statistics.html#statistics.mean" rel="nofollow"><code>staticstics.mean()</code> function</a>, which takes an iterable (including <code>dict.values()</code> dictionary view).</p>
<p>If you meant to calculate the mean <em>key value</em> as weighted by their counts, you'd do your own calculations directly from the counter values. In Python 2 that'd be:</p>
<pre><code>from __future__ import division

mean = sum(key * count for key, count in counter.iteritems()) / sum(counter.itervalues())
</code></pre>
<p>The <code>from __future__</code> import should be at the top of your module and ensures that you won't run into overflow issues with large floating point numbers. In Python 3 that'd be simplified to:</p>
<pre><code>mean = sum(key * count for key, count in counter.items()) / sum(counter.values())
</code></pre>
<p>The median could be calculated with bisection; sort the <code>(key, count)</code> pairs by key, sum the counts, and bisect the half-way point into a accumulated sum of the counts. The index for the insertion point points to the median key in the sorted keys list.</p>
</div>
<div class="post-text" itemprop="text">
<p>Unless you want to write your own statistic functions there is no prêt-à-porter solution (as far as I know).</p>
<p>So at the end you need to create lists, and the fastest way is to use numpy. One way to do it is:</p>
<pre><code>import numpy as np

# One memory allocation will be considerably faster
# if you have multiple discrete values.
elements = np.ones(48+49)
elements[0:48] *= 4082
elements[48:] *= 1146

# Then you can use numpy statistical functions to calculate
np.mean(elements)
np.std(elements)
# ... 
</code></pre>
<p><strong>UPDATE: Create elements from an existing collections.Counter() object</strong></p>
<pre><code>c = collections.Counter({48: 4082, 49: 1146})
elements = np.ones(sum(c.values()))
idx = 0
for value, occurrences in c.iteritems():
    elements[idx:idx + occurrences] *= value
    idx += occurrences
</code></pre>
</div>
<span class="comment-copy">(don't have time to write answer myself, but <code>np.average</code> has a weights parameter, and you can do stddev manually, see <a href="http://stackoverflow.com/questions/2413522/weighted-standard-deviation-in-numpy">here</a> -- if anyone wants to write up an answer using that approach I'll delete this)</span>
<span class="comment-copy">Like this one for brevity. Thanks @Martijn Pieters for clarifying Python's integer &amp; float math features, please don't be mad that I'm accepting this answer :)</span>
<span class="comment-copy">Thanks for fixing my markup.  I don't want the mean of the counts, I want the mean of the values as appropriately weighted by the counts.  I edited the post to add the manually calculated mean, a value about 48.2.</span>
<span class="comment-copy">@chrislott: then your option is to calculate the mean yourself: <code>sum(key * count for key, count in counter.iteritems()) / sum(counter.itervalues(), 0.0)</code> for Python 2.</span>
<span class="comment-copy">Yes still using Python 2.  I'm ignorant about Python's numeric capabilities, are you saying I don't have to be concerned about silent overflow given large values of key, count?</span>
<span class="comment-copy">@chrislott: Python's integers are only limited by how much memory your process can request. You can avoid floating point overflows with <code>from __future__ import division</code>, I <i>think</i>.</span>
<span class="comment-copy">@chrislott: I just confirmed this with an experiment with <code>sys.float_info.max</code>; use <code>from __future__ import division</code> and the division operator will produce a floating point value from large integer division without overflow.</span>
