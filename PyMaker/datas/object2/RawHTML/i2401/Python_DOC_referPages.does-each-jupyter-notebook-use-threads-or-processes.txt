<div class="post-text" itemprop="text">
<p>When I run the command</p>
<blockquote>
<p>jupyter notebook</p>
</blockquote>
<p>from the bash shell this starts a jupyter notebook server on localhost. Every time I open a new notebook and start executing code, is that a new process on a separate core or a new thread on the same core? Suppose I were to run N different independent notebooks which are CPU heavy, on a machine with M cores</p>
<ol>
<li>If they all run from the same core (same process) with different threads then are the rest of the cores are basically idle?</li>
<li>If they run from different cores, then does that mean I can only run M total notebooks at the same time? </li>
<li>Or perhaps its a mix of both: the ipython kernel takes care of launching new threads/processes that are beyond my manual control. In which case only M total notebooks would be able actually execute concurrently at the interpreter level, but I could open as many notebooks as my memory would allow.</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>From what I can tell from reading the documentation, the bug reports, and using it myself, each <code>jupyter notebook</code> command starts it's own worker process, and that's the extent of what's available for running directly. It also is possible to send long-running jobs to separate worker tasks with <a href="https://github.com/micahscopes/nbmultitask/blob/master/examples.ipynb" rel="nofollow noreferrer">an add-on</a> or with <a href="https://docs.python.org/3/library/concurrency.html" rel="nofollow noreferrer">various concurrency modules</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>I did an experiment on my laptop which has 2 cores, max 4 threads. I ran between 2-5 identical notebooks which each incremented a number from 1-100 trillion. It took a few minutes for each notebook to finish executing.</p>
<p>In windows task manager, each notebook was considered its own process. No more than 4 notebooks could execute simultaneously, with each one consuming between 20-25% of a single CPU. The 5th notebook effectively had to wait until the others were done before it began executing.</p>
<p>So to answer my own questions</p>
<ol>
<li>Each execution of a notebook is a separate thread, capable of running on any of the cores of your computer. Cells in the same notebook cannot execute concurrently (obviously) without using a library like Threading.</li>
<li><p>You can have as many notebooks open as your RAM permits, assuming they don't execute. However, you can only run </p>
<blockquote>
<p>MAX_THREADS = THREADS_PER_CORE*NUM_CORES </p>
</blockquote>
<p>notebooks simultaneously. If you try to run more, the additional notebooks will just stall until the other threads finish.</p></li>
<li><p>This is the correct interpretation</p></li>
</ol>
</div>
<span class="comment-copy">This post is actually several questions.  Each "?" in your post is a different question. but generally a good post is focused on a single question.  You might edit to focus on "How many ipython jupyter notebooks can I run on an machine with N cores?" or something similar.  One way to investigate your own questions is that there are system tools like <code>top</code> for Linux and task manager for Windows that allow you to observe the running processes.  Have you tried using these as you run more notebooks, and, if so, what are your observations?</span>
