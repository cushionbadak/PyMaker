<div class="post-text" itemprop="text">
<p>I'm trying to test a publicly available web page that takes a GET request and returns a different JSON file depending on the GET argument.</p>
<p>The API looks like</p>
<pre><code>https://www.example.com/api/page?type=check&amp;code=[Insert string here]
</code></pre>
<p>I made a program to check the results of all possible 4-letter strings on this API. My code looks something like this (with the actual URL replaced):</p>
<pre><code>import time, urllib.request

for a in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
    for b in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
        for c in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
            for d in "ABCDEFGHIJKLMNOPQRSTUVWXYZ":
                a,b,c,d = "J","A","K","E"
                test = urllib.request.urlopen("https://www.example.com/api/page?type=check&amp;code=" + a + b + c + d).read()
                if test != b'{"result":null}':
                    print(a + b + c + d)
                    f = open("codes", "a")
                    f.write(a + b + c + d + ",")
                    f.close()
</code></pre>
<p>This code is completely functional and works as expected. However, there is a problem. Because the program can't progress until it receives a responses, this method is very slow. If this ping time is 100ms for the API, then it will take 100ms for each check. When I modified this code so that it could test half of the results in one instance, and half in another, I noticed that the speed doubled.</p>
<p>Because of this, I'm led to believe that the ping time of the site is the limiting factor in this script. What I want to do is be able to is basically check each code, and then immediately check the next one without waiting for a response.</p>
<p>That would be the equivalent of opening up the page a few thousand times in my browser. It could load many tabs at the same time, since each page is less than a kilobyte.</p>
<p>I looked into using threading to do this, but I'm not sure if its relevant or helpful.</p>
</div>
<div class="post-text" itemprop="text">
<p>User a worker pool, like described here: <a href="https://docs.python.org/3.7/library/multiprocessing.html" rel="nofollow noreferrer">https://docs.python.org/3.7/library/multiprocessing.html</a></p>
<pre><code>from multiprocessing import Pool

def test_url(code):
    ''' insert code to test URL '''
    pass

if __name__ == '__main__':
    with Pool(5) as p:
        print(p.map(test_url, [code1,code2,code3]))
</code></pre>
<p>Just be aware that the website might be rate-limiting the amount of requests you are making.</p>
<p>To be more specific with your example, I would split it up into two phases: (1) <strong>generate test codes</strong> (2) <strong>test url, given one test code</strong>. Once you have the list of codes generated, you can apply the above strategy of applying the verifier to each generated code, using a worker pool.</p>
<p>To generate the test codes, you can use itertools:</p>
<pre><code>codes_to_test = [''.join(i) for i in itertools.product(string.ascii_lowercase, repeat = 5)]
</code></pre>
<p>You have a better understanding of how to test a URL given one test code , so I assume you can write a function <code>test_url(test_code)</code> that will make the appropriate URL request and verify the result as necessary. Then you can call:</p>
<pre><code>with Pool(5) as p:
    print(p.map(test_url, test_codes))
</code></pre>
<p>On top of this, I would suggest two things: make sure <code>test_codes</code> is not enormous at first (for example by taking a sublist of these generated codes) to make sure your code is working correctly and (2) that you can play with the size of the worker pool to not overwhelm your machine or the API.</p>
<p>Alternatively you can use asyncio (<a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer">https://docs.python.org/3/library/asyncio.html</a>) to keep everything in a single process.</p>
</div>
<span class="comment-copy">Thanks for pointing out rate limits.  Consult the website /robots.txt file manually to check for explicit rate limits there. If not, you can use the response time of the website to interpolate your wait time for each request.</span>
<span class="comment-copy">Could you show me how this would work in the context of my code? Like how would I implement my for loops within this?</span>
<span class="comment-copy">I extended my answer with more details and suggestions :)</span>
<span class="comment-copy">If you don't mind, could you actually add this into the code from my question? I tried doing this <a href="https://pastebin.com/raw/etWiw87L" rel="nofollow noreferrer">pastebin.com/raw/etWiw87L</a> but it didn't work</span>
<span class="comment-copy"><code>test_url</code> will take one argument, which is already the code consisting of 5 letters. So change the argument name to <code>code</code> and change how you build the url to <code>'...code='+ code</code>. You don't need <code>pass</code> at the end (in my example it just shows that the function is empty)</span>
