<div class="post-text" itemprop="text">
<p>I have experienced that in other languages. Now I have the same problem in Python. I have a dictionary that has a lot of CRUD actions. One would assume that deleting elements from a dictionary should decrease the memory footprint of it. It's not the case. Once a dictionary grows in size (doubling usually), it never(?) releases allocated memory back. I have run this experiment:</p>
<pre><code>import random
import sys
import uuid

a= {}
for i in range(0, 100000):
    a[uuid.uuid4()] = uuid.uuid4()
    if i % 1000 == 0:
        print sys.getsizeof(a)

for i in range(0, 100000):
    e = random.choice(a.keys())
    del a[e]
    if i % 1000 == 0:
        print sys.getsizeof(a)

print len(a)
</code></pre>
<p>The last line of the first loop is <code>6291736</code>. The last line of the second loop is <code>6291736</code> as well. And the size of the dictionary is <code>0</code>. </p>
<p>So how to tackle this issue? Is there a way to force release of memory? </p>
<p>PS: don't really need to do random - I played with the range of the second loop.</p>
</div>
<div class="post-text" itemprop="text">
<p>The way to do this "rehashing" so it uses less memory is to create a new dictionary and copy the content over.</p>
<p>The Python dictionary implementation is explained really well in this video:</p>
<p><a href="https://youtu.be/C4Kc8xzcA68" rel="nofollow">https://youtu.be/C4Kc8xzcA68</a></p>
<p>There is an atendee asking this same question (<a href="https://youtu.be/C4Kc8xzcA68?t=1593" rel="nofollow">https://youtu.be/C4Kc8xzcA68?t=1593</a>), and the answer given by the speaker is: </p>
<blockquote>
<p>Resizes are only calculated upon insertion; as a dictionary shrinks it just gains a lot of dummy entries and as you refill it will just start reusing those to store keys. [...] you have to copy the keys and values out to a new dictionary</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>Actually a dictionary can shrink upon resize, but the resize only happens upon a key insert not removal.  Here's a comment from the <a href="https://hg.python.org/cpython/file/tip/Objects/dictobject.c#l1207" rel="nofollow noreferrer">CPython source</a> for <code>dictresize</code>:</p>
<blockquote>
<p>Restructure the table by allocating a new table and reinserting all
  items again.  When entries have been deleted, the new table may
  actually be smaller than the old one.</p>
</blockquote>
<p>By the way, since the other answer quotes <a href="https://youtu.be/C4Kc8xzcA68?t=1593" rel="nofollow noreferrer">Brandon Rhodes talk</a> on the dictionary at PyCon 2010, and the quote seems to be at odds with the above (which has been there for years), I thought I would include the full quote, with the missing part in bold.</p>
<blockquote>
<p>Resizes are only calculated upon insertion.  As a dictionary shrinks,
  it just gains a lot of dummy entries and as you refill it, it will
  just start re-using those to store keys.  <strong>It will not resize until you
  manage to make it two-thirds full again at its larger size.  So it
  does not resize as you delete keys.  You have to do an insert to get
  it to figure out it needs to shrink.</strong></p>
</blockquote>
<p>So he does say the resizing operation can "figure out [the dictionary] needs to shrink".  But that only happens on insert.  Apparently when copying over all the keys during resize, the dummy keys can get removed, reducing the size of the backing array.</p>
<p>It isn't clear, however, how to get this to happen, which is why Rhodes says to just copy over everything to a new dictionary.</p>
</div>
<span class="comment-copy">You could try creating a new dictionary with the contents of the old one, and remove the reference to the old one.</span>
<span class="comment-copy">At what point? On schedule? How do I block writes?</span>
<span class="comment-copy">Python's <code>threading</code>, <code>multiprocessing</code>, and <code>asyncio</code> modules <i>all</i> provide you with nearly identical synchronization primitives such as <code>Lock</code>.  I would start looking in the applicable module's documentation.</span>
<span class="comment-copy">Also, 6291736 is 6MB.  Is your application's memory footprint a problem right now?  Premature debugging is the root of all evils...</span>
<span class="comment-copy">Indeed. As long as you are removing entries from the dictionary, they will get reused. 6 MB seems fine. What problem are you trying to solve by freeing this memory? BTW, it will probably never get released back to the OS even if you manage to pry it from Python's hands.</span>
<span class="comment-copy">Link-only answers are not good answers.</span>
<span class="comment-copy">I can't just stop everything -- requests are coming in async fashion. Surely Python async model is crooked but nonetheless there is no guarantee that while I move data from one dictionary to another, there won't be any changes in the source one.</span>
<span class="comment-copy">This seems a lot like stop-the-world garbage collection, and in the same fashion you could use a Lock so async requests wait upon the dict is recreated. More info about Lock: <a href="https://docs.python.org/2/library/threading.html" rel="nofollow noreferrer">docs.python.org/2/library/threading.html</a></span>
<span class="comment-copy">@Schultz9999 Then you need to consider locking, etc as with any async programming. Internally, the lists use an array. It's grown as items are added. To go through and compact the list (essentially doing a "Defrag" of the array) will require blocking other threads.</span>
<span class="comment-copy">Well, you could stop everything. Using a synchronization primitive from whichever of Python's <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">many</a> <a href="https://docs.python.org/3/library/asyncio-sync.html" rel="nofollow noreferrer">concurrency</a> <a href="https://docs.python.org/3.4/library/multiprocessing.html" rel="nofollow noreferrer">models</a> could prevent the dictionary from being updated.</span>
