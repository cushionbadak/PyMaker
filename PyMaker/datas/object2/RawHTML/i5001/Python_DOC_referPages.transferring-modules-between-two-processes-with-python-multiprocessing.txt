<div class="post-text" itemprop="text">
<p>So i have a problem. I'm trying to make my imports faster, so i started using multiprocessing module to split a group of imports into two functions, and then run each on separate core, thus speeding the imports up. But now the code will not recognize the modules at all. What am I doing wrong ?</p>
<pre><code>import multiprocessing


def core1():
    import wikipedia
    import subprocess
    import random
    return wikipedia, subprocess, random



def core2():
    from urllib import request
    import json
    import webbrowser
    return request, json, webbrowser


if __name__ == "__main__":
    start_core_1 = multiprocessing.Process(name='worker 1', target=core1, args = core2())
    start_core_2 = multiprocessing.Process(name='worker 2', target=core2, args = core1())
    start_core_1.start()
    start_core_2.start()

while True:
    user = input('[!] ')
    with request.urlopen('https://api.wit.ai/message?v=20160511&amp;q=%s&amp;access_token=Z55PIVTSSFOETKSBPWMNPE6YL6HVK4YP' % request.quote(user)) as wit_api:  # call to wit.ai api
        wit_api_html = wit_api.read()
        wit_api_html = wit_api_html.decode()
        wit_api_data = json.loads(wit_api_html)
    intent = wit_api_data['entities']['Intent'][0]['value']
    term = wit_api_data['entities']['search_term'][0]['value']
    if intent == 'info_on':
        with request.urlopen('https://kgsearch.googleapis.com/v1/entities:search?query=%s&amp;key=AIzaSyCvgNV4G7mbnu01xai0f0k9NL2ito8vY6s&amp;limit=1&amp;indent=True' % term.replace(' ', '%20')) as response:
            google_knowledge_base_html = response.read()
            google_knowledge_base_html = google_knowledge_base_html.decode()
            google_knowledge_base_data = json.loads(google_knowledge_base_html)
            print(google_knowledge_base_data['itemListElement'][0]['result']['detailedDescription']['articleBody'])
    else:
        print('Something')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think you are missing the important parts of the whole picture i.e. crucial parts of what you need to know about <code>multiprocessing</code> when using it.</p>
<p>Here are some crucial parts that you have to know and then you will understand why you can't just import modules in child process and speed up the thing. Even returning loaded modules is not a perfect answer too.</p>
<p>First, when you use <code>multiprocess.Process</code> a child process is <code>forked</code> (on Linux) or <code>spawned</code> (on Windows). I'll assume you are using Linux. In that case, every child process inherits every loaded module from parent (global state). When child process changes anything, like global variables or imports new modules, those stay just in its context. So, parent process is not aware of it. I believe part of <a href="https://stackoverflow.com/a/48855986/3029287">this</a> can also be of interest.</p>
<p>Second, module can be a set of classes, external lib bindings, functions, etc. and some of them quite probably can't be pickled, at least with <code>pickle</code>. Here is the list of what can be pickled in <a href="https://docs.python.org/2/library/pickle.html#what-can-be-pickled-and-unpickled" rel="nofollow noreferrer">Python 2.7</a> and in <a href="https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled" rel="nofollow noreferrer">Python 3.X</a>. There are even libraries that give you 'more pickling power' like <a href="https://github.com/uqfoundation/dill" rel="nofollow noreferrer">dill</a>. However, I'm not sure pickling whole modules is a good idea at all, not to mention that you have slow imports and yet you want to serialize them and send them to parent process. Even if you manage to do it, it doesn't sound like a best approach.</p>
<p>Some of the ideas on how to change the perspective:</p>
<ol>
<li><p>Try to revise which module you need and why? Maybe you can use other modules that can give you similar functionalities. Maybe these modules are overweighing and bringing too much with them and cost is great in comparing to what you get.</p></li>
<li><p>If you have slow loading of modules, try to make a script that will always be running, so you do not have to run it multiple times.</p></li>
<li><p>If you really need those modules maybe you can separate their using in two processes and then each process does it's own thing. Example would be, one process parses page, other process processes and so on. That way you sped up the loading but you have to deal with passing messages between processes.</p></li>
</ol>
</div>
<span class="comment-copy">What is the exact error/ issue you are facing? Try describing your problem in detail.</span>
<span class="comment-copy">@Reck I am getting TypeError: can't pickle module objects error, you can see in the following image.  <a href="http://prntscr.com/ijkm0x" rel="nofollow noreferrer">prntscr.com/ijkm0x</a></span>
<span class="comment-copy">This should have been mentioned/ added in the question. So that it would easier to understand the exact issue.</span>
<span class="comment-copy">By the error message I can infer that. Module instances which you are passing as args are fed to multiprocessing process. And these processes uses pickle to store the process dumps. And the catch here is that <b>pickle module</b> cannot pickle module objects. And please indent your code.</span>
<span class="comment-copy">You may want to <a href="https://stackoverflow.com/questions/2790828/python-cant-pickle-module-objects-error">check this</a> once.</span>
<span class="comment-copy">actually im using Windows, but this advices have actually been useful. Thanks.</span>
