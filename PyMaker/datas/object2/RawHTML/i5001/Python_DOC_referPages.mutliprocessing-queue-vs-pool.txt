<div class="post-text" itemprop="text">
<p>I'm having the hardest time trying to figure out the difference in usage between <code>multiprocessing.Pool</code> and <code>multiprocessing.Queue</code>.</p>
<p>To help, this is bit of code is a barebones example of what I'm trying to do.</p>
<pre><code>def update():
    def _hold(url):
        soup = BeautifulSoup(url)
        return soup
    def _queue(url):
        soup = BeautifulSoup(url)
        li = [l for l in soup.find('li')]
        return True if li else False

    url = 'www.ur_url_here.org'
    _hold(url)
    _queue(url)
</code></pre>
<p>I'm trying to run <code>_hold()</code> and <code>_queue()</code> at the same time. I'm not trying to have them communicate with each other so there is no need for a <code>Pipe</code>. <code>update()</code> is called every 5 seconds.</p>
<p>I can't really rap my head around the difference between creating a pool of workers, or creating a queue of functions. Can anyone assist me?</p>
<p>The real <code>_hold()</code> and <code>_queue()</code> functions are much more elaborate than the example so concurrent execution actually is necessary, I just thought this example would suffice for asking the question.  </p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>Pool</code> and the <code>Queue</code> belong to two different levels of abstraction.</p>
<p>The Pool of Workers is a concurrent design paradigm which aims to abstract a lot of logic you would otherwise need to implement yourself when using processes and queues.</p>
<p>The <code>multiprocessing.Pool</code> actually uses a <code>Queue</code> internally for operating.</p>
<p>If your problem is simple enough, you can easily rely on a <code>Pool</code>. In more complex cases, you might need to deal with processes and queues yourself.</p>
<p>For your specific example, the following code should do the trick.</p>
<pre><code>def hold(url):
    ...
    return soup

def queue(url):
    ...
    return bool(li)

def update(url):
    with multiprocessing.Pool(2) as pool:
        hold_job = pool.apply_async(hold, args=[url])
        queue_job = pool.apply_async(queue, args=[url])

        # block until hold_job is done
        soup = hold_job.get()
        # block until queue_job is done
        li = queue_job.get()
</code></pre>
<p>I'd also recommend you to take a look at the <a href="https://docs.python.org/3/library/concurrent.futures.html?highlight=concurrent%20futures#module-concurrent.futures" rel="nofollow noreferrer"><code>concurrent.futures</code></a> module. As the name suggest, that is the future proof implementation for the Pool of Workers paradigm in Python.</p>
<p>You can easily re-write the example above with that library as what really changes is just the API names.</p>
</div>
<span class="comment-copy">Thank you this is exactly what I was looking for, I didn't know I could call <code>apply_async()</code> more than once. I will look into <code>futures</code></span>
