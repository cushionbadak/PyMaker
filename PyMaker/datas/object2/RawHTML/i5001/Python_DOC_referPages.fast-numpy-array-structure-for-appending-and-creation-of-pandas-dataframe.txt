<div class="post-text" itemprop="text">
<p>I am trying for hours to come up with the most efficient approach to structure and append flowing tick data to a <strong><a href="https://gitlab.com/tenzing/shared-array" rel="nofollow noreferrer">shared memory</a> numpy array</strong> and later get a pandas DataFrame in a timely fashion.</p>
<pre><code>#source tick data comes in as dict
tick_data = {"bid": float(1.2), "ask": float(1.3), "time": datetime.datetime.now()}


#construct np array
dtype_conf = [('bid', '&lt;f4'), ('ask', '&lt;f4'), ('time', 'datetime64[us]')]
new_tick = np.array([(11.11, 22.22, now)], dtype=dtype_conf)

#append / vstack / .. it to existing shared numpy array
shared_np_array = np.vstack((shared_np_array, new_tick))

#fast construction of pd.DataFrame if needed 
pd.DataFrame(shared_np_array.reshape((1,-1))[0])
</code></pre>
<p>Questions:</p>
<p>1) What is the right way to structure my array and (faster) append new tick data to it?</p>
<p>2) What would be the most efficient approach to create either a pd.DataFrame of the complete array or a pd.Series for a column?</p>
<p>3) Is there a better way to work with shared memory timeseries in python (besides multiprocessing.basemanager)?</p>
<p>Many thanks! </p>
</div>
<div class="post-text" itemprop="text">
<p><code>numpy</code> is not a good choice of data type for <em>appending</em> data.</p>
<p>The most versatile choice in python is <a href="https://docs.python.org/3/library/collections.html#collections.deque" rel="nofollow noreferrer"><code>collections.deque</code></a>, which is optimized for inserting items at the beginning or end of the list.</p>
<p>This is how your code might look:</p>
<pre><code>import pandas as pd, numpy as np
import datetime
from collections import deque

now = datetime.datetime.now()
lst_d = deque()

#source tick data comes in as dict
tick_data = {"bid": float(1.2), "ask": float(1.3), "time": now}

#construct np array
dtype_conf = [('bid', '&lt;f4'), ('ask', '&lt;f4'), ('time', 'datetime64[us]')]
new_tick = np.array([(11.11, 22.22, now)], dtype=dtype_conf)

# existing deque object named lst_d
lst_d.append(list(new_tick))

# example of how your deque may look
lst_d = deque([[1, 2, 'time1'], [3, 4, 'time3'], [4, 5, 'time4']])

#fast dataframe construction
print(pd.DataFrame(list(lst_d), columns=['bid', 'ask', 'time']))

#    bid  ask   time
# 0    1    2  time1
# 1    3    4  time3
# 2    4    5  time4
</code></pre>
<p>Not sure why <code>reshape</code> is required with a <code>numpy</code> array:</p>
<pre><code># example of how your deque may look
lst_d = np.array([[1, 2, 'time1'], [3, 4, 'time3'], [4, 5, 'time4']])

#fast dataframe construction
print(pd.DataFrame(lst_d, columns=['bid', 'ask', 'time']))

#    bid  ask   time
# 0    1    2  time1
# 1    3    4  time3
# 2    4    5  time4
</code></pre>
</div>
<span class="comment-copy">I recommend creating a list of tuples, and making a structured array once, <a href="https://stackoverflow.com/q/48751127/901925">stackoverflow.com/q/48751127/901925</a></span>
<span class="comment-copy">Are you aware that with each <code>vstack</code> you create a new array?</span>
<span class="comment-copy">I see. Do you have a better idea how to append more efficiently?</span>
<span class="comment-copy">Thanks! Problem is that I am stuck to a numpy array as I was planning to use that via posix shared memory (<a href="https://gitlab.com/tenzing/shared-array" rel="nofollow noreferrer">gitlab.com/tenzing/shared-array</a>) for fast write and read between several processes. I was looking for a fast python shared memory solution for quite some time since multiprocess.basemanager and a class dict/ list setup was too slow.</span>
<span class="comment-copy">@trbck, I see. Unfortunately, I don't know how you can improve numpy append performance. Will keep my answer up so that others don't fall into the trap.</span>
<span class="comment-copy">I mean "appending" via vstack is quite fast. But the need to reshape the np.array to create a dataframe with pd.DataFrame(a.reshape((1,-1))[0]) slows it down quite much. I was also wondering if I can change the structure of the np.array to faster create a dataframe here as dtypes (so no further processing/ calculation needed for df) are already properly set up within the np.array anyway.</span>
<span class="comment-copy">@trbck, I added an example. I'm not sure why <code>reshape</code> is necessary</span>
