<div class="post-text" itemprop="text">
<p>I have a 2D NumPy array that could be of any type, but for this example, we can assume it is integers. I am looking to find the fastest way to find all the unique rows in the array.</p>
<p>My initial strategy was to convert each row into a tuple and add this to a set. If the length of the set increased, this would mean a unique row was found.</p>
<p><strong>What I don't know how to do is quickly hash each row as bytes</strong>. There is a question where an <a href="https://stackoverflow.com/questions/16589791/most-efficient-property-to-hash-for-numpy-array">entire array is hashed here</a>.</p>
<p><strong>What I tried - tuple creation</strong></p>
<p>There are many ways to create a tuple, and each one impacts performance. Here is my function that I show 4 different variations:  </p>
<h3>Version 1:</h3>
<pre><code>def unique_int_tuple1(ndarray[np.int64_t, ndim=2] a):
    cdef int i, len_before
    cdef int nr = a.shape[0]
    cdef int nc = a.shape[1]
    cdef set s = set()
    cdef ndarray[np.uint8_t, cast = True] idx = np.zeros(nr, dtype='bool')

    for i in range(nr):
        len_before = len(s)
        s.add(tuple(a[i]))        # THIS LINE IS CHANGED FOR ALL VERSIONS
        if len(s) &gt; len_before:
            idx[i] = True
    return idx
</code></pre>
<h3>Version 2:</h3>
<pre><code>s.add(tuple([a[i, j] for j in range(nc)]))
</code></pre>
<h3>Version 3:</h3>
<p><code>vals</code> is a list with length equal to the number of columns</p>
<pre><code>for j in range(nc):
    vals[j] = a[i, j]
    s.add(tuple(vals))
</code></pre>
<h3>Version 4:</h3>
<pre><code>s.add((a[i, 0], a[i, 1], a[i, 2], a[i, 3]))
</code></pre>
<h2>Performance</h2>
<pre><code>a = np.random.randint(0, 8, (10**5, 4))
%timeit unique_int_tuple1(a)
125 ms ± 1.96 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

%timeit unique_int_tuple2(a)
14.5 ms ± 93.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

%timeit unique_int_tuple3(a)
11.7 ms ± 126 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)

%timeit unique_int_tuple4(a)
9.59 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</code></pre>
<p>Avoiding the <code>tuple</code> constructor (version 4) results in a nice performance gain.</p>
<h3>Using <code>tostring</code></h3>
<p>From the linked SO question above, I can use the <code>tostring</code> method on each row and then hash this.</p>
<pre><code>def unique_int_tostring(ndarray[np.int64_t, ndim=2] a):
    cdef int i, j
    cdef int nr = a.shape[0]
    cdef int nc = a.shape[1]
    cdef set s = set()
    cdef ndarray[np.uint8_t, cast = True] idx = np.zeros(nr, dtype='bool')

    for i in range(nr):
        len_before = len(s)
        s.add(a[i].tostring())
        if len(s) &gt; len_before:
            idx[i] = True
    return idx
</code></pre>
<p>This works but is very slow:</p>
<pre><code>%timeit unique_int_tostring(a)
40 ms ± 428 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre>
<h3>Using typed memoryview</h3>
<p>A huge part of the slowdown, I believe, is the access of each row <code>a[i]</code>. We can used typed memoryviews to increase performance, but <strong>I don't know how to turn elements of typed memoryviews into strings</strong> so they can be hashed.</p>
<pre><code>def unique_int_memoryview(long[:, :] a):
    cdef int i, j
    cdef int nr = a.shape[0]
    cdef int nc = a.shape[1]
    cdef set s = set()
    for i in range(nr):
        s.add(&lt;SOMETHING&gt;)   # NO IDEA HERE
    return s
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This, surprising to me, is slower, but for whatever it's worth, here is a c++ solution that does what you were pointing at - hash each row as a set of bytes.  The 'trick' is taking the address of an element <code>&lt;char*&gt;&amp;a[i, 0]</code> - most everything else is book-keeping.  </p>
<p>I may be doing some obviously sub-optimal and/or performance is likely better with a different hash table impl.</p>
<p>Edit:</p>
<p>re: how to create a string from a row
I think the best you could do is this - construct a <code>bytes</code> object from the pointer.  This does necessarily involve a copy of the row see c api <a href="https://docs.python.org/3/c-api/bytes.html#c.PyBytes_FromStringAndSize" rel="nofollow noreferrer">docs</a>.</p>
<pre><code>%%cython
from numpy cimport *
cimport numpy as np
import numpy as np
from cpython.bytes cimport PyBytes_FromStringAndSize

def unique_int_string(ndarray[np.int64_t, ndim=2] a):
    cdef int i, len_before
    cdef int nr = a.shape[0]
    cdef int nc = a.shape[1]
    cdef set s = set()
    cdef ndarray[np.uint8_t, cast = True] idx = np.zeros(nr, dtype='bool')
    cdef bytes string

    for i in range(nr):
        len_before = len(s)
        string = PyBytes_FromStringAndSize(&lt;char*&gt;&amp;a[i, 0], sizeof(np.int64_t) * nc)
        s.add(string)
        if len(s) &gt; len_before:
            idx[i] = True
    return idx
</code></pre>
<p>// timing</p>
<pre><code>In [9]: from unique import unique_ints

In [10]: %timeit unique_int_tuple4(a)
100 loops, best of 3: 10.1 ms per loop

In [11]: %timeit unique_ints(a)
100 loops, best of 3: 11.9 ms per loop

In [12]: (unique_ints(a) == unique_int_tuple4(a)).all()
Out[12]: True
</code></pre>
<p>// helper.h</p>
<pre><code>#include &lt;unordered_set&gt;
#include &lt;cstring&gt;

struct Hasher {
    size_t size;
    size_t operator()(char* buf) const {
        // https://github.com/yt-project/yt/blob/c1569367c6e3d8d0a02e10d0f3d0bd701d2e2114/yt/utilities/lib/fnv_hash.pyx
        size_t hash_val = 2166136261;
        for (int i = 0; i &lt; size; ++i) {
                hash_val ^= buf[i];
                hash_val *= 16777619;
        }
        return hash_val;
    }
};
struct Comparer {
    size_t size;
    bool operator()(char* lhs, char* rhs) const {
        return (std::memcmp(lhs, rhs, size) == 0) ? true : false;
    }
};

struct ArraySet {
    std::unordered_set&lt;char*, Hasher, Comparer&gt; set;

    ArraySet (size_t size) : set(0, Hasher{size}, Comparer{size}) {}
    ArraySet () {}

    bool add(char* buf) {
        auto p = set.insert(buf);
        return p.second;
    }
};
</code></pre>
<p>// unique.pyx</p>
<pre><code>from numpy cimport int64_t, uint8_t
import numpy as np

cdef extern from 'helper.h' nogil:
    cdef cppclass ArraySet:
        ArraySet()
        ArraySet(size_t)
        bint add(char*)


def unique_ints(int64_t[:, :] a):
    cdef:
        Py_ssize_t i, nr = a.shape[0], nc = a.shape[1]
        ArraySet s = ArraySet(sizeof(int64_t) * nc)
        uint8_t[:] idx = np.zeros(nr, dtype='uint8')

        bint found;

    for i in range(nr):
        found = s.add(&lt;char*&gt;&amp;a[i, 0])
        if found:
            idx[i] = True

    return idx
</code></pre>
<p>// setup.py</p>
<pre><code>from setuptools import setup, Extension
from Cython.Build import cythonize
import numpy as np

exts = [
  Extension('unique', ['unique.pyx'], language='c++', include_dirs=[np.get_include()])
]

setup(name='test', ext_modules=cythonize(exts))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <code>ndarray.view()</code> to change the <code>dtype</code> to <code>byte string</code>, and then use <code>pandas.Series.duplicated()</code> to find duplicated rows:</p>
<pre><code>import numpy as np

a = np.random.randint(0, 5, size=(200, 3))
s = pd.Series(a.view(("S", a[0].nbytes))[:, 0])
s.duplicated()
</code></pre>
<p>the core algorithm of <code>duplicated()</code> is implemented in Cython. However it need to convert the original array to an object array, which maybe slow.</p>
<p>To skip <code>object array</code>, you can use the <a href="https://github.com/attractivechaos/klib/blob/master/khash.h" rel="nofollow noreferrer">khash library</a> that used by Pandas directly, here is the C code:</p>
<pre><code>#include "khash.h"

typedef struct _Buf{
    unsigned short n;
    char * pdata;
} Buf;

khint32_t kh_buf_hash_func(Buf key)
{
    int i;
    char * s;
    khint32_t hash = 0;
    s = key.pdata;
    for(i=0;i&lt;key.n;i++)
    {
        hash += *s++;
        hash += (hash &lt;&lt; 10);
        hash ^= (hash &gt;&gt; 6);
    }
    hash += (hash &lt;&lt; 3);
    hash ^= (hash &gt;&gt; 11);
    hash += (hash &lt;&lt; 15);    
    return hash;
}

khint32_t kh_buf_hash_equal(Buf a, Buf b)
{
    int i;
    if(a.n != b.n) return 0;
    for(i=0;i&lt;a.n;i++){
        if(a.pdata[i] != b.pdata[i]) return 0;
    }
    return 1;
}

KHASH_INIT(buf, Buf, char, 0, kh_buf_hash_func, kh_buf_hash_equal)


void duplicated(char * arr, int row_size, int count, char * res)
{
    kh_buf_t * khbuf;
    Buf row;
    int i, absent;
    khint_t k;
    row.n = row_size;

    khbuf = kh_init_buf();
    kh_resize_buf(khbuf, 4 * count);

    for(i=0;i&lt;count;i++){
        row.pdata = &amp;arr[i * row_size];
        k = kh_put_buf(khbuf, row, &amp;absent);
        if (absent){
            res[i] = 0;
        }
        else{
            res[i] = 1;
        }
    }    
    kh_destroy_buf(khbuf);
}
</code></pre>
<p>then wrap the <code>duplicated()</code> function by Cython or Ctypes or cffi.</p>
</div>
<span class="comment-copy">You might get some improvement by doing <code>a[i,:]</code> instead of <code>a[i]</code> (for both <code>ndarray</code> and for memoryviews) - I doubt if it'll be much though</span>
<span class="comment-copy">@DavidW No, unfortunately that doesn't help. Other ideas include turning the entire array into a string before the loop. Also, I'm not sure turning a row into a string will guarantee uniqueness.</span>
<span class="comment-copy"><code>np.unique(a, axis=0)</code> is coming out at <code>20.6 ms ± 77.5 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)</code> for me. Maybe that's a starting basis though? I'm not sure if that method can be used in Cython.</span>
<span class="comment-copy">@roganjosh np.unique is very slow (unless the data has few duplicates) and sorts the data first. I'm looking for a hash based solution.</span>
<span class="comment-copy">Why not use your own hash function? I've had success implementing the FNV hash in pure cython: <a href="https://github.com/yt-project/yt/blob/c1569367c6e3d8d0a02e10d0f3d0bd701d2e2114/yt/utilities/lib/fnv_hash.pyx" rel="nofollow noreferrer">github.com/yt-project/yt/blob/…</a></span>
<span class="comment-copy">Thanks for this very detailed answer. It seems you created a custom hasher to hash multiple integers. Could you have used a <code>vector</code> instead? Also, I've seen that the default<code>unordered_set</code> has worse performance than Python's <code>set</code>.</span>
<span class="comment-copy">More importantly, I have a question on the 'trick' <code>&lt;char*&gt;&amp;a[i, 0]</code> (thanks very much for this). How do I convert an entire row directly to a string? Attempting: <code>&lt;char*&gt;&amp;a[i]</code> produces a compile error: <code>Cannot take address of memoryview slice</code></span>
<span class="comment-copy">1) <code>std::hash</code> isn't defined by default for vectors either, so would have to define a custom hasher in that case too</span>
<span class="comment-copy">2) see edit for example</span>
<span class="comment-copy">Wow, you are some kind of wizard. Very cool. I tested the new solution and it's 50% slower than the tuple of ints. Shouldn't there be a faster way to convert a row to a string? @HYRY solution above uses <code>a.view(("S", a[0].nbytes))</code></span>
<span class="comment-copy">@TedPetrou, I modified the answer to include the c code that can be wrapped by Cython.</span>
