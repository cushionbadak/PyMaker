<div class="post-text" itemprop="text">
<p>I want to convert a pdf file to text by PyPDF2 but converted text looks differents from PDF file. Specifically, one line in PDF is broken into multiple lines in text and words may be broken as well. Attached is the PDF and the text file I got with the code below. Could anyone help me fix this issue?</p>
<pre><code>enter code here

import PyPDF2

def extractPdfText(filePath=''):

# Open the pdf file in read binary mode.
fileObject = open(filePath, 'rb') # rb

# Create a pdf reader .
pdfFileReader = PyPDF2.PdfFileReader(fileObject)

# Get total pdf page number.
totalPageNumber = pdfFileReader.numPages

# Print pdf total page number.
print('This pdf file contains totally ' + str(totalPageNumber) + ' pages.')

currentPageNumber = 0
text = ''

# Loop in all the pdf pages.
while(currentPageNumber &lt; totalPageNumber ):

    # Get the specified pdf page object.
    pdfPage = pdfFileReader.getPage(currentPageNumber)

    # Get pdf page text.
    text = text + pdfPage.extractText()

    # Process next page.
    currentPageNumber += 1

    return text

pdfFilePath = 'PDF file path'

pdfText = extractPdfText(pdfFilePath)
</code></pre>
<p><a href="https://i.stack.imgur.com/xyTiG.jpg" rel="nofollow noreferrer">pdf file</a></p>
<p><a href="https://i.stack.imgur.com/16LAH.jpg" rel="nofollow noreferrer">converted text</a></p>
</div>
<div class="post-text" itemprop="text">
<p>This is how I would do it.</p>
<pre><code>from io import StringIO
from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter
from pdfminer.converter import TextConverter
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage
import os
import sys, getopt

#converts pdf, returns its text content as a string
def convert(fname, pages=None):
    if not pages:
        pagenums = set()
    else:
        pagenums = set(pages)

    output = io.StringIO()
    manager = PDFResourceManager()
    converter = TextConverter(manager, output, laparams=LAParams())
    interpreter = PDFPageInterpreter(manager, converter)

    infile = open(fname, 'rb')
    for page in PDFPage.get_pages(infile, pagenums):
        interpreter.process_page(page)
    infile.close()
    converter.close()
    text = output.getvalue()
    output.close
    return text 

#converts all pdfs in directory pdfDir, saves all resulting txt files to txtdir
def convertMultiple(pdfDir, txtDir):
    if pdfDir == "": pdfDir = os.getcwd() + "\\" #if no pdfDir passed in 
    for pdf in os.listdir(pdfDir): #iterate through pdfs in pdf directory
        fileExtension = pdf.split(".")[-1]
        if fileExtension == "pdf":
            pdfFilename = pdfDir + pdf 
            text = convert(pdfFilename) #get string of text content of pdf
            textFilename = txtDir + pdf + ".txt"
            textFile = open(textFilename, "w") #make text file
            textFile.write(text) #write text to text file

# set paths accordingly:
pdfDir = "C:/your_path_here/"
txtDir = "C://your_path_here/"
convertMultiple(pdfDir, txtDir)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This answer using <em>encode('utf-8')</em> to keep the output per page together.  I don't know what output you need, because it wasn't specified in your question. </p>
<pre><code>from PyPDF2 import PdfFileReader

def pdf_text_extractor(path):
   with open(path, 'rb') as f:
     pdf = PdfFileReader(f)

     # Get total pdf page number.
     totalPageNumber = pdf.numPages

     currentPageNumber = 0

     while (currentPageNumber &lt; totalPageNumber):
        page = pdf.getPage(currentPageNumber)

        text = page.extractText()
        # The encoding put each page on a single line.  
        # type is &lt;class 'bytes'&gt;
        print(text.encode('utf-8'))

        #################################
        # This outputs the text to a list,
        # but it doesn't keep paragraphs 
        # together 
        #################################
        # output = text.encode('utf-8')
        # split = str(output, 'utf-8').split('\n')
        # print (split)
        #################################

        # Process next page.
        currentPageNumber += 1

path = 'mypdf.pdf'
pdf_text_extractor(path)
</code></pre>
<p>The documentation for PyPDF2 and the <em>extractText()</em> function states this:</p>
<pre><code>extractText()

Locate all text drawing commands, in the order they are provided in the 
content stream, and extract the text. This works well for some PDF files, but 
poorly for others, depending on the generator used. This will be refined in 
the future. Do not rely on the order of text coming out of this function, as 
it will change if this function is made more sophisticated.

Returns: a unicode string object.
</code></pre>
<p>This means that extracting the text exactly like the formatted text in the PDF can be problematic. </p>
<p>You could use tika to accomplish this task, but again it won't be completely clean.  </p>
<pre><code>from tika import parser

parse_entire_pdf = parser.from_file('mypdf.pdf', xmlContent=True)
parse_entire_pdf = parse_entire_pdf['content']
print (parse_entire_pdf)
</code></pre>
<p>The real question is -- How do you plan to use the extracted text?</p>
</div>
<span class="comment-copy">Thanks. Works perfectly</span>
<span class="comment-copy">Thanks @Life is complex. I would like to get the output that looks like pdf which means that one line in pdf is kept in one line in text, not divided into several lines</span>
<span class="comment-copy">Ok.  I will post an update.</span>
<span class="comment-copy">You can use this file for your experiment <a href="https://www.opec.org/opec_web/static_files_project/media/downloads/publications/MOMR%20December%202018.pdf" rel="nofollow noreferrer">opec.org/opec_web/static_files_project/media/downloads/â€¦</a></span>
<span class="comment-copy">I use the text for sentiment analysis. it doesn't matter with line break but sometime one word is broken into 2 parts which cause the problem when this word is important</span>
<span class="comment-copy">Either answer will work for sentiment analysis, but you will have to do some data cleaning to deal with the split words in the PyPDF2 output.</span>
