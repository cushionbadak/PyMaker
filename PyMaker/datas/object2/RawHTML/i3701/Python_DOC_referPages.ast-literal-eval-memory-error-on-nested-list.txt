<div class="post-text" itemprop="text">
<p>I'm trying to use ast.literal_eval on a string, but am getting a memory error. Is the list too nested or what is the problem? Is there an alternative?</p>
<pre><code>MemoryError                               Traceback (most recent call last)
&lt;ipython-input-138-3ea9110f7dc3&gt; in &lt;module&gt;()
      1 s = "[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['Xenophrys_bairdii'],'Vulpanser_spaldingi'],'Vipera_yeltoniensis'],'Vipera_minutus'],'Vanellus_vegans'],'Vanellus_bedriagai'],'Ursus_gratiosa'],'Uroplatus_flavomaculatus'],'Trionyx_leporosum'],'Tringa_aspera'],'Trachemys_sirtalis'],'Terpsihone_varius'],'Spermophilus_hassanica'],'Siniperca_decor'],'Scolopendra_marcianus'],'Rufibrenta_montela'],'Riparia_clinatus'],'Rhinolophus_tuberculosus'],'Rhacodactylus_citrsola'],'Remiz_niloticus'],'Pterinochilus_physalus'],'Procellaria_truncatus'],'Procellaria_lutris'],'Poephagus_indica'],'Platemys_albopillosum'],'Pica_totanus'],'Pica_mexicana'],'Phrynomerus_pelagicus'],'Philothamnus_tuberculosus'],'Petrocincla_acuta'],'Pelomedusa_rusticolus'],'Pagophila_metallica'],'Pachytriton_sibiricus'],'Otis_moschata'],'Otis_franckii'],'Otis_emarginatus'],'Opheodrys_clarus'],'Mylopharyngodon_diffidens'],'Mergus_carinata'],'Meles_carbonaria'],'Mabuya_carnivorus'],'Lystrophis_siebenrocki'],'Lyrurus_tinctorius'],'Lycodon_dendrophila'],'Lutra_plathyrhychos'],'Leptopelis_plumipes'],'Leptopelis_licin'],'Leiurus_grossmani'],'Lasiodora_hipposideros'],'Larus_pulchripes'],'Kinosternon_guineti'],'Kassina_canorus'],'Hysterocrates_chukar'],'Hydrochelidon_euptilura'],'Hemitheconyx_pulchripes'],'Haplopelma_arcticus'],'Hadrurus_dominus'],'Gypaetus_schneideri'],'Glareola_leucophyllata'],'Gerrhosaurus_ruficollis'],'Geochelone_filipjevi'],'Gallinago_pallasii'],'Eutamias_multifasciata'],'Eulabeia_tinnunculus'],'Eudrornias_penelope'],'Eudramias_tadorna'],'Eschrichtius_pulchra'],'Eremophila_similis'],'Equus_fluviatilis'],'Epicrates_carinatus'],'Emydura_avosetta'],'Emberiza_japonica'],'Dyscophus_rubicola'],'Dendrelaphis_griseus'],'Cypselus_ceterus'],'Cynops_rutila'],'Cygnus_rubicola'],'Ctenosaura_sphenocercus'],'Coenobita_variabilis'],'Clemmys_caudata'],'Cervus_comicus'],'Castor_prominanus'],'Casarca_holbrooki'],'Capella_aestivus'],'Buthus_nebularia'],'Bronchocela_bicoloratum'],'Branta_ferrumequinum'],'Balaenoptera_piscator'],'Athene_musculus'],'Argynnis_versicolor'],'Arenaria_javanica'],'Anthropoides_aestivus'],'Anolis_medirostris'],'Anodonta_infrafrenata'],'Ambystoma_alcinous'],'Acanthoceros_euptilura']"
----&gt; 2 ast.literal_eval(s)

~\Anaconda3\lib\ast.py in literal_eval(node_or_string)
     46     """
     47     if isinstance(node_or_string, str):
---&gt; 48         node_or_string = parse(node_or_string, mode='eval')
     49     if isinstance(node_or_string, Expression):
     50         node_or_string = node_or_string.body

~\Anaconda3\lib\ast.py in parse(source, filename, mode)
     33     Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
     34     """
---&gt; 35     return compile(source, filename, mode, PyCF_ONLY_AST)
     36 
     37 

MemoryError: 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Apparently the interpreter has some limit when parsing nested lists (in our example, but most likely applies to other containers as well). It breaks both <code>ast.literal_eval</code> and <code>eval</code> (<strong>unsafe</strong>), and the fact that both of them have the same limit, tells me that they both use some common code (which could also affect other areas). <br/>In my case it's <strong><em>92</em></strong> (<strong><em>93</em></strong> breaks it), but since a quick <em>Python</em> source code search didn't reveal anything relevant (like a constant, <code>#define</code>, or smth similar), this value might be related to my environment (machine, stack, <em>OS</em>, <em>Python</em> version, etc.). <br/>Note that nested lists can have a much higher nesting level (limited by <a href="https://docs.python.org/3/library/sys.html#sys.getrecursionlimit" rel="nofollow noreferrer">[Python]: sys.<strong>getrecursionlimit</strong>()</a> - for me attempting to create <strong><em>999</em></strong> (or higher) level nested lists, raised <code>RecursionError</code>).</p>
<p>Anyway, as an alternative, I used <a href="https://docs.python.org/3/library/json.html" rel="nofollow noreferrer">[Python]: json - JSON encoder and decoder</a>, which worked (with a bit of processing). Note that although this method works for your scenario, it's not at all robust; e.g.: if one of the strings contains <em>quotes</em> (simple or double) it <strong>will no longer work</strong>.</p>
<p><em>code.py</em>:</p>
<pre><code>import sys
import ast
import json
import traceback


LIST_NESTING_LIMIT = 92


def generate_nested_list(count):
    if count &lt;= 0:
        return None
    ret = ["0"]
    for i in range(1, count):
        ret = [ret, "{:d}".format(i)]
    return ret


def test_parse_nested_list(count, parse_func):
    nested_list_str = str(generate_nested_list(count))
    try:
        parsed = parse_func(nested_list_str)
    except:
        traceback.print_exc(limit=0)
    else:
        return parsed


def json_loads_wrapper(nested_list_str):
    return json.loads(nested_list_str.replace("'", "\""))


def main():
    for func in (ast.literal_eval, eval, json_loads_wrapper):
        for i in (LIST_NESTING_LIMIT, LIST_NESTING_LIMIT + 1):
            print("\nTrying to parse a {:d} level nested list using '{:s}':".format(i, func.__name__))
            result = test_parse_nested_list(i, func)
            if result is not None:
                print(result)
    print("\nOriginal list:")
    s = "[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['Xenophrys_bairdii'],'Vulpanser_spaldingi'],'Vipera_yeltoniensis'],'Vipera_minutus'],'Vanellus_vegans'],'Vanellus_bedriagai'],'Ursus_gratiosa'],'Uroplatus_flavomaculatus'],'Trionyx_leporosum'],'Tringa_aspera'],'Trachemys_sirtalis'],'Terpsihone_varius'],'Spermophilus_hassanica'],'Siniperca_decor'],'Scolopendra_marcianus'],'Rufibrenta_montela'],'Riparia_clinatus'],'Rhinolophus_tuberculosus'],'Rhacodactylus_citrsola'],'Remiz_niloticus'],'Pterinochilus_physalus'],'Procellaria_truncatus'],'Procellaria_lutris'],'Poephagus_indica'],'Platemys_albopillosum'],'Pica_totanus'],'Pica_mexicana'],'Phrynomerus_pelagicus'],'Philothamnus_tuberculosus'],'Petrocincla_acuta'],'Pelomedusa_rusticolus'],'Pagophila_metallica'],'Pachytriton_sibiricus'],'Otis_moschata'],'Otis_franckii'],'Otis_emarginatus'],'Opheodrys_clarus'],'Mylopharyngodon_diffidens'],'Mergus_carinata'],'Meles_carbonaria'],'Mabuya_carnivorus'],'Lystrophis_siebenrocki'],'Lyrurus_tinctorius'],'Lycodon_dendrophila'],'Lutra_plathyrhychos'],'Leptopelis_plumipes'],'Leptopelis_licin'],'Leiurus_grossmani'],'Lasiodora_hipposideros'],'Larus_pulchripes'],'Kinosternon_guineti'],'Kassina_canorus'],'Hysterocrates_chukar'],'Hydrochelidon_euptilura'],'Hemitheconyx_pulchripes'],'Haplopelma_arcticus'],'Hadrurus_dominus'],'Gypaetus_schneideri'],'Glareola_leucophyllata'],'Gerrhosaurus_ruficollis'],'Geochelone_filipjevi'],'Gallinago_pallasii'],'Eutamias_multifasciata'],'Eulabeia_tinnunculus'],'Eudrornias_penelope'],'Eudramias_tadorna'],'Eschrichtius_pulchra'],'Eremophila_similis'],'Equus_fluviatilis'],'Epicrates_carinatus'],'Emydura_avosetta'],'Emberiza_japonica'],'Dyscophus_rubicola'],'Dendrelaphis_griseus'],'Cypselus_ceterus'],'Cynops_rutila'],'Cygnus_rubicola'],'Ctenosaura_sphenocercus'],'Coenobita_variabilis'],'Clemmys_caudata'],'Cervus_comicus'],'Castor_prominanus'],'Casarca_holbrooki'],'Capella_aestivus'],'Buthus_nebularia'],'Bronchocela_bicoloratum'],'Branta_ferrumequinum'],'Balaenoptera_piscator'],'Athene_musculus'],'Argynnis_versicolor'],'Arenaria_javanica'],'Anthropoides_aestivus'],'Anolis_medirostris'],'Anodonta_infrafrenata'],'Ambystoma_alcinous'],'Acanthoceros_euptilura']"
    print(json_loads_wrapper(s))


if __name__ == "__main__":
    print("Python {:s} on {:s}\n".format(sys.version, sys.platform))
    main()
</code></pre>
<p><strong>Output</strong>:</p>
<blockquote>
<pre><code>(py35x64_test) e:\Work\Dev\StackOverflow\q050709371&gt;"e:\Work\Dev\VEnvs\py35x64_test\Scripts\python.exe" code.py
Python 3.5.4 (v3.5.4:3f56838, Aug  8 2017, 02:17:05) [MSC v.1900 64 bit (AMD64)] on win32


Trying to parse a 92 level nested list using 'literal_eval': 
[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['0'], '1'], '2'], '3'], '4'], '5'], '6'], '7'], '8'], '9'], '10'], '11'], '12'], '13'], '14'], '15'], '16'], '17'], '18'], '19'], '20'], '21'], '22'], '23'], '24'], '25'], '26'], '27'], '28'], '29'], '30'], '31'], '32'], '33'], '34'], '35'], '36'], '37'], '38'], '39'], '40'], '41'], '42'], '43'], '44'], '45'], '46'], '47'], '48'], '49'], '50'], '51'], '52'], '53'], '54'], '55'], '56'], '57'], '58'], '59'], '60'], '61'], '62'], '63'], '64'], '65'], '66'], '67'], '68'], '69'], '70'], '71'], '72'], '73'], '74'], '75'], '76'], '77'], '78'], '79'], '80'], '81'], '82'], '83'], '84'], '85'], '86'], '87'], '88'], '89'], '90'], '91']

Trying to parse a 93 level nested list using 'literal_eval':
s_push: parser stack overflow
Traceback (most recent call last):
MemoryError

Trying to parse a 92 level nested list using 'eval':
[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['0'], '1'], '2'], '3'], '4'], '5'], '6'], '7'], '8'], '9'], '10'], '11'], '12'], '13'], '14'], '15'], '16'], '17'], '18'], '19'], '20'], '21'], '22'], '23'], '24'], '25'], '26'], '27'], '28'], '29'], '30'], '31'], '32'], '33'], '34'], '35'], '36'], '37'], '38'], '39'], '40'], '41'], '42'], '43'], '44'], '45'], '46'], '47'], '48'], '49'], '50'], '51'], '52'], '53'], '54'], '55'], '56'], '57'], '58'], '59'], '60'], '61'], '62'], '63'], '64'], '65'], '66'], '67'], '68'], '69'], '70'], '71'], '72'], '73'], '74'], '75'], '76'], '77'], '78'], '79'], '80'], '81'], '82'], '83'], '84'], '85'], '86'], '87'], '88'], '89'], '90'], '91']

Trying to parse a 93 level nested list using 'eval':
s_push: parser stack overflow
Traceback (most recent call last):
MemoryError

Trying to parse a 92 level nested list using 'json_loads_wrapper':
[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['0'], '1'], '2'], '3'], '4'], '5'], '6'], '7'], '8'], '9'], '10'], '11'], '12'], '13'], '14'], '15'], '16'], '17'], '18'], '19'], '20'], '21'], '22'], '23'], '24'], '25'], '26'], '27'], '28'], '29'], '30'], '31'], '32'], '33'], '34'], '35'], '36'], '37'], '38'], '39'], '40'], '41'], '42'], '43'], '44'], '45'], '46'], '47'], '48'], '49'], '50'], '51'], '52'], '53'], '54'], '55'], '56'], '57'], '58'], '59'], '60'], '61'], '62'], '63'], '64'], '65'], '66'], '67'], '68'], '69'], '70'], '71'], '72'], '73'], '74'], '75'], '76'], '77'], '78'], '79'], '80'], '81'], '82'], '83'], '84'], '85'], '86'], '87'], '88'], '89'], '90'], '91']

Trying to parse a 93 level nested list using 'json_loads_wrapper':
[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['0'], '1'], '2'], '3'], '4'], '5'], '6'], '7'], '8'], '9'], '10'], '11'], '12'], '13'], '14'], '15'], '16'], '17'], '18'], '19'], '20'], '21'], '22'], '23'], '24'], '25'], '26'], '27'], '28'], '29'], '30'], '31'], '32'], '33'], '34'], '35'], '36'], '37'], '38'], '39'], '40'], '41'], '42'], '43'], '44'], '45'], '46'], '47'], '48'], '49'], '50'], '51'], '52'], '53'], '54'], '55'], '56'], '57'], '58'], '59'], '60'], '61'], '62'], '63'], '64'], '65'], '66'], '67'], '68'], '69'], '70'], '71'], '72'], '73'], '74'], '75'], '76'], '77'], '78'], '79'], '80'], '81'], '82'], '83'], '84'], '85'], '86'], '87'], '88'], '89'], '90'], '91'], '92']

Original list:
[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[[['Xenophrys_bairdii'], 'Vulpanser_spaldingi'], 'Vipera_yeltoniensis'], 'Vipera_minutus'], 'Vanellus_vegans'], 'Vanellus_bedriagai'], 'Ursus_gratiosa'], 'Uroplatus_flavomaculatus'], 'Trionyx_leporosum'], 'Tringa_aspera'], 'Trachemys_sirtalis'], 'Terpsihone_varius'], 'Spermophilus_hassanica'], 'Siniperca_decor'], 'Scolopendra_marcianus'], 'Rufibrenta_montela'], 'Riparia_clinatus'], 'Rhinolophus_tuberculosus'], 'Rhacodactylus_citrsola'], 'Remiz_niloticus'], 'Pterinochilus_physalus'], 'Procellaria_truncatus'], 'Procellaria_lutris'], 'Poephagus_indica'], 'Platemys_albopillosum'], 'Pica_totanus'], 'Pica_mexicana'], 'Phrynomerus_pelagicus'], 'Philothamnus_tuberculosus'], 'Petrocincla_acuta'], 'Pelomedusa_rusticolus'], 'Pagophila_metallica'], 'Pachytriton_sibiricus'], 'Otis_moschata'], 'Otis_franckii'], 'Otis_emarginatus'], 'Opheodrys_clarus'], 'Mylopharyngodon_diffidens'], 'Mergus_carinata'], 'Meles_carbonaria'], 'Mabuya_carnivorus'], 'Lystrophis_siebenrocki'], 'Lyrurus_tinctorius'], 'Lycodon_dendrophila'], 'Lutra_plathyrhychos'], 'Leptopelis_plumipes'], 'Leptopelis_licin'], 'Leiurus_grossmani'], 'Lasiodora_hipposideros'], 'Larus_pulchripes'], 'Kinosternon_guineti'], 'Kassina_canorus'], 'Hysterocrates_chukar'], 'Hydrochelidon_euptilura'], 'Hemitheconyx_pulchripes'], 'Haplopelma_arcticus'], 'Hadrurus_dominus'], 'Gypaetus_schneideri'], 'Glareola_leucophyllata'], 'Gerrhosaurus_ruficollis'], 'Geochelone_filipjevi'], 'Gallinago_pallasii'], 'Eutamias_multifasciata'], 'Eulabeia_tinnunculus'], 'Eudrornias_penelope'], 'Eudramias_tadorna'], 'Eschrichtius_pulchra'], 'Eremophila_similis'], 'Equus_fluviatilis'], 'Epicrates_carinatus'], 'Emydura_avosetta'], 'Emberiza_japonica'], 'Dyscophus_rubicola'], 'Dendrelaphis_griseus'], 'Cypselus_ceterus'], 'Cynops_rutila'], 'Cygnus_rubicola'], 'Ctenosaura_sphenocercus'], 'Coenobita_variabilis'], 'Clemmys_caudata'], 'Cervus_comicus'], 'Castor_prominanus'], 'Casarca_holbrooki'], 'Capella_aestivus'], 'Buthus_nebularia'], 'Bronchocela_bicoloratum'], 'Branta_ferrumequinum'], 'Balaenoptera_piscator'], 'Athene_musculus'], 'Argynnis_versicolor'], 'Arenaria_javanica'], 'Anthropoides_aestivus'], 'Anolis_medirostris'], 'Anodonta_infrafrenata'], 'Ambystoma_alcinous'], 'Acanthoceros_euptilura']
</code></pre>
</blockquote>
</div>
<span class="comment-copy">You broke the parser. Parse it manually.</span>
<span class="comment-copy">The parser is probably implemented recursively and you're blowing the stack.</span>
