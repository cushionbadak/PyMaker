<div class="post-text" itemprop="text">
<p>I am performing the following operations on lists of words. I read lines in from a Project Gutenberg text file, split each line on spaces, perform general punctuation substitution, and then print each word and punctuation tag on its own line for further processing later. I am unsure how to replace every single quote with a tag  or  excepting all apostrophes. My current method is to use a compiled regex:</p>
<pre><code>apo = re.compile("[A-Za-z]'[A-Za-z]")
</code></pre>
<p>and perform the following operation:</p>
<pre><code>if "'" in word and !apo.search(word):
    word = word.replace("'","\n&lt;singlequote&gt;")
</code></pre>
<p>but this  ignores cases where a single quote is used around a word with an apostrophe. It also does not indicate to me whether the single quote is abutting the start of a word of the end of a word.</p>
<p>Example input:</p>
<pre><code>don't
'George
ma'am
end.'
didn't.'
'Won't
</code></pre>
<p>Example output (after processing and printing to file):</p>
<pre><code>don't
&lt;opensingle&gt;
George
ma'am
end
&lt;period&gt;
&lt;closesingle&gt;
didn't
&lt;period&gt;
&lt;closesingle&gt;
&lt;opensingle&gt;
Won't
</code></pre>
<p>I do have a further question in relation to this task: since the distinguishment of <code>&lt;opensingle&gt;</code> vs <code>&lt;closesingle&gt;</code> seems rather difficult, would it be wiser to perform substitutions like </p>
<pre><code>word = word.replace('.','\n&lt;period&gt;')
word = word.replace(',','\n&lt;comma&gt;')
</code></pre>
<p><em>after</em> performing the   replacement operation?</p>
</div>
<div class="post-text" itemprop="text">
<p>What you really need to properly replace starting and ending <code>'</code>
is <strong>regex</strong>.
To match them you should use:</p>
<ul>
<li><code>^'</code> for starting <code>'</code> (<em>opensingle</em>),</li>
<li><code>'$</code> for ending <code>'</code> (<em>closesingle</em>).</li>
</ul>
<p>Unfortunately, <code>replace</code> method does not support regexes,
so you should use <code>re.sub</code> instead.</p>
<p>Below you have an example program, printing your desired output
(in <em>Python 3</em>):</p>
<pre><code>import re
str = "don't 'George ma'am end.' didn't.' 'Won't"
words = str.split(" ")
for word in words:
    word = re.sub(r"^'", '&lt;opensingle&gt;\n', word)
    word = re.sub(r"'$", '\n&lt;closesingle&gt;', word)
    word = word.replace('.', '\n&lt;period&gt;')
    word = word.replace(',', '\n&lt;comma&gt;')
    print(word)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I suggest working smart here: use <a href="http://www.nltk.org" rel="nofollow noreferrer">nltk</a>'s or another NLP toolkit instead.</p>
<p><a href="https://www.nltk.org/book/ch03.html" rel="nofollow noreferrer">Tokenize words</a> like this:</p>
<pre><code>import nltk
sentence = """At eight o'clock on Thursday morning
Arthur didn't feel very good."""
tokens = nltk.word_tokenize(sentence)
</code></pre>
<p>You may not like the fact that contractions like don't are separated. Actually, this is expected behavior. See <a href="https://github.com/nltk/nltk/issues/401" rel="nofollow noreferrer">Issue 401</a>. </p>
<p>However, TweetTokenizer can help with that:</p>
<pre><code>from nltk.tokenize import tknzr = TweetTokenizer()
tknzr.tokenize("The code didn't work!")
</code></pre>
<p>If it gets more involved a RegexpTokenizer could be helpful:</p>
<pre><code>from nltk.tokenize import RegexpTokenizer
s = "Good muffins cost $3.88\nin New York.  Please don't buy me\njust one of them."
tokenizer = RegexpTokenizer('\w+|\$[\d\.]+|\S+')
tokenizer.tokenize(s)
</code></pre>
<p>Then it should be much easier to annotate the tokenized words correctly.</p>
<p>Further references:</p>
<ul>
<li><a href="http://www.nltk.org/api/nltk.tokenize.html" rel="nofollow noreferrer">http://www.nltk.org/api/nltk.tokenize.html</a></li>
<li><a href="http://www.nltk.org/_modules/nltk/tokenize/regexp.html" rel="nofollow noreferrer">http://www.nltk.org/_modules/nltk/tokenize/regexp.html</a></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>I think this can benefit from lookahead or lookbehind references. The python reference is <a href="https://docs.python.org/3/library/re.html" rel="nofollow noreferrer">https://docs.python.org/3/library/re.html</a>, and one generic regex site I often reference is <a href="https://www.regular-expressions.info/lookaround.html" rel="nofollow noreferrer">https://www.regular-expressions.info/lookaround.html</a>.</p>
<p>Your data:</p>
<pre><code>words = ["don't",
         "'George",
         "ma'am",
         "end.'",
         "didn't.'",
         "'Won't",]
</code></pre>
<p>And now I'll define a tuple with regular expressions and their replacements.</p>
<pre><code>In [230]: apo = (
    (re.compile("(?&lt;=[A-Za-z])'(?=[A-Za-z])"), "&lt;apostrophe&gt;",),
    (re.compile("(?&lt;![A-Za-z])'(?=[A-Za-z])"), "&lt;opensingle&gt;",),
    (re.compile("(?&lt;=[.A-Za-z])'(?![A-Za-z])"), "&lt;closesingle&gt;", ),
    (re.compile("(?&lt;=[A-Za-z])\\.(?![A-Za-z])"), "&lt;period&gt;",),
)
     ...:      ...:      ...:      ...:      ...:      ...: 
In [231]: words = ["don't",
         "'George",
         "ma'am",
         "end.'",
         "didn't.'",
         "'Won't",]
     ...:      ...:      ...:      ...:      ...:      ...: 
In [232]: reduce(lambda w2,x: [ x[0].sub(x[1], w) for w in w2], apo, words)
Out[232]: 
['don&lt;apostrophe&gt;t',
 '&lt;opensingle&gt;George',
 'ma&lt;apostrophe&gt;am',
 'end&lt;period&gt;&lt;closesingle&gt;',
 'didn&lt;apostrophe&gt;t&lt;period&gt;&lt;closesingle&gt;',
 '&lt;opensingle&gt;Won&lt;apostrophe&gt;t']
</code></pre>
<p>Here's what's going on with the regexes:</p>
<ol>
<li><code>(?&lt;=[A-Za-z])</code> is a <em>lookbehind</em>, meaning only match (but <em>do not consume</em>) if the preceding character is a letter.</li>
<li><code>(?=[A-Za-z])</code> is a <em>lookahead</em> (still no consume) if the following character is a letter.</li>
<li><code>(?&lt;![A-Za-z])</code> is a <em>negative lookbehind</em>, meaning if there is a letter preceding it, then it will not match.</li>
<li><code>(?![A-Za-z])</code> is a <em>negative lookahead</em>.</li>
</ol>
<p>Note that I added a <code>.</code> check within <code>&lt;closesingle&gt;</code>, and the order within <code>apo</code> matters, because you might be replacing <code>.</code> with <code>&lt;period&gt;</code> ...</p>
<p>This was operating on single words, but should work with sentences as well.</p>
<pre><code>In [233]: onelong = """
don't
'George
ma'am
end.'
didn't.'
'Won't
"""
     ...:      ...:      ...:      ...:      ...:      ...:      ...: 
In [235]: print(
    reduce(lambda sentence,x: x[0].sub(x[1], sentence), apo, onelong)
)

     ...:      ...: 
don&lt;apostrophe&gt;t
&lt;opensingle&gt;George
ma&lt;apostrophe&gt;am
end&lt;period&gt;&lt;closesingle&gt;
didn&lt;apostrophe&gt;t&lt;period&gt;&lt;closesingle&gt;
&lt;opensingle&gt;Won&lt;apostrophe&gt;t
</code></pre>
<p>(The use of <code>reduce</code> is to facilitate applying a regex's <code>.sub</code> on the words/strings and then keep that output for the next regex's <code>.sub</code>, etc.)</p>
</div>
<span class="comment-copy">How do you define a word?</span>
<span class="comment-copy">It's simply a string in an array resulting from words = line.split(). I just split a line on spaces and use \n characters to strip punctuation into tags on new lines when I print out to a file. But I do not want to strip apostrophes because I consider contractions to be suitably-definable "words", in the literal sense.</span>
<span class="comment-copy">The other case (I forgot to mention) is hyphens: I do not want to break up hyphenated words.</span>
<span class="comment-copy">I appreciate the introduction of a new tool (that I guarantee I will be using, even for this task when I begin performing this tokenizing on more complicated books than Joseph Conrad's Heart of Darkness), but for the present circumstances I feel that NLP is overkill. Of course, I was trying to preform this task using sed and gave up, moving to Python, so perhaps I'll end up on NLP soon.</span>
<span class="comment-copy">@malan you are welcomed. And sure you will; arguably, if you process literature without an NLP toolkit you are doing it wrong.</span>
<span class="comment-copy">I am interested in deploying this toolkit now: can it recognize the difference between open quotes and eliding single quotes (e.g. as that in "Let's get <b>'em</b>")?</span>
