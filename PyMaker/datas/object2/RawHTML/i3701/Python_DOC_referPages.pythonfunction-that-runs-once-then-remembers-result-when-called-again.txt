<div class="post-text" itemprop="text">
<p>I just started Python and I've got no idea what <a href="http://en.wikipedia.org/wiki/Memoization" rel="noreferrer">memoization</a> is and how to use it. Also, may I have a simplified example?</p>
</div>
<div class="post-text" itemprop="text">
<p>Memoization effectively refers to remembering ("memoization" → "memorandum" → to be remembered) results of method calls based on the method inputs and then returning the remembered result rather than computing the result again. You can think of it as a cache for method results. For further details, see page 387 for the definition in <strong><em>Introduction To Algorithms</em></strong> (3e), Cormen et al.</p>
<p>A simple example for computing factorials using memoization in Python would be something like this:</p>
<pre><code>factorial_memo = {}
def factorial(k):
    if k &lt; 2: return 1
    if k not in factorial_memo:
        factorial_memo[k] = k * factorial(k-1)
    return factorial_memo[k]
</code></pre>
<p>You can get more complicated and encapsulate the memoization process into a class:</p>
<pre><code>class Memoize:
    def __init__(self, f):
        self.f = f
        self.memo = {}
    def __call__(self, *args):
        if not args in self.memo:
            self.memo[args] = self.f(*args)
        #Warning: You may wish to do a deepcopy here if returning objects
        return self.memo[args]
</code></pre>
<p>Then:</p>
<pre><code>def factorial(k):
    if k &lt; 2: return 1
    return k * factorial(k - 1)

factorial = Memoize(factorial)
</code></pre>
<p>A feature known as "<a href="https://www.python.org/dev/peps/pep-0318/" rel="noreferrer">decorators</a>" was added in Python 2.4 which allow you to now simply write the following to accomplish the same thing:</p>
<pre><code>@Memoize
def factorial(k):
    if k &lt; 2: return 1
    return k * factorial(k - 1)
</code></pre>
<p>The <a href="https://wiki.python.org/moin/PythonDecoratorLibrary" rel="noreferrer">Python Decorator Library</a> has a similar decorator called <a href="https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize" rel="noreferrer"><code>memoized</code></a> that is slightly more robust than the <code>Memoize</code> class shown here.</p>
</div>
<div class="post-text" itemprop="text">
<p>New to Python 3.2 is <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="noreferrer"><code>functools.lru_cache</code></a>. By default, it only caches the 128 most recently used calls, but you can set the <code>maxsize</code> to <code>None</code> to indicate that the cache should never expire:</p>
<pre class="lang-python prettyprint-override"><code>import functools

@functools.lru_cache(maxsize=None)
def fib(num):
    if num &lt; 2:
        return num
    else:
        return fib(num-1) + fib(num-2)
</code></pre>
<p>This function by itself is very slow, try <code>fib(36)</code> and you will have to wait about ten seconds. </p>
<p>Adding <code>lru_cache</code> annotation ensures that if the function has been called recently for a particular value, it will not recompute that value, but use a cached previous result. In this case, it leads to a tremendous speed improvement, while the code is not cluttered with the details of caching.</p>
</div>
<div class="post-text" itemprop="text">
<p>The other answers cover what it is quite well. I'm not repeating that. Just some points that might be useful to you. </p>
<p>Usually, memoisation is an operation you can apply on any function that computes something (expensive) and returns a value. Because of this, it's often implemented as a <a href="http://www.python.org/dev/peps/pep-0318/" rel="noreferrer">decorator</a>. The implementation is straightforward and it would be something like this</p>
<pre><code>memoised_function = memoise(actual_function)
</code></pre>
<p>or expressed as a decorator</p>
<pre><code>@memoise
def actual_function(arg1, arg2):
   #body
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Memoization is keeping the results of expensive calculations and returning the cached result rather than continuously recalculating it. </p>
<p>Here's an example:</p>
<pre><code>def doSomeExpensiveCalculation(self, input):
    if input not in self.cache:
        &lt;do expensive calculation&gt;
        self.cache[input] = result
    return self.cache[input]
</code></pre>
<p>A more complete description can be found in the <a href="http://en.wikipedia.org/wiki/Memoization" rel="noreferrer">wikipedia entry on memoization</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Let's not forget the built-in <code>hasattr</code> function, for those who want to hand-craft. That way you can keep the mem cache inside the function definition (as opposed to a global).</p>
<pre><code>def fact(n):
    if not hasattr(fact, 'mem'):
        fact.mem = {1: 1}
    if not n in fact.mem:
        fact.mem[n] = n * fact(n - 1)
    return fact.mem[n]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I've found this extremely useful</p>
<pre><code>def memoize(function):
    from functools import wraps

    memo = {}

    @wraps(function)
    def wrapper(*args):
        if args in memo:
            return memo[args]
        else:
            rv = function(*args)
            memo[args] = rv
            return rv
    return wrapper


@memoize
def fibonacci(n):
    if n &lt; 2: return n
    return fibonacci(n - 1) + fibonacci(n - 2)

fibonacci(25)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Memoization is basically saving the results of past operations done with recursive algorithms in order to reduce the need to traverse the recursion tree if the same calculation is required at a later stage.</p>
<p>see <a href="http://scriptbucket.wordpress.com/2012/12/11/introduction-to-memoization/" rel="nofollow">http://scriptbucket.wordpress.com/2012/12/11/introduction-to-memoization/</a></p>
<p>Fibonacci Memoization example in Python:</p>
<pre><code>fibcache = {}
def fib(num):
    if num in fibcache:
        return fibcache[num]
    else:
        fibcache[num] = num if num &lt; 2 else fib(num-1) + fib(num-2)
        return fibcache[num]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Memoization is the conversion of functions into data structures. Usually one wants the conversion to occur incrementally and lazily (on demand of a given domain element--or "key"). In lazy functional languages, this lazy conversion can happen automatically, and thus memoization can be implemented without (explicit) side-effects.</p>
</div>
<div class="post-text" itemprop="text">
<p>Well I should answer the first part first: what's memoization?</p>
<p>It's just a method to trade memory for time. Think of <a href="http://en.wikipedia.org/wiki/Multiplication_table" rel="nofollow">Multiplication Table</a>.</p>
<p>Using mutable object as default value in Python is usually considered bad. But if use it wisely, it can actually be useful to implement a <code>memoization</code>.</p>
<p>Here's an example adapted from <a href="http://docs.python.org/2/faq/design.html#why-are-default-values-shared-between-objects" rel="nofollow">http://docs.python.org/2/faq/design.html#why-are-default-values-shared-between-objects</a></p>
<p>Using a mutable <code>dict</code> in the function definition, the intermediate computed results can be cached (e.g. when calculating <code>factorial(10)</code> after calculate <code>factorial(9)</code>, we can reuse all the intermediate results)</p>
<pre><code>def factorial(n, _cache={1:1}):    
    try:            
        return _cache[n]           
    except IndexError:
        _cache[n] = factorial(n-1)*n
        return _cache[n]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is a solution that will work with list or dict type arguments without whining:</p>
<pre><code>def memoize(fn):
    """returns a memoized version of any function that can be called
    with the same list of arguments.
    Usage: foo = memoize(foo)"""

    def handle_item(x):
        if isinstance(x, dict):
            return make_tuple(sorted(x.items()))
        elif hasattr(x, '__iter__'):
            return make_tuple(x)
        else:
            return x

    def make_tuple(L):
        return tuple(handle_item(x) for x in L)

    def foo(*args, **kwargs):
        items_cache = make_tuple(sorted(kwargs.items()))
        args_cache = make_tuple(args)
        if (args_cache, items_cache) not in foo.past_calls:
            foo.past_calls[(args_cache, items_cache)] = fn(*args,**kwargs)
        return foo.past_calls[(args_cache, items_cache)]
    foo.past_calls = {}
    foo.__name__ = 'memoized_' + fn.__name__
    return foo
</code></pre>
<p>Note that this approach can be naturally extended to any object by implementing your own hash function as a special case in handle_item. For example, to make this approach work for a function that takes a set as an input argument, you could add to handle_item:</p>
<pre><code>if is_instance(x, set):
    return make_tuple(sorted(list(x)))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Solution that works with both positional and keyword arguments independently of order in which keyword args were passed (using <a href="http://docs.python.org/2/library/inspect.html#inspect.getargspec" rel="nofollow noreferrer">inspect.getargspec</a>):</p>
<pre><code>import inspect
import functools

def memoize(fn):
    cache = fn.cache = {}
    @functools.wraps(fn)
    def memoizer(*args, **kwargs):
        kwargs.update(dict(zip(inspect.getargspec(fn).args, args)))
        key = tuple(kwargs.get(k, None) for k in inspect.getargspec(fn).args)
        if key not in cache:
            cache[key] = fn(**kwargs)
        return cache[key]
    return memoizer
</code></pre>
<p>Similar question: <a href="https://stackoverflow.com/questions/14621838/identifying-equivalent-varargs-function-calls-for-memoization-in-python">Identifying equivalent varargs function calls for memoization in Python</a></p>
</div>
<div class="post-text" itemprop="text">
<pre><code>cache = {}
def fib(n):
    if n &lt;= 1:
        return n
    else:
        if n not in cache:
            cache[n] = fib(n-1) + fib(n-2)
        return cache[n]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just wanted to add to the answers already provided, the <a href="https://wiki.python.org/moin/PythonDecoratorLibrary#Memoize" rel="nofollow">Python decorator library</a> has some simple yet useful implementations that can also memoize "unhashable types", unlike <code>functools.lru_cache</code>.</p>
</div>
<span class="comment-copy">When the second sentence of the relevant wikipedia article contains the phrase "mutually-recursive descent parsing[1] in a general top-down parsing algorithm[2][3] that accommodates ambiguity and left recursion in polynomial time and space," I think it is entirely appropriate to ask SO what is going on.</span>
<span class="comment-copy">@Clueless: That phrase is preceded by "Memoization has also been used in other contexts (and for purposes other than speed gains), such as in". So it's just a list of examples (and need not be understood); it's not part of the explanation of memoization.</span>
<span class="comment-copy">Here is a good explanation with attached examples of memoization and how to incorporate it into a decorator: <a href="http://www.pycogsci.info/?p=221" rel="nofollow noreferrer">pycogsci.info/?p=221</a></span>
<span class="comment-copy">@StefanGruenwald That link is dead.  Can you please find an update?</span>
<span class="comment-copy">New link to pdf file, since pycogsci.info is down: <a href="http://people.ucsc.edu/~abrsvn/NLTK_parsing_demos.pdf" rel="nofollow noreferrer">people.ucsc.edu/~abrsvn/NLTK_parsing_demos.pdf</a></span>
<span class="comment-copy">Thanks for this suggestion. The Memoize class is an elegant solution which can easily be applied to existing code without needing much refactoring.</span>
<span class="comment-copy">The Memoize class solution is buggy, it will not work the same as the <code>factorial_memo</code>, because the <code>factorial</code> inside <code>def factorial</code> still calls the old unmemoize <code>factorial</code>.</span>
<span class="comment-copy">By the way, you can also write <code>if k not in factorial_memo:</code>, which reads better than <code>if not k in factorial_memo:</code>.</span>
<span class="comment-copy">Should really do this as a decorator.</span>
<span class="comment-copy">@durden2.0 I know this is an old comment, but <code>args</code> is a tuple. <code>def some_function(*args)</code> makes args a tuple.</span>
<span class="comment-copy">Tried fib(1000), got RecursionError: maximum recursion depth exceeded in comparison</span>
<span class="comment-copy">@Andyk Default Py3 recursion limit is 1000. The first time <code>fib</code> is called, it will need to recur down to the base case before memoization can happen. So, your behavior is just about expected.</span>
<span class="comment-copy">If I'm not mistaken, it caches only until the process is not killed, right? Or does it cache regardless of whether the process is killed? Like, say I restart my system - will the cached results still be cached?</span>
<span class="comment-copy">@Kristada673 Yes, it's stored in the process' memory, not on disk.</span>
<span class="comment-copy">Does this introduce significantly more latency than implementing an ad-hoc memoization routine?</span>
<span class="comment-copy">Hmm, now if that was correct Python, it would rock, but it appears not to be... okay, so "cache" is not a dict? Because if it is, it should be  <code>if input not in self.cache</code>  and  <code>self.cache[input]</code>  (<code>has_key</code> is obsolete since... early in the 2.x series, if not 2.0.  <code>self.cache(index)</code> was never correct.  IIRC)</span>
<span class="comment-copy">See <a href="https://docs.python.org/3/library/functools.html#functools.wraps" rel="nofollow noreferrer">docs.python.org/3/library/functools.html#functools.wraps</a> for why one should use <code>functools.wraps</code>.</span>
<span class="comment-copy">Do I need to manually clear the <code>memo</code> so that memory is freed?</span>
<span class="comment-copy">The whole idea is that the results are stored inside memo within a session. I.e. nothing are being cleared as it is</span>
<span class="comment-copy">For more performance pre-seed your fibcache with the first few known values, then you can take the extra logic for handling them out of the 'hot path' of the code.</span>
<span class="comment-copy">Nice attempt. Without whining, a <code>list</code> argument of <code>[1, 2, 3]</code> can mistakenly be considered the same as a different <code>set</code> argument with a value of <code>{1, 2, 3}</code>. In addition, sets are unordered like dictionaries, so they would also need to be <code>sorted()</code>. Also note that a recursive data structure argument would cause an infinite loop.</span>
<span class="comment-copy">Yea, sets should be handled by special casing handle_item(x) and sorting. I shouldn't have said that this implementation handles sets, because it doesn't - but the point is that it can be easily extended to do so by special casing handle_item, and the same will work for any class or iterable object as long as you're willing to write the hash function yourself. The tricky part - dealing with multi-dimensional lists or dictionaries - is already dealt with here, so I've found that this memoize function is a lot easier to work with as a base than the simple "I only take hashable arguments" types.</span>
<span class="comment-copy">The problem I mentioned is due to the fact that <code>list</code>s and <code>set</code>s are "tupleized" into the same thing and therefore become indistinguishable from one another. The example code for adding support for <code>sets</code> described in your latest update doesn't avoid that I'm afraid. This can easily be seen by separately passing <code>[1,2,3]</code> and <code>{1,2,3}</code> as an argument to a "memoize"d test function and seeing whether it's called twice, as it should be, or not.</span>
<span class="comment-copy">yea, I read that problem, but I didn't address it because I think it is much more minor than the other one you mentioned. When was the last time you wrote a memoized function where a fixed argument could be either a list or a set, and the two resulted in different outputs? If you were to run into such a rare case, you would again just rewrite handle_item to prepend, say a 0 if the element is a set, or a 1 if it is a list.</span>
<span class="comment-copy">Actually, there's a similar issue with <code>list</code>s and <code>dict</code>s because it's <i>possible</i> for a <code>list</code> to have exactly the same thing in it that resulted from calling <code>make_tuple(sorted(x.items()))</code> for a dictionary. A simple solution for both cases would be to include the <code>type()</code> of value in the tuple generated. I can think of an even simpler way specifically to handle <code>set</code>s, but it doesn't generalize.</span>
<span class="comment-copy">you could use simply <code>if n not in cache</code> instead. using <code>cache.keys</code> would build an unnecessary list in python 2</span>
<span class="comment-copy">This decorator does not <i>memoize "unhashable types"</i>! It just falls back to calling the function without memoization, going against against the <i>explicit is better than implicit</i> dogma.</span>
