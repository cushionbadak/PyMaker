<div class="post-text" itemprop="text">
<p>Using BeautifulSoup to extract some text, and then I want to save the entries into a csv file. My code as follows:</p>
<pre><code>for trTag in trTags:
    tdTags = trTag.find("td", class_="result-value")
    tdTags_string = tdTags.get_text(strip=True)
    saveFile = open("some.csv", "a")
    saveFile.write(str(tdTags_string) + ",")
    saveFile.close()

saveFile = open("some.csv", "a")
saveFile.write("\n")
saveFile.close()
</code></pre>
<p>It did what I want for the most part EXCEPT whenever if there is a comma (",") within the entry, it sees it as a separator and split the single entry into two different cells (which is not what I want). So I searched around the net and found people suggested of using the csv module and I changed my codes into:</p>
<pre><code>for trTag in trTags:
    tdTags = trTag.find("td", class_="result-value")
    tdTags_string = tdTags.get_text(strip=True)
    print tdTags_string

    with open("some.csv", "a") as f:
        writeFile = csv.writer(f)
        writeFile.writerow(tdTags_string)

saveFile = open("some.csv", "a")
saveFile.write("\n")
saveFile.close()
</code></pre>
<p>This made it even worse, now each letter/number of a word or number occupies a single cell in the csv file. For example, if the entry is "Cat". The "C" is in one cell, "a" is the next cell, and "t" is the third cell, etc.</p>
<p>Edited version:</p>
<pre><code>import urllib2
import re
import csv
from bs4 import BeautifulSoup

SomeSiteURL = "https://SomeSite.org/xyz"
OpenSomeSiteURL = urllib2.urlopen(SomeSiteURL)
Soup_SomeSite = BeautifulSoup(OpenSomeSiteURL, "lxml")
OpenSomeSiteURL.close()

# finding name
NameParentTag = Soup_SomeSite.find("tr", class_="result-item highlight-person")
Name = NameParentTag.find("td", class_="result-value-bold").get_text(strip=True)
saveFile = open("SomeSite.csv", "a")
saveFile.write(str(Name) + ",")
saveFile.close()

# finding other info
# &lt;tbody&gt; -&gt; many &lt;tr&gt; -&gt; in each &lt;tr&gt;, extract second &lt;td&gt;
tbodyTags = Soup_SomeSite.find("tbody")
trTags = tbodyTags.find_all("tr", class_="result-item ")

for trTag in trTags:
    tdTags = trTag.find("td", class_="result-value")
    tdTags_string = tdTags.get_text(strip=True)

    with open("SomeSite.csv", "a") as f:
        writeFile = csv.writer(f)
        writeFile.writerow([tdTags_string])
</code></pre>
<p>2nd edition:</p>
<pre><code>placeHolder = []

for trTag in trTags:
    tdTags = trTag.find("td", class_="result-value")
    tdTags_string = tdTags.get_text(strip=True)
    placeHolder.append(tdTags_string)

with open("SomeSite.csv", "a") as f:
    writeFile = csv.writer(f)
    writeFile.writerow(placeHolder)
</code></pre>
<p>Updated output:</p>
<pre><code>u'stuff1'
u'stuff2'
u'stuff3'
</code></pre>
<p>Output example:</p>
<pre><code>u'record1'  u'31 Mar 1901'  u'California'

u'record1'  u'31 Mar 1901'  u'California'

record1     31-Mar-01       California
</code></pre>
<p>Another edited codes (still having one issue - skipping one line below):</p>
<pre><code>import urllib2
import re
import csv
from bs4 import BeautifulSoup

SomeSiteURL = "https://SomeSite.org/xyz"
OpenSomeSiteURL = urllib2.urlopen(SomeSiteURL)
Soup_SomeSite = BeautifulSoup(OpenSomeSiteURL, "lxml")
OpenSomeSiteURL.close()

# finding name
NameParentTag = Soup_SomeSite.find("tr", class_="result-item highlight-person")
Name = NameParentTag.find("td", class_="result-value-bold").get_text(strip=True)
saveFile = open("SomeSite.csv", "a")
saveFile.write(str(Name) + ",")
saveFile.close()

# finding other info
# &lt;tbody&gt; -&gt; many &lt;tr&gt; -&gt; in each &lt;tr&gt;, extract second &lt;td&gt;
tbodyTags = Soup_SomeSite.find("tbody")
trTags = tbodyTags.find_all("tr", class_="result-item ")

placeHolder = []

for trTag in trTags:
    tdTags = trTag.find("td", class_="result-value")
    tdTags_string = tdTags.get_text(strip=True)
    #print repr(tdTags_string)
    placeHolder.append(tdTags_string.rstrip('\n'))

with open("SomeSite.csv", "a") as f:
    writeFile = csv.writer(f)
    writeFile.writerow(placeHolder)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>with open("some.csv", "a") as f:
        writeFile = csv.writer(f)
        writeFile.writerow([tdTags_string]) # put in a list
</code></pre>
<p><code>writeFile.writerow</code> will iterate over what you pass in so a string <code>"foo"</code> becomes <code>f,o,o</code> three separate values,  wrapping it in a <code>list</code> will prevent this as writer will iterate over the list not the string</p>
<p>You should open your file once as opposed to every time through your loop:</p>
<pre><code>with open("SomeSite.csv", "a") as f:
    writeFile = csv.writer(f)
    for trTag in trTags:
        tdTags = trTag.find("td", class_="result-value")
        tdTags_string = tdTags.get_text(strip=True) # 
        writeFile.writerow([tdTags_string])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>For the latest problem of skipping line, I have found an answer. Instead of</p>
<pre><code>with open("SomeSite.csv", "a") as f:
    writeFile = csv.writer(f)
    writeFile.writerow(placeHolder)
</code></pre>
<p>Use this:</p>
<pre><code>with open("SomeSite.csv", "ab") as f:
    writeFile = csv.writer(f)
    writeFile.writerow(placeHolder)
</code></pre>
<p>Source: <a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow">https://docs.python.org/3/library/functions.html#open</a>. The "a" mode is the appending mode, where as "ab" is an appending mode while opening the file as binary file which solves the problem of skipping one extra line.</p>
</div>
<span class="comment-copy">Thanks, it works (in terms of the comma and separate-cell issues), but somehow instead of putting different entries in a single row, it enters the subsequent entry at two rows below.</span>
<span class="comment-copy">just make sure you are not writing newline chars, this will put entries on different lines</span>
<span class="comment-copy">How do I make sure? I have posted my edited full codes here, I don't see where I might be asking for newline, and I thought the writerow function is supposed to be writing into a single line.</span>
<span class="comment-copy">are you wanting to add all <code>tdTags_string</code> through the loop? print <code>repr(tdTags_string)</code> in the loop, it will show exactly what chars you are writing</span>
<span class="comment-copy">you are also writing to a new row each time through the loop, not sure if you understand that or not.</span>
