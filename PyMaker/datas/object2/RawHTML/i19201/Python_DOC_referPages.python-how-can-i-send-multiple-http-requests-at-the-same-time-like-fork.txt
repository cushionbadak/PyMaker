<div class="post-text" itemprop="text">
<p>Let's say that i have a way to send <a href="http://docs.python-requests.org/en/latest/" rel="nofollow">http request</a> to a server. How it's possible to send two of these requests (or more) to the server at the same time? For example maybe by fork a process? How can i do it?
(also i'm using django)</p>
<pre><code>#This example is not tested...
import requests

def tester(request):
    server_url = 'http://localhost:9000/receive'

    payload = {
        'd_test2': '1234',
        'd_test2': 'demo',
        }
    json_payload = simplejson.dumps(payload)
    content_length = len(json_payload)

    headers = {'Content-Type': 'application/json', 'Content-Length': content_length}
    response = requests.post(server_url, data=json_payload, headers=headers, allow_redirects=True)

    if response.status_code == requests.codes.ok:
        print 'Headers: {}\nResponse: {}'.format(response.headers, response.text)
</code></pre>
<p>Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>I think you want to use threads here rather than forking off new processes. While threads are bad in some cases, that isn't true here. Also, I think you want to use <a href="http://docs.python.org/3/library/concurrent.futures.html" rel="noreferrer"><code>concurrent.futures</code></a> instead of using threads (or processes) directly.</p>
<p>For example, let's say you have 10 URLs, and you're currently doing them one in a row, like this:</p>
<pre><code>results = map(tester, urls)
</code></pre>
<p>But now, you want to send them 2 at a time. Just change it to this:</p>
<pre><code>with concurrent.futures.ThreadPoolExecutor(max_workers=2) as pool:
    results = pool.map(tester, urls)
</code></pre>
<p>If you want to try 4 at a time instead of 2, just change the <code>max_workers</code>. In fact, you should probably experiment with different values to see what works best for your program.</p>
<p>If you want to do something a little fancier, see the documentation—the main <a href="http://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="noreferrer">ThreadPoolExecutor Example</a> is almost exactly what you're looking for.</p>
<p>Unfortunately, in 2.7, this module doesn't come with the standard library, so you will have to install <a href="https://pypi.python.org/pypi/futures" rel="noreferrer">the backport</a> from PyPI. </p>
<p>If you have <a href="http://www.pip-installer.org/en/latest/" rel="noreferrer"><code>pip</code></a> installed, this should be as simple as:</p>
<pre><code>pip install futures
</code></pre>
<p>… or maybe <code>sudo pip install futures</code>, on Unix. </p>
<p>And if you don't have <code>pip</code>, go get it first (follow the link above).</p>
<hr/>
<p>The main reason you sometimes want to use processes instead of threads is that you've got heavy CPU-bound computation, and you want to take advantage of multiple CPU cores. In Python, threading can't effectively use up all your cores. So, if the Task Manager/Activity Monitor/whatever shows that your program is using up 100% CPU on one core, while the others are all at 0%, processes are the answer. With <code>futures</code>, all you have to do is change <code>ThreadPoolExecutor</code> to <code>ProcessPoolExecutor</code>.</p>
<hr/>
<p>Meanwhile, sometimes you need more than just "give me a magic pool of workers to run my tasks". Sometimes you want to run a handful of very long jobs instead of a bunch of little ones, or load-balance the jobs yourself, or pass data between jobs, or whatever. For that, you want to use <a href="http://docs.python.org/2/library/multiprocessing.html" rel="noreferrer"><code>multiprocessing</code></a> or <a href="http://docs.python.org/2/library/threading.html" rel="noreferrer"><code>threading</code></a> instead of <code>futures</code>. </p>
<p>Very rarely, even <em>that</em> is too high-level, and directly tell Python to create a new child process or thread. For that, you go all the way down to <a href="http://docs.python.org/2/library/os.html#os.fork" rel="noreferrer"><code>os.fork</code></a> (on Unix only) or <a href="http://docs.python.org/2/library/thread.html" rel="noreferrer"><code>thread</code></a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>I would use <code>gevent</code>, which can launch these all in so-called green-threads:</p>
<pre><code># This will make requests compatible
from gevent import monkey; monkey.patch_all()
import requests

# Make a pool of greenlets to make your requests
from gevent.pool import Pool
p = Pool(10)

urls = [..., ..., ...]
p.map(requests.get, urls)
</code></pre>
<p>Of course, this example submits <code>get</code>s, but pool is generalized to map inputs into any function, including, say, yours to make requests. These greenlets will run as nearly as simultaneously as using <code>fork</code> but are much faster and much lighter-weight.</p>
</div>
<span class="comment-copy">concurrent.futures looks cool</span>
<span class="comment-copy">Thanks your answer is very interesting but as long as i'am not so familiar with mutliprocessing/threads i need to ask you if you mentioning at your post 5 different things. Right? Unfortunately i'm using 2.7 so i'll have to use futures.</span>
<span class="comment-copy">@JorgeCode: I'm not sure exactly what you meant by "mentioning at your post 5 different things". But I'll try to edit the answer to make it clearer.</span>
<span class="comment-copy">I mean <code>os.fork</code>, <code>multiprocessing</code>, <code>threads</code>, <code>concurrent.futures</code> and <code>futures</code>.</span>
<span class="comment-copy">@JorgeCode: I see. You specifically asked about fork, so I assumed you knew what that meant. I've rewritten the answer to give you my suggested answer first, and then talk about alternatives later. That should be a lot easier to understand than the original version. Sorry for any confusion.</span>
<span class="comment-copy">If you really want to use <code>gevent</code> plus <code>requests</code>, you're probably better off using <a href="https://github.com/kennethreitz/grequests" rel="nofollow noreferrer"><code>grequests</code></a> than doing it yourself. But really, when you're only doing a handful of things concurrently (the OP asked about 2…), there's no advantage to using greenlets. And the disadvantage is that if you ever add any CPU-bound code, your whole system slams to a halt, and you have to start over and rewrite things in a different way.</span>
<span class="comment-copy">Fair point about <code>grequests</code>. I have to imagine that any CPU-bound code in the above example is on the server end, in which case I'm not sure how I see how using <code>gevent</code> is detrimental.</span>
<span class="comment-copy">It's not really detrimental, it just adds something extra to learn, and makes it harder to adapt with in the (unlikely, but not impossible) event that you need to add CPU-bound client code, and requires something outside the stdlib—all of which are pretty minor negatives, but why incur even a few minor negatives if there's no advantage?</span>
<span class="comment-copy">I relate most to your point about including things outside of the standard libraries. While in this case there's no reason for me to be, I am often prejudiced against python threads :-)</span>
<span class="comment-copy">Well, Python threads are almost as bad as greenlets for doing CPU-parallelism, and almost as bad as processes for doing thousands of concurrent I/O-bound tasks, so often they're the wrong choice. But sometimes they're the right choice, and avoiding them for no reason is silly. (I know, you called it "prejudiced", so you already understand this; I'm just explaining this for the benefit of other readers.)</span>
