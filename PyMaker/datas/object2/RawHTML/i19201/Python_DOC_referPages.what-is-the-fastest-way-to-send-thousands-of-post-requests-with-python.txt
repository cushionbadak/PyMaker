<div class="post-text" itemprop="text">
<p>I want to make thousands of POST requests in the fastest possible way.  How can I do this with Python?</p>
<p>So far I just have a for loop which calls the following function many times:</p>
<pre><code>def post(word):
    data = json.dumps({"word":word})
    url = "http://127.0.0.1:8000/updateword"
    req = urllib2.Request(url, data, {'Content-Type': 'application/octet-stream'})
    response=None
    try:
        f = urllib2.urlopen(req)
        response = f.read()
        f.close()
    except urllib2.HTTPError, error:
        k= open('error.html','w')
        k.write(error.read())
        k.close()
    return response
</code></pre>
<p>Is there a better way to do this?</p>
</div>
<div class="post-text" itemprop="text">
<p>The way you've written your code, it waits for the response to one request before sending the next. (On top of that, it may not reuse the HTTP connections, meaning you have to deal with the socket creation/shutdown overhead for each request. Then again, depending on what you're testing, there's a good chance that actually makes it a better test.)</p>
<p>The simplest way to make multiple requests at the same time is to use threads. And the easiest way to do that is with <a href="http://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"><code>concurrent.futures</code></a> (or <a href="https://pypi.python.org/pypi/futures" rel="nofollow"><code>futures</code> from PyPI</a>, if you're using 2.x or 3.1):</p>
<pre><code>with concurrent.futures.ThreadPoolExecutor(max_workers=10) as pool:
    results = pool.map(post, words)
    concurrent.futures.wait(results)
</code></pre>
<p>If you prefer, you can write your own threads and just give each thread 1/10th of <code>words</code> and have it loop over calling <code>post</code>:</p>
<pre><code>def posts(words):
    for word in words:
        post(word)

groupsize = len(words)/10
t = [threading.Thread(target=posts, args=[words[i*groupsize:(i+1)*groupsize]]
     for i in range(10)]
for thread in t:
    thread.start()
for thread in t:
    thread.join()
</code></pre>
<p>Either way, obviously I just pulled that number 10 out of thin air (because it's a little more than the max simultaneous connections most browsers or web service clients will allow you to create), but you'll want to do some performance testing to find the best value.</p>
<p>If it turns out that the best value is <em>huge</em>, like 500 or something, you may be running into the limits of what you can do with threading. In that case, you should consider using greenlets. The simplest way to do this is with <code>gevent</code>—and the simplest to do that is to rewrite your code to use <a href="https://github.com/kennethreitz/grequests" rel="nofollow"><code>grequests</code></a> instead of <code>urllib2</code>.</p>
<p>Meanwhile, if the actual reads are wasting time, and you don't actually need the responses, and they're reasonably big, and you're not trying to test the server's ability to send real responses, you may want to close the socket as soon as you know you're going to get the right data. You <em>can</em> do this with <code>urllib2</code> by writing your own handlers, but that sounds like a lot of work. I think it would actually be simpler, in this case, to just drop down to the level of sockets. First, record the request that gets sent for each POST, and the expected 200 line that you get back when things work. Then do something like this:</p>
<pre><code>with closing(socket.socket()) as c:
    c.connect(('127.0.0.1', 8000))
    c.send(REQUEST_STRING_FORMAT.format([word]))
    with c.makefile() as f:
        response = f.readline()
        if response != RESPONSE_200_STRING:
            response += f.read()
            with open('error.html','w') as k:
                k.write(response)
</code></pre>
</div>
<span class="comment-copy">Have you timed this? Is it too slow?</span>
<span class="comment-copy">Yeah Its been running for about an hour and its not even 5% done.  I was mainly wondering if it's possible to make multiple requests at the same time.</span>
<span class="comment-copy">Try googling "denial of service attack", and you should get plenty of ideas.</span>
<span class="comment-copy">@alexis: Notice he's hitting 127.0.0.1, so… there are easier ways to DoS the server, like just recursively forking off processes, or thrashing swap…</span>
<span class="comment-copy">@Alexis: <a href="http://www.velocityreviews.com/forums/t671623-ping-localhost-dos.html" rel="nofollow noreferrer">this thread</a> has some useful hints on DoSing yourself. Although now that I think of it, as usual, social engineering is easier than hacking here. You just need to convince yourself to turn off the power switch, right?</span>
