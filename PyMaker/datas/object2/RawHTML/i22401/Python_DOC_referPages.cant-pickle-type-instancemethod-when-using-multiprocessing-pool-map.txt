<div class="post-text" itemprop="text">
<p>I'm trying to use <code>multiprocessing</code>'s <code>Pool.map()</code> function to divide out work simultaneously. When I use the following code, it works fine:</p>
<pre><code>import multiprocessing

def f(x):
    return x*x

def go():
    pool = multiprocessing.Pool(processes=4)        
    print pool.map(f, range(10))


if __name__== '__main__' :
    go()
</code></pre>
<p>However, when I use it in a more object-oriented approach, it doesn't work. The error message it gives is:</p>
<pre class="lang-none prettyprint-override"><code>PicklingError: Can't pickle &lt;type 'instancemethod'&gt;: attribute lookup
__builtin__.instancemethod failed
</code></pre>
<p>This occurs when the following is my main program:</p>
<pre><code>import someClass

if __name__== '__main__' :
    sc = someClass.someClass()
    sc.go()
</code></pre>
<p>and the following is my <code>someClass</code> class:</p>
<pre><code>import multiprocessing

class someClass(object):
    def __init__(self):
        pass

    def f(self, x):
        return x*x

    def go(self):
        pool = multiprocessing.Pool(processes=4)       
        print pool.map(self.f, range(10))
</code></pre>
<p>Anyone know what the problem could be, or an easy way around it?</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem is that multiprocessing must pickle things to sling them among processes, and bound methods are not picklable.  The workaround (whether you consider it "easy" or not;-) is to add the infrastructure to your program to allow such methods to be pickled, registering it with the <a href="https://docs.python.org/3/library/copyreg.html?highlight=copyreg" rel="noreferrer">copy_reg</a> standard library method.</p>
<p>For example, Steven Bethard's contribution to <a href="http://bytes.com/topic/python/answers/552476-why-cant-you-pickle-instancemethods" rel="noreferrer">this thread</a> (towards the end of the thread) shows one perfectly workable approach to allow method pickling/unpickling via <code>copy_reg</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>All of these solutions are ugly because multiprocessing and pickling is broken and limited unless you jump outside the standard library.</p>
<p>If you use a fork of <code>multiprocessing</code> called <code>pathos.multiprocesssing</code>, you can directly use classes and class methods in multiprocessing's <code>map</code> functions.  This is because <code>dill</code> is used instead of <code>pickle</code> or <code>cPickle</code>, and <code>dill</code> can serialize almost anything in python.</p>
<p><code>pathos.multiprocessing</code> also provides an asynchronous map functionâ€¦ and it can <code>map</code> functions with multiple arguments (e.g. <code>map(math.pow, [1,2,3], [4,5,6])</code>)</p>
<p>See:
<a href="https://stackoverflow.com/questions/19984152/what-can-multiprocessing-and-dill-do-together">What can multiprocessing and dill do together?</a></p>
<p>and:
<a href="http://matthewrocklin.com/blog/work/2013/12/05/Parallelism-and-Serialization/" rel="noreferrer">http://matthewrocklin.com/blog/work/2013/12/05/Parallelism-and-Serialization/</a></p>
<pre><code>&gt;&gt;&gt; import pathos.pools as pp
&gt;&gt;&gt; p = pp.ProcessPool(4)
&gt;&gt;&gt; 
&gt;&gt;&gt; def add(x,y):
...   return x+y
... 
&gt;&gt;&gt; x = [0,1,2,3]
&gt;&gt;&gt; y = [4,5,6,7]
&gt;&gt;&gt; 
&gt;&gt;&gt; p.map(add, x, y)
[4, 6, 8, 10]
&gt;&gt;&gt; 
&gt;&gt;&gt; class Test(object):
...   def plus(self, x, y): 
...     return x+y
... 
&gt;&gt;&gt; t = Test()
&gt;&gt;&gt; 
&gt;&gt;&gt; p.map(Test.plus, [t]*4, x, y)
[4, 6, 8, 10]
&gt;&gt;&gt; 
&gt;&gt;&gt; p.map(t.plus, x, y)
[4, 6, 8, 10]
</code></pre>
<p>And just to be explicit, you can do exactly want you wanted to do in the first place, and you can do it from the interpreter, if you wanted to.</p>
<pre><code>&gt;&gt;&gt; import pathos.pools as pp
&gt;&gt;&gt; class someClass(object):
...   def __init__(self):
...     pass
...   def f(self, x):
...     return x*x
...   def go(self):
...     pool = pp.ProcessPool(4)
...     print pool.map(self.f, range(10))
... 
&gt;&gt;&gt; sc = someClass()
&gt;&gt;&gt; sc.go()
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
&gt;&gt;&gt; 
</code></pre>
<p>Get the code here:
 <a href="https://github.com/uqfoundation/pathos" rel="noreferrer">https://github.com/uqfoundation/pathos</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You could also define a <code>__call__()</code> method inside your <code>someClass()</code>, which calls <code>someClass.go()</code> and then pass an instance of <code>someClass()</code> to the pool. This object is pickleable and it works fine (for me)...</p>
</div>
<div class="post-text" itemprop="text">
<p>Some limitations though to Steven Bethard's solution :</p>
<p>When you register your class method as a function, the destructor of your class is surprisingly called every time your method processing is finished. So if you have 1 instance of your class that calls n times its method, members may disappear between 2 runs and you may get a message <code>malloc: *** error for object 0x...: pointer being freed was not allocated</code> (e.g. open member file) or <code>pure virtual method called,
terminate called without an active exception</code> (which means than the lifetime of a member object I used was shorter than what I thought). I got this when dealing with n greater than the pool size. Here is a short example :</p>
<pre><code>from multiprocessing import Pool, cpu_count
from multiprocessing.pool import ApplyResult

# --------- see Stenven's solution above -------------
from copy_reg import pickle
from types import MethodType

def _pickle_method(method):
    func_name = method.im_func.__name__
    obj = method.im_self
    cls = method.im_class
    return _unpickle_method, (func_name, obj, cls)

def _unpickle_method(func_name, obj, cls):
    for cls in cls.mro():
        try:
            func = cls.__dict__[func_name]
        except KeyError:
            pass
        else:
            break
    return func.__get__(obj, cls)


class Myclass(object):

    def __init__(self, nobj, workers=cpu_count()):

        print "Constructor ..."
        # multi-processing
        pool = Pool(processes=workers)
        async_results = [ pool.apply_async(self.process_obj, (i,)) for i in range(nobj) ]
        pool.close()
        # waiting for all results
        map(ApplyResult.wait, async_results)
        lst_results=[r.get() for r in async_results]
        print lst_results

    def __del__(self):
        print "... Destructor"

    def process_obj(self, index):
        print "object %d" % index
        return "results"

pickle(MethodType, _pickle_method, _unpickle_method)
Myclass(nobj=8, workers=3)
# problem !!! the destructor is called nobj times (instead of once)
</code></pre>
<p>Output:</p>
<pre><code>Constructor ...
object 0
object 1
object 2
... Destructor
object 3
... Destructor
object 4
... Destructor
object 5
... Destructor
object 6
... Destructor
object 7
... Destructor
... Destructor
... Destructor
['results', 'results', 'results', 'results', 'results', 'results', 'results', 'results']
... Destructor
</code></pre>
<p>The <code>__call__</code> method is not so equivalent, because [None,...] are read from the results :</p>
<pre><code>from multiprocessing import Pool, cpu_count
from multiprocessing.pool import ApplyResult

class Myclass(object):

    def __init__(self, nobj, workers=cpu_count()):

        print "Constructor ..."
        # multiprocessing
        pool = Pool(processes=workers)
        async_results = [ pool.apply_async(self, (i,)) for i in range(nobj) ]
        pool.close()
        # waiting for all results
        map(ApplyResult.wait, async_results)
        lst_results=[r.get() for r in async_results]
        print lst_results

    def __call__(self, i):
        self.process_obj(i)

    def __del__(self):
        print "... Destructor"

    def process_obj(self, i):
        print "obj %d" % i
        return "result"

Myclass(nobj=8, workers=3)
# problem !!! the destructor is called nobj times (instead of once), 
# **and** results are empty !
</code></pre>
<p>So none of both methods is satisfying...</p>
</div>
<div class="post-text" itemprop="text">
<p>There's another short-cut you can use, although it can be inefficient depending on what's in your class instances.</p>
<p>As everyone has said the problem is that the <code>multiprocessing</code> code has to pickle the things that it sends to the sub-processes it has started, and the pickler doesn't do instance-methods.</p>
<p>However, instead of sending the instance-method, you can send the actual class instance, plus the name of the function to call, to an ordinary function that then uses <code>getattr</code> to call the instance-method, thus creating the bound method in the <code>Pool</code> subprocess.  This is similar to defining a <code>__call__</code> method except that you can call more than one member function.</p>
<p>Stealing @EricH.'s code from his answer and annotating it a bit (I retyped it hence all the name changes and such, for some reason this seemed easier than cut-and-paste :-) ) for illustration of all the magic:</p>
<pre><code>import multiprocessing
import os

def call_it(instance, name, args=(), kwargs=None):
    "indirect caller for instance methods and multiprocessing"
    if kwargs is None:
        kwargs = {}
    return getattr(instance, name)(*args, **kwargs)

class Klass(object):
    def __init__(self, nobj, workers=multiprocessing.cpu_count()):
        print "Constructor (in pid=%d)..." % os.getpid()
        self.count = 1
        pool = multiprocessing.Pool(processes = workers)
        async_results = [pool.apply_async(call_it,
            args = (self, 'process_obj', (i,))) for i in range(nobj)]
        pool.close()
        map(multiprocessing.pool.ApplyResult.wait, async_results)
        lst_results = [r.get() for r in async_results]
        print lst_results

    def __del__(self):
        self.count -= 1
        print "... Destructor (in pid=%d) count=%d" % (os.getpid(), self.count)

    def process_obj(self, index):
        print "object %d" % index
        return "results"

Klass(nobj=8, workers=3)
</code></pre>
<p>The output shows that, indeed, the constructor is called once (in the original pid) and the destructor is called 9 times (once for each copy made = 2 or 3 times per pool-worker-process as needed, plus once in the original process).  This is often OK, as in this case, since the default pickler makes a copy of the entire instance and (semi-) secretly re-populates itâ€”in this case, doing:</p>
<pre><code>obj = object.__new__(Klass)
obj.__dict__.update({'count':1})
</code></pre>
<p>â€”that's why even though the destructor is called eight times in the three worker processes, it counts down from 1 to 0 each timeâ€”but of course you can still get into trouble this way.  If necessary, you can provide your own <code>__setstate__</code>:</p>
<pre><code>    def __setstate__(self, adict):
        self.count = adict['count']
</code></pre>
<p>in this case for instance.</p>
</div>
<div class="post-text" itemprop="text">
<p>You could also define a <code>__call__()</code> method inside your <code>someClass()</code>, which calls <code>someClass.go()</code> and then pass an instance of <code>someClass()</code> to the pool. This object is pickleable and it works fine (for me)...</p>
<pre><code>class someClass(object):
   def __init__(self):
       pass
   def f(self, x):
       return x*x

   def go(self):
      p = Pool(4)
      sc = p.map(self, range(4))
      print sc

   def __call__(self, x):   
     return self.f(x)

sc = someClass()
sc.go()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The solution from <a href="https://stackoverflow.com/a/41959862/1613297">parisjohn</a> above works fine with me. Plus the code looks clean and easy to understand. In my case there are a few functions to call using Pool, so I modified parisjohn's code a bit below. I made <strong>call</strong> to be able to call several functions, and the function names are passed in the argument dict from <code>go()</code>:</p>
<pre><code>from multiprocessing import Pool
class someClass(object):
    def __init__(self):
        pass

    def f(self, x):
        return x*x

    def g(self, x):
        return x*x+1    

    def go(self):
        p = Pool(4)
        sc = p.map(self, [{"func": "f", "v": 1}, {"func": "g", "v": 2}])
        print sc

    def __call__(self, x):
        if x["func"]=="f":
            return self.f(x["v"])
        if x["func"]=="g":
            return self.g(x["v"])        

sc = someClass()
sc.go()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A potentially trivial solution to this is to switch to using <code>multiprocessing.dummy</code>. This is a thread based implementation of the multiprocessing interface that doesn't seem to have this problem in Python 2.7. I don't have a lot of experience here, but this quick import change allowed me to call apply_async on a class method.</p>
<p>A few good resources on <code>multiprocessing.dummy</code>:</p>
<p><a href="https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow noreferrer">https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.dummy</a></p>
<p><a href="http://chriskiehl.com/article/parallelism-in-one-line/" rel="nofollow noreferrer">http://chriskiehl.com/article/parallelism-in-one-line/</a></p>
</div>
<div class="post-text" itemprop="text">
<p>In this simple case, where <code>someClass.f</code> is not inheriting any data from the class and not attaching anything to the class, a possible solution would be to separate out <code>f</code>, so it can be pickled:</p>
<pre><code>import multiprocessing


def f(x):
    return x*x


class someClass(object):
    def __init__(self):
        pass

    def go(self):
        pool = multiprocessing.Pool(processes=4)       
        print pool.map(f, range(10))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Why not to use separate func?</p>
<pre><code>def func(*args, **kwargs):
    return inst.method(args, kwargs)

print pool.map(func, arr)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Update: as of the day of this writing, namedTuples are pickable (starting with python 2.7) </p>
<p>The issue here is the child processes aren't able to import the class of the object -in this case, the class P-, in the case of a multi-model project the Class P should be importable anywhere the child process get used</p>
<p>a quick workaround is to make it importable by affecting it to globals()</p>
<pre><code>globals()["P"] = P
</code></pre>
</div>
<span class="comment-copy">if f is a nested function there is a similar error <code>PicklingError: Can't pickle &lt;class 'function'&gt;: attribute lookup builtins.function failed</code></span>
<span class="comment-copy">That's great - thank you. Seem to have progressed some way, anyhow: Using the code at <a href="http://pastebin.ca/1693348" rel="nofollow noreferrer">pastebin.ca/1693348</a> I now get a RuntimeError: maximum recursion depth exceeded. I looked around and one forum post recommended increasing the maximum depth to 1500 (from the default 1000) but I had no joy there. To be honest, I can't see what part (of my code, at least) could be recursing out of control, unless for some reason the code is pickling and unpickling in a loop, due to slight changes I made in order to make Steven's code OO'd?</span>
<span class="comment-copy">Your <code>_pickle_method</code> returns <code>self._unpickle_method</code>, a bound method; so of course pickle now tries to pickle THAT -- and it does as you've told it to: by calling <code>_pickle_method</code>, recursively.  I.e. by <code>OO</code>ing the code in this way, you have inevitably introduced infinite recursion.  I suggest going back to Steven's code (and not worshipping at the altar of OO when not appropriate: many things in Python are best done in a more functional-way, and this is one).</span>
<span class="comment-copy"><a href="http://bytes.com/topic/python/answers/552476-why-cant-you-pickle-instancemethods#edit2155350" rel="nofollow noreferrer">for the lazy</a></span>
<span class="comment-copy"><a href="http://stackoverflow.com/a/7309686/247542">For the super super lazy</a>, see the only answer that bothered to post the actual non-mangled code...</span>
<span class="comment-copy">Another way to fix / circumvent the pickling problem is using dill, see my answer <a href="http://stackoverflow.com/questions/8804830/python-multiprocessing-pickling-error/24673524#24673524" title="python multiprocessing pickling error">stackoverflow.com/questions/8804830/â€¦</a></span>
<span class="comment-copy">Can you please update this answer based on pathos.pp because pathos.multiprocessing doesn't exist anymore?</span>
<span class="comment-copy">I'm the <code>pathos</code> author.  The version you are referring to is several years old.  Try the version on github,  You can use <code>pathos.pp</code> or <a href="https://github.com/uqfoundation/ppft" rel="nofollow noreferrer">github.com/uqfoundation/ppft</a>.</span>
<span class="comment-copy">or <a href="https://github.com/uqfoundation/pathos" rel="nofollow noreferrer">github.com/uqfoundation/pathos</a>. @SaheelGodhane: A new release is long overdue, but should be out shortly.</span>
<span class="comment-copy">I am getting the same error on trying your example</span>
<span class="comment-copy">First <code>pip install setuptools</code>, then <code>pip install git+https://github.com/uqfoundation/pathos.git@master</code>.  This will get the appropriate dependencies.  A new release is nearly readyâ€¦ now almost everything in <code>pathos</code> also runs on windows, and is <code>3.x</code> compatible.</span>
<span class="comment-copy">This is much easier than the technique proposed by Alex Martelli, but you are limited to sending only one method per class to your multiprocessing pool.</span>
<span class="comment-copy">One other detail to bear in mind is that it is <i>only</i> the object (class instance) that gets pickled, not the class itself. Therefore, if you have changed any class attributes from their default values these changes will not propagate to the different processes. The workaround is to make sure that everything your function needs is stored as an instance attribute.</span>
<span class="comment-copy">@dorvak could you please show a simple example with  <code>__call__()</code> ? I think your answer might be the cleaner one - I am struggling to understand this error, and first time I come to see call. By the way, also this answer help to clarify what multiprocessing does: [<a href="http://stackoverflow.com/a/20789937/305883]">stackoverflow.com/a/20789937/305883]</a></span>
<span class="comment-copy">Can you give an example of this?</span>
<span class="comment-copy">There is a <a href="http://stackoverflow.com/a/41959862/666905">new answer</a> posted (currently below this one) with example code for this.</span>
<span class="comment-copy">You get <code>None</code> back because your definition of <code>__call__</code> is missing the <code>return</code>: it should be <code>return self.process_obj(i)</code>.</span>
<span class="comment-copy">@Eric I was getting the same error and I tried this solution, however I started getting new error as "cPickle.PicklingError: Can't pickle &lt;type 'function'&gt;: attribute lookup <b>builtin</b>.function failed". Do you know what can be a probable reason behind it?</span>
<span class="comment-copy">This is by far the best answer for this problem, as it's the easiest to apply to the non-pickle-able default behaviour</span>
