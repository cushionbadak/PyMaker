<div class="post-text" itemprop="text">
<p>I'm looking for a simple process-based parallel map for python, that is, a function</p>
<pre><code>parmap(function,[data])
</code></pre>
<p>that would run function on each element of [data] on a different process (well, on a different core, but AFAIK, the only way to run stuff on different cores in python is to start multiple interpreters), and return a list of results.</p>
<p>Does something like this exist? I would like something <strong>simple</strong>, so a simple module would be nice. Of course, if no such thing exists, I will settle for a big library :-/</p>
</div>
<div class="post-text" itemprop="text">
<p>I seems like what you need is the <a href="http://docs.python.org/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool.map" rel="nofollow noreferrer">map method in multiprocessing.Pool()</a>:</p>
<blockquote>
<p><strong>map(func, iterable[, chunksize])</strong></p>
<pre><code>A parallel equivalent of the map() built-in function (it supports only
one iterable argument though). It blocks till the result is ready.

This method chops the iterable into a number of chunks which it submits to the 
process pool as separate tasks. The (approximate) size of these chunks can be 
specified by setting chunksize to a positive integ
</code></pre>
</blockquote>
<p>For example, if you wanted to map this function:</p>
<pre><code>def f(x):
    return x**2
</code></pre>
<p>to range(10), you could do it using the built-in map() function:</p>
<pre><code>map(f, range(10))
</code></pre>
<p>or using a multiprocessing.Pool() object's method map():</p>
<pre><code>import multiprocessing
pool = multiprocessing.Pool()
print pool.map(f, range(10))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>For those who looking for Python equivalent of R's mclapply(), here is my implementation. It is an improvement of the following two examples:</p>
<ul>
<li>"<a href="http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/" rel="nofollow noreferrer">Parallelize Pandas map() or apply()</a>", as mentioned by @Rafael
Valero.</li>
<li><a href="https://stackoverflow.com/questions/10834960/how-to-do-multiple-arguments-to-map-function-where-one-remains-the-same-in-pytho">How to apply map to functions with multiple arguments</a>.</li>
</ul>
<p>It can be apply to map functions with single or multiple arguments.</p>
<pre><code>import numpy as np, pandas as pd
from scipy import sparse
import functools, multiprocessing
from multiprocessing import Pool

num_cores = multiprocessing.cpu_count()

def parallelize_dataframe(df, func, U=None, V=None):

    #blockSize = 5000
    num_partitions = 5 # int( np.ceil(df.shape[0]*(1.0/blockSize)) )
    blocks = np.array_split(df, num_partitions)

    pool = Pool(num_cores)
    if V is not None and U is not None:
        # apply func with multiple arguments to dataframe (i.e. involves multiple columns)
        df = pd.concat(pool.map(functools.partial(func, U=U, V=V), blocks))
    else:
        # apply func with one argument to dataframe (i.e. involves single column)
        df = pd.concat(pool.map(func, blocks))

    pool.close()
    pool.join()

    return df

def square(x):
    return x**2

def test_func(data):
    print("Process working on: ", data.shape)
    data["squareV"] = data["testV"].apply(square)
    return data

def vecProd(row, U, V):
    return np.sum( np.multiply(U[int(row["obsI"]),:], V[int(row["obsJ"]),:]) )

def mProd_func(data, U, V):
    data["predV"] = data.apply( lambda row: vecProd(row, U, V), axis=1 )
    return data

def generate_simulated_data():

    N, D, nnz, K = [302, 184, 5000, 5]
    I = np.random.choice(N, size=nnz, replace=True)
    J = np.random.choice(D, size=nnz, replace=True)
    vals = np.random.sample(nnz)

    sparseY = sparse.csc_matrix((vals, (I, J)), shape=[N, D])

    # Generate parameters U and V which could be used to reconstruct the matrix Y
    U = np.random.sample(N*K).reshape([N,K])
    V = np.random.sample(D*K).reshape([D,K])

    return sparseY, U, V

def main():
    Y, U, V = generate_simulated_data()

    # find row, column indices and obvseved values for sparse matrix Y
    (testI, testJ, testV) = sparse.find(Y)

    colNames = ["obsI", "obsJ", "testV", "predV", "squareV"]
    dtypes = {"obsI":int, "obsJ":int, "testV":float, "predV":float, "squareV": float}

    obsValDF = pd.DataFrame(np.zeros((len(testV), len(colNames))), columns=colNames)
    obsValDF["obsI"] = testI
    obsValDF["obsJ"] = testJ
    obsValDF["testV"] = testV
    obsValDF = obsValDF.astype(dtype=dtypes)

    print("Y.shape: {!s}, #obsVals: {}, obsValDF.shape: {!s}".format(Y.shape, len(testV), obsValDF.shape))

    # calculate the square of testVals    
    obsValDF = parallelize_dataframe(obsValDF, test_func)

    # reconstruct prediction of testVals using parameters U and V
    obsValDF = parallelize_dataframe(obsValDF, mProd_func, U, V)

    print("obsValDF.shape after reconstruction: {!s}".format(obsValDF.shape))
    print("First 5 elements of obsValDF:\n", obsValDF.iloc[:5,:])

if __name__ == '__main__':
    main()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This can be done elegantly with <a href="https://github.com/ray-project/ray" rel="nofollow noreferrer">Ray</a>, a system that allows you to easily parallelize and distribute your Python code.</p>
<p>To parallelize your example, you'd need to define your map function with the <code>@ray.remote</code> decorator, and then invoke it with <code>.remote</code>. This will ensure that every instance of the remote function will executed in a different process.</p>
<pre><code>import time
import ray

ray.init()

# Define the function you want to apply map on, as remote function. 
@ray.remote
def f(x):
    # Do some work...
    time.sleep(1)
    return x*x

# Define a helper parmap(f, list) function.
# This function executes a copy of f() on each element in "list".
# Each copy of f() runs in a different process.
# Note f.remote(x) returns a future of its result (i.e., 
# an identifier of the result) rather than the result itself.  
def parmap(f, list):
    return [f.remote(x) for x in list]

# Call parmap() on a list consisting of first 5 integers.
result_ids = parmap(f, range(1, 6))

# Get the results
results = ray.get(result_ids)
print(results)
</code></pre>
<p>This will print:</p>
<pre><code>[1, 4, 9, 16, 25]
</code></pre>
<p>and it will finish in approximately <code>len(list)/p</code> (rounded up the nearest integer) where <code>p</code> is number of cores on your machine. Assuming a machine with 2 cores, our example will execute in <code>5/2</code> rounded up, i.e, in approximately <code>3</code> sec.</p>
<p>There are a number of advantages of using Ray over the <a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing</a> module. In particular, the <strong>same code</strong> will run on a single machine as well as on a cluster of machines. For more advantages of Ray see <a href="https://stackoverflow.com/questions/20548628/how-to-do-parallel-programming-in-python/48177988#48177988">this related post</a>.</p>
</div>
<span class="comment-copy">If you're invoking this from a long-lived program, make sure to call <code>pool.close</code> (ideally in the <code>finally</code> block of an enclosing <code>try/finally</code>). Otherwise the pool may fail to clean up child processes and you can end up with zombie processes. See <a href="http://bugs.python.org/issue19675" rel="nofollow noreferrer">bugs.python.org/issue19675</a></span>
<span class="comment-copy">@rogueleaderr Wouldn't it be more idiomatic to use <code>with</code>?</span>
<span class="comment-copy">Good point @CodeMonkey! The first example on the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">official docs</a> uses <code>with</code> so that should handle the cleanup nicely.</span>
<span class="comment-copy"><code>PicklingError: Can't pickle &lt;function &lt;lambda&gt; at 0x121572bf8&gt;: attribute lookup &lt;lambda&gt; on __main__ failed</code> how come it can't work <code>lambda</code>?</span>
<span class="comment-copy">I found here a really good example a little bit more complicated that the previous one: <a href="http://blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply/" rel="nofollow noreferrer">blog.adeel.io/2016/11/06/parallelize-pandas-map-or-apply</a></span>
