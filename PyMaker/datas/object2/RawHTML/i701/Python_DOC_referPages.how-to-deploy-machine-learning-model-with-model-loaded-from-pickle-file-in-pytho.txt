<div class="post-text" itemprop="text">
<p>I have created an NLP model and saved the vectorizer and model in pickle file. I am using these pickle file for predicting the new data. Loading pickle takes around 10 minutes. I want to keep the pickle file loaded in memory and run the prediction when I get the input.</p>
<p>I have a file prediction.py</p>
<pre><code>from sklearn.externals import joblib

count_vectorizer = joblib.load("C:/Count_Vectorizer.pkl")

count_classifier = joblib.load("C:/Count_Classifier.pkl")

X=sys.argv[1]

X_count = count_vectorizer.transform(X)

prediction = count_classifier.predict(X_count )

print(X,prediction)
</code></pre>
<p>I am running the python file with input string as an argument.</p>
<pre><code>$ python prediction.py "Hello World"
</code></pre>
<p>IN this pickle file is loaded every time I am running  the script. Is there anyway to make a program such that the pickle file is already loaded in memory and we run the prediction file and get the result? </p>
</div>
<div class="post-text" itemprop="text">
<p>It depends on your use case. The easiest would be a jupyter notebook so you can play arount. If you are in a bigger project, maybe you are more interested in using some kind of API REST like flask.</p>
</div>
<div class="post-text" itemprop="text">
<p>You would have to change your code structure a little bit.</p>
<h1>1. daemon.py</h1>
<p>This part is responsible for loading models into memory once and should run all the time getting input from 'front' part</p>
<pre><code>import numpy as np    
from sklearn.externals import joblib

count_vectorizer = joblib.load("C:/Count_Vectorizer.pkl")    
count_classifier = joblib.load("C:/Count_Classifier.pkl")

while True:
    # Load your data from file saved on disk, pass path via input
    # User can pass data, separate script saves it and passes it to daemon
    with open(input("Pass your data here")) as f:
        X_count = count_vectorizer.transform(np.fromfile(f))

        prediction = count_classifier.predict(X_count )
        print(X,prediction)
</code></pre>
<p><strong>This is only a sketch</strong> as I don't know your exact use case. Basically, there is an infinite loop taking files (or paths to files like here) and outputting predictions.</p>
<h1>2. front.py</h1>
<p>Using <code>subprocess</code> module you can send path files from the 'front' script to <strong>Daemon</strong> waiting for paths and returning answers. You have to attach input and output streams of <strong>Daemon</strong> to pass the file path and get predictions from that process. </p>
<p><a href="https://docs.python.org/3/library/subprocess.html#subprocess.run" rel="nofollow noreferrer">subprocess.run</a> or <a href="https://docs.python.org/3/library/subprocess.html#subprocess.run" rel="nofollow noreferrer">Popen</a> is probably all you need to perform this operation, go through documentation and example use cases (e.g. <a href="https://stackoverflow.com/questions/28616018/multiple-inputs-and-outputs-in-python-subprocess-communicate">here</a>, <a href="https://www.cyberciti.biz/faq/python-run-external-command-and-get-output/" rel="nofollow noreferrer">here</a> and so on).</p>
<p><strong>EDIT:</strong> @Koalapa answer is another option, as we've said it highly depends on what exactly you wanna do, what is the user load etc.</p>
</div>
<span class="comment-copy">Keep the process running and accept data being sent to it? You can run a web server to accept requests, you can take user input via command line, you can make a gui...etc. Just don't kill the process that loads the pickle.</span>
<span class="comment-copy">You can also use tkinter to build a small UI for your app and have it running. <a href="https://docs.python.org/2/library/tkinter.html" rel="nofollow noreferrer">docs.python.org/2/library/tkinter.html</a></span>
<span class="comment-copy">You could take a look at <a href="http://flask.pocoo.org/" rel="nofollow noreferrer">flask</a></span>
<span class="comment-copy">I need to call a python file with argument all the time I have to do prediction. This python file is called from front end. And I want to use some mechanism that vectorizer and classifier pickle file is not loaded every time. It should be handy so that the result is faster</span>
<span class="comment-copy">Start the file once and pass the user files from front-end to daemon, I don't see where is the problem</span>
<span class="comment-copy">Szymon Maszke: Can you please explain a bit more? I have prediction.py as stated in question. Can you please elaborate your answer using some file name.</span>
<span class="comment-copy">Edited my answer, though I will not write the whole thing, the idea is put out there.</span>
