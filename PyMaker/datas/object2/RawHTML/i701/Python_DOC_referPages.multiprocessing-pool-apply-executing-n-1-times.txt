<div class="post-text" itemprop="text">
<p>Im having an issues with <code>multiprocessing.Pool.apply</code>.<br/>
My objective is to have 5 processes, each filling an array with 100 elements (100 for this test), and then merging then arrays into a single one with length 500. Problem is, it ends up with only 400 elements for any reason i cant understand.</p>
<p>I have tried changing the amount of processes created by the pool but that didn't change anything at all besides the execution time.</p>
<pre><code>import torch.multiprocessing as mp
import itertools

pool = mp.Pool(processes=5)
split = int(500/5)
lst =  pool.apply(RampedGraph, (split,[]))    #each foo returns a list of 100 elements
lst = list(itertools.chain.from_iterable(lst)) #merging the lists into one

len(lst)
&gt;&gt;&gt;400
</code></pre>
<p>The expect output of <code>len(lst)</code> should be <code>500</code>.<br/>
Can anyone enlighten me on what Im doing wrong?</p>
<p>EDIT Foo method explained:</p>
<pre><code>def RampedGraph(popsize, graph_lst):
    cyclic_size = int(math.ceil(popsize/2))
    acyclic_size = popsize - full_size
    append = graph_lst.append
    for _ in range(cyclic_size):
        t = c.Node().cyclic()
        nn = c.number_of_nodes()
        c = c.calculate(0, False)
        append((t,nn,c))
    for _ in range(acyclic_size):
        t = c.Node().acyclic()
        nn = c.number_of_nodes()
        c = c.calculate(0, False)
        append((t,nn,c))
    return graph_lst
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import torch.multiprocessing as mp
# import multiprocessing as mp
import itertools

def RampedGraph(popsize, graph_lst):
    print(mp.current_process().name)
    return list(range(100))

num_workers = 5
pool = mp.Pool(processes=num_workers)
split = int(500/num_workers)
lst =  pool.starmap(RampedGraph, [(split,[])]*num_workers)
lst = list(itertools.chain.from_iterable(lst)) 
print(len(lst))
# 500
</code></pre>
<p><a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.starmap" rel="nofollow noreferrer"><code>pool.starmap(RampedGraph, [(split,[])]*5)</code></a> sends 5 tasks to the task pool.
It causes <code>RampedGraph(split, [])</code> to be called 5 times concurrently.
The 5 results returned by <code>RampedGraph</code> are collected into a list, <code>lst</code>.</p>
<p>Note that calling <code>RampedGraph</code> 5 times concurrently does not guarantee that all 5 processors are used. For example, if <code>RampedGraph</code> were to finish very quickly, it is possible that one processor handles more than one task, and perhaps another processor never gets used at all.
However, if <code>RampedGraph</code> takes a non-trivial amount of time, in general you can expect all 5 worker processes to be used.</p>
<p>Note: I ran the above code with <code>import multiprocessing as mp</code> rather than <code>import torch.multiprocessing as mp</code>. But since <code>torch.multiprocessing</code> is supposed to be a drop-in replacement for <code>multiprocessing</code>, that shouldn't make a difference.</p>
<hr/>
<p>Using <code>multiprocessing</code> comes with both costs and benefits.
The benefit, of course, is the ability to use multiple processors concurrently.
The costs include the time required to launch additional processes, and the cost of interprocess communication. <code>multiprocessing</code> uses <code>Queues</code> to transport arguments to the function run by the worker processes, and to transport the returned value back to the main process. To transport the  returned values through the Queues, the objects are serialized into bytes via pickling. If the pickled objects being sent through the Queues are large, this can add a significant overhead cost when using multiprocessing. Notice that all these costs are not incurred by an equivalent sequential version of the same code.</p>
<p>Particularly when the function run by the worker processes finishes quickly, overhead costs can dominate the total run time of the program, making code which uses multiprocessing slower than a sequential version of the same code.</p>
<p>Thus, a key to speed when using multiprocessing is to try to minimize interprocess communication and to make sure the worker processes do a lot of work so the overhead costs become a relatively small part of the total run time.</p>
</div>
<span class="comment-copy">@unutbu done , added the full method</span>
<span class="comment-copy"><code>pool.apply(RampedGraph, (split,[]))</code> only calls <code>RampedGraph(split, [])</code> once. Are you trying to call <code>RampedGraph</code> 5 times? All with the same argument?</span>
<span class="comment-copy">@unutbu im trying to call it one time for each process, so i can merge 5 arrays of 100 elements. All with the same argument</span>
<span class="comment-copy">much appreciated !</span>
<span class="comment-copy">Hum. Any idea why this approaches takes about 3x more time to execute than simply filling the array with 500 elements? I Assumed it would cut the execution time, not triple it :/</span>
<span class="comment-copy">I added a few words about why <code>multiprocessing</code> can sometimes be slower than a sequential version of the same code. Whether it applies in your case I don't know. We might have to see your actual runnable code to investigate.</span>
