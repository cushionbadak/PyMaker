<div class="post-text" itemprop="text">
<p>I am trying to measure the distance between an object and its reflection. The upper "line" is the reflection. The lower is the object itself. The object is a spiral, this further worsens the view on the object. The light, that is thrown on the object only reflects partly and makes it look as if the object would change its size. The light is produced in a slow motion camera (5000 images/second), thrown on the object to make it visible. The object is permanently moving (all axis). I am trying to analyse its movement from these images.</p>
<p>The images are super low res (15x20 pixel). I applied googles RAISR AI to enlarge the images and increase their quality. In addition I applied a blurr filter to help opencv with making the contours. In the end I apply contours, to mark the relevant area visible.</p>
<p>Before improvement:</p>
<p><a href="https://i.stack.imgur.com/y2SVQ.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/y2SVQ.png"/></a></p>
<p>After improvement + Contours:</p>
<p><a href="https://i.stack.imgur.com/qS9ja.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/qS9ja.png"/></a></p>
<p>This specific picture is one of the good ones. Problem is that most of them look like this:</p>
<p><a href="https://i.stack.imgur.com/28sbm.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/28sbm.png"/></a>
<a href="https://i.stack.imgur.com/mdbkX.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/mdbkX.png"/></a>
<a href="https://i.stack.imgur.com/w8qnh.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/w8qnh.png"/></a>
<a href="https://i.stack.imgur.com/f2Vtg.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/f2Vtg.png"/></a></p>
<p>Is there a person out there, that has an idea how I would measure the distance between the object and its reflection?</p>
<p>My last approach yielded no satisfying result. In that I would make a break above the object. Problem is that the object (reflected lighting to camera) changes its size.</p>
<p><a href="https://i.stack.imgur.com/wVm1C.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/wVm1C.png"/></a>
<a href="https://i.stack.imgur.com/Vydzy.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/Vydzy.png"/></a>
<a href="https://i.stack.imgur.com/5t1VB.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/5t1VB.png"/></a></p>
<p>How would I do something like this?</p>
<p><a href="https://i.stack.imgur.com/KHSNy.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/KHSNy.png"/></a></p>
<p>I have such a nice Boss. I don't wanna tell him that I can't solve this problem. Help is much appreciated.</p>
</div>
<div class="post-text" itemprop="text">
<p>It seems that your main problem is low resolution. It seems to me that RAISR AI is a single frame super resolution approach. </p>
<p>You have a slow motion camera, so maybe you have more images than you need. Then you could use a multiple frame approach as in <a href="https://docs.opencv.org/2.4/modules/superres/doc/super_resolution.html" rel="nofollow noreferrer">opencv super resolution</a> </p>
<p>With a multi frame approach you gain more real information. the single frame approach is just estimating more information.</p>
<p>you tagged this question with <a class="post-tag" href="/questions/tagged/python" rel="tag" title="show questions tagged 'python'">python</a>: A problem could be, that super resolution is not part of the opencv python version. So maybe you need a workaround with <a href="https://docs.python.org/3/library/ctypes.html" rel="nofollow noreferrer">ctypes</a> or another wrapper solution. </p>
</div>
<div class="post-text" itemprop="text">
<p>Techniques based on 2-D correlations provide a rich set of capabilities for recognizing and locating objects and reflections.</p>
<p>Following is an example code that illustrates how this works.  We look for reflections by flipping the image, and in the following we use roll() to illustrate how displacements work in the coordinate system.  The 2-D correlation then gives you a measure of how the two inputs line up as a function of displacing one with respect to the other. (Try experimenting with 1-d data if it helps you more easily get a feel for how this works.  Nothing is different about this in 2-d except for the number of dimensions).</p>
<p>Here we take a gross approach and use the entire image. Since we are working with the Fourier transforms, this is okay.  However, you can sometimes improve performance if you can identify and excise a piece of the image to work with as the reference.</p>
<p>There are also techniques involving projection onto a (ideally) orthonormal basis set, wavelets, etc. These methods work best when the basis set is a good match for the thing you want to find.   Fourier transform based methods work well whenever you are well within the Nyquist limit and meet basic SNR considerations.  But to be fair, the FT too, is an expansion in a basis set.</p>
<p>Finally, it should be noted that no technique whatsoever, can create new information.  If it is not there in the input, no algorithm and no amount of code will find it.</p>
<p>Okay, here is the example code demonstrating correlations.</p>
<pre><code>#!/usr/bin/python

import numpy as np
import matplotlib.pylab as plt
from scipy.signal import correlate2d

plt.figure( figsize=[6,8] )

im = plt.imread("temp.png")

# For simplicity of exposition, we just sum the three color channels.
im1 = np.sum(im,axis=2)

ny = 5
nx = 2

n1 = 1
ax = plt.subplot( ny, nx, n1 )
ax.imshow(  im1 )
ax.set_title( 'raw' )
ax.set_aspect( 'equal' )

corr = correlate2d( im1, im1, boundary='symm', mode='same')

n1 += 1
ax = plt.subplot( ny, nx, n1 )
ax.contourf(  corr, 20 )
ax.set_title( 'auto-correlation' )
ax.set_aspect( 'equal' )


for a in 0, 1:
    imtest = np.roll(im1,4,axis=a)
    corr = correlate2d( im1, imtest, boundary='symm', mode='same')

    n1 += 1
    ax = plt.subplot( ny, nx, n1 )
    ax.imshow( imtest )
    ax.set_title( 'roll axis %d'%a )

    n1 += 1
    ax = plt.subplot( ny, nx, n1 )
    ax.contourf(  corr, 20 )
    ax.set_title( 'correlation, roll axis %d'%a )
    ax.set_aspect( 'equal' )

    imtest = np.flip(im1,axis=a)
    corr = correlate2d( im1, imtest, boundary='symm', mode='same')

    n1 += 1
    ax = plt.subplot( ny, nx, n1 )
    ax.imshow( imtest )
    ax.set_title( 'flip axis %d'%a )

    n1 += 1
    ax = plt.subplot( ny, nx, n1 )
    ax.contourf(  corr, 20 )
    ax.set_title( 'correlation, flip axis %d'%a )
    ax.set_aspect( 'equal' )

plt.tight_layout()
plt.show()
</code></pre>
<p>Here is the output using your raw image.  Notice where the local maxima occur in the correlations, for the self correlation and for the rolls and flips.</p>
<p><a href="https://i.stack.imgur.com/Dg9tJ.png" rel="nofollow noreferrer"><img alt="Output from the sample code" src="https://i.stack.imgur.com/Dg9tJ.png"/></a></p>
<p>See the example listed at the bottom here:<a href="https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.signal.correlate2d.html" rel="nofollow noreferrer">scipy.signal.correlate2d</a></p>
</div>
<span class="comment-copy">Maybe you could use a clustering algorithm on the low res pictures? It seems like you always have three dots+reflection. Or maybe labeling. I don't think, that upscaling via AI is a good idea for scientific images; you don't gain information through upscaling. Maybe it would be good to have some low res sample images for testing</span>
<span class="comment-copy">The low res samples lack information. There is just one pixel between objects, which makes it impossible to analyse distance. The upscaling is an necessary evil, I think.</span>
<span class="comment-copy">(1) Please post your best raw image,  (2) please provide the pixel coordinates of the object and the pixel coordinates of its  reflection, and (3) tell us what measure you want for distance.  I want to be clear about what is what in the image and what you are looking for.  Otherwise, If the problem can be solved, that is all that is needed to solve it.   I'll try to remember to check back for your revisions, and, no promises but if I have some time,  we'll see if we can solve it for you.</span>
<span class="comment-copy">The first image is the best raw image. I don't have the coordinates of the reflection. Only after the conversion to higher resolution I put a line through the contour with opencv. A distance in pixel is enough. I only need distances relative to each other to see the change over a cource of many images.</span>
<span class="comment-copy">Never mind, the image is all that's needed.  Will try to get to it later today.  I envision something that will be quite general.  (I just looked at the image).</span>
<span class="comment-copy">Sorry, I do not understand how this approach might help me. Thanks for your effort though.</span>
<span class="comment-copy">@ArturMüllerRomanov   Look again more closely.  The local maxima give you the offset of the reflection.  You have a lot of noise and low resolution, so it is weak. But it is there, and as a rigorous mathematical fact, it is as robust as any  method can be.  Aside, I have been doing this sort of thing for about 30 years.</span>
<span class="comment-copy">@ArturMüllerRomanov   P/S try some 1-d examples to develop some feel for how to use the approach.</span>
