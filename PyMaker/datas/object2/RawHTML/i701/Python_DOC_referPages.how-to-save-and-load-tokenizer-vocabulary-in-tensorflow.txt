<div class="post-text" itemprop="text">
<p>I've trained a sentiment classifier model using Keras library by following the below steps(broadly).</p>
<ol>
<li>Convert Text corpus into sequences using Tokenizer object/class</li>
<li>Build a model using the model.fit() method </li>
<li>Evaluate this model</li>
</ol>
<p>Now for scoring using this model, I was able to save the model to a file and load from a file. However I've not found a way to save the Tokenizer object to file. Without this I'll have to process the corpus every time I need to score even a single sentence. Is there a way around this?</p>
</div>
<div class="post-text" itemprop="text">
<p>The most common way is to use either <a href="https://docs.python.org/3/library/pickle.html" rel="noreferrer"><code>pickle</code></a> or <a href="https://pypi.python.org/pypi/joblib" rel="noreferrer"><code>joblib</code></a>. Here you have an example on how to use <code>pickle</code> in order to save <code>Tokenizer</code>:</p>
<pre class="lang-py prettyprint-override"><code>import pickle

# saving
with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

# loading
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The accepted answer clearly demonstrates how to save the tokenizer. The following is a comment on the problem of (generally) scoring <em>after</em> fitting or saving. Suppose that a list <code>texts</code> is comprised of two lists <code>Train_text</code> and <code>Test_text</code>, where the set of tokens in <code>Test_text</code> is a subset of the set of tokens in <code>Train_text</code> (an optimistic assumption). Then <code>fit_on_texts(Train_text)</code> gives different results for <code>texts_to_sequences(Test_text)</code> as compared with first calling <code>fit_on_texts(texts)</code> and then <code>text_to_sequences(Test_text)</code>.</p>
<p>Concrete Example:</p>
<pre><code>from keras.preprocessing.text import Tokenizer

docs = ["A heart that",
         "full up like",
         "a landfill",
        "no surprises",
        "and no alarms"
         "a job that slowly"
         "Bruises that",
         "You look so",
         "tired happy",
         "no alarms",
        "and no surprises"]
docs_train = docs[:7]
docs_test = docs[7:]
# EXPERIMENT 1: FIT  TOKENIZER ONLY ON TRAIN
T_1 = Tokenizer()
T_1.fit_on_texts(docs_train)  # only train set
encoded_train_1 = T_1.texts_to_sequences(docs_train)
encoded_test_1 = T_1.texts_to_sequences(docs_test)
print("result for test 1:\n%s" %(encoded_test_1,))

# EXPERIMENT 2: FIT TOKENIZER ON BOTH TRAIN + TEST
T_2 = Tokenizer()
T_2.fit_on_texts(docs)  # both train and test set
encoded_train_2 = T_2.texts_to_sequences(docs_train)
encoded_test_2 = T_2.texts_to_sequences(docs_test)
print("result for test 2:\n%s" %(encoded_test_2,))
</code></pre>
<p>Results:</p>
<pre><code>result for test 1:
[[3], [10, 3, 9]]
result for test 2:
[[1, 19], [5, 1, 4]]
</code></pre>
<p>Of course, if the above optimistic assumption is not satisfied and the set of tokens in Test_text is disjoint from that of Train_test, then test 1 results in a list of empty brackets <code>[].</code></p>
</div>
<div class="post-text" itemprop="text">
<p>I've created the issue <a href="https://github.com/keras-team/keras/issues/9289" rel="nofollow noreferrer">https://github.com/keras-team/keras/issues/9289</a> in  the keras Repo. Until the API is changed, the issue has a link to a gist that has code to demonstrate how to save and restore a tokenizer without having the original documents the tokenizer was fit on. I prefer to store all my model information in a JSON file (because reasons, but mainly mixed JS/Python environment), and this will allow for that, even with sort_keys=True </p>
</div>
<div class="post-text" itemprop="text">
<p>Another option is to save Tokenizer into JSON format:</p>
<pre class="lang-py prettyprint-override"><code>tokenizer_json = tokenizer.to_json()
with io.open('tokenizer.json', 'w', encoding='utf-8') as f:
    f.write(json.dumps(tokenizer_json, ensure_ascii=False))
</code></pre>
<p>The data can be loaded using <code>tokenizer_from_json</code> function from <code>keras_preprocessing.text</code>:</p>
<pre class="lang-py prettyprint-override"><code>with open('tokenizer.json') as f:
    data = json.load(f)
    tokenizer = tokenizer_from_json(data)
</code></pre>
</div>
<span class="comment-copy">Do you call tokenizer.fit_on_texts again on test set?</span>
<span class="comment-copy">No. If you call fit* again it could change the index. The pickle loaded tokenizer is ready to use.</span>
<span class="comment-copy">Wait. You have to save <i>both</i> a model and a tokenizer in order to run a model in the future?</span>
<span class="comment-copy">of course! they have 2 differents roles, the tokenizer will transform text into vectors, it's important to have the same vector space between training &amp; testing.</span>
<span class="comment-copy">moral of the story: if using word embeddings and keras's Tokenizer, use fit_on_texts only once on a very large corpus; or use character n-grams instead.</span>
<span class="comment-copy">the linked gist looks like a good way to "reload" a trained tokenizer. However, the original question potentially relates to "extending" a previously saved tokenizer to new (test) texts; this part still seems open (otherwise, why "save" a model if it won't be used to "score" new data?)</span>
<span class="comment-copy">I think their intents are clear "Without this I'll have to process the corpus every time I need to score even a single sentence". From this, I gather that they want to skip the tokenizing step and evaluate the trained model on other data. They don't ask anything else, which is that you are anticipating. They like most people, only want to use previously tokenized on a different data set which is skipped in most tutorials. Therefore, I think my answer 1) answers what was asked, and 2) provides working code.</span>
<span class="comment-copy">fair points. the question is "Saving Tokenizer object to file for scoring" so one might assume they're asking about scoring (potentially new data), too.</span>
