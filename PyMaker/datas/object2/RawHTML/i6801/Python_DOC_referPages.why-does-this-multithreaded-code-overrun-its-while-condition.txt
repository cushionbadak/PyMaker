<div class="post-text" itemprop="text">
<p>This code is designed to illustrate how multithreaded code can step on its shared variable</p>
<pre><code>#python3.6
from concurrent.futures import ThreadPoolExecutor


def worker(counts, counter):
    counts.append(counter)

for i in range(10):
    counter = 0
    counts = []
    with ThreadPoolExecutor(max_workers=4) as executor:
        while len(counts) &lt; 1000:
            executor.submit(worker, counts, counter)
            counter += 1
        print("counter = {} length counts = {} max(counts) = {}".
            format(counter, len(counts), max(counts)))
</code></pre>
<p>Typical output is:</p>
<pre class="lang-none prettyprint-override"><code>counter = 1217 length counts = 1216 max(counts) = 1215
counter = 1209 length counts = 1185 max(counts) = 1184
counter = 1124 length counts = 1124 max(counts) = 1123
counter = 1339 length counts = 1338 max(counts) = 1337
counter = 1179 length counts = 1178 max(counts) = 1177
counter = 1032 length counts = 1002 max(counts) = 1001
counter = 1001 length counts = 1000 max(counts) = 999
counter = 1001 length counts = 1000 max(counts) = 999
counter = 1201 length counts = 1201 max(counts) = 1200
counter = 1306 length counts = 1304 max(counts) = 1304
</code></pre>
<p>I was expecting to see small deviations from 1000 in the length and max values but numbers between 999 and 1500 are normal.</p>
<p>Given that the <em>while</em> block should complete when <em>counts</em> reaches a length of 999, and that the <em>append</em> operation should be thread-safe, why is there so much variance in the results? I expected small errors, not like these.</p>
</div>
<div class="post-text" itemprop="text">
<p>The delay from when a task is submitted to the executor to when it begins executing is a random variable D with some probability distribution. We may assume that only this task is running (no background tasks, etc.) and that each code line takes one time quantum to execute. For simplicity, assume that the limitation to four concurrent tasks is not present. These are grossly simplified assumptions that will make analyzing this behavior at least somewhat tractable.</p>
<p>Assume that D identically assumes the value of 0. That is, all workers begin executing immediately. This is the synchronous case. I think we can both agree that, in this event, you will always get a counter of 999 every time with no variation.</p>
<p>Now, assume that D is uniformly distributed from 4 to 13, inclusive. That is, there is a 10% chance of the execution of any task being delayed by any of 4, 5, 6, 7, 8, 9, 10, 11, 12 or 13 time quanta. Let's say we want to loop until the counter equals 10. The best case is everything is delayed minimally. The <code>while len(counts) &lt; 10</code> line will execute at times <code>1, 4, 7, ..., 3k - 2</code>, and it kicks off tasks at times <code>2, 5, 8, ..., 3k - 1</code>. The 10th task runs the line <code>counts.append(counter)</code> at time <code>33 = 3(10) - 1 + 4</code>. The loop condition is next checked at time <code>34 = 3(12)-2</code>, meaning that 11 iterations of the loop have completed and the 12th one will not run. Thus <code>counter = 11</code>, and we have one task scheduled that has not yet run (but is still going to run sometime; in our case before you print the results, but in general there is a race condition with printing).</p>
<p>In the worst case, there is a delay of 13, so change <code>33</code> to <code>42</code> and you get the loop condition failing the 15th time, meaning <code>counter = 14</code> and there are 4 tasks outstanding that may or may not complete before you format your print output.</p>
<p>So, in the best case, you will have a list length from 11 to 12 (depending on the race condition with the printing of output), and in the worst case you will have a list length from 14 to 18 (depending on the race conditions). I would expect the results of lots of trials of this to be roughly normally distributed with mean around ~14.5 and standard deviation ~1.2.</p>
<p>You would expect about the same magnitude of error regardless of the target, so by making the target bigger you would see relatively less error (though the same magnitude). This is because the magnitude of error depends only on the distribution of the random variable. This might be why you see it converging for higher values: your task scheduler has the same delay distribution, but it becomes less relevant compared to the overall expectation as you increase that expectation. The lower you make the target, the larger the effect becomes relatively speaking.</p>
<p>Based on the numbers you're getting = say, from ~1000 to ~1500 - I would guess your delay in terms of our line-ops metric is something like 250-900 line-ops if the above model roughly holds. Of course, the distribution is probably not uniform over the range 250-900, but that might be a rough guess. You could check the distribution yourself using timers and compare to the timed average cycle length of your loop. Also, that you have a max workers given changes the analysis by increasing the effective delay above that of the underlying system (assuming the system can execute arbitrarily many processes truly in parallel).</p>
<p>As you can see, even with all the simplifying assumptions, it's a murky analysis, so really nailing down exactly why you see your distribution on a real computer is going to be a tall order.</p>
</div>
<span class="comment-copy">Because the workers are not instantaneously executed.  They will run at some point in the future, but you don't know when.  You cannot count on them being executed before coming around and checking your loop condition.  Instead, your code will keep launching workers until enough have run to put 1,000 things into the list.  However, many more tasks have been submitted and haven't had the chance to run yet.  Can you add counter's value to the print statement?  That'll let you know how many tasks have actually been submitted.</span>
<span class="comment-copy">To add to that: There's no guarantee that this even terminates. If the thread pool never gets CPU share, you can run the loop forever (or rather until you run out of memory for the queue).</span>
<span class="comment-copy">Just for reference, <code>list.append()</code> can be thread-safe.  See the <a href="https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe" rel="nofollow noreferrer">Python FAQ</a>.</span>
<span class="comment-copy">Since the threaded <code>worker</code> function effectively changes the length of the <code>counts</code> list, using the length of that list to control the execution of the <code>while</code> loop body isn't a reliable way to determine how many <code>executor.submit()</code> calls to makeâ€”since earlier calls to it may or may not have executed the <code>worker</code> yet (and updated the length of the list). This would explain why the value in the <code>counter</code> is higher than you apparently expect.</span>
<span class="comment-copy">@jszakmeister "This code is designed to illustrate how multithreaded code can step on its shared variable"?</span>
