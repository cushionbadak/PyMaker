<div class="post-text" itemprop="text">
<p>I'm trying to write a pandas dataframe as a pickle file into an s3 bucket in AWS. I know that I can write dataframe <code>new_df</code> as a csv to an s3 bucket as follows:</p>
<pre><code>bucket='mybucket'
key='path'

csv_buffer = StringIO()
s3_resource = boto3.resource('s3')

new_df.to_csv(csv_buffer, index=False)
s3_resource.Object(bucket,path).put(Body=csv_buffer.getvalue())
</code></pre>
<p>I've tried using the same code as above with <code>to_pickle()</code> but with no success.</p>
</div>
<div class="post-text" itemprop="text">
<p>Further to you answer, you don't need to convert to csv. 
pickle.dumps method returns a byte obj. see here: <a href="https://docs.python.org/3/library/pickle.html" rel="noreferrer">https://docs.python.org/3/library/pickle.html</a> </p>
<pre><code>bucket='your_bucket_name'
key='your_pickle_filename.pkl'
pickle_byte_obj = pickle.dumps([var1, var2, ..., varn]) 
s3_resource = resource('s3')
s3_resource.Object(bucket,key).put(Body=pickle_byte_obj)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I've found the solution, need to call BytesIO into the buffer for pickle files instead of StringIO (which are for CSV files). </p>
<pre><code>pickle_buffer = BytesIO()
s3_resource = boto3.resource('s3')

new_df.to_pickle(pickle_buffer, index=False)
s3_resource.Object(bucket,path).put(Body=pickle_buffer.getvalue())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>this worked for me with pandas 0.23.4 and boto3 1.7.80 :</p>
<pre><code>bucket='your_bucket_name'
key='your_pickle_filename.pkl'
new_df.to_pickle(key)
s3_resource.Object(bucket,path).put(Body=open(key, 'rb'))
</code></pre>
</div>
<span class="comment-copy">Do you have a suggestion, how to use this with a pandas-Dataframe? i tried pickle_byte_obj = df.to_pickle(None).encode() but it doesn't seem to work</span>
