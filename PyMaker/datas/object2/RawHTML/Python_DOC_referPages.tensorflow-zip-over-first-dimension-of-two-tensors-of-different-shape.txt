<div class="post-text" itemprop="text">
<p>Let's say I have two tensors, whose shapes are <code>[b, n]</code> and <code>[b, n, m]</code> respectively.  These can be interpreted as a batch of input vectors each of shape <code>[n]</code> and a batch of weight matrices each of shape <code>[n, m]</code>, where the batch size is <code>b</code>.  I would like to pair these up element-wise across the first dimension, so each input vector has a corresponding weight matrix, and then multiply each input by its weights, resulting in a tensor of shape <code>[b, m]</code>.</p>
<p>In normal Python I suspect this would look something like</p>
<p><code>output_list = [matmul(w, i) for w, i in zip(weight_list, input_list)]</code></p>
<p>but haven't been able to find a Tensorflow analogue; is there a way of doing this?</p>
</div>
<div class="post-text" itemprop="text">
<p><code>tf.matmul</code> can do a matmul over each training example in the batch. But you need to deal with some dimensions problem to achieve your goal.</p>
<pre><code>import tensorflow as tf

b,n,m = 4,3,2
weight_list = tf.random.normal(shape=(b,n,m))
input_list = tf.random.normal(shape=(b,n))
result = tf.squeeze(tf.matmul(tf.expand_dims(input_list,axis=1),weight_list))
print(result.shape)

(4, 2)
</code></pre>
</div>
