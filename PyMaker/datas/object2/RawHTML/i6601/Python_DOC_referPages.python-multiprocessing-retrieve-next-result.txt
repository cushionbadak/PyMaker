<div class="post-text" itemprop="text">
<p>I'm trying to figure out a good way to use the <a href="https://docs.python.org/3.6/library/multiprocessing.html" rel="nofollow noreferrer"><code>multiprocessing</code></a> package in Python 3.6 to run a set of around 100 tasks, with a maximum of 4 of them running simultaneously.  I also want to:</p>
<ol>
<li>repeatedly reap the next completed task from the pool and process its return value, until all tasks have either succeeded or failed;</li>
<li>make exceptions thrown in any given task non-fatal, so I can still access the results from the other tasks.</li>
</ol>
<p>I don't need to maintain the order of tasks submitted to the pool (i.e. I don't need a queue).  The total number of tasks ("100" above) isn't prohibitively huge, e.g. I don't mind submitting them all at once and letting them be queued until workers are available.</p>
<p>I thought that <a href="https://docs.python.org/3.6/library/multiprocessing.html#multiprocessing.pool.Pool" rel="nofollow noreferrer"><code>multiprocessing.Pool</code></a> would be a good fit for this, but I can't seem to find a "get next result" method that I can call iteratively.</p>
<p>Is this something I'm going to have to roll myself from process management primitives?  Or can <code>Pool</code> (or another thing I'm missing) support this workflow?</p>
<p>For context, I'm using each worker to invoke a remote process that could take a few minutes, and that has capacity to handle N jobs simultaneously ("4" in my concretized example above).</p>
</div>
<div class="post-text" itemprop="text">
<p>I came up with the following pattern (shown using 2 workers &amp; 6 jobs, instead of 4 &amp; 100):</p>
<pre><code>import random
import time
from multiprocessing import Pool, TimeoutError
from queue import Queue


def worker(x):
    print("Start: {}".format(x))
    time.sleep(5 * random.random())  # Sleep a random amount of time
    if x == 2:
        raise Exception("Two is bad")
    return x


if __name__ == '__main__':

    with Pool(processes=2) as pool:
        jobs = Queue()
        for i in range(6):
            jobs.put(pool.apply_async(worker, [i]))

        while not jobs.empty():
            j = jobs.get(timeout=1)
            try:
                r = j.get(timeout=0.1)
                print("Done: {}".format(r))
            except TimeoutError as e:
                jobs.put(j)  # Not ready, try again later
            except Exception as e:
                print("Exception: {}".format(e))
</code></pre>
<p>Seems to work pretty well:</p>
<pre><code>Start: 0
Start: 1
Start: 2
Done: 1
Start: 3
Exception: Two is bad
Start: 4
Start: 5
Done: 3
Done: 4
Done: 5
Done: 0
</code></pre>
<p>I'll see whether I can make a general utility to manage the queueing for me.</p>
<p>The main shortcoming I think it has is that completed jobs can go unnoticed for a while, while uncompleted jobs are polled and possibly time out.  Avoiding that would probably require using callbacks - if it becomes a big enough problem, I'll probably add that to my app.</p>
</div>
<span class="comment-copy"><a href="http://pyvideo.org/search.html?q=multiprocessing" rel="nofollow noreferrer">pyvideo.org/search.html?q=multiprocessing</a></span>
<span class="comment-copy">@wwii is there some video in particular you recommend that addresses the question?</span>
<span class="comment-copy">Only in general - I find  the video's of Pycon talks pretty informative. Also the examples given in the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing module documentation</a> seem to be enough to get me started when I want to play around and experiment.</span>
<span class="comment-copy">This is not directly supported. Such workflow would need some kind of buffer implicitly to hold the results until they are retrieved. So instead using a <code>Queue</code> explicitly is reasonable.</span>
<span class="comment-copy">You shouldn't queue the jobs but the results. For the <code>callback</code> parameter of <code>apply_async</code> you can set a function which puts the result into a queue. A separate thread can then <code>get</code> the results sequentially.</span>
