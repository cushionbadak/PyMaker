<div class="post-text" itemprop="text">
<p>According to 
   <a href="https://github.com/joblib/joblib/issues/180" rel="nofollow noreferrer">https://github.com/joblib/joblib/issues/180</a>, and <a href="https://stackoverflow.com/questions/14633269/is-there-a-safe-way-to-create-a-subprocess-from-a-thread-in-python">Is there a safe way to create a subprocess from a thread in python?</a>
the Python multiprocessing module does not allow use from within threads. Is this true?</p>
<p>My understanding is that its fine to fork from threads, as long as you 
aren't holding a threading.Lock when you do so (in the current thread? anywhere in the process?). However, Python's <a href="https://docs.python.org/2/library/threading.html#lock-objects" rel="nofollow noreferrer">documentation</a> is silent on whether threading.Lock objects are safely shared after a fork.</p>
<p>There's also this: locks shared from the logging module causes issues with fork. <a href="https://bugs.python.org/issue6721" rel="nofollow noreferrer">https://bugs.python.org/issue6721</a></p>
<p>I'm not sure how this issue arises. It sounds like the state of any locks in the process are copied into the child process when the current thread forks (which seems like a design error and certain to deadlock). If so, does using multiprocessing really provide any protection against this (since I'm free to create my multiprocessing.Pool after threading.Lock is created and entered by other threads, and after threads have started that using the not-fork-safe logging module) -- the multiprocessing module docs are also silent about whether multiprocessing.Pools should be allocated before Locks.</p>
<p>Does replacing threading.Lock with multiprocessing.Lock everywhere avoid this issue and allow us to safely combine threads and forks?</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>It sounds like the state of any locks in the process are copied into the child process when the current thread forks (which seems like a design error and certain to deadlock).</p>
</blockquote>
<p>It is not a design error, rather, <code>fork()</code> predates single-process multithreading. The state of all locks is copied into the child process because they're just objects in memory; the entire address-space of the process is copied as is in fork. There are only bad alternatives: either copy <em>all</em> threads over fork, or deny forking in multithreaded application.</p>
<p>Therefore, <code>fork()</code>ing in a multithreading program was never the safe thing to do, unless then followed by <code>execve()</code> or <code>exit()</code> in the child process.</p>
<blockquote>
<p>Does replacing threading.Lock with multiprocessing.Lock everywhere avoid this issue and allow us to safely combine threads and forks?</p>
</blockquote>
<p><strong>No.</strong> Nothing makes it safe to combine threads and forks, it cannot be done.</p>
<hr/>
<p>The problem is that when you have multiple threads in a process, after <code>fork()</code> system call you cannot continue safely running the program in POSIX systems.</p>
<p>For example, Linux manuals <a href="http://man7.org/linux/man-pages/man2/fork.2.html" rel="nofollow noreferrer"><code>fork(2)</code></a>:</p>
<blockquote>
<ul>
<li>After a <code>fork(2)</code> in a multithreaded program, the child  can  safely  call
        only  async-signal-safe  functions (see <a href="http://man7.org/linux/man-pages/man7/signal.7.html" rel="nofollow noreferrer"><code>signal(7)</code></a>) until such time as it
        calls <a href="http://man7.org/linux/man-pages/man2/execve.2.html" rel="nofollow noreferrer"><code>execve(2)</code></a>.</li>
</ul>
</blockquote>
<p>I.e. it is OK to <code>fork()</code> in a multithreaded program and then only call async-signal-safe <strong>C</strong> functions (which is a rather limited subset of C functions), until the child process has been replaced with another executable!</p>
<p>Unsafe C function calls in child processes are then for example</p>
<ul>
<li><code>malloc</code> for dynamic memory allocation</li>
<li>any <code>&lt;stdio.h&gt;</code> functions for formatted input</li>
<li>most of the <code>pthread_*</code> functions required for thread state handling, including creation of new threads...</li>
</ul>
<p>Thus there is very little what the child process can actually safely do. Unfortunately CPython core developers have been downplaying the problems caused by this. Even now the <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">documentation</a> says:</p>
<blockquote>
<p>Note that safely forking a multithreaded process is 
  <strong>problematic</strong>.</p>
</blockquote>
<p>Quite an euphemism for "impossible".</p>
<hr/>
<p>It is safe to use multiprocessing <em>from</em> a Python process that has multiple threads of control provided that you're <em>not</em> using the <code>fork</code> start method; in Python 3.4+ it is <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">now possible to change the start method</a>. In previous Python versions including all of Python 2, the POSIX systems always behaved as if <code>fork</code> was specified as the start method; this would result in undefined behaviour.</p>
<p>The problems are not limited to just <code>threading.Lock</code> objects but <strong>all</strong> locks held by the C standard library, the C extensions etc. What is worse that most of the time people would say "it works for <strong>me</strong>"... until it stops from working.</p>
<p>There were even a cases where a seemingly single-threading Python program is actually multithreading in MacOS X, causing failures and deadlocks upon using multiprocessing.</p>
<p>Another problem is that all opened file handles, their use, shared sockets might behave oddly in programs that forks, but that would be the case even in single-threaded programs.</p>
<p>TL;DR: using <code>multiprocessing</code> in multithreaded programs, with C extensions, with opened sockets etc: </p>
<ul>
<li>fine in 3.4+ &amp; POSIX if you explicitly specify a starting method that is not <code>fork</code>, </li>
<li>fine in Windows because it doesn't support forking;</li>
<li>in Python 2 - 3.3 on POSIX: you'll mostly shoot yourself in the foot.</li>
</ul>
</div>
<span class="comment-copy">This issue about of <code>how to control sub thread if include another sub thread</code>, my opinion is <b>no way</b>. we should prefer multiprocessing.Lock everywhere? NO if process under a infinite loop !</span>
<span class="comment-copy">Does multiprocessing invoke fork internally? (In which case we should be concerned if we have already created a Lock).</span>
<span class="comment-copy">@user48956 this doesn't have anything to do with python Locks; the thing is you cannot, really in any way, prevent the bad behaviour from your Python code, if you've got a multithreading program.</span>
<span class="comment-copy">I'm not sure is fair to say this is impossible to be safe. I think the problems is that forking is done unaware of locks. In a better (higher-level) framework, you could, for example, assert or block at fork until there are no active locks. This would require that Python only depends on C-libraries that are fork-safe and have no locks, or that Python guarantees no C code is executing at fork. Its possible, but difficult. It might be possible for Python to ask the OS -- 'does this process hold any OS-locks right now?' if Yes, you need to wait to fork (or assert).</span>
