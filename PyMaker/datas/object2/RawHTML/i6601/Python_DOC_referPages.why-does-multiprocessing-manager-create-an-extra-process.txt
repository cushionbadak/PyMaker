<div class="post-text" itemprop="text">
<pre><code>#!/usr/bin/env python

import multiprocessing
import sys
import time    

def sleeping_worker(state):
    s_time = state['sleep_time']
    print('sleeping_worker: start to sleep for {0} seconds'.format(s_time))
    time.sleep(s_time)


def main():
    # the main has been seen
    manager = multiprocessing.Manager()
    # the main and the worker threadA has been seen

    time_to_sleep = 10
    state = manager.dict(sleep_time=time_to_sleep)

    while True:
        state = manager.dict(sleep_time=time_to_sleep)
        worker = multiprocessing.Process(target=sleeping_worker, args=(state, ))
        worker.start()
        # the main, the worker threadA and the worker threadB have been seen

        worker.join()
        # the main and worker threadA has been seen
        print('main: return from sleeping_worker')


if __name__ == "__main__":
    main()


"""
xx       22897 25004  0 10:00 pts/0    00:00:00 python ./testThread.py
xx       22898 22897  0 10:00 pts/0    00:00:00 python ./testThread.py
xx       22960 22897  0 10:00 pts/0    00:00:00 python ./testThread.py

the main thread: 22897
the worker threadA: 22898
the worker threadB: 22960
"""
</code></pre>
<p>I use <code>multiprocessing.Process</code> to create a worker process but I see there are two worker processes created. The worker processA runs at the same time with the main process. The worker processB only runs for 10 seconds, and then it will terminate and start over again.</p>
<p>Based on my observation, the worker processA is created after the call of <code>manager = multiprocessing.Manager()</code>, and this is NOT expected at all. The worker processB is created when <code>worker.start()</code> is called, and this is expected.</p>
<p>Since the call to <code>sleeping_worker</code> function is expensive in real code, I would like to eliminate the worker processA completely. Is that possible? Ideally, I only expect to see two processes (i.e. main and worker processB).</p>
</div>
<div class="post-text" itemprop="text">
<p><code>multiprocessing.Manager</code> works by creating a "server" process, which is responsible for housing all your shared data. Then, your main process and worker processes communicate to the managed objects in the server process via proxies. As stated in the <a href="https://docs.python.org/3/library/multiprocessing.html#managers" rel="nofollow noreferrer">docs</a> (emphasis mine):</p>
<blockquote>
<p>Managers provide a way to create data which can be shared between
  different processes, including sharing over a network between
  processes running on different machines. <strong>A manager object controls a
  server process</strong> which manages shared objects. Other processes can
  access the shared objects by using proxies.</p>
</blockquote>
<p>There's no way to use a <code>Manager</code> without spawning the server process; the server process is a core part of the <code>Manager</code>'s functionality.</p>
</div>
<span class="comment-copy">When you say threadA/threadB, do you mean processA/processB?</span>
<span class="comment-copy">@Dano, yes. You are right. I should have said 'Process' instead of 'Thread'.</span>
<span class="comment-copy">Just tried to remove the both 'state = manager.dict(sleep_time=time_to_sleep)' and `manager = multiprocessing.Manager()' and replace with 'state = {'sleep_time': time_to_sleep}'. Now I only see two processes running! To me, I don't need shared data instead I just want to pass parameters from main to worker process.</span>
<span class="comment-copy">@q0987 If you don't need to see the changes you make to the <code>dict</code> in the main process, then you should absolutely just use a regular <code>dict</code>. In addition to the overhead of spawning the server process when using a <code>Manager</code>, accessing or modifying <code>manager.dict()</code> is extremely slow, because it has to talk to a remote process.</span>
<span class="comment-copy">Good point. At the time, I thought I have to create a <code>manager.dict()</code> in order to pass data from the main to the worker process. Now the issue has been found and it saved me 33% of CPU &amp; Memory usage. Thank you</span>
