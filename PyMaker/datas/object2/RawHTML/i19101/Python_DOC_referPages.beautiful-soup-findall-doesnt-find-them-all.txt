<div class="post-text" itemprop="text">
<p>I'm trying to parse a website and get some info with BeautifulSoup.findAll but it doesn't find them all.. I'm using python3</p>
<p>the code is this</p>
<pre><code>#!/usr/bin/python3

from bs4 import BeautifulSoup
from urllib.request import urlopen

page = urlopen ("http://mangafox.me/directory/")
# print (page.read ())
soup = BeautifulSoup (page.read ())

manga_img = soup.findAll ('a', {'class' : 'manga_img'}, limit=None)

for manga in manga_img:
    print (manga['href'])
</code></pre>
<p>it only prints the half of them...</p>
</div>
<div class="post-text" itemprop="text">
<p>Different HTML parsers deal differently with broken HTML. That page serves broken HTML, and the <code>lxml</code> parser is not dealing very well with it:</p>
<pre><code>&gt;&gt;&gt; import requests
&gt;&gt;&gt; from bs4 import BeautifulSoup
&gt;&gt;&gt; r = requests.get('http://mangafox.me/directory/')
&gt;&gt;&gt; soup = BeautifulSoup(r.content, 'lxml')
&gt;&gt;&gt; len(soup.find_all('a', class_='manga_img'))
18
</code></pre>
<p>The standard library <a href="http://docs.python.org/3/library/html.parser.html" rel="noreferrer"><code>html.parser</code></a> has less trouble with this specific page:</p>
<pre><code>&gt;&gt;&gt; soup = BeautifulSoup(r.content, 'html.parser')
&gt;&gt;&gt; len(soup.find_all('a', class_='manga_img'))
44
</code></pre>
<p>Translating that to your specific code sample using <code>urllib</code>, you would specify the parser thus:</p>
<pre><code>soup = BeautifulSoup(page, 'html.parser')  # BeatifulSoup can do the reading
</code></pre>
</div>
<span class="comment-copy">Wow.  That saved me from banging my head on the table more.  How did you know that the lxml parser was having problems (other than the obvious it was only returning 18 rows). i.e. how should I have known this was a problem other than it silently having the wrong number of rows?</span>
<span class="comment-copy">Experience; mostly through helping people here on SO.</span>
<span class="comment-copy">Similar problem occurred in <a href="https://stackoverflow.com/questions/49526147/how-to-get-lis-using-beautifulsoup#49526542">this question</a>. But, here, changing <code>html.parser</code> to <code>lxml</code> worked (looking for an explanation why the reverse is working).</span>
<span class="comment-copy">@KeyurPotdar: exactly the same reason: <i>Different HTML parsers deal differently with broken HTML</i>. Different broken input into any of the different parsers will result in different output. It depends on the input and the desired output which one will work better.</span>
