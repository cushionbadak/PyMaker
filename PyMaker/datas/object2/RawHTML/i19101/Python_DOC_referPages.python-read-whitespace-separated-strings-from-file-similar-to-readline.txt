<div class="post-text" itemprop="text">
<p>In Python, <code>f.readline()</code> returns the next line from the file <code>f</code>. That is, it starts at the current position of <code>f</code>, reads till it encounters a line break, returns everything in between and updates the position of <code>f</code>.</p>
<p>Now I want to do the exactly the same, but for whitespace separated files (not only newlines). For example, consider a file <code>f</code> with the content</p>
<pre><code>token1 token2

token3                            token4


         token5
</code></pre>
<p>So I'm looking for some function <code>readtoken()</code> such that after opening <code>f</code>, the first call of <code>f.readtoken()</code> returns <code>token1</code>, the second call retuns <code>token2</code> etc.</p>
<p>For efficiency and to avoid problems with very long lines or very large files, there should be no buffering.</p>
<p>I was almost sure that this should be possible "out of the box" with the standard library. However, I didn't find any suitable function or a way to redefine the delimiters for <code>readline()</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>You'd need to create a wrapper function; this is easy enough:</p>
<pre><code>def read_by_tokens(fileobj):
    for line in fileobj:
        for token in line.split():
            yield token
</code></pre>
<p>Note that <code>.readline()</code> doesn't just read a file character by character until a newline is encountered; the file is read in blocks (a buffer) to improve performance.</p>
<p>The above method reads the file by lines but yields the result split on whitespace. Use it like:</p>
<pre><code>with open('somefilename') as f:
    for token in read_by_tokens(f):
        print(token)
</code></pre>
<p>Because <code>read_by_tokens()</code> is a generator, you either need to loop directly over the function result, or use the <a href="http://docs.python.org/3/library/functions.html#next"><code>next()</code> function</a> to get tokens one by one:</p>
<pre><code>with open('somefilename') as f:
    tokenized = read_by_tokens(f)

    # read first two tokens separately
    first_token = next(tokenized)
    second_token = next(tokenized)

    for token in tokenized:
        # loops over all tokens *except the first two*
        print(token)
</code></pre>
</div>
<span class="comment-copy">Note that this is a generator (+1), so it works like <code>for line in f</code> rather than <code>f.readline()</code></span>
<span class="comment-copy">@HenryKeiter: You should really use the file as an iterator anyway instead of using <code>.readline()</code> calls, but yes.</span>
<span class="comment-copy">Of course. I just wanted it to be clear since he's specifically asking about <code>readline</code>. Your edits have made my comment superfluous though :)</span>
<span class="comment-copy">Thank you for this explanation! The read calls will be in different contexts, so I won't use the it as an iterator.</span>
