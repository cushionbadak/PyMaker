<div class="post-text" itemprop="text">
<p>I want to delete duplicated dictionary objects from  a List of dictionaries.
I don't want the dict element that has the same 'plate' element with another dict element in the list. I want it only once.</p>
<pre><code>datalist = [

{
    'plate': "01",
    'confidence' : "80"
},

{
    'plate': "01",
    'confidence' : "60"
},

{
    'plate': "02",
    'confidence' : "91"
},

{
    'plate': "02",
    'confidence' : "91"
},
]
</code></pre>
<p>My output should be like this:</p>
<pre><code>datalist = [

{
    'plate': "01",
    'confidence' : "80"
},

{
    'plate': "02",
    'confidence' : "91"
},
]
</code></pre>
<p>This is my code, but I'm not getting the exact result.</p>
<pre><code>def filter(datalist):
    previous = ""
    for data in datalist:
        current  = data['plate']
        if current is previous:
            datalist.remove(data)
        previous = current 

    return datalist

datalist = [

    {
        'plate': "01",
        'confidence' : "80"
    },

    {
        'plate': "01",
        'confidence' : "60"
    },

    {
        'plate': "02",
        'confidence' : "91"
    },

    {
        'plate': "02",
        'confidence' : "91"
    },
]


print (filter(datalist))
</code></pre>
<p>This gives me the output:</p>
<pre><code>[

    {
        'plate': "01",
        'confidence' : "80"
    },

    {
        'plate': "02",
        'confidence' : "91"
    },

    {
        'plate': "02",
        'confidence' : "91"
    },
]
</code></pre>
<p>which is not expected, what's wrong with my code.</p>
</div>
<div class="post-text" itemprop="text">
<p>If any element from the groups of duplicates is acceptable, you could do:</p>
<pre><code>datalist = [
    {'plate': "01", 'confidence': "80"},
    {'plate': "01", 'confidence': "60"},
    {'plate': "02", 'confidence': "91"},
    {'plate': "02", 'confidence': "91"},
]

result = list({ d['plate'] : d for d in datalist }.values())
print(result)
</code></pre>
<p><strong>Output</strong></p>
<pre><code>[{'plate': '02', 'confidence': '91'}, {'plate': '01', 'confidence': '60'}]
</code></pre>
<p>The idea is to create a dictionary where the keys are values of <code>plate</code> and the values are the dictionaries themselves. If you want to keep the first duplicate entries use <a href="https://docs.python.org/3/library/functions.html#reversed" rel="nofollow noreferrer">reversed</a>:</p>
<pre><code>result = list({d['plate']: d for d in reversed(datalist)}.values())
</code></pre>
<p><strong>Output</strong></p>
<pre><code>[{'plate': '02', 'confidence': '91'}, {'plate': '01', 'confidence': '80'}]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use the <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer"><code>unique_everseen</code> recipe</a>, also available in 3rd party <a href="https://more-itertools.readthedocs.io/en/latest/" rel="nofollow noreferrer"><code>more_itertools</code></a>:</p>
<pre><code>from more_itertools import unique_everseen
from operator import itemgetter    

datalist = list(unique_everseen(datalist, key=itemgetter('plate')))
</code></pre>
<p>Internally, this solution uses <code>set</code> to keep track of seen plates, yielding only dictionaries with new plate values. Therefore, ordering is maintained and only the first instance of any given plate is kept.</p>
</div>
<div class="post-text" itemprop="text">
<p>you can also use pandas</p>
<pre><code>import pandas as pd
df = pd.DataFrame(data = datalist)
df.drop_duplicates(subset = ['plate'],keep='first',inplace=True)
output = df.to_dict(orient='record')
</code></pre>
<p>keep = 'first' or 'last' will help in which entry to keep in output</p>
</div>
<div class="post-text" itemprop="text">
<p>If you are a <code>pandas</code> user, you can consider</p>
<pre><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; datalist = [{'plate': "01", 'confidence': "80"}, {'plate': "01", 'confidence': "60"}, {'plate': "02", 'confidence': "91"}, {'plate': "02", 'confidence': "91"}]
&gt;&gt;&gt; pd.DataFrame(datalist).drop_duplicates('plate').to_dict(orient='records')                                                                               
[{'confidence': '80', 'plate': '01'}, {'confidence': '91', 'plate': '02'}]
</code></pre>
<p>If you want to keep the last seen duplicates, pass <code>keep='last'</code>.</p>
<pre><code>&gt;&gt;&gt; pd.DataFrame(datalist).drop_duplicates('plate', keep='last').to_dict(orient='records')
[{'confidence': '60', 'plate': '01'}, {'confidence': '91', 'plate': '02'}]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming you want to only keep the first duplicated dict found, You can use <code>setdefault()</code>:</p>
<pre><code>datalist = [
    {"plate": "01", "confidence": "80"},
    {"plate": "01", "confidence": "60"},
    {"plate": "02", "confidence": "91"},
    {"plate": "02", "confidence": "91"},
]

result = {}
for d in datalist:
    result.setdefault(d["plate"], d)

print(list(result.values()))
# [{'plate': '01', 'confidence': '80'}, {'plate': '02', 'confidence': '91'}]
</code></pre>
<p>If you instead want the last duplicates, simply iterate in <a href="https://docs.python.org/3/library/functions.html#reversed" rel="nofollow noreferrer"><code>reverse()</code></a>. </p>
</div>
<div class="post-text" itemprop="text">
<p>You can use one groupby:</p>
<pre><code>list(map(lambda x: next(x[1]), groupby(sorted(datalist, key=lambda d: d['plate']), lambda d: d['plate'])))
</code></pre>
<p>Results:</p>
<pre><code>[{'plate': '01', 'confidence': '80'}, {'plate': '02', 'confidence': '91'}]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Good old verbose <code>for</code> loop, then list comprehension:</p>
<pre><code>tmp=[]
for dct in datalist:
  if not any(e[0] == dct["plate"] for e in tmp):
    tmp.append((dct["plate"], dct["confidence"]))


[ {"plate": plate, "confidence": confidence} for plate, confidence in tmp ]
#=&gt; [{'plate': '01', 'confidence': '80'}, {'plate': '02', 'confidence': '91'}]
</code></pre>
</div>
<span class="comment-copy">Related, not exact duplicate as here we only want to consider one key when considering duplicates: <a href="https://stackoverflow.com/questions/9427163/remove-duplicate-dict-in-list-in-python">Remove duplicate dict in list in Python</a></span>
<span class="comment-copy">you can also use pandas  import pandas as pd; df = pd.DataFrame(data = datalist); df.drop_duplicates(subset = ['plate'],keep='first',inplace=True); output = df.to_dict(orient='record')</span>
<span class="comment-copy">This produces the wrong result because the last duplicated entries are kept, not the first.</span>
<span class="comment-copy">@timgeb OP didn't clearly specify that they want the first entry - only that they don't want duplicate entries.</span>
<span class="comment-copy">@MatthiasFischer OP specified the desired output.</span>
<span class="comment-copy">@timgeb Updated the answer!</span>
<span class="comment-copy">@DanielMesejo good! Creative answer by the way!</span>
<span class="comment-copy">Nice use of <code>itemgetter()</code> here.</span>
<span class="comment-copy">Good answer for the uninitiated, like me. Although, I prefer pandas as more simple method.</span>
<span class="comment-copy">Huh, I did not know that you could pass <code>'record'</code> instead of <code>'records'</code>. This seems to be undocumented. +1 for obscure knowledge :)</span>
<span class="comment-copy">Update: seems like you can pass <code>'r'</code>, <code>'re'</code>, ..., <code>'records'</code>, <code>'recordsasdf'</code>, ...</span>
<span class="comment-copy">:D Thanks @timgeb . We can use anything that starts with 'r' . I have just checked the source code.  <a href="http://github.com/pandas-dev/pandas/blob/v0.23.4/pandas/core/frame.py#L987-L1102" rel="nofollow noreferrer">github.com/pandas-dev/pandas/blob/v0.23.4/pandas/core/â€¦</a></span>
<span class="comment-copy">this requires the initial list to be sorted.</span>
<span class="comment-copy">Answer is updated.</span>
