<div class="post-text" itemprop="text">
<p>I am trying to execute n processes simultaneously. The example below works with 2 processes that are supplied externally.</p>
<p>At the moment it is all hard-coded for just these 2 processes but I would need to come up with the generic solution how to accomplish the same - i.e. run n processes at the same time.</p>
<p>My code is as follows:</p>
<pre><code>import multiprocessing

'''

The first process: print 'aa'
The second Process: print 'BB'

'''

def TR1(): 
    print 'aaaaaaaaa'

def TR2(): 
    print 'BBBBBBBB'

if __name__ == '__main__':

    process_1 = multiprocessing.Process(name='process_1', target=TR1)
    process_2 = multiprocessing.Process(name='process_2', target=TR2)

    process_1.start()
    process_2.start()
</code></pre>
<p>Thanks for your suggestions!</p>
</div>
<div class="post-text" itemprop="text">
<p>You can either spawn processes in a loop, or use executor pool.</p>
<p>In real life, later one is often preferred approach, as you can limit pool size <em>and</em> have easy result gathering.</p>
<p>If you're using python 2, there's <a href="https://pypi.org/project/futures/" rel="nofollow noreferrer">backport</a> including <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor" rel="nofollow noreferrer"><code>ProcessPoolExecutor</code></a></p>
</div>
<span class="comment-copy">If you are trying to learn Python, I would strongly recommend moving to Python 3 already. By the original timetable, Python 2 would be dead already; and you can clearly tell that experts and library maintainers are reluctant to continue to support the old version.</span>
<span class="comment-copy">Unfortunately, on the project I am working on, there is just Python 2 service available.</span>
<span class="comment-copy">What about starting your processes in a loop?</span>
<span class="comment-copy">I am not sure if multiprocessing supports declaration of processes in a loop. If so, it looks like all of the functions (TR1(), TR2(), etc.) would also have to be created in a for loop...?</span>
<span class="comment-copy">Then you need a list or generator for your functions as well.</span>
<span class="comment-copy">Thanks for showing me the direction, I will check the pool of workers in multiprocessing <a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow noreferrer">docs</a></span>
<span class="comment-copy">A pool usually applies/maps the <b>same</b> function to to the input, but distributes the input to n workers. According to your original question this is not what you want. Why is this the accepted answer?</span>
<span class="comment-copy">This actually works as the processes are all of the same type so I can use it as: def p(arg):     print arg  if <b>name</b> == '<b>main</b>':     pool = multiprocessing.Pool(None)     args = ['Hi', 'There', 'Whats up']     r = pool.map_async(p, args)     r.wait()</span>
<span class="comment-copy">@jan-christoph-terasa can you please clarify for me, why <i>same</i> function?</span>
<span class="comment-copy">@Slam Hmm, reading the docs you can use <code>apply_async</code> to call your functions and arguments in a loop and they will evaluate without blocking. So yes, this answer is OK, if you use <code>apply_async</code> instead of <code>map</code> or the the blocking alternatives.</span>
