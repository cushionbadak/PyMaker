<div class="post-text" itemprop="text">
<p>I have this piece of python code, that loops thru a list of urls in a text file(urls.txt) then follows redirects of all urls and if the url contains a specific string, it writes it to a file called redirects.txt</p>
<pre><code>import urllib.request
import ssl
redf = open('redirect.txt', 'w')
with open('urls.txt') as f:
   for row in f:
    #try:

      context = ssl._create_unverified_context()
      finalurl = ''
      try:
        res      = urllib.request.urlopen(row, context=context, timeout=10)
        finalurl = res.geturl().strip()
      except:
          #remove from list
          print("error:"+finalurl)

      # filedata = file.read()
      if finalurl.strip():
        if "/admin/" in finalurl:
            redf.write(finalurl+"\n");
</code></pre>
<p>The problem is that I have to wait for the entire URS to be processed before the redirect.txt file is created.</p>
<p>How can I write in real time?</p>
</div>
<div class="post-text" itemprop="text">
<p>The file is created, but since your output is small, it's likely that it's all stuck in the write buffer until the file is closed. If you need the file to be filled in more promptly, either open it in <a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow noreferrer">line buffered mode by passing <code>buffering=1</code></a>:</p>
<pre><code>open('redirect.txt', 'w', buffering=1)
</code></pre>
<p>or <code>flush</code> after each <code>write</code>, either by <a href="https://docs.python.org/3/library/io.html#io.BufferedWriter.flush" rel="nofollow noreferrer">explicitly calling <code>flush</code></a>:</p>
<pre><code>redf.write(finalurl+"\n")
redf.flush()
</code></pre>
<p>or, since you're adding newlines anyway so you may as well let it work for you, by using <a href="https://docs.python.org/3/library/functions.html#print" rel="nofollow noreferrer"><code>print</code> with <code>flush=True</code></a>:</p>
<pre><code>print(finalurl, file=redf, flush=True)
</code></pre>
<p>Side-note: You <em>really</em> want to use <a href="https://www.python.org/dev/peps/pep-0343/" rel="nofollow noreferrer"><code>with</code> statements</a> with files opened for write in particular, but you only used it for the file being read (where it's less critical, since the worst case is just a delayed handle close, not lost writes). Otherwise exceptions can lead to arbitrary delaying in the file being flushed/closed. Just combine the two opens into one <code>with</code>, e.g.:</p>
<pre><code>with open('urls.txt') as f, open('redirect.txt', 'w', buffering=1) as redf:
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could append to the redirect file, rather than keeping it open for the duration of your program. </p>
<pre><code>import urllib.request
import ssl

def append(line):
    with open('redirect.txt', 'a') as redf:
        redf.write(line)

with open('urls.txt') as f:
   for row in f:

      ...

      if finalurl.strip():
        if "/admin/" in finalurl:
            append(finalurl)
</code></pre>
<p>Depending on any other interaction with the file whilst it's being processed, you may need to add a <code>try/except</code> mechanism to re-try in the <code>append</code> function.</p>
</div>
<span class="comment-copy">I'm just guessing here, but there may be no efficient way to do this. I only say so because in any OS a file has to be <code>close</code>d or saved before changes can be read.</span>
<span class="comment-copy">Repeatedly opening, writing, and closing a file is a fairly high overhead operation; I'd discourage this approach unless the writes occurred unpredictably (e.g. driven by user input or the like in many parts of a complex application). When all the writes occur in a defined time frame, don't constantly open and close the file.</span>
<span class="comment-copy">üëç I agree: your buffer/flush mechanism looks more appropriate.</span>
