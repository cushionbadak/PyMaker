<div class="post-text" itemprop="text">
<p>I am experimenting with Beautiful Soup and I am trying to extract information from a HTML document that contains segments of the following type:</p>
<pre><code>&lt;div class="entity-body"&gt;
&lt;h3 class="entity-name with-profile"&gt;
&lt;a href="https://www.linkedin.com/profile/view?id=AA4AAAAC9qXUBMuA3-txf-cKOPsYZZ0TbWJkhgfxfpY&amp;amp;trk=manage_invitations_profile" 
data-li-url="/profile/mini-profile-with-connections?_ed=0_3fIDL9gCh6b5R-c9s4-e_B&amp;amp;trk=manage_invitations_miniprofile" 
class="miniprofile" 
aria-label="View profile for Ivan Grigorov"&gt;
&lt;span&gt;Ivan Grigorov&lt;/span&gt;
&lt;/a&gt;
&lt;/h3&gt;
&lt;p class="entity-subheader"&gt;
Teacher
&lt;/p&gt;
&lt;/div&gt;
</code></pre>
<p>I have used the following commands:</p>
<pre><code>with open("C:\Users\pv\MyFiles\HTML\Invites.html","r") as Invites: soup = bs(Invites, 'lxml')
soup.title
out: &lt;title&gt;Sent Invites\n| LinkedIn\n&lt;/title&gt;
invites = soup.find_all("div", class_ = "entity-body")
type(invites)
out: bs4.element.ResultSet
len(invites)
out: 0
</code></pre>
<p>Why find_all returns empty ResultSet object?</p>
<p>Your advice will be appreciated.</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem is that the document is not read, it is a just <code>TextIOWrapper</code> (<a href="https://docs.python.org/3/library/io.html" rel="nofollow noreferrer">Python 3</a>) or <code>File</code>(<a href="https://docs.python.org/2/tutorial/inputoutput.html" rel="nofollow noreferrer">Python 2)</a> object. You have to read the documet and pass markup, essentily a <code>string</code> to <code>BeautifulSoup</code>.</p>
<p>The correct code would be:</p>
<pre><code>with open("C:\Users\pv\MyFiles\HTML\Invites.html", "r") as Invites:
    soup = BeautifulSoup(Invites.read(), "html.parser")
    soup.title
    invites = soup.find_all("div", class_="entity-body")
    len(invites)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import bs4

html = '''&lt;div class="entity-body"&gt;
&lt;h3 class="entity-name with-profile"&gt;
&lt;a href="https://www.linkedin.com/profile/view?id=AA4AAAAC9qXUBMuA3-txf-cKOPsYZZ0TbWJkhgfxfpY&amp;amp;trk=manage_invitations_profile" 
data-li-url="/profile/mini-profile-with-connections?_ed=0_3fIDL9gCh6b5R-c9s4-e_B&amp;amp;trk=manage_invitations_miniprofile" 
class="miniprofile" 
aria-label="View profile for Ivan Grigorov"&gt;
&lt;span&gt;Ivan Grigorov&lt;/span&gt;
&lt;/a&gt;
&lt;/h3&gt;
&lt;p class="entity-subheader"&gt;
Teacher
&lt;/p&gt;
&lt;/div&gt;'''

soup = bs4.BeautifulSoup(html, 'lxml')
invites = soup.find_all("div", class_ = "entity-body")
len(invites)
</code></pre>
<p>out:</p>
<pre><code>1
</code></pre>
<p>this code works fine</p>
</div>
<span class="comment-copy">Try viewing page when You fetch it. If You can't see this <code>div</code> tag there, it would mean this part is generated using <code>JS</code>, so You wouldn't be able to scrape it this way (You'd have to use <code>selenium</code>).</span>
<span class="comment-copy">I changed the code as you suggested but I still get len(invites) to be 0.</span>
<span class="comment-copy">I get 1. Maybe add a <code>print</code>statement: <code>print(len(invites))</code>(Python 3) or <code>print len(invites)</code> (Python 2).</span>
<span class="comment-copy">Then the problem lies with the statement that reads the html page and converts it to a soup object.  It is strange because I have copied this syntax from a book and I have tested it with another html page.  The html page is produced by Chrome through the Save as... command when right clicking the webpage opened in the browser.  What is going wrong?</span>
<span class="comment-copy">@gk7  Can you provide the full HTML code or URL of that page</span>
<span class="comment-copy">Thanks for the reply.  The webpage is: <a href="https://www.linkedin.com/people/invite" rel="nofollow noreferrer">linkedin.com/people/invite</a></span>
<span class="comment-copy">@gk7 I got 404.</span>
<span class="comment-copy">If you are a linkedin user you must log in and using this address will get the people you have invited to connect with you but have not answered as of now.  You can experiment with this feature by sending some invitations -- if it is empty.</span>
