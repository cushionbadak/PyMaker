<div class="post-text" itemprop="text">
<p>Im trying to scape multiple pages of a football website. All the links are are in the list teamLinks. An example of one of the links is: '<a href="http://www.premierleague.com//clubs/1/Arsenal/squad?se=79" rel="nofollow noreferrer">http://www.premierleague.com//clubs/1/Arsenal/squad?se=79</a>'.
I was just wondering if it was possible to make the requests function wait until the page is fully updated before it is implemented. If you click on the link it will display initially the 2018/2019 squad and then refresh to the 2017/2018 squad which is the one i want.    </p>
<pre><code>playerLink1 = []
playerLink2 = []

for i in range(len(teamLinks)):

    # Request
    squadPage = requests.get(teamlinks[i])
    squadTree = html.fromstring(squadPage.content)

    #Extract the player links.
    playerLocation = squadTree.cssselect('.playerOverviewCard')

    #For each player link within the team page.
    for i in range(len(playerLocation)):

        #Save the link, complete with domain.
        playerLink1.append("http://www.premierleague.com/" + 
        playerLocation[i].attrib['href'] + '?se=79')
        #For the second link, change the page from player overview to stats
        playerLink2.append(playerLink1[i].replace("overview", "stats"))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The page you are trying to scrap is using Javascript to load the player list which you want.  </p>
<p><strong>Option 1:</strong> You can use this new module called <a href="https://pypi.org/project/requests-html/" rel="nofollow noreferrer">requests-html</a>(never tried myself)  which claims to support Javascript.</p>
<p><strong>Option 2:</strong> Using devtools of Chrome, I could find the actual XHR request made by page to get the player list. This code can get your required output with requests module.</p>
<pre><code>import json
playerLink1 = []
playerLink2 = []
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.75 Safari/537.36',
'Origin': 'https://www.premierleague.com',
'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
'Referer': 'https://www.premierleague.com//clubs/1/Arsenal/squad?se=79'}

res = requests.get('https://footballapi.pulselive.com/football/teams/1/compseasons/79/staff?altIds=true&amp;compCodeForActivePlayer=EN_PR', headers=headers)

player_data = json.loads(res.content.decode('utf-8'))

for player in player_data['players']:
    href = 'https://www.premierleague.com/players/{}/{}/'.format(player['id'], player['name']['display'].replace(' ', '-'))
    playerLink1.append("http://www.premierleague.com/" + href + "overview" + '?se=79')
    playerLink2.append(href + "stats")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I have found one solution.You have to use selenium <code>webdriver</code> in <code>headless</code> mode and get the <code>page_source</code> from driver and give some <code>time.sleep()</code>.I have checked the data it showing as expected.</p>
<p>However I don't know your url list so you can create your list and try that.Let me know if you need further helps.</p>
<pre><code>from selenium import webdriver
from bs4 import BeautifulSoup
import time

teamlinks=['http://www.premierleague.com//clubs/1/Arsenal/squad?se=79','http://www.premierleague.com//clubs/1/Arsenal/squad?se=54']
playerLink1 = []
playerLink2 = []


    for i in range(len(teamlinks)):
        chrome_options = webdriver.ChromeOptions()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('window-size=1920x1080');
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(teamlinks[i])
        time.sleep(10)
        squadPage=driver.page_source
        soup = BeautifulSoup(squadPage, 'html.parser')
        playerLocation = soup.findAll('a', class_=re.compile("playerOverviewCard"))
        for i in range(len(playerLocation)):

            #Save the link, complete with domain.
            playerLink1.append("http://www.premierleague.com/" +
            playerLocation[i]['href'] + '?se=79')
            #For the second link, change the page from player overview to stats
            playerLink2.append(playerLink1[i].replace("overview", "stats"))
        driver.quit()
    print(playerLink2)
</code></pre>
</div>
<span class="comment-copy">Yes this worked perfectly however without the addition of "<a href="http://www.premierleague.com/" rel="nofollow noreferrer">premierleague.com</a>" and  '?se=79' to the url</span>
<span class="comment-copy">Actually, I saw such addition in your code in question. Anyways, if you have found solution to your problem then please select an answer to close the question.</span>
<span class="comment-copy">Thank you! This worked as well.</span>
