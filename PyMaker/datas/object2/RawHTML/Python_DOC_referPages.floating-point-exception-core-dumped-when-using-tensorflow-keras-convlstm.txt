<div class="post-text" itemprop="text">
<p>I'm trying to train a ConvLSTM model with tensorflow.keras but I get a Floating point exception (core dumped)</p>
<p><strong>System information</strong></p>
<ul>
<li>OS Platform and Distribution: Ubuntu 18.04, docker</li>
<li>TensorFlow installed from: tensorflow docker: latest-gpu</li>
<li>Python version: 2.7</li>
<li>CUDA/cuDNN version: 10.0/7</li>
<li>GPU model and memory: RTX 2080, Memory: 8G</li>
<li>Nvidia Driver version: 418</li>
</ul>
<p>For reappearing the crash, I use mnist and format it as the same structure of my dataset.</p>
<h3>Here is my code</h3>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import ConvLSTM2D, BatchNormalization, Dense, Flatten
from tensorflow.keras.optimizers import SGD
from tensorflow.keras import utils, regularizers
from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler
from tensorflow.keras import backend as K

from tensorflow.keras.datasets import mnist

from tensorflow.compat.v1 import ConfigProto
from tensorflow.compat.v1 import InteractiveSession
config = ConfigProto()
config.gpu_options.allow_growth = True
session = InteractiveSession(config=config)
K.set_session(session)  # set this TensorFlow session as the default session for Keras


window_len = 50

# load capg dba data
(x_train, y_train), (x_test, y_test) = mnist.load_data()


x_train = x_train.reshape(x_train.shape[0], 1, 28, 28, 1)
x_train = x_train.repeat(window_len, axis=1)

x_test = x_test.reshape(x_test.shape[0], 1, 28, 28, 1)
x_test = x_test.repeat(window_len, axis=1)

y_train = utils.to_categorical(y_train, 10)
y_test = utils.to_categorical(y_test, 10)
print(x_train.shape)
print(y_train.shape)

print(x_test.shape)
print(y_test.shape)


model = Sequential()
model.add(ConvLSTM2D(filters=32, kernel_size=(3,3), input_shape=(window_len, 28, 28, 1), padding='same',
                     activation='relu', activity_regularizer=regularizers.l1(l=0.01), name='convlstm_1'))
model.add(Flatten())
# model.add(BatchNormalization(momentum=0.9, name='bn_1'))
model.add(Dense(10, activation='softmax'))

sgd = SGD(clipnorm=1, clipvalue=0.5, momentum=0.9)
model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

def learning_rate_tuner(epoch):
    lr = 0.01
    if 20 &lt;= epoch &lt; 40:
        lr = 0.001
    elif epoch &gt;= 40:
        lr = 0.0001
    return lr

lr_scheduler = LearningRateScheduler(learning_rate_tuner)

history = model.fit(x_train, y_train, batch_size=32, epochs=200, validation_data=(x_test, y_test),
                    callbacks=[lr_scheduler])


# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()
</code></pre>
<p>Because there is no backtrace for python, I use gdb get a backtrace,</p>
<pre><code>Thread 47 "python" received signal SIGFPE, Arithmetic exception.
[Switching to Thread 0x7fe613fff700 (LWP 2125)]
0x00007fe7668a190b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
(gdb) bt
#0  0x00007fe7668a190b in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#1  0x00007fe7668a1dc2 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#2  0x00007fe766a38f7e in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#3  0x00007fe7668910ab in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#4  0x00007fe766891512 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#5  0x00007fe7669e35b6 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#6  0x00007fe7667a33eb in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#7  0x00007fe7667a3668 in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#8  0x00007fe7667a36ae in ?? () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#9  0x00007fe766912c80 in cuLaunchKernel () from /usr/lib/x86_64-linux-gnu/libcuda.so.1
#10 0x00007fe79e565dc2 in cudart::cudaApiLaunchKernelCommon(void const*, dim3, dim3, void**, unsigned long, CUstream_st*, bool) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007fe79e565fb7 in cudart::cudaApiLaunchKernel(void const*, dim3, dim3, void**, unsigned long, CUstream_st*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007fe79e59a41b in cudaLaunchKernel () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007fe79dacd013 in tensorflow::Status tensorflow::CudaLaunchKernel&lt;int, float const*, tensorflow::functor::Dimension&lt;3&gt;, float*, int, float const*, tensorflow::functor::Dimension&lt;3&gt;, float*&gt;(void (*)(int, float const*, tensorflow::functor::Dimension&lt;3&gt;, float*), dim3, dim3, unsigned long, CUstream_st*, int, float const*, tensorflow::functor::Dimension&lt;3&gt;, float*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007fe79dada19f in tensorflow::functor::ReverseTransformFilter&lt;Eigen::GpuDevice, float, 4&gt;::operator()(Eigen::GpuDevice const&amp;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float const, 4, 1, long&gt;, 16, Eigen::MakePointer&gt;, Eigen::TensorMap&lt;Eigen::Tensor&lt;float, 4, 1, long&gt;, 16, Eigen::MakePointer&gt;) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#15 0x00007fe79d60e2da in tensorflow::LaunchConv2DBackpropFilterOp&lt;Eigen::GpuDevice, float&gt;::operator()(tensorflow::OpKernelContext*, bool, bool, tensorflow::Tensor const&amp;, tensorflow::Tensor const&amp;, int, int, int, int, tensorflow::Padding const&amp;, std::vector&lt;long long, std::allocator&lt;long long&gt; &gt; const&amp;, tensorflow::Tensor*, tensorflow::TensorFormat) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#16 0x00007fe79d60f38c in tensorflow::Conv2DSlowBackpropFilterOp&lt;Eigen::GpuDevice, float&gt;::Compute(tensorflow::OpKernelContext*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#17 0x00007fe79594a96b in tensorflow::BaseGPUDevice::ComputeHelper(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#18 0x00007fe79594b732 in tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#19 0x00007fe7959a39b1 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#20 0x00007fe7959a3bfa in std::_Function_handler&lt;void (), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(absl::InlinedVector&lt;tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, 8ul, std::allocator&lt;tensorflow::(anonymous namespace)::ExecutorState::TaggedNode&gt; &gt; const&amp;, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#21 0x00007fe795a2fc46 in Eigen::ThreadPoolTempl&lt;tensorflow::thread::EigenEnvironment&gt;::WorkerLoop(int) ()
   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#22 0x00007fe795a2eb04 in std::_Function_handler&lt;void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function&lt;void ()&gt;)::{lambda()#1}&gt;::_M_invoke(std::_Any_data const&amp;) () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/../libtensorflow_framework.so
#23 0x00007fe7d2b6dc80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#24 0x00007fe7e55446ba in start_thread (arg=0x7fe613fff700) at pthread_create.c:333
#25 0x00007fe7e527a41d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
</code></pre>
<p>At the beginning I thought it is an exploding gradient problem, so I added <code>clipnorm</code> and <code>clipvalue</code>, but it still crashed. Then I tried shorter sequence, like 20, the crash occurred, it trained longer, but it still crashed after several epochs. I tried other tensorflow version, 1.13.1 in nvidia-docker and got the same problem. Is it my model setting problem or my code is wrong?</p>
<p>Thanks,</p>
</div>
<div class="post-text" itemprop="text">
<p>Solve it, the problem is the nvidia driver. I reinstall the driver 410 and fix the problem. Now I'm using tensorflow 1.13.1 gpu version, cuda 10.0, cudnn 7.4.</p>
</div>
