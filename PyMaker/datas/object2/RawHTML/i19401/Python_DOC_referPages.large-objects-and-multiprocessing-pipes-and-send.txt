<div class="post-text" itemprop="text">
<p>I've recently found out that, if we create a pair of parent-child connection objects by using <code>multiprocessing.Pipe</code>, and if an object <code>obj</code> we're trying to send through the pipe is too large, my program hangs without throwing exception or doing anything at all. See code below. (The code below uses the <code>numpy</code> package to produce a large array of floats.)</p>
<pre><code>import multiprocessing as mp
import numpy as np

def big_array(conn, size=1200):
    a = np.random.rand(size)
    print "Child process trying to send array of %d floats." %size
    conn.send(a)
    return a

if __name__ == "__main__":
    print "Main process started."
    parent_conn, child_conn = mp.Pipe()
    proc = mp.Process(target=big_array, args=[child_conn, 1200])
    proc.start()
    print "Child process started."
    proc.join()
    print "Child process joined."
    a = parent_conn.recv()
    print "Received the following object."
    print "Type: %s. Size: %d." %(type(a), len(a))
</code></pre>
<p>The output is the following.</p>
<pre><code>Main process started.
Child process started.
Child process trying to send array of 1200 floats.
</code></pre>
<p>And it hangs here indefinitely. However, if instead of 1200, we try to send an array with 1000 floats, then the program executes successfully, with the following output as expected.</p>
<pre><code>Main process started.
Child process started.
Child process trying to send array of 1000 floats.
Child process joined.
Received the following object.
Type: &lt;type 'numpy.ndarray'&gt;. Size: 1000.
Press any key to continue . . .
</code></pre>
<p>This looks like a bug to me. The documentation says the following.</p>
<blockquote>
<p>send(obj)
  Send an object to the other end of the connection which should be read using recv().</p>
<p>The object must be picklable. Very large pickles (approximately 32 MB+, though it depends on the OS) may raise a ValueError exception.</p>
</blockquote>
<p>But with my run, not even a <code>ValueError</code> exception was thrown, the program just hangs there. Moreover, the 1200-long <code>numpy</code> array is 9600 bytes big, certainly not more than 32MB! This looks like a bug. Does anyone know how to solve this problem?</p>
<p>By the way, I'm using Windows 7, 64-bit.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try to move <code>join()</code> below <code>recv()</code>:</p>
<pre><code>import multiprocessing as mp

def big_array(conn, size=1200):
    a = "a" * size
    print "Child process trying to send array of %d floats." %size
    conn.send(a)
    return a

if __name__ == "__main__":
    print "Main process started."
    parent_conn, child_conn = mp.Pipe()
    proc = mp.Process(target=big_array, args=[child_conn, 120000])
    proc.start()
    print "Child process started."
    print "Child process joined."
    a = parent_conn.recv()
    proc.join()
    print "Received the following object."
    print "Type: %s. Size: %d." %(type(a), len(a))
</code></pre>
<p>But I don't really understand why your example works even for small sizes. I was thinking that writing to pipe and then making the process to join without first reading the data from pipe will block the join. You should first receive from pipe, then join. But apparently it does not block for small sizes...?</p>
<p>Edit: from the docs (<a href="http://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming" rel="noreferrer">http://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming</a>):</p>
<p>"An example which will deadlock is the following:"</p>
<pre><code>from multiprocessing import Process, Queue

def f(q):
q.put('X' * 1000000)

if __name__ == '__main__':
    queue = Queue()
    p = Process(target=f, args=(queue,))
    p.start()
    p.join()                    # this deadlocks
    obj = queue.get()
</code></pre>
</div>
<span class="comment-copy">Similar behaviour can be observed on CentOS, but I with higher numbers and I also noticed it scales with available RAM. How much RAM do you have? What Python version?</span>
<span class="comment-copy">Python version 2.7.3. RAM is 16GB which I think is plenty!</span>
<span class="comment-copy">I've tried it on Python 3.3 as well, same problem.</span>
<span class="comment-copy">Same problem on Windows on same Python versions. On CentOS with both 2.6 I can hang around 28000 and on 2.7 I hang around 16000, but never get a <code>ValueError</code>. Perhaps a <a href="http://bugs.python.org/" rel="nofollow noreferrer">bur report</a> should be submitted.</span>
