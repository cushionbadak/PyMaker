<div class="post-text" itemprop="text">
<p>I have a script reading in a csv file with very huge fields:</p>
<pre><code># example from http://docs.python.org/3.3/library/csv.html?highlight=csv%20dictreader#examples
import csv
with open('some.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
</code></pre>
<p>However, this throws the following error on some csv files:</p>
<pre><code>_csv.Error: field larger than field limit (131072)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The csv file might contain very huge fields, therefore increase the <code>field_size_limit</code>:</p>
<pre><code>import sys
import csv

csv.field_size_limit(sys.maxsize)
</code></pre>
<p><code>sys.maxsize</code> works for Python 2.x and 3.x. <code>sys.maxint</code> would only work with Python 2.x (<a href="https://stackoverflow.com/questions/13795758/what-is-sys-maxint-in-python-3">SO: what-is-sys-maxint-in-python-3</a>)</p>
<h3>Update</h3>
<p>As Geoff pointed out, the code above might result in the following error: <code>OverflowError: Python int too large to convert to C long</code>. 
To circumvent this, you could use the following <em>quick and dirty</em> code (which should work on every system with Python 2 and Python 3):</p>
<pre><code>import sys
import csv
maxInt = sys.maxsize

while True:
    # decrease the maxInt value by factor 10 
    # as long as the OverflowError occurs.

    try:
        csv.field_size_limit(maxInt)
        break
    except OverflowError:
        maxInt = int(maxInt/10)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This could be because your CSV file has embedded single or double quotes. If your CSV file is tab-delimited try opening it as:</p>
<pre><code>c = csv.reader(f, delimiter='\t', quoting=csv.QUOTE_NONE)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Below is to check the current limit</p>
<pre><code>csv.field_size_limit()
</code></pre>
<p>Out[20]: 131072</p>
<p>Below is to increase the limit. Add it to the code</p>
<pre><code>csv.field_size_limit(100000000)
</code></pre>
<p>Try checking the limit again</p>
<pre><code>csv.field_size_limit()
</code></pre>
<p>Out[22]: 100000000</p>
<p>Now you won't get the error "_csv.Error: field larger than field limit (131072)"</p>
</div>
<div class="post-text" itemprop="text">
<p><em>csv</em> field sizes are controlled via <a href="https://docs.python.org/3/library/csv.html#csv.field_size_limit" rel="nofollow noreferrer">[Python 3]: csv.<strong>field_size_limit</strong>(<em>[new_limit]</em>)</a>:</p>
<blockquote>
<p>Returns the current maximum field size allowed by the parser. If <em>new_limit</em> is given, this becomes the new limit.</p>
</blockquote>
<p>It is set by default to <strong><em>128k</em></strong> or <strong><em>0x20000</em></strong> (<em>131072</em>), which should be enough for any decent <em>.csv</em>:</p>
<blockquote>
<pre class="lang-py prettyprint-override"><code>&gt;&gt;&gt; import csv
&gt;&gt;&gt; csv.field_size_limit()
131072
</code></pre>
</blockquote>
<p>However, when dealing with a <em>.csv</em> file (<strong>with the correct <em>quoting</em> and <em>delimiter</em></strong>) having (at least) one field longer than this size, the error pops up. <br/>To get rid of the error, the size limit should be increased (to avoid any worries, the maximum possible value is attempted).</p>
<p>Behind the scenes (check <a href="https://github.com/python/cpython/blob/master/Modules/_csv.c" rel="nofollow noreferrer">[GitHub]: python/cpython - (master) cpython/Modules/_csv.c</a> for implementation details), the variable that holds this value is a <em>C <strong>long</strong></em></p></div>
<div class="post-text" itemprop="text">
<p>Sometimes, a row contain double quote column. When csv reader try read this row, not understood end of column and fire this raise.
Solution is below:</p>
<pre><code>reader = csv.reader(cf, quoting=csv.QUOTE_MINIMAL)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Find the cqlshrc file usually placed in .cassandra directory.</p>
<p>In that file append,</p>
<pre><code>[csv]
field_size_limit = 1000000000
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I just had this happen to me on a 'plain' CSV file. Some people might call it an invalid formatted file. No escape characters, no double quotes and delimiter was a semicolon.</p>
<p>A sample line from this file would look like this:</p>
<blockquote>
<p>First cell; Second " Cell with one double quote and leading
  space;'Partially quoted' cell;Last cell</p>
</blockquote>
<p>the single quote in the second cell would throw the parser off its rails. What worked was:</p>
<pre><code>csv.reader(inputfile, delimiter=';', doublequote='False', quotechar='', quoting=csv.QUOTE_NONE)
</code></pre>
</div>
<span class="comment-copy">Even better would be to consider <i>why</i> there are such big fields  Is that expected in your data? Sometimes errors like these are indicative of a different problem.  I had some Bad Data in mine that included a random double quote character and thus had to use the QUOTE_NONE option shown in another answer here.</span>
<span class="comment-copy">I updated my question to indicate that in my case huge fields might occur. There is no bad data in the csv file.</span>
<span class="comment-copy">@dustmachine Such things happen because sometimes you find people storing images (or other binary files) in base64 format in database tables.</span>
<span class="comment-copy">On Windows 7 64bit with Python 2.6, <code>maxInt = sys.maxsize</code> returns <code>9223372036854775807L</code> which consequently results in a <code>TypeError: limit must be an integer</code> when calling <code>csv.field_size_limit(maxInt)</code>. Interestingly, using <code>maxInt = int(sys.maxsize)</code> does not change this. A crude workaround is to simlpy use <code>csv.field_size_limit(2147483647)</code> which of course cause issues on other platforms. In my case this was adquat to identify the broken value in the CSV, fix the export options in the other application and remove the need for  <code>csv.field_size_limit()</code>.</span>
<span class="comment-copy">This is the right answer in most cases</span>
<span class="comment-copy">Thank you!!  If you are using csvkit (an excellent python library and command-line csv toolkit) and get the original error because your file uses unbalanced single or double quotes, you can select QUOTE_NONE via the <code>-u 3</code> command line option, aka <code>--quoting 3</code></span>
<span class="comment-copy">simply didn't work for me</span>
