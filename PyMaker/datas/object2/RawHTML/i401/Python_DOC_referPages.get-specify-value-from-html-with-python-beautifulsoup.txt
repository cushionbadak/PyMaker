<div class="post-text" itemprop="text">
<p>Im new in scrapping,
And am doing some scrapping project and I trying to get value from the Html Below:</p>
<pre><code>&lt;div class="buttons_zoom"&gt;&lt;div class="full_prod"&gt;&lt;a href="javascript:void(0)" onclick="js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')" title="לחם אחיד פרוס אנג'ל 750 גרם - פרטים נוספים"&gt;&lt;img alt="פרטים נוספים" border="0" src="template/images/new_site/icon-view-prod-cartpage.png"/&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
</code></pre>
<p>i want to get this value :
379104
which located in onclick
im using BeautifulSoup 
The code:</p>
<pre><code> for i in page_content.find_all('div', attrs={'class':'prodPrice'}):
            temp = i.parent.parent.contents[0]
</code></pre>
<p>temp return list of objects and temp= to the Html Above
can someone help to extract this id
thanks!!</p>
<p>Edit******
Wow guys thanks for amazing explanation!!!!!  but i have 2 issues 1.retry mechanism that no working i set it to timeout=1 in order to make it fail but once its fail its return: </p>
<pre><code>requests.exceptions.RetryError: HTTPSConnectionPool(host='www.XXXXX.il', port=443): Max retries exceeded with url: /default.asp?catid=%7B2234C62C-BD68-4641-ABF4-3C225D7E3D81%7D (Caused by ResponseError('too many redirects',)) 
</code></pre>
<p>can you please help me with retry mechanism code below : 2. perfromance issues witout the retry mechanism when im set timeout=6 scrapping duration of 8000 items taking 15 minutes how i can improve this code performance ? Code below:</p>
<pre><code>def get_items(self, dict):
        itemdict = {}
        for k, v in dict.items():
            boolean = True
        # here, we fetch the content from the url, using the requests library
            while (boolean):
             try:
                a =requests.Session()
                retries = Retry(total=3, backoff_factor=0.1, status_forcelist=[301,500, 502, 503, 504])
                a.mount(('https://'), HTTPAdapter(max_retries=retries))
                page_response = a.get('https://www.XXXXXXX.il' + v, timeout=1)
             except requests.exceptions.Timeout:
                print  ("Timeout occurred")
                logging.basicConfig(level=logging.DEBUG)
             else:
                 boolean = False

            # we use the html parser to parse the url content and store it in a variable.
            page_content = BeautifulSoup(page_response.content, "html.parser")
            for i in page_content.find_all('div', attrs={'class':'prodPrice'}):
                parent = i.parent.parent.contents[0]
                getparentfunc= parent.find("a", attrs={"href": "javascript:void(0)"})
                itemid = re.search(".*'(\d+)'.*", getparentfunc.attrs['onclick']).groups()[0]
                itemName = re.sub(r'\W+', ' ', i.parent.contents[0].text)
                priceitem = re.sub(r'[\D.]+ ', ' ', i.text)
                itemdict[itemid] = [itemName, priceitem]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>from bs4 import BeautifulSoup as bs
import re

txt = """&lt;div class="buttons_zoom"&gt;&lt;div class="full_prod"&gt;&lt;a href="javascript:void(0)" onclick="js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')" title="לחם אחיד פרוס אנג'ל 750 גרם - פרטים נוספים"&gt;&lt;img alt="פרטים נוספים" border="0" src="template/images/new_site/icon-view-prod-cartpage.png"/&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;"""

soup = bs(txt,'html.parser')
a = soup.find("a", attrs={"href":"javascript:void(0)"})
r = re.search(".*'(\d+)'.*", data).groups()[0]
print(r) # will print '379104'
</code></pre>
<hr/>
<p>Edit</p>
<p>Replaced <code>".*\}.*,.*'(\d+)'\).*"</code> with <code>".*'(\d+)'.*"</code>. They produce the same result but the latter is much cleaner.</p>
<hr/>
<h1>Explanation : Soup</h1>
<p><code>find</code> the (first) element w/ an <code>a</code> tag where the attribute "href" has "javascript:void(0)" as its value. More about <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kwargs" rel="nofollow noreferrer">beautiful soup keyword arguments here</a>.  </p>
<pre><code>a = soup.find("a", attrs={"href":"javascript:void(0)"})
</code></pre>
<p>This is equivalent to</p>
<pre><code>a = soup.find("a", href="javascript:void(0)")
</code></pre>
<blockquote>
<p>In older versions of Beautiful Soup, which don’t have the class_ shortcut, you can use the attrs trick mentioned above. Create a dictionary whose value for “class” is the string (or regular expression, or whatever) you want to search for. -- <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#attrs" rel="nofollow noreferrer">see beautiful soup documentation about "attrs"</a></p>
</blockquote>
<p><code>a</code> points to an element of type <code>&lt;class 'bs4.element.Tag'&gt;</code>. We can access the tag attributes like we would do for a dictionary via the property <code>a.attrs</code> (more about that at <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#attributes" rel="nofollow noreferrer">beautiful soup attributes</a>). That's what we do in the following statement.  </p>
<pre><code>a_tag_attributes = a.attrs # that's the dictionary of attributes in question...
</code></pre>
<p>The dictionary keys are named after the tags attributes. Here we have the following keys/attributes name : 'title', 'href' and 'onclick'.<br/>
We can check that out for ourselves by printing them.  </p>
<pre><code>print(a_tag_attributes.keys()) # equivalent to print(a.attrs.keys())
</code></pre>
<p>This will output</p>
<pre><code>dict_keys(['title', 'href', 'onclick']) # those are the attributes names (the keys to our dictionary)
</code></pre>
<p>From here, we need to get the data we are interested in. The key to our data is "onclick" (it's named after the html attribute where the data we seek lays).  </p>
<pre><code>data = a_tag_attributes["onclick"] # equivalent to data = a.attrs["onclick"] 
</code></pre>
<p><code>data</code> now holds the following string.  </p>
<pre><code>"js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')"
</code></pre>
<h1>Explanation : Regex</h1>
<p>Now that we have isolated the piece that contains the data we want, we're going to extract just the portion we need.<br/>
We'll do so by using a regular expression (<a href="https://www.regular-expressions.info/" rel="nofollow noreferrer">this site is an excellent resource if you want to know more about Regex, good stuff</a>).</p>
<p>To use regular expression in Python we
must import the Regex module <code>re</code>. More about the "re" module <a href="https://docs.python.org/3/library/re.html" rel="nofollow noreferrer">here, good good stuff</a>.</p>
<pre><code>import re
</code></pre>
<p>Regex lets us search a string that matches a pattern.  </p>
<p>Here the string is our data, and the pattern is <code>".*'(\d+)'.*"</code> (which is also a string as you can tell by the use of the double quotes).</p>
<blockquote>
<p>You can think of regular expressions as wildcards on steroids. You are probably familiar with wildcard notations such as <code>*.txt</code> to find all text files in a file manager. The regex equivalent is <code>^.*\.txt$</code>.</p>
</blockquote>
<p>Best you read about regular expressions to further understand what it is about. Here's a <a href="https://www.regular-expressions.info/quickstart.html" rel="nofollow noreferrer">quick start, good good good stuff</a>.</p>
<p>Here we <code>search</code> for a string. We describe the string as having none or an infinite number of characters. Those characters are followed by some digits (at least one) and an enclosed in single quotes. Then we have some more characters.  </p>
<p>The parenthesis is used to extract a group (that's called capturing in regex), we capture just the part that's a number.  </p>
<blockquote>
<p>By placing part of a regular expression inside round brackets or parentheses, you can group that part of the regular expression together. This allows you to apply a quantifier to the entire group or to restrict alternations to part of the regex.<br/>
  Only parentheses can be used for grouping. Square brackets define a character class, and curly braces are used by a quantifier with specific limits. -- <a href="https://www.regular-expressions.info/brackets.html" rel="nofollow noreferrer">Use Parentheses for Grouping and Capturing</a></p>
</blockquote>
<pre><code>r = re.search(".*'(\d+)'.*", data)
</code></pre>
<p>Defining the symbols :  </p>
<p>.* matches any character (except for line terminators), * means there can be none or infinite amount<br/>
' matches the character '<br/>
\d+ matches a least one digit (equal to [0-9]); that's the part we capture<br/>
(\d+) Capturing Group; this means capture the part of the string where a digit is repeated at least one<br/>
() are used for capturing, the part that match the pattern within the parentheses are saved. </p>
<p>The part captured (if any) can later be access with a call to <code>r.groups()</code> on the result of a <code>re.search</code>.<br/>
This returns a tuple containing what was captured or <code>None</code>(<code>r</code> refers to the results of the <code>re.search</code> function call).    </p>
<p>In our case the first (and only) item of the tuple are the digits...  </p>
<pre><code>captured_group = r.groups()[0] # that's the tuple containing our data (we captured...)
</code></pre>
<p>We can now access our data which is at the first index of the tuple (we only captured one group)</p>
<pre><code> print(captured_group[0]) # this will print out '379104'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Both solutions below assume regular/consistent structure to the <code>onclick</code> attribute</p>
<p>If there can only be one match then something like the following.</p>
<pre><code>from bs4 import BeautifulSoup as bs

html ='''    
&lt;div class="buttons_zoom"&gt;&lt;div class="full_prod"&gt;&lt;a href="javascript:void(0)" onclick="js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')" title="לחם אחיד פרוס אנג'ל 750 גרם - פרטים נוספים"&gt;&lt;img alt="פרטים נוספים" border="0" src="template/images/new_site/icon-view-prod-cartpage.png"/&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;

'''    
soup = bs(html, 'lxml')
element = soup.select_one('[onclick^="js:getProdID"]')
print(element['onclick'].split(',')[2].strip(')'))
</code></pre>
<p>If more than one match</p>
<pre><code>from bs4 import BeautifulSoup as bs

html ='''
&lt;div class="buttons_zoom"&gt;&lt;div class="full_prod"&gt;&lt;a href="javascript:void(0)" onclick="js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')" title="לחם אחיד פרוס אנג'ל 750 גרם - פרטים נוספים"&gt;&lt;img alt="פרטים נוספים" border="0" src="template/images/new_site/icon-view-prod-cartpage.png"/&gt;&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;
'''
soup = bs(html, 'lxml')
elements = soup.select('[onclick^="js:getProdID"]')
for element in elements:
    print(element['onclick'].split(',')[2].strip(')'))
</code></pre>
</div>
<span class="comment-copy">So appreciate can you explain please this 2 lines : a = soup.find("a", attrs={"href":"javascript:void(0)"}) r = re.search(".*\}.*,.*'(\d+)').*", a.attrs['onclick']).groups()[0]</span>
<span class="comment-copy">Sure. I'll add somme comments to my code to give some explanation.</span>
<span class="comment-copy">I added some explanation...</span>
<span class="comment-copy">Wow guys thanks for amazing explanation!!!!!  but i have 2 issues 1.retry mechanism that no working i set it to timeout=1 in order to make it fail but once its fail its return: requests.exceptions.RetryError: HTTPSConnectionPool(host='www.XXXXX.il', port=443): Max retries exceeded with url: /default.asp?catid=%7B2234C62C-BD68-4641-ABF4-3C225D7E3D81%7D (Caused by ResponseError('too many redirects',))  can you please help me with retry mechanism code below : 2. perfromance issues witout the retry mechanism when im set timeout=6 scrapping duration of 8000 items taking 15 minutes</span>
<span class="comment-copy">Thanks Remy can you also help with the performance issue and retry mechanism</span>
<span class="comment-copy">Did you try this? It is more efficient, faster and reliable then using regex which you should <a href="https://stackoverflow.com/a/1732454/6241235">avoid</a> when dealing with html.</span>
<span class="comment-copy">You are correct, one should not use Regex to parse HTML. That's the reason why I used BeautifulSoup to parse the HTML and make my way to the piece of data I'm interested in, which is <code>"js:getProdID('https://www.XXXXXXX.co.il','{31F93B1D-449F-4AD7-BFB0-97A0A8E068F6}','379104')"</code>.  The data does not contain any HTML (it is clean, it's just a plain string), from this point I'm allowed to use whatever method gets the job done. You chose to use <code>split</code> and <code>strip</code> (which is a valid answer, that's the first solutions I went for as well) that's why I've up-voted your answer.</span>
<span class="comment-copy">But I chose to use a regular expression instead. You could argue that I'm killing a fly with a bazooka, that's an argument to which I would concede. But that gets the job done and cleanly at that.</span>
<span class="comment-copy">OP never mentioned he/she was after performance. I'm not convinced that your method is more efficient. The way I see it, <code>split</code> have to search the string in order to find the character to split on. It must then create a <code>list</code> containing of as many strings as there are split character plus one.  <code>strip</code> would have a similar mechanic as well (from my understanding at least). That's a lot of moving pieces IMO, I fail to see why you claim that your solution is more efficient. Could you please explain ?</span>
<span class="comment-copy">Don't worry about it, thank you for your apology. I have to admit I doubted my self a bit and thought that question more thoroughly... And that's thanks to you, it was a good exercise, thank you.</span>
