<div class="post-text" itemprop="text">
<p>Let's say I have a dictionary of strings as keys and values as integers.
Where keys will be distinct strings encountered and how many times they are encountered.</p>
<p>For example: <code>"word word word"</code> would produce: <code>{"word" : 3}</code></p>
<p>I want to say for the variables:</p>
<pre><code>item -&gt; our dictionary
string -&gt; word encountered
</code></pre>
<p>Â </p>
<pre><code>if string in item:
    # increase existing keys' value by 1
    item.update({string, item.get(string) + 1})

else:
    # create the key and initialize value to 1
    item.update({string : 1})
</code></pre>
<p>This algorithm is slow because hashing happens twice by calling the <code>update</code> and <code>string in item</code> method, would be faster if when python performs the hashing to check if string exists in item either increase the value by 1 if a key exists there or create the key and put value as 1.</p>
<p>In Java the corresponding method would be:</p>
<pre><code>item.merge(string, 1, Integer::sum)
</code></pre>
<p>Reduces code from an <code>if-else</code> statement to just one line and skips hashing again.
Just wondering if such method exists in python 3.</p>
<p>Thanks in advance!  </p>
</div>
<div class="post-text" itemprop="text">
<p>I did some timing analysis using different ways to fill the dictionary. First, the setup:</p>
<pre><code>import collections, re    
lorem = "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum."
words = re.findall("\w+", lorem.lower())
</code></pre>
<p>Now, the functions, using your approach with <code>update</code>, or just using <code>+=</code>, or <a href="https://docs.python.org/3/library/stdtypes.html#dict.get" rel="nofollow noreferrer"><code>get</code></a> with default, as well as <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>defaultdict</code></a> and <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>Counter</code></a>:</p>
<pre><code>def f1():
    d = {}
    for w in words:
        if w in d:
            d.update({w: d[w] + 1})
        else:
            d.update({w: 1})
    return d

def f2():
    d = {}
    for w in words:
        if w in d:
            d[w] += 1
        else:
            d[w] = 1
    return d

def f3():
    d = {}
    for w in words:
        d[w] = d.get(w, 0) + 1
    return d

def f4():
    d = collections.defaultdict(int)
    for w in words:
        d[w] += 1
    return d

def f5():
    return collections.Counter(words)
</code></pre>
<p>They all produce the same result, although the last two use a subclass of <code>dict</code>:</p>
<pre><code>In [41]: f1() == f2() == f3() == f4() == f5()
Out[41]: True
</code></pre>
<p>Using <code>update</code> is pretty wasteful here; <code>+=</code> is fastest, even with the <code>in</code> check, whereas <code>defaultdict</code> and <code>Counter</code> are shorter, but also slower.</p>
<pre><code>In [42]: %timeit f1()
10000 loops, best of 3: 81.8 us per loop

In [43]: %timeit f2()
10000 loops, best of 3: 24.8 us per loop

In [44]: %timeit f3()
10000 loops, best of 3: 40.8 us per loop

In [45]: %timeit f4()
10000 loops, best of 3: 52.6 us per loop

In [46]: %timeit f5()
10000 loops, best of 3: 104 us per loop
</code></pre>
<p>Note, however, that in this example text, most words occur only once, which might skew the tests. Using <code>words = words * 100</code>, we get this, making <code>Counter</code> less slow, and <code>defaultdict</code> the fastest.</p>
<pre><code>In [2]: %timeit f1()
100 loops, best of 3: 8.21 ms per loop

In [3]: %timeit f2()
100 loops, best of 3: 2.76 ms per loop

In [4]: %timeit f3()
100 loops, best of 3: 3.58 ms per loop

In [5]: %timeit f4()
100 loops, best of 3: 2.13 ms per loop

In [6]: %timeit f5()
100 loops, best of 3: 6.11 ms per loop
</code></pre>
<p>Still, personally I'd use <code>Counter</code> as the difference in running time is probably not much of a problem, it's the shortest, the intention is immediately clear, and it also provides some useful helper methods, like getting most common entries and such.</p>
</div>
<div class="post-text" itemprop="text">
<p>Idiomatic Python would be</p>
<pre><code>from collections import defaultdict
d = defaultdict(int)
for word in "word word word".split():
    d[word] += 1
</code></pre>
</div>
<span class="comment-copy">"This algorithm is slow because hashing happens twice" What makes you think that this has any measurable effect?</span>
<span class="comment-copy">Because I've had the same exact if-else statement in Java and when I switched to the merge function I got considerable amount of performance increase so I would assume same thing would happen in python.</span>
<span class="comment-copy">Personally, I'd rather think that using <code>update</code> makes your code slow. Why create a new dict to merge into the old one, when you can just use <code>item[string] += 1</code> or <code>item[string] = 1</code>? Or use <code>defaultdict</code> or <code>Counter</code>.</span>
<span class="comment-copy">Thanks for the advice, I just started learning python today and already went ahead implementing this: <a href="http://nifty.stanford.edu/2017/guerzhoy-SAT-synonyms/" rel="nofollow noreferrer">nifty.stanford.edu/2017/guerzhoy-SAT-synonyms</a>  as a challenge without any knowledge of the language.</span>
<span class="comment-copy">both f2() and f4() gave 2x performance increase! I went with f4() because it doesn't branch.</span>
<span class="comment-copy"><i>Truly</i> idiomatic Python would be <code>d = collections.Counter("word word word".split())</code>.</span>
<span class="comment-copy">or perhaps <code>d = collections.Counter(word.lower() for word in re.findall(r"\w", "word word word"))</code></span>
