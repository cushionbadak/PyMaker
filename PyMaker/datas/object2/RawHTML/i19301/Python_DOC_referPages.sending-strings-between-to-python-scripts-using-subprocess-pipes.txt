<div class="post-text" itemprop="text">
<p>I want to open a Python script using subprocess in my main python program. I want these two programs to be able to chat with one another as they are both running so I can monitor the activity in the slave script, i.e. I need them to send strings between each other.</p>
<p>The main program will have a function similar to this that will communicate with and monitor the slave script:</p>
<p><strong>Script 1</strong></p>
<pre><code>import subprocess
import pickle
import sys
import time
import os

def communicate(clock_speed, channel_number, frequency):
    p = subprocess.Popen(['C:\\Python27\\pythonw','test.py'], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
    data = pickle.dumps([clock_speed, channel_number, frequency]).replace("\n", "\\()")
    print data
    p.stdin.write("Start\n")
    print p.stdout.read()
    p.stdin.write(data + "\n")
    p.poll()
    print p.stdout.readline()
    print "return:" + p.stdout.readline()
    #p.kill()

if __name__ == '__main__':
    print "GO"
    communicate(clock_speed = 400, channel_number = 0, frequency = 5*1e6)
</code></pre>
<p>The test.py script looks similar to this:</p>
<p><strong>Script 2</strong></p>
<pre><code>import ctypes
import pickle
import time
import sys

start = raw_input("")
sys.stdout.write("Ready For Data")
data = raw_input("")
data = pickle.loads(data.replace("\\()", "\n"))
sys.stdout.write(str(data))
###BUNCH OF OTHER STUFF###
</code></pre>
<p>What I want these scripts to do is the following:</p>
<ol>
<li>Script 1 to open Script 2 using Popen</li>
<li>Script 1 sends the string "Start\n"</li>
<li>Script 2 reads this string and sends the string "Ready For Data"</li>
<li>Script 1 reads this string and sends the pickled data to Script 2</li>
<li>Then whatever...</li>
</ol>
<p>The main question is how to do parts 2-4. Then the rest of the communication between the two scripts should follow. As of now, I have only been able to read the strings from Script 2 after it has been terminated.</p>
<p>Any help is greatly appreciated.</p>
<p><strong>UPDATE:</strong></p>
<p>Script 1 must be run using 32-bit Python, while Script 2 must be run using 64-bit Python.</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem with pipes is that if you call a read operation and there is nothing to read, your code is stalled until the other party writes something for you to read. Also if you write too much, your next write operation might block until the other party reads something out of the pipe and frees it.</p>
<p>There are "non-blocking calls" you can make, that will return an error in these cases instead of blocking, but your application will still need to deal with the errors sensibly.</p>
<p>In any case, you need to set up some kind of <strong>protocol</strong>. Think of HTTP, or any other protocol you know well: there are requests and responses, and while you are reading either of the two the protocol always tells you if there is something else you need to read or not. That way you can always make an informed decision on whether to wait for more data or not.</p>
<p>Here is an example that works. It works because there is the following protocol:</p>
<ul>
<li>p1 sends a single line, ending with '\n';</li>
<li>p2 does the same;</li>
<li>p1 sends another line;</li>
<li>p2 does the same;</li>
<li>both are happy and exit.</li>
</ul>
<p>In order to write a line to the pipe (on either side) and make sure it gets onto the pipe, I call <code>write()</code> and then <code>flush()</code>.</p>
<p>In order to read a single line from the pipe (on either side) but not a single byte more, thus blocking my code until the line is ready and no longer than that, I use <code>readline()</code>.</p>
<p>There are other calls you could make and other protocols, including ready-made ones, but the single-line protocol works well for simple things and for a demo like this.</p>
<p>p1.py:</p>
<pre><code>import subprocess

p = subprocess.Popen(['python', 'p2.py'], stdin=subprocess.PIPE, stdout=subprocess.PIPE)
p.stdin.write("Hello\n")
p.stdin.flush()
print 'got', p.stdout.readline().strip()
p.stdin.write("How are you?\n")
p.stdin.flush()
print 'got', p.stdout.readline().strip()
</code></pre>
<p>p2.py:</p>
<pre><code>import sys

data = sys.stdin.readline()
sys.stdout.write("Hm.\n")
sys.stdout.flush()
data = sys.stdin.readline()
sys.stdout.write("Whatever.\n")
sys.stdout.flush()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I also had a problem similar to this, where there was no way to send general Python objects between different processes without running into the problem of knowing either when the other side hasn't sent an object or is closed. Also trying to use <code>multiprocessing.Queue</code> usually means that the process needs to have been started by the current process which is not always the case when two processes want to collaborate.</p>
<p>To combat this I use the <a href="https://pypi.python.org/pypi/picklepipe" rel="nofollow noreferrer"><code>picklepipe</code></a> module, which defines a generic object serialization pipe interface as well as a pipe that uses the <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer"><code>pickle</code></a> protocol called the <code>PicklePipe</code> (also one that uses the <a href="https://docs.python.org/3/library/marshal.html" rel="nofollow noreferrer"><code>marshal</code></a> protocol called <code>MarshalPipe</code>). It can send more than just strings, it can send any pickleable object to it's peer.</p>
<p>The pipes are even selectable, meaning they can be used by the <code>selectors</code> module (or <code>selectors2</code>, <code>selectors34</code>) as file objects when a new object is ready to be received. This makes waiting for many different pipes to be ready very efficient.</p>
<p>Supports Python 2.7+ (and probably 2.6) and all major platforms. Can even send objects between two different versions of Python! Check out the <a href="http://picklepipe.readthedocs.io/en/latest/" rel="nofollow noreferrer">project documentation</a> or <a href="https://github.com/SethMichaelLarson/picklepipe" rel="nofollow noreferrer">view the source on Github</a>.</p>
<p>Disclosure: I am the author of <code>picklepipe</code>. I would love to hear your feedback. :)</p>
</div>
<span class="comment-copy">Could you use the <a href="http://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing module</a> which is designed to run python in supbrocesses</span>
<span class="comment-copy">The reason why I am using subprocess is because I need the second script to be run using 64-bit Python, while the main script is run in 32-bit Python. It is a driver issue. I did not think that multiprocessing allowed for this.</span>
<span class="comment-copy">I think I had a similar problem with a threadpool running in python and each thread "communicating" with some node.js workers -- what worked for me was to <code>flush()</code> the stdout after each <code>write()</code> since otherwise, buffering delayed everything until the streams were closed.</span>
<span class="comment-copy">It allows calls to other machines so possibly <a href="http://docs.python.org/2/library/multiprocessing.html#using-a-remote-manager" rel="nofollow noreferrer">docs.python.org/2/library/â€¦</a></span>
<span class="comment-copy">There might be issues with <code>"\n"</code> on Windows: whether <code>.readline()</code> understands newline characters produced by other end (<code>b"\n"</code> &lt;--&gt; <code>b"\r\n"</code> conversions).</span>
<span class="comment-copy">Excellent answer. Thank you. Also, the "\n" works on Windows for me (in case anyone reading this for reference is worried about this issue).</span>
