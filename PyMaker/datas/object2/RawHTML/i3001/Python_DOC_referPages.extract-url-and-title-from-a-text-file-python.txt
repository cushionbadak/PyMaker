<div class="post-text" itemprop="text">
<p>I have a text file in the following manner: </p>
<pre><code>&lt;a href="https://en.wikipedia.org/wiki/Scotland" h="ID=SERP,5161.1"&gt;Scotland - Wikipedia
&lt;a href="https://www.visitscotland.com/" h="ID=SERP,5177.1"&gt;VisitScotland - Official Site
&lt;a href="https://www.bbc.co.uk/news/scotland" h="ID=SERP,5191.1"&gt;BBC Scotland News - Official Site
&lt;a href="https://www.lonelyplanet.com/scotland" h="ID=SERP,5207.1"&gt;Scotland travel - Lonely Planet
</code></pre>
<p>From this text file, I want to extract the URLs i.e only the main domain like 'en.wikipedia.org','www.bbc.co.uk' etc into Links.txt </p>
<p>And the Title i.e 'Scotland - Wikipedia','VisitScotland - Official Site' etc into Titles.txt </p>
<p>I'm new to regex, tried using some regex function to extract but wasn't successful.</p>
</div>
<div class="post-text" itemprop="text">
<p>Explanation of this regexps <a href="https://regex101.com/r/7AxZVQ/1" rel="nofollow noreferrer">here</a> and <a href="https://regex101.com/r/7AxZVQ/2" rel="nofollow noreferrer">here</a>. Assuming your data is stored in <code>data.txt</code>:</p>
<pre><code>import re

with open('data.txt', 'r', newline='') as f_in, \
    open('links.txt', 'w', newline='') as links_out, \
    open('titles.txt', 'w', newline='') as titles_out:

    data = f_in.read()

    for link in re.findall(r'(?:href=")([^"]+)', data):
        links_out.write(link + '\n')

    for title in re.findall(r'(?:&gt;)(.*?)$', data, flags=re.M):
        titles_out.write(title + '\n')
</code></pre>
<p>In titles.txt you will have:</p>
<pre><code>Scotland - Wikipedia
VisitScotland - Official Site
BBC Scotland News - Official Site
Scotland travel - Lonely Planet
</code></pre>
<p>In links.txt you will have:</p>
<pre><code>https://en.wikipedia.org/wiki/Scotland
https://www.visitscotland.com/
https://www.bbc.co.uk/news/scotland
https://www.lonelyplanet.com/scotland
</code></pre>
<p>Note:
The parsing of HTML document is better done and more robust with <code>BeautifulSoup</code> or similar libraries.</p>
<p>EDIT:</p>
<p>To parse only domains, you can use <code>urllib.urlparse</code>:</p>
<pre><code># on the top:
from urllib.parse import urlparse

for link in re.findall(r'(?:href=")([^"]+)', data):
    url = urlparse(link)
    links_out.write(url.scheme + '://' + url.netloc + '\n')
</code></pre>
<p>The links.txt will look:</p>
<pre><code>https://en.wikipedia.org
https://www.visitscotland.com
https://www.bbc.co.uk
https://www.lonelyplanet.com
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If your file is an html file you can use Beautifulsoup</p>
<pre><code>from bs4 import BeautifulSoup

html = #YOUR FILE HERE

soup = BeautifulSoup(html)
links = soup.find_all('a')

for tag in links:
    link = tag.get('href',None)
    if link is not None:
        #Do whatever with the link
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import re
s = """&lt;a href="https://en.wikipedia.org/wiki/Scotland" h="ID=SERP,5161.1"&gt;Scotland - Wikipedia
&lt;a href="https://www.visitscotland.com/" h="ID=SERP,5177.1"&gt;VisitScotland - Official Site
&lt;a href="https://www.bbc.co.uk/news/scotland" h="ID=SERP,5191.1"&gt;BBC Scotland News - Official Site
&lt;a href="https://www.lonelyplanet.com/scotland" h="ID=SERP,5207.1"&gt;Scotland travel - Lonely Planet"""

links = re.findall(r"href=\"(.*?)\"", s)
titles = re.findall(r"&gt;(.*)", s)
print(links)
print(titles)
</code></pre>
<p>Write To File</p>
<pre><code>with open("links.txt", "w") as links_file, open("titles.txt", "w") as titles_file:
    links_file.write("\n".join(links))
    titles_file.write("\n".join(titles))
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>['https://en.wikipedia.org/wiki/Scotland', 'https://www.visitscotland.com/', 'https://www.bbc.co.uk/news/scotland', 'https://www.lonelyplanet.com/scotland']
['Scotland - Wikipedia', 'VisitScotland - Official Site', 'BBC Scotland News - Official Site', 'Scotland travel - Lonely Planet']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Even though regex solutions will work, using regex to parse HTML is <strong>almost always</strong> a bad idea. You can get all sorts of issues if previously unexpected symbols are encountered or tags have additional arguments, etc.</p>
<p>Here's a way to do it with python's built-in libraries for parsing HTML and URLs.
Used modules are <a href="https://docs.python.org/3/library/html.parser.html" rel="nofollow noreferrer">html.parser</a> and <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse" rel="nofollow noreferrer">urllib.parse</a></p>
<pre><code>from html.parser import HTMLParser
from urllib.parse import urlparse

class URLTitleParser(HTMLParser):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.links = []
        self.titles = []

    def handle_starttag(self, tag, attrs):
        if tag.lower() != 'a':
            return

        for key, value in attrs:
            if key == 'href':
                url = urlparse(value)
                self.links.append(url.hostname)
                break

    def handle_data(self, data):
        self.titles.append(data.strip())


if __name__ == '__main__':
    parser = URLTitleParser()

    with open('data.txt') as data:
        parser.feed(data.read())

    with open('links.txt', 'w') as links:
        links.write('\n'.join(parser.links))

    with open('titles.txt', 'w') as titles:
        titles.write('\n'.join(parser.titles))
</code></pre>
</div>
<span class="comment-copy"><a href="https://pythex.org" rel="nofollow noreferrer">pythex.org</a> should be quite helpful in the future</span>
<span class="comment-copy">And what have you tried so far to solve the problem? :)</span>
<span class="comment-copy">It works!!. There is a package called tldextract in python to shorten the url or to extract only the main domain.I'll try using that too. thanks!</span>
<span class="comment-copy">@raven I updated my answer, you can use urllib.urlparse for extracting only domains</span>
<span class="comment-copy">thanks! @Andrej</span>
<span class="comment-copy">It works!!. Thanks a lot</span>
<span class="comment-copy">You are welcome :)</span>
