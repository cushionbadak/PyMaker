<div class="post-text" itemprop="text">
<p>The <code>Python</code> code below executes in about <code>2 sec</code>. An equivalent code in <code>C</code> executes in <code>6 ms</code>.</p>
<p>Some explanations: I have serial data of 2 <code>ADC</code> channels (<code>adc0</code>, <code>adc1</code>, <code>adc0</code>, <code>adc1</code>, ...).
If <code>adc1 &lt;= 10</code> I must add <code>adc1</code> to the sum, else I must add <code>adc0</code>. These values are multiplied by different coefficients (<code>0.1</code> and <code>0.01</code>).</p>
<pre><code>#!/usr/bin/env python
import time
import numpy as np 

dd = np.random.randint(0, 20, size=(2*1000*1000))

t_start = time.clock()

avg_sum1 = 0.0
BlockOffset = 0     
while BlockOffset &lt; len(dd):
    if dd[BlockOffset + 1] &lt;= 10:
        avg_sum1 += dd[BlockOffset + 1] * 0.1
    else:
        avg_sum1 += dd[BlockOffset + 0] * 0.01
    BlockOffset += 2

print('Avg: ' + str(avg_sum1 / len(dd) / 2))    
print('Exe time: ' + str(time.clock() - t_start))
</code></pre>
<p>What is fastest way to do this with built-in functions or <code>numpy</code>?</p>
</div>
<div class="post-text" itemprop="text">
<p>Firstly you need to fix your average calc (operator precedence):</p>
<pre><code>avg_sum1 / (len(dd) / 2)  # or avg_sum1 / len(dd) * 2

Out[]:
0.31740819000001924
2.8 s ± 28.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
</code></pre>
<p>You can do this in <code>numpy</code>, e.g.:</p>
<pre><code>In []:
np.where(dd[1::2] &lt;= 10, dd[1::2]*0.1, dd[0::2]*0.01).mean()

Out[]:
0.31740818999999987
10.8 ms ± 61.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are many ways to speed it up. Here is a solution using <code>pandas</code> (maybe that can also be done using just <code>numpy</code>).</p>
<p>In this code, <code>f1()</code> is your original function and <code>f2()</code> is using <code>pandas</code>.</p>
<pre><code>import numpy as np
import pandas as pd
import time

def f1(data):
    t_start = time.perf_counter()

    offset = 0
    sum_1 = 0.0
    while offset &lt; data.shape[0]:
        if data[offset + 1] &lt;= 10:
            sum_1 += data[offset + 1] * 0.1
        else:
            sum_1 += data[offset + 0] * 0.01
        offset += 2
    n = data.shape[0] / 2
    avg_1 = sum_1 / n

    t_end = time.perf_counter()

    return {
        'calc_time': t_end - t_start,
        'n': n,
        'sum': sum_1,
        'avg': avg_1,
    }

def f2(data):
    t_start = time.perf_counter()

    df = pd.DataFrame()
    df['adc0'] = data[0::2]     # every second element, starting at 0
    df['adc1'] = data[1::2]     # every second element, starting at 1

    df['sum_value'] = np.where(
        df['adc1'] &lt;= 10,
        df['adc1'] * 0.1,
        df['adc0'] * 0.01)
    sum_1 = df['sum_value'].sum()
    n = df.shape[0]
    avg_1 = sum_1 / n

    t_end = time.perf_counter()

    return {
        'calc_time': t_end - t_start,
        'n': n,
        'sum': sum_1,
        'avg': avg_1,
    }

if __name__ == '__main__':
    numbers = np.random.randint(0, 20, size=(2*1000*1000))

    r = f1(numbers)
    print(r)
    r = f2(numbers)
    print(r)
</code></pre>
<p>This code shows that <code>f2()</code> is faster, using about <code>123 ms</code> (less than 10% of the time of <code>f1()</code>).</p>
<pre><code># f1
{'avg': 0.31791369000003045, 'n': 1000000.0, 'sum': 317913.69000003044,
 'calc_time': 4.765112441743648}
# f2
{'avg': 0.31791368999999986, 'n': 1000000, 'sum': 317913.68999999989,
 'calc_time': 0.12356162259120662}
</code></pre>
<p><strong>Obs:</strong> I assume that the difference of <code>sum</code> and <code>avg</code> between the two functions originates in how the float precision is handled, but I don't know for sure.
How many decimal places do you need to consider for your use case? Does this small difference matter?</p>
</div>
<span class="comment-copy">Although the question may be on-topic here, <a href="https://codereview.stackexchange.com/">Code Review</a> might be more suitable for your demonstrated needs.</span>
<span class="comment-copy">Please add some written explanation of what your code needs to do, also expected output.</span>
<span class="comment-copy">You should not time your code using <a href="https://docs.python.org/3/library/time.html#time.clock" rel="nofollow noreferrer"><code>time.clock()</code></a>. Prefer using <a href="https://docs.python.org/3/library/time.html#time.perf_counter" rel="nofollow noreferrer"><code>time.perf_counter()</code></a> or the <a href="https://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer"><code>timeit</code> module</a></span>
<span class="comment-copy">Thank you Mathias.  But for me need increase computing speed.</span>
<span class="comment-copy">I tested both solution on my machine:        f1   Avg: 0.31760221000002087   Exe time: 1.982864   f2(AChampion)   Avg: 0.3176022100000002   Exe time: 0.017103   f3(Ralf)   {'sum': 317602.2100000002, 'avg': 0.3176022100000002, 'calc_time':   0.07925199999999988, 'n': 1000000}</span>
<span class="comment-copy">Note: <code>0.1235...</code> is about <code>123ms</code> - <code>0.002</code> would be <code>2ms</code>.</span>
<span class="comment-copy">Note:  input data for f1 and f2 same, but sum and avg difference. Why?</span>
<span class="comment-copy">@AChampion your right, I mixed up my conversion. I corrected the time in my answer.</span>
<span class="comment-copy">@Darius I added a note to my answer. In short: I am not sure where the difference comes from.</span>
<span class="comment-copy">@Ralf  posible answer her: <a href="https://docs.python.org/2/tutorial/floatingpoint.html" rel="nofollow noreferrer">docs.python.org/2/tutorial/floatingpoint.html</a></span>
