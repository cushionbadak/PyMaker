<div class="post-text" itemprop="text">
<p>I'm trying to import a large size of JSON FILE from Amazon S3 into AWS RDS-PostgreSQL using Python. But, these errors occured,</p>
<blockquote>
<p>Traceback (most recent call last):</p>
<p>File "my_code.py", line 67, in </p>
<p>file_content = obj['Body'].read().decode('utf-8').splitlines(True)</p>
<p>File "/home/user/asd-to-qwe/fgh-to-hjk/env/local/lib/python3.6/site-packages/botocore/response.py", line 76, in read</p>
<p>chunk = self._raw_stream.read(amt)</p>
<p>File "/home/user/asd-to-qwe/fgh-to-hjk/env/local/lib/python3.6/site-packages/botocore/vendored/requests/packages/urllib3/response.py", line 239, in read</p>
<p>data = self._fp.read()</p>
<p>File "/usr/lib64/python3.6/http/client.py", line 462, in read</p>
<p>s = self._safe_read(self.length)</p>
<p>File "/usr/lib64/python3.6/http/client.py", line 617, in _safe_read</p>
<p>return b"".join(s)</p>
<p>MemoryError</p>
</blockquote>
<p>// my_code.py</p>
<pre><code>import sys
import boto3
import psycopg2
import zipfile
import io
import json

s3 = boto3.client('s3', aws_access_key_id=&lt;aws_access_key_id&gt;, aws_secret_access_key=&lt;aws_secret_access_key&gt;)
connection = psycopg2.connect(host=&lt;host&gt;, dbname=&lt;dbname&gt;, user=&lt;user&gt;, password=&lt;password&gt;)
cursor = connection.cursor()

bucket = sys.argv[1]
key = sys.argv[2]
obj = s3.get_object(Bucket=bucket, Key=key)

def insert_query(data):
    query = """
        INSERT INTO data_table
        SELECT
            (src.test-&gt;&gt;'url')::varchar, (src.test-&gt;&gt;'id')::bigint,
            (src.test-&gt;&gt;'external_id')::bigint, (src.test-&gt;&gt;'via')::jsonb
        FROM (SELECT CAST(%s AS JSONB) AS test) src
    """
    cursor.execute(query, (json.dumps(data),))


if key.endswith('.zip'):
    zip_files = obj['Body'].read()
    with io.BytesIO(zip_files) as zf:
        zf.seek(0)
        with zipfile.ZipFile(zf, mode='r') as z:
            for filename in z.namelist():
                with z.open(filename) as f:
                    for line in f:
                        insert_query(json.loads(line.decode('utf-8')))
if key.endswith('.json'):
    file_content = obj['Body'].read().decode('utf-8').splitlines(True)
    for line in file_content:
        insert_query(json.loads(line))


connection.commit()
connection.close()
</code></pre>
<p>Are there any solutions to these problems? Any help would do, thank you so much!</p>
</div>
<div class="post-text" itemprop="text">
<p>A significant savings can be had by avoiding slurping your whole input file into memory as a <code>list</code> of lines.</p>
<p>Specifically, these lines are terrible on memory usage, in that they involve a peak memory usage of a <code>bytes</code> object the size of your whole file, plus a <code>list</code> of lines with the complete contents of the file as well:</p>
<pre><code>file_content = obj['Body'].read().decode('utf-8').splitlines(True)
for line in file_content:
</code></pre>
<p>For a 1 GB ASCII text file with 5 million lines, on 64 bit Python 3.3+, that's a peak memory requirement of roughly 2.3 GB for <em>just</em> the <code>bytes</code> object, the <code>list</code>, and the individual <code>str</code>s in the <code>list</code>. A program that needs 2.3x as much RAM as the size of the files it processes won't scale to large files.</p>
<p>To fix, change that original code to:</p>
<pre><code>file_content = io.TextIOWrapper(obj['Body'], encoding='utf-8')
for line in file_content:
</code></pre>
<p>Given that <a href="https://boto3.readthedocs.io/en/latest/reference/services/s3.html?highlight=get_object#S3.Client.get_object" rel="nofollow noreferrer"><code>obj['Body']</code> appears to be usable for lazy streaming</a> this should remove <em>both</em> copies of the complete file data from memory. Using <code>TextIOWrapper</code> means <code>obj['Body']</code> is lazily read and decoded in chunks (of a few KB at a time), and the lines are iterated lazily as well; this reduces memory demands to a small, largely fixed amount (the peak memory cost would depend on the length of the longest line), regardless of file size.</p>
<p><strong>Update:</strong></p>
<p>It looks like <code>StreamingBody</code> doesn't implement the <code>io.BufferedIOBase</code> ABC. It does have <a href="https://botocore.readthedocs.io/en/latest/reference/response.html" rel="nofollow noreferrer">its own documented API</a> though, that can be used for a similar purpose. If you can't make the <code>TextIOWrapper</code> do the work for you (it's much more efficient and simple if it can be made to work), an alternative would be to do:</p>
<pre><code>file_content = (line.decode('utf-8') for line in obj['Body'].iter_lines())
for line in file_content:
</code></pre>
<p>Unlike using <code>TextIOWrapper</code>, it doesn't benefit from bulk decoding of blocks (each line is decoded individually), but otherwise it should still achieve the same benefits in terms of reduced memory usage.</p>
</div>
<span class="comment-copy">Possible duplicate of <a href="https://stackoverflow.com/questions/51549272/importing-large-size-of-zipped-json-file-from-amazon-s3-into-aws-rds-postgresql">Importing Large Size of Zipped JSON File from Amazon S3 into AWS RDS-PostgreSQL Using Python</a></span>
<span class="comment-copy">The Zipped File is the problem in there. But in here, it's the JSON File. The method read() is the problem when reading the JSON file, I always get the Memory Error. Is there anymore ways to read the JSON file? Thank you</span>
<span class="comment-copy">It's raising an error.   Traceback (most recent call last): File "my_code.py", line 67, in &lt;module&gt; file_content = io.TextIOWrapper(obj['Body'], encoding='utf-8') AttributeError: 'StreamingBody' object has no attribute 'readable'</span>
<span class="comment-copy">@GeraldMilan: Ugh. They made a kinda file-like object that isn't actually compatible with <a href="https://docs.python.org/3/library/io.html#class-hierarchy" rel="nofollow noreferrer">the <code>io</code> ABCs</a>. You could wrap the <code>StreamingBody</code> in a simple file-like class that implemented <a href="https://docs.python.org/3/library/io.html#io.BufferedIOBase" rel="nofollow noreferrer">the <code>BufferedIOBase</code> ABC</a>, or if it's already really close to what you need, monkey-patch in the necessary stuff (e.g. <code>obj['Body'].readable = True</code> to set that specific attribute).</span>
<span class="comment-copy">@GeraldMilan: If that doesn't work, or it's too complicated, I updated the answer to provide an alternative that works with <a href="https://botocore.readthedocs.io/en/latest/reference/response.html" rel="nofollow noreferrer">the <code>StreamingBody</code> API</a>.</span>
<span class="comment-copy">It now works, sir. Thank you very much!</span>
