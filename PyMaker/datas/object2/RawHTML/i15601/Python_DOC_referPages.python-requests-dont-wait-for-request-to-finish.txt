<div class="post-text" itemprop="text">
<p>In Bash, it is possible to execute a command in the background by appending <code>&amp;</code>. How can I do it in Python?</p>
<pre><code>while True:
    data = raw_input('Enter something: ') 
    requests.post(url, data=data) # Don't wait for it to finish.
    print('Sending POST request...') # This should appear immediately.
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I use <code>multiprocessing.dummy.Pool</code>. I create a singleton thread pool at the module level, and then use <code>pool.apply_async(requests.get, [params])</code> to launch the task.</p>
<p>This command gives me a future, which I can add to a list with other futures indefinitely until I'd like to collect all or  some of the results.</p>
<p><code>multiprocessing.dummy.Pool</code> is, against all logic and reason, a THREAD pool and not a process pool.</p>
<p>Example (works in both Python 2 and 3, as long as requests is installed):</p>
<pre><code>from multiprocessing.dummy import Pool

import requests

pool = Pool(10) # Creates a pool with ten threads; more threads = more concurrency.
                # "pool" is a module attribute; you can be sure there will only
                # be one of them in your application
                # as modules are cached after initialization.

if __name__ == '__main__':
    futures = []
    for x in range(10):
        futures.append(pool.apply_async(requests.get, ['http://example.com/']))
    # futures is now a list of 10 futures.
    for future in futures:
        print(future.get()) # For each future, wait until the request is
                            # finished and then print the response object.
</code></pre>
<p>The requests will be executed concurrently, so running all ten of these requests should take no longer than the longest one. This strategy will only use one CPU core, but that shouldn't be an issue because almost all of the time will be spent waiting for I/O.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here's a hacky way to do it:</p>
<pre><code>try:
    requests.get("http://127.0.0.1:8000/test/",timeout=0.0000000001)
except requests.exceptions.ReadTimeout: 
    pass
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>According to the <a href="http://docs.python-requests.org/en/latest/user/advanced/#advanced" rel="nofollow">doc</a>, you should move to another library : </p>
<blockquote>
<p>Blocking Or Non-Blocking?</p>
<p>With the default Transport Adapter in place, Requests does not provide
  any kind of non-blocking IO. The Response.content property will block
  until the entire response has been downloaded. If you require more
  granularity, the streaming features of the library (see Streaming
  Requests) allow you to retrieve smaller quantities of the response at
  a time. However, these calls will still block.</p>
<p>If you are concerned about the use of blocking IO, there are lots of
  projects out there that combine Requests with one of Pythonâ€™s
  asynchronicity frameworks.</p>
<p>Two excellent examples are
  <a href="https://github.com/kennethreitz/grequests" rel="nofollow">grequests</a> and
  <a href="https://github.com/ross/requests-futures" rel="nofollow">requests-futures</a>.</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>If you can write the code to be executed separately in a separate python program, <a href="https://stackoverflow.com/questions/5611576/how-do-i-spawn-a-separate-python-process">here</a> is a possible solution based on subprocessing.</p>
<p>Otherwise you may find useful <a href="https://stackoverflow.com/questions/2846653/python-multithreading-for-dummies">this question</a> and related answer: the trick is to use the threading library to start a separate thread that will execute the separated task.</p>
<p>A caveat with both approach could be the number of items (that's to say the number of threads) you have to manage. If the <code>item</code>s in <code>parent</code> are too many, you may consider halting every batch of items till at least some threads have finished, but I think this kind of management is non-trivial.</p>
<p>For more sophisticated approach you can use an actor based approach, I have not used <a href="http://www.pykka.org/en/latest/" rel="nofollow noreferrer">this library</a> myself but I think it could help in that case.</p>
</div>
<div class="post-text" itemprop="text">
<p>Elegant solution from <a href="https://stackoverflow.com/a/27022707/2816916">Andrew Gorcester</a>. In addition, without using futures, it is possible to use the <code>callback</code> and <code>error_callback</code> attributes (see 
<a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async" rel="nofollow noreferrer">doc</a>) in order to perform asynchronous processing:</p>
<pre><code>def on_success(r: Response):
    if r.status_code == 200:
        print(f'Post succeed: {r}')
    else:
        print(f'Post failed: {r}')

def on_error(ex: Exception):
    print(f'Post requests failed: {ex}')

pool.apply_async(requests.post, args=['http://server.host'], kwargs={'json': {'key':'value'},
                        callback=on_success, error_callback=on_error))
</code></pre>
</div>
<span class="comment-copy">Unlike CPU-bound concurrency issues in Python, this could possibly be resolved with a separate thread, or the use of <code>multiprocessing.dummy</code> for a thread pool.</span>
<span class="comment-copy">Your solution looks interesting, but also confusing. What's a future? What's the module level? Could you provide a working example?</span>
<span class="comment-copy">@octosquidopus added example to answer</span>
<span class="comment-copy">Your example works well, but that is not exactly what I am trying to do. Instead of sending concurrent requests, I would like to send them one at a time, but without blocking the rest of the code. My example should be now be less ambiguous.</span>
<span class="comment-copy">I think the formatting should be <code>pool.apply_async(requests.post, [url], {'data': data})</code>. The function signature is essentially (function_to_run, list_of_positional_args, dict_of_kwargs).</span>
<span class="comment-copy"><code>r</code> isn't a response object, it's a future for a response object. You get the real response with <code>r.get()</code> -- that produces a response object that's the same as any other. If you only want the status code you could do <code>r.get().status_code</code> (note that if the request resulted in an exception, the exception will be raised when you call <code>get()</code>). You can also do <code>response = r.get()</code> and proceed as normal.  If you <code>r.get()</code> before the actual asynchronous request is complete, then you will automatically wait until the request is complete before proceeding.</span>
<span class="comment-copy">You can loss a response this way often. The question was about requests.post and its body is also more fragile with a very short timeout than a simple get.</span>
<span class="comment-copy">works well when we do not need any response from the api</span>
<span class="comment-copy">I tried requests-futures, but it fails at <code>csrf = s.cookies['csrftoken']</code>.</span>
