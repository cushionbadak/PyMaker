<div class="post-text" itemprop="text">
<p>I am using python's <code>subprocess</code> module to start a new process. I would like to capture the output of the new process in real time so I can do things with it (display it, parse it, etc.). I have seen many examples of how this can be done, some use custom file-like objects, some use <code>threading</code> and some attempt to read the output until the process has completed. </p>
<p><a href="https://stackoverflow.com/questions/2297933/creating-a-custom-sys-stdout-class"><strong>File Like Objects Example (click me)</strong></a></p>
<ul>
<li>I would prefer not to use custom file-like objects because I want to allow users to supply their own values for <code>stdin</code>, <code>stdout</code> and <code>stderr</code>.</li>
</ul>
<p><a href="https://codereview.stackexchange.com/questions/6567/how-to-redirect-a-subprocesses-output-stdout-and-stderr-to-logging-module/17959#17959"><strong>Threading Example (click me)</strong></a></p>
<ul>
<li>I do not really understand why threading is required so I am reluctant to follow this example. If someone can explain why the threading example makes sense I would be happy listen. However, this example also restricts users from supplying their own <code>stdout</code> and <code>stderr</code> values.</li>
</ul>
<p><strong>Read Output Example (see below)</strong></p>
<p>The example which makes the most sense to me is to read the <code>stdout</code>, <code>stderr</code> until the process has finished. Here is some example code: </p>
<pre><code>import subprocess

# Start a process which prints the options to the python program.
process = subprocess.Popen(
                           ["python", "-h"],
                           bufsize=1,
                           stdin=subprocess.PIPE,
                           stdout=subprocess.PIPE,
                           stderr=subprocess.PIPE,
                           )    

# While the process is running, display the output to the user.
while True:

    # Read standard output data.
    for stdout_line in iter(process.stdout.readline, ""):

        # Display standard output data.
        sys.stdout.write(stdout_line)

    # Read standard error data.
    for stderr_line in iter(process.stderr.readline, ""):

        # Display standard error data.
        sys.stderr.write(stderr_line)

    # If the process is complete - exit loop.
    if process.poll() != None:
        break
</code></pre>
<p>My question is,</p>
<p><strong>Q.</strong> Is there a recommended approach for capturing the output of a process using python?</p>
</div>
<div class="post-text" itemprop="text">
<p>First, your design is a bit silly, since you can do the same thing like this:</p>
<pre><code>process = subprocess.Popen(
                           ["python", "-h"],
                           bufsize=1,
                           stdout=sys.stdout,
                           stderr=sys.stderr
                           )
</code></pre>
<p>… or, even better:</p>
<pre><code>process = subprocess.Popen(
                           ["python", "-h"],
                           bufsize=1
                           )
</code></pre>
<p>However, I'll assume that's just a toy example, and you might want to do something more useful.</p>
<hr/>
<p>The main problem with your design is that it won't read anything from <code>stderr</code> until <code>stdout</code> is done.</p>
<p>Imagine you're driving an MP3 player that prints each track name to stdout, and logging info to stderr, and you want to play 10 songs. Do you really want to wait 30 minutes before displaying any of the logging to your users?</p>
<p>If that <em>is</em> acceptable, then you might as well just use <code>communicate</code>, which takes care of all of the headaches for you.</p>
<p>Plus, even if it's acceptable for your model, are you sure you can queue up that much unread data in the pipe without it blocking the child? On every platform?</p>
<p>Just breaking up the loop to alternate between the two won't help, because you could end up blocking on <code>stdout.readline()</code> for 5 minutes while <code>stderr</code> is piling up.</p>
<p>So that's why you need some way to read from both at once.</p>
<hr/>
<p>How do you read from two pipes at once?</p>
<p>This is the same problem (but smaller) as handling 1000 network clients at once, and it has the same solutions: threading, or multiplexing (and the various hybrids, like doing green threads on top of a multiplexor and event loop, or using a threaded proactor, etc.).</p>
<p>The best sample code for the threaded version is <a href="http://hg.python.org/cpython/file/7f176a45211f/Lib/subprocess.py#l880" rel="nofollow"><code>communicate</code></a> from the 3.2+ source code. It's a little complicated, but if you want to handle all of the edge cases properly on both Windows and Unix there's really no avoiding a bit of complexity.</p>
<p>For multiplexing, you can use the <a href="http://docs.python.org/3/library/select.html" rel="nofollow"><code>select</code></a> module, but keep in mind that this only works on Unix (you can't <code>select</code> on pipes on Windows), and it's buggy without 3.2+ (or the <code>subprocess32</code> backport), and to really get all the edge cases right you need to add a signal handler to your <code>select</code>. Unless you really, really don't want to use threading, this is the harder answer.</p>
<p>But the <em>easy</em> answer is to use someone else's implementation. There are a dozen or more modules on PyPI specifically for async subprocesses. Alternatively, if you already have a good reason to write your app around an event loop, just about every modern event-loop-driven async networking library (including the stdlib's <a href="http://docs.python.org/dev/library/asyncio.html" rel="nofollow"><code>asyncio</code></a>) includes subprocess support out of the box, that works on both Unix and Windows.</p>
<hr/>
<blockquote>
<p>Is there a recommended approach for capturing the output of a process using python?</p>
</blockquote>
<p>It depends on who you're asking; a thousand Python developers might have a thousand different answers… or at least half a dozen. If you're asking what the core devs would recommend, I can take a guess:</p>
<p>If you don't need to capture it asynchronously, use <code>communicate</code> (but make sure to upgrade to at least 3.2 for important bug fixes). If you do need to capture it asynchronously, use <code>asyncio</code> (which requires 3.4).</p>
</div>
<span class="comment-copy">Can you give a sample of input and output?</span>
<span class="comment-copy">Ha that's it! I was comparing output from different versions of python. Rookie mistake!! I removed the truncate issue from the original question. Thanks for prompting me to look a little harder.</span>
<span class="comment-copy">Lol. You're welcome!</span>
<span class="comment-copy">Whoever downvoted this, why?</span>
<span class="comment-copy">Firstly, I didn't down vote this answer. Thanks very much for your explanation. Secondly, I am hesitant to use the default io values (sys.stdout and sys.stderr) because some applications tend to override these values (in my case it is a 3D application called Maya. It has it's own python interpreter and uses some sort of custom file-like objects for the io streams). Providing subprocess.PIPE seems ensure some consistency. I will take a look at the example in python 3.2+. Thanks!</span>
<span class="comment-copy">I have posted a new question which hopefully describes my issue more specifically. Please take a look. Your input is appreciated. <a href="http://stackoverflow.com/questions/21247721/reading-output-from-child-process-using-python" title="reading output from child process using python">stackoverflow.com/questions/21247721/…</a></span>
