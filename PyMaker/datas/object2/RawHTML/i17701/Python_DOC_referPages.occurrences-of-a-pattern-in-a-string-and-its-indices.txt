<div class="post-text" itemprop="text">
<p>If I have a pattern 'haha' and a text 'hahahaha', I want the indices of the pattern to be returned in a list like [0,2,4].
However, if I do it this way</p>
<pre><code>def find_pat(text, pattern)
    import re
        return[x.start() for x in re.finditer(pattern,text)]
</code></pre>
<p>it returns [0,4], and fails to see the repetition of the pattern at index 2. 
How would I achieve the needed output in the most pythonic and efficient way?</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>pattern = "haha"
text = "hahahaha"
[i for i in range(len(text)-len(pattern)+1) if text[i:].startswith(pattern)]
</code></pre>
<p>iter will consume the tokens it has seen so it consumes the first four letters with the first match ...</p>
<p>actually the solution using the look ahead is probably the right one(based on the question rather than the usecase)  but this would also work ...</p>
</div>
<div class="post-text" itemprop="text">
<p>Use positive lookahead assertion:</p>
<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; def find_pat(text, pattern):
...     return [x.start() for x in re.finditer("(?={})".format(pattern), text)]
...
&gt;&gt;&gt; find_pat('hahahaha', 'haha')
[0, 2, 4]
&gt;&gt;&gt;
</code></pre>
<p>Here is a <a href="http://www.regular-expressions.info/lookaround.html" rel="nofollow">reference</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>As Joran Beasley's answer shows, using plain string functions will be much faster than using regexps for static string lookups.</p>
<p>But testing <code>startswith</code> N times could itself be a huge slowdown if N is very large and matches are uncommon. Also, since you were using <code>finditer</code> rather than <code>findall</code>, I suspect you may be worried about that case.</p>
<p>You can get the best of both worlds by using <a href="http://docs.python.org/3/library/stdtypes.html#str.find" rel="nofollow"><code>str.find</code></a>. Of course ultimately this is doing the same work as using <code>startswith</code> at each point—but it's doing that work in C, zipping over long stretches with no matches as much as 20x faster.</p>
<p>On the other hand, there's no way to wrap this repeated <code>find</code> up in a trivial looping expression. (Unless you build a complicated wrapper using <code>iter</code> around a closure, but I doubt that would actually help anything.) So, the code will look more complicated than Joran's listcomp. And it could be <em>slower</em> when matches are very common (because in that case you're spending most of your time in the loop, and an explicit loop statement is slower than a comprehension).</p>
<p>On the plus side, the extra verbosity means it's more obvious how to customize it. For example, if you decide you want to skip overlapped matches, just do <code>i += len(pattern)</code> instead of <code>i += 1</code>.</p>
<pre><code>def finditer(text, pattern):
    i = 0
    while True:
        i = text.find(pattern, i)
        if i == -1: return
        yield i
        i += 1
</code></pre>
<p>From a quick test (under 64-bit Apple CPython 2.7.5):</p>
<pre><code>In [931]: pattern = 'ha'
In [932]: text = 'hahahaha'
In [933]: %timeit [i for i in range(len(text)-len(pattern)+1) if text[i:].startswith(pattern)]
100000 loops, best of 3: 2.69 µs per loop
In [934]: %timeit list(finditer(text, pattern))
100000 loops, best of 3: 3.56 µs per loop
In [935]: text = ('hahahaha' + string.ascii_lowercase + 'ha')*100
pattern = 'ha'
In [936]: %timeit [i for i in range(len(text)-len(pattern)+1) if text[i:].startswith(pattern)]
100000 loops, best of 3: 1.74 ms per loop
In [937]: %timeit list(finditer(text, pattern))
100000 loops, best of 3: 180 µs per loop
</code></pre>
<p>So, it's almost as fast as Joran's code even for a very short string with 50% matches; for a much longer string with 11% matches, it's already 9.6x faster. If matches are even less common, or if we don't actually need a list, obviously it will win even bigger.</p>
</div>
<div class="post-text" itemprop="text">
<p>I'm sure there's a better way to do this. Here's my first take on it though:</p>
<p>EDIT: I misread the question -- he was trying to match [haha]haha, ha[haha]ha, and haha[haha]. Mine only matches [haha]haha and haha[haha] because I thought he was looking for unique matches. Reading comprehension is a plus, when programming.</p>
<pre><code>def find_text(text,pattern):
    indexes = list()
    index = 0
    patlen = len(pattern)
    while index&lt;=len(text)-patlen:
        if text[index:].startswith(pattern):
            indexes.append(index)
            index+=patlen
        else:
            index+=1
    return indexes
</code></pre>
</div>
<span class="comment-copy">There are likely better approaches than regex here, since you seem to only be searching for literal strings (as opposed to regexes).</span>
<span class="comment-copy">For what it's worth, your function is much faster than a regex lookup, and more correct than mine! :). with yours as <code>a</code>, mine as <code>b</code>, and iCodez's regex as <code>c</code>, <code>timeit(a) == 3.385546386501602</code>, <code>timeit(b) == 2.024211750664243</code> (but only returns [0,4]), <code>timeit(c)</code> == 4.476999654101547`</span>
<span class="comment-copy">thanks a lot! I definitely have to learn more about the re module.</span>
<span class="comment-copy">Oops, this only matches the unique patterns, like your <code>re.finditer</code>. My mistake, I misunderstood the question! @JoranBeasley's answer is likely the best. List comprehensions are MUCH faster than regex.</span>
