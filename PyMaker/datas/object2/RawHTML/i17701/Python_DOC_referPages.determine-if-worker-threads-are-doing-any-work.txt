<div class="post-text" itemprop="text">
<p>I have written a spider that takes urls from a list, loads the according pages using <code>requests</code> in separate threads using <code>concurrent.futures.ThreadPoolExecutor</code> and when a page is loaded some info is extracted from it, put into an <code>item</code> (a dictionary) and that <code>item</code> is put into a <code>Queue()</code> called <code>collected_items</code>.</p>
<p>After running a spider method that creates jobs for <code>ThreadPoolExecutor</code> in separate threads (simplified):</p>
<pre><code>def start_requests(self):

    def start_requests():
        for url in self.start_urls:
            self.start_request(url)

    self._executor = ThreadPoolExecutor(self.max_workers)
    self._executor.submit(start_requests)
</code></pre>
<p>I am waiting for the items collected by worker threads:</p>
<pre><code>spider = Spider()
spider.start_requests()

while not spider._executor._work_queue.empty() or not collected_items.empty():
    try:
        item = collected_items.get(timeout=0.25)
    except queue.Empty:
        continue
    print('Found an item %s' item)
</code></pre>
<p>However sometimes the <code>while</code> loop breaks before all the items have been collected.</p>
<p><code>spider._executor._threads</code> is a <code>set</code> of worker threads which in <code>while</code> loop take work items from <code>spider._executor._work_queue</code> and run associated callables.</p>
<p>Condition <code>not spider._executor._work_queue.empty() or not collected_items.empty()</code> is not reliable, because the work item queue in executor maybe empty as well as the collected items queue, but at the time of checking this condition an executor worker thread could have taken the last work item from <code>spider._executor._work_queue</code> and right now is doing some work that will add a collected item to <code>collected_items</code> queue (which at the moment is empty too). Or the work item queue has not received yet the first work item.</p>
<p>I don't see a way to reliably determine whether I have still to wait for new items to appear in <code>collected_items</code> or move on.</p>
<p>UPDATE:</p>
<p>I would solve this if after finishing a work item the worker thread would call <a href="http://docs.python.org/3/library/queue.html#queue.Queue.task_done" rel="nofollow"><code>work_queue.task_done()</code></a>. Unfortunately <a href="http://hg.python.org/cpython/file/37caaf21f827/Lib/concurrent/futures/thread.py#l63" rel="nofollow">it's not the case</a>.</p>
<p>I've added a comment to a related bug: <a href="http://bugs.python.org/issue14119#msg207512" rel="nofollow">http://bugs.python.org/issue14119#msg207512</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Write your worker code like this:</p>
<pre><code>def run():
    while True:
        item = work_queue.get()
        work(item)
        work_queue.task_done()
</code></pre>
<p>And use <code>queue.unfinished_tasks</code> as the condition.</p>
</div>
<span class="comment-copy">Seems a tough problem. BTW, did you typo <code>def Spider(self):</code> with <code>def start_requests(self):</code>?</span>
<span class="comment-copy">@WKPlus, no it's not a typo. I've done a closure to run the inner <code>start_requests</code> in a separate worker thread.</span>
<span class="comment-copy">Thanks for the comment. Looking through the source of <code>concurrent/futures/thread.py</code> I also thought of this. But I have to monkey patch the standard library code or duplicate it.</span>
