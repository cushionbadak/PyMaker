<div class="post-text" itemprop="text">
<p>The following python code works fine when I use it on a test dataset of a few thousand records but when I try it with an xml of about 400MB it runs out of memory. Is there a way to get it to read line by line?</p>
<pre><code>import urllib
import xml.etree.ElementTree as ET

url = raw_input('Enter - ')

value,count,total, counts =0,0,0, dict()

print "Retrieving: ", url
file=urllib.urlopen(url)
data=file.read()
print 'Retrieved',len(data),'characters'
xml=ET.fromstring(data)
tags=xml.findall('.//Postcode')
for tag in tags:
#    print tag.text
    count+=int(tag.text)
print 'Count: ', len(tags)
print 'Sum: ', count
</code></pre>
<p>This will write to sqlite3 but fails with a memory error on testing (before it gets to the DB writing process that's not included in the sample code above).</p>
<p>The data I am trying to read can be freely downloaded from <a href="http://data.gov.au/dataset/abn-bulk-extract" rel="nofollow">http://data.gov.au/dataset/abn-bulk-extract</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Which part have failed? The file.read() or ET.fromstring?</p>
<p>Easy solution (besides buying more memory) would be to save the retrieved file and use ET.parse(filename) to avoid reading the XML as a string to memory.</p>
<p>Other case is to use xml.sax API, which don't parse XML at the same time.</p>
</div>
<span class="comment-copy">Your first problem is this: <code>data=file.read()</code>.  That is where you are reading the entire result into memory.</span>
<span class="comment-copy">Take a look at <a href="https://docs.python.org/3/library/xml.etree.elementtree.html#pull-api-for-non-blocking-parsing" rel="nofollow noreferrer">docs.python.org/3/library/â€¦</a> , and it references <a href="https://docs.python.org/3/library/xml.etree.elementtree.html#xml.etree.ElementTree.iterparse" rel="nofollow noreferrer">iterparse</a>.  It looks like you can pass the file-like object returned from urlopen to ElementTree.iterparse() to do what you need.</span>
<span class="comment-copy">The "print 'Retrieved',len(data),'characters'" works so it is failing after this. I get an out of memory error. I have 16GB RAM and at least 500GB free on my drives so...It is reading the file off my hard drive (so I have already downloaded it)</span>
<span class="comment-copy">when I try "xml=ET.parse(url)" I get    &gt;&gt;File "C:\Python27\ArcGIS10.4\lib\xml\etree\ElementTree.py", line 653, in parse     data = source.read(65536) MemoryError  The issue is trying to consume the dataset line by line or I guess finding a way to chunk into a couple of pieces of 50Mb each...</span>
