<div class="post-text" itemprop="text">
<p>I'm trying to crawl a list of URLs contained in a CSV file.  The URLs are listed in column 6 in the CSV.   The format of the URLs is: <a href="https://www.targetdomain.com/mainDirectoryName/subDirectoryName/pageName" rel="nofollow">https://www.targetdomain.com/mainDirectoryName/subDirectoryName/pageName</a>.</p>
<p>I'm not reading the data in from the CSV correctly with the code below. Where am I making a coding error?</p>
<pre><code>list_of_urls = open(filename).read()

for i in range(6,len(list_of_urls)):

    try:
        url=str(list_of_urls[i][0])
        #crawl urls
        secondCrawlRequest = requests.get(url, headers=http_headers, timeout=5)

        raw_html = secondCrawlRequest.text
    except requests.ConnectionError as e:
        logging.exception(e)
    except requests.HTTPError as e:
        logging.exception(e)
    except requests.Timeout as e:
        logging.exception(e)
    except requests.RequestException as e:
        logging.exception(e)
        sys.exit(1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You should use <a href="https://docs.python.org/3/library/csv.html#csv.reader" rel="nofollow"><code>csv.reader</code></a>:</p>
<pre><code>import csv 

with open(filename, newline='') as csvfile:
    reader = csv.reader(csvfile)
    for row in reader:
        try:
            # 0-based column numbering, so 6th column is number 5
            response = requests.get(row[5], headers=http_headers, timeout=5)
            print(response.text)
        except (requests.ConnectionError, requests.HTTPError, requests.Timeout) as e:
            logging.exception(e)
        except requests.RequestException as e:
            logging.exception(e) 
            sys.exit(1)
</code></pre>
<p>If you need to skip the header row, you can do it by calling <code>next(reader)</code>:</p>
<pre><code> reader = csv.reader(csvfile)
 next(reader)  # consumes one input row discarding it
 for row in reader: ...
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>if url has no fixed occurrence with respect to column or row in csv , u can simply use regex and read file line by line as follows:</p>
<pre><code>import re
import requests

filename = 'shitty_url.csv'
with open(filename, 'r') as csvfile:
    for line in csvfile:
        url_pattern = re.search('https:\/\/(.+?) ', line)
        if url_pattern:
            found_url = url_pattern.group(1)
            url = 'https://%s' % found_url
            crawler = requests.get(url, timeout=5)
</code></pre>
<p>hope this helps :)</p>
</div>
<span class="comment-copy">The URLs start on the second row in the CSV.  How do I bypass the header row?</span>
<span class="comment-copy">@Lifeiscomplex added</span>
