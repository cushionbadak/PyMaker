<div class="post-text" itemprop="text">
<p>Using Python 2.7 and scandir, I need to traverse down all directories and subdirectories and return a list of the directories ONLY. Not the files. The depth of subdirectories in along a path may vary.</p>
<p>I am aware of os.walk, but my directory has 2 million files and therefore os.walk is to slow for this.</p>
<p>Currently the code below works for me, but I suspect there may be an easier way/loop to achieve the same result, and I'd like to know how it can be improved. Also the limitation of my function is that it is still limited by the depth I can traverse into the sub-directories, and perhaps this can be overcome. </p>
<pre><code>def list_directories(path):
dir_list = []
for entry in scandir(path):
    if entry.is_dir():
        dir_list.append(entry.path)
        for entry2 in scandir(entry.path):
            if entry2.is_dir():
                dir_list.append(entry2.path)
                for entry3 in scandir(entry2.path):
                    if entry3.is_dir():
                        dir_list.append(entry3.path)
                        for entry4 in scandir(entry3.path):
                            if entry4.is_dir():
                                dir_list.append(entry4.path)
                                for entry5 in scandir(entry4.path):
                                    if entry5.is_dir():
                                        dir_list.append(entry5.path)
                                        for entry6 in scandir(entry5.path):
                                            if entry6.is_dir():
                                                dir_list.append(entry6.path)
return dir_list
for item in filelist_dir(directory):
    print item
</code></pre>
<p>Please let me know if you have a better alternative to quickly returning all directories and sub-directories in a path that has millions of files.</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://pypi.python.org/pypi/scandir" rel="nofollow noreferrer">scandir</a> supports a <a href="https://pypi.python.org/pypi/scandir#walk" rel="nofollow noreferrer">walk()</a> function that includes the same optimizations of scandir() so it should be faster than os.walk(). (scandir's <a href="https://pypi.python.org/pypi/scandir#background" rel="nofollow noreferrer">background section</a> suggests a 3-10 time improvement on Linux/Mac OS X.)</p>
<p>So you could just use that... Something like this code might work:</p>
<pre><code>from scandir import walk

def list_directories(path):
    dir_list = []
    for root, _, _ in walk(path):
        # Skip the top-level directory, same as in your original code:
        if root == path:
            continue
        dir_list.append(root)
    return dir_list
</code></pre>
<p>If you want to implement this using scandir() instead, in order to implement something that supports an arbitrary depth you should use recursion.</p>
<p>Something like:</p>
<pre><code>from scandir import scandir

def list_directories(path):
    dir_list = []
    for entry in scandir(path):
        if entry.is_dir() and not entry.is_symlink():
            dir_list.append(entry.path)
            dir_list.extend(list_directories(entry.path))
    return dir_list
</code></pre>
<p><em>NOTE</em>: I added a check for is_symlink() too, so it doesn't traverse symlinks. Otherwise a symlink pointing to '.' or '..' would make this recurse forever...</p>
<p>I still think using scandir.walk() is better (simpler, more reliable), so if that suits you, use that instead!</p>
</div>
<div class="post-text" itemprop="text">
<p>First, to avoid that limit of 6 directories, you probably want to do this recursively:</p>
<pre><code>def list_directories(path):
    dir_list = []
    for entry in scandir(path):
        if entry.is_dir():
            dir_list.append(entry.path)
            dir_list.extend(list_directories(entry.path))
</code></pre>
<hr/>
<p>Also, since you're using Python 2.7, part of the reason <code>os.walk</code> is too slow is that Python 2.7 uses <code>listdir</code> instead of <code>scandir</code> for <code>walk</code>. The <a href="https://pypi.python.org/pypi/scandir/1.7" rel="nofollow noreferrer"><code>scandir</code> backport package</a> includes its own implementation of <code>walk</code> (basically the same one used in Python 3.5) that provides the same API as <code>walk</code> but with a major speedup (especially on Windows).</p>
<hr/>
<p>Beyond that, your main performance cost probably depends on the platform.</p>
<p>On Windows, it's mainly the cost to read the directory entries. And there's really not much you can do about it; <code>scandir</code> is already doing this the fastest way.</p>
<p>On POSIX, it's probably mainly the cost to <code>stat</code> each file to see if it's a directory. You can speed this up a bit by using <a href="http://man7.org/linux/man-pages/man3/fts.3.html" rel="nofollow noreferrer"><code>fts</code></a> (especially on Linux) But as far as I know, there are no good Python wrappers for it. If you know <code>ctypes</code>, it's not that complicated to just call it; the hard part is coming up with a good design for exposing all of its features to Python (which, of course, you don't need to do). See <a href="https://github.com/abarnert/py-fts" rel="nofollow noreferrer">my unfinished library on GitHub</a> if you want to try this yourself.</p>
<hr/>
<p>Alternatively, you might want to use <a href="https://linux.die.net/man/1/find" rel="nofollow noreferrer"><code>find</code></a> (which uses <code>fts</code> under the covers), either driving it via <a href="https://docs.python.org/3/library/subprocess.html" rel="nofollow noreferrer"><code>subprocess</code></a>, or having it drive your script.</p>
<hr/>
<p>Finally, you may want to do things in parallel. This may actually slow things down instead of speeding things up if your filesystem is, say, an old laptop hard drive as opposed to, say, two SSDs and a RAID stripe with high-end controllers. So definitely try it and see before committing too much.</p>
<p>If you're doing non-trivial work, a single walk thread queuing up directories for your worker(s) to work on is probably all you need.</p>
<p>If walking is the whole point, you'll want to pull multiple walkers in parallel. The way <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer"><code>concurrent.futures.ThreadPoolExecutor</code></a> wraps things up may just be good enough out of the box, and it's dead simple. For maximum speed, you may need to manually queue things up and pull them in batches, shard the work by physical volume, etc., but probably none of that will be necessary. (If it is, and if you can muddle through reading Rust code, <a href="https://github.com/BurntSushi/ripgrep" rel="nofollow noreferrer"><code>ripgrep</code></a> put a lot of work into navigating a filesystem as quickly as possible.)</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use python builtin module <code>os.walk</code>:</p>
<pre><code>for root, dirs, files in os.walk(".", topdown=False):
   for name in files:
      print(os.path.join(root, name))
   for name in dirs:
      #this will get your all directories within the path
      print(os.path.join(root, name))
</code></pre>
<p>For more info visit this link : <a href="https://docs.python.org/3/library/os.html#os.walk" rel="nofollow noreferrer">os.walk</a></p>
</div>
<span class="comment-copy">Check <a href="https://stackoverflow.com/questions/33135038/how-do-i-use-os-scandir-to-return-direntry-objects-recursively-on-a-directory" title="how do i use os scandir to return direntry objects recursively on a directory">stackoverflow.com/questions/33135038/â€¦</a></span>
<span class="comment-copy">Thanks @Filipe, can I please ask you to edit your answer to include an example of using scandir.walk() to perform this? Thanks again...</span>
<span class="comment-copy">@JensHiestermann: Done!</span>
<span class="comment-copy">Brilliant @Filipe, your answer has helped me.</span>
<span class="comment-copy">Thanks @abarnert... this answer is also 100% correct. Thanks for the assistance.</span>
<span class="comment-copy">The question says "I am aware of os.walk, but my directory has 2 million files and therefore os.walk is to slow for this."</span>
