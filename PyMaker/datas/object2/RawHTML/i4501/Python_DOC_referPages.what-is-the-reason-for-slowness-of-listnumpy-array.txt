<div class="post-text" itemprop="text">
<p>It is well known, that if <code>a</code> is a numpy array, then <code>a.tolist()</code> is faster than <code>list(a)</code>, for example:</p>
<pre><code>&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; big_np=np.random.randint(1,10**7,(10**7,))

&gt;&gt;&gt; %timeit list(big_np)
1 loop, best of 3: 869 ms per loop
&gt;&gt;&gt; %timeit big_np.tolist()
1 loop, best of 3: 306 ms per loop
</code></pre>
<p>That means, the naive <code>list(a)</code> version is about factor <code>3</code> slower than the special-function <code>tolist()</code>. </p>
<p>However, comparing it to the the performance of the build-in <code>array</code>-module:</p>
<pre><code>&gt;&gt;&gt; import array
&gt;&gt;&gt; big_arr=array.array('i', big_np)
&gt;&gt;&gt; %timeit list(big_arr)
1 loop, best of 3: 312 ms per loop
</code></pre>
<p>we can see, that one should probably say, that <code>list(a)</code> is slow rather than <code>tolist()</code> is fast, because <code>array.array</code> is as fast as the special function.</p>
<p>Another observation: <code>array.array</code>-module and <code>tolist</code> benefit from the <a href="https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong" rel="nofollow noreferrer">small-integer-pool</a> (i.e. when values are in range <code>[-5, 256]</code>), but this is not the case for <code>list(a)</code>:</p>
<pre><code>##only small integers:
&gt;&gt;&gt; small_np=np.random.randint(1,250, (10**7,))
&gt;&gt;&gt; small_arr=array.array('i', small_np)

&gt;&gt;&gt; %timeit list(small_np)
1 loop, best of 3: 873 ms per loop
&gt;&gt;&gt; %timeit small_np.tolist()
10 loops, best of 3: 188 ms per loop
&gt;&gt;&gt; %timeit list(small_arr)
10 loops, best of 3: 150 ms per loop
</code></pre>
<p>As we can see the faster versions are about 2 times faster, but the slow version is as slow as before.</p>
<p>My question: what slows <code>list(numpy.array)</code> down compared to <code>list(array.array)</code>?</p>
<p><strong>Edit:</strong></p>
<p>One more observation, for Python2.7, it takes longer if the integers are bigger (i.e. cannot be hold by <code>int32</code>):</p>
<pre><code>&gt;&gt;&gt; very_big=np.random.randint(1,10**7,(10**7,))+10**17
&gt;&gt;&gt; not_so_big=np.random.randint(1,10**7,(10**7,))+10**9
&gt;&gt;&gt; %timeit very_big.tolist()
1 loop, best of 3: 627 ms per loop
&gt;&gt;&gt; %timeit not_so_big.tolist()
1 loop, best of 3: 302 ms per loop
</code></pre>
<p>but still faster, than the slow list-version.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a partial answer explaining your observation re the small integer pool:</p>
<pre><code>&gt;&gt;&gt; a = np.arange(10)
&gt;&gt;&gt; type(list(a)[0])
&lt;class 'numpy.int64'&gt;
&gt;&gt;&gt; type(a.tolist()[0])
&lt;class 'int'&gt;
</code></pre>
<p>As we can see <code>tolist</code> seems to try and create elements of native python type whereas the array iterator (which is what is used by the list constructor) doesn't bother.</p>
<p>Indeed, the C implementation of <code>tolist</code> (source <a href="https://github.com/numpy/numpy/blob/cfe8772057e16994f140f587ac6c2d0e12b744f5/numpy/core/src/multiarray/convert.c" rel="nofollow noreferrer">here</a>) uses <code>PyArray_GETITEM</code> <a href="http://numpy-discussion.10968.n7.nabble.com/PyArray-GETITEM-and-PyArray-SETITEM-td44930.html" rel="nofollow noreferrer">which is the equivalent to Python <code>arr[index].item()</code>, not - as one might assume - <code>arr[index]</code></a></p>
</div>
<div class="post-text" itemprop="text">
<p>Basically, the answer of Paul Panzer explains what happens: in the slow <code>list(...)</code> version the resulting elements of the list are not python-integers, but are numpy-scalars, e.g. <code>numpy.int64</code>. This answer just elaborates a little bit and connects the dots.</p>
<p>I didn't make a systematic profiling, but when stopped in the debugger, every time both versions were in the routines which created the integer-object, so it is very probably this is where the lion's share of the execution time is spent, and the overhead doesn't play a big role.</p>
<p>The <code>list(..)</code>-version, iterator calls <a href="https://github.com/numpy/numpy/blob/1062cb2332152fe421297454559981825d4c7907/numpy/core/src/multiarray/mapping.c#L1355" rel="nofollow noreferrer"><code>array_item</code></a>, which has an special treatment for one-dimensional arrays and calls <a href="https://github.com/numpy/numpy/blob/a2bddfa976225954ba345853aa3aa3817950dafc/numpy/core/src/multiarray/scalarapi.c#L625" rel="nofollow noreferrer"><code>PyArray_Scalar</code></a>, which is a quite generic function and doesn't use the machinery of the Pythons-integer-creation. It happens to be slower than the Python-version, there is also no integer-pool for small values.</p>
<p>The <code>.tolist()</code> version calls <a href="https://github.com/numpy/numpy/blob/cfe8772057e16994f140f587ac6c2d0e12b744f5/numpy/core/src/multiarray/convert.c#L82" rel="nofollow noreferrer"><code>recursive_tolist</code></a>, which eventually uses Python's <a href="https://github.com/python/cpython/blob/dd431b32f4a599fff9c9cddfe9d48cc66b347481/Objects/longobject.c#L243" rel="nofollow noreferrer"><code>PyLong_FromLong(long)</code></a>, which shows all the observed behaviors and happens to be faster than  numpy-functionality (probably, because it is not the normal way of using numpy, not many optimizations were done).</p>
<p>There is a small difference for Python2 compared to Python3: Python2 has two different classes of integers: the one, more efficient, for numbers up to 32bit and the one for arbitrary big numbers - thus for the bigger numbers the most general (and thus more costly)  path must be taken - this also can be observed.</p>
</div>
<div class="post-text" itemprop="text">
<p>Constructing a list with <code>list(something)</code> iterates over something and collects the result of the iteration into a new list.</p>
<p>If <code>list(small_np)</code> is slower than <code>list(small_arr)</code> one could assume that iterating over <code>small_np</code> is slower than iterating over <code>small_arr</code>. Let's verify that: </p>
<pre><code>%timeit for i in small_np: pass   # 1 loop, best of 3: 916 ms per loop
%timeit for i in small_arr: pass  # 1 loop, best of 3: 261 ms per loop
</code></pre>
<p>Yep, iterating over a numpy array seems to be slower. This is where I must start speculating. Numpy arrays are flexible. They can have an arbitrary number of dimensions with various strides. Array arrays are always flat. This flexibility probably likely comes at a cost, which manifests in more complex iteration.</p>
</div>
<span class="comment-copy">Ther work differently  tolist() converts all the values to python primiteves recursively  list() creates a python list from an iterable  more on it: <a href="https://stackoverflow.com/questions/27890735/difference-between-listnumpy-array-and-numpy-array-tolist" title="difference between listnumpy array and numpy array tolist">stackoverflow.com/questions/27890735/…</a></span>
<span class="comment-copy">@OlafGórski Doesn't <code>array.array</code> use an iterator and still as fast?</span>
<span class="comment-copy">What's the type of the list elements in the different cases?</span>
<span class="comment-copy">@hpaulj it is <code>&lt;type 'numpy.int32'&gt;</code> for <code>list(numpy-array)</code> and <code>int</code> otherwise</span>
<span class="comment-copy"><code>list</code> iterates on the 1st dimension.  If the array is 2d, the result is a list of 1d arrays.  In general <code>list</code> and <code>tolist</code> don't produce the same thing, and shouldn't be expected to be comparable in speed.</span>
<span class="comment-copy">Do you think, that creating a <code>numpy.int64</code>-object is slower than creating an  <code>int</code>-object?</span>
<span class="comment-copy">@ead I really don't know. If  you were to force me to take a guess I'd lean towards yes, but that's just superstition based on the vague experience that "all things numpy come with overheads".</span>
<span class="comment-copy">I think the most time is used for creation of the int-objects. Please see my last edit which shows, that for bigger values it becomes slower, because another "integer"-type is used internally.</span>
<span class="comment-copy">@ead Python <code>int</code> objects smaller than 256 are cached (<a href="https://stackoverflow.com/questions/15171695/whats-with-the-integer-cache-inside-python">see here</a>), which makes using them relatively cheap.</span>
<span class="comment-copy">@ead interesting, do you happen to know whether python on windows switches directly to arbitrary size ints (which I'd guess are way more expensive) or to something like int64 first? (Assuming it uses the platform C int for small ints.)</span>
<span class="comment-copy">I don't believe (without further proof) that the iteration is slower because of stride or similar. It could be slower, because the creation of the returned object is slower (and the question is, why this is the case here).</span>
<span class="comment-copy">Iterating over a <code>numpy.ndarray</code> potentially iterates over subarrays while  iterating over <code>array.array</code> always iterates over elements. This will <i>at least</i> require additional checks in numpy.</span>
<span class="comment-copy">@ead for <code>list(a)</code> vs <code>a.tolist</code> we can see from the source that <code>list(a)</code> goes through the iterator protocol, whereas 'a.tolist' uses a simple direct loop. There doesn't seem to be any special casing of `array.array´ (lists and tuples are special cased), so I would concur that it likely boils down to differences in the iterators.</span>
