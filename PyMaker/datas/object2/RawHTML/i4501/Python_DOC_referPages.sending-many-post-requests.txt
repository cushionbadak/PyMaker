<div class="post-text" itemprop="text">
<p>I'm relatively new to Python and requests, so I'm not sure the best way to go about this.</p>
<p>I need to send a large amount of POST requests to a URL. Right now, I'm simply using a loop and sending the request, which yields roughly 100 posts every 10 - 30 seconds, depending on the internet. I'm looking for a way to do this faster and with more posts. Multiprocessing was recommended to me, but my knowledge here is very lacking (I've already frozen my computer trying to spawn too many processes).</p>
<p>How can I effectively implement multiprocessing to increase my results?</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a code sample taken from <a href="http://skipperkongen.dk/2016/09/09/easy-parallel-http-requests-with-python-and-asyncio/" rel="nofollow noreferrer">http://skipperkongen.dk/2016/09/09/easy-parallel-http-requests-with-python-and-asyncio/</a> which may solve your problem. It uses the requests library to make the request and asyncio for the asynchronous calls. The only change you'd have to make is from a GET call to a POST call.</p>
<p>This was written in Python 3.5 (as expressed in the article)</p>
<pre><code># Example 2: asynchronous requests
import asyncio
import requests

async def main():
    loop = asyncio.get_event_loop()
    futures = [
        loop.run_in_executor(
            None, 
            requests.get, 
            'http://example.org/'
        )
        for i in range(20)
    ]
    for response in await asyncio.gather(*futures):
        pass

loop = asyncio.get_event_loop()
loop.run_until_complete(main())
</code></pre>
<p>I would also recommend reading the entire article as it shows time comparisons when using lots of threads.</p>
</div>
<div class="post-text" itemprop="text">
<p>There's no reason to use multiprocessing here. Making requests of HTTP servers is almost entirely I/O-bound, not CPU-bound, so threads work just fine.</p>
<p>And the very first example of using <code>ThreadPoolExecutor</code> in the stdlib's <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="nofollow noreferrer"><code>concurrent.futures</code></a> documentation does exactly what you're asking for, except with <code>urllib</code> instead of <code>requests</code>.</p>
<hr/>
<p>If you're doing anything complicated, look at <a href="https://github.com/ross/requests-futures" rel="nofollow noreferrer"><code>requests-futures</code></a>.</p>
<hr/>
<p>If you really <em>do</em> need to use multiprocessing for some reason (e.g., you're doing a whole lot of text processing on each result, and you want to parallelize that along with the requesting), you can just switch the <code>ThreadPoolExecutor</code> to a <code>ProcessPoolExecutor</code> and change nothing else in your code.</p>
</div>
<span class="comment-copy">It would be helpful to include examples from your code which show what you're currently doing, and which areas you think need improvement. Thanks.</span>
<span class="comment-copy">You really don't need to add <code>asyncio</code> into the equation if you're not going to use async sockets anywhere. It's just running a loop to dispatch everything to a thread pool executor, which is easier to use directly.</span>
