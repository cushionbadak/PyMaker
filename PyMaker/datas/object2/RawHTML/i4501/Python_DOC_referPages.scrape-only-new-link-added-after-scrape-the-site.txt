<div class="post-text" itemprop="text">
<p>I have a code that scrape all links, titles and sizes of products with certain keywords. After the first scrape is done i want the script check again and again if new item are added. I try while True: but it seems doesnt work because gives me the same data multiple time. The script is this:</p>
<pre><code>import requests
import csv
from bs4 import BeautifulSoup
import time

headers = {"user-agent" : "Mozilla/5.0 (Macintosh; Intel Mac OS X 
10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 
Safari/537.36"}
keywords = ["nike", "air"]
base_url = "https://www.julian-fashion.com"

while True:
    for page in range(0,11):
        url = "https://www.julian-fashion.com/en-US/men/shoes/sneakerscurrPage={}".format(page)
        r = requests.get(url)
        soup = BeautifulSoup(r.content,"html.parser")
        all_links = soup.find_all("li", attrs={"class":"product in-stock"})
        for link in all_links:
            for s in keywords:
                if s not in link.a["href"]:
                    found = False
                    break
                else:
                    product = link.a["href"]
                    found = True
                    if found:
                        print("Product found.")
                        print(base_url+link.a["href"])
                        print(link.img["title"])
                        print(link.div.div.ul.text)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You are missing <code>?</code> before currPage, it should look like that: <code>https://www.julian-fashion.com/en-US/men/shoes/sneakers?currPage={}</code>.<code>?</code> indicates a start of the <a href="https://en.wikipedia.org/wiki/Query_string" rel="nofollow noreferrer">query string</a>. Now your code will work.</p>
<p>You also can omit page <code>0</code>, because this site starts pagination from <code>1</code> and providing <code>0</code> gives <code>404 Page not found</code>. Besides that, you don't need <code>while True</code> because you want to execute this block of code only once. <code>For</code> loop takes care of changing pages and it is enough.</p>
<p>There is a bug here:</p>
<pre><code>for s in keywords:
    if s not in link.a["href"]:
        found = False
        break
</code></pre>
<p>you break from the loop if a keyword is not in <code>link.a['href']</code>. Notice that if the first <code>keyword</code> from your list is not there, it doesn't mean one of the next ones won't.</p>
<p>Your code after a few fixes:</p>
<pre><code>import requests
from bs4 import BeautifulSoup

headers = {
    "user-agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36"
}
keywords = ["nike", "air"]
base_url = "https://www.julian-fashion.com"

for page in range(1, 11):
    print(f'[PAGE NR {page}]')
    url = "https://www.julian-fashion.com/en-US/men/shoes/sneakers?currPage={}".format(page)
    r = requests.get(url)
    soup = BeautifulSoup(r.content, "html.parser")
    all_links = soup.find_all("li", attrs={"class": "product in-stock"})
    for link in all_links:
        if any(key in link.a["href"] for key in keywords):
            print("Product found.")
            print(base_url + link.a["href"])
            print(link.img["title"])
            print(link.div.div.ul.text)
</code></pre>
<p>Here is my version of the code, I used <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#css-selectors" rel="nofollow noreferrer"><code>.select()</code></a> instead of <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all" rel="nofollow noreferrer"><code>.find_all()</code></a>. This is better, because if the creators of the page will add some new classes to the elements you search for, <code>.select()</code> that uses CSS selectors will still be able to target these elements. I also used <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urljoin" rel="nofollow noreferrer"><code>urljoin</code></a> to create absolute links, see <a href="https://stackoverflow.com/a/44002210/4796844">here</a> why.</p>
<pre><code>from bs4 import BeautifulSoup
import requests
from urllib.parse import urljoin

keywords = ["nike", "air"]
base_url = "https://www.julian-fashion.com"

for page in range(1, 11):
    print(f'[PAGE NR {page}]')
    url = "https://www.julian-fashion.com/en-US/men/shoes/sneakers?currPage={}".format(page)
    r = requests.get(url)
    soup = BeautifulSoup(r.text, "html.parser")
    all_items = soup.select('li.product.in-stock')

    for item in all_items:
        link = urljoin(base_url, item.a['href'])

        if any(key in link for key in keywords):
            title = item.img["title"]
            sizes = [size.text for size in item.select('.sizes &gt; ul &gt; li')]

            print(f'ITEM FOUND: {title}\n'
                  f'sizes available: {", ".join(sizes)}\n'
                  f'find out more here: {link}\n')
</code></pre>
<p>Perhaps you wanted the keywords to be the brands to filter items by, if so, you can use the code below instead of checking if the keyword is in the link to the item.</p>
<pre><code>    if item.select_one('.brand').text.lower() in keywords:
</code></pre>
<p>instead of:</p>
<pre><code>    if any(key in link for key in keywords):
</code></pre>
<p><strong>Monitor:</strong></p>
<p>To make a simple monitor that checks for new items on the website, you can use the code below and adjust it to your needs:</p>
<pre><code>from bs4 import BeautifulSoup
import requests
import time

item_storage = dict()

while True:
    print('scraping')
    html = requests.get('http://localhost:8000').text
    soup = BeautifulSoup(html, 'html.parser')

    for item in soup.select('li.product.in-stock'):
        item_id = item.a['href']

        if item_id not in item_storage:
            item_storage[item_id] = item
            print(f'NEW ITEM ADDED: {item_id}')

    print('sleeping')
    time.sleep(5)  # here you can adjust the frequency of checking for new items
</code></pre>
<p>You can test that locally by creating an <code>index.html</code> file with several <code>&lt;li class="product in-stock"&gt;</code>, you can copy them from the website. <a href="https://developer.chrome.com/devtools#access" rel="nofollow noreferrer">Enter Chrome DevTools</a>, find some <code>li</code>s in the <code>Elements</code> tab. Right-click on one -&gt; Copy -&gt; Copy outerHTML, then paste it into the <code>index.html</code> file. Then in console run: <code>python -m http.server 8000</code> and run the above script. During the execution, you can add some more items and see their <code>href</code> printed.</p>
<p><strong>Example output:</strong></p>
<pre><code>scraping
NEW ITEM /en-US/product/47341/nike/sneakers/air_maestro_ii_ltd_sneakers
NEW ITEM /en-US/product/47218/y3/sneakers/saikou_sneakers
sleeping
scraping
NEW ITEM /en-US/product/47229/y3/sneakers/tangutsu_slip_on
sleeping
</code></pre>
</div>
<span class="comment-copy">Could you please change the URL back to the one from the original question (before edits), because my answer addresses that issue and will become unclear if you attempt to fix the code after getting the answer. The ending used to be: <code>sneakerscurrPage={}</code> and I comment on the missing <code>?</code>.</span>
<span class="comment-copy">Hello! Thanks for Your answer and suggestion! What i didn't know is how to make the script wait to get a new link added in the website. I tried with while true but didn't work. Thanks</span>
<span class="comment-copy">You mean a script running 24/7 that prints items once they get added?</span>
<span class="comment-copy">yes. Similar to a monitor</span>
<span class="comment-copy">@Phil I updated answer with the example of a simple monitor.</span>
<span class="comment-copy">Thanks for Your Reply. I re-edited the link. I try to use the last script but i'm getting:iMac-di-Filippo:desktop phil$ python moni.py   File "moni.py", line 17     print(f'NEW ITEM ADDED: {item_id}')                                      ^ SyntaxError: invalid syntax</span>
