<div class="post-text" itemprop="text">
<p>How to select rows from a DataFrame based on values in some column in pandas?<br/>
In SQL I would use: </p>
<pre><code>select * from table where colume_name = some_value. 
</code></pre>
<p><em>I tried to look at pandas documentation but did not immediately find the answer.</em></p>
</div>
<div class="post-text" itemprop="text">
<p>To select rows whose column value equals a scalar, <code>some_value</code>, use <code>==</code>:</p>
<pre><code>df.loc[df['column_name'] == some_value]
</code></pre>
<p>To select rows whose column value is in an iterable, <code>some_values</code>, use <code>isin</code>:</p>
<pre><code>df.loc[df['column_name'].isin(some_values)]
</code></pre>
<p>Combine multiple conditions with <code>&amp;</code>: </p>
<pre><code>df.loc[(df['column_name'] &gt;= A) &amp; (df['column_name'] &lt;= B)]
</code></pre>
<p>Note the parentheses. Due to Python's <a href="https://docs.python.org/3/reference/expressions.html#operator-precedence" rel="noreferrer">operator precedence rules</a>, <code>&amp;</code> binds more tightly than <code>&lt;=</code> and <code>&gt;=</code>. Thus, the parentheses in the last example are necessary. Without the parentheses </p>
<pre><code>df['column_name'] &gt;= A &amp; df['column_name'] &lt;= B
</code></pre>
<p>is parsed as </p>
<pre><code>df['column_name'] &gt;= (A &amp; df['column_name']) &lt;= B
</code></pre>
<p>which results in a <a href="https://stackoverflow.com/questions/36921951/truth-value-of-a-series-is-ambiguous-use-a-empty-a-bool-a-item-a-any-o">Truth value of a Series is ambiguous error</a>.</p>
<hr/>
<p>To select rows whose column value <em>does not equal</em> <code>some_value</code>, use <code>!=</code>:</p>
<pre><code>df.loc[df['column_name'] != some_value]
</code></pre>
<p><code>isin</code> returns a boolean Series, so to select rows whose value is <em>not</em> in <code>some_values</code>, negate the boolean Series using <code>~</code>:</p>
<pre><code>df.loc[~df['column_name'].isin(some_values)]
</code></pre>
<hr/>
<p>For example,</p>
<pre><code>import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
#      A      B  C   D
# 0  foo    one  0   0
# 1  bar    one  1   2
# 2  foo    two  2   4
# 3  bar  three  3   6
# 4  foo    two  4   8
# 5  bar    two  5  10
# 6  foo    one  6  12
# 7  foo  three  7  14

print(df.loc[df['A'] == 'foo'])
</code></pre>
<p>yields</p>
<pre><code>     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<hr/>
<p>If you have multiple values you want to include, put them in a
list (or more generally, any iterable) and use <code>isin</code>:</p>
<pre><code>print(df.loc[df['B'].isin(['one','three'])])
</code></pre>
<p>yields</p>
<pre><code>     A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<hr/>
<p>Note, however, that if you wish to do this many times, it is more efficient to
make an index first, and then use <code>df.loc</code>:</p>
<pre><code>df = df.set_index(['B'])
print(df.loc['one'])
</code></pre>
<p>yields</p>
<pre><code>       A  C   D
B              
one  foo  0   0
one  bar  1   2
one  foo  6  12
</code></pre>
<p>or, to include multiple values from the index use <code>df.index.isin</code>:</p>
<pre><code>df.loc[df.index.isin(['one','two'])]
</code></pre>
<p>yields</p>
<pre><code>       A  C   D
B              
one  foo  0   0
one  bar  1   2
two  foo  2   4
two  foo  4   8
two  bar  5  10
one  foo  6  12
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h3>tl;dr</h3>
<p>The pandas equivalent to </p>
<pre><code>select * from table where column_name = some_value
</code></pre>
<p>is</p>
<pre><code>table[table.column_name == some_value]
</code></pre>
<p>Multiple conditions:</p>
<pre><code>table[(table.column_name == some_value) | (table.column_name2 == some_value2)]
</code></pre>
<p>or</p>
<pre><code>table.query('column_name == some_value | column_name2 == some_value2')
</code></pre>
<h3>Code example</h3>
<pre><code>import pandas as pd

# Create data set
d = {'foo':[100, 111, 222], 
     'bar':[333, 444, 555]}
df = pd.DataFrame(d)

# Full dataframe:
df

# Shows:
#    bar   foo 
# 0  333   100
# 1  444   111
# 2  555   222

# Output only the row(s) in df where foo is 222:
df[df.foo == 222]

# Shows:
#    bar  foo
# 2  555  222
</code></pre>
<p>In the above code it is the line <code>df[df.foo == 222]</code> that gives the rows based on the column value, <code>222</code> in this case.</p>
<p>Multiple conditions are also possible:</p>
<pre><code>df[(df.foo == 222) | (df.bar == 444)]
#    bar  foo
# 1  444  111
# 2  555  222
</code></pre>
<p>But at that point I would recommend using the <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html" rel="noreferrer">query</a> function, since it's less verbose and yields the same result:</p>
<pre><code>df.query('foo == 222 | bar == 444')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are a few basic ways to select rows from a pandas data frame.</p>
<ol>
<li>Boolean indexing</li>
<li>Positional indexing</li>
<li>Label indexing</li>
<li>API</li>
</ol>
<p>For each base type, we can keep things simple by restricting ourselves to the pandas API or we can venture outside the API, usually into <code>numpy</code>, and speed things up.</p>
<p>I'll show you examples of each and guide you as to when to use certain techniques.</p>
<hr/>
<p><strong>Setup</strong><br/>
The first thing we'll need is to identify a condition that will act as our criterion for selecting rows.  The OP offers up <code>column_name == some_value</code>.  We'll start there and include some other common use cases.</p>
<p>Borrowing from @unutbu:</p>
<pre><code>import pandas as pd, numpy as np

df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
</code></pre>
<hr/>
<p>Assume our criterion is column <code>'A'</code> = <code>'foo'</code></p>
<p><strong>1.</strong><br/>
<em>Boolean</em> indexing requires finding the true value of each row's <code>'A'</code> column being equal to <code>'foo'</code>, then using those truth values to identify which rows to keep.  Typically, we'd name this series, an array of truth values, <code>mask</code>.  We'll do so here as well.</p>
<pre><code>mask = df['A'] == 'foo'
</code></pre>
<p>We can then use this mask to slice or index the data frame</p>
<pre><code>df[mask]

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>This is one of the simplest ways to accomplish this task and if performance or intuitiveness isn't an issue, this should be your chosen method.  However, if performance is a concern, then you might want to consider an alternative way of creating the <code>mask</code>.</p>
<hr/>
<p><strong>2.</strong><br/>
<em>Positional</em> indexing has its use cases, but this isn't one of them.  In order to identify where to slice, we first need to perform the same boolean analysis we did above.  This leaves us performing one extra step to accomplish the same task.</p>
<pre><code>mask = df['A'] == 'foo'
pos = np.flatnonzero(mask)
df.iloc[pos]

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p><strong>3.</strong><br/>
<em>Label</em> indexing can be very handy, but in this case, we are again doing more work for no benefit</p>
<pre><code>df.set_index('A', append=True, drop=False).xs('foo', level=1)

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p><strong>4.</strong><br/>
<em><code>pd.DataFrame.query</code></em> is a very elegant/intuitive way to perform this task.  But is often slower.  <strong>However</strong>, if you pay attention to the timings below, for large data, the query is very efficient.  More so than the standard approach and of similar magnitude as my best suggestion.</p>
<pre><code>df.query('A == "foo"')

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<hr/>
<p>My preference is to use the <code>Boolean</code> <code>mask</code> </p>
<p>Actual improvements can be made by modifying how we create our <code>Boolean</code> <code>mask</code>.</p>
<p><strong><code>mask</code> alternative 1</strong><br/>
<em>Use the underlying <code>numpy</code> array and forgo the overhead of creating another <code>pd.Series</code></em> </p>
<pre><code>mask = df['A'].values == 'foo'
</code></pre>
<p>I'll show more complete time tests at the end, but just take a look at the performance gains we get using the sample data frame.  First, we look at the difference in creating the <code>mask</code></p>
<pre><code>%timeit mask = df['A'].values == 'foo'
%timeit mask = df['A'] == 'foo'

5.84 µs ± 195 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
166 µs ± 4.45 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>
<p>Evaluating the <code>mask</code> with the <code>numpy</code> array is ~ 30 times faster.  This is partly due to <code>numpy</code> evaluation often being faster.  It is also partly due to the lack of overhead necessary to build an index and a corresponding <code>pd.Series</code> object.</p>
<p>Next, we'll look at the timing for slicing with one <code>mask</code> versus the other.</p>
<pre><code>mask = df['A'].values == 'foo'
%timeit df[mask]
mask = df['A'] == 'foo'
%timeit df[mask]

219 µs ± 12.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
239 µs ± 7.03 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
<p>The performance gains aren't as pronounced.  We'll see if this holds up over more robust testing.</p>
<hr/>
<p><strong><code>mask</code> alternative 2</strong><br/>
We could have reconstructed the data frame as well.  There is a big caveat when reconstructing a dataframe—you must take care of the <code>dtypes</code> when doing so!</p>
<p>Instead of <code>df[mask]</code> we will do this</p>
<pre><code>pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)
</code></pre>
<p>If the data frame is of mixed type, which our example is, then when we get <code>df.values</code> the resulting array is of <code>dtype</code> <code>object</code> and consequently, all columns of the new data frame will be of <code>dtype</code> <code>object</code>.  Thus requiring the <code>astype(df.dtypes)</code> and killing any potential performance gains.</p>
<pre><code>%timeit df[m]
%timeit pd.DataFrame(df.values[mask], df.index[mask], df.columns).astype(df.dtypes)

216 µs ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
1.43 ms ± 39.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
<p>However, if the data frame is not of mixed type, this is a very useful way to do it.</p>
<p>Given</p>
<pre><code>np.random.seed([3,1415])
d1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))

d1

   A  B  C  D  E
0  0  2  7  3  8
1  7  0  6  8  6
2  0  2  0  4  9
3  7  3  2  4  3
4  3  6  7  7  4
5  5  3  7  5  9
6  8  7  6  4  7
7  6  2  6  6  5
8  2  8  7  5  8
9  4  7  6  1  5    
</code></pre>
<hr/>
<pre><code>%%timeit
mask = d1['A'].values == 7
d1[mask]

179 µs ± 8.73 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>
<p>Versus</p>
<pre><code>%%timeit
mask = d1['A'].values == 7
pd.DataFrame(d1.values[mask], d1.index[mask], d1.columns)

87 µs ± 5.12 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)
</code></pre>
<p>We cut the time in half.</p>
<hr/>
<p><strong><code>mask</code> alternative 3</strong><br/>
@unutbu also shows us how to use <code>pd.Series.isin</code> to account for each element of <code>df['A']</code> being in a set of values.  This evaluates to the same thing if our set of values is a set of one value, namely <code>'foo'</code>.  But it also generalizes to include larger sets of values if needed.  Turns out, this is still pretty fast even though it is a more general solution.  The only real loss is in intuitiveness for those not familiar with the concept.</p>
<pre><code>mask = df['A'].isin(['foo'])
df[mask]

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>However, as before, we can utilize <code>numpy</code> to improve performance while sacrificing virtually nothing.  We'll use <code>np.in1d</code></p>
<pre><code>mask = np.in1d(df['A'].values, ['foo'])
df[mask]

     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<hr/>
<p><strong>Timing</strong><br/>
I'll include other concepts mentioned in other posts as well for reference.<br/>
<em>Code Below</em> </p>
<p>Each Column in this table represents a different length data frame over which we test each function. Each column shows relative time taken, with the fastest function given a base index of <code>1.0</code>.</p>
<pre><code>res.div(res.min())

                         10        30        100       300       1000      3000      10000     30000
mask_standard         2.156872  1.850663  2.034149  2.166312  2.164541  3.090372  2.981326  3.131151
mask_standard_loc     1.879035  1.782366  1.988823  2.338112  2.361391  3.036131  2.998112  2.990103
mask_with_values      1.010166  1.000000  1.005113  1.026363  1.028698  1.293741  1.007824  1.016919
mask_with_values_loc  1.196843  1.300228  1.000000  1.000000  1.038989  1.219233  1.037020  1.000000
query                 4.997304  4.765554  5.934096  4.500559  2.997924  2.397013  1.680447  1.398190
xs_label              4.124597  4.272363  5.596152  4.295331  4.676591  5.710680  6.032809  8.950255
mask_with_isin        1.674055  1.679935  1.847972  1.724183  1.345111  1.405231  1.253554  1.264760
mask_with_in1d        1.000000  1.083807  1.220493  1.101929  1.000000  1.000000  1.000000  1.144175
</code></pre>
<p>You'll notice that fastest times seem to be shared between <code>mask_with_values</code> and <code>mask_with_in1d</code></p>
<pre><code>res.T.plot(loglog=True)
</code></pre>
<p><a href="https://i.stack.imgur.com/ljeTd.png" rel="noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/ljeTd.png"/></a></p>
<p><strong>Functions</strong> </p>
<pre><code>def mask_standard(df):
    mask = df['A'] == 'foo'
    return df[mask]

def mask_standard_loc(df):
    mask = df['A'] == 'foo'
    return df.loc[mask]

def mask_with_values(df):
    mask = df['A'].values == 'foo'
    return df[mask]

def mask_with_values_loc(df):
    mask = df['A'].values == 'foo'
    return df.loc[mask]

def query(df):
    return df.query('A == "foo"')

def xs_label(df):
    return df.set_index('A', append=True, drop=False).xs('foo', level=-1)

def mask_with_isin(df):
    mask = df['A'].isin(['foo'])
    return df[mask]

def mask_with_in1d(df):
    mask = np.in1d(df['A'].values, ['foo'])
    return df[mask]
</code></pre>
<hr/>
<p><strong>Testing</strong> </p>
<pre><code>res = pd.DataFrame(
    index=[
        'mask_standard', 'mask_standard_loc', 'mask_with_values', 'mask_with_values_loc',
        'query', 'xs_label', 'mask_with_isin', 'mask_with_in1d'
    ],
    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],
    dtype=float
)

for j in res.columns:
    d = pd.concat([df] * j, ignore_index=True)
    for i in res.index:a
        stmt = '{}(d)'.format(i)
        setp = 'from __main__ import d, {}'.format(i)
        res.at[i, j] = timeit(stmt, setp, number=50)
</code></pre>
<hr/>
<p><strong>Special Timing</strong><br/>
Looking at the special case when we have a single non-object <code>dtype</code> for the entire data frame.
<em>Code Below</em> </p>
<pre><code>spec.div(spec.min())

                     10        30        100       300       1000      3000      10000     30000
mask_with_values  1.009030  1.000000  1.194276  1.000000  1.236892  1.095343  1.000000  1.000000
mask_with_in1d    1.104638  1.094524  1.156930  1.072094  1.000000  1.000000  1.040043  1.027100
reconstruct       1.000000  1.142838  1.000000  1.355440  1.650270  2.222181  2.294913  3.406735
</code></pre>
<p>Turns out, reconstruction isn't worth it past a few hundred rows.</p>
<pre><code>spec.T.plot(loglog=True)
</code></pre>
<p><a href="https://i.stack.imgur.com/K1bNc.png" rel="noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/K1bNc.png"/></a></p>
<p><strong>Functions</strong> </p>
<pre><code>np.random.seed([3,1415])
d1 = pd.DataFrame(np.random.randint(10, size=(10, 5)), columns=list('ABCDE'))

def mask_with_values(df):
    mask = df['A'].values == 'foo'
    return df[mask]

def mask_with_in1d(df):
    mask = np.in1d(df['A'].values, ['foo'])
    return df[mask]

def reconstruct(df):
    v = df.values
    mask = np.in1d(df['A'].values, ['foo'])
    return pd.DataFrame(v[mask], df.index[mask], df.columns)

spec = pd.DataFrame(
    index=['mask_with_values', 'mask_with_in1d', 'reconstruct'],
    columns=[10, 30, 100, 300, 1000, 3000, 10000, 30000],
    dtype=float
)
</code></pre>
<p><strong>Testing</strong> </p>
<pre><code>for j in spec.columns:
    d = pd.concat([df] * j, ignore_index=True)
    for i in spec.index:
        stmt = '{}(d)'.format(i)
        setp = 'from __main__ import d, {}'.format(i)
        spec.at[i, j] = timeit(stmt, setp, number=50)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I find the syntax of the previous answers to be redundant and difficult to remember. Pandas introduced the <code>query()</code> method in v0.13 and I much prefer it. For your question, you could do <code>df.query('col == val')</code></p>
<p>Reproduced from <a href="http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query">http://pandas.pydata.org/pandas-docs/version/0.17.0/indexing.html#indexing-query</a></p>
<pre><code>In [167]: n = 10

In [168]: df = pd.DataFrame(np.random.rand(n, 3), columns=list('abc'))

In [169]: df
Out[169]: 
          a         b         c
0  0.687704  0.582314  0.281645
1  0.250846  0.610021  0.420121
2  0.624328  0.401816  0.932146
3  0.011763  0.022921  0.244186
4  0.590198  0.325680  0.890392
5  0.598892  0.296424  0.007312
6  0.634625  0.803069  0.123872
7  0.924168  0.325076  0.303746
8  0.116822  0.364564  0.454607
9  0.986142  0.751953  0.561512

# pure python
In [170]: df[(df.a &lt; df.b) &amp; (df.b &lt; df.c)]
Out[170]: 
          a         b         c
3  0.011763  0.022921  0.244186
8  0.116822  0.364564  0.454607

# query
In [171]: df.query('(a &lt; b) &amp; (b &lt; c)')
Out[171]: 
          a         b         c
3  0.011763  0.022921  0.244186
8  0.116822  0.364564  0.454607
</code></pre>
<p>You can also access variables in the environment by prepending an <code>@</code>.</p>
<pre><code>exclude = ('red', 'orange')
df.query('color not in @exclude')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Faster results can be achieved using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.where.html" rel="noreferrer">numpy.where</a>. </p>
<p>For example, with <a href="https://stackoverflow.com/questions/17071871/select-rows-from-a-dataframe-based-on-values-in-a-column-in-pandas/17071908#17071908">unubtu's setup</a> -</p>
<pre><code>In [76]: df.iloc[np.where(df.A.values=='foo')]
Out[76]: 
     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>Timing comparisons:</p>
<pre><code>In [68]: %timeit df.iloc[np.where(df.A.values=='foo')]  # fastest
1000 loops, best of 3: 380 µs per loop

In [69]: %timeit df.loc[df['A'] == 'foo']
1000 loops, best of 3: 745 µs per loop

In [71]: %timeit df.loc[df['A'].isin(['foo'])]
1000 loops, best of 3: 562 µs per loop

In [72]: %timeit df[df.A=='foo']
1000 loops, best of 3: 796 µs per loop

In [74]: %timeit df.query('(A=="foo")')  # slowest
1000 loops, best of 3: 1.71 ms per loop
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is a simple example  </p>
<pre><code>from pandas import DataFrame

# Create data set
d = {'Revenue':[100,111,222], 
     'Cost':[333,444,555]}
df = DataFrame(d)


# mask = Return True when the value in column "Revenue" is equal to 111
mask = df['Revenue'] == 111

print mask

# Result:
# 0    False
# 1     True
# 2    False
# Name: Revenue, dtype: bool


# Select * FROM df WHERE Revenue = 111
df[mask]

# Result:
#    Cost    Revenue
# 1  444     111
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I just tried editing this, but I wasn't logged in, so I'm not sure where my edit went. I was trying to incorporate multiple selection. So I think a better answer is:</p>
<p>For a single value, the most straightforward (human readable) is probably:</p>
<pre><code>df.loc[df['column_name'] == some_value]
</code></pre>
<p>For lists of values you can also use:</p>
<pre><code>df.loc[df['column_name'].isin(some_values)]
</code></pre>
<p>For example,</p>
<pre><code>import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
               'B': 'one one two three two two one three'.split(),
               'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
#      A      B  C   D
# 0  foo    one  0   0
# 1  bar    one  1   2
# 2  foo    two  2   4
# 3  bar  three  3   6
# 4  foo    two  4   8
# 5  bar    two  5  10
# 6  foo    one  6  12
# 7  foo  three  7  14

print(df.loc[df['A'] == 'foo'])
</code></pre>
<p>yields</p>
<pre><code>     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>If you have multiple criteria you want to select against, you can put them in a list and use 'isin':</p>
<pre><code>print(df.loc[df['B'].isin(['one','three'])])
</code></pre>
<p>yields</p>
<pre><code>      A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>Note, however, that if you wish to do this many times, it is more efficient to make A the index first, and then use df.loc:</p>
<pre><code>df = df.set_index(['A'])
print(df.loc['foo'])
</code></pre>
<p>yields</p>
<pre><code>  A      B  C   D
foo    one  0   0
foo    two  2   4
foo    two  4   8
foo    one  6  12
foo  three  7  14
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you finding rows based on some integer in a column, then</p>
<pre><code>df.loc[df['column_name'] == 2017]
</code></pre>
<p>If you are finding value based on string</p>
<pre><code>df.loc[df['column_name'] == 'string']
</code></pre>
<p>If based on both</p>
<pre><code>df.loc[(df['column_name'] == 'string') &amp; (df['column_name'] == 2017)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
df[df['A']=='foo']

OUTPUT:
   A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>To append to this famous question (though a bit too late): You can also do <code>df.groupby('column_name').get_group('column_desired_value').reset_index()</code> to make a new data frame with specified column having a particular value. E.g.</p>
<pre><code>import pandas as pd
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split()})
print("Original dataframe:")
print(df)

b_is_two_dataframe = pd.DataFrame(df.groupby('B').get_group('two').reset_index()).drop('index', axis = 1) 
#NOTE: the final drop is to remove the extra index column returned by groupby object
print('Sub dataframe where B is two:')
print(b_is_two_dataframe)
</code></pre>
<p>Run this gives:</p>
<pre><code>Original dataframe:
     A      B
0  foo    one
1  bar    one
2  foo    two
3  bar  three
4  foo    two
5  bar    two
6  foo    one
7  foo  three
Sub dataframe where B is two:
     A    B
0  foo  two
1  foo  two
2  bar  two
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>For selecting only specific columns out of multiple columns for a given value in pandas:</p>
<pre><code>select col_name1, col_name2 from table where column_name = some_value.
</code></pre>
<p>Options:</p>
<pre><code>df.loc[df['column_name'] == some_value][[col_name1, col_name2]]
</code></pre>
<p>or </p>
<pre><code>df.query['column_name' == 'some_value'][[col_name1, col_name2]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you came here looking to select rows from a dataframe by including those whose column's value is NOT any of a list of values, here's how to flip around unutbu's answer for a list of values above:</p>
<pre><code>df.loc[~df['column_name'].isin(some_values)]
</code></pre>
<p>(To not include a single value, of course, you just use the regular not equals operator, <code>!=</code>.)</p>
<p>Example:</p>
<pre><code>import pandas as pd
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split()})
print(df)
</code></pre>
<p>gives us</p>
<pre><code>     A      B
0  foo    one
1  bar    one
2  foo    two
3  bar  three
4  foo    two
5  bar    two
6  foo    one
7  foo  three    
</code></pre>
<p>To subset to just those rows that AREN'T <code>one</code> or <code>three</code> in column <code>B</code>:</p>
<pre><code>df.loc[~df['B'].isin(['one', 'three'])]
</code></pre>
<p>yields</p>
<pre><code>     A    B
2  foo  two
4  foo  two
5  bar  two
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can also use .apply:</p>
<pre><code>df.apply(lambda row: row[df['B'].isin(['one','three'])])
</code></pre>
<p>It actually works row-wise (i.e., applies the function to each row).</p>
<p>The output is </p>
<pre><code>   A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14
</code></pre>
<p>The results is the same as using as mentioned by @unutbu</p>
<pre><code>df[[df['B'].isin(['one','three'])]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>df.loc[df['column_name'] == some_value]
</code></pre>
</div>
<span class="comment-copy">Check here: <a href="https://github.com/debaonline4u/Python_Programming/tree/master/pandas_and_data_visualization" rel="nofollow noreferrer">github.com/debaonline4u/Python_Programming/tree/master/…</a></span>
<span class="comment-copy"><code>df.query</code> and <code>pd.eval</code> seem like good fits for this use case. For information on the <code>pd.eval()</code> family of functions, their features and use cases, please visit <a href="https://stackoverflow.com/questions/53779986/dynamic-expression-evaluation-in-pandas-using-pd-eval">Dynamic Expression Evaluation in pandas using pd.eval()</a>.</span>
<span class="comment-copy">This is a  Comparison with SQL:  <a href="https://pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html" rel="nofollow noreferrer">pandas.pydata.org/pandas-docs/stable/comparison_with_sql.html</a>  where you can run pandas as SQL.</span>
<span class="comment-copy">In fact, df[df['colume_name']==some_value] also works. But my first attempt, df.where(df['colume_name']==some_value) does not work... not sure why...</span>
<span class="comment-copy">When you use <code>df.where(condition)</code>, the condition has to have the same shape as <code>df</code>.</span>
<span class="comment-copy">FYI: If you want to select a row based upon two (or more) labels (either requiring both or either), see <a href="http://stackoverflow.com/questions/31756340/selecting-rows-from-a-dataframe-based-on-values-in-multiple-columns-in-pandas/31756517#" title="selecting rows from a dataframe based on values in multiple columns in pandas">stackoverflow.com/questions/31756340/…</a></span>
<span class="comment-copy">What about the negative "isnotin" does that exist?</span>
<span class="comment-copy">@BlackHat: <code>isin</code> returns a boolean mask. To find rows not in <code>some_iterable</code>, negate the boolean mask using <code>~</code> (a tilde). That is, <code>df.loc[~df['column_name'].isin(some_values)]</code></span>
<span class="comment-copy">I really like the approach here. Thanks for having added it.  It seems a bit more elegant than the accepted answer - which is still ok but this is great thanks.</span>
<span class="comment-copy"><code>query</code> is the only answer here that is compatible with method chaining.  It seems like it's the pandas analog to <code>filter</code> in dplyr.</span>
<span class="comment-copy">Hi, in your third example (multiple columns) I think you need square brackets <code>[</code> not round brackets <code>(</code> on the outside.</span>
<span class="comment-copy">at first I thought that <code>|</code> was for AND, but of course it is OR-operator...</span>
<span class="comment-copy">I like <code>query</code> a lot as it is very readable. It is worth noting that it also works for multi-index dataframes where one can also query on different index levels (see the answer <a href="https://stackoverflow.com/a/49045951/1534017">here</a>).</span>
<span class="comment-copy">Fantastic answer! 2 questions though, i) how would <code>.iloc(numpy.where(..))</code> compare in this scheme? ii) would you expect the rankings to be the same when using multiple conditions?</span>
<span class="comment-copy">For performance of <code>pd.Series.isin</code>, note it <i>does</i> use <code>np.in1d</code> under the hood in a specific scenario, uses khash in others, and implicitly applies a trade-off between cost of hashing versus performance in specific situations. <a href="https://stackoverflow.com/a/50881584/9209546">This answer</a> has more detail.</span>
<span class="comment-copy"><code>df[mask.values]</code> is what I needed. Thanks</span>
<span class="comment-copy">You only need package <code>numexpr</code> installed.</span>
<span class="comment-copy">In my case I needed quotation because val is a string. df.query('col == "val"')</span>
<span class="comment-copy">How is this any different from imolit's answer?</span>
