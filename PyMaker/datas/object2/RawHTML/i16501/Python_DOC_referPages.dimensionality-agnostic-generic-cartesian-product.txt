<div class="post-text" itemprop="text">
<p>I'm looking to generate the cartesian product of a relatively large number of arrays to span a high-dimensional grid. Because of the high dimensionality, it won't be possible to store the result of the cartesian product computation in memory; rather it will be written to hard disk.  Because of this constraint, I need access to the intermediate results as they are generated. What I've been doing so far is this:</p>
<pre><code>for x in xrange(0, 10):
    for y in xrange(0, 10):
        for z in xrange(0, 10):
            writeToHdd(x,y,z)
</code></pre>
<p>which, apart from being very nasty, is not scalable (i.e. it would require me writing as many loops as dimensions). I have tried to use the solution proposed <a href="https://stackoverflow.com/questions/1208118/using-numpy-to-build-an-array-of-all-combinations-of-two-arrays">here</a>, but that is a recursive solution, which therefore makes it quite hard to obtain the results on the fly as they are being generated. Is there any 'neat' way to do this other than having a hardcoded loop per dimension?</p>
</div>
<div class="post-text" itemprop="text">
<p>In plain Python, you can generate the Cartesian product of a collection of iterables using <a href="https://docs.python.org/3/library/itertools.html#itertools.product" rel="nofollow"><code>itertools.product</code></a>.</p>
<pre><code>&gt;&gt;&gt; arrays = range(0, 2), range(4, 6), range(8, 10)
&gt;&gt;&gt; list(itertools.product(*arrays))
[(0, 4, 8), (0, 4, 9), (0, 5, 8), (0, 5, 9), (1, 4, 8), (1, 4, 9), (1, 5, 8), (1, 5, 9)]
</code></pre>
<p>In Numpy, you can combine <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html" rel="nofollow"><code>numpy.meshgrid</code></a> (passing <code>sparse=True</code> to avoid expanding the product in memory) with <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndindex.html#numpy.ndindex" rel="nofollow"><code>numpy.ndindex</code></a>:</p>
<pre><code>&gt;&gt;&gt; arrays = np.arange(0, 2), np.arange(4, 6), np.arange(8, 10)
&gt;&gt;&gt; grid = np.meshgrid(*arrays, sparse=True)
&gt;&gt;&gt; [tuple(g[i] for g in grid) for i in np.ndindex(grid[0].shape)]
[(0, 4, 8), (0, 4, 9), (1, 4, 8), (1, 4, 9), (0, 5, 8), (0, 5, 9), (1, 5, 8), (1, 5, 9)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think I figured out a nice way using a memory mapped file:</p>
<pre><code>def carthesian_product_mmap(vectors, filename, mode='w+'):
    '''
    Vectors should be a tuple of `numpy.ndarray` vectors. You could
    also make it more flexible, and include some error checking
    '''        
    # Make a meshgrid with `copy=False` to create views
    grids = np.meshgrid(*vectors, copy=False, indexing='ij')

    # The shape for concatenating the grids from meshgrid
    shape = grid[0].shape + (len(vectors),)

    # Find the "highest" dtype neccesary
    dtype = np.result_type(*vectors)

    # Instantiate the memory mapped file
    M = np.memmap(filename, dtype, mode, shape=shape)

    # Fill the memmap with the grids
    for i, grid in enumerate(grids):
        M[...,i] = grid

    # Make sure the data is written to disk (optional?)
    M.flush()

    # Reshape to put it in the right format for Carthesian product
    return M.reshape((-1, len(vectors)))
</code></pre>
<p>But I wonder if you really need to store the whole Carthesian product (there's a lot of data duplication). Is it not an option to generate the rows in the product at the moment they're needed?</p>
</div>
<div class="post-text" itemprop="text">
<p>It seems you just want to loop over an arbitrary number of dimensions. My generic solution for this is using an index field and increment indices plus handling overflows.</p>
<p>Example:</p>
<pre><code>n = 3 # number of dimensions
N = 1 # highest index value per dimension

idx = [0]*n
while True:
    print(idx)
    # increase first dimension
    idx[0] += 1
    # handle overflows
    for i in range(0, n-1):
        if idx[i] &gt; N:
            # reset this dimension and increase next higher dimension
            idx[i] = 0
            idx[i+1] += 1
    if idx[-1] &gt; N:
        # overflow in the last dimension, we are finished
        break
</code></pre>
<p>Gives:</p>
<pre><code>[0, 0, 0]
[1, 0, 0]
[0, 1, 0]
[1, 1, 0]
[0, 0, 1]
[1, 0, 1]
[0, 1, 1]
[1, 1, 1]
</code></pre>
<p>Numpy has something similar inbuilt: <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndenumerate.html" rel="nofollow">ndenumerate</a>.</p>
</div>
<span class="comment-copy">Great solution!</span>
<span class="comment-copy">You could also do assignment by broadcasting, see <a href="http://stackoverflow.com/a/11146645/2379410">stackoverflow.com/a/11146645/2379410</a></span>
<span class="comment-copy">Just out of curiosity; would Numpy memmap outperform a database-based solution? I guess a database would have some overhead to get the connection set up etc, but I would think that databases provide 'smart' indexing/compression systems etc?</span>
<span class="comment-copy">@danielvdende, I don't have experience with databases.. Maybe when the disk IO is the bottleneck it could be equally fast as Numpy</span>
<span class="comment-copy">Thanks! Seems so simple in hindsight, just couldn't figure it out!</span>
<span class="comment-copy">The answer by Gareth Rees has the advantage that it works with arbitrary ranges right out of the box and uses an inbuilt function. I would prefer it my answer also does the trick in simple cases.</span>
