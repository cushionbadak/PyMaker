<div class="post-text" itemprop="text">
<p>i wrote a Python web scraper yesterday and ran it in my terminal overnight. it only got through 50k pages. so now i just have a bunch of terminals open concurrently running the script at different starting and end points. this works fine because the main lag is obviously opening web pages and not actual CPU load. more elegant way to do this? especially if it can be done locally</p>
</div>
<div class="post-text" itemprop="text">
<p>You have an I/O bound process, so to speed it up you will need to send requests concurrently.  This doesn't necessarily require multiple processors, you just need to avoid waiting until one request is done before sending the next.</p>
<p>There are a number of solutions for this problem. Take a look at <a href="https://medium.com/p/40e9b2b36148" rel="nofollow">this blog post</a> or check out <a href="http://www.gevent.org/" rel="nofollow">gevent</a>, <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow">asyncio</a> (backports to pre-3.4 versions of Python should be available) or another async IO library.</p>
<p>However, when scraping other sites, you must remember: you can send requests very fast with concurrent programming, but depending on what site you are scraping, this may be very rude.  You could easily bring a small site serving dynamic content down entirely, forcing the administrators to block you.  Respect <code>robots.txt</code>, try to spread your efforts between multiple servers at once rather than focusing your entire bandwidth on a single server, and carefully throttle your requests to single servers unless you're sure you don't need to.</p>
</div>
<span class="comment-copy"><a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow noreferrer">docs.python.org/2/library/multiprocessing.html</a> all you need is in there</span>
<span class="comment-copy">Python does not have true "threading". Since the GIL is present on CPython (which is what I'm assuming you are using), you must use the multiprocessing module. However, in your case, the <code>threading</code> module may be useful depending on how you are scraping these sites, simply because it sounds like you are I/O bound.</span>
<span class="comment-copy">Yeah, because this is I/O-bound, not CPU-bound, <code>threading</code> will probably parallelize things pretty well. You could also go the asynchronous route, via <a href="https://twistedmatrix.com" rel="nofollow noreferrer"><code>twisted</code></a>, <a href="http://tornadoweb.org" rel="nofollow noreferrer"><code>tornado</code></a>, or <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer"><code>asyncio</code></a> (if you're using Python 3.4).</span>
