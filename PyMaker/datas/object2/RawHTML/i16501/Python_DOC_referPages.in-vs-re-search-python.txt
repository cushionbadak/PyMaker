<div class="post-text" itemprop="text">
<p>I have a python 2.7 script which usually runs for hours, and I am now trying to optimize it. It has a lot of searches for strings, which represents the heavy part of computation. At the moment I am currently using <code>re.search('stringToFind', haystack)</code> to find substrings in longer strings. I am considering rewriting all expressions that do not contain regular expressions and use <code>in</code> instead. Almost all strings that are searched for are normal strings, ie contains no regular expressions.</p>
<p>I know that <code>in</code> uses a <code>contains</code> method to check substrings, but I have no clue how re.search works for strings that are non-re. How does re.search actually work? Would it really be more efficient to use in rather than re.search for substring in string comparision?</p>
<p>EDIT: To clarify I can give an example of currently running code:</p>
<pre><code>if re.search('extern', variable):
    # Do something...
</code></pre>
<p>Could be replace by:</p>
<pre><code>if 'extern' in variable:
    # Do  something...
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>As others have commented, executing a regular expression search is inherently more complex than a simple substring search. Here's a very rough benchmark:</p>
<pre><code>import timeit
import re
s = '0' * 1000 + 'foo' + '0' * 1000
rgx = re.compile(r'foo')
setup = 'from __main__ import s, rgx'
print timeit.timeit('"foo" in s', setup = setup)             # 0.745168924332
print timeit.timeit('rgx.search(s).group(0)', setup = setup) # 1.14249396324
</code></pre>
<p>But if your program runs for hours, I doubt that the source of the problem lies in such areas.</p>
</div>
<span class="comment-copy">what do you mean by <code>strings that are non-re</code>? An example would be better.</span>
<span class="comment-copy">Which approach was faster in your timing tests?</span>
<span class="comment-copy">I would fully expect <code>in</code> to be faster.</span>
<span class="comment-copy">i posit that you're trying to optimize 0.1% of run time of your script down to 0.01%, and thus completely wasting your time.  <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">docs.python.org/3/library/profile.html</a></span>
<span class="comment-copy">If your search string is a plain text string, and if you don't need any actual regex features (like <a href="http://www.regular-expressions.info/wordboundaries.html" rel="nofollow noreferrer">word boundaries</a>), then there is no reason to use a regex in the first place.</span>
<span class="comment-copy">But, i think complexity of regex can effect the benchmark ? You are just using a simple regex here.</span>
<span class="comment-copy">@myildirim The regex has to be simple; otherwise, a simple substring search wouldn't be a viable alternative, and the OP's question wouldn't make any sense -- unless I'm misunderstanding the question.</span>
<span class="comment-copy">I am actually not using real regular expressions, just checking occurences of normal strings. Added an update now showing some code.</span>
<span class="comment-copy">Thank you for the example, I never actually thought of timing an example. It seemed so logical to just check the implementation. My values when timing had an even bigger difference, 0.88 vs 3.02. Replacing all unneccessary regex.</span>
