<div class="post-text" itemprop="text">
<p>I'm trying to call ~ 300 API calls at the same time, so that I would get the results in a couple of seconds max.</p>
<p>My pseudo-code looks like this:</p>
<pre><code>def function_1():
    colors = ['yellow', 'green', 'blue', + ~300 other ones]
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    res = loop.run_until_complete(get_color_info(colors))

async def get_color_info(colors):
    loop = asyncio.get_event_loop()
    responses = []
    for color in colors:
        print("getting color")
        url = "https://api.com/{}/".format(color)
        data = loop.run_in_executor(None, requests.get, url)
        r = await data
        responses.append(r.json())
    return responses
</code></pre>
<p>Doing this I get <code>getting color</code> printed out every second or so and the code takes forever, so I'm pretty sure they don't run simultaneously. What am I doing wrong?</p>
</div>
<div class="post-text" itemprop="text">
<h3><code>aiohttp</code> with Native Coroutines (<code>async</code>/<code>await</code>)</h3>
<p>Here is a typical pattern that accomplishes what you're trying to do.  (Python 3.7+.)</p>
<p>One major change is that you will need to move from <code>requests</code>, which is built for synchronous IO, to a package such as <a href="https://github.com/aio-libs/aiohttp" rel="noreferrer"><code>aiohttp</code></a> that is built specifically to work with <code>async</code>/<code>await</code> (native coroutines):</p>
<pre><code>import asyncio
import aiohttp  # pip install aiohttp aiodns


async def get(
    session: aiohttp.ClientSession,
    color: str,
    **kwargs
) -&gt; dict:
    url = f"https://api.com/{color}/"
    print(f"Requesting {url}")
    resp = await session.request('GET', url=url, **kwargs)
    # Note that this may raise an exception for non-2xx responses
    # You can either handle that here, or pass the exception through
    data = await resp.json()
    print(f"Received data for {url}")
    return data


async def main(colors, **kwargs):
    # Asynchronous context manager.  Prefer this rather
    # than using a different session for each GET request
    async with aiohttp.ClientSession() as session:
        tasks = []
        for c in colors:
            tasks.append(get(session=session, color=c, **kwargs))
        # asyncio.gather() will wait on the entire task set to be
        # completed.  If you want to process results greedily as they come in,
        # loop over asyncio.as_completed()
        htmls = await asyncio.gather(*tasks, return_exceptions=True)
        return htmls


if __name__ == '__main__':
    colors = ['red', 'blue', 'green']  # ...
    # Either take colors from stdin or make some default here
    asyncio.run(main(colors))  # Python 3.7+
</code></pre>
<p>There are two distinct elements to this, one being the asynchronous aspect of the coroutines and one being the concurrency introduced on top of that when you specify a container of tasks (futures):</p>
<ul>
<li>You create one coroutine <code>get</code> that uses <code>await</code> with two <em>awaitables</em>: the first being <a href="https://github.com/aio-libs/aiohttp/blob/49261c192ff225372dffb39056c3c311714b12c5/aiohttp/client.py#L245" rel="noreferrer"><code>.request</code></a> and the second being <a href="https://github.com/aio-libs/aiohttp/blob/49261c192ff225372dffb39056c3c311714b12c5/aiohttp/client_reqrep.py#L985" rel="noreferrer"><code>.json</code></a>.  This is the async aspect.  The purpose of <code>await</code>ing these IO-bound responses is to tell the event loop that other <code>get()</code> calls can take turns running through that same routine.</li>
<li>The concurrent aspect is encapsulated in <code>await asyncio.gather(*tasks)</code>.  This maps the awaitable <code>get()</code> call to each of your <code>colors</code>.  The result is an aggregate list of returned values.  Note that this wrapper will wait until <em>all</em> of your responses come in and call <code>.json()</code>.  If, alternatively, you want to process them greedily as they are ready, you can loop over <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed" rel="noreferrer"><code>asyncio.as_completed</code></a>: each Future object returned represents the earliest result from the set of the remaining awaitables.</li>
</ul>
<p>Lastly, take note that <a href="https://github.com/python/cpython/blob/fec35c99aa749bb90cb29349bed6b3393907c4c1/Lib/asyncio/runners.py#L8" rel="noreferrer"><code>asyncio.run()</code></a> is a high-level "porcelain" function introduced in Python 3.7.  In earlier versions, you can mimic it (roughly) like:</p>
<pre><code># The "full" versions makes a new event loop and calls
# loop.shutdown_asyncgens(), see link above
loop = asyncio.get_event_loop()
try:
    loop.run_until_complete(main(colors))
finally:
    loop.close()
</code></pre>
<hr/>
<h3>Limiting Requests</h3>
<p>There are a number of ways to limit the rate of concurrency.  For instance, see <a href="https://stackoverflow.com/a/40845135/7954504"><code>asyncio.semaphore</code> in async-await function</a> or <a href="https://www.artificialworlds.net/blog/2017/05/31/python-3-large-numbers-of-tasks-with-limited-concurrency/" rel="noreferrer">large numbers of tasks with limited concurrency</a>.</p>
</div>
<span class="comment-copy">The <code>await</code> keyword literally means to <i>wait for</i> a result. Any instructions after it are only executed <i>after</i> the result is ready. Doing work concurrently requires running <i>several</i> coroutines at once, not having one do several things.</span>
<span class="comment-copy">Good answer. I wish there was a blog post that explained this as succinctly. Introductory texts on the topic are often outdated or downright incorrect. You might want to mention the use of <code>Semaphore</code> to limit the number of concurrent requests, which tends to belong to the same pattern.</span>
<span class="comment-copy">@user4815162342 Here's an article I wrote recently - appreciate any feedback &amp; corrections.  <a href="https://realpython.com/async-io-python/" rel="nofollow noreferrer">realpython.com/async-io-python</a></span>
