<div class="post-text" itemprop="text">
<p>I have written a simple python script to import data into elasticsearch using <code>bulk</code> API. </p>
<pre><code># -*- encoding: utf-8 -*-
import csv
import datetime
import hashlib
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
from dateutil.relativedelta import relativedelta


ORIGINAL_FORMAT = '%y-%m-%d %H:%M:%S'
INDEX_PREFIX = 'my-log'
INDEX_DATE_FORMAT = '%Y-%m-%d'
FILE_ADDR = '/media/zeinab/ZiZi/Elastic/python/elastic-test/elasticsearch-import-data/sample_data/sample.csv'


def set_data(input_file):
    with open(input_file) as csvfile:
        reader = csv.DictReader(csvfile)
        for row in reader:
            sendtime = datetime.datetime.strptime(row['sendTime'].split('.')[0], ORIGINAL_FORMAT)

            yield {
                "_index": '{0}-{1}_{2}'.format(
                                        INDEX_PREFIX,
                                        sendtime.replace(day=1).strftime(INDEX_DATE_FORMAT),
                                        (sendtime.replace(day=1) + relativedelta(months=1)).strftime(INDEX_DATE_FORMAT)),
                "_type": 'data',
                '_id': hashlib.md5("{0}{1}{2}{3}{4}".format(sendtime, row['IMSI'], row['MSISDN'], int(row['ruleRef']), int(row['sponsorRef']))).digest(),
                "_source": {
                    'body': {
                        'status': int(row['status']),
                        'sendTime': sendtime
                    }
                }
            }


if __name__ == "__main__":
    es = Elasticsearch(['http://{0}:{1}'.format('my.host.ip.addr', 9200)])
    es.indices.delete(index='*')
    success, _ = bulk(es, set_data(FILE_ADDR))
</code></pre>
<p><a href="https://github.com/elastic/elasticsearch-py/issues/508#issuecomment-268756014" rel="nofollow noreferrer">This comment</a> helped me on writing/using <code>set_data</code> method.</p>
<p>Unfortunately I get this exception:</p>
<pre><code>/usr/bin/python2.7 /media/zeinab/ZiZi/Elastic/python/elastic-test/elasticsearch-import-data/import_bulk_data.py
Traceback (most recent call last):
  File "/media/zeinab/ZiZi/Elastic/python/elastic-test/elasticsearch-import-data/import_bulk_data.py", line 59, in &lt;module&gt;
    success, _ = bulk(es, set_data(source_file))
  File "/usr/local/lib/python2.7/dist-packages/elasticsearch/helpers/__init__.py", line 257, in bulk
    for ok, item in streaming_bulk(client, actions, **kwargs):
  File "/usr/local/lib/python2.7/dist-packages/elasticsearch/helpers/__init__.py", line 180, in streaming_bulk
    client.transport.serializer):
  File "/usr/local/lib/python2.7/dist-packages/elasticsearch/helpers/__init__.py", line 60, in _chunk_actions
    action = serializer.dumps(action)
  File "/usr/local/lib/python2.7/dist-packages/elasticsearch/serializer.py", line 50, in dumps
    raise SerializationError(data, e)
elasticsearch.exceptions.SerializationError: ({u'index': {u'_type': 'data', u'_id': '8\x1dI\xa2\xe9\xa2H-\xa6\x0f\xbd=\xa7CY\xa3', u'_index': 'my-log-2017-04-01_2017-05-01'}}, UnicodeDecodeError('utf8', '8\x1dI\xa2\xe9\xa2H-\xa6\x0f\xbd=\xa7CY\xa3', 3, 4, 'invalid start byte'))

Process finished with exit code 1
</code></pre>
<p>I can insert this data into elasticsearch successfully using <code>index</code> API:</p>
<pre><code>es.index(index='{0}-{1}_{2}'.format(
    INDEX_PREFIX,
    sendtime.replace(day=1).strftime(INDEX_DATE_FORMAT),
    (sendtime.replace(day=1) + relativedelta(months=1)).strftime(INDEX_DATE_FORMAT)
),
         doc_type='data',
         id=hashlib.md5("{0}{1}{2}{3}{4}".format(sendtime, row['IMSI'], row['MSISDN'], int(row['ruleRef']), int(row['sponsorRef']))).digest(),
         body={
                'status': int(row['status']),
                'sendTime': sendtime
            }
         )
</code></pre>
<p>But the issue with <code>index</code> API is that it's very slow; it needs about 2 seconds to import just 50 records. I hoped <code>bulk</code> API would help me on the speed.</p>
</div>
<div class="post-text" itemprop="text">
<p>According to the <a href="https://docs.python.org/3/library/hashlib.html#hashlib.hash.digest" rel="nofollow noreferrer">hashlib documentation</a>, the <code>digest</code> method will</p>
<blockquote>
<p>Return the digest of the data passed to the update() method so far. This is a bytes object of size digest_size which may contain bytes in the whole range from 0 to 255.</p>
</blockquote>
<p>So the resulting bytes may not decodeable to unicode.</p>
<pre><code>&gt;&gt;&gt; id_ = hashlib.md5('abc'.encode('utf-8')).digest()
&gt;&gt;&gt; id_
b'\x90\x01P\x98&lt;\xd2O\xb0\xd6\x96?}(\xe1\x7fr'
&gt;&gt;&gt; id_.decode('utf-8')
Traceback (most recent call last):
  File "&lt;console&gt;", line 1, in &lt;module&gt;
UnicodeDecodeError: 'utf-8' codec can't decode byte 0x90 in position 0: invalid start byte
</code></pre>
<p>The <code>hexdigest</code> method will produce a string as output; from the <a href="https://docs.python.org/3/library/hashlib.html#hashlib.hash.hexdigest" rel="nofollow noreferrer">docs</a>:</p>
<blockquote>
<p>Like digest() except the digest is returned as a string object of double length, containing only hexadecimal digits. This may be used to exchange the value safely in email or other non-binary environments.</p>
</blockquote>
<pre><code>&gt;&gt;&gt; id_ = hashlib.md5('abc'.encode('utf-8')).hexdigest()
&gt;&gt;&gt; id_
'900150983cd24fb0d6963f7d28e17f72'
</code></pre>
</div>
<span class="comment-copy">There is a unicode issue with you <code>_id</code> field. I am not sure how to fix it, but try to cast the id into a string and/or creating your dictionary using the <code>dict()</code> constructor. Also, there is no need for a <code>body</code> key in the <code>_source</code> field</span>
