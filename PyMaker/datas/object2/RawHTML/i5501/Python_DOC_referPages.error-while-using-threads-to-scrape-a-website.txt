<div class="post-text" itemprop="text">
<p>I am trying to build a bot that will scrap the purchase history of purchased domains. So far I was able to extract the domain from the csv file and store them into a list (PS: there are 10k domains). The problem accures when I am trying to scrap the website with them. I have tried doing this with two domains and it works perfectly. Does anyone know what error is this and how I can fix it? Thank you very much in advance.</p>
<p>my code:</p>
<pre><code>datafile = open('/Users/.../Documents/Domains.csv', 'r')
myreader = csv.reader(datafile, delimiter=";",)
domains   = []
for row in myreader:
    domains.append(row[1])
del domains[0]
print("The Domains have been stored into a list")

nmb_sells_record = 0

def result_catcher(domains,queue):
    template_url = "https://namebio.com/{}".format(domain)
    get = requests.get(template_url)
    results = get.text
    last_sold =  results[results.index("last sold for ")+15:results.index(" on 2")].replace(",","")
    last_sold = int(last_sold)
    if not "No historical sales found." in results:
        sold_history = results[results.index("&lt;span class=\"label label-success\"&gt;"):results.index(" USD&lt;/span&gt; on &lt;span class=\"label")]
    queue.put(results)

#domains = ["chosen.com","koalas.com"]
queues = {}
nmb=0
for x in range(len(domains)):
    new_queue = "queue{}".format(nmb)
    queues[new_queue] = queue.Queue()
    nmb += 1
count = 0
for domain in domains:
    for queue in queues: 
        t = threading.Thread(target=result_catcher, args=(domain,queues[queue]))
        t.start()
print("The Requests were all sent, now they are beeing analysed")   
for queue in queues:
    response_domain = queues[queue].get()
    nmb_sells_record = response_domain.count("for $") + response_domain.count("USD")


print("The Bot has recorded {} domain sells".format(nmb_sells_record))
</code></pre>
<p>The output of my code:</p>
<pre><code>Exception in thread Thread-345:
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/util/connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/socket.py", line 743, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 8] nodename nor servname provided, or not known

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connection.py", line 284, in connect
    conn = self._new_conn()
  File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/urllib3/connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.VerifiedHTTPSConnection object at 0x115a55a20&gt;: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>From the python <a href="https://docs.python.org/3/library/socket.html#socket.gaierror" rel="nofollow noreferrer">docs</a>:</p>
<blockquote>
<p><strong>exception socket.gaierror</strong> A subclass of OSError, this exception is raised for address-related errors by getaddrinfo() and getnameinfo().</p>
<p>The accompanying value is a pair (error, string) representing an error
  returned by a library call. string represents the description of
  error, as returned by the gai_strerror() C function. The numeric error
  value will match one of the EAI_* constants defined in this module.</p>
</blockquote>
<p>gai =&gt; get address info</p>
<p>From the <a href="https://pypi.python.org/pypi/urllib3" rel="nofollow noreferrer">urllib3 wikipage</a>:</p>
<blockquote>
<p><strong>New exception: NewConnectionError</strong>, raised when we fail to establish a new connection, usually ECONNREFUSED socket error.</p>
</blockquote>
<p>Some possible reasons for an ECONNREFUSED error <a href="https://stackoverflow.com/questions/2333400/what-can-be-the-reasons-of-connection-refused-errors/2361762">here</a> along with some commandline commands to probe the address and port. </p>
<p>By the way, instead of reading all the rows into an array, then deleting the first item in the array, which makes python slide all the other items over one spot, you can more efficiently skip the header(?) like this:</p>
<pre><code>myreader = csv.reader(datafile, delimiter=";",)
next(my_reader)  #&lt;==== HERE ****

domains   = []

for row in myreader:
    domains.append(row[1])
</code></pre>
<p><code>next()</code> will throw a StopIteration exception if there isn't a next row.  If you want to prevent that, you can call <code>next(my_reader, None)</code>, which will return None if there is no next row.</p>
<p>Threading example:</p>
<pre><code>import requests
import threading

resources = [
    "dfactory.com",
    "dog.com",
    "cat.com",
]

def result_catcher(resource):
    template_url = "https://namebio.com/{}".format(resource)
    get = requests.get(template_url)


threads = []

for resource in resources:
    t = threading.Thread(target=result_catcher, args=(resource,) )
    t.start()
    threads.append(t)

for thread in threads:
    thread.join()

print("All threads done executing.")
</code></pre>
<p>By the way, there will be an optimal number of threads to start, which is less than N.  Create a thread pool, and when one thread is done have it go back and read another resource path from a worker queue.  You'll have to run some tests to figure out how many threads are optimal. Creating 10,000 threads is not optimal.  If you have four cores, as few as 10 threads may be optimal.</p>
</div>
<span class="comment-copy">Oh, I see, I will take a look at the urlib3 wikipage now. Do you have an idea on how to fix this?</span>
<span class="comment-copy">@Fozoro, Can you <code>print(template_url)</code> and post the url that causes the error?</span>
<span class="comment-copy">good call, the url is <a href="https://namebio.com/dfactory.com" rel="nofollow noreferrer">namebio.com/dfactory.com</a> what makes all this even more strange is that dfactory.com is the first domain in the list</span>
<span class="comment-copy">What happens if you try: <code>get = requests.get("https://namebio.com/dfactory.com")</code>?  I do not get an error when I do that.</span>
<span class="comment-copy">I would assume that this is due to the fact that it will just skip the url that causes the problem (PS: I donâ€™t think that you can actually get an error when using try:)</span>
