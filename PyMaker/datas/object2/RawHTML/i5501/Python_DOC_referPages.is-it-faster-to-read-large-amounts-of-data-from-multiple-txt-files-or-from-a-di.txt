<div class="post-text" itemprop="text">
<p>I am working on a personal project (using Python 3) that will retrieve weather information for any city in the United States.  My program prompts the user to enter as many city-state combinations as they wish, and then it retrieves the weather information and creates a weather summary for each city entered.  Behind the scenes, I'm essentially taking the State entered by the user, opening a .txt file corresponding to that State, and then getting a weather code that is associated with the city entered, which I then use in a URL request to find weather information for the city.  Since I have a .txt file for every state, I have 50 .txt files, each with a large number of city-weather code combinations.</p>
<p>Would it be faster to keep my algorithm the way that it currently is, or would it be faster to keep all of this data in a dictionary? This is how I was thinking about storing the data in a dictionary:</p>
<pre><code>info = {'Virginia':{'City1':'ID1','City2':'ID2'},'North Carolina':{'City3':'ID3'}} 
</code></pre>
<p>I'd be happy to provide some of my code or elaborate if necessary.</p>
<p>Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>If you have a large datafile, you will spend days shifting through the file and putting the values in the .py file. If it is a small file I would use a dictionary, but if it were a large file a .txt file.</p>
<p>Other possible solutions are: </p>
<ul>
<li><p>sqlite</p></li>
<li><p><a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer">pickle</a></p></li>
<li><p><a href="https://docs.python.org/3/library/shelve.html" rel="nofollow noreferrer">shelve</a></p></li>
</ul>
<h3>Other Resources</h3>
<p><a href="https://stackoverflow.com/questions/3276230/basic-data-storage-with-python">Basic data storage with Python</a><br/>
<a href="https://docs.python.org/3/library/persistence.html" rel="nofollow noreferrer">https://docs.python.org/3/library/persistence.html</a><br/>
<a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer">https://docs.python.org/3/library/pickle.html</a><br/>
<a href="https://docs.python.org/3/library/shelve.html" rel="nofollow noreferrer">https://docs.python.org/3/library/shelve.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>It almost certainly would be much faster to preload the data from the files, <em>if</em> you're using the same python process for many user requests. If the process handles just one request and exits, this approach would be slower <em>and</em> use more memory. For some number of requests between "one" and "many", they'd be about equal on speed.</p>
<p>For a situation like this I would probably use <a href="https://sqlite.org/" rel="nofollow noreferrer">sqlite</a>, for which python has built-in support. It would be much faster than scanning text files without the time and memory overhead of loading the full dictionary.</p>
</div>
<div class="post-text" itemprop="text">
<p>It is probably not a very good idea to have a large amount of text files, because it will slow down in large or numerous director(y|ies) access. But If you have large data records, you might wish to choose an intermediate solution, in indexing one data file and load the index in a dictionary.</p>
</div>
<span class="comment-copy">How big are those txt files?</span>
