<div class="post-text" itemprop="text">
<p>I use the following code to dynamically generate a list of dictionaries of every combination of incremental probabilities associated with a given list of items, such that the probabilities sum to 1. For example, if the <code>increment_divisor</code> were <code>2</code> (leading to increment of <code>1/2</code> or <code>0.5</code>), and the list contained 3 items <code>['a', 'b', 'c']</code>, then the function should return</p>
<pre><code>[{'a': 0.5, 'b': 0.5, 'c': 0.0},
 {'a': 0.5, 'b': 0.0, 'c': 0.5},
 {'a': 0.0, 'b': 0.5, 'c': 0.5},
 {'a': 1.0, 'b': 0.0, 'c': 0.0},
 {'a': 0.0, 'b': 1.0, 'c': 0.0},
 {'a': 0.0, 'b': 0.0, 'c': 1.0}]
</code></pre>
<p>The code is as follows. The script generates the incrementer by calculating <code>1/x</code> and then iteratively adds the incrementer to <code>increments</code> until the value is <code>&gt;= 1.0</code>. I already know that python <code>float</code>s are imprecise, but I want to be sure that the last value in <code>increments</code> will be something very close to 1.0.</p>
<pre><code>from collections import OrderedDict
from itertools import permutations

def generate_hyp_space(list_of_items, increment_divisor):
    """Generate list of OrderedDicts filling the hypothesis space.

    Each OrderedDict is of the form ...
    { i1: 0.0, i2: 0.1, i3: 0.0, ...}
    ... where .values() sums to 1.

    Arguments:
    list_of_items     -- items that receive prior weights
    increment_divisor -- Increment by 1/increment_divisor. For example,
                         4 yields (0.0, 0.25, 0.5, 0.75, 1.0).
    """
    _LEN = len(list_of_items)
    if increment_divisor &lt; _LEN:  # permutations() returns None if this is True
        print('WARN: increment_divisor too small, so was reset to '
              'len(list_of_items).', file=sys.stderr)
        increment_divisor = _LEN
    increment_size = 1/increment_divisor
    h_space = []
    increments = []
    incremental = 0.0
    while incremental &lt;= 1.0:
        increments.append(incremental)
        incremental += increment_size
    for p in permutations(increments, _LEN):
        if sum(p) == 1.0:
            h_space.append(OrderedDict([(list_of_items[i], p[i])
                                        for i in range(_LEN)]))
    return h_space
</code></pre>
<p>How large can the <code>increment_divisor</code> be before the imprecision of <code>float</code> breaks the reliability of the script? (specifically, <code>while incremental &lt;= 1.0</code> and <code>if sum(p) == 1.0</code>)</p>
<p>This is a small example, but real use will involve much larger permutation space. Is there a more efficient/effective way to achieve this goal? (I already plan to implement a cache.) Would <code>numpy</code> datatypes be useful here for speed or precision?</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>The script generates the incrementer by calculating <code>1/x</code> and then iteratively adds the incrementer to <code>increments</code> until the value is <code>&gt;= 1.0</code>.</p>
</blockquote>
<p>No, no, no. Just make a list of <code>[0/x, 1/x, ..., (x-1)/x, x/x]</code> by dividing each integer from 0 to x by x:</p>
<pre><code>increments = [i/increment_divisor for i in range(increment_divisor+1)]
# or for Python 2
increments = [1.0*i/increment_divisor for i in xrange(increment_divisor+1)]
</code></pre>
<p>The list will always have exactly the right number of elements, no matter what rounding errors occur.</p>
<hr/>
<p>With NumPy, this would be <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.linspace.html" rel="nofollow noreferrer"><code>numpy.linspace</code></a>:</p>
<pre><code>increments = numpy.linspace(start=0, stop=1, num=increment_divisor+1)
</code></pre>
<hr/>
<p>As for your overall problem, working in floats at all is probably a bad idea. You should be able to do the whole thing with integers and only divide by <code>increment_divisor</code> at the end, so you don't have to deal with floating-point precision issues in <code>sum(p) == 1.0</code>. Also, <code>itertools.permutations</code> doesn't do what you want, since it doesn't allow repeated items in the same permutation.</p>
<p>Instead of filtering permutations at all, you should use an algorithm based on the <a href="https://en.wikipedia.org/wiki/Stars_and_bars_(combinatorics)" rel="nofollow noreferrer">stars and bars</a> idea to generate all possible ways to place <code>len(list_of_items) - 1</code> separators between <code>increment_divisor</code> outcomes, and convert separator placements to probability dicts.</p>
</div>
<div class="post-text" itemprop="text">
<p>Thanks to @user2357112 for...</p>
<ol>
<li>...pointing out the approach to work with <code>int</code>s until the last step.</li>
<li>...directing me to stars and bars approach.</li>
</ol>
<p>I implemented <code>stars_and_bars</code> as a generator as follows:</p>
<pre><code>def stars_and_bars(n, k, the_list=[]):
    """Distribute n probability tokens among k endings.

    Generator implementation of the stars-and-bars algorithm.

    Arguments:
    n   --  number of probability tokens (stars)
    k   --  number of endings/bins       (bars+1)
    """
    if n == 0:
        yield the_list + [0]*k
    elif k == 1:
        yield the_list + [n]
    else:
        for i in range(n+1):
            yield from stars_and_bars(n-i, k-1, the_list+[i])
</code></pre>
</div>
<span class="comment-copy">I'm not able to follow your work here entirely. But you really should not do stuff like this: <code>sum(p) == 1.0</code>. When using numpy, you can use the more safe <code>np.isclose(x, 1.0)</code> and tune it's parameters for your use-case. Depending on your problem, you can also always scale your vector to sum up to 1, but that depends on what you actually want to do. Numpy's dtypes only help on fp-accuracy level. Meaning: np.float64 should behave quite similar (check the internals) compared to python's default and depending on your OS/Compiler, there is also np.float128.</span>
<span class="comment-copy">Different implementations of <b>sum</b> is another complexity. Read <a href="https://docs.python.org/3/library/math.html#math.fsum" rel="nofollow noreferrer">this</a>.</span>
<span class="comment-copy">Why not use the <code>decimal</code> module? What are you hoping to gain from <code>numpy</code>? Numpy floats suffer from the same underlying problems of floating point arithmetic, it just offers a beefier <code>np.float128</code>. As for speed, it depends on what you want to do, but unless it involves large arrays and vectorized operations, it likely will not help from the speed perspective either.</span>
<span class="comment-copy">@bebop can also use the difference between this method and his own as a practical introduction to numeric instability.</span>
<span class="comment-copy">@user2357112 Great thoughts, thanks. I actually do want to use permutations, since each item should only have one probability assigned to it. Since that is the case, the stars and bars algorithm isn't relevant, is it?</span>
<span class="comment-copy">@bebop: Stars and bars is highly relevant.</span>
<span class="comment-copy">Don't just look at the final formula; look at the actual concept used in the proof.</span>
<span class="comment-copy">@user2357112 Thanks! See my answer here: <a href="http://stackoverflow.com/a/43285539/2903532">stackoverflow.com/a/43285539/2903532</a></span>
