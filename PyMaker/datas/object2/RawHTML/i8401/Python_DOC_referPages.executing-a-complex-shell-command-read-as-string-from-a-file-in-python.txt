<div class="post-text" itemprop="text">
<p>I have a configuration file where user can specify a set of shell commands.
Commands are basically a chain of pipe-separated shell commands.</p>
<pre><code>CMD1 = grep "SomeOtherString" | grep "XX" | cut -d":" -f9 | cut -d"," -f1

CMD2 = grep "SomeOtherString" | tail -1| cut -d":" -f9 | cut -d"," -f1 | cut -d"[" -f2 | cut -d"]" -f1
</code></pre>
<p>I am able to read the commands in my Python scripts. My question is how will I be able to run these read command strings in Python and get the output.</p>
<p>Any solution with <code>subprocess</code>, <code>plumbum</code>, <code>sh</code> will be acceptable.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use <a href="https://docs.python.org/3/library/subprocess.html#subprocess.check_output" rel="nofollow noreferrer">subprocess.check_output</a>()</p>
<pre><code>output = subprocess.check_output(output)
</code></pre>
<p>Something to be aware of is that unlike the other subprocess commands, a subprocess.CalledProcessError will be raised if a non-zero error code is returned.</p>
<hr/>
<p>You shouldn't need to do this, but in case it comes in handy to somebody out there, I did run into an experience once where for some reason the above solution did not work, and so, instead, I did the following.</p>
<pre><code>    stdout_fh = io.StringIO()
    stderr_fh = io.StringIO()
    with redirect_stderr(stderr_fh):
        with redirect_stdout(stdout_fh):
            subprocess.run(command, shell=True)
    stderr = stderr_fh.getvalue()
    stdout = stderr_fh.getvalue()
</code></pre>
</div>
<span class="comment-copy">if you know about subprocess, why not try it? <a href="https://docs.python.org/3/library/subprocess.html" rel="nofollow noreferrer">docs.python.org/3/library/subprocess.html</a> , <a href="https://stackoverflow.com/documentation/python/1393/subprocess-library#t=201704070552204503464">stackoverflow.com/documentation/python/1393/â€¦</a></span>
<span class="comment-copy">As an aside, your pipelines look like they want to be small Awk scripts instead.  <code>CMD1 = awk -F: '/SomeOtherString/ &amp;&amp; /XX/ { s=$9; sub(/,.*/, "", s); print s }'</code> and <code>CMD2 = awk -F: '/SomeOtherString { s=$9; sub(/][^],]*,.*/, "", s); sub(/^[^[]*\[/, "", s); } END { print s }'</code></span>
<span class="comment-copy">@tripleee yes , it can have awk commands too : grep "Something" ${LOGFILE}|tail -1|awk -F"=" '{ print $3 }'</span>
<span class="comment-copy">My point is that your scripts probably should probably be written entirely, or at least predominantly in Awk.  Once you have more than two or three <code>grep</code> and <code>cut</code> and <code>tail</code> commands in a pipeline, you should start thinking.  And of course, your latest example is much better written <code>awk -F= '/Something/ { s=$3 } END { print s }' "$LOGFILE"</code></span>
<span class="comment-copy">Thanks .. we ll m more inclined to know what issues can occur if i pass a chain of commands as string to python subprocesss</span>
