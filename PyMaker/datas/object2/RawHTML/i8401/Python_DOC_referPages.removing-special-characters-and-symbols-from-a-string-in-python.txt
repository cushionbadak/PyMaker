<div class="post-text" itemprop="text">
<p>I am trying to do what my title says. I have a list of about 30 thousand business addressess, and I'm trying to make each address as uniform as possible</p>
<p>As far as removing weird symbols and characters goes, I have found three suggestions, but I don't understand how they are different.</p>
<p>If somebody can explain the difference, or provide insight into a better way to standardize address information, please and thank you!</p>
<pre><code>address = re.sub(r'([^\s\w]|_)+', '', address)

address = re.sub('[^a-zA-Z0-9-_*.]', '', address)

address = re.sub(r'[^\w]', ' ', address)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The first suggestion uses the <code>\s</code> and <code>\w</code> regex wildcards.</p>
<p><code>\s</code> means "match any whitespace".
<code>\w</code> means "match any letter or number".</p>
<p>This is used as an inverted capture group (<code>[^\s\w]</code>), which, all together, means "match anything which isn't whitespace, a letter or a number". Finally, it is combined using an alternative <code>|</code> with <code>_</code>, which will just match an underscore and given a <code>+</code> quantifier which matches one or more times.</p>
<p>So what this says is: "Match any sequence of one or more characters which aren't whitespace, letters, numbers or underscores and remove it".</p>
<p>The second option says: "Match any character which isn't a letter, number, hyphen, underscore, dot or asterisk and remove it". This is stated by that big capture group (the stuff between the brackets).</p>
<p>The third option says "Take anything which is not a letter or number and replace it by a space". It uses the <code>\w</code> wildcard, which I have explained.</p>
<p>All of the options use <em>Regular Expressions</em> in order to match character sequences with certain characteristics, and the <code>re.sub</code> function, which <em>sub</em>-stitutes anything matched by the given regex by the second string argument.</p>
<p>You can read more about Regular Expressions in Python <a href="https://docs.python.org/2/library/re.html" rel="nofollow noreferrer">here</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>The enumeration <code>[^a-zA-Z0-9-_*.]</code> enumerates exactly the character ranges to remove (though the literal <code>-</code> should be at the beginning or end of the character class).</p>
<p><code>\w</code> is defined as "word character" which in traditional ASCII locales included A-Z and a-z as well as digits and underscore, but with Unicode support, it matches accented characters, Cyrillics, Japanese ideographs, etc.</p>
<p><code>\s</code> matches space characters, which again with Unicode includes a number of extended characters such as the non-breakable space, numeric space, etc.</p>
<p>Which exactly to choose obviously depends on what you want to accomplish and what you mean by "special characters".  Numbers are "symbols", all characters are "special", etc.</p>
<p>Here's a pertinent quotation from <a href="https://docs.python.org/3/library/re.html" rel="nofollow noreferrer">the Python <code>re</code> documentation</a>:</p>
<blockquote>
<p>\s</p>
<blockquote>
<p>For Unicode (str) patterns:</p>
<blockquote>
<p>Matches Unicode whitespace characters (which includes <code>[ \t\n\r\f\v]</code>, and also many other characters, for example the non-breaking spaces mandated by typography rules in many languages). If the <code>ASCII</code> flag is used, only <code>[ \t\n\r\f\v]</code> is matched (but the flag affects the entire regular expression, so in such cases using an explicit <code>[ \t\n\r\f\v]</code> may be a better choice).</p>
</blockquote>
<p>For 8-bit (bytes) patterns:</p>
<blockquote>
<p>Matches characters considered whitespace in the ASCII character set; this is equivalent to <code>[ \t\n\r\f\v]</code>.</p>
</blockquote>
</blockquote>
<p>\w</p>
<blockquote>
<p>For Unicode (str) patterns:</p>
<blockquote>
<p>Matches Unicode word characters; this includes most characters that can be part of a word in any language, as well as numbers and the underscore. If the <code>ASCII</code> flag is used, only <code>[a-zA-Z0-9_]</code> is matched (but the flag affects the entire regular expression, so in such cases using an explicit <code>[a-zA-Z0-9_]</code> may be a better choice).</p>
</blockquote>
<p>For 8-bit (bytes) patterns:</p>
<blockquote>
<p>Matches characters considered alphanumeric in the ASCII character set; this is equivalent to <code>[a-zA-Z0-9_]</code>.</p>
</blockquote>
</blockquote>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>How you read the <code>re.sub</code> function is like this (<a href="https://docs.python.org/2/library/re.html#re.sub" rel="nofollow noreferrer">more docs</a>):</p>
<pre><code>re.sub(a, b, my_string)  # replace any matches of regex a with b in my_string
</code></pre>
<p>I would go with the second one. Regexes can be tricky, but this one says:</p>
<pre><code>[^a-zA-Z0-9-_*.]   # anything that's NOT a-z, A-Z, 0-9, -, * .
</code></pre>
<p>Which seems like it's what you want. Whenever I'm using regexes, I use this site:</p>
<p><a href="http://regexr.com/" rel="nofollow noreferrer">http://regexr.com/</a></p>
<p>You can put in some of your inputs, and make sure they are matching the right kinds of things before throwing them in your code! </p>
</div>
<span class="comment-copy">They all do pretty much the same thing, with slight variations in what they delete. Without knowing what you think is non-weird it's hard to give any advice.. The regex howto will tell you what the different categories mean: <a href="https://docs.python.org/2/howto/regex.html#regex-howto" rel="nofollow noreferrer">docs.python.org/2/howto/regex.html#regex-howto</a></span>
<span class="comment-copy">Each little component of the regexes are explained here (pretty complicated, but searchable!): <a href="https://docs.python.org/2/library/re.html#regular-expression-syntax" rel="nofollow noreferrer">docs.python.org/2/library/re.html#regular-expression-syntax</a></span>
<span class="comment-copy">If "address" is an email address, you are truncating some valid characters.  If you are a spammer, that's a good thing.</span>
