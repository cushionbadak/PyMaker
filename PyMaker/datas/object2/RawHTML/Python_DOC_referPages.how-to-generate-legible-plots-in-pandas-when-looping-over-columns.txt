<div class="post-text" itemprop="text">
<p>Generate the dataframe for replicability:</p>
<pre><code>df = pd.DataFrame(np.random.randn(50, 1000), columns=list('ABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDED'))
</code></pre>
<p>Check for normalcy of distribution of each variable (note: this takes a long time to run)</p>
<pre><code># Set the column names

columns= df.columns

# Loop over all columns

fig, axs = plt.subplots(len(df.columns), figsize=(5, 25))
for n, col in enumerate(df.columns):
    df[col].hist(ax=axs[n])
</code></pre>
<p>Result generates illegible histograms and takes a very long time to run.</p>
<p>The length of time is okay, but I am curious if anyone has suggestions for generating legible histograms (do not have to be fancy), which can be quickly reviewed for the entire dataframe to ensure the normality of the distributions.</p>
</div>
<div class="post-text" itemprop="text">
<p>I really like <a href="https://stackoverflow.com/a/55254844/3284713">Nathaniel's</a> answer but I will add my two cents.</p>
<p>I would go for <a href="https://seaborn.pydata.org/index.html" rel="nofollow noreferrer">seaborn</a> and in particular <a href="https://seaborn.pydata.org/generated/seaborn.distplot.html" rel="nofollow noreferrer">seaborn.distplot</a>. 
This will allow you to easily fit a normal distribution to each histogram plot and make the visualization easier.</p>
<pre><code>import seaborn as sns
from scipy.stats import norm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

cols = 1000
df = pd.DataFrame(np.random.normal(0, 1, [50, cols]))
from scipy.stats import norm
fig, ax = plt.subplots(figsize = (16, 10))
for i, col in enumerate(df.columns):
    ax=fig.add_subplot(25, 4, i+1)
    sns.distplot(df[col],fit=norm, kde=False,ax=ax)
plt.tight_layout()
</code></pre>
<p>Additionally, I am not sure if putting columns with the same name in your example was done on purpose. If that's the case the easiest solution to loop through the columns is to use <code>.iloc</code> and the code would look like this:</p>
<pre><code>import seaborn as sns
from scipy.stats import norm
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

 df = pd.DataFrame(np.random.randn(50, 1000), columns=list('ABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDEDABCDABCDED'))

fig, ax = plt.subplots(figsize = (12, 10))
for i, col in enumerate(df.columns):
    plt.subplot(25, 40, i+1)
    sns.distplot(df.iloc[:,i],fit=norm, kde=False,ax=plt.gca())
    plt.axis('off')
plt.tight_layout()
</code></pre>
<p><a href="https://i.stack.imgur.com/tnv1v.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/tnv1v.png"/></a></p>
</div>
<div class="post-text" itemprop="text">
<p>This code generates 1000 histograms and allows you to see each one in sufficient detail to understand how normally-distributed the columns are:</p>
<pre><code>import pandas as pd
import matplotlib.pyplot as plt

cols = 1000
df = pd.DataFrame(np.random.normal(0, 1, [50, cols]))

# Loop over all columns
fig, ax = plt.subplots(figsize = (16, 10))
for n, col in enumerate(df.columns):
    plt.subplot(25, 40, n+1)
    df[col].hist(ax = plt.gca())
    plt.axis('off')
plt.tight_layout()

plt.savefig('1000_histograms.png', bbox_inches='tight', pad_inches = 0, dpi = 200)
</code></pre>
<p><a href="https://i.stack.imgur.com/y6oRI.png" rel="nofollow noreferrer"><img alt="1000 histograms" src="https://i.stack.imgur.com/y6oRI.png"/></a></p>
<p>Another way to ascertain normality is with a QQ plot, which may be easier to visualize in bulk compared to a histogram:</p>
<pre><code>import statsmodels.api as sm

cols = 1000
df = pd.DataFrame(np.random.normal(0,1, [50, cols]))

fig, axs = plt.subplots(figsize=(18, 12))
for n, col in enumerate(df.columns):
    plt.subplot(25,40,n+1)
    sm.qqplot(df[col], ax=plt.gca(), #line='45', 
              marker='.', markerfacecolor='C0', markeredgecolor='C0', 
              markersize=2)
#    sm.qqline(ax=plt.gca(), line='45', fmt='lightgray')
    plt.axis('off')

plt.savefig('1000_QQ_plots13.png', bbox_inches='tight', pad_inches=0, dpi=200)
</code></pre>
<p><a href="https://i.stack.imgur.com/INvk7.png" rel="nofollow noreferrer"><img alt="1000 QQ plots" src="https://i.stack.imgur.com/INvk7.png"/></a></p>
<p>The closer each line is to a 45 degree diagonal, the more normally-distributed the column data is.</p>
</div>
<div class="post-text" itemprop="text">
<ol>
<li>Plotting vs normality test</li>
<li>Proposition</li>
<li>Output example</li>
<li>Corresponding code sample</li>
</ol>
<h2>Plotting vs normality test</h2>
<p>As discussed in comments below, the OP question has changed to thousands of plots management. From that perspective, <a href="https://stackoverflow.com/a/55254844/7237062">Nathaniel answer's is appropriate</a>.</p>
<p>However, I felt that the unsaid intent was to decide wheter a given variable was normally distributed or not, with thousands+ variables to consider.</p>
<blockquote>
<p>Check for normalcy of distribution of each variable (note: this takes a long time to run)</p>
</blockquote>
<p>With that in mind, it appears (to me) that having a human reviewing thousands of plots to spot normal/non-normal distributions is an innapropriate method. There is a french idiom for this: "usine à gaz" ("gas factory")</p>
<p>Therefore, this answer focuses on performing the analysis programmatically and provide some kind of more concise report.</p>
<h2>Proposition</h2>
<p>Perform analysis of data normality over a huge number of columns.
It relies on the suggestion expressed <a href="https://stackoverflow.com/a/55211165/7237062">in this answer</a>.</p>
<p>The idea is to:</p>
<ul>
<li>perform a distribution test (normality) for all columns</li>
<li>capitalize into a dataframe the results</li>
<li>Report into a graph the normal/non-normal ratios.</li>
<li>Report the non-normal column names.</li>
</ul>
<p>With this method, we can further use programming to manipulate the normal/non-normal columns. For instance, we could perform additional distribution tests, or plot only the non normal distribution, thus reducing the number of graphs to actually observe.</p>
<h2>Output example:</h2>
<pre><code>------------
Columns probably not a normal dist:
  Column  Not_Normal  p-value   Normality
0      V        True      0.0  Not Normal
0      W        True      0.0  Not Normal
0      X        True      0.0  Not Normal
0      Y        True      0.0  Not Normal
0      Z        True      0.0  Not Normal
</code></pre>
<p><a href="https://i.stack.imgur.com/vhwFD.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/vhwFD.png"/></a></p>
<p><em>Disclaimer: methods used may not be statistically "canonical". One should be very careful when using statistical tools, since each one as its specific usage domain/use case.</em></p>
<p><em>I chose a 0.01 (1%) p-value, since it could be the upcoming standard value in scientific publications instead of the usual 0.05 (5%))</em></p>
<p><em>One should read <a href="https://en.wikipedia.org/wiki/Normality_test" rel="nofollow noreferrer">https://en.wikipedia.org/wiki/Normality_test</a></em></p>
<blockquote>
<p>Tests of univariate normality include the following:</p>
</blockquote>
<ul>
<li>D'Agostino's K-squared test,</li>
<li>Jarque–Bera test,</li>
<li>Anderson–Darling test,</li>
<li>Cramér–von Mises criterion,</li>
<li>Lilliefors test,</li>
<li>Kolmogorov–Smirnov test</li>
<li>Shapiro–Wilk test, and</li>
<li>Pearson's chi-squared test.</li>
</ul>
<hr/>
<h2>Code</h2>
<p>Behavior may vary on your computer depending on RNG (random numbers generation).
<em>The following example is made with 5 normal random sampling and 5 pareto random sampling using numpy.
The normality test performs well in these conditions (even if I feel that the 0.0 p value tests are suspicious even for a pareto random generation)</em>
Nevertheless, I think we can agree that it is about the <em>method</em>, not actual the results.</p>
<pre><code>import pandas as pd
import numpy as np
import scipy
from scipy import stats
import seaborn as sb
import matplotlib.pyplot as plt
import sys

print('System: {}'.format(sys.version))
for module in [pd, np, scipy, sb]:
    print('Module {:10s} - version {}'.format(module.__name__, module.__version__))

nb_lines = 10000
headers_normal = 'ABCDE'
headers_pareto = 'VWXYZ'
reapeat_factor = 1
nb_cols = len(list(reapeat_factor * headers_normal))

df_normal = pd.DataFrame(np.random.randn(nb_lines, nb_cols), columns=list(reapeat_factor * headers_normal))

df_pareto = pd.DataFrame((np.random.pareto(12.0, size=(nb_lines,nb_cols )) + 15.) * 4., columns=list(reapeat_factor * headers_pareto))

df = df_normal.join(df_pareto)

alpha = 0.01
df_list = list()

# normality code taken from https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html
cat_map = {True: 'Not Normal',
           False: 'Maybe Normal'}
for col in df.columns:
    k2, p = stats.normaltest(df[col])
    is_not_normal = p &lt; alpha
    tmp_df = pd.DataFrame({'Column': [col],
                           'Not_Normal': [is_not_normal],
                           'p-value': [p],
                           'Normality': cat_map[is_not_normal]
                           })
    df_list.append(tmp_df)

df_results = pd.concat(df_list)
df_results['Normality'] = df_results['Normality'].astype('category')

print('------------')
print('Columns names probably not a normal dist:')
# full data
print(df_results[(df_results['Normality'] == 'Not Normal')])
# only column names
# print(df_results[(df_results['Normality'] == 'Not Normal')]['Column'])
print('------------')
print('Plotting countplot')
sb.countplot(data=df_results, y='Normality', orient='v')
plt.show()
</code></pre>
<p>Outputs:</p>
<pre><code>System: 3.7.2 (default, Feb 21 2019, 17:35:59) [MSC v.1915 64 bit (AMD64)]
Module pandas     - version 0.24.1
Module numpy      - version 1.16.2
Module scipy      - version 1.2.1
Module seaborn    - version 0.9.0
------------
Columns names probably not a normal dist:
  Column  Not_Normal  p-value   Normality
0      V        True      0.0  Not Normal
0      W        True      0.0  Not Normal
0      X        True      0.0  Not Normal
0      Y        True      0.0  Not Normal
0      Z        True      0.0  Not Normal
------------
Plotting countplot
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Try something like this:</p>
<pre><code>plt.figure(figsize=(26, 3 * len(df.columns))
for i, col in enumerate(df.columns):
    plt.subplot(3, 4, i + 1)
    plt.hist(df[col], color='blue', bins=100)
    plt.title(col)
</code></pre>
<p>4 is the number of columns, 3 is the number of rows. I suppose instead of 3 it is better to write something like this:</p>
<pre><code>plt.subplot(len(df.columns) / 4, 4, i + 1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Try this - tight_layout ensures no overlap, figsize controls the size of each plot.</p>
<pre><code>import pandas as pd, numpy as np
import matplotlib.pyplot as plt
df = pd.DataFrame(np.random.randn(1000, 3*30), columns=list('ABC'*30))

df.hist(figsize=(20,20))
plt.tight_layout()
plt.show()
</code></pre>
<p>However, if you are after a normality test, would suggest to use something like this: <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html" rel="nofollow noreferrer">https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html</a> instead of relying on visual inspection, especially if you have many variables.</p>
</div>
<span class="comment-copy">@ALollz thank you for the suggestion- I updated the question accordingly.</span>
<span class="comment-copy">duplicate of: <a href="https://stackoverflow.com/questions/54959390/how-to-get-legible-histograms-of-each-column-in-a-dataframe" title="how to get legible histograms of each column in a dataframe">stackoverflow.com/questions/54959390/…</a></span>
<span class="comment-copy">This is a sensible answer to a non-asked question. You don't assess the normality of 1000 samples by reviewing 1000 histograms.</span>
<span class="comment-copy">@Goyo totally agree, I did not write that explicitly: Who would manually review thousands of graphs ?! (BTW That is why I find things like correlograms very limited once you have more than 3-4 variables)</span>
<span class="comment-copy">@LoneWanderer thank you for your response. This is very helpful. However, when I apply your example to my df, I get an error that says:  &lt;ipython-input-45-3c25e104fe88&gt; in &lt;module&gt;      25                            'Not_Normal': [is_not_normal],      26                            'p-value': [p], ---&gt; 27                            'Normality': cat_map[is_not_normal]      28                            })      29     df_list.append(tmp_df) TypeError: unhashable type: 'numpy.ndarray'. I wonder if you might know where that comes from? All my columns contain numbers and I have 743 columns.</span>
<span class="comment-copy">I had issues with your example since several columns had the same name: df[column] would return several columns instead of just one. I'll give a look again to the code.</span>
<span class="comment-copy">see <a href="https://stackoverflow.com/questions/9022656/typeerror-unhashable-type-numpy-ndarray" title="typeerror unhashable type numpy ndarray">stackoverflow.com/questions/9022656/…</a>, some of your shapes might not be consistent for the distributions test (eg: passing <code>[[values,...]]</code>whereas<code>[values, ...]</code>is expected).</span>
