<div class="post-text" itemprop="text">
<p>I have a list containing process objects, and i want only 100 of them to be active and running at any time, and after they are done they should exit from memory, and the next 100 process should start, and so on.., I've writen a demo code in python3, and i want to know if there are any problems or limitation with it.</p>
<pre><code>process = [List of process]
while len(process) != 0:
    i=0
    for i in range (100):
        process[0].start()
        copy = process[0]
        del process[0]
        print(process[0])

    copy.join()
    print("joining")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It might be most sensible to use <code>multiprocessing.Pool</code> which produces a pool of worker processes based on the max number of cores available on your system, and then basically feeds tasks in as the cores become available.</p>
<p>Hardcoding number of process' might actually slow your execution and more importantly, there is a threat of process' entering <code>deadlock</code> state. </p>
<p>In python, multiple process' are spawned according to POSIX standard(using <code>fork</code>). During this <code>fork</code>, everything from the parent except threads are copied into the child process. Be careful of shared memory space and inheriting config from parent to child. More on this if you are interested - <a href="https://stackoverflow.com/questions/53385540/how-can-i-inherit-parent-logger-when-using-pythons-multiprocessing-especially/53385789#53385789">How can I inherit parent logger when using Python's multiprocessing? Especially for paramiko</a></p>
<pre><code>import multiprocessing

def f(name):
    print 'hello', name

if __name__ == '__main__':
    pool = multiprocessing.Pool() #use all available cores, otherwise specify the number you want as an argument
    for i in xrange(0, 512):
        pool.apply_async(f, args=(i,)) #process function f asynchronously.
    pool.close() #safely close the pool and all associated process.
    pool.join() #execute process' in pool.
</code></pre>
<p>Hardcoding something like <code>p = multiprocessing.pool(999999)</code> is likely to suffer a catastrophic death on any machine by grinding disk and grokking RAM.</p>
<p>Number of process's should always be determined by Python and it depends on:</p>
<ol>
<li><p>Hardware capability to run process' simultaneously.</p></li>
<li><p>OS deciding to give resources to process'</p></li>
</ol>
<p>If you still want to hardcode number of process, using semaphore restricted number of process is safe:</p>
<pre><code>pool = multiprocessing.Semaphore(4) # no of cpus of your system.
</code></pre>
<p>Hope this helps.</p>
</div>
<span class="comment-copy">Have you looked into <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow noreferrer">process pools</a>? Or <a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor" rel="nofollow noreferrer">process pool executors</a>.</span>
<span class="comment-copy">have you looked at the question?</span>
