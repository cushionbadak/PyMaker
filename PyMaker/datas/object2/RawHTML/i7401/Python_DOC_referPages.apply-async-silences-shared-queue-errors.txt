<div class="post-text" itemprop="text">
<p>Consider the following example:</p>
<pre><code>from multiprocessing import Queue, Pool

def work(*args):
    print('work')
    return 0

if __name__ == '__main__':
    queue = Queue()
    pool = Pool(1)
    result = pool.apply_async(work, args=(queue,))
    print(result.get())
</code></pre>
<p>This raises the following <code>RuntimeError</code>:</p>
<pre><code>Traceback (most recent call last):
  File "/tmp/test.py", line 11, in &lt;module&gt;
    print(result.get())
  [...]
RuntimeError: Queue objects should only be shared between processes through inheritance
</code></pre>
<p>But interestingly the exception is only raised when I try to <code>get</code> the result, not when the "sharing" happens. Commenting the corresponding line silences the error while I actually <em>did share</em> the queue (and <code>work</code> is never executed!).</p>
<p><strong>So here goes my question:</strong> Why is this exception only raised when the result is requested, and not when the <code>apply_async</code> method is invoked even though the error seems to be recognized because the target <code>work</code> function is never called?</p>
<p>It looks like the exception occurs in a different process and can only be made available to the main process when inter-process communication is performed in form of requesting the result. Then, however, I'd like to know why such checks are not performed <em>before</em> dispatching to the other process.<br/>
(If I used the queue in both <code>work</code> and the main process for communication then this would (silently) introduce a deadlock.)</p>
<hr/>
<p>Python version is 3.5.2.</p>
<hr/>
<p>I have read the following questions:</p>
<ul>
<li><a href="https://stackoverflow.com/a/30039159/3767239">Sharing many queues among processes in Python</a></li>
<li><a href="https://stackoverflow.com/q/3217002/3767239">How do you pass a Queue reference to a function managed by pool.map_async()?</a></li>
<li><a href="https://stackoverflow.com/q/9908781/3767239">Sharing a result queue among several processes</a></li>
<li><a href="https://stackoverflow.com/a/42659752/3767239">Python multiprocessing: RuntimeError: “Queue objects should only be shared between processes through inheritance”</a></li>
<li><a href="https://stackoverflow.com/a/25558333/3767239">Python sharing a lock between processes</a></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>This behavior results from the design of the <code>multiprocessing.Pool</code>.</p>
<p>Internally, when you call <code>apply_async</code>, you put your job in the <code>Pool</code> call queue and then get back a <code>AsyncResult</code> object, which allow you to retrieve your computation result using get.
Another thread is then in charge of pickling your work. In this thread, the <code>RuntimeError</code> happens but you already returned from the call to <code>async_apply</code>. Thus, it sets the results in <code>AsyncResult</code> as the exception, which is raised when you call <code>get</code>.</p>
<p>This behavior using some kind of future results is better understood when you try using <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer"><code>concurrent.futures</code></a>, which have explicit future objects and, IMO, a better design to handle failures, has you can query the future object for failure without calling the <code>get</code> function.</p>
</div>
<span class="comment-copy">Thank you for your answer! I have a question though. If <code>Queue</code> objects cannot be shared among processes via arguments why are we allowed to do exactly this with a <code>multiprocessing.Process</code> object (see <a href="https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes" rel="nofollow noreferrer">this documentation example -&gt; Queues</a>)? This doesn't raise a <code>RuntimeError</code> and works fine, so where is the difference? The arguments must be transferred to the other process as well, as it is the case for the <code>Pool</code>. What about pickling here?</span>
<span class="comment-copy">In the <code>Pool</code>, the process are spawn when you instanciate it. Thus, when you call <code>apply_async</code>, the <code>Process</code> are already started. You can pass a <code>Queue</code> in the <code>Pool</code> using the arguments <code>initializer</code> and <code>initargs</code> to declare a global <code>Queue</code> in the child processes I think.</span>
<span class="comment-copy">You can also declare the <code>Queue</code> as a global attribute of your module, to avoid messing with <code>initializer</code>. <code>pickle</code> should be able to handle this case I think.</span>
