<div class="post-text" itemprop="text">
<p>I'm running into a very peculiar issue with using multiprocessing pools in Python 3... See the code below:</p>
<pre><code>import multiprocessing as MP                                       

class c(object):                                                   
    def __init__(self):                                            
        self.foo = ""                                              

    def a(self, b):                                                
        return b                                                   

    def main(self):                                                
        with open("/path/to/2million/lines/file", "r") as f:
            self.foo = f.readlines()                               

o = c()                                                            
o.main()                                                           
p = MP.Pool(5)                                                     
for r in p.imap(o.a, range(1,10)):                                 
    print(r)                                                       
</code></pre>
<p>If I execute this code as is, this is my extremely slow result:</p>
<pre><code>1
2
3
4
5
6
7
8
9

real    0m6.641s
user    0m7.256s
sys     0m1.824s                    
</code></pre>
<p>However, if i removed the line <code>o.main()</code>, then I get much faster execution time:</p>
<pre><code>1
2
3
4
5
6
7
8
9

real    0m0.155s
user    0m0.048s
sys     0m0.004s
</code></pre>
<p>My environment has plenty of power, and I've made sure I'm not running into any memory limits. I also tested it with a smaller file, and execution time is much more acceptable. Any insight?</p>
<p>EDIT: I removed the disk IO part, and just created a list instead. I can prove the disk IO has nothing to do with the problem...</p>
<pre><code>for i in range(1,500000):
    self.foo.append("foobar%d\n"%i)

real    0m1.763s user    0m1.944s sys     0m0.452s

for i in range(1,1000000):
    self.foo.append("foobar%d\n"%i)
real    0m3.808s user    0m4.064s sys     0m1.016s
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Under the hood, <code>multiprocessing.Pool</code> uses a <code>Pipe</code> to transfer the data from the parent process to the Pool workers.</p>
<p>This adds a hidden cost to the scheduling of tasks as the entire <code>o</code> object gets serialised into a <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer"><code>Pickle</code></a> object and transferred via an OS pipe.</p>
<p>This is done for each and every task you are scheduling (10 times in your example). If your file is 10 Mb in size, you are shifting 100Mb of data.</p>
<p>According to the <a href="https://docs.python.org/3/library/multiprocessing.html?highlight=multiprocessing#programming-guidelines" rel="nofollow noreferrer">multiprocessing Programming Guidelines</a>:</p>
<blockquote>
<p>As far as possible one should try to avoid shifting large amounts of data between processes.</p>
</blockquote>
<p>A simple way to speed up your logic would be calculating the amount of lines in your file, splitting them in equal chunks, sending only the line indexes to the worker processes and let them <code>open</code> the file, <code>seek</code> the right line and process the data.</p>
</div>
<span class="comment-copy">How long does the <code>o.main()</code> take on its own? (Without the following MP code.)</span>
<span class="comment-copy"><code>real    0m0.182s    user    0m0.112s    sys     0m0.068s</code> The file size is actually only 27M.</span>
<span class="comment-copy">Can you try it with <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor" rel="nofollow noreferrer"><code>threadpoolexecutor</code></a> and/or <a href="https://stackoverflow.com/a/3386632/1189040"><code>ThreadPool</code></a> to see if it has something to do with the process overhead ?</span>
