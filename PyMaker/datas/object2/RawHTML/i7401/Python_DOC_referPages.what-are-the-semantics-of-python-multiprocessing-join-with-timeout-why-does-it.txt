<div class="post-text" itemprop="text">
<p>Newbie here in <code>Python</code> and <code>sympy</code>. I have simple question.</p>
<p>If I start a worker using multiprocessing, and give it some small timeout say 3 seconds, in the <code>join</code> call. What happens if the worker is busy itself, may be waiting for something to complete? what happens when the timeout expires and worker itself is waiting for <code>sympy</code>?</p>
<p>I found that if the worker calls <code>sympy</code> on a long computation, the join hangs waiting for the worker, much longer than the time out period. </p>
<p>Here is a MWE</p>
<pre><code>from multiprocessing import Process, Queue
from sympy import *
x = symbols('x')

def worker(integrand,que):
    que.put(integrate(integrand, x))

if __name__ == '__main__':       
    que = Queue()
    result = "still waiting "

    #this first call works OK since it is easy integral
    #action_process = Process(target=worker,args=(cos(x),que))

    #this one hangs inside sympy since hard integral
    p = Process(target=worker,args=(1/(x**3+cos(x)),que))

    # start the process and wait for max of 3 seconds.
    p.start()   
    p.join(timeout=3)
    result=que.get()    
    print("result from worker is " + str(result))
    p.terminate()
</code></pre>
<p><strong>Question:</strong> Is it possible to force the worker to terminate at the timeout? Is there another option to use to do that? Am I doing something wrong in the above?</p>
<p>If not possible to force timeout at join, then what is the meaning of join() after n seconds, if the worker can't join? </p>
<p>Only reason I am trying the above is to find a way to timeout on long computation in <code>sympy</code>, since I am on windows and timers and alarms do not work on windows, so I thought to try multiprocessing with timeout, but it does not seem to do what I want and hence this will not be any use for what I want.</p>
<p>ps. if you run the above, worker will hang inside <code>sympy</code> for long time, may be 10 minutes or more, and might have to kill it manually.</p>
<p>The above is on windows. But I also tried in on Linux, and it also hangs.</p>
<p>Anacode 4.3.1, Python 3.6</p>
<p><strong>Update</strong></p>
<p>Thanks to hint in answer, this below seems to work now</p>
<pre><code>from multiprocessing import Process, Queue
from sympy import *
x = symbols('x')

def worker(integrand,que):
    que.put(integrate(integrand, x))

if __name__ == '__main__':       
    que = Queue()
    result = "timed out "

    #this one hangs inside sympy since hard integral
    p = Process(target=worker,args=(1/(x**3+cos(x)),que))

    # start the process and wait for max of 3 seconds.
    p.start()   
    p.join(timeout=3)

    try:
       result=que.get(block=False)    
    except:
       print("timed out on que.get()")
       pass

    print("result from worker is " + str(result))
    p.terminate()
</code></pre>
<p>I still need to test it more to make sure the worker process() does get killed by terminate as I do not want to have zombie workers around. </p>
</div>
<div class="post-text" itemprop="text">
<p>The reason why your code never reaches the <code>print</code> "in time" is because it doesn't get beyond the <code>result=que.get()</code>. You specified a timeout for <code>p.join</code> which makes the calling process resume after the specified timeout. However <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue.get" rel="nofollow noreferrer"><code>que.get</code></a> is also blocking and therefore waits until an item has been put in the queue. You can specify a timeout here as well: <code>que.get(timeout=...)</code> or simply turn off blocking: <code>que.get(block=False)</code>. In any case, if no item is available in the queue, it will raise a <a href="https://docs.python.org/3/library/queue.html#queue.Empty" rel="nofollow noreferrer"><code>queue.Empty</code></a> exception.</p>
<p>However the documentation contains <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.terminate" rel="nofollow noreferrer">several</a> <a href="https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues" rel="nofollow noreferrer">warnings</a> about terminating a process that holds a (shared) reference to a queue. The <a href="https://docs.python.org/3/library/multiprocessing.html#programming-guidelines" rel="nofollow noreferrer">Programming Guidelines</a> seem to contain a solution for that case and also warn of possible deadlocks (see "Joining processes that use queues").</p>
</div>
<span class="comment-copy">Are you sure that this function has an elementary integral?</span>
<span class="comment-copy">@Anis This one does not. But this is really beside the point. I just needed to set a timeout  on sympy calls.</span>
<span class="comment-copy">thanks. I added updated code using <code>que.get(block=False)</code> it seems to work OK so far. But I am not sure if I still need to check for something else or not.</span>
