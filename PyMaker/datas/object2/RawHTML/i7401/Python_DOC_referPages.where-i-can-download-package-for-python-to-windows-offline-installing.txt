<div class="post-text" itemprop="text">
<p>This is code work when regression, but not work when classification </p>
<blockquote>
<p>import pandas as pd
      import xgboost as xgb
      import numpy as np
      import itertools</p>
</blockquote>
<pre><code>salesPath = "E:\\python\\Salesprog\\"

test = pd.read_excel(salesPath + 'test.xlsx')
test.describe()

def latinizator(letter, dic):
    for i, j in dic.items():
        letter = letter.replace(i, j)
    return letter
&gt;
</code></pre>
<p>This is latinizator, and it work good</p>
<pre><code>&gt;
legend = {
'а':'a',
'б':'b',
'в':'v',
'г':'g',
'д':'d',
'е':'e',
'ё':'yo',
'ж':'zh',
'з':'z',
'и':'i',
'й':'y',
'к':'k',
'л':'l',
'м':'m',
'н':'n',
'о':'o',
'п':'p',
'р':'r',
'с':'s',
'т':'t',
'у':'u',
'ф':'f',
'х':'h',
'ц':'ts',
'ч':'ch',
'ш':'sh',
'щ':'shch',
'ъ':'y',
'ы':'y',
'ь':"'",
'э':'e',
'ю':'yu',
'я':'ya',

'А':'A',
'Б':'B',
'В':'V',
'Г':'G',
'Д':'D',
'Е':'E',
'Ё':'Yo',
'Ж':'Zh',
'З':'Z',
'И':'I',
'Й':'Y',
'К':'K',
'Л':'L',
'М':'M',
'Н':'N',
'О':'O',
'П':'P',
'Р':'R',
'С':'S',
'Т':'T',
'У':'U',
'Ф':'F',
'Х':'H',
'Ц':'Ts',
'Ч':'Ch',
'Ш':'Sh',
'Щ':'Shch',
'Ъ':'Y',
'Ы':'Y',
'Ь':"'",
'Э':'E',
'Ю':'Yu',
'Я':'Ya',
}
phrases = []
for line in test['column_10']:
        phrases.append(latinizator(line, legend))
phrases = pd.DataFrame(phrases, columns = {'column_10'})
</code></pre>
<p>this is xgb regressor, but when classificator, dont work</p>
<pre><code>&gt;
test_y = test[['y_1','y_2','y_3','y_4']]
test_x = test.drop(['column_10','y_1','y_2','y_3','y_4'], axis=1)
test_x_exp2 = test_x**2
for i in list(test_x_exp2):
    test_x_exp2.rename(columns = {i:i+'exp2'}, inplace = True)
test_x_exp3 = test_x**3
for i in list(test_x_exp3):
    test_x_exp3.rename(columns = {i:i+'exp3'}, inplace = True)
test_x_exp4 = test_x**4
for i in list(test_x_exp4):
    test_x_exp4.rename(columns = {i:i+'exp4'}, inplace = True)
test_x_exp12 = test_x**(1/2)
for i in list(test_x_exp12):
    test_x_exp12.rename(columns = {i:i+'exp12'}, inplace = True)
test_x_log = np.log2(test_x)
for i in list(test_x_log):
    test_x_log.rename(columns = {i:i+'log'}, inplace = True)
test_x_sin = np.sin(test_x)
for i in list(test_x_sin):
    test_x_sin.rename(columns = {i:i+'sin'}, inplace = True)
test_x_cos = np.cos(test_x)
for i in list(test_x_cos):
    test_x_cos.rename(columns = {i:i+'cos'}, inplace = True)
summ = test_x 
b = []    
for i in range(2,9):
    for j in list(itertools.combinations(['column_1','column_2','column_4', 'column_5', 'column_6','column_7','column_8','column_9'],i)):
        b.append(j)
for i in b:
    a = 0
    nazv = ''
    for j in i:
        nazv = nazv + str(j)
        a = a + test_x[''+str(j)+'']
    a = pd.DataFrame(a, columns={nazv + 'plus'})    
    summ = summ.join(a)
for i in b:
    a = 0
    nazv = ''
    for j in i:
        nazv = nazv + str(j)
        a = a * test_x[''+str(j)+'']
    a = pd.DataFrame(a, columns={nazv + 'multi'})    
    summ = summ.join(a)
summ = summ.join(test_x_exp2).join(test_x_exp3).join(test_x_exp4).join(test_x_exp12).join(test_x_log).join(test_x_cos).join(test_x_sin)          
</code></pre>
<p>cat_feat thisi is line</p>
<pre><code>cat_feat = ['column_10']
one_hot = pd.get_dummies(phrases['column_10'])
rdf = summ.join(one_hot)
rdf = rdf.join(test_y[['y_2']])
rdf = rdf.join(test_y[['y_1']])

pd.set_option("display.max_columns",100)
rdf.corr()[rdf.corr() &gt; 0.1]

from sklearn.model_selection import train_test_split
trg = test_y[['y_2']]
trn = rdf.drop(['y_1','y_2'], axis=1)


X_train, X_test, y_train, y_test = train_test_split(trn, trg, test_size=0.3, random_state=42)
from sklearn.metrics import r2_score
from sklearn.model_selection import GridSearchCV

xgb_model = xgb.XGBRegressor()


cv = 10
#First step
alpha=[i for i in range(40, 600, 20)]
xgb_params  = [
    {
    "n_estimators": alpha
    }
]
#nacenka.to_excel(salesPath + 'nacenka111.xlsx')
xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=-1, verbose=2)
xgb_grid.fit(X_train, y_train)
</code></pre>
<p>Other rezult</p>
<pre><code>#First result check
xgb_best = xgb.XGBRegressor(n_estimators=xgb_grid.best_params_['n_estimators'])
xgb_best.fit(X_train, y_train)
best_predictions = xgb_best.predict(X_test)
r2_score(y_test, best_predictions)
best_predictions1 = pd.DataFrame(best_predictions)

r2_score(y_test, xgb_grid.predict(X_test))

import matplotlib.pyplot as plot
pred = xgb_best.booster().get_score(importance_type='weight')
print(xgb_best.booster().get_score(importance_type='weight'))
df = pd.DataFrame([pred])
df.plot(kind='bar')

#Second step
alpha1=[i for i in range(3, 10, 2)]
alpha2=[i for i in range(1, 6, 1)]
xgb_params  = [
    {
    "learning_rate": [0.1],
    "n_estimators": [xgb_grid.best_params_['n_estimators']],
    "max_depth": alpha1,
    "min_child_weight": alpha2
    }
]
xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=-1, verbose=3)
xgb_grid.fit(X_train, y_train)

print(xgb_grid.best_params_)

#Third step
# step 2b - tuning max_depth and min_child_weight
xgb_params  = [
    {
    "learning_rate": [0.1],
    "n_estimators": [xgb_grid.best_params_['n_estimators']],
    "max_depth": [xgb_grid.best_params_['max_depth']-1, xgb_grid.best_params_['max_depth'], xgb_grid.best_params_['max_depth']+1],
    "min_child_weight": [xgb_grid.best_params_['min_child_weight']-1, xgb_grid.best_params_['min_child_weight'], xgb_grid.best_params_['min_child_weight']+1]
    }
]

xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=4, verbose=3)
xgb_grid.fit(X_train, y_train)

print(xgb_grid.best_params_)

#Fourth step tuning gamma
xgb_params  = [
    {
    "learning_rate": [0.1],
    "n_estimators": [xgb_grid.best_params_['n_estimators']],
    "max_depth": [xgb_grid.best_params_['max_depth']],
    "min_child_weight": [xgb_grid.best_params_['min_child_weight']],
    "gamma": [i/10.0 for i in range(0,5)]
    }
]

xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=4, verbose=3)
xgb_grid.fit(X_train, y_train)

print(xgb_grid.best_params_)

## step 4 - tuning subsample, colsample_bytree
xgb_params  = [
    {
    "learning_rate": [0.1],
    "n_estimators": [xgb_grid.best_params_['n_estimators']],
    "max_depth": [xgb_grid.best_params_['max_depth']],
    "min_child_weight": [xgb_grid.best_params_['min_child_weight']],
    "gamma": [xgb_grid.best_params_['gamma']],
    "subsample": [i/10.0 for i in range(6,10)],
    "colsample_bytree": [i/10.0 for i in range(6,10)]
    }
]

xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=4, verbose=3)
xgb_grid.fit(X_train, y_train)

print(xgb_grid.best_params_)

# step 5a - tuning regularization
xgb_params  = [
    {
    "learning_rate": [0.1],
    "n_estimators": [xgb_grid.best_params_['n_estimators']],
    "max_depth": [xgb_grid.best_params_['max_depth']],
    "min_child_weight": [xgb_grid.best_params_['min_child_weight']],
    "gamma": [xgb_grid.best_params_['gamma']],
    "subsample": [xgb_grid.best_params_['subsample']],
    "colsample_bytree": [xgb_grid.best_params_['colsample_bytree']],
    'reg_alpha': [1e-5, 0, 0.001, 0.005, 0.01, 1e-05, 0.05, 0.1, 1, 2, 5, 10, 100]
    }
]

xgb_grid = GridSearchCV(xgb_model, xgb_params, scoring='r2', cv=cv, n_jobs=4, verbose=3)
xgb_grid.fit(X_train, y_train)
print(xgb_grid.best_params_)

#Получаем параметры согласно обученной модели
xgb_best = xgb.XGBRegressor(n_estimators=xgb_grid.best_params_['n_estimators'],
                              learning_rate=0.1,
                              max_depth=6, 
                              min_child_weight=8,
                              gamma=xgb_grid.best_params_['gamma'], 
                              subsample=xgb_grid.best_params_['subsample'], 
                              colsample_bytree=xgb_grid.best_params_['colsample_bytree'], 
                              reg_alpha=xgb_grid.best_params_['reg_alpha'])
xgb_best.fit(X_train, y_train)

r2_score(y_test, xgb_best.predict(X_test))
</code></pre>
<p>when regressor start have problem with classificator</p>
</div>
<div class="post-text" itemprop="text">
<p>All the packages are available at <a href="https://pypi.python.org/pypi" rel="nofollow noreferrer">https://pypi.python.org/pypi</a>
Click on the following link to download the corresponding packages:</p>
<ol>
<li>matplotlib - <a href="https://pypi.python.org/pypi/matplotlib" rel="nofollow noreferrer">https://pypi.python.org/pypi/matplotlib</a></li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>Any search engine would have pointed you to:
<a href="https://pypi.python.org/pypi/pip" rel="nofollow noreferrer">https://pypi.python.org/pypi/pip</a></p>
<p>There you can download the <a href="https://docs.python.org/3/installing/index.html" rel="nofollow noreferrer">wheel</a> files, which you can then install using the <code>pip</code> tool locally. If your company prevents access to that site, download the needed packages somewhere else. Be careful to check the dependencies of those packages and also download additional packages.</p>
<p>For windows, an alternative is the <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow noreferrer">Unofficial Windows Binaries</a> by Christoph Gohlke.</p>
<p>P.S.: <a href="https://docs.python.org/3/library/sys.html#module-sys" rel="nofollow noreferrer">sys</a> and <a href="https://docs.python.org/3/library/warnings.html#module-warnings" rel="nofollow noreferrer">warnings</a> are always available.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python package management toolkit like <code>easy_instsall</code> and <code>pip</code> just download the package folder with executable python code to your local folder which is contained by the module search path and manage the dependency. </p>
<p>You could just get the source file of specific module you need and put in your working directory and you are good to go</p>
<p>For example, you could just </p>
<p><code>git clone https://github.com/numpy/numpy.git numpy</code></p>
<p>to put <code>numpy</code> in your project once you download that as a folder in your project (or maybe you'd like to download that with another machine able to connect the internet and copy that folder with an usb drive or something)</p>
<p>More over, this <a href="https://docs.python.org/2/tutorial/modules.html#the-module-search-path" rel="nofollow noreferrer">manual</a> about the Python library search path maybe help you to understand all the stuff under hook</p>
<p><strong>You should be careful about the dependency stuff by this way though.</strong></p>
</div>
<div class="post-text" itemprop="text">
<p>I would definately have a look at Anaconda. <a href="https://www.continuum.io/downloads" rel="nofollow noreferrer">https://www.continuum.io/downloads</a></p>
<p>List of packages included:
<a href="https://docs.continuum.io/anaconda/packages/pkg-docs" rel="nofollow noreferrer">https://docs.continuum.io/anaconda/packages/pkg-docs</a></p>
<p>From what I can see the only package not included is "warnings". </p>
</div>
<span class="comment-copy">I think the op's question is he can't use pip to get package</span>
<span class="comment-copy">The question states that the internet access is prohibited, not the use of the pip tool. This downloading the packages somewhere else and installing from the wheel-files should work.</span>
<span class="comment-copy">hmm, then this maybe better than just download the folder of the module, since pip could manage dependency stuff for us, will delete my answer :D</span>
<span class="comment-copy">@armnotstrong when using pip to install from a local file, dependencies must be present as a local file, too - otherwise <code>pip</code> will try to download it - I think your answer is a viable way, you should restore it.</span>
