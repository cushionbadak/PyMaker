<div class="post-text" itemprop="text">
<p>This is the Python Code:</p>
<pre><code> import numpy as np

  def find_nearest_vector(array, value):
      idx = np.array([np.linalg.norm(x+y) for (x,y) in array-value]).argmin()
      return array[idx]

  A = np.random.random((10,2))*100
  """ A = array([[ 34.19762933,  43.14534123],
  [ 48.79558706,  47.79243283],
  [ 38.42774411,  84.87155478],
  [ 63.64371943,  50.7722317 ],
  [ 73.56362857,  27.87895698],
  [ 96.67790593,  77.76150486],
  [ 68.86202147,  21.38735169],
  [  5.21796467,  59.17051276],
  [ 82.92389467,  99.90387851],
  [  6.76626539,  30.50661753]])"""

  pt = [6, 30]  

  print find_nearest_vector(A,pt)

  #array([  6.76626539,  30.50661753])
</code></pre>
<p>Can somebody explain me the step-by-step process of getting the nearest vector? The whole process of function "find_nearest_vector()". Can someone show me the tracing process of this function? Thank you.</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://en.wikipedia.org/wiki/Euclidean_distance" rel="nofollow noreferrer">From Wikipedia</a>; the L2 (Euclidean) norm is defined as</p>
<p><a href="https://i.stack.imgur.com/S03ZV.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/S03ZV.png"/></a></p>
<p><code>np.linalg.norm</code> simply implements this formula in numpy, but only works for two points at a time. Additionally, it appears your implementation is <em>incorrect</em>, as @unutbu pointed out, it only happens to work by chance in some cases.</p>
<p>If you want to vectorize this, I'd recommend implementing the L2 norm yourself with vectorised numpy.</p>
<p>This works when <code>pt</code> is a 1D array:</p>
<pre><code>&gt;&gt;&gt; pt = np.array(pt)
&gt;&gt;&gt; A[((A - pt[ None, :]) ** 2).sum(1).argmin()]
array([ 6.76626539, 30.50661753])  
</code></pre>
<p>Note, the closest point will have the smallest L2 norm as well as the smallest <em>squared</em> L2 norm, so this is, in a sense, even more efficient than <code>np.linalg.norm</code> which additionally computes the square root. </p>
</div>
<span class="comment-copy"><code>np.linalg.norm(x+y)</code> looks like a mistake. This will not necessarily give you the nearest vector. (Consider what would happen if <code>x = -y</code> and <code>x</code> is very large.)</span>
<span class="comment-copy">Or, more concretely, if <code>A = np.array([[10**6, -10**6], [1,1]]); pt = [0,0]</code> then <code>find_nearest_vector(A, pt)</code> returns <code>array([ 1000000, -1000000])</code> which is clearly wrong -- the nearest vector is <code>[1,1]</code>.</span>
<span class="comment-copy">@unutbu Yup, you're right. My bad.</span>
<span class="comment-copy">Your code could be fixed by replacing <code>np.linalg.norm(x+y)</code> with <code>x**2 + y**2</code>, but it does not leverage NumPy to your advantage. Using a <a href="https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions" rel="nofollow noreferrer">list comprehension</a> here is much slower than <a href="https://stackoverflow.com/a/49467878/190597">cᴏʟᴅsᴘᴇᴇᴅ's solution</a> when <code>len(array)</code> is large.</span>
<span class="comment-copy">Is there any efficient way to get the closest point of an array? Given by the above code? Thanks.</span>
<span class="comment-copy">What is the process of A[((A - pt[ None, :]) ** 2).sum(1).argmin()] ? Can you please explain the step by step process of choosing the closest point? Thankyou.</span>
<span class="comment-copy">Also what is the purpose of .sum(1) here? Your reply is very appreciated. Thanks.</span>
<span class="comment-copy">@CharlotteSampiano Please break it down and run each component yourself to understand what is happening. It's just broadcasted vectorised code for Euclidean distance. Once you understand the formula, translating it to code is very straightforward.</span>
<span class="comment-copy">sum(1) is a sum along the first axis.</span>
