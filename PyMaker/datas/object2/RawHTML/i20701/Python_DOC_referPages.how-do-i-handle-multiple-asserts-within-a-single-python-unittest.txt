<div class="post-text" itemprop="text">
<p>This is a problem that came up when performing a single test that had multiple independent failure modes, due to having multiple output streams.  I also wanted to show the results of asserting the data on all those modes, regardless of which failed first.  Python's unittest has no such feature outside of using a Suite to represent the single test, which was unacceptable since my single test always needed to be run as a single unit; it just doesn't capture the nature of the thing.</p>
<p>A practical example is testing an object that also generates a log.  You want to assert the output of it's methods, but you also want to assert the log output.  The two outputs require different tests, which can be neatly expressed as two of the stock asserts expressions, but you also don't want the failure of one to hide the possible failure of the other within the test.  So you really need to test both at the same time.</p>
<p>I cobbled together this useful little widget to solve my problem.</p>
<pre><code>def logFailures(fnList):
    failurelog = []
    for fn in fnList:
        try:
            fn()
        except AssertionError as e:
            failurelog.append("\nFailure %d: %s" % (len(failurelog)+1,str(e)))

    if len(failurelog) != 0:
        raise AssertionError(
            "%d failures within test.\n %s" % (len(failurelog),"\n".join(failurelog))
        )
</code></pre>
<p>Which is used like so:</p>
<pre><code>def test__myTest():
    # do some work here
    logFailures([
        lambda: assert_(False,"This test failed."),
        lambda: assert_(False,"This test also failed."),
    ])
</code></pre>
<p>The result is that logFailures() will raise an exception that contains a log of all the assertions that were raised in methods within the list.</p>
<p><strong>The question:</strong> While this does the job, I'm left wondering if there's a better way to handle this, other than having to go to the length of creating nested suites of tests and so forth?</p>
</div>
<div class="post-text" itemprop="text">
<p>I disagree with the dominant opinion that one should write a test method for each assertion. There are situations where you want to check multiple things in one test method. Here is my answer for how to do it:</p>
<pre><code># Works with unittest in Python 2.7
class ExpectingTestCase(unittest.TestCase):
    def run(self, result=None):
        self._result = result
        self._num_expectations = 0
        super(ExpectingTestCase, self).run(result)

    def _fail(self, failure):
        try:
            raise failure
        except failure.__class__:
            self._result.addFailure(self, sys.exc_info())

    def expect_true(self, a, msg):
        if not a:
            self._fail(self.failureException(msg))
        self._num_expectations += 1

    def expect_equal(self, a, b, msg=''):
        if a != b:
            msg = '({}) Expected {} to equal {}. '.format(self._num_expectations, a, b) + msg
            self._fail(self.failureException(msg))
        self._num_expectations += 1
</code></pre>
<p>And here are some situations where I think it's useful and not risky:</p>
<p>1) When you want to test code for different sets of data. Here we have an add() function and I want to test it with a few example inputs. To write 3 test methods for the 3 data sets means repeating yourself which is bad. Especially if the call was more elaborate.:</p>
<pre><code>class MyTest(ExpectingTestCase):
    def test_multiple_inputs(self):
        for a, b, expect in ([1,1,2], [0,0,0], [2,2,4]):
            self.expect_equal(expect, add(a,b), 'inputs: {} {}'.format(a,b))
</code></pre>
<p>2) When you want to check multiple outputs of a function. I want to check each output but I don't want a first failure to mask out the other two.</p>
<pre><code>class MyTest(ExpectingTestCase):
    def test_things_with_no_side_effects(self):
        a, b, c = myfunc()
        self.expect_equal('first value', a)
        self.expect_equal('second value', b)
        self.expect_equal('third value', c)
</code></pre>
<p>3) Testing things with heavy setup costs. Tests must run quickly or people stop using them. Some tests require a db or network connection that takes a second which would really slow down your test. If you are testing the db connection itself, then you probably need to take the speed hit. But if you are testing something unrelated, we want to do the slow setup once for a whole set of checks.</p>
</div>
<div class="post-text" itemprop="text">
<p>This feels like over-engineering to me.  Either:</p>
<ul>
<li><p>Use two asserts in one test case. If the first assert fails, it's true, you won't know whether the second assert passed or not.  But you're going to fix the code anyway, so fix it, and then you'll find out if the second assert passed.</p></li>
<li><p>Write two tests, one to check each condition.  If you fear duplicated code in the tests, put the bulk of the code in a helper method that you call from the tests.</p></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>With using a subtest, execution would not stop after the first failure
<a href="https://docs.python.org/3/library/unittest.html#subtests" rel="noreferrer">https://docs.python.org/3/library/unittest.html#subtests</a></p>
<p>Here are example with two fail asserts:</p>
<pre><code>class TestMultipleAsserts(unittest.TestCase):

    def test_multipleasserts(self):
        with self.subTest():
            self.assertEqual(1, 0)
        with self.subTest():
            self.assertEqual(2, 0)
</code></pre>
<p>Output will be:</p>
<pre><code>======================================================================
FAIL: test_multipleasserts (__main__.TestMultipleAsserts) (&lt;subtest&gt;)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "./test.py", line 9, in test_multipleasserts
    self.assertEqual(1, 0)
AssertionError: 1 != 0

======================================================================
FAIL: test_multipleasserts (__main__.TestMultipleAsserts) (&lt;subtest&gt;)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "./test.py", line 11, in test_multipleasserts
    self.assertEqual(2, 0)
AssertionError: 2 != 0

----------------------------------------------------------------------
Ran 1 test in 0.000s

FAILED (failures=2)
</code></pre>
<p>You can easy wrap subtest as following</p>
<pre><code>class MyTestCase(unittest.TestCase):
    def expectEqual(self, first, second, msg=None):
        with self.subTest():
            self.assertEqual(first, second, msg)

class TestMA(MyTestCase):
    def test_ma(self):
        self.expectEqual(3, 0)
        self.expectEqual(4, 0)
</code></pre>
</div>
<span class="comment-copy">"you also don't want the failure of one to hide the possible failure of the other within the test". If you want to test two different things, make it two different tests!</span>
<span class="comment-copy">"you also don't want the failure of one to hide the possible failure of the other within the test". Yes - I want: these are unit tests.  If one test failes, correct the failing and re-run the tests.</span>
<span class="comment-copy">Something like this should be present in unit test frameworks by default. Does anybody know one that has this functionality?</span>
<span class="comment-copy">It is important to note that this only applies to Python 3.4 and later, according to your link</span>
