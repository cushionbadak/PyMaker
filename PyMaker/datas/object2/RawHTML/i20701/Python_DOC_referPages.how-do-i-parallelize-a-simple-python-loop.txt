<div class="post-text" itemprop="text">
<p>This is probably a trivial question, but how do I parallelize the following loop in python?</p>
<pre><code># setup output lists
output1 = list()
output2 = list()
output3 = list()

for j in range(0, 10):
    # calc individual parameter value
    parameter = j * offset
    # call the calculation
    out1, out2, out3 = calc_stuff(parameter = parameter)

    # put results into correct output list
    output1.append(out1)
    output2.append(out2)
    output3.append(out3)
</code></pre>
<p>I know how to start single threads in Python but I don't know how to "collect" the results. </p>
<p>Multiple processes would be fine too - whatever is easiest for this case. I'm using currently Linux but the code should run on Windows and Mac as-well.</p>
<p>What's the easiest way to parallelize this code?</p>
</div>
<div class="post-text" itemprop="text">
<p>Using multiple threads on CPython won't give you better performance for pure-Python code due to the global interpreter lock (GIL).  I suggest using the <a href="http://docs.python.org/library/multiprocessing.html"><code>multiprocessing</code></a> module instead:</p>
<pre><code>pool = multiprocessing.Pool(4)
out1, out2, out3 = zip(*pool.map(calc_stuff, range(0, 10 * offset, offset)))
</code></pre>
<p>Note that this won't work in the interactive interpreter.</p>
<p>To avoid the usual FUD around the GIL: There wouldn't be any advantage to using threads for this example anyway.  You <em>want</em> to use processes here, not threads, because they avoid a whole bunch of problems.</p>
</div>
<div class="post-text" itemprop="text">
<p>To parallelize a simple for loop, <a href="https://joblib.readthedocs.io/en/latest/parallel.html" rel="noreferrer">joblib</a> brings a lot of value to raw use of multiprocessing. Not only the short syntax, but also things like transparent bunching of iterations when they are very fast (to remove the overhead) or capturing of the traceback of the child process, to have better error reporting.</p>
<p>Disclaimer: I am the original author of joblib.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>What's the easiest way to parallelize this code?</p>
</blockquote>
<p>I really like <code>concurrent.futures</code> for this, available in Python3 <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="noreferrer">since version 3.2</a> - and via backport to 2.6 and 2.7 on <a href="http://pythonhosted.org/futures/" rel="noreferrer">PyPi</a>.</p>
<p>You can use threads or processes and use the exact same interface.</p>
<h2>Multiprocessing</h2>
<p>Put this in a file - futuretest.py:</p>
<pre><code>import concurrent.futures
import time, random               # add some random sleep time

offset = 2                        # you don't supply these so
def calc_stuff(parameter=None):   # these are examples.
    sleep_time = random.choice([0, 1, 2, 3, 4, 5])
    time.sleep(sleep_time)
    return parameter / 2, sleep_time, parameter * parameter

def procedure(j):                 # just factoring out the
    parameter = j * offset        # procedure
    # call the calculation
    return calc_stuff(parameter=parameter)

def main():
    output1 = list()
    output2 = list()
    output3 = list()
    start = time.time()           # let's see how long this takes

    # we can swap out ProcessPoolExecutor for ThreadPoolExecutor
    with concurrent.futures.ProcessPoolExecutor() as executor:
        for out1, out2, out3 in executor.map(procedure, range(0, 10)):
            # put results into correct output list
            output1.append(out1)
            output2.append(out2)
            output3.append(out3)
    finish = time.time()
    # these kinds of format strings are only available on Python 3.6:
    # time to upgrade!
    print(f'original inputs: {repr(output1)}')
    print(f'total time to execute {sum(output2)} = sum({repr(output2)})')
    print(f'time saved by parallelizing: {sum(output2) - (finish-start)}')
    print(f'returned in order given: {repr(output3)}')

if __name__ == '__main__':
    main()
</code></pre>
<p>And here's the output:</p>
<pre><code>$ python3 -m futuretest
original inputs: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
total time to execute 33 = sum([0, 3, 3, 4, 3, 5, 1, 5, 5, 4])
time saved by parallellizing: 27.68999981880188
returned in order given: [0, 4, 16, 36, 64, 100, 144, 196, 256, 324]
</code></pre>
<h2>Multithreading</h2>
<p>Now change <code>ProcessPoolExecutor</code> to <code>ThreadPoolExecutor</code>, and run the module again:</p>
<pre><code>$ python3 -m futuretest
original inputs: [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]
total time to execute 19 = sum([0, 2, 3, 5, 2, 0, 0, 3, 3, 1])
time saved by parallellizing: 13.992000102996826
returned in order given: [0, 4, 16, 36, 64, 100, 144, 196, 256, 324]
</code></pre>
<p>Now you have done both multithreading and multiprocessing! </p>
<h2>Note on performance and using both together.</h2>
<p>Sampling is far too small to compare the results.</p>
<p>However, I suspect that multithreading will be faster than multiprocessing in general, especially on Windows, since Windows doesn't support forking so each new process has to take time to launch. On Linux or Mac they'll probably be closer.</p>
<p>You can nest multiple threads inside multiple processes, but it's recommended to not use multiple threads to spin off multiple processes. </p>
</div>
<div class="post-text" itemprop="text">
<pre><code>from joblib import Parallel, delayed
import multiprocessing

inputs = range(10) 
def processInput(i):
    return i * i

num_cores = multiprocessing.cpu_count()

results = Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in inputs)
print(results)
</code></pre>
<p>The above works beautifully on my machine (Ubuntu, package joblib was pre-installed, but can be installed via <code>pip install joblib</code>).</p>
<p>Taken from <a href="https://blog.dominodatalab.com/simple-parallelization/" rel="noreferrer">https://blog.dominodatalab.com/simple-parallelization/</a></p>
</div>
<div class="post-text" itemprop="text">
<p>There are a number of advantages to using <a href="https://github.com/ray-project/ray" rel="noreferrer">Ray</a>:</p>
<ul>
<li>You can parallelize over multiple machines in addition to multiple cores (with the same code).</li>
<li>Efficient handling of numerical data through shared memory (and zero-copy serialization).</li>
<li>High task throughput with distributed scheduling.</li>
<li>Fault tolerance.</li>
</ul>
<p>In your case, you could start Ray and define a remote function</p>
<pre><code>import ray

ray.init()

@ray.remote(num_return_vals=3)
def calc_stuff(parameter=None):
    # Do something.
    return 1, 2, 3
</code></pre>
<p>and then invoke it in parallel</p>
<pre><code>output1, output2, output3 = [], [], []

# Launch the tasks.
for j in range(10):
    id1, id2, id3 = calc_stuff.remote(parameter=j)
    output1.append(id1)
    output2.append(id2)
    output3.append(id3)

# Block until the results have finished and get the results.
output1 = ray.get(output1)
output2 = ray.get(output2)
output3 = ray.get(output3)
</code></pre>
<p>To run the same example on a cluster, the only line that would change would be the call to ray.init(). The relevant documentation can be found <a href="https://ray.readthedocs.io/en/latest/" rel="noreferrer">here</a>.</p>
<p>Note that I'm helping to develop Ray.</p>
</div>
<div class="post-text" itemprop="text">
<p>why dont you use threads, and one mutex to protect one global list?</p>
<pre><code>import os
import re
import time
import sys
import thread

from threading import Thread

class thread_it(Thread):
    def __init__ (self,param):
        Thread.__init__(self)
        self.param = param
    def run(self):
        mutex.acquire()
        output.append(calc_stuff(self.param))
        mutex.release()   


threads = []
output = []
mutex = thread.allocate_lock()

for j in range(0, 10):
    current = thread_it(j * offset)
    threads.append(current)
    current.start()

for t in threads:
    t.join()

#here you have output list filled with data
</code></pre>
<p>keep in mind, you will be as fast as your slowest thread</p>
</div>
<div class="post-text" itemprop="text">
<p>This could be useful when implementing multiprocessing and parallel/ distributed computing in Python.</p>
<p><a href="https://www.youtube.com/watch?v=KtvP8cgwnlw" rel="nofollow">YouTube tutorial on using techila package</a></p>
<p>Techila is a distributed computing middleware, which integrates directly with Python using the techila package. The peach function in the package can be useful in parallelizing loop structures. (Following code snippet is from the <a href="http://www.techilatechnologies.com/forum" rel="nofollow">Techila Community Forums</a>)</p>
<pre><code>techila.peach(funcname = 'theheavyalgorithm', # Function that will be called on the compute nodes/ Workers
    files = 'theheavyalgorithm.py', # Python-file that will be sourced on Workers
    jobs = jobcount # Number of Jobs in the Project
    )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Let's say we have an async function</p>
<pre><code>async def work_async(self, student_name: str, code: str, loop):
"""
Some async function
"""
    # Do some async procesing    
</code></pre>
<p>That needs to be run on a large array. Some attributes are being passed to the program and some are used from property of dictionary element in the array.</p>
<pre><code>async def process_students(self, student_name: str, loop):
    market = sys.argv[2]
    subjects = [...] #Some large array
    batchsize = 5
    for i in range(0, len(subjects), batchsize):
        batch = subjects[i:i+batchsize]
        await asyncio.gather(*(self.work_async(student_name,
                                           sub['Code'],
                                           loop)
                       for sub in batch))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>very simple example of parallel processing is</p>
<pre><code>from multiprocessing import Process

output1 = list()
output2 = list()
output3 = list()

def yourfunction():
    for j in range(0, 10):
        # calc individual parameter value
        parameter = j * offset
        # call the calculation
        out1, out2, out3 = calc_stuff(parameter=parameter)

        # put results into correct output list
        output1.append(out1)
        output2.append(out2)
        output3.append(out3)

if __name__ == '__main__':
    p = Process(target=pa.yourfunction, args=('bob',))
    p.start()
    p.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I found <code>joblib</code> is very useful with me. Please see following example:</p>
<pre><code>from joblib import Parallel, delayed
def yourfunction(k):   
    s=3.14*k*k
    print "Area of a circle with a radius ", k, " is:", s

element_run = Parallel(n_jobs=-1)(delayed(yourfunction)(k) for k in range(1,10))
</code></pre>
<p>n_jobs=-1: use all available cores</p>
</div>
<div class="post-text" itemprop="text">
<p>Have a look at this;</p>
<p><a href="http://docs.python.org/library/queue.html" rel="nofollow">http://docs.python.org/library/queue.html</a></p>
<p>This might not be the right way to do it, but I'd do something like;</p>
<p>Actual code;</p>
<pre><code>from multiprocessing import Process, JoinableQueue as Queue 

class CustomWorker(Process):
    def __init__(self,workQueue, out1,out2,out3):
        Process.__init__(self)
        self.input=workQueue
        self.out1=out1
        self.out2=out2
        self.out3=out3
    def run(self):
            while True:
                try:
                    value = self.input.get()
                    #value modifier
                    temp1,temp2,temp3 = self.calc_stuff(value)
                    self.out1.put(temp1)
                    self.out2.put(temp2)
                    self.out3.put(temp3)
                    self.input.task_done()
                except Queue.Empty:
                    return
                   #Catch things better here
    def calc_stuff(self,param):
        out1 = param * 2
        out2 = param * 4
        out3 = param * 8
        return out1,out2,out3
def Main():
    inputQueue = Queue()
    for i in range(10):
        inputQueue.put(i)
    out1 = Queue()
    out2 = Queue()
    out3 = Queue()
    processes = []
    for x in range(2):
          p = CustomWorker(inputQueue,out1,out2,out3)
          p.daemon = True
          p.start()
          processes.append(p)
    inputQueue.join()
    while(not out1.empty()):
        print out1.get()
        print out2.get()
        print out3.get()
if __name__ == '__main__':
    Main()
</code></pre>
<p>Hope that helps.</p>
</div>
<span class="comment-copy">Since this is the chosen answer, is it possible to have a more comprehensive example? What are the arguments of <code>calc_stuff</code>?</span>
<span class="comment-copy">@EduardoPignatelli Please just read the documentation of the <code>multiprocessing</code> module for more comprehensive examples.  <code>Pool.map()</code> basically works like <code>map()</code>, but in parallel.</span>
<span class="comment-copy">Is there a way to simply add in a tqdm loading bar to this structure of code? I've used tqdm(pool.imap(calc_stuff, range(0, 10 * offset, offset))) but I don't get a full loading bar graphic.</span>
<span class="comment-copy">@user8188120 I've never heard of tqdm before, so sorry, I can't help with that.</span>
<span class="comment-copy">While this link may answer the question, it is better to include the essential parts of the answer here and provide the link for reference.  Link-only answers can become invalid if the linked page changes. - <a href="/review/low-quality-posts/18774262">From Review</a></span>
<span class="comment-copy">And as a library developer, I respectfully disagree: our documentation is kept to date as the library and the ecosystem evolve, while we cannot control the amount of outdated information that there is on stackoverflow.</span>
<span class="comment-copy">I tried joblib with jupyter, it is not working. After the Parallel-delayed call, the page stopped working.</span>
<span class="comment-copy">Hi, I have a problem using joblib (<a href="https://stackoverflow.com/questions/52166572/python-parallel-no-space-cant-pickle" title="python parallel no space cant pickle">stackoverflow.com/questions/52166572/â€¦</a>), do you have any clue what may be the cause?  Thanks very much.</span>
<span class="comment-copy">does ThreadPoolExecutor bypass the limitations imposed by GIL? also wouldnt you need to join() in order to wait for the executors to finish or is this taken care of implicitly inside the context manager</span>
<span class="comment-copy">No and no, yes to "handled implicitly"</span>
<span class="comment-copy">For some reason, when scaling up the problem, multithreading is extremely fast, but multiprocessing spawns a bunch of stuck processes (in macOS). Any idea why that could be? The process contains just nested loops and math, nothing exotic.</span>
<span class="comment-copy">@komodovaran_ A process is a full Python process, one per each, while a thread is just a thread of execution with its own stack that shares the process, its bytecode and everything else it has in memory with all the other threads - does that help?</span>
<span class="comment-copy">I tried your code but on my system the sequential version of this code takes about half a minute and the above parallel version takes 4 minutes. Why so?</span>
<span class="comment-copy">I know this is a very old answer, so it's a bummer to get a random downvote out of nowhere. I only downvoted because threads won't parallelize anything. Threads in Python are bound to only one thread executing on the interpreter at a time because of the global interpreter lock, so they support <a href="http://stackoverflow.com/q/1897993/2615940">concurrent programming, but not parallel</a>  as OP is requesting.</span>
<span class="comment-copy">@skrrgwasme I know you know this, but when you use the words "they won't parallelize anything", that might mislead readers. If the operations take a long time because they are IO bound, or sleeping while they wait for an event, then the interpreter is freed up to run the other threads, so this will result in the speed increase people are hoping for in those cases. Only CPU bound threads are really affected by what skrrgwasme says.</span>
<span class="comment-copy">Probably the threaded version will run slower in that case.</span>
<span class="comment-copy">While this link may answer the question, it is better to include the essential parts of the answer here and provide the link for reference.  Link-only answers can become invalid if the linked page changes.</span>
<span class="comment-copy">@S.L.Barth thank you for the feedback. I added a small sample code to the answer.</span>
<span class="comment-copy">You know, it is better to check already existing answers before posting your own. <a href="https://stackoverflow.com/a/50926231/9609843">This answer</a> also proposes to use <code>joblib</code>.</span>
