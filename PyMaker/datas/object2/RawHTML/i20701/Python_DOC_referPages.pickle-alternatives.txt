<div class="post-text" itemprop="text">
<p>I am trying to serialize a large (~10**6 rows, each with ~20 values) list, to be used later by myself (so pickle's lack of safety isn't a concern).</p>
<p>Each row of the list is a tuple of values, derived from some SQL database. So far, I have seen datetime.datetime, strings, integers, and NoneType, but I might eventually have to support additional data types.</p>
<p>For serialization, I've considered pickle (cPickle), json, and plain text - but only pickle saves the type information: json can't serialize datetime.datetime, and plain text has its obvious disadvantages.</p>
<p>However, cPickle is pretty slow for data this large, and I'm looking for a faster alternative.</p>
<p>Any suggestions?</p>
<p>Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>I think you should give <a href="http://www.pytables.org/" rel="nofollow">PyTables</a> a look. It should be ridiculously fast, at least faster than using an RDBMS, since it's very lax and doesn't impose any read/write restrictions, plus you get a better interface for managing your data, at least compared to pickling it.</p>
</div>
<div class="post-text" itemprop="text">
<p>Pickle is actually quite fast so long as you aren't using the (default) ASCII protocol.  Just make sure to dump using <code>protocol=pickle.HIGHEST_PROTOCOL</code>.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>Protocol buffers are a flexible, efficient, automated mechanism for
  serializing structured data â€“ think XML, but smaller, faster, and
  simpler. </p>
<p>advantages over XML:</p>
<ul>
<li>are simpler</li>
<li>are 3 to 10 times smaller</li>
<li>are 20 to 100 times faster</li>
<li>are less ambiguous</li>
<li>generate data access classes that are easier to use programmatically</li>
</ul>
</blockquote>
<p><a href="https://developers.google.com/protocol-buffers/docs/pythontutorial" rel="noreferrer">https://developers.google.com/protocol-buffers/docs/pythontutorial</a></p>
</div>
<div class="post-text" itemprop="text">
<ul>
<li><a href="https://developers.google.com/protocol-buffers/docs/pythontutorial" rel="nofollow">
Protocol Buffer</a> - e.g. used in <a href="http://caffe.berkeleyvision.org/" rel="nofollow">Caffe</a>; maintains type information, but you have to put quite much effort in it compared to pickle</li>
<li><a href="http://msgpack.org/" rel="nofollow">MessagePack</a>: See <a href="https://pypi.python.org/pypi/msgpack-python/" rel="nofollow">python package</a> - supports streaming (<a href="http://pynash.org/2013/02/13/messagepack-streaming.html" rel="nofollow">source</a>)</li>
<li><a href="http://bsonspec.org/" rel="nofollow">BSON</a>: see <a href="http://api.mongodb.org/python/current/api/bson/" rel="nofollow">python package docs</a></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>I usually serialize to plain text (*.csv) because I found it to be fastest. The <em>csv</em> module works quite well. See <a href="http://docs.python.org/library/csv.html" rel="nofollow">http://docs.python.org/library/csv.html</a></p>
<p>If you have to deal with unicode for your strings, check out the UnicodeReader and UnicodeWriter examples at the end.</p>
<p>If you serialize for your own future use, I guess it would suffice to know that you have the same data type per csv column (e.g., string are always on column 2).</p>
</div>
<div class="post-text" itemprop="text">
<p>For hundreds of thousands of simple (up to JSON-compatible) complexity Python objects, I've found the best combination of simplicity, speed, and size by combining:</p>
<ul>
<li><a href="https://github.com/Iotic-Labs/py-ubjson" rel="nofollow noreferrer">py-ubjson</a></li>
<li><a href="https://docs.python.org/3/library/gzip.html" rel="nofollow noreferrer">gzip</a></li>
</ul>
<p>It beats <code>pickle</code> and <code>cPickle</code> options by orders of magnitude.</p>
<pre><code>with gzip.open(filename, 'wb') as f:
    ubjson.dump(items, f)


with gzip.open(filename, 'rb') as f:
    return ubjson.load(f)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://avro.apache.org/docs/current/index.html" rel="nofollow noreferrer">Avro</a> seems to be promising and properly designed but yet non popular solution.</p>
</div>
<span class="comment-copy">Have you considered dumping it into an SQLite database?</span>
<span class="comment-copy">Actually - I haven't. Might be the simplest...</span>
<span class="comment-copy">Looks promising. I'll give it a shot - thanks!</span>
<span class="comment-copy">It should be noted that for <code>python3</code> the default format is actually binary, according to the docs. <a href="http://docs.python.org/3.4/library/pickle.html?highlight=pickle#pickle" rel="nofollow noreferrer">docs.python.org/3.4/library/pickle.html?highlight=pickle#pickle</a></span>
<span class="comment-copy">A semantically better alternative is <code>protocol=pickle.HIGHEST_PROTOCOL</code></span>
<span class="comment-copy">Thanks, @moose! Updated from <code>protocol=-1</code>.</span>
<span class="comment-copy">as in <code>pickle.dump(data, file, protocol=pickle.HIGHEST_PROTOCOL)</code></span>
<span class="comment-copy">That's not so good for me - since it doesn't maintain type information, I have to loop over the data and convert it, which is very slow (at least in my implementation, using a list comprehension of list comprehensions).</span>
