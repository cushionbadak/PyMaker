<div class="post-text" itemprop="text">
<p>I am trying to make a new list in my existing csv file (not using pandas).
Here is my code: </p>
<pre><code>with open ('/Users/Weindependent/Desktop/dataset/albumlist.csv','r') as case0:
    reader = csv.DictReader(case0)
    album = []
    for row in reader:
        album.append(row)
print ("Number of albums is:",len(album))
</code></pre>
<p>The CSV file was downloaded from the <a href="https://data.world/notgibs/rolling-stones-top-500-albums" rel="nofollow noreferrer">Rolling Stone's Top 500 albums data set on data.world</a>.</p>
<p>My logic is to create an empty list named album and have all the records in this list. But it seems the line of <code>for row in reader</code> has some issue.</p>
<p>the error message I got is: </p>
<pre><code>UnicodeDecodeError: 'utf-8' codec can't decode byte 0xca in position 1040: invalid continuation byte
</code></pre>
<p>Can anyone let me know what I did wrong? </p>
</div>
<div class="post-text" itemprop="text">
<p>You need to open the file in the correct codec; UTF-8 is not the correct one. The dataset doesn't specify it, but I have determined that the most likely codec is <code>mac_roman</code>:</p>
<pre><code>with open ('/Users/Weindependent/Desktop/dataset/albumlist.csv', 'r', encoding='mac_roman') as case0:
</code></pre>
<p>The <a href="https://www.kaggle.com/notgibs/500-greatest-albums-of-all-time-rolling-stone/" rel="nofollow noreferrer">original Kaggle dataset</a> doesn't bother to document it, and the various kernels that use the set all just clobber the encoding. It's clearly a 8-bit Latin-variant (the majority of the data is ASCII with a few individual 8-bit codepoints).</p>
<p>So I analysed the data, and found there are just two such codepoints in 9 rows:</p>
<pre><code>&gt;&gt;&gt; import re
&gt;&gt;&gt; eightbit = re.compile(rb'[\x80-\xff]')
&gt;&gt;&gt; with open('albumlist.csv', 'rb') as bindata:
...     nonascii = [l for l in bindata if eightbit.search(l)]
...
&gt;&gt;&gt; len(nonascii)
9
&gt;&gt;&gt; {c for l in nonascii for c in eightbit.findall(l)}
{b'\x89', b'\xca'}
</code></pre>
<p>The 0x89 byte appears in just one line:</p>
<pre><code>&gt;&gt;&gt; sum(l.count(b'\x89') for l in nonascii)
1
&gt;&gt;&gt; sum(l.count(b'\xca') for l in nonascii)
22
&gt;&gt;&gt; next(l for l in nonascii if b'\x89' in l)
b'359,1972,Honky Ch\x89teau,Elton John,Rock,"Pop Rock,\xcaClassic Rock"\r\n'
</code></pre>
<p>That's clearly <a href="https://en.wikipedia.org/wiki/Honky_Ch%C3%A2teau" rel="nofollow noreferrer">Elton John's 1972 <em>Honky Château</em> album</a>, so the 0x89 byte must represent the <a href="http://www.fileformat.info/info/unicode/char/00E2/index.htm" rel="nofollow noreferrer">U+00E2 LATIN SMALL LETTER A WITH CIRCUMFLEX</a> codepoint.</p>
<p>The 0xCA bytes all appear to represent an alternative space character, they all appear righ after commas in the genre and subgenre columns (with one album exception):</p>
<pre><code>&gt;&gt;&gt; import csv
&gt;&gt;&gt; for row in csv.reader((l.decode('ascii', 'backslashreplace') for l in nonascii)):
...     for col in row:
...         if '\\' in col: print(col)
...
Reggae,\xcaPop,\xcaFolk, World, &amp; Country,\xcaStage &amp; Screen
Reggae,\xcaRoots Reggae,\xcaRocksteady,\xcaContemporary,\xcaSoundtrack
Electronic,\xcaStage &amp; Screen
Soundtrack,\xcaDisco
Rock,\xcaBlues
Blues Rock,\xcaElectric Blues,\xcaHarmonica Blues
Garage Rock,\xcaPsychedelic Rock
Honky Ch\x89teau
Pop Rock,\xcaClassic Rock
Funk / Soul,\xcaFolk, World, &amp; Country
Rock,\xcaPop
Stan Getz\xca/\xcaJoao Gilberto\xcafeaturing\xcaAntonio Carlos Jobim
Bossa Nova,\xcaLatin Jazz
Lo-Fi,\xcaIndie Rock
</code></pre>
<p>These 0xCA bytes are almost certainly representing the <a href="http://www.fileformat.info/info/unicode/char/00A0/index.htm" rel="nofollow noreferrer">U+00A0 NO-BREAK SPACE</a> codepoint.</p>
<p>With these two mappings, you can try to determine what 8-bit codecs would make the same mapping. Rather than manually try out <a href="https://docs.python.org/3/library/codecs.html" rel="nofollow noreferrer">all Python's codecs</a> I used <a href="https://github.com/tripleee/8bit/" rel="nofollow noreferrer">Tripleee's 8-bit codec mapping</a> to see what codecs use these mappings. There are only two:</p>
<blockquote>
<ul>
<li>0x89</li>
</ul>
<p>â‎ (U+00E2):  mac_arabic, mac_croatian, mac_farsi, mac_greek, mac_iceland, mac_roman, mac_romanian, mac_turkish</p>
<ul>
<li><p>0xca</p>
<p>‎ (U+00A0):     mac_centeuro, mac_croatian, mac_cyrillic, mac_greek, mac_iceland, mac_latin2, mac_roman, mac_romanian, mac_turkish</p></li>
</ul>
</blockquote>
<p>There are 6 encodings that are listed in both sets:</p>
<pre><code>&gt;&gt;&gt; set1 = set('mac_arabic, mac_croatian, mac_farsi, mac_greek, mac_iceland, mac_roman, mac_romanian, mac_turkish'.split(', '))
&gt;&gt;&gt; set2 = set('mac_centeuro, mac_croatian, mac_cyrillic, mac_greek, mac_iceland, mac_latin2, mac_roman, mac_romanian, mac_turkish'.split(', '))
&gt;&gt;&gt; set1 &amp; set2
{'mac_turkish', 'mac_iceland', 'mac_romanian', 'mac_greek', 'mac_croatian', 'mac_roman'}
</code></pre>
<p>Of these, <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman" rel="nofollow noreferrer">Mac OS Roman <code>mac_roman</code></a> codec is probably the most likely to have been used as Microsoft Excel for Mac <a href="https://donatstudios.com/CSV-An-Encoding-Nightmare" rel="nofollow noreferrer">used Mac Roman to create CSV files</a> for a long time. However, it doesn't really matter, any of those 6 would work here.</p>
<p>You may want to replace those U+00A0 non-breaking spaces if you want to split out the genre and subgenre columns (really the genre and <em>style</em> columns if these were taken from Discogs).</p>
</div>
<span class="comment-copy">This can be helpful: <a href="https://stackoverflow.com/questions/12752313/unicodedecodeerror-in-python-3-when-importing-a-csv-file" title="unicodedecodeerror in python 3 when importing a csv file">stackoverflow.com/questions/12752313/…</a></span>
<span class="comment-copy">The data file you are reading from is probably not UTF-8 encoded. You'll have to specify a different encoding with <code>encoding="...."</code>. What encoding to use, we can't tell you, sorry.</span>
<span class="comment-copy">How can I tell what type the file is encoded?</span>
<span class="comment-copy">Where did the dataset come from? Did they document this perhaps?</span>
<span class="comment-copy">Since you got as far as 1040 bytes into the CSV until you hit a decoding error, chances are the file is also encoded with a single-byte encoding, the most popular of which is <code>cp1252</code>. Give it a try first.</span>
