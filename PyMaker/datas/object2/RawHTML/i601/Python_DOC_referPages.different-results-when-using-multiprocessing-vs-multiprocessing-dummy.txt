<div class="post-text" itemprop="text">
<p>I have a long running task that can be parallelized. I debugged code with use of <code>multiprocessing.dummy</code>. It works well and I get results I expect. But when I change it to  <code>multiprocessing</code>, it runs <code>_test</code> function impossibly fast and actual output is not even touched</p>
<p><b>The job</b> is to fill pandas DataFrame with data up to some row count threshold. Each of longer processes in while cycle adds about 2500 rows at one run. Data acquisition is independent on other processes. </p>
<p><b>The idea</b> is, that processes pass DataFrame through Queue between each other and use lock to block access to it from other processes while they work with Dataframe. Once their work is done, they put it back and release lock.</p>
<p>Once DataFrame is filled to required size, process can end and other processes are no longer required to finish(but Im not sure, if they are terminated once they finish without join() or just what happens with them - therefore .is_alive() check could replace .join())</p>
<p>For this example <code>TRAINING_DATA_LENGTH</code> is set only to 10k but actual size will be much higher</p>
<p><b>The problem</b> is, that when I change from <code>multiprocessing.dummy</code> to <code>multiprocessing</code> whole operation is finished in 0.7 seconds and returned X size is 0</p>
<hr/>
<ul>
<li><p>Maybe there is another way how to do it but Im not yet aware of it.</p></li>
<li><p>Also I need it to run in separate file not <code>__main__</code></p></li>
</ul>
<hr/>
<h2>test_mp.py</h2>
<pre><code>import pandas as pd
import multiprocessing
from multiprocessing import Process,Queue,Lock
import time
import numpy as np


TRAINING_DATA_LENGTH = 10e3

def get_training_data_mp(testing = False,updating = False):    
    s = time.time()
    processes = []
    output = Queue()
    X = pd.DataFrame([])
    output.put(X)
    lock = Lock()

    for i in range(multiprocessing.cpu_count()):           
        p = Process(target=_test,args=(testing,updating,5000,1000,lock,output))
        p.daemon = True
        p.start()
        processes.append(p)

    print([p.is_alive() for p in processes])
#    while all([p.is_alive() for p in processes]):
#        print('alive')    
#        time.sleep(3)            

    for process in processes:
        process.join()               
    print('finished')  

    X = output.get()
    e = time.time()
    print(e-s)
    return X

def _test(testing,updating,max_test_amount,max_train_amount_from_last_days,lock,output):
    time.sleep(2) # short init work

    lock.acquire()   
    X = output.get() 

    while (((not testing or updating) and X.shape[0]&lt;TRAINING_DATA_LENGTH)     or 
           (testing and X.shape[0]&lt;max_test_amount)):

        if updating and X.shape[0]&lt;max_train_amount_from_last_days:
            output.put(X)
            lock.release()

            time.sleep(2) # long work
            action = '1'
        elif (testing and X.shape[0]&lt;max_test_amount*0.25) and not updating:
            output.put(X)
            lock.release()

            time.sleep(2) # long work
            action = '2'
        else:
            output.put(X)
            lock.release()

            time.sleep(2) # long work
            action = '3'               

        time.sleep(5) # main long work
        x = pd.DataFrame(np.random.randint(0,10000,size=(2500, 4)), columns=list('ABCD')) # simulated result

        lock.acquire()
        X = output.get()
        if X.shape[0] == 0:
            X = x
        else:
            X = X.append(x)   

        # correcting output    
        X = X.drop_duplicates(keep='first')
        X.reset_index(drop=True,inplace = True)
        time.sleep(0.5) # short work

    output.put(X)    
    lock.release() 
</code></pre>
<p>and run it form another file </p>
<pre><code>import test_mp
X = test_mp.get_training_data_mp(True)
print(X.shape[0])
</code></pre>
<hr/>
<p>with <code>multiprocessing.dummy</code> I get following output:</p>
<pre><code>[True, True, True, True]
finished
17.01797342300415
12500
</code></pre>
<p>with <code>multiprocessing</code> Its:</p>
<pre><code>[True, True, True, True]
finished
0.7530431747436523 # due to time.sleep() its impossible to be finished this fast
0 # expected &gt;= TRAINING_DATA_LENGTH
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Adding <code>if __name__ == '__main__':</code> in runfile made the code execute and get "some" results. But with more testing it appears to be using only one core(or I have something wrong in code)</p>
<pre><code>import test_mp
if __name__ == '__main__':
    X = test_mp.get_training_data_mp()
    print([x.shape[0] for x in X])
</code></pre>
<h2>test_mp.py</h2>
<pre><code>import multiprocessing
from multiprocessing import Process,Queue,Lock
import time
import numpy as np


TRAINING_DATA_LENGTH = 10e3

def get_training_data_mp(testing = False,updating = False): 
    s = time.time()
    processes = []
    output = Queue()
    X = []
    x = [X,X,X,X]
    output.put(x)
    lock = Lock()

    for i in range(multiprocessing.cpu_count()):           
        p = Process(target=_test,args=(i,testing,updating,5000,1000,lock,output))
        p.daemon = True
        p.start()
        processes.append(p)

    while all([p.is_alive() for p in processes]):  
        lock.acquire()
        x = output.get()
        print([len(X) for X in x])
        output.put(x)
        lock.release()
        time.sleep(3)    

    print([p.is_alive() for p in processes])
#    for process in processes:
#        process.join()               
    print('finished') 

    x = output.get()
    my_x = x

    e = time.time()
    print(e-s)
    return my_x

def _test(i,testing,updating,max_test_amount,max_train_amount_from_last_days,lock,output):
    time.sleep(2) # long work

    lock.acquire()   
    x = output.get()
    X = x[i]

    while (((not testing or updating) and len(X)&lt;TRAINING_DATA_LENGTH) or 
           (testing and len(X)&lt;max_test_amount)):

        x[i] = X
        output.put(x)
        lock.release()              

        y = np.array(np.random.randint(0,10000,size=(2500, 4)))
        time.sleep(2) # main long work

        lock.acquire()
        X = output.get()
        X = x[i]
        if len(X) == 0:
            X = y
        else:
            X = np.append(X,y,axis=0)   
        # correcting output    
        time.sleep(0.5) # short work
    x[i] = X        
    output.put(x)    
    lock.release()
</code></pre>
<hr/>
<p>with <code>multiprocessing.dummy</code> I get following output:</p>
<pre><code>[0, 0, 0, 0]
[5000, 0, 5000, 0]
[False, True, True, True]
finished
7.50442910194397
[10000, 7500, 7500, 2500] # All processes were obtaining data &lt;- intended
</code></pre>
<p>with <code>multiprocessing</code> Its:</p>
<pre><code>[0, 0, 0, 0]
[0, 0, 2500, 0]
[0, 10000, 0, 0]
[False, False, True, False]
finished
12.15569543838501
[0, 0, 10000, 0] # Only one process was obtaining data &lt;- wrong
</code></pre>
<hr/>
<h1>Solved</h1>
<p><code>time.sleep()</code> does not stress processor, but when its switched for function like </p>
<pre><code>def sleep():
    n = 0
    for i in range(6000):
        n = i**i
</code></pre>
<p>the results from both <code>multiprocessing.dummy</code> and <code>multiprocessing</code> are as expected - both returns same length, but multiprocessing N-times faster</p>
</div>
<span class="comment-copy">You code doesn't have an <code>if __name__ == '__main__':</code> statement to alll it be safely imported by a new Python interpreterter—which likely doesn't matter with <code>dummy</code> but is <code>import</code>ant when doing "real" multiprocessing. See the section titled "Safe importing of main module" in the multiprocessing <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming" rel="nofollow noreferrer">Programming guidelines</a> the documentation for more information.</span>
<span class="comment-copy">Okay, I modified it and it seemed to work, but now the problem is, that even when i start 4 processes, only one is filling the DataFrame</span>
<span class="comment-copy">Haven't ever seen the <code>if __name__ == '__main__':</code> used exactly like this for multiprocessing, so am not totally sure if it accomplishes the goal of using it. I also think I see a few other potential issues, such as with the way the checking of alive processes is being done. Unfortunately I don't have <code>pandas</code> installed, so can't actually run your code—a big part of the reason I haven't posted an answer. If you could remove the use of pandas and provide a <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a> that reproduces the problem, then perhaps I (and many others) could be of more assistance.</span>
<span class="comment-copy">I work with python for about 2 months now and currently starting with multiprocessing library. This was the first place where I thought you meant.... Edited it to not use pandas</span>
<span class="comment-copy">False alarm - time.sleep() kinda confuses everything. When I switched it to function that stresses processor to max for couple of seconds everything works how I expect</span>
