<div class="post-text" itemprop="text">
<p>I really need a general question answered.  I have a script that uses threading right now to access 1000s of devices and get information from them.  I now have a requirement to get that information in the the same order everyday..  </p>
<p>So I need to have information pull from my list and access these devices everyday in the same order.  I also have to get this information back in the same order.  </p>
<p>I can disable threading to do this, but then the scrip takes hours to run.  What type of Queue can i use to keep threading but access these devices and write the in the same order every-time? Is this possible?</p>
</div>
<div class="post-text" itemprop="text">
<p>Are you sure you need to access the devices in the same order? In that case you can't use any concurrency by definition.</p>
<p>Otherwise, the <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map" rel="nofollow"><code>map</code></a> method of the <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"><code>concurrent.futures</code></a> module will work perfectly: it executes a sequence of tasks concurrently in a pool of N threads or processes and returns their results in the same sequence as they were provided.</p>
<p>You can even try <code>ProcessPoolExecutor</code> instead of <code>ThreadPoolExecutor</code> (they're interchangable) to see if it improves performance further.</p>
<p>There is an example that may help you: <a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor-example" rel="nofollow">ProcessPoolExecutor Example</a> (primes).</p>
<p>A backport <a href="https://pypi.python.org/pypi/futures" rel="nofollow"><code>futures</code></a> is available for old versions of Python.</p>
</div>
<span class="comment-copy">Accessing them in order is the hard part. I assume its much faster in parallel, so what part of the operation is expensive? You could potentially do setup work in parallel but then the data query part in serial. Not easily, though!</span>
<span class="comment-copy">I guess the biggest issue is getting the information back in the same order every time.  I am getting the information and writing it to a file.  I then use a difflib to compare the files for changes.  But I need it all in the same order or it shows the file is different every time.  I have also seen some information going in places it shouldn't be. (Saying the device has something it doesnt)</span>
<span class="comment-copy">IN that case, a multiprocessing Pool or ThreadPool (renamed and reimplemented in python 3) and their <code>imap</code> method may work because they preserve order on return. Another option is to add a sequence number to your current implementation. When you complete, you can sort the file and strip the sequence number to get the "diffable" file. This may be preferable if you have a large information set you don't want to hold in memory. "information going in places it shouldn't" could be multiple threads writing the same file - you could create a lock to control writing the file.</span>
<span class="comment-copy">Which is good for writing them in the same order but not for accessing them in the same order. If they really need to be accessed in order, pools won't do it.</span>
<span class="comment-copy">well okay, then.</span>
<span class="comment-copy">You may want to read up on how pools work.</span>
<span class="comment-copy">Suppose I have a,b,c,d,e,f,g,h,i tasks in a pool of 3 workers. Depending on how you set up chunksize and how long a given operation works, g may very well execute before b.</span>
<span class="comment-copy">@tdelaney Please stop trying to spread your ignorance. Explore <code>concurrent.futures</code>, try the mentioned example and see that it preserves the order. The flaw in your logic is, even though tasks may execute in an arbitrary order, it is easy to put the results in order.</span>
