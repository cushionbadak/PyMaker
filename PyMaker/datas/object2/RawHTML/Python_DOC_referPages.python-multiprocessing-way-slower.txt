<div class="post-text" itemprop="text">
<p>I created a multiproc function which is slower than a monoprocess</p>
<pre><code>for n in range(nombre_de_cycles):
    debut = time.time()
    paris.reveil_multiproc(2)
    duree = time.time() - debut
    print((n, duree), end=",")
</code></pre>
<p>gives : </p>
<pre><code>(0, 13.04754900932312),(1, 11.9977388381958),(2, 12.56324291229248),(3, 12.289109945297241),(4, 12.300051927566528),(5, 12.322132110595703),(6, 12.058021783828735),(7, 13.218597173690796),(8, 11.991199016571045),(9, 12.178853034973145),
</code></pre>
<p>When the monoproc :</p>
<pre><code>   for n in range(nombre_de_cycles):
        debut = time.time()
        paris.reveil()
        duree = time.time() - debut
        print((n, duree), end=",")
</code></pre>
<p>gives</p>
<pre><code>(0, 0.19302606582641602),(1, 0.030661821365356445),(2, 0.28160881996154785),(3, 0.04853320121765137),(4, 0.20609474182128906),(5, 0.04185295104980469),(6, 0.20528626441955566),(7, 0.040557146072387695),(8, 0.19860100746154785),(9, 0.11386394500732422),
</code></pre>
<p>Here are the functions : </p>
<pre><code>Class Ville:
    timestamp = 0
    def __init__(self, nb_de_cyclistes, Prestataire):
        self.timestamp =0

    def reveil(self):
        self.timestamp += 1
        list(map(lambda cycliste :cycliste.avancer(self.timestamp), self.cyclistes))

    def faire_avancer(cycliste):
        cycliste.avancer(Ville.timestamp)

    def reveil_multiproc(self, n_jobs=1):
        import multiprocessing
        self.timestamp += 1
        Ville.timestamp = self.timestamp
        pool            = multiprocessing.Pool(n_jobs)
        pool.map(Ville.faire_avancer, self.cyclistes)
</code></pre>
<p>What do I do wrong ? </p>
</div>
<div class="post-text" itemprop="text">
<p>Multiprocessing is not a 1-size-fits-all solution. You incur significant overhead with your solution to do very little work.</p>
<p>You have the overhead of: Creating 2 worker processes, splitting <code>self.cylistes</code> into chunks, serializing it with <code>pickle</code>, and using IPC to send it to the subprocess. All this to simply call <code>cycliste.avancer()</code> which appears to do very little work.</p>
<p>Having a large list of hundreds of thousands of items is trivial and means nothing when we can't see how much work you're doing in <code>avancer()</code>. The more items you have in here will actually most likely slow down the multiprocessing approach because it's unlikely you've implemented optimizations for <code>pickle</code> performance.</p>
<p>You need to learn how to use Python's profiling tools (ex: cProfile, line_profiler) before making premature optimizations.</p>
<p>Use <code>multiprocessing</code> when you have long-running, CPU-intensive tasks that do not spend most of their time waiting on IO. If each call to <code>avancer()</code> took 30 seconds to run, then you would see much better performance with <code>multiprocessing</code> then without it.</p>
</div>
<span class="comment-copy">Creating and managing the multiple processes takes time, in this case more time than it takes to simply run your code serially.</span>
<span class="comment-copy">Yes but even for a list of a hundred thousands, the performance are so bad !?</span>
<span class="comment-copy">check your cpu usage.  This could be a case where the workers are being bottlenecked by communication with the main thread.  You should ideally see 2 threads at 100% usage</span>
<span class="comment-copy">Updating an attribute value (which is what I assume <code>avancer</code> is doing, takes 10s of nanoseconds. Starting a new process takes a couple of milliseconds, hundreds of times slower than the task you want the process to do in the first place.</span>
