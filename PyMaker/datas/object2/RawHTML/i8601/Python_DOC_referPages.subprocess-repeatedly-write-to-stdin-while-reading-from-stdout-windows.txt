<div class="post-text" itemprop="text">
<p>I want to call an external process from python. The process I'm calling reads an input string and gives tokenized result, and waits for another input (binary is MeCab tokenizer if that helps).</p>
<p>I need to tokenize thousands of lines of string by calling this process.</p>
<p>Problem is <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen.communicate" rel="nofollow noreferrer">Popen.communicate()</a> works but waits for the process to die before giving out the STDOUT result. I don't want to keep closing and opening new subprocesses for thousands of times. (And I don't want to send the whole text, it may easily grow over tens of thousands of -long- lines in future.)</p>
<pre><code>from subprocess import PIPE, Popen

with Popen("mecab -O wakati".split(), stdin=PIPE,
           stdout=PIPE, stderr=PIPE, close_fds=False,
           universal_newlines=True, bufsize=1) as proc:
    output, errors = proc.communicate("foobarbaz")

print(output)
</code></pre>
<p>I've tried reading <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen.stdout" rel="nofollow noreferrer"><code>proc.stdout.read()</code></a> instead of using communicate but it is blocked by <code>stdin</code> and doesn't return any results before <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen.stdin" rel="nofollow noreferrer"><code>proc.stdin.close()</code></a> is called. Which, again means I need to create a new process everytime.</p>
<p>I've tried to implement queues and threads from a similar question as below, but it either doesn't return anything so it's stuck on <code>While True</code>, or when I force stdin buffer to fill by repeteadly sending strings, it outputs all the results at once.</p>
<pre><code>from subprocess import PIPE, Popen
from threading import Thread
from queue import Queue, Empty

def enqueue_output(out, queue):
    for line in iter(out.readline, b''):
        queue.put(line)
    out.close()

p = Popen('mecab -O wakati'.split(), stdout=PIPE, stdin=PIPE,
          universal_newlines=True, bufsize=1, close_fds=False)
q = Queue()
t = Thread(target=enqueue_output, args=(p.stdout, q))
t.daemon = True
t.start()

p.stdin.write("foobarbaz")
while True:
    try:
        line = q.get_nowait()
    except Empty:
        pass
    else:
        print(line)
        break
</code></pre>
<p>Also looked at the Pexpect route, but it's windows port doesn't support some important modules (pty based ones), so I couldn't apply that as well.</p>
<p>I know there are a lot of similar answers, and I've tried most of them. But nothing I've tried seems to work on Windows.</p>
<p>EDIT: some info on the binary I'm using, when I use it via command line. It runs and tokenizes sentences I give, until I'm done and forcibly close the program.</p>
<p><em>(...waits_for_input -&gt; input_recieved -&gt; output -&gt; waits_for_input...)</em></p>
<p>Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>If mecab uses C <code>FILE</code> streams with default buffering, then piped stdout has a 4 KiB buffer. The idea here is that a program can efficiently use small, arbitrary-sized reads and writes to the buffers, and the underlying standard I/O implementation handles automatically filling and flushing the much-larger buffers. This minimizes the number of required system calls and maximizes throughput. Obviously you don't want this behavior for interactive console or terminal I/O or writing to <code>stderr</code>. In these cases the C runtime uses line-buffering or no buffering. </p>
<p>A program can override this behavior, and some do have command-line options to set the buffer size. For example, Python has the "-u" (unbuffered) option and <code>PYTHONUNBUFFERED</code> environment variable. If mecab doesn't have a similar option, then there isn't a generic workaround on Windows. The C runtime situation is too complicated. A Windows process can link statically or dynamically to one or several CRTs. The situation on Linux is different since a Linux process generally loads a single system CRT (e.g. GNU libc.so.6) into the global symbol table, which allows an <code>LD_PRELOAD</code> library to configure the C <code>FILE</code> streams. Linux <code>stdbuf</code> uses this trick, e.g. <code>stdbuf -o0 mecab -O wakati</code>.</p>
<hr/>
<p>One option to experiment with is to call <code>CreateConsoleScreenBuffer</code> and get a file descriptor for the handle from <code>msvcrt.open_osfhandle</code>. Then pass this as <code>stdout</code> instead of using a pipe. The child process will see this as a TTY and use line buffering instead of full buffering. However managing this is non-trivial. It would involve reading (i.e. <code>ReadConsoleOutputCharacter</code>) a sliding buffer (call <code>GetConsoleScreenBufferInfo</code> to track the cursor position) that's actively written to by another process. This kind of interaction isn't something that I've ever needed or even experimented with. But I have used a console screen buffer non-interactively, i.e. reading the buffer after the child has exited. This allows reading up to 9,999 lines of output from programs that write directly to the console instead of <code>stdout</code>, e.g. programs that call <code>WriteConsole</code> or open "CON" or "CONOUT$".</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a workaround for Windows. This should also be adaptable to other operating systems. 
Download a console emulator like ConEmu (<a href="https://conemu.github.io/" rel="nofollow noreferrer">https://conemu.github.io/</a>) 
Start it instead of mecab as your subprocess. </p>
<pre><code>p = Popen(['conemu'] , stdout=PIPE, stdin=PIPE,
      universal_newlines=True, bufsize=1, close_fds=False)
</code></pre>
<p>Then send the following as the first input:</p>
<pre><code>mecab -O wakafi &amp; exit
</code></pre>
<p>You are letting the emulator handle the file output issues for you; the way it normally does when you manually interact with it. 
I am still looking into this; but already looks promising... </p>
<p>Only problem is conemu is a gui application; so if no other way to hook into its input and output, one might have to tweak and rebuild from sources (it's open source). I haven't found any other way; but this should work. </p>
<p>I have asked the question about running in some sort of console mode <a href="https://stackoverflow.com/questions/45285782/how-to-run-conemu-as-a-simple-console-application">here</a>; so you can check that thread also for something. The author Maximus is on SO...</p>
</div>
<span class="comment-copy">Since you’re just running MeCab in <code>wakati</code> mode, can you not just pipe all the lines of your input (newlines and all) into the process’ stdin?</span>
<span class="comment-copy">@AhmedFasih I can but the input is the comments, posts etc in a user database, so all the inputs together is a very large file and can grow exponentially to the point it could be larger than memory soon. I would prefer to do it sequentially if I can as it also benefits my general code logic (performing tokenization per user -&gt; processing user -&gt; etc...).</span>
<span class="comment-copy">If mecab uses C <code>FILE</code> streams with default buffering, then piped <code>stdout</code> has a 4 KiB buffer. Have you tried writing input repeatedly until mecab fills and flushes its <code>stdout</code> buffer? Does mecab have a command-line option to force using no buffering or line buffering instead of full buffering?</span>
<span class="comment-copy">There's no generic way on Windows to modify the output buffer size used by <code>FILE</code> streams. The C runtime situation is too complicated. A process can link statically or dynamically to one or more CRTs. The situation on Linux is different, so there are commands like <code>stdbuf</code> that can attempt to modify the buffering of standard <code>FILE</code> streams.</span>
<span class="comment-copy">FWIW, the Tao of Windows says that the correct solution is to rebuild the external process as a DLL.  Of course, that isn't always practical.</span>
<span class="comment-copy">Won't make any difference.  It is output going to the console that is treated differently; whether or not an instance of the command prompt is present has no effect.  Also, what's with the semicolon?</span>
<span class="comment-copy">My reasoning is you should have nothing to do with running mecab directly; but instead run cmd.exe and then just send the command to run mecab to it (exiting after running mecab). This way it should be like manually starting cmd.exe and entering the command. Or does the output buffer issue cause problems when run like that?</span>
<span class="comment-copy">Then there is the brute force approach to just start cmd.exe (not as a subprocess) ; send keystrokes to itn make the command for running mecab redirect the output to a file (command &gt;out.txt); and get your tokenized output from there. Can you not run mecab from the command line at all??</span>
<span class="comment-copy">The problem occurs whenever output is redirected.  It doesn't matter whether output is redirected by Python or by the command processor, i.e., when you say <code>&gt;out.txt</code> - it's all the same as far as the child program is concerned.  If you <i>don't</i> redirect output, as is usually the case when the program is run manually, there's no problem - except that in this scenario that makes it difficult for the parent process to see what the output is.  Eryksun's answer goes into more detail.</span>
<span class="comment-copy">Okay I get you. But I would have thought that the involved process of using a console screen buffer to communicate with the child would have been handled by  an important program like cmd.exe. It would use that to get output from the child and then write to the output file you specified. Surely Microsoft is big enough to write all that code in an hour. No need to redirect output with a pipe here. If that's the implementation of cmd.exe what about powershell? I mean if a program can print something to screen it can also write it to file. Is it possible they cannot do that; why??</span>
