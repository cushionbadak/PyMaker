<div class="post-text" itemprop="text">
<p>I'm fairly new to NLP and trying to learn the techniques that can help me get my job done. </p>
<p>Here is my task: I have to classify stages of a drilling process based on text memos. </p>
<p><a href="https://i.stack.imgur.com/j6BUS.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/j6BUS.png"/></a></p>
<p>I have to classify labels for "Activity", "Activity Detail", "Operation" based on what's written in "Com" column. </p>
<p>I've been reading a lot of articles online and all the different kinds of techniques that I've read really confuses me. </p>
<p>The buzz words that I'm trying to understand are</p>
<ol>
<li>Skip-gram (prediction based method, Word2Vec)</li>
<li>TF-IDF (frequency based method)</li>
<li>Co-Occurrence Matrix (frequency based method)</li>
</ol>
<p>I am given about ~40,000 rows of data (pretty small, I know), and I came across an article that says neural-net based models like Skip-gram might not be a good choice if I have small number of training data. So I was also looking into frequency based methods too. Overall, I am unsure which technique is the best for me.</p>
<p>Here's what I understand:</p>
<ol>
<li>Skip-gram: technique used to represent words in a vector space. But I don't understand what to do next once I vectorized my corpus</li>
<li>TF-IDF: tells how important each word is in each sentence. But I still don't know how it can be applied on my problem</li>
<li>Co-Occurence Matrix: I don'y really understand what it is.</li>
<li>All the three techniques are to numerically represent texts. But I am unsure what step I should take next to actually classify labels.</li>
</ol>
<p>What approach &amp; sequence of techniques should I use to tackle my problem? If there's any open source Jupyter notebook project, or link to an article (hopefully with codes) that did the similar job done, please share it here.</p>
</div>
<div class="post-text" itemprop="text">
<p>Let's get things a bit clearer. You task is to create a system that will predict labels for given texts, right? And label prediction (classification) can't be done for unstructured data (texts). So you need to make your data structured, and then train and infer your classifier. Therefore, you need to induce two separate systems:</p>
<ol>
<li>Text vectorizer (as you said, it helps to numerically represent texts).</li>
<li>Classifier (to predict the labels for numerically represented texts).</li>
</ol>
<p>Skip-Gram and co-occurrence matrix are ways to vectorize your texts (here is a nice <a href="http://veredshwartz.blogspot.com/2016/01/representing-words.html" rel="nofollow noreferrer">article</a> that explains their difference). In case of skip-gram you could download and use a 3rd party model that already has mapping of vectors to most of the words; in case of co-occurrence matrix you need to build it on your texts (if you have specific lexis, it will be a better way). In this matrix you could use different measures to represent the degree of co-occurrence of words with words or documents with documents. TF-IDF is one of such measures (that gives a score for every word-document pair); there are a lot of others (PMI, BM25, etc). This <a href="https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f" rel="nofollow noreferrer">article</a> should help to implement classification with co-occurrence matrix on your data. And this <a href="https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568" rel="nofollow noreferrer">one</a> gives an idea how to do the same with Word2Vec. </p>
<p>Hope it helped! </p>
</div>
