<div class="post-text" itemprop="text">
<p>I have two strings: one a word and one a scramble of letters. I want to see if this scramble of letters holds enough letters to spell the word. I have come up with an algorithm to do this but it isn't efficient enough and I was hoping I could get some help making it faster. </p>
<p>Here's what I have so far:</p>
<pre><code>s1 = 'hypochondriac'
s2 = 'yqhpwoewnqlchpijcdrxpoa'

temp = list(s1)
for X in s2:
    for Y in temp:
        if X == Y:
            temp.remove(X)
            X = '@'
if temp == []:
    print('Found ', s1)
</code></pre>
<p>I have an issue where once X matches I need to increment X but I didn't know how so I just take it out of the equation by making it the at symbol.  I tried using break but it doesn't reach far enough to break the to the s2 loop. Either way, I'm pretty sure this double for loop idea is super slow compared to what someone with some experience would use. Any ideas?</p>
</div>
<div class="post-text" itemprop="text">
<p>Your code is not efficient, no, because you iterate in a double loop. For each letter in <code>s1</code>, in the worst-case scenario (no matches) you loop over all of <code>s2</code>.</p>
<p>Use a <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>Counter</code> object</a> instead; these act as <em>multi-sets</em>, where you can both test if a character is present in O(1) time and manage remaining counts:</p>
<pre><code>from collections import Counter

def contains(s1, s2):
    s2set = Counter(s2)
    for c in s1:
        count = s2set[c]
        if not c:
            return False
        if count == 1:
            del s2set[c]
        else:
            s2set[c] = count - 1
    return True
</code></pre>
<p>You can also turn <code>s1</code> into a multi-set, and check if the multi-set for <code>s2</code> contains enough letters for each entry:</p>
<pre><code>def contains(s1, s2):
    s1set = Counter(s1)
    s2set = Counter(s2)
    for c, count in s1set.items():
        if count &gt; s2set[c]:
            return False
    return True
</code></pre>
<p>The latter can be reduced further with the <a href="https://docs.python.org/3/library/functions.html#all" rel="nofollow noreferrer"><code>all()</code> function</a>, which returns <code>False</code> early if any of the results it is passed is <code>False</code>, <code>True</code> otherwise:</p>
<pre><code>def contains(s1, s2):
    s2set = Counter(s2)
    return all(count &lt;= s2set[c] for c, count in Counter(s1).items())
</code></pre>
<p>In all these you only have to iterate over both <code>s1</code> and <code>s2</code> <em>once</em> (either directly or to produce the multi-set).</p>
<p>Demo of the latter:</p>
<pre><code>&gt;&gt;&gt; from collections import Counter
&gt;&gt;&gt; def contains(s1, s2):
...     s2set = Counter(s2)
...     return all(count &lt;= s2set[c] for c, count in Counter(s1).items())
...
&gt;&gt;&gt; s1 = 'hypochondriac'
&gt;&gt;&gt; s2 = 'yqhpwoewnqlchpijcdrxpoa'
&gt;&gt;&gt; contains(s1, s2)
True
&gt;&gt;&gt; contains(s1 + 'b', s2)
False
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Extending @Martijn_Pieters solution you can use <code>Counter</code> in this way:</p>
<pre><code>from collection import Counter
def contains(s1, s2):
    c1, c2 = Counter(s1), Counter(s2)
    return all(c1[c] &lt;= c2[c] for c in s1)
</code></pre>
<p>You can rely on the fact <code>Counter[key]</code> will default to returning 0 if <code>key</code> doesn't exist.</p>
</div>
<div class="post-text" itemprop="text">
<p>Do it the other way round. Remove the characters from <code>s2</code>:</p>
<pre><code>s1 = 'hypochondriac'
s2 = 'yqhpwoewnqlchpijcdrxpoa'

temp = list(s2)
try:
    for ch in s1:
        temp.remove(ch)
except ValueError:
    print("not found")
else:
    print("found", s1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here's a vectorized approach using <a href="http://www.numpy.org/" rel="nofollow noreferrer"><code>NumPy</code></a> -</p>
<pre><code>import numpy as np

def in_string(s1,s2):
    arr1 = np.fromstring(s1, dtype=np.uint8)
    arr2 = np.fromstring(s2, dtype=np.uint8)
    return np.in1d(arr1,arr2).all()
</code></pre>
<p>Sample run -</p>
<pre><code>In [50]: in_string('hypochondriac','yqhpwoewnqlchpijcdrxpoa')
Out[50]: True

# Let's add in a `z` at the end of first word which isn't in the scramble
In [51]: in_string('hypochondriacz','yqhpwoewnqlchpijcdrxpoa')
Out[51]: False
</code></pre>
<hr/>
<p>Here's another NumPy based one using <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.searchsorted.html" rel="nofollow noreferrer"><code>np.searchsorted</code></a> -</p>
<pre><code>def in_string_v2(s1,s2):
    arr1 = np.fromstring(s1, dtype=np.uint8)
    arr2 = np.fromstring(s2, dtype=np.uint8)
    u1 = np.unique(arr1)
    u2 = np.unique(arr2)
    return ~(np.searchsorted(u2,u1) == np.searchsorted(u2,u1,'right')).any()
</code></pre>
<hr/>
<p>Here's another one that processes a list of words in one go against one scramble at a time -</p>
<pre><code>def in_string_v3(list_s1,s2):
    l_arr1 = np.fromstring("".join(list_s1), dtype=np.uint8)
    arr2 = np.fromstring(s2, dtype=np.uint8)
    lens = np.array(map(len,list_s1))
    comp_lens = np.in1d(l_arr1,arr2).cumsum()[lens.cumsum()-1]
    calc_lens = np.append(comp_lens[0],comp_lens[1:]-comp_lens[:-1])
    return lens == calc_lens
</code></pre>
<p>Sample run -</p>
<pre><code>In [185]: ls1 = ['hypochondriac','hypochondriachsdhsahdsadhsa','hihfheifheozz']

In [186]: s2 = 'yqhpwoewnqlchpijcdrxpoadjksdgdkjsfkbdsfbdsdsaduiawyei'

In [187]: in_string_v3(ls1,s2)
Out[187]: array([ True,  True, False], dtype=bool)
</code></pre>
<p>One more to process a list of words in a different way -</p>
<pre><code>def in_string_v4(list_s1,s2):
    l_arr1 = np.fromstring("".join(list_s1), dtype=np.uint8)
    arr2 = np.fromstring(s2, dtype=np.uint8)
    lens = np.array(map(len,list_s1))
    clens = lens.cumsum()
    non_matching_idx = np.nonzero(~np.in1d(l_arr1,arr2))[0]
    non_matching_grp = np.unique(clens.searchsorted(non_matching_idx))
    return ~np.in1d(np.arange(len(list_s1)),non_matching_grp)
</code></pre>
</div>
<span class="comment-copy">Thanks for the help! I made the changes and tested each of these approaches and there were only slight performance increases. I guess the performance hits I'm seeing are coming from somewhere less obvious to me.</span>
<span class="comment-copy">@user1362058: Are you on Python 2? <code>Counter()</code> on 2.7 is a little slow when counting, which can dominate the performance. Python 3 has added C optimisations to address this.</span>
<span class="comment-copy">@user1362058: you should see Counter win on 2.7 for large strings however, as your approach is asymptotically slower (O(NM) vs O(N+M)).</span>
<span class="comment-copy">I'm on Python 3.</span>
<span class="comment-copy">@user1362058: then I can't reproduce any performance decrease of these methods over yours. What is your test methodology?</span>
<span class="comment-copy">I'm not sure why, but this approach has been the slowest I've tested so far. I thought a numpy approach would have sped it up considerably.</span>
<span class="comment-copy">@user1362058 How long are the input strings? How did you test it out? Did you use <code>%timeit</code> for timing?</span>
<span class="comment-copy">I am a novice with these things. I don't know how to use timeit. I have just been using the time.time() approach.</span>
<span class="comment-copy">My test input is 1000 scrambles with a dictionary of ~170,000 words.</span>
<span class="comment-copy">@user1362058 Could you add a minimal sample case into the question with few scrambles ( I am guessing it would be a list of scrambles) and a minimal dictionary with those words?</span>
