<div class="post-text" itemprop="text">
<p>I have written a script, which basically splits all strings in a sentence into parts;</p>
<p>for instance;</p>
<pre><code>"geldigim" -&gt; "gel" "di" "g" "i" "m"
</code></pre>
<p>While some string may be split as above, some of them may be split as following;</p>
<pre><code>"bildi" &gt; "bil" "di"
</code></pre>
<p>or some sentences may not be split at all.</p>
<pre><code>"kos" -&gt; "kos"
</code></pre>
<p>It is totally decided by a function which splits the strings into parts.</p>
<p>What I want to do is the following:</p>
<pre><code>geldigim -&gt; /gel* *di* *g* *i* *m/
bildi -&gt; /bil* *di/
kos -&gt; /kos/
</code></pre>
<p>What I did is;</p>
<p>I have a corpus which has 37251512 sentences. I have written the following script;</p>
<pre><code>if __name__ == "__main__":
        io = morfessor.MorfessorIO()
        print "Importing corpus ..."
        f = codecs.open("corpus/corpus_tr_en/corpus.tr", encoding="utf-8").readlines()
        print "Importing morphology model ..."
        model = io.read_binary_model_file('seg/tr/model.bin')
        corpus = open('dataset/dataset_tr_en/full_segmented.tr', 'w')
        for a in range(len(f)):
                print str(a) + ' : ' + str(len(f))
                words = f[a].replace('\n', '').split()
                line_str = ''
                for word in words:
                        segmentation = model.viterbi_segment(word)[0]
                        if len(segmentation) == 1:
                                line_str = '/' + segmentation[0] + '/'
                        if len(segmentation) == 2:
                                line_str = '/' + segmentation[0] + '* *' + segmentation[1] + '/'
                        if len(segmentation) &gt; 2:
                                line_str = ''
                                for b in range(len(segmentation)):
                                        if (b == 0):
                                                line_str = line_str + '/' + segmentation[b] + '*'
                                        if (b != 0) and (b != (len(segmentation) - 1)):
                                                line_str = line_str + ' *' + segmentation[b] + '* '
                                        if (b == (len(segmentation) - 1)):
                                                line_str = line_str + ' *' + segmentation[b] + '/'
                        line_str = line_str + ' '
                        corpus.write(line_str.encode('utf-8'))
                corpus.write('\n')

        corpus.close()
</code></pre>
<p>This script loops over each sentence, and each word in a sentence, and splits it into parts with <code>io.read_binary_model_file</code> function.</p>
<p>But it is so expensive for me, it is very slow.</p>
<p>Could you suggest me a way which will make the process very fast?</p>
<p>Thanks,</p>
</div>
<div class="post-text" itemprop="text">
<ul>
<li>Jean-François Fabre covered the  <a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips#String_Concatenation" rel="nofollow noreferrer">string optimization</a> really well. </li>
<li>The other elephant is the use of <code>readlines()</code> for 37,251512 sentences. Just use <code>for a in f</code>, see <a href="http://stupidpythonideas.blogspot.de/2013/06/readlines-considered-silly.html" rel="nofollow noreferrer">here</a> for detailed explanation. </li>
<li>Depending on how many duplicates there are you in your data and the performance of the model.viterbi_segment function, it might be beneficial to use a <a href="https://docs.python.org/3/tutorial/datastructures.html#sets" rel="nofollow noreferrer"><code>set</code></a> of words instead of doing it all over for repeated words.</li>
<li>It seems that you are using python 2.#, in that case use <a href="https://stackoverflow.com/questions/135041/should-you-always-favor-xrange-over-range"><code>xrange</code></a> instead of <code>range</code></li>
<li><code>.replace('\n', '').split()</code> is slow since it has to loop over the whole line when you just want to remove the last line break (there can't be more than one in your case). You could use <a href="https://docs.python.org/2/library/string.html" rel="nofollow noreferrer"><code>rstrip('\n')</code></a>`</li>
<li>There is some reduncancy in your code, e.g. each line needs to end with <code>/</code> but you have it in 3 places.</li>
<li>All those changes might be tiny but they will add up and your code becomes easier to read as well</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>What probably slows down a lot is the composition of <code>line_str</code> using multiple string concatenations, which are not recommended if you want performance (well it is okay for things like <code>filename = base+".txt"</code> but not for intensive processing.</p>
<p>Create <code>line</code> as a <code>list</code> instead and use <code>str.join</code> to create the final string just to write it to disk. Appending to a <code>list</code> is much faster.</p>
<p>And as Maximilian just suggested, you could turn your conditions to <code>elif</code> since they are exclusive to each other (x2). Also added some more micro-optimizations that enhance readability as well.</p>
<p>My proposal of how your inner loop should look like:</p>
<pre><code>for word in words:
        segmentation = model.viterbi_segment(word)[0]
        lenseg = len(segmentation)
        if lenseg == 1:
                line = ['/',segmentation[0],'/']
        elif lenseg == 2:
                line = ['/',segmentation[0],'* *',segmentation[1],'/']
        elif lenseg &gt; 2:
                line = []
                for b in range(lenseg):
                        if b == 0:
                                line += ['/',segmentation[0],'*']
                        elif b != (lenseg - 1):
                                line += [' *',segmentation[b],'* ']
                        else:
                                line+= [' *',segmentation[b],'/']
        line.append(" ")
        corpus.write("".join(line).encode('utf-8'))
</code></pre>
<p>Alternatives:</p>
<ul>
<li>write each string to the output file everytime</li>
<li>write data to a <code>io.StringIO</code> object and retrieve it to write in the output file.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>How about inner loop like this:</p>
<pre><code>line = '* *'.join(segmentation)
corpus.write(("/%s/ " % line).encode('utf-8'))
</code></pre>
<p>An then, since you can keep the input in memory at the same time, I would also try to keep the output in memory, and write it out in one go, maybe like this:</p>
<pre><code>lines = []
for a in range(len(f)):
    print str(a) + ' : ' + str(len(f))
    words = f[a].replace('\n', '').split()
    for word in words:
        line = '* *'.join(segmentation)
        lines.append("/%s/ " % line)
corpus.write("\n".join(lines).encode('utf-8')
</code></pre>
</div>
<span class="comment-copy">What does viterbi_segment() do? Could you post the code for this function, please? /Teşekkür* *ler/</span>
<span class="comment-copy">It is basically a function, which basically fits the string into a machine learning model created by "Morfessor".</span>
<span class="comment-copy">I was asking because if you showed us the code, maybe there is way to speed it up.</span>
<span class="comment-copy">using elif instead of redundant ifs would probably speedup the whole thing a bit more.</span>
<span class="comment-copy">right! I was so focused on the strings that I did not see that. Makes sense, although it's probably a micro-optimization compared to the string issue. And maybe the problem is in the viterbi function as well but we don't have it. At any rate, if the number of words is big, the list trick should speed the program <i>a lot</i> (already had the problem myself with big text file)</span>
<span class="comment-copy">if we are already talking about micro-optimization, len(segmentation) is calculated 3 times, put it in a variable (same for len(f)), the 2nd if block can use some elifs as well, segmentation[b] in the first if can be written as segmentation[0].</span>
<span class="comment-copy">edited. And writing as <code>elif</code> allows to simplify the conditions a great deal. Should be on codereview...</span>
<span class="comment-copy">Almost no difference</span>
<span class="comment-copy">That will give quite some different output that what is asked for, e.g. missing \ and additional spaces.</span>
<span class="comment-copy">How so? Won't <code>/%s/ " % line</code> cover that?</span>
<span class="comment-copy">Sorry, my mistake, I misread your code. I guess it should work fine.</span>
<span class="comment-copy">Almost no difference</span>
<span class="comment-copy">Hmm. Then I would try to run a (line) profiler to see where it spends the most time (small/large string ops, and small/large disk I/O). For example: <code>python -m cProfile myscript.py -s time</code></span>
