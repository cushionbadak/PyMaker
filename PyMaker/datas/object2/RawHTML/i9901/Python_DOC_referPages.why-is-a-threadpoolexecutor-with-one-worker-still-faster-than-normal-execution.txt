<div class="post-text" itemprop="text">
<p>I'm using this library, <a href="https://github.com/madisonmay/Tomorrow/blob/master/tomorrow/tomorrow.py" rel="nofollow noreferrer">Tomorrow</a>, that in turn uses the <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor" rel="nofollow noreferrer">ThreadPoolExecutor</a> from the standard library, in order to allow for Async function calls.</p>
<p>Calling the decorator <code>@tomorrow.threads(1)</code> spins up a ThreadPoolExecutor with 1 worker.</p>
<h1>Question</h1>
<ul>
<li>Why is it faster to execute a function using <code>1 thread worker</code> over just calling it as is (e.g. normally)?</li>
<li>Why is it slower to execute the same code with <code>10 thread workers</code> in place of just 1, or even None?</li>
</ul>
<h1>Demo code</h1>
<p><em>imports excluded</em></p>
<pre><code>def openSync(path: str):
    for row in open(path):
        for _ in row:
            pass

@tomorrow.threads(1)
def openAsync1(path: str):
    openSync(path)

@tomorrow.threads(10)
def openAsync10(path: str):
    openSync(path)

def openAll(paths: list):
    def do(func: callable)-&gt;float:
        t = time.time()
        [func(p) for p in paths]
        t = time.time() - t
        return t
    print(do(openSync))
    print(do(openAsync1))
    print(do(openAsync10))

openAll(glob.glob("data/*"))
</code></pre>
<p><em>Note: The <code>data</code> folder contains 18 files, each 700 lines of random text.</em></p>
<h1>Output</h1>
<p><strong>0 workers:</strong> 0.0120 <em>seconds</em> <br/>
<strong>1 worker:</strong> 0.0009 <em>seconds</em> <br/>
<strong>10 workers:</strong> 0.0535 <em>seconds</em> <br/></p>
<h1>What I've tested</h1>
<ul>
<li>I've ran the code more than a couple dusin times, with different programs running in the background (ran a bunch yesterday, and a couple today). The numbers change, ofc, but the order is always the same. (I.e. 1 is fastest, then 0 then 10).</li>
<li>I've also tried changing the order of execution (e.g. moving the do calls around) in order to eliminate caching as a factor, but still the same.

<ul>
<li>Turns out that executing in the order <code>10</code>, <code>1</code>, <code>None</code> results in a different order <em>(1 is fastest, then 10, then 0)</em> compared to every other permutation. The result shows that whatever <code>do</code> call is executed last, is considerably slower than it would have been had it been executed first or in the middle instead. </li>
</ul></li>
</ul>
<h1>Results (After receiving solution from @Dunes)</h1>
<p><strong>0 workers:</strong> 0.0122 <em>seconds</em> <br/>
<strong>1 worker:</strong> 0.0214 <em>seconds</em> <br/>
<strong>10 workers:</strong> 0.0296 <em>seconds</em> <br/></p>
</div>
<div class="post-text" itemprop="text">
<p>When you call one of your async functions it returns a "futures" object (instance of <code>tomorrow.Tomorrow</code> in this case). This allows you to submit all your jobs without having to wait for them to finish. However, never actually wait for the jobs to finish. So all <code>do(openAsync1)</code> does is time how long it takes to setup all the jobs (should be very fast). For a more accurate test you need to do something like:</p>
<pre><code>def openAll(paths: list):
    def do(func: callable)-&gt;float:
        t = time.time()
        # do all jobs if openSync, else start all jobs if openAsync
        results = [func(p) for p in paths]
        # if openAsync, the following waits until all jobs are finished
        if func is not openSync:
            for r in results:
                r._wait()
        t = time.time() - t
        return t
    print(do(openSync))
    print(do(openAsync1))
    print(do(openAsync10))

openAll(glob.glob("data/*"))
</code></pre>
<p>Using additional threads in python generally slows things down. This is because of the global interpreter lock which means only 1 thread can ever be active, regardless of the number of cores the CPU has.</p>
<p>However, things are complicated by the fact that your job is IO bound. More worker threads <em>might</em> speed things up. This is because a single thread might spend more time waiting for the hard drive to respond than is lost between context switching between the various threads in the multi-threaded variant.</p>
<p>Side note, even though neither <code>openAsync1</code> and <code>openAsync10</code> wait for jobs to complete, <code>do(openAsync10)</code> is probably slower because it requires more synchronisation between threads when submitting a new job.</p>
</div>
<span class="comment-copy">Your sample size is probably way too small for anything approaching accurate performance statistics. You also need to consider the impact of caching (within the operating system) when testing things such as file operations.</span>
<span class="comment-copy">@DarkFalcon I've ran the code more than a couple dusin times, with different programs running in the background (ran a bunch yesterday, and a couple today). The numbers change, ofc, but the order of is always the same.  I've also tried swapping the order of execution, e.g. moving the <code>do</code> calls around. Still the same.</span>
<span class="comment-copy">Your tests appear incorrect. That is, the async variants are not required to wait for all work to be finished before ending the test. That is, you are only timing how long it takes to setup all the worker threads, and not how long it takes those threads to complete their work.</span>
<span class="comment-copy">@Dunes I'm not sure i understand... could you post an answer with some sample code explaining where I'm at fault?</span>
<span class="comment-copy">Thanks! Working as intended (and learned something new about async in python) :)</span>
