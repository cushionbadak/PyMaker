<div class="post-text" itemprop="text">
<p>On the input I have a signed array of bytes <code>barr</code> (usually little endian, but that probably doesn't matter) and a float <code>f</code> to multiply <code>barr</code> with.</p>
<p>My approach is to convert <code>barr</code> into an integer <code>val</code> (using <code>int.from_bytes</code> function), multiply it, perform overflow checks and "crop" multiplied <code>val</code> if needed, then convert it back into an array of bytes.</p>
<pre><code>def multiply(barr, f):
        val = int.from_bytes(barr, byteorder='little', signed=True)
        val *= f
        val = int (val)
        val = cropInt(val, bitLen = barr.__len__()*8)
        barr = val.to_bytes(barr.__len__(), byteorder='little', signed=True)
        return barr

def cropInt(integer, bitLen, signed = True):
        maxValue = (2**(bitLen-1)-1) if signed else (2**(bitLen)-1)
        minValue = -maxValue-1 if signed else 0
        if integer &gt; maxValue:
            integer = maxValue
        if integer &lt; minValue:
            integer = minValue
        return integer
</code></pre>
<p>However this process is extremely slow when processing a large amount of data. Is there a better, more efficient way to do that?</p>
</div>
<div class="post-text" itemprop="text">
<p>Pure Python is rather innefective for any numeric calculations - because due to each number being treated as an object, each operation involves a lot of "under the hood" steps.</p>
<p>On the other hand, Python can be very effective for numeric calculation if you use the appropriate set of third party libraries. </p>
<p>In your case, sice performance matters, you can make use of <a href="http://www.numpy.org/" rel="nofollow noreferrer"><code>NumPy</code></a> - the de facto Python package for numeric processing.</p>
<p>With it the casting, multiplication and recasting will be done in native code in one pass each (and after knowing better NumPy than I do, probably with even less steps) - and should give you an improvement of 3-4 orders of magnitude in speed for this task:</p>
<pre><code>import numpy as np
def multiply(all_bytes, f, bitlen, signed=True): 

    # Works for 8, 16, 32 and 64 bit integers:
    dtype = "%sint%d" % ("" if signed else "",   bitlen)
    max_value = 2 ** (bitlen- (1 if signed else 0)) - 1

    input_data = np.frombuffer(all_bytes, dtype=dtype)
    processed = np.clip(input_data * f, 0, max_value)
    return bytes(processed.astype(dtype))
</code></pre>
<p>Please not this example takes all your byte-data at once, not one at a time as you pass to your original "multiply" function. Threfore, you also have to pass it the size in bits of your integers.</p>
<p>The line that goes <code>dtype = "%sint%d" % ("" if signed else "",   bitlen)</code> creates the data-type name, as used by NumPy from the number of bits passed in. SInce the name is just a string, it interpolates a string adding or not an "u" prefix, depending on the datatype being unsigned, and put the number of bits at the end. NumPy datatypes can be checked at: <a href="https://docs.scipy.org/doc/numpy/user/basics.types.html" rel="nofollow noreferrer">https://docs.scipy.org/doc/numpy/user/basics.types.html</a> </p>
<p>Running with an array of 500000 8bit signed integers I get these timings:</p>
<p>In [99]: %time y = numpy_multiply(data, 1.7, 8)
CPU times: user 3.01 ms, sys: 4.96 ms, total: 7.97 ms
Wall time: 7.38 ms</p>
<p>In [100]: %time x = original_multiply(data, 1.7, 8)
CPU times: user 11.3 s, sys: 1.86 ms, total: 11.3 s
Wall time: 11.3 s</p>
<p>(That is after modifying your function to operate on all bytes at a time as well) - an speedup of 1500 times, as I've stated on the first draft.</p>
</div>
<span class="comment-copy">Try to use <a href="https://docs.python.org/3/library/struct.html" rel="nofollow noreferrer">struct</a> module to parse bytes sequnces. Also you can remove <code>maxValue</code> and <code>minValue</code> calculation from <code>cropInt</code> function to increase its speed.</span>
<span class="comment-copy">Unfortunately each array of bytes might be of different length thus I need to count it every time (but since they are mostly of the same length, I could build a short-term memory for the computation).</span>
<span class="comment-copy">From a quick <code>timeit</code> session, most of the time is spent for <code>int.from_bytes()</code> and <code>int.to_bytes()</code>, which will be difficult to make faster</span>
<span class="comment-copy">Did you mean more <i>efficient</i>?</span>
<span class="comment-copy">Yes, sorry. Post and its title edited</span>
<span class="comment-copy">FYI, this does not produce the same result as OP method. (but I don't know why...)</span>
<span class="comment-copy">And it is actually <i>slower</i> than OP method</span>
<span class="comment-copy">Sorry - this can't possibily be slower than the OP method - but if you are trying with a single number at a time - this takes the whole amount of data the OP needs at once.</span>
<span class="comment-copy">I want to believe you, but timeit says otherwise :) : with arbitrary <code>my_bytes = b"1EZR3"</code> and <code>my_float = 8.0</code>, I get 5.972544721647864 for yours and 3.836732462648797 for OP. But I am not able to get an explanation for that difference.</span>
<span class="comment-copy">Also it is necessary to also compute <code>min_value = -max_value - 1</code> and replace 0 in <code>np.clip(input_data * f, 0, max_value)</code> by <code>min_value</code> since in your implementation -100*0.2 is always set to zero.</span>
