<div class="post-text" itemprop="text">
<p>My code is running, but idk exactly how it's works, and then i need to expand this function..</p>
<p>I want to loop by POST method with same url after login..</p>
<pre><code>   class myspider(scrapy.Spider):
    name = 'myspider'
    start_urls = ['login_url']
    target_urls = 'target_url'

    # sent data
    def parse(self, response):
        return scrapy.FormRequest.from_response(
            response,
            formdata={'user': 'x', 'pass': 'y'},
            callback=self.after_login
        )

    # responds after login form sent
    def after_login(self, response):
        if "authentication failed" in response.text:
            self.log("Login failed", level=log.ERROR)
            return
        hxs = scrapy.Selector(response)
        yum = hxs.xpath('//span[@id="userName"]/text()').get()

    # responds after login result extracted
    @classmethod
    def from_crawler(cls, crawler, *args, **kwargs):
        spider = super(spider_new_fee, cls).from_crawler(crawler, *args, **kwargs)
        crawler.signals.connect(spider.spider_idle,
                                signal=scrapy.signals.spider_idle)
        return spider

    # Second parsing
    def spider_idle(self):
        self.crawler.signals.disconnect(self.spider_idle,
                                        signal=scrapy.signals.spider_idle)

        mydata={'param1': param1, 'param2': param2, 'param3': 'param3'}    
        self.crawler.engine.crawl(scrapy.Request(
            url_target,
            method='POST',
            body=json.dumps(mydata),
            headers={'Content-Type':'application/json'},
            callback=self.parse_page2
        ), self)

        raise DontCloseSpider

    # Extract second parsing
    def parse_page2(self, response):
        self.logger.info("Visited %s", response.url)
        hxs = scrapy.Selector(response)
        root = lxml.html.fromstring(response.body)
        lxml.etree.strip_elements(root, lxml.etree.Comment, "script", "head")

        try:
            data= lxml.html.tostring(root, method="text", encoding=str)
        except Exception as e:
            data= lxml.html.tostring(root, method="text", encoding=unicode)

        texts = json.loads(data)
        res={}

        # do something with result

        return res
</code></pre>
<p>This code is works, I'am login, and scrap next url with login.. It's success to login, and success get result item inside url, and then after first(idle method) this scrap next url, and lastly parsing the result..</p>
<p>But idk, is this best method to scrap after login?, and any more mature code to handling this purpose ?, is there good technical explanation(my explanation is too simple)?, and lastly how this code could scrap more with iterate target_url with different POST request,, i want to add in idle method, but still fail,,</p>
<p>some fail try :</p>
<pre><code>    multi_param = self.allparam.split("-")
    for param in multi_param:
        self.logger.info("Visited %s", target_url)
        mydata={'param1': param1, 'param2': param2, 'param3': 'param3'}    
        self.crawler.engine.crawl(scrapy.Request(
            url=target_url,
            method='POST',
            body=json.dumps(mydata),
            dont_filter=True,
            callback=self.parse_page2
        ), self)
</code></pre>
<p>another fail try :</p>
<p>I am remove function class method, and after login i am add another scrap, it's fail because it didn't get session in login.. :(</p>
<p>Thanks for help,,</p>
</div>
<div class="post-text" itemprop="text">
<p>I think you need to add some code in <code>spider_idle</code> that's is when second request sent,,</p>
<p>something like :</p>
<pre><code>    def spider_idle(self):
      allparam = self.listparam.split("-")
      for param in allparam:
        mydata={'param1': param}    
        self.crawler.engine.crawl(scrapy.Request(
            url=self.target_url,
            method='POST',
            body=json.dumps(my_data),
            dont_filter=True,
            headers={'Content-Type':'application/json'},
            callback=self.parse_page2
        ), self)
</code></pre>
<p>This <code>code</code> will iterate your request POST,, hope this help..</p>
</div>
