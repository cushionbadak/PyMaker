<div class="post-text" itemprop="text">
<p>I have a huge list of proxies (70k) and I have this script:</p>
<pre><code>entries = open("proxy.txt").readlines()
proxiesp = [x.strip().split(":") for x in entries] 
proxies = []
for x in proxiesp:
    x = tuple(x)
    proxies.append(x)
    set(proxies)
</code></pre>
<p>And the operation of set(proxies) so the duplicates removing, is really slow. Is there a way to speed up this using threads?</p>
</div>
<div class="post-text" itemprop="text">
<p>No, threading won't speed this up, for three reasons:</p>
<ol>
<li><p>The Python GIL prevents Python code from being executed in parallel; threads executing Python code can only be run concurrently. For the same amount of CPU work, the same amount of time or more is required.</p></li>
<li><p>To be able to add to the same datastructure from multiple threads, you'd have to add locking, slowing down threading more.</p></li>
<li><p>Your code is slow because it is wasting cycles, because you are recreating the set object each iteration and then discarding it again. This is sucking up all the time as <code>proxies</code> continues to grow, so in the end you created sets for each size of <code>proxies</code>, from length 1 all the way up to length 70k, approaching 5 million steps to throw away 70k sets.</p></li>
</ol>
<p>You should produce the set <strong>once</strong>. You can do so in a set comprehension:</p>
<pre><code>with open('proxy.txt') as f:
    proxies = {tuple(line.strip().split(':')) for line in f}
</code></pre>
</div>
<span class="comment-copy">Unsure threading is the way to go - what does "really slow" mean? What object is precisely a "proxy"? if it consists of a long list of stings, the hashing might be what takes time. Or maybe you could declare <code>proxies</code> as a set, and directly populate it <code>proxies.add(tuple(x))</code></span>
<span class="comment-copy">Threads often do not offer perfomance benefits with CPython. You can use multiple processes though.</span>
<span class="comment-copy"><code>set(proxies)</code> creates a set object, then discards it again. That'll just waste time, since you are not actually <i>using</i> that object. You can simplify your code down to <code>with open('proxy.txt') as f: proxies = {tuple(line.strip().split(':')) for line in f}</code> to produce a tuple of unique tuples.</span>
<span class="comment-copy">Python threads are not going to speed anything up here, no, as the Python GIL ensures those threads can't run in parallel, only concurrently, and you'd have to <i>lock</i> the set to even add anything to it.</span>
<span class="comment-copy">for this size you propably will not gain a speedup from using multiple cores because oth the overhead for distributing and joining the workload</span>
<span class="comment-copy">Actually in some cases (mostly long calls to external libraries) the GIL is released so that threading may increase performance - but not in this case.</span>
<span class="comment-copy">@janbrohl: that's why I explicitly qualified this to <i>python code</i>. The GIL can only be released when executing code that won't affect the internal Python interpreter loop data structures.</span>
<span class="comment-copy">From the user's perspective calling <a href="https://docs.python.org/3/library/hashlib.html#hashlib.hash.update" rel="nofollow noreferrer">hash.update</a> is python code.</span>
<span class="comment-copy">@janbrohl: and so are loads of I/O-related functions. This is not one of those. That's beside the point however.</span>
<span class="comment-copy">@janbrohl: this isn't the place to hash out exactly when the GIL can be released, or detail exactly when you can expect it to be.</span>
