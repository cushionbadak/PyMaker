<div class="post-text" itemprop="text">
<p>I have a problem in python where I want to run two loops at the same time. I feel like I need to do this because the second loop needs to be rate limited, but the first loop really shouldn't be rate limited. Also, the second loop takes an input from the first.</p>
<p>I'm looking fro something that works something like this:</p>
<pre><code>for line in file:
do some stuff
list = []
list.append("an_item")

Rate limited:
for x in list:
do some stuff simultaneously
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are two basic approaches with different tradeoffs: synchronously switching between tasks, and running in threads or subprocesses. First, some common setup:</p>
<pre><code>from queue import Queue # or Queue, if python 2
work = Queue()

def fast_task():
    """ Do the fast thing """
    if done:
        return None
    else:
        return result

def slow_task(arg):
    """ Do the slow thing """

RATE_LIMIT = 30 # seconds
</code></pre>
<p>Now, the synchronous approach. It has the advantage of being much simpler, and easier to debug, at the cost of being a bit slower. How much slower depends on the details of your tasks. How it works is, we run a tight loop that calls the fast job every time, and the slow job only if enough time has passed. If the fast job is no longer producing work and the queue is empty, we quit.</p>
<pre><code>import time
last_call = 0

while True:
    next_job = fast_task()
    if next_job:
        work.put(next_job)
    elif work.empty():
        # nothing left to do
        break
    else:
        # fast task has done all its work - short sleep to slow the spin
        time.sleep(.1)

    now = time.time()
    if now - last_call &gt; RATE_LIMIT:
        last_call = now
        slow_task(work.get())
</code></pre>
<p>If you feel like this doesn't work fast enough, you can try the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer"><code>multiprocessing</code></a> approach. You can use the same structure for working with threads or processes, depending on whether you import from <code>multiprocessing.dummy</code> or <code>multiprocessing</code> itself. We use a <code>multiprocessing.Queue</code> for communication instead of <code>queue.Queue</code>.</p>
<pre><code>def do_the_fast_loop(work_queue):
    while True:
        next_job = fast_task()
        if next_job:
            work_queue.put(next_job)
        else:
            work_queue.put(None) # sentinel - tells slow process to quit
            break

def do_the_slow_loop(work_queue):
    next_call = time.time()
    while True:
        job = work_queue.get()
        if job is None: # sentinel seen - no more work to do
            break
        time.sleep(max(0, next_call - time.time()))
        next_call = time.time() + RATE_LIMIT
        slow_task(job)

if __name__ == '__main__':
    # from multiprocessing.dummy import Queue, Process # for threads
    from multiprocessing import Queue, Process # for processes
    work = Queue()
    fast = Process(target=fast_task, args=(work,))
    slow = Process(target=slow_task, args=(work,))
    fast.start()
    slow.start()
    fast.join()
    slow.join()
</code></pre>
<p>As you can see, there's quite a lot more machinery for you to implement, but it will be somewhat faster. Again, how much faster depends a lot on your tasks. I'd try all three approaches - synchronous, threaded, and multiprocess - and see which you like best.</p>
</div>
<div class="post-text" itemprop="text">
<p>You need to do 2 things:</p>
<ol>
<li>Put the function require data from the other on its own process</li>
<li>Implement a way to communicate between the two processes (e.g. <a href="https://docs.python.org/3.6/library/multiprocessing.html#exchanging-objects-between-processes" rel="nofollow noreferrer">Queue</a>)</li>
</ol>
<p>All of this must be done thanks to the <a href="https://docs.python.org/3.6/glossary.html#term-global-interpreter-lock" rel="nofollow noreferrer">GIL</a>.</p>
</div>
<span class="comment-copy">What approach is best here depends entirely on the nature of the "stuff" you want to do. Is it disk I/O? Network connections? CPU-heavy calculations? Calls to libraries written in C?</span>
<span class="comment-copy">@NathanVÄ“rzemnieks The first loop is reading from a file and making DNS lookups. It runs fairly quickly and is only limited by the speed of the DNS server. The second loop is making GET requests to an API and needs to be rate limited to adhere the to limits placed on the API to avoid having the user's IP blocked. It also writes the results to a file. I would like to have the first loop run a quickly as possible and have the second loop run through the results as quickly as the API allows.</span>
