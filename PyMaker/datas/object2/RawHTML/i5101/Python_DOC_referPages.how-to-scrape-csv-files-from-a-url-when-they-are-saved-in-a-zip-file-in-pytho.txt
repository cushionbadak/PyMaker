<div class="post-text" itemprop="text">
<p>I am trying to scrape some <code>.csv</code> files from a website. I currently have a list of links: </p>
<pre><code>master_links = [
    'http://mis.nyiso.com/public/csv/damlbmp/20161201damlbmp_zone_csv.zip', 
    'http://mis.nyiso.com/public/csv/damlbmp/20160301damlbmp_zone_csv.zip', 
    'http://mis.nyiso.com/public/csv/damlbmp/20160201damlbmp_zone_csv.zip']
</code></pre>
<p>when I try to use:</p>
<pre><code>pd.read_csv(master_links[0])]
</code></pre>
<p>it returns an error because each <code>.zip</code> file contains multiple <code>.csv</code> within them. I understand why this isn't working, but I haven't figured out how to unzip these files, and then put the .csv files into pd.read_csv without saving everything to my computer. </p>
<p>Is this possible?  </p>
</div>
<div class="post-text" itemprop="text">
<p>You can do that with a custom file reader for <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" rel="nofollow noreferrer"><code>pandas.read_csv()</code></a> like:</p>
<h3>Code:</h3>
<pre><code>def fetch_multi_csv_zip_from_url(url, filenames=(), *args, **kwargs):
    assert kwargs.get('compression') is None
    req = urlopen(url)
    zip_file = zipfile.ZipFile(BytesIO(req.read()))

    if filenames:
        names = zip_file.namelist()
        for filename in filenames:
            if filename not in names:
                raise ValueError(
                    'filename {} not in {}'.format(filename, names))
    else:
        filenames = zip_file.namelist()

    return {name: pd.read_csv(zip_file.open(name), *args, **kwargs)
            for name in filenames}
</code></pre>
<p>Some Docs:
 (<a href="https://docs.python.org/3/library/zipfile.html" rel="nofollow noreferrer">ZipFile</a>) (<a href="https://docs.python.org/3/library/io.html#io.BytesIO" rel="nofollow noreferrer">BytesIO</a>) (<a href="https://docs.python.org/3.5/library/urllib.request.html#urllib.request.urlopen" rel="nofollow noreferrer">urlopen</a>)</p>
<h3>Test Code:</h3>
<pre><code>try:
    from urllib.request import urlopen
except ImportError:
    from urllib2 import urlopen
from io import BytesIO
import zipfile
import pandas as pd

master_links = [
    'http://mis.nyiso.com/public/csv/damlbmp/20161201damlbmp_zone_csv.zip',
    'http://mis.nyiso.com/public/csv/damlbmp/20160301damlbmp_zone_csv.zip',
    'http://mis.nyiso.com/public/csv/damlbmp/20160201damlbmp_zone_csv.zip']

dfs = fetch_multi_csv_zip_from_url(master_links[0])
print(dfs['20161201damlbmp_zone.csv'].head())
</code></pre>
<h3>Results:</h3>
<pre><code>         Time Stamp    Name   PTID  LBMP ($/MWHr)  \
0  12/01/2016 00:00  CAPITL  61757          21.94   
1  12/01/2016 00:00  CENTRL  61754          16.85   
2  12/01/2016 00:00  DUNWOD  61760          20.85   
3  12/01/2016 00:00  GENESE  61753          16.16   
4  12/01/2016 00:00     H Q  61844          15.73   

   Marginal Cost Losses ($/MWHr)  Marginal Cost Congestion ($/MWHr)  
0                           1.21                              -4.45  
1                           0.11                              -0.45  
2                           1.58                              -2.99  
3                          -0.49                              -0.36  
4                          -0.55                               0.00  
</code></pre>
</div>
<span class="comment-copy">Wow, that is amazing. Could you point me towards some documentation or examples so I can understand a bit better what is going on in the custom file reader. I feel like it is better to understand this, rather than just copying it</span>
<span class="comment-copy">Also my plan was to iterate over all entries in master_links list using a for loop, and then append them together. With the code as it stands you this only picks out '20161201damlbmp_zone.csv' when you define df</span>
<span class="comment-copy">Why do you need the filename as the second entry in fetch_multi_csv_zip_from_url() ?</span>
<span class="comment-copy">Except for pandas these are all standard Python.  I have added some links, and a loop.</span>
<span class="comment-copy">Thanks for the help, much appreciated</span>
