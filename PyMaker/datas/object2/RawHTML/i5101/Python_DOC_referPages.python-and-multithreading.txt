<div class="post-text" itemprop="text">
<p>The python incref is define like this</p>
<pre><code>#define Py_INCREF(op) (                         \
    _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA       \
    ((PyObject *)(op))-&gt;ob_refcnt++)
</code></pre>
<p>With multi-core, the incrementation is only is L1 cache and not flushed to memory.</p>
<p>If two thread increment the refcnt at the same time, in differents core, without a flush to the real memory, for me, it's possible to lost one incrementation. 
- ob_refcnt=1
- Core 1 increment, but not flush =&gt; ob_refcnt=2 in L1 cache of core 1
- Core 2 increment, but not flush =&gt; ob_refcnt=2 in L1 cache of core 2
- WTF</p>
<p>Is it a risk to use multi-core or multi-process ?</p>
<p>The PyObject was declared like this:</p>
<pre><code>typedef struct _object {
    _PyObject_HEAD_EXTRA
    Py_ssize_t ob_refcnt;
    struct _typeobject *ob_type;
} PyObject
</code></pre>
<p>But Py_ssize_t is just a ssize_t or intptr_t.</p>
<p>The _Py_atomic* functions and attributes do not seem to be used.</p>
<p>How Python can manage this scenario ? How can it flush the cache between threads ?</p>
</div>
<div class="post-text" itemprop="text">
<p>The CPython implementation of Python has <a href="https://stackoverflow.com/questions/1294382/what-is-a-global-interpreter-lock-gil">the global interpreter lock (GIL)</a>. It is undefined behaviour to call the vast majority of Python C API functions (including <code>Py_INCREF</code>) without holding this lock and will almost certainly result in inconsistent data or your program crashing.</p>
<p>The GIL can be <a href="https://docs.python.org/3/c-api/init.html#thread-state-and-the-global-interpreter-lock" rel="noreferrer">released and acquired as described in the documentation</a>.</p>
<p>Because of the need to hold this lock in order to operate on Python objects multithreading in Python is pretty limited, and the only operations that parallelize well are things like waiting for IO or pure C calculations on large arrays. The <code>multiprocessing</code> module (that starts isolated Python processes) is another option for parallel Python.</p>
<hr/>
<p>There have been <a href="https://greek0.net/blog/2015/05/23/python_atomic_refcounting_slowdown/" rel="noreferrer">attempts to use atomic types for reference counting</a> (to remove/minimize the need for the GIL) but these caused significant slowdowns in single-threaded code so were abandoned.</p>
</div>
<div class="post-text" itemprop="text">
<p>Why not use Lock's or Semaphore's of Python ?
<a href="https://docs.python.org/2/library/threading.html" rel="nofollow noreferrer">https://docs.python.org/2/library/threading.html</a></p>
</div>
<span class="comment-copy">A risk in what sense?</span>
<span class="comment-copy">How Python can manage this scenario ? Python can't manage any thread ! Because all threads used seperated  python shell, you can only <code>start,stop,pause</code> actions. Data addresses are shared between processes (not copied, moved, only the shadow data image is rendered(Snapshot)).</span>
<span class="comment-copy">I the code to manage GIL, I suppose the mfence was called to flush all the incrementation. Is it correct ?</span>
<span class="comment-copy">I'm not 100% sure. <a href="https://github.com/python/cpython/blob/2ebc5ce42a8a9e047e790aefbf9a94811569b2b6/Python/ceval_gil.h#L191" rel="nofollow noreferrer">Internally it does seem to use some <code>_PyAtomic</code> calls</a> but I don't know if they're the right ones personally...</span>
