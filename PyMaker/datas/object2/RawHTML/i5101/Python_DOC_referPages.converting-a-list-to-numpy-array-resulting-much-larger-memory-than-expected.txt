<div class="post-text" itemprop="text">
<p>I have a list with 2940 elements - each element is a (60, 2094) numpy array. </p>
<pre><code>print('DataX:')
print('len:')
print(len(dataX))
print('shape:')
for i in range(5):
    print(dataX[i].shape)
print('dtype:')
print(dataX[0].dtype)

print('size',sys.getsizeof(dataX)/1000000)
</code></pre>
<p>results in :</p>
<pre><code>DataX:
len:
2940
shape:
(60, 2094)
(60, 2094)
(60, 2094)
(60, 2094)
(60, 2094)
dtype:
float64
size 0.023728
</code></pre>
<p>However, if I try to turn this in to a numpy array (which should result in a shape of (2940, 60, 2094), the size of the array is much, much larger.</p>
<pre><code>#convert list to array

X = np.array(dataX)
print('X:')
print('shape', X.shape)
print('size',sys.getsizeof(X)/1000000)
</code></pre>
<p>Output:</p>
<pre><code>DataX:
shape (2940, 60, 2094)
size 2955.052928
</code></pre>
<p>Why is this the case?</p>
<p>If I try it with a bigger dataset, I end up with the "Memory" error. </p>
</div>
<div class="post-text" itemprop="text">
<p>From the <a href="https://docs.python.org/3/library/sys.html#sys.getsizeof" rel="nofollow noreferrer">sys.getsizeof docs</a>:</p>
<blockquote>
<p>Only the memory consumption directly attributed to the object is
  accounted for, not the memory consumption of objects it refers to.</p>
</blockquote>
<p><code>sys.getsizeof</code> returns the memory consumption of the list object itself, not including the objects contained by the list. A single one of your arrays:</p>
<pre><code>In [3]: arr = np.zeros(dtype=np.float64, shape=(60, 2094))

In [4]: arr.size
Out[4]: 125640

In [5]: arr.nbytes
Out[5]: 1005120 
</code></pre>
<p>The python object wrapping the primitive array adds about 100 bytes.</p>
<p>Note, there is <em>always</em> overhead for being an object, note:</p>
<pre><code>In [6]: sys.getsizeof(arr)
Out[6]: 1005232
</code></pre>
<p>The actual memory consumption, then is about:</p>
<pre><code>In [7]: arr.nbytes*1e-9
Out[7]: 0.00100512 # one megabyte
</code></pre>
<p>And if we had 2940 of them, just those objects would be:</p>
<pre><code>In [8]: arr.nbytes*2940*1e-9
Out[8]: 2.9550528000000003 # almost 3 gigabytes
</code></pre>
<p>If I actually put these all in a list:</p>
<pre><code>In [13]: alist = []

In [14]: alist.append(arr)

In [15]: for _ in range(2940 - 1):
    ...:     alist.append(arr.copy())
    ...:
</code></pre>
<p>The list object itself is essentially backed by an array of py_object pointers. On my machine (64bit) a pointer will be one machine word, i.e. 64bits or 8 bytes. So:</p>
<pre><code>In [19]: sys.getsizeof(alist)
Out[19]: 23728

In [20]: 8*len(alist) # 8 bytes per pointer
Out[20]: 23520
</code></pre>
<p>So <code>sys.getsizeof</code> is only accounting for an array of pointers, plus object overhead, but that isn't even <em>close</em> to accounting for the 3 gigabytes consumed by the array objects being pointed to.</p>
<p>Lo and behold:</p>
<pre><code>In [21]: arr = np.array(alist)

In [22]: arr.shape
Out[22]: (2940, 60, 2094)

In [23]: arr.size
Out[23]: 369381600

In [24]: arr.nbytes
Out[24]: 2955052800

In [25]: arr.nbytes* 1e-9
Out[25]: 2.9550528000000003
</code></pre>
</div>
<span class="comment-copy">Have you read the documentation about sys.getsizeof? <a href="https://docs.python.org/3/library/sys.html#sys.getsizeof" rel="nofollow noreferrer">docs.python.org/3/library/sys.html#sys.getsizeof</a></span>
<span class="comment-copy">Hi. Are you talking about this part "but this does not have to hold true for third-party extensions as it is implementation specific." I don't think it holds true in my case as I'm getting a "Memory" error for <code>X</code> when I increase the data size, but don't seem to be getting a "Memory" error for the list of arrays. I also checked the memory size with task manager and it seems to be true.</span>
<span class="comment-copy"><code>sys.getsizeof</code> only gives you the size of the <i>list</i>, not including the objects in the list. That is the source of the discrepancy.</span>
<span class="comment-copy">Thank you for this. I just want to run a few tests tomorrow just to make sure, as I was experiencing some conflicting behavior as to what you just listed out.</span>
<span class="comment-copy">@Moondra the other thing to understand is that when you do <code>arr = np.array(alist)</code> then it will require <i>double</i> since data is copied not shared</span>
