<div class="post-text" itemprop="text">
<p>I have a dictionary of form
example:- </p>
<pre><code> all_ways = {key1:[list1], key2:[list2], ... keyN[listN]}
</code></pre>
<p>I want to find only those elements of the <code>ith</code> list such that it is a part of at least one another list say <code>jth</code> list <code>(i!=j)</code> and then for all keys store only those elements that satisfy the above condition.</p>
<p>Is there any good way of doing it except using multiple loops? </p>
<p>Example:-</p>
<pre><code>key1: [1,2,3,4,5,100,111,123] 
key2: [1,2,3,13,15,17] 
key3:[100,110,111,1000] 
</code></pre>
<p>answer: </p>
<pre><code>key1:[1,2,3,100,111] 
key2:[1,2,3]
key3:[100,111]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can achieve this in linear time (no nested loops) wrt to the overall number of list elements:</p>
<pre><code>from collections import Counter
from itertools import chain

d = {'key1': [1,2,3,4,5,100,111,123],
     'key2': [1,2,3,13,15,17],
     'key3': [100,110,111,1000]}

# histogramm over the chained lists
c = Counter(chain(*d.values()))  
# c = Counter(chain(*map(set, d.values())))  # if there are duplicates in the lists

# for every key k in d, pick only those elements x from their value lists v
# that occur more than once overall (thus in multiple lists)
result = {k: [x for x in v if c[x] &gt; 1] for k, v in d.items()}
# {'key1': [1, 2, 3, 100, 111], 
#  'key2': [1, 2, 3], 
#  'key3': [100, 111]}
</code></pre>
<p>The <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>collections.Counter</code></a> holds counts of how many lists an element appears in for each unique list element while ignoring duplicates within single lists (via <code>set</code>). The nested comprehension then picks only elements with counts greater <code>1</code>, therefore guaranteeing that they occur in more than one list.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here are a couple of other methods, with benchmarking on a realistic data set. This answer assumes no duplicates within a list, and ordering of output (duplicate items for each key) does not matter.</p>
<pre><code>import numpy as np
from itertools import groupby, chain
from collections import Counter

d = {'key'+str(i): list(np.random.randint(0, 1000000, 50)) for i in range(1, 50000)}

def return_dups_jp1(d):
    def get_dups(a):
        seen = set()
        dup = set()
        for x in a:
            if x not in seen:
                seen.add(x)
            else:
                dup.add(x)
        return dup

    def apply_dups(d, dups):
        return {k: list(set(v) &amp; dups) for k, v in d.items()}

    return apply_dups(d, get_dups(chain.from_iterable(d.values())))

def return_dups_jp2(d):
    b = sorted(chain.from_iterable(d.values()))
    dups = {group[0] for group in groupby(b) if len(list(group[1])) &gt; 1}
    return {k: list(set(v) &amp; dups) for k, v in d.items()}

def return_dups_sch(d):
    c = Counter(chain(*d.values()))
    return {k: [x for x in v if c[x] &gt; 1] for k, v in d.items()}
</code></pre>
<p>Benchmarking:</p>
<pre><code>x = return_dups_jp1(d)
y = return_dups_jp2(d)
z = return_dups_sch(d)

assert all(set(x['key'+str(i)]) == set(y['key'+str(i)]) for i in range(1, 50000))
assert all(set(y['key'+str(i)]) == set(z['key'+str(i)]) for i in range(1, 50000))

%timeit return_dups_jp1(d)
# 1 loop, best of 3: 2.56 s per loop

%timeit return_dups_jp2(d)
# 1 loop, best of 3: 5.12 s per loop

%timeit return_dups_sch(d)
# 1 loop, best of 3: 2.66 s per loop
</code></pre>
</div>
<span class="comment-copy">Instinctively, this may be hard without loops. How many dictionary items / items per list, roughly?</span>
<span class="comment-copy">70,000 keys and each key has on an average 50 elements in its list.</span>
<span class="comment-copy">Possibly, this could be processed efficiently a dictionary comprehension + single loop. But I'll wait to see if anyone offers an alternative.</span>
<span class="comment-copy">It would be benficial to provide an example.</span>
<span class="comment-copy">Example: key1: [1,2,3,4,5,100,111,123] key2: [1,2,3,13,15,17] key3:[100,110,111,1000]  answer: key1:[1,2,3,100,111] key2:[1,2,3] key3:[100,111]</span>
<span class="comment-copy">Okay that helps a lot. If you can tell me how the algorithm works and not just the implementation that would be great.</span>
<span class="comment-copy">One obvious point on performance. <code>Counter</code> does not stop counting once 2 items are registered. So it's doing slightly more work than it should do.</span>
<span class="comment-copy">@DivyangVashi I added some explanation.</span>
<span class="comment-copy">@jp_data_analysis That is true, but you need to look at each element either way in order to know if you have seen it twice already. Implementing your own check will hardly beat the optimzed counter.</span>
<span class="comment-copy">@schwobaseggl, Well, you are saving updating a dictionary value each time. In this (relatively small) data set it's fine. Just an observation. I did upvote your answer, it's the cleanest solution.</span>
