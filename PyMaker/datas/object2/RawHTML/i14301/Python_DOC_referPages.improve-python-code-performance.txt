<div class="post-text" itemprop="text">
<p>How do I improve the performance of this simple piece of python code ?
Isn't <code>re.search</code> the best way to find a matching line, since it is almost ~6x slower than Perl or am I doing something wrong ?</p>
<pre><code>#!/usr/bin/env python

import re
import time
import sys

i=0
j=0
time1=time.time()
base_register =r'DramBaseAddress\d+'
for line in  open('rndcfg.cfg'):
    i+=1
    if(re.search(base_register, line)):
        j+=1
time2=time.time()

print (i,j)
print (time2-time1)    
print (sys.version)
</code></pre>
<p>This code takes about 0.96 seconds to complete (Average of 10 runs)
<br/>Output:</p>
<pre><code>168197 2688
0.8597519397735596
3.3.2 (default, Sep 24 2013, 15:14:17)
[GCC 4.1.1]
</code></pre>
<p>while the following Perl code does it in 0.15 seconds.</p>
<pre><code>#!/usr/bin/env perl
use strict;
use warnings;

use Time::HiRes qw(time);

my $i=0;my $j=0;
my $time1=time;
open(my $fp, 'rndcfg.cfg');
while(&lt;$fp&gt;)
{
    $i++;
    if(/DramBaseAddress\d+/)
    {
        $j++;
    }
}
close($fp);
my $time2=time;

printf("%d,%d\n",$i,$j);
printf("%f\n",$time2-$time1);
printf("%s\n",$]);
</code></pre>
<p><br/>Output:</p>
<pre><code>168197,2688
0.135579
5.012001
</code></pre>
<p>EDIT: Corrected regular expression - Which worsened the performance slightly</p>
</div>
<div class="post-text" itemprop="text">
<p>actually, regular expression is less efficient than the string methods in Python. From <a href="https://docs.python.org/2/howto/regex.html#use-string-methods" rel="nofollow noreferrer">https://docs.python.org/2/howto/regex.html#use-string-methods</a>: </p>
<blockquote>
<p>Strings have several methods for performing operations with fixed
  strings and they’re usually much faster, because the implementation is
  a single small C loop that’s been optimized for the purpose, instead
  of the large, more generalized regular expression engine.</p>
</blockquote>
<p>replacing <code>re.search</code> with <code>str.find</code> will give you better runtime. otherwise, using the <code>in</code> operator that others suggested would be optimized, too.</p>
<p>as for the speed difference between the Python &amp; Perl version, i'll just chalk it up to the inherent quality of each language: <a href="https://stackoverflow.com/questions/12793562/text-processing-python-vs-perl-performance">text processing - python vs perl performance</a></p>
</div>
<div class="post-text" itemprop="text">
<p>In this case you are using a fixed string, not a regular expression.</p>
<p>For regular strings there are faster methods:</p>
<pre><code>&gt;&gt;&gt; timeit.timeit('re.search(regexp, "banana")', setup = "import re;     regexp=r'nan'")
1.2156920433044434
&gt;&gt;&gt; timeit.timeit('"banana".index("nan")')
0.23752403259277344
&gt;&gt;&gt; timeit.timeit('"banana".find("nan")')
0.2411658763885498
</code></pre>
<p>Now this kind of text processing is the sweet spot of Perl (aka Practical Extraction and Reporting Language) (aka Pathological Eclectic Rubbish Lister) and has been optimized extensively over the years. All that collective focus adds up.</p>
</div>
<div class="post-text" itemprop="text">
<p>The overhead of calling <code>re.compile</code>, despite the caching, is massive. Use</p>
<pre><code>is_wanted_line = re.compile(r"DramBaseAddress\d+").search

for i, line in enumerate(open('rndcfg.cfg')):
    if is_wanted_line(line):
        j += 1
</code></pre>
<p>instead.</p>
<p>Further, you can do</p>
<pre><code>key = "DramBaseAddress"
is_wanted_line = re.compile(r"DramBaseAddress\d+").search

for i, line in enumerate(open('rndcfg.cfg')):
    if key in line and is_wanted_line(line):
        j += 1
</code></pre>
<p>to further reduce overhead.</p>
<p>You can also consider doing your own buffering:</p>
<pre><code>key = b"DramBaseAddress"
is_wanted_line = re.compile(rb"DramBaseAddress\d+").search

with open("rndcfg.cfg", "rb") as file:
    rest = b""

    for chunk in iter(lambda: file.read(32768), b""):
        i += chunk.count(b"\n")
        chunk, _, rest = (rest + chunk).rpartition(b"\n")

        if key in rest and is_wanted_line(chunk):
            j += 1

    if key in rest and is_wanted_line(rest):
        j += 1
</code></pre>
<p>which removes the line-splitting and encoding overhead. (This isn't quite the same as it doesn't account for multiple instances per chunk. Such behaviour is relatively simple to add, but may not strictly be needed in your case.)</p>
<p>This is a bit heavyweight, but thrice as fast as the Perl - 8x if you remove <code>i += chunk.count(b"\n")</code>!</p>
</div>
<span class="comment-copy">You should pre-compile the regular expression if you use it several times, or in this case use <code>in</code> instead: <code>if base_register in line:</code>.</span>
<span class="comment-copy">If you read the note to <a href="https://docs.python.org/3/library/re.html#re.compile" rel="nofollow noreferrer"><code>re.compile</code></a> you'll see: "The compiled versions of the most recent patterns passed to re.compile() and the module-level matching functions are cached, so programs that use only a few regular expressions at a time needn’t worry about compiling regular expressions."</span>
<span class="comment-copy">How can I use <code>str.find</code> for a regex ?</span>
<span class="comment-copy">oh <code>str.find</code> is not regex at all; it's a simple substring matching. I just noticed the <code>\d+</code> part of your regex, so this might not be totally applicable, but if you only want to count the lines with <code>"DramBaseAddress"</code> in them (that is, if the trailing digits don't make a difference), then you can replace <code>if(re.search(base_register, line)):</code> with either <code>if "DramBaseAddress" in line:</code> or <code>if line.find("DramBaseAddress") &gt; -1:</code>. If the trailing digits are important, however, then your best bet is @Veedrac's answer below.</span>
<span class="comment-copy">do you have any test that validates the claim "The overhead of calling re.compile, despite the caching, is massive."? I use a lot of <code>re.compile</code> lol</span>
<span class="comment-copy">@oxymor0n I timed it. It was taking almost 2/3 of the time. Note that for one-off uses or searches of long strings, the overhead is likely to be amortized much better.</span>
<span class="comment-copy">interesting, thanks. I always assume the caching performance would be better than that :/</span>
