<div class="post-text" itemprop="text">
<p>let say we have a list of strings which is so big that if I save it as a normal text file(every element in a separate line) it'll be 1GB in size;</p>
<p>currently I use this code to save the list:</p>
<pre><code>savefile = codecs.open("BigList.txt", "w", "utf-8")
savefile.write("\r\n".join(BigList));
savefile.close()
</code></pre>
<p>as soon as we reach to this part of code: <code>"\r\n".join(BigList)</code>, I can see a huge bump in memory usage and also considerable time(~1min) to save the results;</p>
<p>any tip or suggestion for better handling this list(less memory-usage) and save it on hard-disk more quickly?</p>
</div>
<div class="post-text" itemprop="text">
<p>The join in:</p>
<pre><code>"\r\n".join(BigList)
</code></pre>
<p>is creating a very large string in the memory before writing it down. It will be much more memory efficient if you use a for loop:</p>
<pre><code>for line in BigList:
   savefile.write(line + "\r\n")
</code></pre>
<p>another question is, why do you have so many strings in the memory in the first place?</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>for line in BigList:
    savefile.write(line+'\n')
</code></pre>
<p>I would do it by iterating.</p>
</div>
<div class="post-text" itemprop="text">
<p>To save disk-space you could do:</p>
<pre><code>from gzip impo GzipFile
with GzipFile('dump.txt', 'w') as fh:
    fh.write('\r\n'.join(BigList))
</code></pre>
<p>(also use the <code>with</code> operator instead).
Combine this with a <code>for</code> operator in order to save memory:</p>
<pre><code>from gzip impo GzipFile
with GzipFile('dump.txt', 'w') as fh:
    for item in BigList:
        fh.write(str(item)+'\r\n')
</code></pre>
<p>And to do it really quick you could potentially do (<strong>saves memory, disk-space and time</strong>):</p>
<pre><code>import pickle
from gzip import GzipFile

with GzipFile('dump.pckl', 'wb') as fh:
    pickle.dump(BigList, fh)
</code></pre>
<p>Note however that this big list of yours would only be accessible to external programs if they understand pythons pickle structure on the data.
But assuming you want to re-use the BigList in your own application, pickle is the way to go.</p>
<p>Noticed some comment about you reading a big textfile in order to write to another file..
In that case the above an approach that would work for you.<br/>
If you want to save memory or time over two files. Consider the following instead:</p>
<pre><code>with open('file_one.txt', 'rb') as inp:
    with open('file_two.txt', 'wb' out:
        for line in inp:
            out.write(do_work(line)+b'\r\n')
</code></pre>
</div>
<span class="comment-copy">Is it the filesize or memory-usage you're mainly interested in conserving? There's always a trade-off in one of the following: CPU, Memory, Disk</span>
<span class="comment-copy">memory-usage; what is important is: using less memory-usage and save on hard-disk as fast as possible;</span>
<span class="comment-copy">You shouldn't be using <code>"\r\n"</code> at all but <code>"\n"</code> (which will be translated to <code>"\r\n"</code> on saving the file, since you've opened it in text mode). Right now, you're getting <code>"\r\r\n"</code> in your file...</span>
<span class="comment-copy">@TimPietzcker: <code>codecs.open</code> always opens in binary mode, whether on <a href="https://docs.python.org/2/library/codecs.html#codecs.open" rel="nofollow noreferrer">Python 2</a> or <a href="https://docs.python.org/3/library/codecs.html#codecs.open" rel="nofollow noreferrer">Python 3</a>.</span>
<span class="comment-copy">@user2357112: Oh, I overlooked the <code>codecs.</code> part. Of course!</span>
<span class="comment-copy">I'm reading a very big text file and add some strings to every line of it while working with the file as a list</span>
<span class="comment-copy">it may be possible to work with fixed sized group of lines perhaps.</span>
<span class="comment-copy">very effective! thanks;</span>
