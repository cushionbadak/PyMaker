<div class="post-text" itemprop="text">
<p>I'm using <em>asyncio</em> with the <em>requests</em> module to make an asynchronous HTTP request.</p>
<p>I can make a GET request like this:</p>
<pre><code>@asyncio.coroutine
def do_checks():
    loop = asyncio.get_event_loop()
    req = loop.run_in_executor(None, requests.get, 'https://api.github.com/user')
    resp = yield from req
    print(resp.status_code)
loop = asyncio.get_event_loop()
loop.run_until_complete(do_checks())
</code></pre>
<p>However, I need to do support Basic HTTP Auth (<a href="http://docs.python-requests.org/en/v0.10.6/api/?highlight=auth#requests.Request.auth">described here</a>) in the request.</p>
<p>According to the documentation, <em>url</em> and <em>auth</em> are both named parameters for requests.get().</p>
<p>But, if I run this (note the addition of <strong>url=''</strong> and <strong>auth = ''</strong>):</p>
<pre><code>@asyncio.coroutine
def do_checks():
    loop = asyncio.get_event_loop()
    req = loop.run_in_executor(None, requests.get, url='https://api.github.com/user', auth=HTTPBasicAuth('user', 'pass'))
    resp = yield from req
    print(resp.status_code)
loop = asyncio.get_event_loop()
loop.run_until_complete(do_checks())
</code></pre>
<p>I get this error:</p>
<pre><code>TypeError: run_in_executor() got an unexpected keyword argument 'url'
</code></pre>
<p>In the prototype for asyncio.run_in_executor(), additional arguments are supported:</p>
<pre><code>BaseEventLoop.run_in_executor(executor, callback, *args)
</code></pre>
<p>requests.get() clearly supports named parameters (get, auth, etc.). What's wrong?</p>
</div>
<div class="post-text" itemprop="text">
<p>Two ways to do that. Create a wrapper function, or just use a session to provide the auth.</p>
<p>Using a session:</p>
<pre><code>@asyncio.coroutine
def do_checks():
    loop = asyncio.get_event_loop()
    session = requests.Session()
    session.auth = HTTPBasicAuth('user', 'pass')
    req = loop.run_in_executor(None, session.get, 'https://api.github.com/user')
    resp = yield from req
    print(resp.status_code)
</code></pre>
<p>Writing a wrapper function (note that I'm using <code>def</code> for clarity here, but that a <code>lambda</code> would obviously work too):</p>
<pre><code>@asyncio.coroutine
def do_checks():
    def do_req():
        return requests.get('https://api.github.com/user', auth=HTTPBasicAuth('user', 'pass'))
    loop = asyncio.get_event_loop()
    req = loop.run_in_executor(None, do_req)
    resp = yield from req
    print(resp.status_code)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is actually a design decision in <code>asyncio</code>. From the docstring of asyncio/base_events.py:</p>
<pre><code>"""Base implementation of event loop.

The event loop can be broken up into a multiplexer (the part
responsible for notifying us of IO events) and the event loop proper,
which wraps a multiplexer with functionality for scheduling callbacks,
immediately or at a given time in the future.

Whenever a public API takes a callback, subsequent positional
arguments will be passed to the callback if/when it is called.  This
avoids the proliferation of trivial lambdas implementing closures.
Keyword arguments for the callback are not supported; this is a
conscious design decision, leaving the door open for keyword arguments
to modify the meaning of the API call itself.
"""
</code></pre>
<p>Note the last sentence there.</p>
<p>The <a href="http://legacy.python.org/dev/peps/pep-3156/#callback-style" rel="noreferrer">asyncio PEP</a> notes this as well, and recommends a lambda to work around it:</p>
<blockquote>
<p>This convention specifically does not support keyword arguments.
  Keyword arguments are used to pass optional extra information about
  the callback. This allows graceful evolution of the API without having
  to worry about whether a keyword might be significant to a callee
  somewhere. If you have a callback that must be called with a keyword
  argument, you can use a lambda. For example:</p>
<p><code>loop.call_soon(lambda: foo('abc', repeat=42))</code></p>
</blockquote>
</div>
<span class="comment-copy">Thanks for the answer! The session method worked for me. If I use the wrapper function, I can't figure out how to use do_req() in a for loop to call multiple different URLs without redefining do_req() each time (since I can't pass in the URL as an argument).</span>
<span class="comment-copy">@user3689902 Just redefine a new function every time. Doing this with a lambda is quite lightweight.</span>
<span class="comment-copy">Sounds good, thanks again. :)</span>
<span class="comment-copy">The asyncio docs recommend using <code>functools.partial</code>, "because asyncio can inspect functools.partial() object to display parameters in debug mode, whereas lambda functions have a poor representation."  <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio-pass-keywords" rel="nofollow noreferrer">docs.python.org/3/library/â€¦</a></span>
