<div class="post-text" itemprop="text">
<p>I am newbie and started coding in pyhton in the last few months. I have a script that takes a proteome (800 Kb file of 2850 strings) and check each individual protein (protein_string) against a large dataset (8Gb file of 23 million strings saved in the code as dictionary of id:protein_string) and report Ids of all identical strings (up to 8500 ids can be reported for each string). The current script takes 4 hours to run. What could be done to speed up the process in general and how can I convert my script to multiprocessing or multithreading (not sure of the difference) for the part of the code doing the comparisons?</p>
<pre><code>import sys
from Bio import AlignIO
from Bio import SeqIO
from Bio.Seq import Seq
import time
start_time = time.time()

databasefile = sys.argv[1]
queryfile = sys.argv[2]

file_hits = "./" + sys.argv[2].split("_protein")[0] + "_ZeNovo_hits_v1.txt"
file_report = "./" + sys.argv[2].split("_protein")[0] + "_ZeNovo_report_v1.txt"
format = "fasta"
output_file = open(file_hits, 'w')
output_file_2 = open(file_report,'w')
sequences_dict = {}

output_file.write("{}\t{}\n".format("protein_query", "hits"))
for record in SeqIO.parse(databasefile, format):
    sequences_dict[record.description] = str(record.seq)
print("processed database in --- {:.3f} seconds ---".format(time.time() - start_time))

processed_counter = 0
for record in SeqIO.parse(queryfile, format):
    query_seq = str(record.seq)
    count = 0
    output_file.write("{}\t".format(record.description))
    for id, seq in sequences_dict.items():
        if seq == query_seq:
            count += 1
            output_file.write("{}\t".format(id))
    processed_counter += 1
    output_file.write("\n")
    print("processed protein "+str(processed_counter))
    output_file_2.write(record.description+'\t'+str(count)+'\t'+str(len(record.seq))+'\t'+str(record.seq)+'\n')
output_file.close()
output_file_2.close()
print("Done in --- {:.3f} seconds ---".format(time.time() - start_time))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Preliminarily it seems to me that it might make more sense to, instead of storing your dict as <code>{ id : seq }</code>, store it as <code>{ seq : [id_list] }</code>. Since it sounds like there are many repeats of each sequence, this will save time in accessing all ID's of a specific sequence. You can do this when reading in your data by using a <code>defaultdict</code> with the default value as an empty list, and when you read an ID and sequence, you can add it to the dict with <code>sequences_dict[record.seq].append(record.description)</code>.</p>
<p>Let me know if this helps and if I can help with anything else.</p>
</div>
<div class="post-text" itemprop="text">
<p>Following Sam Hollenbach's suggestion, I might make the following (4) changes to your code.</p>
<pre><code>import sys
from Bio import AlignIO
from Bio import SeqIO
from Bio.Seq import Seq
import time
start_time = time.time()
from collections import defaultdict


databasefile = sys.argv[1]
queryfile = sys.argv[2]

file_hits = "./" + sys.argv[2].split("_protein")[0] + "_ZeNovo_hits_v1.txt"
file_report = "./" + sys.argv[2].split("_protein")[0] + "_ZeNovo_report_v1.txt"
_format = "fasta" #(change 1)
output_file = open(file_hits, 'w')
output_file_2 = open(file_report,'w')
sequences_dict = defaultdict(list)

output_file.write("{}\t{}\n".format("protein_query", "hits"))
for record in SeqIO.parse(databasefile, _format):
    sequences_dict[record.seq].append(record.description) #(change 2)
    #sequences_dict[record.description] = str(record.seq)
print("processed database in --- {:.3f} seconds ---".format(time.time() - start_time))

processed_counter = 0
for record in SeqIO.parse(queryfile, _format):
    query_seq = record.seq #(change 3)
    count = 0
    output_file.write("{}\t".format(record.description))
    if query_seq in sequences_dict: #(change 4)
        count = len(sequences_dict[query_seq])
        output_file.write('\t'.join(sequences_dict[query_seq]) + "\n")
    processed_counter += 1
    print("processed protein", processed_counter)
    output_file_2.write(record.description+'\t'+str(count)+
                        '\t'+str(len(record.seq))+'\t'+str(record.seq)+'\n')
output_file.close()
output_file_2.close()
print("Done in --- {:.3f} seconds ---".format(time.time() - start_time))
</code></pre>
<p>Change #1: - change name of format variable to _format (to avoid clashing with the Python term 'format'
And make the changes in your code where that is used.</p>
<p>Change #2: Use the <code>record.seq</code> as the key to the dictionary and append the <code>record.description</code> to the list (as the value)</p>
<p>Change #3: There is no need to cast <code>record.seq</code> to <code>str</code> - it already is a string.</p>
<p>Change #4: These 3 lines will locate any matching record much faster than iterating through the dictionary as in your original code.</p>
<p>I'm not sure how <code>output_file.write("{}\t".format(record.description))</code> should be handled.</p>
<p>Also, can't say that I've found all the changes needed for a complete working program. If you have any questions after trying the suggested changes, let me know.</p>
</div>
<span class="comment-copy">Start with <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">profiling your code</a> and identifying the slowest parts of it.</span>
<span class="comment-copy">Thanks for the suggestion! It helped and time reduced to 4.30 minutes.</span>
<span class="comment-copy">Yes I did all of these changes but I will add change#1 to my current script.</span>
