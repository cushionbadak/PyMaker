<div class="post-text" itemprop="text">
<p>I am trying to use python and scrap the website <a href="https://ipinfo.io/countries/" rel="nofollow noreferrer">https://ipinfo.io/countries/</a> to get the data in the below format. This is nothing but the ASN Data.</p>
<p>The specific information below can be found in(<a href="https://ipinfo.io/AS3320" rel="nofollow noreferrer">https://ipinfo.io/AS3320</a>)</p>
<pre><code>{
  3320: {
     "country": "DE",
     "name": "Deutsche Telekom AG",
     "registry": "ripe",
     "num_ip_addresses": 34756096
 },
</code></pre>
<p>I have written a program that can get all the countries and then map it back to the ASN id  --&gt; <a href="https://ipinfo.io/AS3320" rel="nofollow noreferrer">https://ipinfo.io/AS3320</a> However I am having difficulty to parse all the pages data using Beautiful soup.</p>
<pre><code>import urllib.request
import bs4
import re
import json


url = 'https://ipinfo.io/countries'
SITE = 'https://ipinfo.io'

def url_to_soup(url):
    req = urllib.request.Request(url)
    opener = urllib.request.build_opener()
    html = opener.open(req)
    soup = bs4.BeautifulSoup(html, "html.parser")
    return soup


def find_pages(page):
    pages = []
    for link in page.find_all(href=re.compile('/countries/')):
         pages.append(link.get('href'))
    return pages


def scrape_pages(links):
    mappings = {}

    print("Scraping Pages for ASN Data...")

    for link in links:
        country_page = url_to_soup(SITE + link)
        current_country = link.split('/')[2]
        for row in country_page.find_all('tr'):
            columns = row.find_all('td')
            if len(columns) &gt; 0:
                #print(columns)
                current_asn = re.findall(r'\d+', columns[0].string)[0]
                #print("/AS"+current_asn)
                 #"Recursively I am generating the URL's using above "
                abc = url_to_soup(SITE + '/AS' + current_asn)
                print(abc.find_all('div')) 
                 #THe above code is where I am stuck with 
                 # How to get the country, name, registry, Ip_address
                #name = columns[1].string
                #print(name)
             """routes_v4 = columns[3].string
            routes_v6 = columns[5].string
            mappings[current_asn] = {'Country': current_country,
                                     'Name': name,
                                     'Registry': routes_v4,
                                     'num_ip_addresses': routes_v6}
return mappings"""


main_page = url_to_soup(url)
country_links = find_pages(main_page)
#print(country_links)
asn_mappings = scrape_pages(country_links)
#print(asn_mappings)
</code></pre>
<p>The result is a huge dump of HTML page consisting all the information, however I am not able to filter it as per the needs. </p>

#

<p>Edit 1:</p>

#

<pre><code>import urllib.request
import bs4
import re

url ='https://ipinfo.io/AS7018'
def url_to_soup(url):
    req = urllib.request.Request(url)
    opener = urllib.request.build_opener()
    html = opener.open(req)
    soup = bs4.BeautifulSoup(html, "html.parser")
    return soup


s = str(url_to_soup(url))
asn_code, name = re.search(r'&lt;h3 class="font-semibold m-0 t-xs-24"&gt;(?P&lt;ASN_CODE&gt;AS\d+) (?P&lt;NAME&gt;[\w.\s]+)&lt;/h3&gt;', s).groups()

print(asn_code)


country = re.search(r'.*href="/countries.*"&gt;(?P&lt;COUNTRY&gt;.*)?&lt;/a&gt;',s).group("COUNTRY")
print(country)
registry = re.search(r'Registry.*?pb-md-1"&gt;(?P&lt;REGISTRY&gt;.*?)&lt;/p&gt;',s, re.S).group("REGISTRY").strip()
print(registry)
# flag re.S make the '.' special character match any character at all, including a newline;
ip = re.search(r'IP Addresses.*?pb-md-1"&gt;(?P&lt;IP&gt;.*?)&lt;/p&gt;',s, re.S).group("IP").strip()
print(ip)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h3>there should be 3-level page link in your needs</h3>
<p>1 <code>https://ipinfo.io/countries/</code> for <code>all countries</code>, </p>
<p>2 <code>https://ipinfo.io/countries/us</code> for <code>us all ASN</code>, </p>
<p>and 3 <code>https://ipinfo.io/AS26611</code> for <code>detail ASN data</code>.</p>
<p>It's seemed that step 3 missed in your codes, and if you get the page resource of detail ASN data page, you can use the regex below as reference ï¼š</p>
<pre class="lang-py prettyprint-override"><code>
s = """ your ASN detail data page """

asn_code, name = re.search(r'&lt;h3 class="font-semibold m-0 t-xs-24"&gt;(?P&lt;ASN_CODE&gt;AS\d+) (?P&lt;NAME&gt;.*?)&lt;/h3&gt;',s).groups()


country = re.search(r'.*href="/countries.*"&gt;(?P&lt;COUNTRY&gt;.*)?&lt;/a&gt;',s).group("COUNTRY")

registry = re.search(r'Registry.*?pb-md-1"&gt;(?P&lt;REGISTRY&gt;.*?)&lt;/p&gt;',s, re.S).group("REGISTRY").strip()

# flag re.S make the '.' special character match any character at all, including a newline;

ip = re.search(r'IP Addresses.*?pb-md-1"&gt;(?P&lt;IP&gt;.*?)&lt;/p&gt;',s, re.S).group("IP").strip()

</code></pre>
<p><a href="https://docs.python.org/3/library/re.html?highlight=regex#re.S" rel="nofollow noreferrer">see more regex flag, re.S</a></p>
<p><a href="https://docs.python.org/3/library/re.html?highlight=regex#re.search" rel="nofollow noreferrer">more about re.search</a></p>
<p><a href="https://docs.python.org/3/library/re.html?highlight=regex#regular-expression-syntax" rel="nofollow noreferrer">more about regex syntax</a></p>
<p><br/></p>
<h3>Besides, I highly recommend <a href="http://html.python-requests.org/" rel="nofollow noreferrer"><code>requests-html</code></a> module both for efficiently request the page and parse the html (CSS selector and Xpath selector which are more efficient than regex).</h3>
<p>hope it useful</p>
</div>
<span class="comment-copy">I need help on regex to extract the Country, Name, registry and num_ip_address info. I am new to beautiful soup and not able to get the correct code.</span>
<span class="comment-copy">Hi Jia, Thanks for contributing and helping. However I am getting error on my system for the line asn_code, name = re.search(r'&lt;h3 class="font-semibold m-0 t-xs-24"&gt;(?P&lt;ASN_CODE&gt;AS\d+) (?P&lt;NAME&gt;[\w.\s]+)&lt;/h3&gt;', s).group()</span>
<span class="comment-copy">The error is Group is not available for None Type. I know that the regex might not be matching at some cases but not sure how to get rid of that</span>
<span class="comment-copy">make sure that you get the page resource from detail page like <code>https://ipinfo.io/AS13489</code></span>
<span class="comment-copy">and can you show me the page link which make error</span>
<span class="comment-copy">okay, I am adding my code in the edit section.</span>
