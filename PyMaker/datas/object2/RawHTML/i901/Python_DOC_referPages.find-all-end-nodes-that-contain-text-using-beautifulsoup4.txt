<div class="post-text" itemprop="text">
<p>I'm new to Python and BeautifulSoup4 </p>
<p>I'm trying to extract (only) the textual content of all tags that are either 'div','p','li' and only from the immediate node, not the child nodes - hence the two options <code>text=True, recursive=False</code></p>
<p>These are my attempts:</p>
<pre><code>content = soup.find_all("b", "div", "p", text=True, recursive=False)
</code></pre>
<p>and </p>
<pre><code>tags = ["div", "p", "li"]
content = soup.find_all(tags, text=True, recursive=False)
</code></pre>
<p>Both of these give me no output, do you know what I'm doing wrong?</p>
<p>EDIT - adding more code and a sample doc that I'm testing with, <code>print(content)</code> is empty</p>
<pre><code>import requests
from bs4 import BeautifulSoup

url = "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#a-list"
response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})

soup = BeautifulSoup(response.text, "html.parser")

tags = ["div", "p", "li"]
content = soup.find_all(tags, text=True, recursive=False)

print(content)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>From your Question and comments on the previous answer I think you are trying to find </p>
<blockquote>
<ul>
<li><p>the innermost tags</p></li>
<li><p>that are either 'p' or 'li' or 'div'</p></li>
<li><p>Should contain some text</p></li>
</ul>
</blockquote>
<pre><code>import requests
from bs4 import BeautifulSoup
from bs4 import NavigableString

url = "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#a-list"
response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})

soup = BeautifulSoup(response.text, "html.parser")
def end_node(tag):
    if tag.name not in ["div", "p", "li"]:
        return False
    if isinstance(tag,NavigableString): #if str return
        return False
    if not tag.text: #if no text return false
        return False
    elif len(tag.find_all(text=False)) &gt; 0: #no other tags inside other than text
        return False
    return True #if valid it reaches here
content = soup.find_all(end_node)
print(content) #all end nodes matching our criteria
</code></pre>
<p>Sample of the output</p>
<pre><code>[&lt;p&gt;These instructions illustrate all major features of Beautiful Soup 4,
with examples. I show you what the library is good for, how it works,
how to use it, how to make it do what you want, and what to do when it
violates your expectations.&lt;/p&gt;, &lt;p&gt;The examples in this documentation should work the same way in Python
2.7 and Python 3.2.&lt;/p&gt;, &lt;p&gt;This documentation has been translated into other languages by
Beautiful Soup users:&lt;/p&gt;, &lt;p&gt;Here are some simple ways to navigate that data structure:&lt;/p&gt;, &lt;p&gt;One common task is extracting all the URLs found within a page’s &amp;lt;a&amp;gt; tags:&lt;/p&gt;, &lt;p&gt;Another common task is extracting all the text from a page:&lt;/p&gt;, &lt;p&gt;Does this look like what you need? If so, read on.&lt;/p&gt;, &lt;p&gt;If you’re using a recent version of Debian or Ubuntu Linux, you can
install Beautiful Soup with the system package manager:&lt;/p&gt;, &lt;p&gt;I use Python 2.7 and Python 3.2 to develop Beautiful Soup, but it
should work with other recent versions.&lt;/p&gt;, &lt;p&gt;Beautiful Soup is packaged as Python 2 code. When you install it for
use with Python 3, it’s automatically converted to Python 3 code. If
you don’t install the package, the code won’t be converted. There have
also been reports on Windows machines of the wrong version being
installed.&lt;/p&gt;, &lt;p&gt;In both cases, your best bet is to completely remove the Beautiful
Soup installation from your system (including any directory created
when you unzipped the tarball) and try the installation again.&lt;/p&gt;, &lt;p&gt;This table summarizes the advantages and disadvantages of each parser library:&lt;/p&gt;, &lt;li&gt;Batteries included&lt;/li&gt;, &lt;li&gt;Decent speed&lt;/li&gt;, 
....
]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can iterate over your tags, then apply <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#navigating-using-tag-names" rel="nofollow noreferrer"><code>soup.find_all()</code></a> on each tag:</p>
<pre><code>import requests
from bs4 import BeautifulSoup

url = "https://www.crummy.com/software/BeautifulSoup/bs4/doc/#a-list"
response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})

soup = BeautifulSoup(response.text, features="lxml")

tags = ["div", "p", "li"]

for tag in tags:
    content = soup.find_all(tag, recursive=True)

    for x in content:
        print(x)
</code></pre>
<p>Which prints out each <code>&lt;div&gt;</code>, <code>&lt;p&gt;</code> and <code>&lt;li&gt;</code> tag on the HTML page. </p>
<p>You can also set <code>recursive=True</code> to traverse the document recursively and extract all nested child tags. If you don't want these nested children, keep <code>recursive=False</code>.</p>
<p>You can also use <a href="https://pypi.org/project/lxml/" rel="nofollow noreferrer"><code>lxml</code></a> instead, which is faster than <a href="https://docs.python.org/3/library/html.parser.html" rel="nofollow noreferrer"><code>html.parser</code></a>. You can see the differences in this <a href="https://stackoverflow.com/questions/45494505/python-difference-between-lxml-and-html-parser-and-html5lib-with-beautifu/45494776#45494776">answer</a>. This might be beneficial if the HTML document is very big. </p>
</div>
<span class="comment-copy">What does your HTML document look like?</span>
<span class="comment-copy">I plan to use it on many differnt HTML docs, I've done similar things with JSoup in Java ... but it's a different way of thinking - will add more code now</span>
<span class="comment-copy">You should set <code>recursive=True</code>(since there is no immediate node), or use methods such as <code>find_all_previous/find_all_next</code>, and it is better to use <code>lxml</code> instead of <code>html.parser</code>.</span>
<span class="comment-copy">thanks William recursive=False was intentional, but I believe you're saying that without a specific node to traverse recursive=False won't find anything</span>
<span class="comment-copy">No I hadn't, I assumed there was a shorter way. But if there isn't then this works perfectly well - thanks!</span>
<span class="comment-copy">thanks will do, I'll use lxml ... for now I'm still getting an empty <code>contents</code> list when trying just "div" tags, but it's ok - I have a better idea, I'll try an tease it out</span>
<span class="comment-copy">however recursive=False was intentional but I'll look into it, I may have misunderstood what it's for</span>
<span class="comment-copy">@Ankur I've edited my answer.</span>
<span class="comment-copy">Many thanks @RoadRunner, the last issue for me is to get the end nodes (rather than all nodes) - is that possible (that's why I used recursive=False) if not that's ok - I can do the traversal to get the end nodes</span>
