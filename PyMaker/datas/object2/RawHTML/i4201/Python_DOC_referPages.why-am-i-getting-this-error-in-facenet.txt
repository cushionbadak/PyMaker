<div class="post-text" itemprop="text">
<p>I am trying to run facematch(facenet) on my Virtual Machine (Google Cloud Platform). At first, things were running smoothly and it was embedding the points of the faces, but then out of the blue, my code stopped working.</p>
<p>The first code, you can see the imports are there</p>
<p><a href="https://i.stack.imgur.com/HNgoY.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/HNgoY.png"/></a></p>
<p>For the second code, you can see the imports are there.</p>
<p><a href="https://i.stack.imgur.com/OpaLo.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/OpaLo.png"/></a></p>
<p>This is the ls commands, so you can see that all the directories/modules are there and see the errors I'm getting</p>
<p><a href="https://i.stack.imgur.com/HKKsB.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/HKKsB.png"/></a></p>
<p>Anyone can share some insight on what I'm doing wrong?</p>
<p>Face_match_demo code:</p>
<pre><code>import tensorflow as tf
import numpy as np
import facenet
from align import detect_face
import cv2
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--img1", type = str, required=True)
parser.add_argument("--img2", type = str, required=True)
args = parser.parse_args()
# some constants kept as default from facenet
minsize = 20
threshold = [0.6, 0.7, 0.7]
factor = 0.709
margin = 44
input_image_size = 160
sess = tf.Session()
# read pnet, rnet, onet models from align directory and files are det1.npy, det2.npy, det3.npy
pnet, rnet, onet = detect_face.create_mtcnn(sess, 'align')
# read 20170512-110547 model file downloaded from https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk
facenet.load_model("20170512-110547/20170512-110547.pb")
# Get input and output tensors
images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
embedding_size = embeddings.get_shape()[1]
def getFace(img):
    faces = []
    img_size = np.asarray(img.shape)[0:2]
    bounding_boxes, _ = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)
    if not len(bounding_boxes) == 0:
        for face in bounding_boxes:
            if face[4] &gt; 0.50:
                det = np.squeeze(face[0:4])
                bb = np.zeros(4, dtype=np.int32)
                bb[0] = np.maximum(det[0] - margin / 2, 0)
                bb[1] = np.maximum(det[1] - margin / 2, 0)
                bb[2] = np.minimum(det[2] + margin / 2, img_size[1])
                bb[3] = np.minimum(det[3] + margin / 2, img_size[0])
                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]
                resized = cv2.resize(cropped, (input_image_size,input_image_size),interpolation=cv2.INTER_CUBIC)
                prewhitened = facenet.prewhiten(resized)
                faces.append({'face':resized,'rect':[bb[0],bb[1],bb[2],bb[3]],'embedding':getEmbedding(prewhitened)})
    return faces
def getEmbedding(resized):
    reshaped = resized.reshape(-1,input_image_size,input_image_size,3)
    feed_dict = {images_placeholder: reshaped, phase_train_placeholder: False}
    embedding = sess.run(embeddings, feed_dict=feed_dict)
    return embedding
def compare2face(img1,img2):
    face1 = getFace(img1)
    face2 = getFace(img2)
    if face1 and face2:
        # calculate Euclidean distance
        dist = np.sqrt(np.sum(np.square(np.subtract(face1[0]['embedding'], face2[0]['embedding']))))
        return dist
    return -1
img1 = cv2.imread(args.img1)
img2 = cv2.imread(args.img2)
distance = compare2face(img1, img2)
threshold = 1.10    # set yourself to meet your requirement
print("distance = "+str(distance))
</code></pre>
<p>face_embeddings_demo code:</p>
<pre><code>import tensorflow as tf
from align import detect_face
import facenet
import cv2
import imutils
import numpy as np
import argparse
parser = argparse.ArgumentParser()
parser.add_argument("--img", type = str, required=True)
args = parser.parse_args()
# some constants kept as default from facenet
minsize = 20
threshold = [0.6, 0.7, 0.7]
factor = 0.709
margin = 44
input_image_size = 160
sess = tf.Session()
# read pnet, rnet, onet models from align directory and files are det1.npy, det2.npy, det3.npy
pnet, rnet, onet = detect_face.create_mtcnn(sess, 'align')
# read 20170512-110547 model file downloaded from https://drive.google.com/file/d/0B5MzpY9kBtDVZ2RpVDYwWmxoSUk
facenet.load_model("20170512-110547/20170512-110547.pb")
# Get input and output tensors
images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")
embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")
phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")
embedding_size = embeddings.get_shape()[1]
def getFace(img):
    faces = []
    img_size = np.asarray(img.shape)[0:2]
    bounding_boxes, points = detect_face.detect_face(img, minsize, pnet, rnet, onet, threshold, factor)
    if not len(bounding_boxes) == 0:
        for face in bounding_boxes:
            if face[4] &gt; 0.50:
                det = np.squeeze(face[0:4])
                bb = np.zeros(4, dtype=np.int32)
                bb[0] = np.maximum(det[0] - margin / 2, 0)
                bb[1] = np.maximum(det[1] - margin / 2, 0)
                bb[2] = np.minimum(det[2] + margin / 2, img_size[1])
                bb[3] = np.minimum(det[3] + margin / 2, img_size[0])
                cropped = img[bb[1]:bb[3], bb[0]:bb[2], :]
                resized = cv2.resize(cropped, (input_image_size,input_image_size),interpolation=cv2.INTER_CUBIC)
                prewhitened = facenet.prewhiten(resized)
                faces.append({'face':resized,'rect':[bb[0],bb[1],bb[2],bb[3]],'embedding':getEmbedding(prewhitened)})
    return faces
def getEmbedding(resized):
    reshaped = resized.reshape(-1,input_image_size,input_image_size,3)
    feed_dict = {images_placeholder: reshaped, phase_train_placeholder: False}
    # print(feed_dict)
    embedding = sess.run(embeddings, feed_dict=feed_dict)
    return embedding
img = cv2.imread(args.img)
img = imutils.resize(img,width=1000)
faces = getFace(img)
for face in faces:
    print("Embeddings = "+str(face['embedding']))
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You <a href="https://docs.python.org/3/tutorial/modules.html#packages" rel="nofollow noreferrer">have to have the <code>__init__.py</code> in the package directory</a> to be recognized as a package. It can be an empty file, but it has to be present. You don't have this in the <code>align</code> directory.</p>
<p>From the <a href="https://docs.python.org/3/tutorial/modules.html#packages" rel="nofollow noreferrer">documentation</a>:</p>
<blockquote>
<p>The __init__.py files are required to make Python treat the directories as containing packages</p>
</blockquote>
<hr/>
<p>From your comment, the error</p>
<blockquote>
<p>usage: face_match_demo.py [-h] --img1 IMG1 --img2 IMG2 face_match_demo.py: error: ambiguous option: --img=images/faces.jpg could match --img2, --img1</p>
</blockquote>
<p>means that <code>face_match_demo.py</code> is actually a utility to <strong><em>match two images</em></strong>, to say whether they contain the same face or not. So you have to provide two images to it, and it will tell if the face is the same. And you need to use the --img1 and --img2 options to do that like this:</p>
<pre><code>python face_match_demo.py --img1 images/faces.jpg --img2 [[another face image]]
</code></pre>
</div>
<span class="comment-copy"><a href="http://idownvotedbecau.se/imageofcode" rel="nofollow noreferrer">idownvotedbecau.se/imageofcode</a></span>
<span class="comment-copy">When you only post images, your post looks like spam, and others need to be able to copy and paste your code to help you.  Please post your code here, so the community can help you.  Also, be sure to use 4 space indentation for code, so it shows up as a code block.  Happy coding!</span>
<span class="comment-copy">Removed links, and added the images.</span>
<span class="comment-copy">So just create an empty file named <b>init</b>.py in the align directory?</span>
<span class="comment-copy">Yes, but with two underscores before and after it, so <b><i>__init__.py</i></b></span>
<span class="comment-copy">Oh I see the underscores were turned into bold formatting in the quote, let me fix that.</span>
<span class="comment-copy">Thank you so much, it worked for the embedding code but for the face match demo I get this error: "usage: face_match_demo.py [-h] --img1 IMG1 --img2 IMG2 face_match_demo.py: error: ambiguous option: --img=images/faces.jpg could match --img2, --img1"</span>
<span class="comment-copy">Updated answer.</span>
