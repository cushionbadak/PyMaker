<div class="post-text" itemprop="text">
<p>I am using scipy to generate a sparse finite difference matrix, constructing it initially from block matrices and then editing the diagonal to account for boundary conditions. The resulting sparse matrix is of the BSR type. I have found that if I convert the matrix to a dense matrix and then back to a sparse matrix using the <code>scipy.sparse.BSR_matrix</code> function, I am left with a sparser matrix than before. Here is the code I use to generate the matrix:</p>
<pre><code>size = (4,4)

xDiff = np.zeros((size[0]+1,size[0]))
ix,jx = np.indices(xDiff.shape)
xDiff[ix==jx] = 1
xDiff[ix==jx+1] = -1

yDiff = np.zeros((size[1]+1,size[1]))
iy,jy = np.indices(yDiff.shape)
yDiff[iy==jy] = 1
yDiff[iy==jy+1] = -1

Ax = sp.sparse.dia_matrix(-np.matmul(np.transpose(xDiff),xDiff))
Ay = sp.sparse.dia_matrix(-np.matmul(np.transpose(yDiff),yDiff))

lap = sp.sparse.kron(sp.sparse.eye(size[1]),Ax) + sp.sparse.kron(Ay,sp.sparse.eye(size[0]))

#set up boundary conditions
BC_diag = np.array([2]+[1]*(size[0]-2)+[2]+([1]+[0]*(size[0]-2)+[1])*(size[1]-2)+[2]+[1]*(size[0]-2)+[2])

lap += sp.sparse.diags(BC_diag)
</code></pre>
<p>If I check the sparsity of this matrix I see the following:</p>
<pre><code>lap
&lt;16x16 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
with 160 stored elements (blocksize = 4x4) in Block Sparse Row format&gt;
</code></pre>
<p>However, if I convert it to a dense matrix and then back to the same sparse format I see a much sparser matrix:</p>
<pre><code>sp.sparse.bsr_matrix(lap.todense())
&lt;16x16 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
with 64 stored elements (blocksize = 1x1) in Block Sparse Row format&gt;
</code></pre>
<p>I suspect that the reason this is happening is because I constructed the matrix using the sparse.kron function but my question is if there is a way to arrive at the smaller sparse matrix without converting to dense first, for example if I end up wanting to simulate a very large domain.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>BSR</code> stores the data in dense blocks:</p>
<pre><code>In [167]: lap.data.shape                                                        
Out[167]: (10, 4, 4)
</code></pre>
<p>In this case those blocks have quite a few zeros.</p>
<pre><code>In [168]: lap1 = lap.tocsr() 
In [170]: lap1                                                                  
Out[170]: 
&lt;16x16 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 160 stored elements in Compressed Sparse Row format&gt;
In [171]: lap1.data                                                             
Out[171]: 
array([-2.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  1., -3.,  1.,  0.,  0.,
        1.,  0.,  0.,  0.,  1., -3.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,
        1., -2.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0., -3.,  1.,  0.,
        0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1., -4.,  1.,  0., 
        ...
        0.,  0.,  1., -2.])
</code></pre>
<p>In place cleanup:</p>
<pre><code>In [172]: lap1.eliminate_zeros()                                                
In [173]: lap1                                                                  
Out[173]: 
&lt;16x16 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 64 stored elements in Compressed Sparse Row format&gt;
</code></pre>
<p>If I specify the <code>csr</code> format when using <code>kron</code>:</p>
<pre><code>In [181]: lap2 = sparse.kron(np.eye(size[1]),Ax,format='csr') + sparse.kron(Ay,n
     ...: p.eye(size[0]), format='csr')                                         
In [182]: lap2                                                                  
Out[182]: 
&lt;16x16 sparse matrix of type '&lt;class 'numpy.float64'&gt;'
    with 64 stored elements in Compressed Sparse Row format&gt;
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>[I have been informed that my answer is incorrect. The reason, if I understand, is that Scipy is not using Lapack for creating matrices but is using its own code for this purpose. Interesting. The information though unexpected has the ring of authority. I shall defer to it!</p>
<p>[I will leave the answer posted for reference, but no longer assert that the answer were correct.] </p>
<p>Generally speaking, when it comes to complicated data structures like sparse matrices, you have two cases:</p>
<ol>
<li>the constructor knows the structure's full contents in advance; or</li>
<li>the structure is designed to be built up gradually so that the structure's full contents are known only after the structure is complete.</li>
</ol>
<p>The classic case of the complicated data structure is the case of the binary tree. You can make a binary tree more efficient by copying it after it is complete. Otherwise, the standard red-black implementation of the tree leaves some search paths as long as twice as long as others—which is usually okay but is not optimal.</p>
<p>Now, you probably knew all that, but I mention it for a reason. Scipy depends on Lapack. Lapack brings several different storage schemes. Two of these are the</p>
<ul>
<li>general sparse and</li>
<li>banded</li>
</ul>
<p>schemes. It would appear that Scipy begins by storing your matrix as sparse, where the indices of each nonzero element are explicitly stored; but that, on copy, Scipy notices that the banded representation is the more appropriate—for your matrix is, after all, banded.</p>
</div>
<span class="comment-copy">Note the change in blocksize.  In the second case the size is 1x1.  I wonder if <code>lap.tocsr()</code> would do the same thing.  I haven't worked the BSR much, but I think it stores the blocks as dense arrays.</span>
<span class="comment-copy">Aha, I have a downvote. Is my answer incorrect? I should like to know. Would be happy to delete the answer if it is wrong but the answer is right as far as I know.</span>
<span class="comment-copy"><code>scipy.sparse</code> isn't using Lapack for creating matrices.  It has its own code, a mix of Python and <code>cython</code>.</span>
<span class="comment-copy">@hpaulj Fair enough. Answer updated, thanks.</span>
