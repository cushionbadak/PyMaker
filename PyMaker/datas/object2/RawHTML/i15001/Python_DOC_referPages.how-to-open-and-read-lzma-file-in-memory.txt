<div class="post-text" itemprop="text">
<p>I have a giant file, let's call it <strong>one-csv-file.xz</strong>. It is an XZ-compressed CSV file.</p>
<p>How can I open and parse through the file without first decompressing it to disk? What if the file is, for example, 100 GB? Python cannot read all of that into memory at once, of course. Will it page or run out of memory?</p>
</div>
<div class="post-text" itemprop="text">
<p>You can iterate through an <code>LZMAFile</code> object</p>
<pre><code>import lzma  # python 3, try lzmaffi in python 2
with open('one-csv-file.xz') as compressed:
    with lzma.LZMAFile(compressed) as uncompressed:
        for line in uncompressed:
            do_stuff_with(line)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can decompress incrementally.  See <a href="https://docs.python.org/3/library/lzma.html" rel="nofollow">Compression using the LZMA Algorithm</a>.  You create an <code>LZMADecompressor</code> object, and then use the <code>decompress</code> method with successive chunks of the compressed data to get successive chunks of the uncompressed data.</p>
</div>
<span class="comment-copy">Cf. <a href="https://stackoverflow.com/questions/49348091/">here</a> to cope with a text encoding other than ASCII.</span>
<span class="comment-copy">Yea what actually worked for me too was the link provided by @user1016274</span>
