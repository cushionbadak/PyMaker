<div class="post-text" itemprop="text">
<p>I want to build a function that will return True if any two items in a list are the same. </p>
<p>For example, <code>[1,7,3,7,4]</code> should return <code>True</code> and <code>["one","ONE","One"]</code> should return <code>False</code>.</p>
<p>I need help with which parts of python look for duplicates.</p>
</div>
<div class="post-text" itemprop="text">
<p>Loop over the values and use a <code>set</code> to track what you have already seen. As soon as you see a value <em>again</em>, return <code>True</code>:</p>
<pre><code>def has_duplicates(lst):
    seen = set()
    for elem in lst:
        if elem in seen:
            return True
        seen.add(elem)
    return False
</code></pre>
<p>This is very efficient in that it short-circuits; it won't loop over the whole list if a duplicate has been detected early on.</p>
</div>
<div class="post-text" itemprop="text">
<p>Martijn's <a href="https://stackoverflow.com/a/28678384/4099593">answer</a> is the best, but with a few exceptions, this is worth a try.</p>
<pre><code>&gt;&gt;&gt; chk = lambda x: len(l) != len(set(l)) # check the length after removing dupes. 
&gt;&gt;&gt; l = [1,7,3,7,4] 
&gt;&gt;&gt; chk(l)
True
&gt;&gt;&gt; l = ["one","ONE","One"]
&gt;&gt;&gt; chk(l)
False
</code></pre>
<p><em>Note</em> - As <a href="https://stackoverflow.com/questions/28678337/repetition-inside-of-lists/28678422?noredirect=1#comment45649931_28678422">Martijn</a> mentions in a comment, this is a slower process. </p>
</div>
<div class="post-text" itemprop="text">
<p>Using a <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow">collections.Counter</a> dict:</p>
<pre><code>from collections import Counter
def has_dupes(l):
    # if most repeated key count is &gt; 1 we have at least one dupe
    return Counter(l).most_common(1)[0][1] &gt; 1
</code></pre>
<p>Or use <code>any</code>:</p>
<pre><code>def has_dupes(l):
    return any(v &gt; 1 for v in Counter(l).values()) 
</code></pre>
</div>
<span class="comment-copy">Related: <a href="http://stackoverflow.com/q/11236006">Identify duplicate values in a list in Python</a></span>
<span class="comment-copy">Wouldn't a list be faster? (<code>seen = []</code>) I did a quick <code>timeit</code> (<code>timeit.timeit("s.add(5)", "s = set()")</code> was <code>0.100...</code> and <code>timeit.timeit("s.append(5)", "s = []")</code> was <code>0.0911</code>)</span>
<span class="comment-copy">Why not just do: <code>if len(set(lst)) != len(lst)</code></span>
<span class="comment-copy">@RPGillespie Because that has to iterate over the whole list.</span>
<span class="comment-copy">@Reticality because <code>set(lst)</code> iterates over the whole list to produce the set. No, using a list for <code>seen</code> is going to be <i>slower</i>. Don't compare appending speed of sets and lists here, it is <i>membership testing</i> that'll kill you, as it is O(N) for lists vs. O(1) for sets. The larger the number of unique values the slower testing against the list is going to be.</span>
<span class="comment-copy">This requires iteration over the <i>whole</i> list. Try this out with <code>[1] + list(range(1000000))</code> for example.</span>
<span class="comment-copy">@MartijnPieters Yep, It is a very slow way to do!. :) (But hopefully not a <i>wrong</i> way)</span>
<span class="comment-copy">This is slower still than using <code>len(set(l))</code> as it requires a O(N) loop over all the values, followed by creating a heap to find the most common element, again O(N). Asymptotically the same as <code>len(set(l))</code> but with a higher fixed cost per iteration.</span>
<span class="comment-copy">@MartijnPieters, yes, but a linear solution, another example of how to do what the OP wants and an introduction to a Counter dict which is a pretty useful tool. If the question was what is the optimal way because I have a huge amount of data then that would be different but it's not.</span>
<span class="comment-copy">I'm merely commenting on the performance aspects of the solution, because I do think that matters. Otherwise this whole question would just be a dupe of <a href="http://stackoverflow.com/q/11236006">Identify duplicate values in a list in Python</a></span>
<span class="comment-copy">@MartijnPieters, fair enough but  I don't think in this case performance is a concern at all.  <code>has_dupes([1] + list(range(1000000)))</code> takes <code>249ms</code> `</span>
<span class="comment-copy">If it is no concern we may as well dupe this. But there is a <i>generic</i> use here for future visitors. Some of those may well be concerned with performance.</span>
