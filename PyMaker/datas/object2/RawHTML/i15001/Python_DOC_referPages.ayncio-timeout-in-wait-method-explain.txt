<div class="post-text" itemprop="text">
<pre><code>&gt;&gt;&gt; import asyncio
&gt;&gt;&gt; help(asyncio.wait)
</code></pre>
<p>..</p>
<pre><code>Help on function wait in module asyncio.tasks:

wait(fs, *, loop=None, timeout=None, return_when='ALL_COMPLETED')
    Wait for the Futures and coroutines given by fs to complete.

    Coroutines will be wrapped in Tasks.

    Returns two sets of Future: (done, pending).

    Usage:

        done, pending = yield from asyncio.wait(fs)

    Note: This does not raise TimeoutError! Futures that aren't done
    when the timeout occurs are returned in the second set.
(END)
</code></pre>
<p>I dont quite understand last Note in this help (what is second set? is it pending/reprocessing set? how do I execute pending tasks and combine the results of both done and pending and then save in DB)</p>
<p>My problem: 
I'm using asyncio with aiohttp, have millions of urls , few of them might raise timeout error. I want to send them in a queue for reprocessing or it should take care by eventpool.</p>
<pre><code>import asyncio
import aiohttp
sem = asyncio.Semaphore(10)

def process_data(url):
    with (yield from sem):
          response = yield from aiohttp.request('GET', url)
          print(response)

loop = asyncio.get_event_loop()
c = asyncio.wait([process_data(url) for url in url_list], timeout=10)
loop.run_until_complete(c)
</code></pre>
<p>PS: I'm not using <code>wait_for</code> method.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here are the two sets from the help:</p>
<pre><code>Returns two sets of Future: (done, pending).
</code></pre>
<p>The second set is the <code>pending</code> set, jobs that haven't finished within the timeout. It will return a tuple with two lists of futures, one of those that are done, and one that are still pending.</p>
<p>instead of:</p>
<pre><code>c = asyncio.wait([process_data(url) for url in url_list], timeout=10)
loop.run_until_complete(c)
</code></pre>
<p>you should probably:</p>
<pre><code>def dostuff():
    done, pending = yield from asyncio.wait([process_data(url) for url in url_list], timeout=10)

    # do something with pending

loop.run_until_complete(dostuff())
</code></pre>
<p>Here is more information: </p>
<p><a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.wait" rel="nofollow">https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.wait</a></p>
</div>
<span class="comment-copy">I want to run pending tasks as well(asynchronously). how can I pass again in event_loop)?</span>
<span class="comment-copy">@michael The pending tasks continue to execute after the <code>wait</code> timeout expires. They're not cancelled or aborted or anything like that. So there's no operation required to re-schedule them - they'll keep running in the background as long as you don't stop the event loop.</span>
