<div class="post-text" itemprop="text">
<p>I have an input_file.fa file like this (<a href="https://en.wikipedia.org/wiki/FASTA_format" rel="nofollow noreferrer">FASTA</a> format):</p>
<pre><code>&gt; header1 description
data data
data
&gt;header2 description
more data
data
data
</code></pre>
<p>I want to read in the file one chunk at a time, so that each chunk contains one header and the corresponding  data, e.g. block 1:</p>
<pre><code>&gt; header1 description
data data
data
</code></pre>
<p>Of course I could just read in the file like this and split:</p>
<pre><code>with open("1.fa") as f:
    for block in f.read().split("&gt;"):
        pass
</code></pre>
<p>But <em>I want to avoid the reading the whole file into memory</em>, because the files are often large.</p>
<p>I can read in the file line by line of course:</p>
<pre><code>with open("input_file.fa") as f:
    for line in f:
        pass
</code></pre>
<p>But ideally what I want is something like this:</p>
<pre><code>with open("input_file.fa", newline="&gt;") as f:
    for block in f:
        pass
</code></pre>
<p>But I get an error:</p>
<blockquote>
<p>ValueError: illegal newline value: &gt;</p>
</blockquote>
<p>I've also tried using the <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer">csv module</a>, but with no success.</p>
<p>I did find <a href="https://stackoverflow.com/questions/16260061/reading-a-file-with-a-specified-delimiter-for-newline">this post</a> from 3 years ago, which provides a generator based solution to this issue, but it doesn't seem that compact, is this really the only/best solution? It would be neat if it is possible to create the generator with a single line rather than a separate function, something like this pseudocode:</p>
<pre><code>with open("input_file.fa") as f:
    blocks = magic_generator_split_by_&gt;
    for block in blocks:
        pass
</code></pre>
<p>If this is impossible, then I guess you could consider my question a duplicate of the other post, but if that is so, I hope people can explain to me why the other solution is the only one. Many thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>A general solution here will be write a generator function for this that yields one group at a time. This was you will be storing only one group at a time in memory.</p>
<pre><code>def get_groups(seq, group_by):
    data = []
    for line in seq:
        # Here the `startswith()` logic can be replaced with other
        # condition(s) depending on the requirement.
        if line.startswith(group_by):
            if data:
                yield data
                data = []
        data.append(line)

    if data:
        yield data

with open('input.txt') as f:
    for i, group in enumerate(get_groups(f, "&gt;"), start=1):
        print ("Group #{}".format(i))
        print ("".join(group))
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>Group #1
&gt; header1 description
data data
data

Group #2
&gt;header2 description
more data
data
data
</code></pre>
<hr/>
<p>For FASTA formats in general I would recommend using <a href="http://biopython.org/wiki/Biopython" rel="nofollow">Biopython</a> package.</p>
</div>
<div class="post-text" itemprop="text">
<p>One approach that I like is to use <a href="https://docs.python.org/3.5/library/itertools.html#itertools.groupby" rel="nofollow"><code>itertools.groupby</code></a> together with a simple <code>key</code> fuction:</p>
<pre><code>from itertools import groupby


def make_grouper():
    counter = 0
    def key(line):
        nonlocal counter
        if line.startswith('&gt;'):
            counter += 1
        return counter
    return key
</code></pre>
<p>Use it as:</p>
<pre><code>with open('filename') as f:
    for k, group in groupby(f, key=make_grouper()):
        fasta_section = ''.join(group)   # or list(group)
</code></pre>
<p>You need the <code>join</code> only if you have to handle the contents of a whole section as a single string. If you are only interested in reading the lines one by one you can simply do:</p>
<pre><code>with open('filename') as f:
    for k, group in groupby(f, key=make_grouper()):
        # parse &gt;header description
        header, description = next(group)[1:].split(maxsplit=1)
        for line in group:
            # handle the contents of the section line by line
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>def read_blocks(file):
    block = ''
    for line in file:
        if line.startswith('&gt;') and len(block)&gt;0:
            yield block
            block = ''
        block += line
    yield block


with open('input_file.fa') as f:
    for block in read_blocks(f):
        print(block)
</code></pre>
<p>This will read in the file line by line and you will get back the blocks with the yield statement. This is lazy so you don't have to worry about large memory footprint.</p>
</div>
<span class="comment-copy">Have you tried using <a href="http://biopython.org/wiki/Biopython" rel="nofollow noreferrer">biopython.org/wiki/Biopython</a>?</span>
<span class="comment-copy">@AshwiniChaudhary Thank you, good idea, that should help for this case, but ideally I'd also like a generic solution that would work beyond biological sequence data formats.</span>
<span class="comment-copy">Although this still isn't quite the idea I had in mind, I think it's a good practical solution to the issue (better than the one in the other post), so I'm going to mark as solved, thanks for your help.</span>
<span class="comment-copy">You can change <code>data = [line]</code> with <code>data = []</code> and move <code>data.append(line)</code> outside the outer <code>if</code>, removing the <code>else</code>s thus avoiding the double call.</span>
<span class="comment-copy">Thank you for your thoughtful response. I will have to look more carefully to fully understand the code. Do you think there is a particular advantage of this approach over the other ones suggested?</span>
<span class="comment-copy">@Chris_Rands This approach is basically equivalent to Ashwini answer, but uses <code>itertools</code> to avoid manually grouping the lines. It's a matter of taste.</span>
