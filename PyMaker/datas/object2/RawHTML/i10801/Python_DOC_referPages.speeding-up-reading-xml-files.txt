<div class="post-text" itemprop="text">
<p>I have a document of patents that is a concatenated string of xml files in one text document.  I'm looking to split it up into separate documents each a single xml file.  My code works but I need to speed it up.  My code is like this: </p>
<pre><code>import time

count = 0

filestr = ''

line = 'x'

start_time = time.time()
with open('C:/Users/RNCZF01/Documents/Cameron-Fen/Economics-Projects/Patent-project/similarity/Patents/ipg121225.xml') as txtfile:
while line:        
    line = txtfile.readline()
    if '&lt;?xml version="1.0" encoding="UTF-8"?&gt;' in line:
        filestr = str(count) + '.xml'
        count += 1

    with open('C:/Users/RNCZF01/Documents/Cameron-Fen/Economics-Projects/Patent-project/similarity/Patents/2012-12-25/' + filestr, 'ab') as textfile:
        textfile.write(line)
        textfile.write('\n')

print("--- %s seconds ---" % (time.time() - start_time))
</code></pre>
<p>The one optimization I can think of to speed it up is the if statement.  It checks if the line contains the xml header: <code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</code>.  It probably would be significantly faster if I could check that the line was <code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</code> instead of just containing it.  But when I write  <code>if line == '&lt;?xml version="1.0" encoding="UTF-8"?&gt;':</code> it doesn't pick up the line.  Do I need to include a <code>\n</code> at the end or something?  Are there any other optimizations you can think of to speed this process up?  thanks,</p>
<p>Cameron</p>
</div>
<div class="post-text" itemprop="text">
<p>instead of checking each line, you might want to load the whole file content and perform the python regex pattern matcher. This way you will reduce the steps to check and get all the matches just by calling method findall().</p>
<p>Here is the doc link - <a href="https://docs.python.org/3/howto/regex.html" rel="nofollow">https://docs.python.org/3/howto/regex.html</a></p>
</div>
<span class="comment-copy">How large is this file?  Can you just load it all in memory and split on the documentation declarations?</span>
<span class="comment-copy">Aside: I'd be very interested to hear what XML schema your patent XML files follow.</span>
<span class="comment-copy">So I'm testing it on a small subset of the file currently, but the total file is 23GBs.  I don't think I'll have access to a cluster but not sure of that.  I could multithread it which is something I will do, but curious about other optimizations.  As far as XML schema, I'm not sure, but here is a link to one sample file: <a href="https://drive.google.com/open?id=0B2Kz5NTvWjJud3VGQS16Rks4alU" rel="nofollow noreferrer">drive.google.com/open?id=0B2Kz5NTvWjJud3VGQS16Rks4alU</a> .  I downloaded the files from google patents page here: <a href="https://www.google.com/googlebooks/uspto-patents-grants-text.html" rel="nofollow noreferrer">google.com/googlebooks/uspto-patents-grants-text.html</a></span>
<span class="comment-copy">To get an idea of what I need, it takes about half an hour to run one weeks worth of patents.  I have maybe 100 years worth of patents that I'd like to run.  Of course it isn't terrible if I can't run everything, but the faster my code works the more patents I can run.</span>
<span class="comment-copy">Will that work for 23GB of data?  I don't think I'll have that much memory.  I guess I could split it up and do that sequentially or something.  I'm reading though just for my own edification if nothing else.  Thanks!</span>
