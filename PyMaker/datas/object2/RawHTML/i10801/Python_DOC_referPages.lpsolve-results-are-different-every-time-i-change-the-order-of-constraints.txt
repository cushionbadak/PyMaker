<div class="post-text" itemprop="text">
<p>I have noticed a strange behaviour of lpsolve library (using it in python 3.4).</p>
<p>When I <strong>change the order of constraints</strong> which I add to the lpsolve model the results are also slightly different.</p>
<p>Will be glad for any hints why this is happening.</p>
<p>Adding both models to reproduce the case:</p>
<pre><code>    lp model 1: http://pastie.org/private/mginn1s7orxkq58mv3dxrw
    lp model 2: http://pastie.org/private/ron5k7y3hipxhci1hap8nq
</code></pre>
<p>If you run both models you will get slightly different results (while the objective function is almost the same):</p>
<pre><code>    obj1:  458093300.0000001
    obj2:  458093300.00000006

    vars1:  [0.0, 350260.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1900.0, 1198215.0, 318324.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4310807.0, 0.0, 0.0, 0.0, 1345965.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4505218.0, 0.0, 1689912.0, 0.0, 0.0, 0.0, 0.0, 0.0, 479929.0, 0.0, 0.0, 0.0, 0.0, 0.0, 782031.0, 0.0, 0.0, 190146.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5224280.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3058056.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 650240.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 509539.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1351133.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 301872.0, 5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 380880.0, 268556.0, 1201311.0]
    vars2:  [0.0, 350260.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1198215.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 515323.0, 0.0, 0.0, 0.0, 1345965.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4505218.0, 0.0, 1010333.0, 0.0, 0.0, 0.0, 0.0, 0.0, 479938.0, 0.0, 0.0, 0.0, 0.0, 0.0, 782031.0, 0.0, 0.0, 190146.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5224280.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3082057.0, 0.0, 0.0, 3061853.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 650240.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 623447.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1347336.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 301872.0, 305463.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 536019.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 380880.0, 268556.0, 1201311.0]
</code></pre>
<p>Python code to reproduce:</p>
<pre><code>    from lpsolve55 import *

    mod1 = lpsolve("read_lp", "/home/../model_1.lp")
    mod2 = lpsolve("read_lp", "/home/../model_2.lp")

    res1 = lpsolve('solve', mod1)
    res2 = lpsolve('solve', mod2)

    obj1 = lpsolve('get_objective', mod1)
    obj2 = lpsolve('get_objective', mod2)

    vars1 = lpsolve('get_variables', mod1)[0]
    vars2 = lpsolve('get_variables', mod2)[0]


    print("obj1: ", obj1)
    print("obj2: ", obj2)

    print("vars1: ", vars1)
    print("vars2: ", vars2)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This could be because your model is not completely numerically stable. You probably have inputs variable who are not in the same range (eg: x1 can be -1..+1 and x2 can be -1000000..+1000000)</p>
</div>
<span class="comment-copy">Could you provide some examples? :)</span>
<span class="comment-copy">@FredBarclay, added both models to reproduce the case.</span>
<span class="comment-copy">added models which can be reproduced in original message. Do you have any ideas?</span>
<span class="comment-copy">I run your 2 model in LPSolve IDE with the defaul parameters except for the simplex type where I have put 'primal primal' And I did get the exact same result for the 2 models. But seeing from the the difference (1e-16 percentile) of the 2 values, it look like more a rounding error due to the order in which the calculation are done than something completely wrong.</span>
<span class="comment-copy">could you please try to reproduce it with <i>all</i> default options. I have added python code to run.</span>
<span class="comment-copy">Your code is perfectly fine. The difference of values is purely due to rounding approximation in floating point calculations. See [<a href="https://docs.python.org/3/tutorial/floatingpoint.html]" rel="nofollow noreferrer">docs.python.org/3/tutorial/floatingpoint.html]</a> for more information</span>
<span class="comment-copy">My first answer was a wild guess because you didn't put any values in your first version of your question. Seeing the values in your second version of the question, I could answer without any doubt that the difference is due to rounding errors and there is nothing you can do about it. if you do (obj1-obj2)/obj1 you will get around 2e-16 who is perfectly fine and you can consider these 2 values as perfectly equal for a computer. For most of my programs I even consider 2 values equal at 1e-8.</span>
