<div class="post-text" itemprop="text">
<pre><code>def dowork():
  y = []
  z = []
  ab = 0
  start_time = time.time()
  t = threading.current_thread()

  for x in range(0,1500):
    y.append(random.randint(0,100000))
  for x in range(0,1500):
    z.append(random.randint(0,1000))
  for x in range(0,100):
    for k in range(0,len(z)):
      ab += y[k] ** z[k]
  print(" %.50s..." % ab)
  print("--- %.6s seconds --- %s" % (time.time() - start_time, t.name))

#do the work!
threads = []
for x in range(0,4): #4 threads
  threads.append(threading.Thread(target=dowork))

for x in threads:
  x.start() # and they are off
</code></pre>
<p>Results:</p>
<pre><code> 23949968699026357507152486869104218631097704347109...
--- 11.899 seconds --- Thread-2
 10632599432628604090664113776561125984322566079319...
--- 11.924 seconds --- Thread-4
 20488842520966388603734530904324501550532057464424...
--- 12.073 seconds --- Thread-1
 17247910051860808132548857670360685101748752056479...
--- 12.115 seconds --- Thread-3
[Finished in 12.2s]
</code></pre>
<p>And now let's do it in 1 thread:</p>
<pre><code>def dowork():
  y = []
  z = []
  ab = 0
  start_time = time.time()
  t = threading.current_thread()

  for x in range(0,1500):
    y.append(random.randint(0,100000))
  for x in range(0,1500):
    z.append(random.randint(0,1000))
  for x in range(0,100):
    for k in range(0,len(z)):
      ab += y[k] ** z[k]
  print(" %.50s..." % ab)
  print("--- %.6s seconds --- %s" % (time.time() - start_time, t.name))

# print(threadtest())
threads = []
for x in range(0,4):
  threads.append(True)

for x in threads:
  dowork()
</code></pre>
<p>Results:</p>
<pre><code> 14283744921265630410246013584722456869128720814937...
--- 2.8463 seconds --- MainThread
 13487957813644386002497605118558198407322675045349...
--- 2.7690 seconds --- MainThread
 15058500261169362071147461573764693796710045625582...
--- 2.7372 seconds --- MainThread
 77481355564746169357229771752308217188584725215300...
--- 2.7168 seconds --- MainThread
[Finished in 11.1s]
</code></pre>
<p>Why is single threaded and multi-threaded scripts have the <strong>same</strong> processing time?
Shouldn't the multi-threaded implementation only be 1/#number of threads less? (I know when you reach your max cpu threads there is diminishing returns) </p>
<p>Did I mess up my implementation?</p>
</div>
<div class="post-text" itemprop="text">
<p>Multithreading in Python does not work like other languages, it has something to do with the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">global interpreter lock</a> if I recalled correctly. There are a lot of different workarounds though, for example you can use <a href="http://sdiehl.github.io/gevent-tutorial/" rel="nofollow">gevent's coroutine based "threads"</a>. I myself prefer <a href="http://dask.pydata.org/en/latest/index.html" rel="nofollow">dask</a> for work that needs to run concurrently. For example</p>
<pre><code>import dask.bag as db
start = time.time()
(db.from_sequence(range(4), npartitions=4)
     .map(lambda _: dowork())
    .compute())
print('total time: {} seconds'.format(time.time() - start))

start = time.time()
threads = []
for x in range(0,4):
  threads.append(True)

for x in threads:
  dowork()
print('total time: {} seconds'.format(time.time() - start))
</code></pre>
<p>and the output</p>
<pre><code> 19016975777667561989667836343447216065093401859905...
--- 2.4172 seconds --- MainThread
 32883203981076692018141849036349126447899294175228...
--- 2.4685 seconds --- MainThread
 34450410116136243300565747102093690912732970152596...
--- 2.4901 seconds --- MainThread
 50964938446237359434550325092232546411362261338846...
--- 2.5317 seconds --- MainThread
total time: 2.5557193756103516 seconds
 10380860937556820815021239635380958917582122217407...
--- 2.3711 seconds --- MainThread
 13309313630078624428079401365574221411759423165825...
--- 2.2861 seconds --- MainThread
 27410752090906837219181398184615017013303570495018...
--- 2.2853 seconds --- MainThread
 73007436394172372391733482331910124459395132986470...
--- 2.3136 seconds --- MainThread
total time: 9.256525993347168 seconds
</code></pre>
<p>In this case dask uses <code>multiprocessing</code> to do the work, which may or may not be desireable for your case.</p>
<p>Also instead of using cpython, you can try other implementation of python, for example <a href="http://pypy.org/" rel="nofollow">pypy</a>, <a href="https://bitbucket.org/stackless-dev/stackless/wiki/Home" rel="nofollow">stackless python</a> etc. which claimed to provide workaround/solution to the problem.</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="http://www.dabeaz.com/GIL/" rel="nofollow">Here is a link to presentations about the GIL</a> <a href="http://www.dabeaz.com/GIL/" rel="nofollow">http://www.dabeaz.com/GIL/</a></p>
<p>The author of these presentations explained GIL in detail with examples. He also has a few videos posted on Youtube</p>
<p>In addition to using threads you might also interested in asynchronous programming. In python 3, <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow">This library is added to python</a> to provide asynchronous concurrency</p>
</div>
<div class="post-text" itemprop="text">
<p>In CPython, threads don't run in parallel because of the Global Intepreter Lock. From the Python wiki (<a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">https://wiki.python.org/moin/GlobalInterpreterLock</a>):</p>
<blockquote>
<p>In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>Here is a complete test and example regarding multithreading and multiprocessing vs single threaded/process.</p>
<p>The computation, you can pick any computation you want.</p>
<pre><code>import time, os, threading, random,  multiprocessing 

def dowork():
  total = 0
  start_time = time.time()
  t = threading.current_thread()
  p = multiprocessing.current_process()
  for x in range(0,100):
    total += random.randint(1000000-1,1000000) ** random.randint(37000-1,37000)
  print("--- %.6s seconds DONE --- %s | %s" % (time.time() - start_time, p.name, t.name))
</code></pre>
<p>The test:</p>
<pre><code>t, p = [], []
for x in range(0,4):
  #create thread
  t.append(threading.Thread(target=dowork))
  #create child process
  p.append(multiprocessing.Process(target=dowork))
#multi-thread
start_time = time.time()
for l in t:
  l.start()

for l in t:
  l.join()

print("===== %.6s seconds Multi-Threads =====" % (time.time() - start_time))
start_time = time.time()
#multi-process
for l in p:
  l.start()
for l in p:
  l.join()

print("===== %.6s seconds Multi-Processes =====" % (time.time() - start_time))
start_time = time.time()
# Sequential
for l in p:
  dowork()
print("===== %.6s seconds Single Process/Thread  =====" % (time.time() - start_time))
</code></pre>
<p>And here is the sample output:</p>
<pre><code>#Sample Output:

--- 2.6412 seconds DONE --- MainProcess | Thread-1
--- 2.5712 seconds DONE --- MainProcess | Thread-2
--- 2.5774 seconds DONE --- MainProcess | Thread-3
--- 2.5973 seconds DONE --- MainProcess | Thread-4
===== 10.388 seconds Multi-Threads =====
--- 2.4816 seconds DONE --- Process-4 | MainThread
--- 2.4841 seconds DONE --- Process-3 | MainThread
--- 2.4965 seconds DONE --- Process-2 | MainThread
--- 2.5182 seconds DONE --- Process-1 | MainThread
===== 2.5241 seconds Multi-Processes =====
--- 2.4624 seconds DONE --- MainProcess | MainThread
--- 2.6447 seconds DONE --- MainProcess | MainThread
--- 2.5716 seconds DONE --- MainProcess | MainThread
--- 2.4369 seconds DONE --- MainProcess | MainThread
===== 10.115 seconds Single Process/Thread  =====
[Finished in 23.1s]
</code></pre>
</div>
<span class="comment-copy">The threads don't run in parallel because of CPython's <i>Global Interpreter Lock</i>. It's a well-know flaw with CPython. Try multiprocessing instead.</span>
<span class="comment-copy">Ok, if you give me a link to that, or the multiprocessing, please put an answer and I will accept it. You have answered it.</span>
<span class="comment-copy"><a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow noreferrer">docs.python.org/2/library/multiprocessing.html</a></span>
<span class="comment-copy">What about <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">docs.python.org/3/library/multiprocessing.html</a> ?  Will that allow parallelism without GIL?</span>
<span class="comment-copy">multiprocessing uses multiple processes to achieve parallelism. However compared to spawning a new thread, starting a new process may take longer time, also you probably need to figure a way to enable them to talk to each other (if applicable). The solution I suggested uses <code>dask.bag</code>, which uses <code>multiprocessing</code> behind the scene.</span>
<span class="comment-copy">So the multiprocesses talk to each other under dask.bag so i don't have to ? is it done by sharing serialized data? local sockets? just curious.</span>
<span class="comment-copy">lol, dask.bag doesn't solve that automagically for you, I chose dask.bag for work mainly for the simplicity.If you really need data to be passed between processes, you would probably have to introduce a multiprocessing.Manager.Queue to calls like <code>.map()</code> and <code>.map_partition()</code> calls <a href="https://docs.python.org/3.4/library/multiprocessing.html#multiprocessing.Queue" rel="nofollow noreferrer">docs.python.org/3.4/library/â€¦</a></span>
<span class="comment-copy">I don't think I need data passed. I understand multiprocessing doesn't share resources. I was curious what's the advantage or dask.bag ? Is it a higher level api of multiprocessing? Like you said for simplicity.</span>
