<div class="post-text" itemprop="text">
<p>Novice to threading here. I'm borrowing a lot of the code from this <a href="https://stackoverflow.com/questions/3472515/python-urllib2-urlopen-is-slow-need-a-better-way-to-read-several-urls/3472905#3472905">thread</a> while trying to build my first script using threading/queue:</p>
<pre><code>import threading, urllib2
import Queue
import sys
from PIL import Image
import io, sys

def avhash(url,queue):
    if not isinstance(url, Image.Image):
        try:
            im = Image.open(url)
        except IOError:
            fd=urllib2.urlopen(url)
            image_file=io.BytesIO(fd.read())
            im=Image.open(image_file)
            im = im.resize((8, 8), Image.ANTIALIAS).convert('L')
            avg = reduce(lambda x, y: x + y, im.getdata()) / 64.
    hash = reduce(lambda x, (y, z): x | (z &lt;&lt; y),
                  enumerate(map(lambda i: 0 if i &lt; avg else 1, im.getdata())),
                  0)

    queue.put({url:hash})
    queue.task_done()

def fetch_parallel(job_list):
    q = Queue.Queue()
    threads = [threading.Thread(target=avhash, args = (job,q)) for job in job_list[0:50]]
    for t in threads:
        t.daemon = True
        t.start()

    for t in threads:
        t.join()
    return [q.get() for _ in xrange(len(job_list))]
</code></pre>
<p>In this case the job_list is a list of URLs. I've found that this code works fine when this list is equal to or less than 50, but it hangs when &gt; 50. There must be something I'm fundamentally not understanding about how threading works?</p>
</div>
<div class="post-text" itemprop="text">
<p>Your problem is this line:</p>
<pre><code>return [q.get() for _ in xrange(len(job_list))]
</code></pre>
<p>If <code>job_list</code> has more than 50 elements, then you try to read more results from your queue than you have put in. Therefore:</p>
<pre><code>return [q.get() for _ in xrange(len(job_list[:50]))]
</code></pre>
<p>or, even better:</p>
<pre><code>MAX_LEN = 50
...
threads = [... for job in job_list[:MAXLEN]]
...
return [q.get() for _ in job_list[:MAXLEN]]
</code></pre>
<p>[EDIT]</p>
<p>It seems you want your program to do something different than what it does. Your program takes the first 50 entries in <code>job_list</code>, handles each of these in a thread and disregards all other jobs. From your comment below I assume you want to handle all jobs, but only 50 at a time. For this, you should use a thread pool. In Python &gt;= 3.2 you could use <code>concurrent.futures.ThreadPoolExecutor</code> <a href="http://docs.python.org/3/library/concurrent.futures.html?highlight=threadpool#concurrent.futures.ThreadPoolExecutor" rel="nofollow">[link]</a>.</p>
<p>In Python &lt; 3.2 you have to roll your own:</p>
<pre><code>CHUNK_SIZE = 50

def fetch_parallel(job_list):
    results = []
    queue = Queue.Queue()
    while job_list:
        threads = [threading.Thread(target=avhash, args=(job, queue))
                      for job in job_list[:CHUNK_SIZE]]
        job_list = job_list[CHUNK_SIZE:]
        for thread in threads:
            thread.daemon = True
            thread.start()
        for thread in threads:
            thread.join()
        results.extend(queue.get() for _ in threads)
    return results
</code></pre>
<p>(untested)</p>
<p>[/EDIT]</p>
</div>
<span class="comment-copy">Hi, the code runs without error, but it only returns the first 50 results.</span>
<span class="comment-copy">Please see my edit.</span>
<span class="comment-copy">This works, thank you</span>
