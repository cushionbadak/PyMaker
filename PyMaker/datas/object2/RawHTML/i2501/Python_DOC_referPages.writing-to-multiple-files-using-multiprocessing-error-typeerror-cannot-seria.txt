<div class="post-text" itemprop="text">
<p>I'm trying to write to file the result from multiprocessing (4 cores/processes). Since the CPU cores work simultaneously, I thought of making 4 files, <code>0.txt</code>, <code>1.txt</code>, <code>2.txt</code> and <code>3.txt</code> and keep it in a <code>multiprocessing.Manager().list()</code>. But I'm getting error, <code>TypeError: cannot serialize '_io.TextIOWrapper' object</code>.</p>
<pre><code>def run_solver(total, proc_id, result, fouts):
    for i in range(10)):
        fouts[proc_id].write('hi\n')

if __name__ == '__main__':
    processes = []
    fouts = Manager().list((open('0.txt', 'w'), open('1.txt', 'w'), open('2.txt', 'w'), open('3.txt', 'w')))
    for proc_id in range(os.cpu_count()):
        processes.append(Process(target=run_solver, args=(int(total/os.cpu_count()), proc_id, result, fouts)))

    for process in processes:
        process.start()

    for process in processes:
        process.join()

    for i in range(len(fouts)):
        fouts[i].close()
</code></pre>
<p>I've tried to populate the list with file handle inside the function too, like below.</p>
<pre><code>def run_solver(total, proc_id, result, fouts):
    fout[proc_id] = open(str(proc_id)+'.txt', 'w')
    for i in range(10)):
        fouts[proc_id].write('hi\n')
    fout[proc_id].close()

if __name__ == '__main__':
    processes = []
    fouts = Manager().list([0]*os.cpu_count())
</code></pre>
<p>Both doesn't work and I understood there's something related to not able to serialize or unpickleable. But I don't know how to resolve this. Can someone suggest a solution?</p>
</div>
<div class="post-text" itemprop="text">
<p>Open the files <em>in each process</em>. Do not open them in the manager, you can't send open files from the manager process to the executor processes.</p>
<pre><code>def run_solver(total, proc_id, result, fouts):
    with open(fouts[proc_id], 'w') as openfile:
        for i in range(10)):
            openfile.write('hi\n')

if __name__ == '__main__':
    processes = []
    with Manager() as manager:
        fouts = manager.list(['0.txt', '1.txt', '2.txt', '3.txt'])
        for proc_id in range(os.cpu_count()):
            processes.append(Process(
                target=run_solver, args=(
                    int(total/os.cpu_count()), proc_id, result, fouts)
            ))
</code></pre>
<p>If you are sharing filenames between processes, you want to prevent race conditions when writing to those files, you really want to use a lock per file too:</p>
<pre><code>def run_solver(total, proc_id, result, fouts, locks):
    with open(fouts[proc_id], 'a') as openfile:
        for i in range(10)):
            with locks[proc_id]:
                openfile.write('hi\n')
                openfile.flush()


if __name__ == '__main__':
    processes = []
    with Manager() as manager:
        fouts = manager.list(['0.txt', '1.txt', '2.txt', '3.txt'])
        locks = manager.list([Lock() for fout in fouts])

        for proc_id in range(os.cpu_count()):
            processes.append(Process(
                target=run_solver, args=(
                    int(total/os.cpu_count()), proc_id, result, fouts, locks
                )
            ))
</code></pre>
<p>Because the files are opened with <code>with</code> they are closed automatically each time, and they are opened in append mode so different processes don't clobber one another. You do need to remember to flush the write buffer before unlocking again.</p>
<p>As an aside, you probably want to look at the <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow noreferrer">process pools</a> rather than do your own manual pooling.</p>
</div>
<span class="comment-copy">You need to share the filename, and open the file in each process. You can't just send across open file objects.</span>
<span class="comment-copy">Thanks, I got it working. I actually removed the <code>fouts</code> list entirely and just created file handles inside the processes. But why do I have to lock the <code>proc_id</code> variable? When I'm creating a file handle, like <code>openfile</code>, shouldn't it be separated from other 3 instances/processes since each one is opening different files?</span>
<span class="comment-copy">@akhilc: you are sharing files across multiple processes, so multiple processes could be trying to write to the same file. Locking prevents problems there as data from different processes could end up mangled together.</span>
<span class="comment-copy">@akhilc: the file handles may be separate, but the files on disk are not.</span>
<span class="comment-copy">I've 4 processes, since I didn't know how to write to same file, I'm using separate files for each process. So process <code>0</code> writes to <code>0.txt</code> and so on. So each process should have it's own file on disk too right?</span>
<span class="comment-copy">@akhilc: your code uses <code>os.cpu_count()</code>. I now see that I assumed that you re-used files if you had more than 4 CPUs, but you'll just run out of files.</span>
