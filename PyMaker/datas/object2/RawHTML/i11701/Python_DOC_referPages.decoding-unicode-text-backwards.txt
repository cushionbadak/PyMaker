<div class="post-text" itemprop="text">
<p>Many text encodings have the property that you can go through encoded text <em>backwards</em> and still be able to decode it. ASCII, UTF-8, UTF-16, and UTF-32 all have this property. This lets you do handy things like read the last line of a file without reading all the lines before it, or go backwards a few lines from your current position in a file.</p>
<p>Unfortunately, Python doesn't seem to come with any way to decode a file backwards. You can't <code>read</code> backwards, or <code>seek</code> by character quantity in an encoded file. The decoders in the <a href="https://docs.python.org/3/library/codecs.html" rel="nofollow"><code>codecs</code></a> module support incremental decoding <em>forwards</em>, but not backwards. There doesn't seem to be any "UTF-8-backwards" codec I could feed UTF-8 bytes to in reverse order.</p>
<p>I could probably implement the codec-dependent character boundary synchronization myself, read binary chunks backward, and feed properly-aligned chunks to appropriate decoders from the <code>codecs</code> module, but that sounds like the kind of thing where a non-expert would miss some subtle detail and not notice the output is wrong.</p>
<p>Is there any simple way to decode text backward in Python with existing tools?</p>
<hr/>
<p>Several people appear to have missed the point that <strong>reading the entire file to do this defeats the purpose</strong>. While I'm clarifying things, I might as well add that <strong>this needs to work for variable-length encodings</strong>, too. <strong>UTF-8 support is a must</strong>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Absent a general-purpose solution, here is one specific to utf-8:</p>
<pre><code>def rdecode(it):
    buffer = []
    for ch in it:
        och = ord(ch)
        if not (och &amp; 0x80):
            yield ch.decode('utf-8')
        elif not (och &amp; 0x40):
            buffer.append(ch)
        else:
            buffer.append(ch)
            yield ''.join(reversed(buffer)).decode('utf-8')
            buffer = []

utf8 = 'ho math\xc4\x93t\xc4\x93s hon \xc4\x93gap\xc4\x81 ho I\xc4\x93sous'
print utf8.decode('utf8')
for i in rdecode(reversed(utf8)):
    print i,
print ""
</code></pre>
<p>Result:</p>
<pre><code>$ python x.py 
ho mathētēs hon ēgapā ho Iēsous
s u o s ē I   o h   ā p a g ē   n o h   s ē t ē h t a m   o h 
</code></pre>
</div>
<span class="comment-copy">Possible duplicate of <a href="http://stackoverflow.com/questions/2301789/read-a-file-in-reverse-order-using-python">Read a file in reverse order using python</a></span>
<span class="comment-copy">@gravity: That reads the entire file. I'm specifically trying not to do that.</span>
<span class="comment-copy">There's a specific community wiki answer there that involves reading in chunks.  Please take a look at it at this direct link: <a href="http://stackoverflow.com/questions/260273/most-efficient-way-to-search-the-last-x-lines-of-a-file-in-python/260433#260433" title="most efficient way to search the last x lines of a file in python">stackoverflow.com/questions/260273/…</a></span>
<span class="comment-copy">@gravity: That doesn't work with Unicode.</span>
<span class="comment-copy">P.s. the UTF-8 boundary test is easy. The first byte of a chunk must not satisfy <code>(x &amp; 0xc0) == 0x80</code>.</span>
<span class="comment-copy">That looks like what I was thinking of for the "implement it myself" case, although it doesn't have any of the chunking optimization you'd want for operating on real files. I guess a lot of the work I didn't want to deal with was really in multiple codec support and writing a convenient, efficient file object that supports <code>read</code>-ing forwards and backwards and backwards iteration; for just UTF-8, the decoding itself isn't too bad.</span>
