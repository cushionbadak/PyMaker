<div class="post-text" itemprop="text">
<p>I would like to know which one of <code>json.dump()</code> or <code>json.dumps()</code> are the most efficient when it comes to encoding a large array to json format.</p>
<p>Can you please show me an example of using <code>json.dump()</code>?</p>
<p>Actually I am making a Python CGI that gets large amount of data from a MySQL database using the ORM SQlAlchemy, and after some user triggered processing, I store the final output in an Array that I finally convert to Json.</p>
<p>But when converting to JSON with : </p>
<pre><code> print json.dumps({'success': True, 'data': data}) #data is my array
</code></pre>
<p>I get the following error: </p>
<pre><code>Traceback (most recent call last):
  File "C:/script/cgi/translate_parameters.py", line 617, in     &amp;lt;module&amp;gt;
f.write(json.dumps(mytab,default=dthandler,indent=4))
  File "C:\Python27\lib\json\__init__.py", line 250, in dumps
    sort_keys=sort_keys, **kw).encode(obj)
  File "C:\Python27\lib\json\encoder.py", line 209, in encode
    chunks = list(chunks)
MemoryError
</code></pre>
<p>So, my guess is using <code>json.dump()</code> to convert data by chunks. Any ideas on how to do this? </p>
<p>Or other ideas besides using <code>json.dump()</code>?</p>
</div>
<div class="post-text" itemprop="text">
<p>You can simply replace</p>
<pre><code>f.write(json.dumps(mytab,default=dthandler,indent=4))
</code></pre>
<p>by</p>
<pre><code>json.dump(mytab, f, default=dthandler, indent=4)
</code></pre>
<p>This should "stream" the data into the file.</p>
</div>
<div class="post-text" itemprop="text">
<p><strong>The <code>JSON</code> module will allocate the entire JSON string in memory before writing, which is why <code>MemoryError</code> occurs.</strong></p>
<p>To get around this problem, use <a href="https://docs.python.org/3/library/json.html#json.JSONEncoder.iterencode" rel="noreferrer"><code>JSON.Encoder().iterencode()</code></a>:</p>
<pre class="lang-py prettyprint-override"><code>with open(filepath, 'w') as f:
    for chunk in json.JSONEncoder().iterencode(object_to_encode):
        f.write(chunk)
</code></pre>
<p>However note that this will generally take quite a while, since it is writing in many small chunks and not everything at once.</p>
<hr/>
<p><em>Special case:</em></p>
<p>I had a Python object which is a list of dicts. Like such:</p>
<pre class="lang-py prettyprint-override"><code>[
    { "prop": 1, "attr": 2 },
    { "prop": 3, "attr": 4 }
    # ...
]
</code></pre>
<p>I could <code>JSON.dumps()</code> individual objects, but the dumping whole list generates a <code>MemoryError</code> To speed up writing, I opened the file and wrote the JSON delimiter manually:</p>
<pre class="lang-py prettyprint-override"><code>with open(filepath, 'w') as f:
    f.write('[')

    for obj in list_of_dicts[:-1]:
        json.dump(obj, f)
        f.write(',')

    json.dump(list_of_dicts[-1], f)
    f.write(']')
</code></pre>
<p>You can probably get away with something like that if you know your JSON object structure beforehand. For a general use, just use <code>JSON.Encoder().iterencode()</code>.</p>
</div>
<span class="comment-copy">I don't know the implementation details but <code>dumps</code> outputs to a string, which must be built up and held in memory. <code>dump</code> writes out to a file, which I assume will be streaming and not keep the result in memory.</span>
<span class="comment-copy"><code>chunk</code>s are yielded by <code>JSON.Encoder().iterencode()</code> generator. See my answer.</span>
<span class="comment-copy">This doesn't work, even assuming <code>mytab</code> in your example is a JSON-serialisable object, <code>json.dump()</code> doesn't know which object you're dumping. In addition, even trying that still produces <code>MemoryError</code> for large objects.</span>
<span class="comment-copy">Right .. forgot mytab as argument. Fixed. Concerning Memory it might be worth trying other json libraries hoping for a more memory efficient implementation...</span>
<span class="comment-copy">Found a workaround eventually, posting my answer <code>:]</code></span>
<span class="comment-copy">That is just what <code>json.dump</code> does: <a href="https://hg.python.org/cpython/file/v2.7.10/Lib/json/__init__.py#l183" rel="nofollow noreferrer">hg.python.org/cpython/file/v2.7.10/Lib/json/__init__.py#l183</a></span>
<span class="comment-copy">Yes, but iterencode() is too slow if you try large objects - It is best to divide chunks down to where your memory can handle, then pass it all to encode() at once.</span>
