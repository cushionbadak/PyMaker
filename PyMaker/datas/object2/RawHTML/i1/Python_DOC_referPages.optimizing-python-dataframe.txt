<div class="post-text" itemprop="text">
<p>I have the following code that takes 800ms to execute, however the data is not that much.. just few columns and and few rows
Is there an opportunity to make it faster, I really don't know where is the bottelneck in that code</p>
<pre><code>def compute_s_t(df,
                gb=('session_time', 'trajectory_id'),
                params=('t', 's', 's_normalized', 'v_direct', 't_abs', ),
                fps=25, inplace=True):

    if not inplace:
        df = df.copy()

    orig_columns = df.columns.tolist()
    # compute travelled distance
    df['dx'] = df['x_world'].diff()
    df['dy'] = df['y_world'].diff()
    t1 = datetime.datetime.now()

    df['ds'] = np.sqrt(np.array(df['dx'] ** 2 + df['dy'] ** 2, dtype=np.float32))


    df['ds'].iloc[0] = 0  # to avoid NaN returned by .diff()
    df['s'] = df['ds'].cumsum()
    df['s'] = (df.groupby('trajectory_id')['s']
                 .transform(subtract_nanmin))

    # compute travelled time
    df['dt'] = df['frame'].diff() / fps
    df['dt'].iloc[0] = 0  # to avoid NaN returned by .diff()
    df['t'] = df['dt'].cumsum()
    df['t'] = (df.groupby('trajectory_id')['t']
                 .transform(subtract_nanmin))
    df['t_abs'] = df['frame'] / fps
    # compute velocity
    # why values[:, 0]? why duplicate column?
    df['v_direct'] = df['ds'].values / df['dt'].values
    df.loc[df['t'] == 0, 'v'] = np.NaN

    # compute normalized s
    df['s_normalized'] = (df.groupby('trajectory_id')['s']
                            .transform(divide_nanmax))

    # skip intermediate results
    cols = orig_columns + list(params)
    t2 = datetime.datetime.now()

    print((t2 - t1).microseconds / 1000)


    return df[cols]
</code></pre>
<p>Here is the profiler output:</p>
<pre><code>     18480 function calls (18196 primitive calls) in 0.593 seconds
</code></pre>
<p>Ordered by: call count</p>
<pre><code>  ncalls  tottime  percall  cumtime  percall filename:lineno(function)

       11    0.000    0.000    0.580    0.053 frame.py:3105(__setitem__)
       11    0.000    0.000    0.000    0.000 frame.py:3165(_ensure_valid_index)
       11    0.000    0.000    0.580    0.053 frame.py:3182(_set_item)
       11    0.000    0.000    0.000    0.000 frame.py:3324(_sanitize_column)
       11    0.000    0.000    0.003    0.000 generic.py:2599(_set_item)
       11    0.000    0.000    0.577    0.052 generic.py:2633(_check_setitem_copy)
       11    0.000    0.000    0.000    0.000 indexing.py:2321(convert_to_index_sliceable)
</code></pre>
<p>According to the comments I have used a profiler and I put the profiling result of the function above.</p>
<pre><code>def subtract_nanmin(x):
    return x - np.nanmin(x)


def divide_nanmax(x):
    return x / np.nanmax(x)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>One thing to do is replace:</p>
<pre><code>df.columns.tolist()
</code></pre>
<p>with</p>
<pre><code>df.columns.values.tolist()
</code></pre>
<p>This is much faster. Here's an experiment with a random 100x100 dataframe:</p>
<blockquote>
<pre><code>%timeit df.columns.values.tolist()
</code></pre>
<p>output:</p>
<pre><code>1.29 µs ± 19.8 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)
</code></pre>
<p>and with the same df:</p>
<pre><code>%timeit df.columns.tolist()
</code></pre>
<p>output: </p>
<pre><code>6.91 µs ± 241 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)
</code></pre>
</blockquote>
<p>UPDATE:</p>
<p>What are <code>subtract_nanmin</code> and <code>divide_nanmax</code>?</p>
<p>Instead of</p>
<pre><code>df['ds'].iloc[0] = 0  # to avoid NaN returned by .diff()
df['dt'].iloc[0] = 0  # to avoid NaN returned by .diff()
</code></pre>
<p>You can use <code>df.fillna(0)</code> or <code>df['ds'].fillna(0)</code> to get rid of NaNs</p>
</div>
<span class="comment-copy">Time to learn <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">profiling</a>?</span>
<span class="comment-copy">@adrtam I did profile the code, and I said it takes 800ms, but don't know how to optimize it</span>
<span class="comment-copy">What I mean is to find which line is contributing significantly</span>
<span class="comment-copy">4/3    0.000    0.000    0.317    0.106 indexing.py:298(_setitem_with_indexer)</span>
<span class="comment-copy">0.318    0.106 indexing.py:182(<b>setitem</b>)</span>
<span class="comment-copy">This optimized the stuff little bit, do you have any other ideas about other operations ?</span>
<span class="comment-copy">how to optimize that line ```    _df['side_diff'][_df['s'] == 0] = 0 ```</span>
<span class="comment-copy">I didn't see that line in your code. Also, what are you trying to do with it?</span>
<span class="comment-copy">I added both functions in the post please take a look at them</span>
