<div class="post-text" itemprop="text">
<p>I have a problem that as to be solved as efficient as possible. My current approach kind of works, but is extreme slow.</p>
<p>I have a dataframe with multiple columns, in this case I only care for one of them. It contains positive continuous numbers and some zeros.
<strong>my goal:</strong> is to find the row where nearly no zeros appear in the following rows.</p>
<p>To make clear what I mean I wrote this example to replicate my problem:</p>
<pre><code>df = pd.DataFrame([0,0,0,0,1,0,1,0,0,2,0,0,0,1,1,0,1,2,3,4,0,4,0,5,1,0,1,2,3,4,
                   0,0,1,2,1,1,1,1,2,2,1,3,6,1,1,5,1,2,3,4,4,4,3,5,1,2,1,2,3,4],
                   index=pd.date_range('2018-01-01', periods=60, freq='15T'))
</code></pre>
<p><a href="https://i.stack.imgur.com/pExqQ.png" rel="nofollow noreferrer"><img alt="Plotted data" src="https://i.stack.imgur.com/pExqQ.png"/></a>
There are some zeros at the beginning, but they get less after some time.
Here comes my unoptimized code to visualize the number of zeros:</p>
<pre><code>zerosum = 0 # counter for all zeros that have appeared so far
for i in range(len(df)):
    if(df[0][i]== 0.0):
        df.loc[df.index[i],'zerosum']=zerosum
        zerosum+=1
    else:
        df.loc[df.index[i],'zerosum']=zerosum
df['zerosum'].plot()
</code></pre>
<p><a href="https://i.stack.imgur.com/mdKBy.png" rel="nofollow noreferrer"><img alt="Distribution of zeros" src="https://i.stack.imgur.com/mdKBy.png"/></a></p>
<p>With that unoptimized code I can see the distribution of zeros over time. </p>
<p><strong>My expected output:</strong> would be in this example the date 01-Jan-2018 08:00, because no zeros appear after that date. </p>
<p>The problem I have when dealing with my real data is some single zeros can appear later. Therefore I can't just pick the last row that contains a zero. I have to somehow inspect the distribution of zeros and ignore later outliers.</p>
<p>Note: The visualization is not necessary to solve my problem, I just included it to explain my problem as good as possible. Thanks</p>
</div>
<div class="post-text" itemprop="text">
<p>Ok</p>
<p>Second go</p>
<pre><code>import pandas as pd
import numpy as np
import math
df = pd.DataFrame([0,0,0,0,1,0,1,0,0,2,0,0,0,1,1,0,1,2,3,4,0,4,0,5,1,0,1,2,3,4,
                   0,0,1,2,1,1,1,1,2,2,1,3,6,1,1,5,1,2,3,4,4,4,3,5,1,2,1,2,3,4], 
                   index=pd.date_range('2018-01-01', periods=60, freq='15T'),
                   columns=['values'])
</code></pre>
<p>We create a column that contains the rank of each zero, and zero if there is a non-zero value</p>
<pre><code>df['zero_idx'] = np.where(df['values']==0,np.cumsum(np.where(df['values']==0,1,0)), 0)
</code></pre>
<p>We can use this column to get the location of any zero of any rank. I dont know what your criteria is for naming a zero an outlier. But lets say we want to make sure at we are past at least 90% of all zeros...</p>
<pre><code># Total number of zeros
n_zeros = max(df['zero_idx'])
# Get past at least this percentage
tolerance = 0.9
# The rank of the abovementioned zero
rank_tolerance = math.ceil(tolerance * n_zeros)

df[df['zero_idx']==rank_tolerance].index
Out[44]: DatetimeIndex(['2018-01-01 07:30:00'], dtype='datetime64[ns]', freq='15T')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Okay, If you need to get the index after the last zero occurred, you can try this:</p>
<pre><code>last = 0
for i in range(len(df)):
    if(df[0][i] == 0):
        last = i
print(df.iloc[last+1])
</code></pre>
<p>or by Filtering:</p>
<pre><code>new = df.loc[df[0]==0]
last = df.index.get_loc(new.index[-1])
print(df.iloc[last+1])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>here my solution using a filter and <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.cumsum.html" rel="nofollow noreferrer">cumsum</a>:</p>
<pre><code>df = pd.DataFrame([0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 2, 3, 4, 0, 4, 0, 5, 1, 0, 1, 2, 3, 4,
                   0, 0, 1, 2, 1, 1, 1, 1, 2, 2, 1, 3, 6, 1, 1, 5, 1, 2, 3, 4, 4, 4, 3, 5, 1, 2, 1, 2, 3, 4],
                  index=pd.date_range('2018-01-01', periods=60, freq='15T'))

a = df[0] == 0
df['zerosum'] = a.cumsum()

maxval = max(df['zerosum'])
firstdate = df[df['zerosum'] == maxval].index[1]
print(firstdate)
</code></pre>
<p>output:</p>
<pre><code> 2018-01-01 08:00:00
</code></pre>
</div>
<span class="comment-copy">I have edited my answer according to your comments</span>
<span class="comment-copy">Thanks for your answer. That solution would be good if no outliers would appear. Maybe I should have added that to my example. The real data I'm dealing with is much longer and I sometimes get a single outlier zero.</span>
