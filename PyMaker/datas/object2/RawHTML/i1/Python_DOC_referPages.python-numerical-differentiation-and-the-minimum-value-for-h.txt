<div class="post-text" itemprop="text">
<p>I calculate the first derivative using the following code:</p>
<pre><code>def f(x):
   f = np.exp(x)
   return f

def dfdx(x):
   Df = (f(x+h)-f(x-h)) / (2*h)
   return Df
</code></pre>
<p>For example, for <code>x == 10</code> this works fine. But when I set <code>h</code> to around <code>10E-14</code> or below, <code>Df</code> starts 
to get values that are really far away from the expected value <code>f(10)</code> and the relative error between the expected value and <code>Df</code> becomes huge.</p>
<p>Why is that? What is happening here?</p>
</div>
<div class="post-text" itemprop="text">
<p>The evaluation of <code>f(x)</code> has, at best, a rounding error of <code>|f(x)|*mu</code> where <code>mu</code> is the machine constant of the floating point type. The total error of the central difference formula is thus approximately</p>
<pre><code>2*|f(x)|*mu/(2*h)  +  |f'''(x)|/6 * h^2
</code></pre>
<p>In the present case, the exponential function is equal to all of its derivatives, so that the error is proportional to </p>
<pre><code>mu/h + h^2/6
</code></pre>
<p>which has a minimum at <code>h = (3*mu)^(1/3)</code>, which for the double format with <code>mu=1e-16</code> is around <code>h=1e-5</code>.</p>
<p>The precision is increased if instead of <code>2*h</code> the actual difference <code>(x+h)-(x-h)</code> between the evaluation points is used in the denominator. This can be seen in the following loglog plot of the distance to the exact derivative.</p>
<p><a href="https://i.stack.imgur.com/YXTQD.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/YXTQD.png"/></a></p>
</div>
<div class="post-text" itemprop="text">
<p>You are probably encountering some numerical instability, as for x = 10 and h =~ 1E-13, the argument for np.exp is very close to 10 whether h is added or subtracted, so small approximation errors in the value of np.exp are scaled significantly by the division with the very small 2 * h.</p>
</div>
<div class="post-text" itemprop="text">
<p>In addition to the answer by <a href="https://stackoverflow.com/a/55206811">@LutzL</a> I will add some info from a great book <a href="https://rads.stackoverflow.com/amzn/click/com/0521880688" rel="nofollow noreferrer">Numerical Recipes 3rd Edition: The Art of Scientific Computing</a> from chapter 5.7 about <strong>Numerical Derivatives</strong>, especially about the choice of <strong>optimal <code>h</code> value for given <code>x</code></strong>:</p>
<ul>
<li>Always choose <code>h</code> so that <code>h</code> and <code>x</code> differ by an exactly representable number. Funny stuff like <code>1/3</code> should be avoided, except when <code>x</code> is equal to something along the lines of <code>14.3333333</code>.</li>
<li>Round-off error is approximately <code>epsilon * |f(x) * h|</code>, where epsilon is floating point accuracy, Python represents floating point numbers with double precision so it's <code>1e-16</code>. It may differ for more complicated functions (where precision errors arise further), though it's not your case.</li>
<li>Choice of optimal <code>h</code>: Not getting into details it would be <code>sqrt(epsilon) * x</code> for simple forward case, except when your <code>x</code> is near zero (you will find more information in the book), which is your case. You may want to use higher <code>x</code> values in such cases, complementary answer is already provided. In the case of <code>f(x+h) - f(x-h)</code> as in your example it would amount to <code>epsilon ** 1/3 * x</code>, so approximately <code>5e-6</code> times <code>x</code>, which choice might be a little difficult in case of small values like yours. Quite close (if one can say so bearing in mind floating point arithmetic...) to practical results posted by <a href="https://stackoverflow.com/a/55206811">@LutzL</a> though.</li>
<li>You may use other derivative formulas, except the <code>symmetric</code> one you are using. You may want to use the <code>forward</code> or <code>backward</code> evaluation(if the function is costly to evaluate and you have calculated <code>f(x)</code> beforehand. If your function is cheap to evaluate, you may want to evaluate it multiple times using higher order methods to make the precision error smaller (see <a href="https://en.wikipedia.org/wiki/Numerical_differentiation" rel="nofollow noreferrer">five-point stencil on wikipedia</a> as provided in the comment to your question).</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>This <a href="https://docs.python.org/3/tutorial/floatingpoint.html" rel="nofollow noreferrer">Python tutorial</a> explains the reason behind the limited precision. In summary, decimals are ultimately represented in binary and the precision is about 17 significant digits. So, you are right that it gets fuzzy beyond 10E-14.</p>
</div>
<span class="comment-copy">Read the section <a href="https://en.wikipedia.org/wiki/Numerical_differentiation#Practical_considerations_using_floating_point_arithmetic" rel="nofollow noreferrer">"Practical considerations using floating point arithmetic"</a> of the wikipedia article <a href="https://en.wikipedia.org/wiki/Numerical_differentiation" rel="nofollow noreferrer">"Numerical differentiation"</a>.</span>
