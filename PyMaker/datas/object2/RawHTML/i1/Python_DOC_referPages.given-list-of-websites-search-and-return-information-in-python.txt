<div class="post-text" itemprop="text">
<p>I created a function that returns a list of urls given a specific companies name. I want to know search through this list of urls and find information on whether the company is owned by another company.</p>
<p>Example: The company "Marketo" was acquired by Adobe. </p>
<p>I want to return whether some company was acquired and by whom.</p>
<p>Here is what I have so far:</p>
<pre><code>import requests
from googlesearch import search
from bs4 import BeautifulSoup as BS


def get_url(company_name):
    url_list = []
    for url in search(company_name, stop=10):
        url_list.append(url)
    return url_list


test1 = get_url('Marketo')
print(test1[7])


r = requests.get(test1[7])
html = r.text
soup = BS(html, 'lxml')
stuff = soup.find_all('a')


print(stuff)
</code></pre>
<p>I am new to web scraping and I have no idea how to really search through each URL (assuming I can) and find the information I seek.</p>
<p>The value of test1 is the following list:</p>
<pre><code>['https://www.marketo.com/', 'https://www.marketo.com/software/marketing-automation/', 'https://blog.marketo.com/', 'https://www.marketo.com/software/', 'https://www.marketo.com/company/', 'https://www.marketo.com/solutions/pricing/', 'https://www.marketo.com/solutions/', 'https://en.wikipedia.org/wiki/Marketo', 'https://www.linkedin.com/company/marketo', 'https://www.cmswire.com/digital-marketing/what-is-marketo-a-marketers-guide/']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>I want to return whether some company was acquired and by whom</p>
</blockquote>
<p>You can scrape the <a href="https://www.crunchbase.com/" rel="nofollow noreferrer">crunchbase</a> website to get this information.The downside is that you will be limiting your search to their site. To extend this you could perhaps include some other sites also.</p>
<pre><code>import requests
from bs4 import BeautifulSoup
import re
while True:
    print()
    organization_name=input('Enter organization_name: ').strip().lower()
    crunchbase_url='https://www.crunchbase.com/organization/'+organization_name
    headers={
        'User-Agent':'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'
    }
    r=requests.get(crunchbase_url,headers=headers)
    if r.status_code == 404:
        print('This organization is not available\n')
    else:
        soup=BeautifulSoup(r.text,'html.parser')
        overview_h2=soup.find('h2',text=re.compile('Overview'))
        try:
            possible_acquired_by_span=overview_h2.find_next('span',class_='bigValueItemLabelOrData')
            if possible_acquired_by_span.text.strip() == 'Acquired by':
                acquired_by=possible_acquired_by_span.find_next('span',class_='bigValueItemLabelOrData').text.strip()
            else:
                acquired_by=False
        except Exception as e:
                acquired_by=False
                # uncomment below line if you want to see the error
                # print(e)
        if acquired_by:
            print('Acquired By: '+acquired_by+'\n')
        else:
            print('No acquisition information available\n')

    again=input('Do You Want To Continue? ').strip().lower()
    if  again not in ['y','yes']:
        break
</code></pre>
<p>Sample Output:</p>
<pre><code>Enter organization_name: Marketo
Acquired By: Adobe Systems

Do You Want To Continue? y

Enter organization_name: Facebook
No acquisition information available

Do You Want To Continue? y

Enter organization_name: FakeCompany
This organization is not available

Do You Want To Continue? n
</code></pre>
<p><strong>Notes</strong></p>
<ul>
<li><p>Read the <a href="https://about.crunchbase.com/terms-of-service/" rel="nofollow noreferrer">crunchbase Terms</a> and seek their consent before you deploy this in any commercial projects. </p></li>
<li><p>Also checkout the <a href="https://data.crunchbase.com/docs/using-the-api" rel="nofollow noreferrer">crunchbase api</a> - I think this will be the legit way to go forward with what you are asking for. </p></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>You can find that information from site like Crunchbase.</p>
<p>The steps to get it are as follows:</p>
<ol>
<li><p>build the url containing the information for your target company. Suppose you find the url containing the information you need like:</p>
<p><code>url = 'https://www.example.com/infoaboutmycompany.html'</code></p></li>
<li><p>use selenium to get the html, as the site does not allow you to scrape the page directly. Something like this:</p>
<p><code>from selenium import webdriver
from bs4 import BeautifulSoup
driver = webdriver.Firefox()
driver.get(url)
html = driver.page_source</code></p></li>
<li><p>use BeautifulSoup to get the text from the div containing the information. It has a specific class, that you can easily find looking at the html:</p>
<p><code>bsobj = BeautifulSoup(html, 'lxml')
res = bsobj.find('div', {'class':'alpha beta gamma'})
res.text.strip()</code></p></li>
</ol>
<p>Less than 10 lines of code to get it.</p>
<p>Of course, it works changing your list, from a list of urls to a list of companies, hopefully considered by that site. For marketo it works.</p>
</div>
<div class="post-text" itemprop="text">
<p>As mention by other answers <strong>crunchbase</strong> is a good place to get this type of information, but you will require a headless browser to scrap the crunchbase 
such as <strong>Selenium</strong></p>
<hr/>
<p>If you are using ubuntu installing Selenium is fairly easy. Selenium requires a driver to interface with the chosen browser. For example, Firefox requires geckodriver</p>
<ul>
<li>pip install selenium</li>
<li>sudo pip3 install selenium --upgrade</li>
</ul>
<p>install lastest version of geckodriver</p>
<ul>
<li>wget <a href="https://github.com/mozilla/geckodriver/releases/download/v0.24.0/geckodriver-v0.24.0-linux64.tar.gz" rel="nofollow noreferrer">https://github.com/mozilla/geckodriver/releases/download/v0.24.0/geckodriver-v0.24.0-linux64.tar.gz</a></li>
<li>tar -xvzf geckodriver*</li>
<li>chmod +x geckodriver</li>
</ul>
<p>Add the driver to your PATH so other tools can find it or in the directory where all your software all install otherwise it will throw an error ('geckodriver' executable needs to be in PATH)</p>
<ul>
<li>mv geckodriver /usr/bin/</li>
</ul>
<hr/>
<p><strong>code</strong></p>
<hr/>
<pre><code>from bs4 import BeautifulSoup as BS
from selenium import webdriver


baseurl = "https://www.crunchbase.com/organization/{0}"

query = input('type company name : ').strip().lower()
url = baseurl.format(query)

driver = webdriver.Firefox()
driver.get(url)
html = driver.page_source
soup = BS(html, 'lxml')
acquiredBy = soup.find('div', class_= 'flex-no-grow cb-overflow-ellipsis identifier-label').text


print(acquiredBy)
</code></pre>
<hr/>
<p>You can also get other information using the same logic just inspect the class/ id and the scrap the information.</p>
</div>
<span class="comment-copy">See <a href="https://stackoverflow.com/questions/42299268/scraping-a-list-of-urls" title="scraping a list of urls">stackoverflow.com/questions/42299268/scraping-a-list-of-urls</a></span>
<span class="comment-copy">Could you give us the value of the <code>test1</code> list ?</span>
<span class="comment-copy">@Maaz just included the output</span>
<span class="comment-copy">The information you are looking for in the wikipedia link is not so easy to find. There is not this information inside the infobox on the right, so you have to find it on the text using some language processing</span>
<span class="comment-copy">I don't think what you are asking for is possible - to scrape information from a webpage, you have to know where you would find it on that webpage. There's no way you can guarantee that this information is even on a particular company's website - let alone in a "uniform" place on each one. You're probably better off looking for an API to get this kind of information - I see that for UK companies, for example, you could use <a href="https://developer.companieshouse.gov.uk/api/docs/" rel="nofollow noreferrer">this</a>. I don't know if other countries have anything similar.</span>
<span class="comment-copy">For the 'User Agent' part, I do not use a Linux machine so will this work for windows?</span>
<span class="comment-copy">@Wolfy It should work.</span>
<span class="comment-copy">Could you expand your answer with an example? I will gladly accept your answer after I see a working solution.</span>
<span class="comment-copy">I do not know whether this kind of scraping is completely fair. Probably someone from the stackoverflow staff should consent the plain code. Anyway I will give you a coding idea of each step.</span>
<span class="comment-copy">Have you tried to use my code? Any problem?</span>
<span class="comment-copy">I just started looking at it now, what is the 'alpha beta gamma', is that just something you are trying to find the html?</span>
<span class="comment-copy">I do get a number of errors: selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.</span>
