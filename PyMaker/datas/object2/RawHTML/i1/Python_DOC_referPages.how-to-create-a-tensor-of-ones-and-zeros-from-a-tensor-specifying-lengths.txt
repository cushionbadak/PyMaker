<div class="post-text" itemprop="text">
<p>I have the following code that calculates the loss of a neural network.</p>
<pre><code>loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits = y_hat_logits)
</code></pre>
<p>y_hat_logits is of dimension 10x100 (100 outputs for each batch element), however, it is 100 because I have padded data so in reality it could be that in every batch element, only the first e.g. 10, 20, or 30 of the actual logits are useful, so when I calculate the loss I want to make a mask so that the logits that correspond to padded data are set to 0, before passing it to my loss function. I know how to find how many logits are "useful" in each batch element, using the following code that I found online:</p>
<pre><code>def length(sequence):
   used = tf.sign(tf.reduce_max(tf.abs(sequence), axis= 2))
   length = tf.reduce_sum(used, axis=1)
   length = tf.cast(length, tf.int32)
   return length
</code></pre>
<p>This will return a tensor of shape 10x1, where the values correspond to the number of useful logits before I pad data. E.g. if the first value in the tensor is 5, that means only the first 5 logits in my batch element should be considered. Now I want to take this tensor, and if the first value is 5, I want to create a new 10x100 mask, where the first row has 5 ones and 95 zeros, so then I can do element wise multiplication of my y_hat_logits with this mask, to get a masked version of y_hat_logits where all logits corresponding to padded data is set to 0.</p>
<p>So for example if length(sequence) returns a tensor [5,3,1,0,7], I want to create a mask where the first row is [1,1,1,1,1,0,...,0], the second row is [1,1,1,0,...,0], the third row is [1,0,...,0], the fourth row is [0,...,0], the last row is [1,1,1,1,1,1,1,0,...,0]. Now what troubles me is how to do this using tf commands, because it is easy if I use np arrays. I imagine I have to do something like a nested map_fn, but I am not sure how to do this exactly.</p>
<p>In setting up my graph, I want to pass y_hat_masked_logits to my loss function, which will be the element wise product of my 10x100 mask with my 10x100 logits. I hope I made the question clear.</p>
<p>Thanks!</p>
<hr/>
<p>Actually another implementation I've been trying is with using map_fn and tf.slice but I'm making no progress. Would this be an easier approach? To take a slice of size 5 or whatever from the 1st row of the tensor and then 0 pad till 100?</p>
</div>
<div class="post-text" itemprop="text">
<p>There is already a function for what you are trying to achieve in Tensorflow. The example below should help you:</p>
<pre><code>lengths = np.array([5,3,1,0,7])
maxlen = tf.reduce_max(lengths)
# 7
mask = tf.sequence_mask(lengths, maxlen=maxlen, dtype=tf.int32)
# [[1 1 1 1 1 0 0]
#  [1 1 1 0 0 0 0]
#  [1 0 0 0 0 0 0]
#  [0 0 0 0 0 0 0]
#  [1 1 1 1 1 1 1]]
</code></pre>
</div>
