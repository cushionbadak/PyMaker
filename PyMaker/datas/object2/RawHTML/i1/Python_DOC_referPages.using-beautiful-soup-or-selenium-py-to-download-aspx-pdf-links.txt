<div class="post-text" itemprop="text">
<p>The site I am trying to scrape is this:
<a href="http://www.imperial.courts.ca.gov/CourtCalendars/Public/MCalendars.aspx" rel="nofollow noreferrer">http://www.imperial.courts.ca.gov/CourtCalendars/Public/MCalendars.aspx</a></p>
<p>It uses ASPX to generate the links to the PDFs that I want.  </p>
<p>The old code I was trying to adapt was:</p>
<pre><code>import requests, sys, webbrowser, bs4, os

# v1 - this finds links but due to asp does not click through
print('Checking for Calendars')
res = requests.get('https://imperial.courts.ca.gov/CourtCalendars/Public/MCalendars.aspx')
res.raise_for_status

soup = bs4.BeautifulSoup(res.text, 'html.parser')

os.makedirs('Calendars', exist_ok=True)

for link in soup.findAll('a', href=True):
    if link.string == 'Misdemeanor':
        linkUrl = 'http:' + link.get('href')

        res = requests.get(linkUrl) # this line is in error because aspx
        #link in html d/n = link after click

        res.raise_for_status()

        pdfFile = open(os.path.join('Calendar', os.path.basename(linkUrl)), 'wb')
        for chunk in res.iter_content(100000):
            pdfFile.write(chunk)
        pdfFile.close
</code></pre>
<p>That code worked on another site where link address on the first page = link address but here with dynamic ASPX links it doesn't.  </p>
<p>I was thinking using KEYS to right click on each link then open in new tab, download, but that seems excessive.  (And I am not sure how to manage several tabs in Selenium.)  </p>
<p>Is there a way to simply download each link within the if loop?</p>
<p>Another alternative I began was:</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.keys import Keys
browser = webdriver.Firefox()
browser.get('https://imperial.courts.ca.gov/CourtCalendars/Public/MCalendars.aspx')

# using singular find_element, then click
# this gets one of the links, but not all
# per git, need to use find elements and loop through

#beneath gets 0 new tabs
linkElems = browser.find_elements_by_link_text('Misdemeanor')
totalLinks = len(linkElems)

for i in linkElems:
    i.send_keys(Keys.CONTROL + 't')
</code></pre>
<p>But basically again I am unsure how to click and download (or open, download, close) each one.  </p>
<p>Thanks in advance.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use Chrome options.</p>
<pre><code>chromeOptions=webdriver.ChromeOptions()
prefs = {"plugins.always_open_pdf_externally": True}
chromeOptions.add_experimental_option("prefs",prefs)
driver = webdriver.Chrome(chrome_options=chromeOptions)
driver.get("https://imperial.courts.ca.gov/CourtCalendars/Public/MCalendars.aspx")

linkElems = driver.find_elements_by_link_text('Misdemeanor')

for i in linkElems:
    driver.get(i.get_attribute('href'))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I bet it's breaking not because of being an ASPX file but because it's a relative path.
It should work if you do this:</p>
<pre class="lang-py prettyprint-override"><code>linkUrl = 'https://imperial.courts.ca.gov/CourtCalendars/Public/' + link.get('href')
</code></pre>
</div>
<span class="comment-copy">Thank you.  I just ran into another problem where I couldn't use get requests so this saved me.</span>
<span class="comment-copy">Thank you.  This seems to work )but has created a new problem in that now I need to shorten/sanitize linkUrl for writing to the pdfFile basename).  But improvement!</span>
