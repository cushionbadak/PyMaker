<div class="post-text" itemprop="text">
<p>I am trying to optimize my python training script (I need to run in multiple times, so it makes sense to try to speed up). I have a dataset composed of 9 months of data. The validation setup is a kind of "temporal validation" in which I leave one month out, I train on the remaining set of months (with different sampling methods) and I make a prediction over the "test month". </p>
<pre><code>months # set of months
for test_month in months:
    sample_list = generate_different_samples([months - test-months])
    for sample in sample_list:
         xgb.train(sample)
         xgb.predict(test_month)
         # evalutaion after
</code></pre>
<p>In practice, I have for each month almost 100 different training samples. I am running my code on a machine with 16 cores and 64GB of RAM. The memory is not a problem (the dataset contains millions of instances but they do not fill the memory). I am currently parallelizing at a "test_month" level, thus creating a <code>ProcessPool</code> that run all the 9 months together, however, I am struggling in setting the <code>nthread</code> parameter of xgboost. At the moment is <code>2</code>, in this way each thread will run on a single core, but I am reading online different opinions (<a href="https://github.com/dmlc/xgboost/issues/3042" rel="nofollow noreferrer">https://github.com/dmlc/xgboost/issues/3042</a>). Should I increase this number? I know that the question may be a little vague, but I was looking for a systematic way to select the best value based on the dataset structure. </p>
</div>
<div class="post-text" itemprop="text">
<p>It will not come as a surprise, but there is no single golden-goose strategy for this. At least I never bumped into one so far. If you establish one, please share it here- I will be interested to learn.</p>
<p>There is an advice in <code>lightgbm</code>, which is a competitor GBM tool, where <a href="https://lightgbm.readthedocs.io/en/latest/Parameters.html#num_threads" rel="nofollow noreferrer">they say</a>:</p>
<blockquote>
<p>for the best speed, set this to the number of real CPU cores, not the number of threads (most CPUs use hyper-threading to generate 2 threads per CPU core)</p>
</blockquote>
<p>I'm not aware if there a similar recommendation from xgboost authors. But to the zeroth order approximation, i do not see a reason, why the two implementations would scale differently.</p>
<p>The most in-depth benchmarking of GBM tools that I saw is <a href="https://sites.google.com/view/lauraepp/benchmarks" rel="nofollow noreferrer">this one by Laurae</a>. It shows, among other things, performance scaling as a function of the number of threads. Beware, that it is really advanced and conclusions from there might not directly apply, unless one implements the same preparatory steps on the OS level.</p>
</div>
