<div class="post-text" itemprop="text">
<p>I am importing a text file with 5 columns of data (of different datatypes). For some reason once the data is imported and cleaned. They are all assigned type Object in pandas so there is no way to distinguish the columns. </p>
<p>My goal is to distinguish the columns by datatype and drop columns that contain a specific data type. The code and results are as follows:</p>
<pre><code>import pandas as pd
import re

data = pd.read_csv('SevAvail2.txt', sep="\t", header=None)
df = pd.DataFrame(data)


header = df.column = df.iloc[0]
header = df.reindex(df.index.drop(0))

# print(header)
df = header
df = df.loc[:, df.isnull().mean() &lt; .95]

#count remaining column length and print list with count
col_length = len(df.columns)
print(col_length)
header_label = []
for i in range(0, col_length):
    header_label.append(i)

#reset headers to (0 : n)
df.columns = header_label

# print(df)
for column in df.columns[0:]:
    print(df[column])
</code></pre>
<p>Resulting columns:</p>
<pre><code>1     AB21313BF
2     AB21313GF
3     AB21313SF
4     AB21313CF
5     AB21313KF
Name: 0, dtype: object

1          BABA TECH
2              LALA TECH
3              NDMP
4          IND CORP
5          CAMP 
Name: 1, dtype: object

1       9.2500
2      15.7500
3       7.0000
4      19.7500
5      33.5000
Name: 2, dtype: object

1         -65
2        1.75
3           0
4          -4
5        .75)
Name: 3, dtype: object

1      4,501,561.00 
2      3,145,531.00 
3      1,454,303.00 
4      1,420,949.00 
5      1,095,575.00 
Name: 4, dtype: object
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use pandas <code>infer_dtype</code> api to infer the datatype of the columns.</p>
<h3>Example:</h3>
<pre><code>import pandas as pd
df = pd.DataFrame({'c1': [1,2], 'c2': [1.0,2.0], 'c3': ["a","b"]})
for c in df.columns:
    print (pd.lib.infer_dtype(df[c]))
</code></pre>
<p>Output:</p>
<p><code>integer
floating
string</code></p>
<p>Documentation: <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.api.types.infer_dtype.html" rel="nofollow noreferrer">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.api.types.infer_dtype.html</a></p>
<h3>Numbers stored as strings:</h3>
<p>When a number contains "," and stored as string (ex:'4,501,561.00'), one brute force way is </p>
<pre><code>import pandas as pd
df = pd.DataFrame({'c1': ['4,501,561.00','501,561.00'], 'c2': [1.0,2.0], 'c3': ["a","b"]})
for c in df.columns:
    if pd.lib.infer_dtype(df[c]) == 'string':
        # Or is it a number stored as string 
        try:
            df[c].str.replace(',','').astype(float)
            print ("floating")
        except:
            print ("string")
    else:
        print (pd.lib.infer_dtype(df[c]))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If it should be a number and python is recognizing as object, it means there are non-numeric characters in the field. You could review the source file manually, or force the columns you believe should be numeric as such. Alternatively, you can force the datatype on import by assigning them in your read statement</p>
<pre><code>pr.read_csv('filename', sep='/t', dtype= {'Field1':int, 'Field2':str... }
</code></pre>
<p>and so on...</p>
</div>
<span class="comment-copy">Thanks for sharing- it returns all of them as string for some reason. Any thoughts?</span>
<span class="comment-copy">@ravecoder '4,501,561.00' is  treated as a string. Looks like all your data is stored as strings.</span>
<span class="comment-copy">@ravecoder One brute force way is to have a try except block and try converting it to all possible datatype one after the other. For example <code>df['c1'] = df['c1'].str.replace(',','').astype(float)</code></span>
<span class="comment-copy">Thanks for sharing. The goal is to process large amounts of sourcefiles and a lot of them have different column setups.. thus trying to delete a specific type of column. This means I wont be able to force the datatype. Also means its difficult to review source files manually because of the sheer amount of them. Any other thoughts?</span>
<span class="comment-copy">Sounds like the solution proposed by mujjiga is more appropriate :) You could alter your process before importing to python? see if you can standardize the source files at the source maybe?</span>
<span class="comment-copy">Yeah I'm going to have to standardize at the source. @mujjiga's solution seems most apt. Thanks for the input</span>
