<div class="post-text" itemprop="text">
<p>I'm new-ish to python and started experimenting with  Beautiful Soup 4. I tried writing code that would get all the links on one page then with those links repeat the prosses until I have an entire website parsed. </p>
<pre><code>import bs4 as bs
import urllib.request as url

links_unclean = []
links_clean = []
soup = bs.BeautifulSoup(url.urlopen('https://pythonprogramming.net/parsememcparseface/').read(), 'html.parser')

for url in soup.find_all('a'):
    print(url.get('href'))
    links_unclean.append(url.get('href'))

for link in links_unclean:
    if (link[:8] == 'https://'):
        links_clean.append(link)

print(links_clean)

while True:
    for link in links_clean:
        soup = bs.BeautifulSoup(url.urlopen(link).read(), 'html.parser')

        for url in soup.find_all('a'):
            print(url.get('href'))
            links_unclean.append(url.get('href'))

        for link in links_unclean:
            if (link[:8] == 'https://'):
                links_clean.append(link)

        links_clean = list(dict.fromkeys(links_clean))



input()
</code></pre>
<p>But I'm now getting this error:</p>
<blockquote>
<p>'NoneType' object is not callable
       line 20, in 
       soup = bs.BeautifulSoup(url.urlopen(link).read(), 
       'html.parser')</p>
</blockquote>
<p>Can you pls help.</p>
</div>
<div class="post-text" itemprop="text">
<p>Be careful when importing modules <code>as</code> something. In this case, <code>url</code> on line 2 gets overridden in your <code>for</code> loop when you iterate.</p>
<p>Here is a shorter solution that will also give back only URLs containing <strong>https</strong> as part of the <strong>href</strong> attribute:</p>
<pre><code>from bs4 import BeautifulSoup
from urllib.request import urlopen


content = urlopen('https://pythonprogramming.net/parsememcparseface/')
soup = BeautifulSoup(content, "html.parser")
base = soup.find('body')

for link in BeautifulSoup(str(base), "html.parser").findAll("a"):
    if 'href' in link.attrs:
        if 'https' in link['href']:
            print(link['href'])
</code></pre>
<p>However, this paints an incomplete picture as not all links are captured because of errors on the page with HTML tags. May I recommend also the following alternative, which is very simple and works flawlessly in your scenario (<strong>note</strong>: you will need the package <a href="https://html.python-requests.org/" rel="nofollow noreferrer">Requests-HTML</a>):</p>
<pre><code>from requests_html import HTML, HTMLSession

session = HTMLSession()
r = session.get('https://pythonprogramming.net/parsememcparseface/')

for link in r.html.absolute_links:
    print(link)
</code></pre>
<p>This will output all URLs, including both those that reference other URLs on the same domain and those that are external websites.</p>
</div>
<div class="post-text" itemprop="text">
<p>I would consider using an attribute = value css selector and using the <code>^</code> operator to specify that the <code>href</code> attributes begin with <code>https</code>. You will then only have valid protocols. Also, use set comprehensions to ensure no duplicates and <code>Session</code> to re-use connection.</p>
<pre><code>from bs4 import BeautifulSoup as bs
import requests
import pandas as pd
final = []

with requests.Session() as s:
    r = s.get('https://pythonprogramming.net/parsememcparseface/')
    soup = bs(r.content, 'lxml')
    httpsLinks = {item['href'] for item in soup.select('[href^=https]')}
    for link in httpsLinks:
        r = s.get(link)
        soup = bs(r.content, 'lxml')
        newHttpsLinks = [item['href'] for item in soup.select('[href^=https]')]
        final.append(newHttpsLinks)
tidyList =  list({item for sublist in final for item in sublist})  
df = pd.DataFrame(tidyList)
print(df)
</code></pre>
</div>
