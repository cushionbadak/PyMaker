<div class="post-text" itemprop="text">
<p>I have a data frame with location data like "Los Angeles, CA".</p>
<p>The goal is the iterate over all entries of the column and save the long and lat in a new column. Any input or tips are highly welcome !</p>
<p>I tried it for a single value and it worked.</p>
<pre><code>from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="xxx")
location=geolocator.geocode(df['Location'][1])
print(location.longitude)
print(location.latitude)
</code></pre>
<p>-117.8704931</p>
<p>33.7500378</p>
<p>Now, As a beginner I thought let's do a for loop:</p>
<pre><code>df['lat']=0
print(df['Location'][1])
for x in range(1,len(df)+1):
    location = geolocator.geocode(df['Location'][x])
    df['loc'][x]=location.latitude
</code></pre>
<p>I get the following warning:</p>
<pre><code>SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
  df['loc'][x]=location.latitude
</code></pre>
<p>and after ~2 mins the following error:</p>
<pre><code>socket.timeout: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\skpok\Anaconda3\lib\site-packages\geopy\geocoders\base.py", line 344, in _call_geocoder
    page = requester(req, timeout=timeout, **kwargs)
  File "C:\Users\skpok\Anaconda3\lib\urllib\request.py", line 525, in open
    response = self._open(req, data)
  File "C:\Users\skpok\Anaconda3\lib\urllib\request.py", line 543, in _open
    '_open', req)
  File "C:\Users\skpok\Anaconda3\lib\urllib\request.py", line 503, in _call_chain
    result = func(*args)
  File "C:\Users\skpok\Anaconda3\lib\urllib\request.py", line 1360, in https_open
    context=self._context, check_hostname=self._check_hostname)
  File "C:\Users\skpok\Anaconda3\lib\urllib\request.py", line 1319, in do_open
    raise URLError(err)
urllib.error.URLError: &lt;urlopen error timed out&gt;

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\skpok\Downloads\test123.py", line 12, in &lt;module&gt;
    location = geolocator.geocode(df['Location'][x])
  File "C:\Users\skpok\Anaconda3\lib\site-packages\geopy\geocoders\osm.py", line 309, in geocode
    self._call_geocoder(url, timeout=timeout), exactly_one
  File "C:\Users\skpok\Anaconda3\lib\site-packages\geopy\geocoders\base.py", line 367, in _call_geocoder
    raise GeocoderTimedOut('Service timed out')
geopy.exc.GeocoderTimedOut: Service timed out
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Nominatim has a maximum request per second rule (1 per second).  You should try to put in a clause where the script sleeps between loops.</p>
<p>You can try </p>
<pre><code>import time
df['lat']=0
print(df['Location'][1])
for x in range(1,len(df)+1):
    location = geolocator.geocode(df['Location'][x])
    time.sleep(2)
    df.at[x, 'lat']=location.latitude
</code></pre>
</div>
<span class="comment-copy">With regards to service timeouts you might find the geopy's RateLimiter class helpful: <a href="https://geopy.readthedocs.io/en/1.18.1/#usage-with-pandas" rel="nofollow noreferrer">geopy.readthedocs.io/en/1.18.1/#usage-with-pandas</a></span>
<span class="comment-copy">Thanks so much, given that I have 100k entries, this will take quite a bit of time. Maybe I should look into renting a cheap server to do it , instead of letting my machine run for that many hours</span>
<span class="comment-copy">I've used Google Maps for something like this. They allow around 300K at the start for free using their API. And if you're using geopy, you just have to change a line and a half of code.</span>
