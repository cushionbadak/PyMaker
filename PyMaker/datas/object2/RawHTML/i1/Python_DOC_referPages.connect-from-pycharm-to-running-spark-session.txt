<div class="post-text" itemprop="text">
<p>I am currently trying to set up my spark environment and wondered what is the best practice. I want to write my Code in Pycharm and execute it from there. How can i connect to a local (on my Mac) already running Spark-Session from there? My idea so far was to start a pyspark-shell in the terminal and if I run my code in Pycharm it should connect to that running Spark-Session.</p>
<p>How to do that?</p>
<p>Thanks in advance!</p>
</div>
<div class="post-text" itemprop="text">
<p>You could try creating a spark shell from within python, using this:</p>
<pre><code>import os, sys
os.environ['SPARK_HOME']="/home/spark-2.4.0-bin-hadoop2.7" #path to spark
sys.path.append(os.path.join(os.environ['SPARK_HOME'], 'python') )
sys.path.append(os.path.join(os.environ['SPARK_HOME'], 'python/lib/py4j-0.10.7-src.zip'))

import pyspark
spark = pyspark.sql.SparkSession.builder.appName("pysaprk_python").getOrCreate()

print (spark.version, spark.sparkContext.master)
</code></pre>
</div>
<span class="comment-copy">but that session is only gonna live until the end of the code in Pycharm. I would like to have an independent SparkSession that I can connect to and if the Code in Pycharm is done the SparkSession still should live...</span>
<span class="comment-copy">don't know how to do that, if I find anything I'll let you know. but if you could elaborate for what purpose this is needed perhaps it would help, cheers</span>
<span class="comment-copy">purpose would be monitoring. always nicer if u can access the SparkUI and check the jobs etc. after your app is finished</span>
<span class="comment-copy">checkout built in history server (<a href="https://spark.apache.org/docs/latest/monitoring.html" rel="nofollow noreferrer">spark.apache.org/docs/latest/monitoring.html</a>) and <a href="https://github.com/hammerlab/spree" rel="nofollow noreferrer">spree</a></span>
