<div class="post-text" itemprop="text">
<p>I have to implement a proxy pool in a server that has multiple crawlers that use scrapy.</p>
<p>How would I implement a proxy pool given that I already have a DB with multiple proxies that are been updated all time.</p>
<p>I don't want to add the proxies directly in the code, mainly because a lot of those proxies die really fast and some of the crawlers take too long to finish.</p>
<p>Is there a way to implement this using a middleware or something that would not require to change every crawler I got ?</p>
<p>Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>Yes, you can implement such a proxy handling using a <a href="https://docs.scrapy.org/en/latest/topics/downloader-middleware.html" rel="nofollow noreferrer">downloader middleware</a>.</p>
<p><a href="https://github.com/search?q=scrapy%20proxy" rel="nofollow noreferrer">Search Github for ‘scrapy proxy’</a> to find some examples of downloader middlewares that handle proxy configuration.</p>
</div>
