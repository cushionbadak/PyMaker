<div class="post-text" itemprop="text">
<p>Objects cannot be serialised to json so therefore need to be converted or parsed through a custom JsonEncoder class.</p>
<p>pandas Dataframe has a number of methods, like <code>from_records</code> to read json data. Yet when you read that json data back it is returned as int64 instead of timestamp.</p>
<p>There are many ways to skin a cat in pandas. What is the best way to preserve data structures when reading and writing json?</p>
</div>
<div class="post-text" itemprop="text">
<p>For what its worth I save pandas dataframes to a Postgres Database, and I want to preserve the timezoned index. I employ the following code:</p>
<pre><code>class db_JsonEncodedDataFrameWithTimezone(db.TypeDecorator):
    """Enables JSON storage by encoding and decoding on the fly."""
    impl = db.Text

    def process_bind_param(self, value, dialect):
        if value is not None and isinstance(value, pd.DataFrame):
            timezone = value.index.tz.zone
            df_json = value.to_json(orient="index")
            data = {'timezone': timezone, 'df': df_json, 'index_name': value.index.name}
            value = json.dumps(data)
        return value

    def process_result_value(self, value, dialect):
        if value is not None:
            data = json.loads(value)
            df = pd.read_json(data['df'], orient="index")
            df.index = df.index.tz_localize('UTC')
            df.index = df.index.tz_convert(data['timezone'])
            df.index.name = data['index_name']
            value = df
        return value

    def compare_values(self, x, y):
        from pandas.util.testing import assert_frame_equal
        try:
            assert_frame_equal(x, y, check_names=True, check_like=True)
            return True
        except (AssertionError, ValueError, TypeError):
            return False
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If I have correctly understood your problem, you are looking for a serialization way preserving the data types of a dataframe.</p>
<p>The problem is that the <em>interchange</em> formats internally use few types: only strings for csv, strings and numbers for json. Of course there are ways to give formatting hints at read time (date format for date columns in csv), and it is generaly easy to convert back to the proper type after extraction, by I think that you would hope a more <em>natural</em> way. As suggested by Attack68 you could use a database but for example a SQLite database would be off because it has no internal date type.</p>
<p>IMHO a simple way would be to rely on the good old <code>pickle</code> module. After all, a dataframe is a Python object that contains other Python objects, so pickle is good at serializing that. The only point to remember is that, at deserialization time, pandas will have to be imported before calling <code>pickle.load</code>.</p>
<p>But I have just tested with a (tiny) dataframe containing various datatypes, and pickle was great as correctly saving and restoring them.</p>
</div>
<span class="comment-copy">Pandas is not a generic json decoder. It can only (correctly) process json files is specific format and is known to be bad at processing deeply nested json files. IMHO your current question is <i>unclear</i>.</span>
<span class="comment-copy">@SergeBallesta the question is pandas for some reason did a hackjob at converting data to and from json. try write from a pandas df to json something that contains a pd.Timestamp object and then read it back into a df. you will have two different objects</span>
<span class="comment-copy">seems like json is not the one to serialise timestamps or other objects. thanks for the alternative !</span>
