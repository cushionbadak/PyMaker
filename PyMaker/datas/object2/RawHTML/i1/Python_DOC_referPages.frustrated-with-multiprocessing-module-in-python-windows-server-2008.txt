<div class="post-text" itemprop="text">
<p>I am dealing with a CPU-bound task and try to use multiprocessing module on my server to speed up the calculation. The configure is as follows:</p>
<ul>
<li>system: windows server 2008 r2</li>
<li>RAM: 32g RAM</li>
<li>core: (Intel E5-2643 v2 @ 3.5GHz) * 12</li>
<li>Environment: Pycharm &amp; python 3.6</li>
</ul>
<p>When I open more than 4 cores, the error msg box keeps popping out and says that python stop working with fault module name StackHash_1dc2. It seems to be a problem on one of the subprocess, cause the other subprocess runs well, but with this error the main process cannot terminate automatically. The wiered thing is that if I run the same code 5 straight times, there is only 2 times that the error may occur, so I believe this is not a bug, but rather something much more worse.</p>
<p>However, I couldn't reproduce the error on my own pc cause it has only 4 cores. 
I know it is dumb to use multiprocessing on windows, but I can't change system on the server. What can I do to make it right?</p>
<p>Below is just a sample code which can arise the problem on my server:</p>
<pre><code>import multiprocessing
import pandas as pd
from scipy import stats

def func(msg):
    print('Hello, ', msg)
    a = []
    for i in range(50):
        I = 200000
        S = pd.DataFrame([0.03] * I)
        d1 = (0.04 - S[0]) / 0.004
        p = stats.norm.cdf(d1, 0, 1)
        a.append(p.sum())
    print('Goodbye,', msg)

def run():
    if __name__ == '__main__':
        multiprocessing.freeze_support()
        pool = multiprocessing.Pool(processes=11)

        for i in range(20):
            msg = '%d' % (i)
            pool.apply_async(func,(msg, ))

        print('Mark~~~~~~~~~~~~~~~')
        pool.close()
        pool.join()
        print('sub-process done')

if __name__ == '__main__':
    run()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Have same problem. While using Multiprocessing Pool, each subprocess should be writing out multiple pickles, but some output pickles are missing, and Python (3.6.5) is crashing. Problem event name BEX64, and the same fault module StackHash_1dc2. I think it is either a memory access or write conflict from the interaction of multiple subprocesses. Problem resolves when I limit each process to writing out a single pickle. In your code above, you have multiple subprocesses appending to list a (each subprocess will try to open and write to a discrete copy of this list unless it is declared as shared via a multiprocessing manager, I think). list a needs to be declared as a shared resource for multiprocessing (but I have not worked out how to do this).</p>
</div>
<span class="comment-copy">I doubt this is related but why the double if name == main? Is that a typo or does it have some sort of use?</span>
<span class="comment-copy">This is just a sample. The second if name == main is the place I run multiple things besides the run(ï¼‰ function. Moreover, in windows we need to call multiprocessing right after "if name == main"</span>
<span class="comment-copy">In this sample, I just create a local variable a, which will not be shared by the other subprocess, so there is no interaction between subproces. If you want to use a shared list, then manager.list() should be used in the main process and pass the list as an argument to each subprocess. I hope this can solve your problem. As for my problem, I updated python to 3.7.1, and the problem is slightly solved cause I can open 8 process in the same code without crash, though running with 12 subprocesses is still unstable. Therefore I suggest you update python to the the latest version.</span>
