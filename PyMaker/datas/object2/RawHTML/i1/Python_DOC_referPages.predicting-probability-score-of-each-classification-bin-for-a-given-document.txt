<div class="post-text" itemprop="text">
<p>I am creating a python model that will classify a given document based on the text. Because each document still needs to be manually reviewed by a human, I am creating a suggestion platform that will give the user the top n-classes that a given document belongs too. Additionally each document can belong to more than one class. I have a training set of documents filled with rich text and their tags.</p>
<p>What I would like to do is perform a regression on each document to get a probabilistic score of each classification and return the top 5 highest scored classes.</p>
<p>I have looked into Bayes classification models, and recommendation systems and I think a logistic regression will help be better as it returns a score. I am new to machine learning and would appreciate any advice or examples that is modeled after this kind of problem. Thank you.</p>
<p>EDIT: Specifically, my problem is how should I parse my text data for ML modeling with logistic regression? Do I need to represent my text in a vector format using Word2Vec/Doc2Vec or a Bag-of-words model?</p>
</div>
<div class="post-text" itemprop="text">
<p>In short, build a <a href="https://en.wikipedia.org/wiki/Multiclass_classification" rel="nofollow noreferrer">multi-class</a> or <a href="https://en.wikipedia.org/wiki/Multi-label_classification" rel="nofollow noreferrer">multi-label classification</a> model. Then <a href="https://en.wikipedia.org/wiki/Platt_scaling" rel="nofollow noreferrer">calibrate</a> your model outputs. Either <code>Word2Vec</code> or <code>Bag-of-words</code> model can be used to build such a model. </p>
<p>Longer version. See the figure below. This is Figure 1 from <a href="https://arxiv.org/abs/1706.04599" rel="nofollow noreferrer">this</a> paper. The output from your model would be logits and you could apply a softmax (multi-class) or sigmoid (multi-label) transform on the logits. If you want more confidence on the classifier output, the calibration step described in the paper is probably what you want to perform. This step is to convert the classifier output into a representation of the likelihood of true correctness using additional validation dataset.</p>
<p><img alt="Figure1 from paper" src="https://i.stack.imgur.com/6JLGl.png"/></p>
</div>
<span class="comment-copy">what is exactly the step on using a logistic regression for text classification that you are having problems understanding?</span>
<span class="comment-copy">On the NLP side, what is the best way to represent my text data for modeling in a logistic regression? (e.g. word2vec, bag-of -words)</span>
<span class="comment-copy">depends on the problem, the data, etc.</span>
<span class="comment-copy">In addition to w2v &amp; BOW, you could also consider TFIDF &amp; Fasttext. Sckit supports tfidf in a nearly identical manner to bow, and gensim supports fasttext nearly identically to its support of w2v. But it really is just experimentation. Also, you could use a relatively simple neural net as another alternative to logistic regression (typically they have higher performance).</span>
