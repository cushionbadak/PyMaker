<div class="post-text" itemprop="text">
<p>I have a python generator that returns lots of items, for example:</p>
<pre><code>import itertools

def generate_random_strings():
    chars = "ABCDEFGH"
    for item in itertools.product(chars, repeat=10):
        yield "".join(item)
</code></pre>
<p>I then iterate over this and perform various tasks, the issue is that I'm only using one thread/process for this:</p>
<pre><code>my_strings = generate_random_strings()
for string in my_strings:
    # do something with string...
    print(string)
</code></pre>
<p>This works great, I'm getting all my strings, but it's slow. I would like to harness the power of Python multiprocessing to "divide and conquer" this for loop. However, of course, I want each string to be processed only once. While I've found much documentation on multiprocessing, I'm trying to find the most simple solution for this with the least amount of code.
I'm assuming each thread should take a big chunk of items every time and process them before coming back and getting another big chunk etc...</p>
<p>Many thanks,</p>
</div>
<div class="post-text" itemprop="text">
<p>Most simple solution with least code? multiprocessing context manager.</p>
<p>I assume that you can put "do something with string" into a function called "do_something"</p>
<pre><code>from multiprocessing import Pool as ProcessPool

number_of_processes = 4

with ProcessPool(number_of_processes) as pool:
    pool.map(do_something, my_strings)
</code></pre>
<p>If you want to get the results of "do_something" back again, easy!</p>
<pre><code>with ProcessPool(number_of_processes) as pool:
    results = pool.map(do_something, my_strings)
</code></pre>
<p>You'll get them in a list.</p>
<p>Multiprocessing.dummy is a syntactic wrapper for process pools that lets you use the multiprocessing syntax. If you want threads instead of processes, just do this:</p>
<pre><code>from multiprocessing.dummy import Pool as ThreadPool
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You may use <code>multiprocessing</code>.</p>
<pre><code>import multiprocessing

def string_fun(string):
    # do something with string...
    print(string)

my_strings = generate_random_strings()
num_of_threads = 7
pool = multiprocessing.Pool(num_of_threads)
pool.map(string_fun, my_strings)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming you're using the lastest version of Python, you may want to read something about asyncio module. Multithreading is not easy to implement due to GIL lock: <i>"In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe."</i>
<br/></p>
<p>So you can swap on Multiprocessing, or, as reported above, take a look at asycio module.<br/>
asyncio — Asynchronous I/O &gt; <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer">https://docs.python.org/3/library/asyncio.html</a>
<br/><br/>
I'll integrate this answer with some code as soon as possible.<br/>
Hope it helps,<br/>
<b>Hele</b></p>
</div>
<div class="post-text" itemprop="text">
<p>As @Hele mentioned, asyncio is best of all, here is an example</p>
<p><strong>Code</strong></p>
<pre><code>#!/usr/bin/python3
# -*- coding: utf-8 -*-

# python 3.7.2

from asyncio import ensure_future, gather, run
import random

alphabet = 'ABCDEFGH'
size = 1000


async def generate():
    tasks = list()
    result = None

    for el in range(1, size):
        task = ensure_future(generate_one())
        tasks.append(task)

        result = await gather(*tasks)

    return list(set(result))


async def generate_one():
    return ''.join(random.choice(alphabet) for i in range(8))


if __name__ == '__main__':

    my_strings = run(generate())

    print(my_strings)
</code></pre>
<p><strong>Output</strong></p>
<pre><code>['CHABCGDD', 'ACBGAFEB', ...
</code></pre>
<p>Of course, u need to improve generate_one, this variant is very slow.</p>
</div>
<span class="comment-copy">Side-note on speed: It won't make a huge difference, but if you change <code>for item in itertools.product(chars, repeat=10): yield "".join(item)</code> to <code>yield from map( "".join, itertools.product(chars, repeat=10))</code> it will produce results moderately faster (by pushing all the work to the C layer, removing bytecode interpreter overhead, and by ensuring <code>product</code>'s <code>tuple</code>s are released before the next one is requested, which allows it to reuse the <code>tuple</code> rather than allocating new ones).</span>
<span class="comment-copy">Thanks for the tip!</span>
<span class="comment-copy">You've got the imports completely backwards. <code>multiprocessing.dummy.Pool</code> is a thread-based pool, not a process-based pool, and <code>multiprocessing.Pool</code> is process-based, not thread-based.</span>
<span class="comment-copy">Ah shit yes sorry. Fixed now.</span>
<span class="comment-copy">Will this code only pass one string per process? Would it be faster if we were to pass a whole chunk of it? Just trying to wrap my head around this.</span>
<span class="comment-copy">@LoicDuros According to the docs it does exactly this - "This method chops the iterable into a number of chunks which it submits to the process pool as separate tasks." (<a href="https://docs.python.org/3.4/library/multiprocessing.html?highlight=process#multiprocessing.pool.Pool.map" rel="nofollow noreferrer">docs.python.org/3.4/library/…</a>)</span>
<span class="comment-copy">OK, thanks, and what if the generator yielded a gigantic number of items, would it require to "read" it through in order to execute pool.map</span>
<span class="comment-copy">The reason I'm asking is because when I'm only using 4 characters permutations it's actually outputting stuff from string_fun, but if I switch to higher numbers, it looks like it's stuck.</span>
<span class="comment-copy">Nevermind this is due to the generate_strings anyway.</span>
<span class="comment-copy">I've prepared example, can u check it?</span>
<span class="comment-copy">Yes, is fine :)</span>
<span class="comment-copy">Thank you, I will look into asyncio</span>
<span class="comment-copy">Thanks! I will test and compare</span>
