<div class="post-text" itemprop="text">
<p>I need to run a function <code>int f(int i)</code> with 10_000 parameters and it takes around 1sec to execute due to I/O time.<br/>
In a language like Python, I can use threads (or <code>async/await</code>, I know, but I'll talk about it later) to parallelize this task.<br/>
If I want to always have 10 running threads, and to split the task between them, I can use <a href="https://stackoverflow.com/questions/3033952/threading-pool-similar-to-the-multiprocessing-pool">ThreadingPool</a> :</p>
<pre><code>def f(p):
    x = [...]
    return x

p = ThreadPool()
xs = p.map(f, range(10_000))
</code></pre>
<p>But <strong>how does it work</strong> ? If I want to implement a similar thing with, let's say NodeJS and <code>f = http("www.google.com", callback)</code>, where should I begin ? <strong>What's the algorithms for this kind of problem ?</strong><br/>
Again, I'd like to get 10 requests at the same time, and when one is finished  the next one should start.  </p>
<h3>What I've been thinking so far (ugly because the callback is starting a new call to the f() function):</h3>
<pre><code>queue = ["www.google.com", "www.facebook.com"]
var f = function(url) {
  http.get(url, (e) =&gt; {
    const newUrl = queue.pop();
    f(newUrl);
  });
};

for (var i = 0; i &lt; 10; i++) {
  f(queue.pop());
}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Reimplementation of that Bluebird function I linked to:</p>
<p><div class="snippet" data-babel="false" data-console="true" data-hide="false" data-lang="js">
<div class="snippet-code">
<pre class="snippet-code-js lang-js prettyprint-override"><code>const mapWithConcurrency = async (values, concurrency, fn) =&gt; {
    let i = 0;
    let results = values.map(() =&gt; null);

    const work = async () =&gt; {
        while (i &lt; values.length) {
            const current = i++;
            results[current] = await fn(values[current]);
        }
    };

    await Promise.all(Array.from({length: concurrency}, work));

    return results;
};

mapWithConcurrency(Array.from({length: 30 * 15}, (_, i) =&gt; i), 10, async i =&gt; {
    const el = document.body.appendChild(document.createElement('i'));
    el.style.left = 5 * (i % 30) + 'px';
    el.style.top = 5 * (i / 30 | 0) + 'px';
    await new Promise(resolve =&gt; { setTimeout(resolve, Math.random() * 500); });
    el.style.background = 'black';
    return 2 * i;
}).then(results =&gt; {
    console.log(results.length, results.every((x, i) =&gt; x === 2 * i));
});</code></pre>
<pre class="snippet-code-css lang-css prettyprint-override"><code>i {
    background: grey;
    transition: background 0.3s ease-out;
    position: absolute;
    width: 5px;
    height: 5px;
}</code></pre>
</div>
</div>
</p>
</div>
<div class="post-text" itemprop="text">
<p>Not sure it is how ThreadPool and other libraries are implemented but here is a hint : use Queues to count how many tasks/threads are running.<br/>
I didn't try this code but it can give you an idea: we create a Thread checking every 0.2 second if we should start another Thread.<br/>
This implies a lot of context switching however and might not be efficient.</p>
<pre><code>class Pool:
    def __init__(self, func: Callable, params: list, thread_max = 10):
        self.func = func
        self.params = params
        self.running = 0
        self.finished = []
        self.thread_max = thread_max
        self.threads = []

    def start(self):
        Thread(target=check, args=(0.2)).start()

    def check(self, t_sleep=0.5):
        done = False
        while not done:
            sleep(t_sleep)
            # first check for finished threads
            for t in threads:
                if not t.isAlive():
                    # do something with return value
                    # ...
                    self.threads.remove(t)

            if not len(self.params): # mean there is no more task left to LAUNCH
                done = len(self.threads) # gonna be 0 when every tasks is COMPLETE
                continue # avoid the next part (launching thread)

            # now start some threads if needed
            while len(self.threads) &lt; self.thread_max:
                arg = self.params.pop()
                thread = Thread(target=self.func, args=(arg, ))
                threads.insert(thread)
                thread.start()
</code></pre>
<h3>I however do not have any clue for async/await (keywords now available in python)</h3>
</div>
<div class="post-text" itemprop="text">
<p>In python, the thread pool only uses 1 cpu core. But since your task is I/O bounded, it will do better than serial execution of the 10k function calls.</p>
<p>To do better, you can try process pool, which can utilize multiple cores. Or even combine asyncio with processes. Depending on your problem, there may or may not be further speedup using these two approaches, using thread pool as baseline. </p>
<p>See <a href="https://pymotw.com/3/asyncio/executors.html#processes" rel="nofollow noreferrer">this example of combining thread/process with asyncio</a>. It should work for your case directly. Your function <code>f</code> is the equivalent of their function <code>block</code>.</p>
<p>In Python 3.6, the general form of asyncio code is to create an event loop to run an async function. A very simple example is</p>
<pre><code>import asyncio

async def coroutine():
    print('in coroutine')

coro = coroutine()
event_loop = asyncio.get_event_loop()

event_loop.run_until_complete(coro)
event_loop.close()
</code></pre>
<p>For simplicity, you can think of the return of the <code>async def</code> function is something to be executed (a coroutine), and the loop executes it. If there are N tasks to be executed asynchronuously, you can define them with N <code>async def</code> functions, and another one that <code>await</code>s them. This very last <code>async</code> function defines what 'finish' means for the N tasks. For example, maybe 'finish' means all N tasks are done, or whenever 1 of them is done, etc. And the loop executes this N+1'th function.</p>
<p>In Python 3.7, the asyncio APIs changed a little, and the loop doesn't need to be created explicitly.
You can find some examples in <a href="https://nosarthur.github.io/coding/2018/12/03/asyncio.html" rel="nofollow noreferrer">my blog post</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>To have a similar behaviour that nodejs you have To use reactive x programming. What you are looking for is rxpy . 
<a href="https://github.com/ReactiveX/RxPY" rel="nofollow noreferrer">https://github.com/ReactiveX/RxPY</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Late answer, but the way I normally handle multiple threads with a maximum thread limit of <code>X</code>, is as follows:</p>
<pre><code>import threading
import requests, json
import time
from urllib.parse import urlparse

final_dict = {} # will hold final results

def parser(u):
    try:
        parsed_uri = urlparse(u) # parse url to get domain name that'l be used as key in final_dict
        domain = "{uri.netloc}".format(uri=parsed_uri)
        x = requests.get(u)
        status_code = x.status_code
        headers = x.headers
        cookies = x.cookies
        # OR cookies = ";".join(f"{k}:{v}" for k,v in x.cookies.iteritems())
        html = x.text
        # do something with the parsed url, in this case, I created a dictionary containing info about the parsed url: timestamp, url, status_code, html, headers and cookies
        if not domain in final_dict:
            final_dict[domain] = []
        final_dict[domain].append( {'ts': time.time(), 'url': u, 'status': status_code , 'headers': str(headers), 'cookies': str(cookies), 'html': html} )

    except Exception as e:
        pass
        print(e)
        return {}

max_threads = 10
urls = ['https://google.com','https://www.facebook.com', 'https://google.com/search?q=hello+world', 'https://www.facebook.com/messages/', 'https://google.com/search?q=learn+python', 'https://www.facebook.com/me/photos', 'https://google.com/search?q=visit+lisboa', 'https://www.facebook.com/me/photos_albums']

for u in urls:
    threading.Thread(target=parser, args=[u]).start()
    tc = threading.active_count()
    while tc == max_threads:
        tc = threading.active_count()
        time.sleep(0.2)

while tc != 1: # wait for threads to finish, when tc == 1 no more threads are running apart from the main process.
    tc = threading.active_count()
    time.sleep(0.2)

print(json.dumps(final_dict))

'''
# save to file
with open("output.json", "w") as f:
    f.write(json.dumps(final_dict))

# load from file
with open("output.json") as f:
    _json = json.loads(f.read())
'''
</code></pre>
<hr/>
<p><strong>Output:</strong></p>
<ol>
<li>Please check the <code>json</code> generated above at: <a href="https://jsoneditoronline.org/?id=403e55d841394a5a83dbbda98d5f2ccd" rel="nofollow noreferrer">https://jsoneditoronline.org/?id=403e55d841394a5a83dbbda98d5f2ccd</a></li>
<li>The code above is, some how, "my own code" and by this I mean that it was used in a previous project and it may not fully answer your question, still, hope it's a good resource for future users.   </li>
<li>On <code>Linux</code> I normally set <code>max_threads</code> to <code>250</code> and on <code>Windows</code> to
around <code>150</code>.</li>
</ol>
<hr/>
<p><a href="https://i.stack.imgur.com/SmESr.jpg" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/SmESr.jpg"/></a></p>
</div>
<span class="comment-copy">You donâ€™t need a thread pool to do this in Node.js. (You would if your tasks were CPU-bound, but Node is all about evented I/O on a single thread.) Anyway, see the <code>concurrency</code> option in <a href="http://bluebirdjs.com/docs/api/promise.map.html" rel="nofollow noreferrer">bluebirdjs.com/docs/api/promise.map.html</a>, and probably <a href="https://www.npmjs.com/package/request-promise" rel="nofollow noreferrer">npmjs.com/package/request-promise</a> for convenience.</span>
<span class="comment-copy">Promise are a nice alternative for callback, but you can't control how many task you are starting. Here I don't want to run the <code>f()</code> function 10K times at the same moment.</span>
<span class="comment-copy">Not only <i>can</i> you control how many tasks youâ€™re starting, the <code>concurrency</code> option I linked to will do it all for you.</span>
<span class="comment-copy">Okay, your comment was not refreshed when I wrote mine. My question is more about <i>how is it done</i> than <i>it could be done with some tools</i>. Thanks anyway for the link</span>
<span class="comment-copy">Thank you for helping me understanding pooling. But your solution isn't really efficient, is it ? I'd like to hear a bit more about async/await too.</span>
