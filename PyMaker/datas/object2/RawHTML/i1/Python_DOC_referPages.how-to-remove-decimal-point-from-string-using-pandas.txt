<div class="post-text" itemprop="text">
<p>I'm reading an xls file and converting to csv file in databricks using pyspark.
My input data is of string format 101101114501700 in the xls file. But after converting it to CSV format using pandas and writing to the datalake folder my data is showing as 101101114501700.0. My code is given below. Please help me why am I getting the decimal part in the data.</p>
<pre><code>for file in os.listdir("/path/to/file"):
     if file.endswith(".xls"):
       filepath = os.path.join("/path/to/file",file)         
       filepath_pd = pd.ExcelFile(filepath)
       names = filepath_pd.sheet_names        
       df = pd.concat([filepath_pd.parse(name) for name in names])        
       df1 = df.to_csv("/path/to/file"+file.split('.')[0]+".csv", sep=',', encoding='utf-8', index=False)
       print(time.strftime("%Y%m%d-%H%M%S") + ": XLS files converted to CSV and moved to folder"
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Your question has nothing to do with Spark or PySpark. It's related to <a href="https://pandas.pydata.org/" rel="nofollow noreferrer">Pandas</a>.</p>
<p>This is because Pandas interpret and infer columns' data type automatically. Since all the values of your column are numeric, Pandas will consider it as <code>float</code> data type.</p>
<p>To avoid this, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.ExcelFile.parse.html#pandas.ExcelFile.parse" rel="nofollow noreferrer"><code>pandas.ExcelFile.parse</code></a> method accepts an argument called <code>converters</code>, you could use this to tell Pandas the specific column data type by:</p>
<pre><code># if you want one specific column as string
df = pd.concat([filepath_pd.parse(name, converters={'column_name': str}) for name in names])
</code></pre>
<p>OR</p>
<pre><code># if you want all columns as string
# and you have multi sheets and they do not have same columns
# this merge all sheets into one dataframe
def get_converters(excel_file, sheet_name, dt_cols):
    cols = excel_file.parse(sheet_name).columns
    converters = {col: str for col in cols if col not in dt_cols}
    for col in dt_cols:
        converters[col] = pd.to_datetime
    return converters

df = pd.concat([filepath_pd.parse(name, converters=get_converters(filepath_pd, name, ['date_column'])) for name in names]).reset_index(drop=True)
</code></pre>
<p>OR</p>
<pre><code># if you want all columns as string
# and all your sheets have same columns
cols = filepath_pd.parse().columns
dt_cols = ['date_column']
converters = {col: str for col in cols if col not in dt_cols}
for col in dt_cols:
    converters[col] = pd.to_datetime
df = pd.concat([filepath_pd.parse(name, converters=converters) for name in names]).reset_index(drop=True)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think the field is automatically parsed as float when reading the excel. I would correct it afterwards:</p>
<pre><code>df['column_name'] = df['column_name'].astype(int)
</code></pre>
<p>If your column contains Nulls you canÂ´t convert to integer so you will need to fill nulls first:</p>
<pre><code>df['column_name'] = df['column_name'].fillna(0).astype(int)
</code></pre>
<p>Then you can concatenate and store the way you were doing it</p>
</div>
<span class="comment-copy">Thanks Yuan for your reply. I have tried your solution but apparently dtype is not supported with Python engine. Any other solution you may have please share .Many thanks in advance</span>
<span class="comment-copy">updated the answer</span>
<span class="comment-copy">Thanks Yuan, for one column it is working fine.If for multiple columns then how to make it as generic?</span>
<span class="comment-copy">I updated the answer, it unions all your sheets into one <code>dataframe</code> and converts all columns of all sheets into <code>string</code></span>
<span class="comment-copy">Thanks Yuan, it works good for number columns but for date(2019-03-19) data it is appending like this 2019-03-19 00:00:00. Can you please let me know why this is causing ? And can we do the same thing using read_excel is it possible with this one</span>
<span class="comment-copy">Thanks gigorio for your reply.But i need that  column to be in string because after converting to csv i'm doing substr for some columns.Can i have alternate solution using read_excel one?</span>
<span class="comment-copy">df['column_name'] = df['column_name'].fillna(0).astype(int).astype(str)</span>
