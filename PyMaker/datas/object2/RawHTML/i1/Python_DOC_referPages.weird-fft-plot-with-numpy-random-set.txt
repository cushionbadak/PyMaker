<div class="post-text" itemprop="text">
<p>Code below:</p>
<pre><code>import numpy as np 
from numpy import random_intel
import mkl_fft
import matplotlib.pyplot as plt

n = 10**5
a = np.random_intel.rand(n)
b = mkl_fft.fft(a)
plt.scatter(b.real,b.imag)
plt.show()
print(b)
for i in b :
    if i.real &gt; n/2:
        print("Weird FFT Number is ",i)
</code></pre>
<p>Result is :
<img alt="output" src="https://i.stack.imgur.com/Um1Qx.png"/></p>
<p>You can see:</p>
<pre><code>Weird FFT Number is  (50020.99077289924+0j)
</code></pre>
<p>Why FFT with random set came out one particular number?</p>
<hr/>
<p>(Thanks to Paul Panzer &amp; SleuthEye)</p>
<p>With <code>mkl_fft.fft(a-0.5)</code> the final result is:
<a href="https://i.stack.imgur.com/npnks.png" rel="nofollow noreferrer"><img alt="final result" src="https://i.stack.imgur.com/npnks.png"/></a></p>
<hr/>
<p>[2019/03/29 Updated]</p>
<p>With normalized data everything went well</p>
<p><code>b = mkl_fft.fft((a - np.mean(a))/np.std(a))</code></p>
<p>The average value of  <code>(a - np.mean(a))/np.std(a)</code> is near zero</p>
</div>
<div class="post-text" itemprop="text">
<p>That is the constant or zero frequency mode, which is essentially the mean of your signal. You are sampling uniformly from the unit interval, so the mean is ~0.5. Some fft implementations scale this with the number of points to save a multiplication.</p>
</div>
<div class="post-text" itemprop="text">
<p>The large value in the FFT output happens to be the very first one which corresponds to the DC component. This indicates that the input has a non-zero average value over the entire data set. </p>
<p>Indeed if you look closer at the input data, you might notice that the values are always between 0 and 1, with an average value around 0.5. This is consistent with the <code>rand</code> function implementation which provides pseudo-random samples drawn from a uniform distribution over [0, 1).</p>
<p>You may confirm this to be the case by subtracting the average value with</p>
<pre><code>b = mkl_fft.fft(a - np.mean(a))
</code></pre>
<p>and noting that the large initial value <code>b[0]</code> should be near zero.</p>
</div>
<span class="comment-copy"><i>"decreases significantly to be of similar magnitude as the others"</i> Don't think so, should be zero up to numerical noise. Whereas the other modes should be distinct from zero.</span>
<span class="comment-copy">I based that statement on the fact that typically a random variable with zero expected value would still have some non-zero average value, but you are right that in this specific case where the mean is constructed to be exactly zero, <code>b[0]</code> should be very near zero.</span>
<span class="comment-copy">Yep, I think you are correct if instead of the sample mean you subtract the true mean, which should be 0.5 (-resolution/2 if we want to be pedantic).</span>
<span class="comment-copy">I found out a ultimate solution :<code>b = mkl_fft.fft((a - np.mean(a))/np.std(a))</code></span>
