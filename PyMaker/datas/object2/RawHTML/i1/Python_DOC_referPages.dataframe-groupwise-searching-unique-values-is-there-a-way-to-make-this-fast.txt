<div class="post-text" itemprop="text">
<p><strong>Task:</strong><br/>
In a dataframe of columns product, day, pgroup, price  (logical key = product, day) for some of the rows column pgroup is empty. If there are other datasets for this product containing a value it should be used for the empty datasets.</p>
<p>Currently I am looping over products, searching unique values of group for each product. 
I would like to do this in a faster way.</p>
<p><strong>Example:</strong></p>
<p><strong>Data:</strong> </p>
<pre><code>df = pd.DataFrame([['a','2018-02-03','G1',47],
              ['a','2018-02-04',None,25],
              ['a','2018-02-05','G1',10],
              ['a','2018-02-06',None,22],
              ['a','2018-02-07',None,84],
              ['b','2018-02-03',None,10],
              ['b','2018-02-04',None,21],
              ['b','2018-02-05',None,2],
              ['b','2018-02-06','G2',18],
              ['b','2018-02-07','G2',11],
              ['c','2018-02-03','G2',63],
              ['c','2018-02-04','G2',83],
              ['c','2018-02-05',None,20],
              ['c','2018-02-06',None,68],
              ['c','2018-02-07',None,33]])
df.columns = ['product','day','pgroup', 'value']
</code></pre>
<p><strong>Code:</strong> </p>
<pre><code># Loop for each product
for xprod in df['product'].unique().tolist():
    # find unique values for pgroup
    unique_values = df[df['product'] == xprod]['pgroup'].unique()
    # Change Datatypes because of NaN-Values in Series
    unique_values_str = [str(i) for i in unique_values]
    # 2 values, first is NaN =&gt; take second 
    if len(unique_values_str) == 2 and (unique_values_str[0] == 'nan'):
        df.loc[df['product'] == xprod, 'pgroup'] = unique_values_str[1]
    # 2 values, second is NaN =&gt; take first
    elif len(unique_values_str) == 2 and (unique_values_str[1] == 'nan'):
        df.loc[df['product'] == xprod, 'pgroup'] = unique_values_str[0] 
</code></pre>
<p><strong>Expected result:</strong></p>
<pre><code>    product     day         pgroup  value
0   a           2018-02-03  G1      47
1   a           2018-02-04  G1      25
2   a           2018-02-05  G1      10
3   a           2018-02-06  G1      22
4   a           2018-02-07  G1      84
5   b           2018-02-03  G2      10
6   b           2018-02-04  G2      21
7   b           2018-02-05  G2      2
8   b           2018-02-06  G2      18
9   b           2018-02-07  G2      11
10  c           2018-02-03  G2      63
11  c           2018-02-04  G2      83
12  c           2018-02-05  G2      20
13  c           2018-02-06  G2      68
14  c           2018-02-07  G2      33
</code></pre>
<p><strong>Annotation:</strong><br/>
According to my examination the parts that take most of the time are the first two lines:</p>
<pre><code> # Loop for each product
    for xprod in df['product'].unique().tolist():
        # find unique values for pgroup
        unique_values = df[df['product'] == xprod]['pgroup'].unique()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This feels a bit hacky, and i dont know really how it will perform but i think it should be a little quicker. </p>
<pre><code>df2 = df
df2['pgroup'] = df.groupby(['product'])['pgroup'].transform(lambda x : repr(set(x) - set([None]) ).replace("{'",'').replace("'}",'') )
</code></pre>
<p>You might also have to change how it tidies up the string produced from repr if it causes any problems with the values that pgroup can take.</p>
</div>
<span class="comment-copy">Your MWE is broken. What is <code>col_1</code>?</span>
<span class="comment-copy">Thanks and sorry.  <code>col_1</code> should have been <code>pgroup</code>. I changed this.</span>
<span class="comment-copy">Great. In my case it improves performance by factor 10-20.  Note: I had to replace <code>None</code> by <code>pd.nan</code> <code>df2.groupby(['product'])['pgroup'].transform(lambda x : repr(set(x) - set([np.nan] )).replace("{'",'').replace("'}",''))</code></span>
<span class="comment-copy">May I ask an additional question:  To achieve an even better performance:   Is it possible to restrict this logic to groups which contain <code>NaN</code>/ <code>None</code> values ?</span>
<span class="comment-copy">To be honest i'm not sure, it probably worth another question. I wouldnt have thought it would speed the query up that much up though even if you could as you would still need to perform an operation on each of the groups to check for the presence of the nan while the only real time gain is removing the need to convert the group into a set which isnt that time consuming.</span>
