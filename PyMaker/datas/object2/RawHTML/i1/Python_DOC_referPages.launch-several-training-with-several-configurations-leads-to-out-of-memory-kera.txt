<div class="post-text" itemprop="text">
<p>I want to train a model with several configurations (apprx 100 differents cases). My main algorithm is on a main .py file which I want to launch 100 times. This .py file works well and everything is going ok if I execute it one time.</p>
<p>I created another .py files which call the first one and give every parameters to it. The problem is that at a random time during the second training, I have an ResourceExhaustedError.</p>
<pre><code>ResourceExhaustedError: OOM when allocating tensor with shape[4096,1] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
 [[node predictions_16/random_uniform/RandomUniform (defined at /home/acarlier/venv/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:4139)  = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=87654321, seed2=7886430, _device="/job:localhost/replica:0/task:0/device:GPU:0"](predictions_16/random_uniform/shape)]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
</code></pre>
<p>I have a GTX 1060 6gb. So I think that the main .py file is not well closed beetween two iterations. Is it possible to close it (in a clean way) and launch it for the others training ?</p>
<p>Thanks you</p>
<p>EDIT:</p>
<p>I tried to :</p>
<pre><code>from my_main_keras_file import train_function

train_function(all my parameters)

del train_function
</code></pre>
<p>But I still have the same problem, the del is not deleting all things which have been created during the execution of the function.</p>
</div>
<div class="post-text" itemprop="text">
<p>I added keras.backend.clear_session() at the end of my training .py file. This clear the session as expected and I'm now able to compute several training one by one !</p>
<p>Thanks you @sebrockm</p>
</div>
<span class="comment-copy">That sounds more like you don't have the resources to run 100 training loops at the same time, nothing to do with the main .py file.</span>
<span class="comment-copy">@nuric indeed. holding the training data in ram 100 times seems to be the problem here ... it says so right in the error message: OOM -&gt; Out Of Memory.</span>
<span class="comment-copy">I'm okay that it can't be computed in the same time, but, it works well 1 time. So why I can't do a for loop in which I compute 1 train each loop ?</span>
<span class="comment-copy">I'm searching like a way to clear all the datas created by the import and then re-import this part of the project</span>
<span class="comment-copy">Have you tried <a href="https://stackoverflow.com/questions/52133347/how-can-i-clear-a-model-created-with-keras-and-tensorflowas-backend" title="how can i clear a model created with keras and tensorflowas backend">stackoverflow.com/questions/52133347/â€¦</a> ?</span>
