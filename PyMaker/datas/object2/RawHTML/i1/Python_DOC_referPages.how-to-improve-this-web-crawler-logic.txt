<div class="post-text" itemprop="text">
<p>Im working on a web crawler that will crawl only internal links using requests and bs4.</p>
<p>I have a rough working version below but Im not sure how to properly handle checking if a link has been crawled previously or not.</p>
<pre><code>import re
import time
import requests
import argparse
from bs4 import BeautifulSoup


internal_links = set()

def crawler(new_link):


    html = requests.get(new_link).text 
    soup = BeautifulSoup(html, "html.parser")
    for link in soup.find_all('a', attrs={'href': re.compile("^http://")}):
        if "href" in link.attrs:
            print(link)
            if link.attrs["href"] not in internal_links:
                new_link = link.attrs["href"]
                print(new_link)
                internal_links.add(new_link)
                print("All links found so far, ", internal_links)
                time.sleep(6)
                crawler(new_link)


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('url', help='Pass the website url you wish to crawl')
    args = parser.parse_args()

    url = args.url

    #Check full url has been passed otherwise requests will throw error later

    try:
        crawler(url)

    except:
        if url[0:4] != 'http':
            print('Please try again and pass the full url eg http://example.com')



if __name__ == '__main__':
    main()
</code></pre>
<p>These are the last few lines of the output:</p>
<pre><code>All links found so far,  {'http://quotes.toscrape.com/tableful', 'http://quotes.toscrape.com', 'http://quotes.toscrape.com/js', 'http://quotes.toscrape.com/scroll', 'http://quotes.toscrape.com/login', 'http://books.toscrape.com', 'http://quotes.toscrape.com/'}
&lt;a href="http://quotes.toscrape.com/search.aspx"&gt;ViewState&lt;/a&gt;
http://quotes.toscrape.com/search.aspx
All links found so far,  {'http://quotes.toscrape.com/tableful', 'http://quotes.toscrape.com', 'http://quotes.toscrape.com/js', 'http://quotes.toscrape.com/search.aspx', 'http://quotes.toscrape.com/scroll', 'http://quotes.toscrape.com/login', 'http://books.toscrape.com', 'http://quotes.toscrape.com/'}
&lt;a href="http://quotes.toscrape.com/random"&gt;Random&lt;/a&gt;
http://quotes.toscrape.com/random
All links found so far,  {'http://quotes.toscrape.com/tableful', 'http://quotes.toscrape.com', 'http://quotes.toscrape.com/js', 'http://quotes.toscrape.com/search.aspx', 'http://quotes.toscrape.com/scroll', 'http://quotes.toscrape.com/random', 'http://quotes.toscrape.com/login', 'http://books.toscrape.com', 'http://quotes.toscrape.com/'}
</code></pre>
<p>so it is working, but only up until a certain point and then it doesn't seem to follow the links any further.</p>
<p>Im sure its because of this line</p>
<pre><code>for link in soup.find_all('a', attrs={'href': re.compile("^http://")}):
</code></pre>
<p>as that will only find the links that start with http and on a lot of the internal pages the links dont have that but when I try it like this</p>
<pre><code>for link in soup.find_all('a')
</code></pre>
<p>the program runs very briefly and then ends:</p>
<pre><code>http://books.toscrape.com
{'href': 'http://books.toscrape.com'}
http://books.toscrape.com
All links found so far,  {'http://books.toscrape.com'}
index.html
{'href': 'index.html'}
index.html
All links found so far,  {'index.html', 'http://books.toscrape.com'}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could reduce </p>
<pre><code>for link in soup.find_all('a', attrs={'href': re.compile("^http://")}):
        if "href" in link.attrs:
            print(link)
            if link.attrs["href"] not in internal_links:
                new_link = link.attrs["href"]
                print(new_link)
                internal_links.add(new_link)
</code></pre>
<p>To</p>
<pre><code>links = {link['href'] for link in soup.select("a[href^='http:']")}
internal_links.update(links)  
</code></pre>
<p>This uses a grabs only qualifying a tag elements with http protocol and uses a set comprehension to ensure no dupes. It then updates the existing set with any new links. I don't know enough python to comment on efficiency of using .update but I believe it modifies the existing set rather than creating a new one. More methods for combining sets are listed here: <a href="https://stackoverflow.com/questions/17429123/how-to-join-two-sets-in-one-line-without-using">How to join two sets in one line without using "|"</a></p>
</div>
<span class="comment-copy">thanks, this partially works but it still has the problem of not being able to find links without the http eg &lt;a href="/author/Albert-Einstein"&gt;(about)&lt;/a&gt; and thus its just crawling the top level pages and not going any deeper.</span>
<span class="comment-copy">That should also be easy. I will update.</span>
<span class="comment-copy">Do the relative paths always start with /author?</span>
<span class="comment-copy">Can you supply an example url? You would simply add the selector for the relative href urls to the existing selector using css Or  syntax  soup.select("a[href^='http:'], a[href^='/']     ")    Not sure if you need to escape that last / with //</span>
<span class="comment-copy">I was testing against <a href="http://toscrape.com" rel="nofollow noreferrer">toscrape.com</a> but that site doesn't use full paths for internal links which is why it wasn't finding them all. Ive tried it with a site with full url paths and now it works, ideally this would work for both situations but this will do for now thanks. I will post my finished code soon and mark the answer.</span>
