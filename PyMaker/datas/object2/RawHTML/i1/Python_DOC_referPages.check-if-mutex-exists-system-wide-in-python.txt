<div class="post-text" itemprop="text">
<p>I have a python program than may be called several times at any time by some scheduler.</p>
<p>It generates a string following some pattern and I want to make sure that this string hasn't been generated by another process running at the same time (lock string). If so, it has to generate a new string following the same pattern and check again that if doesn't exists. If a process ends, the related string can be reused by a new one (unlock string).</p>
<p>Example:</p>
<pre><code>t=0 
  process 1 - "string_1"

t=1 (process_1 finished)
  process 2 - "string_1"
  process 3 - "string_2" (cause "string_1" already exists)

t=2 (process 2 and 3 still running)
  process 4 - "string_3"

t=3 (procces 3 finished)
  process 5 - "string_2"

and so on...
</code></pre>
<p>Any ideas how to achieve this "sort of" system-wide mutex based on strings?</p>
</div>
<div class="post-text" itemprop="text">
<p>You could coordinate processes using some global resource, such as the filesystem.
Create a file named <code>/tmp/string_1</code> to claim that string, or append string_1 to <code>/tmp/log</code> or something.
Use filesystem locking if desired, or a coordinating <a href="https://docs.python.org/3/library/threading.html#threading.Lock" rel="nofollow noreferrer">mutex</a>.</p>
<p>But it would be simpler to just append a uuid to each string.
High entropy unique IDs are <a href="https://docs.python.org/3/library/uuid.html" rel="nofollow noreferrer">easy to generate</a>.
Depending on request rates, you may be able to get away with using truncated IDs.</p>
<p>If you really do need a counter, consider having a single producer maintain it, and hand out unique IDs.
Simplest way would be via a <a href="https://docs.python.org/3/library/queue.html#queue.Queue" rel="nofollow noreferrer">queue</a>.
Producer writes to the queue, and consumers read IDs from it.</p>
</div>
<div class="post-text" itemprop="text">
<p>Let's put this code as an example of what I want using fcntl:</p>
<pre><code>import fcntl, time

def my_function():
    n = 0
    while n &lt; 10:
        str = "string_{}".format(n)
        try:
            f = open('/tmp/{}'.format(str))
            print("Attempting to lock {}".format(f.name))
            fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)
            time.sleep(3)
            return str
        except IOError:
            n += 1
    if n == 10:
        raise Exception("All options are in use")

def main():
    str = my_function()
    print(str)
    time.sleep(5)

if __name__ == "__main__":
    main()
</code></pre>
<p>The problem here is that when <code>my_function()</code> finishes the locking is gone, and if I call this script at that time (before main() ends), it will select the same string. Is there a way to keep that lock until the full script has ended execution?</p>
</div>
<span class="comment-copy">Just tried using fcntl, see answer above.</span>
<span class="comment-copy">Your central complaint seems to be about script / lock lifetime, you want to hold the lock for longer. You hold it for 3s but not the full 8s. Notice that the lock lasts exactly as long as the open file descriptor. When you exit the function, cPython decrements the ref count on <code>f</code> down to zero as it goes out of scope, and closes the file descriptor, releasing the lock. For that particular lock to be long lived, you have to keep the descriptor alive. For example, the function could return a (name, filedesc) tuple to <code>main</code>, and you could make <code>main</code> responsible for closing / releasing it.</span>
