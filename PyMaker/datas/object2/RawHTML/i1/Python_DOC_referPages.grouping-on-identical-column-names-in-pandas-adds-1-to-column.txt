<div class="post-text" itemprop="text">
<p>I am trying to group identical columns in a single dataframe, similar to this question: <a href="https://stackoverflow.com/questions/53940035/grouping-on-identical-column-names-in-pandas">Grouping on identical column names in pandas</a></p>
<p>However that answer is not working for me. When I apply the accepted answer to that question, my dataframe has '.1' added to the second iteration of the duplicated columns. My duplicated columns do not have duplicated data, which may be the problem?</p>
<p>Here is my table:</p>
<pre><code>Timepoint Col1 Col2 Col3 Col1 Col2 Col3

   1       1    2   3
   2       4    5   6
   3                      7    8    9
   4                      10   11   12
</code></pre>
<p>I would like the table to look like this:</p>
<pre><code>Timepoint Col1 Col2 Col3 
     1     1    2   3
     2     4    5   6
     3     7    8   9
     4     10   11  12
</code></pre>
<p>But the table looks like this when I apply the linked code:</p>
<pre><code>Timepoint Col1 Col2 Col3 Col1.1 Col2.1 Col3.1

   1       1    2   3
   2       4    5   6
   3                      7      8     9
   4                      10     11    12
</code></pre>
<p>My dataframe has hundreds of columns so I need a solution that doesn't specify the columns that need to be grouped.</p>
<p>Note that this is not a duplicate of this question:<a href="https://stackoverflow.com/questions/45970751/shift-nans-to-the-end-of-their-respective-rows">Shift NaNs to the end of their respective rows</a> because that question does not have duplicated column names and it shifts data to a differently labeled column.</p>
</div>
<div class="post-text" itemprop="text">
<p>Create index by <code>Timepoint</code> by <a href="http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.set_index.html" rel="nofollow noreferrer"><code>DataFrame.set_index</code></a>, then use <code>groupby</code> with lambda function with <code>split</code> and aggregate <code>sum</code>, or <code>max</code>, or <code>mean</code> or <code>first</code>. Aggregation method depends of data, but if always mising values like in sample data output is always same:</p>
<pre><code>df = (df.set_index('Timepoint')
       .groupby(lambda x: x.split('.')[0], axis=1).sum()
       .reset_index())
print (df)
   Timepoint  Col1  Col2  Col3
0          1   1.0   2.0   3.0
1          2   4.0   5.0   6.0
2          3   7.0   8.0   9.0
3          4  10.0  11.0  12.0
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>an example of solution:</p>
<pre><code>import pandas as pd


data = """
Timepoint,Col1,Col2,Col3,Col1,Col2,Col3
1,1,2,3,,,
2,4,5,6,,,
3,,,,7,8,9
4,,,,10,11,12 
"""
df = pd.read_csv(pd.compat.StringIO(data), sep=',')
df.rename(columns=lambda x: x.split('.')[0], inplace=True)
print(df)
</code></pre>
<p>output:</p>
<pre><code>   Timepoint  Col1  Col2  Col3  Col1  Col2  Col3
0          1   1.0   2.0   3.0   NaN   NaN   NaN
1          2   4.0   5.0   6.0   NaN   NaN   NaN
2          3   NaN   NaN   NaN   7.0   8.0   9.0
3          4   NaN   NaN   NaN  10.0  11.0  12.0
</code></pre>
<hr/>
<pre><code>df = df.fillna(0)
print(df)
</code></pre>
<p>output:</p>
<pre><code>   Timepoint  Col1  Col2  Col3  Col1  Col2  Col3
0          1   1.0   2.0   3.0   0.0   0.0   0.0
1          2   4.0   5.0   6.0   0.0   0.0   0.0
2          3   0.0   0.0   0.0   7.0   8.0   9.0
3          4   0.0   0.0   0.0  10.0  11.0  12.0
</code></pre>
<hr/>
<pre><code>df = df.groupby(level=0, axis=1).sum()
print(df)
</code></pre>
<p>output:</p>
<pre><code>   Col1  Col2  Col3  Timepoint
0   1.0   2.0   3.0        1.0
1   4.0   5.0   6.0        2.0
2   7.0   8.0   9.0        3.0
3  10.0  11.0  12.0        4.0
</code></pre>
</div>
<span class="comment-copy">What do you have in your 'empty' rows ? NaNs ?</span>
<span class="comment-copy">Sure, wrong dupe, so reopened.</span>
<span class="comment-copy">How working my solution?</span>
<span class="comment-copy">It appears that jezrael has the correct solution. Thank you!</span>
<span class="comment-copy">I can't use .sum() because there could be places where data has been duplicated. I tried df = df.groupby(level=0, axis=1).mean(), which is the solution in the original problem I linked to. Unfortunately that code isn't working for me.</span>
