<div class="post-text" itemprop="text">
<p>I am trying to scrape a set of webpages.  When I scrape from one webpage directly, I am able to access the html.  However, when I iterate through a pd dataframe to scrape a set of webpages, even a dataframe with only one row, I see a truncated html and cannot extract my desired data.</p>

Iterating through a dataframe of 1 row:

<pre><code>import pandas as pd
from urllib.request import urlopen
from bs4 import BeautifulSoup
import requests
import re

first_names = pd.Series(['Robert'], index = [0])
last_names = pd.Series(['McCoy'], index = [0])
names = pd.DataFrame(columns = ['first_name', 'last_name'])
names['first_name'] = first_names
names['last_name'] = last_names

freq = []

for first_name, last_name in names.iterrows():
    url = "https://zbmath.org/authors/?q={}+{}".format(first_name, 
    last_name)
    r = requests.get(url)
    html = BeautifulSoup(r.text)
    html=str(html)
    frequency = re.findall('Joint\sPublications"&gt;(.*?)&lt;/a&gt;', html)
    freq.append(frequency)

print(freq)
</code></pre>
<p>[[]]</p>

Accessing the webpage directly.  Same code, but now not blocked.

<pre><code>url = "https://zbmath.org/authors/?q=robert+mccoy"
r = requests.get(url)
html = BeautifulSoup(r.text)
html=str(html)
frequency = re.findall('Joint\sPublications"&gt;(.*?)&lt;/a&gt;', html)
freq.append(frequency)

print(freq)
</code></pre>
<p>[[], ['10', '8', '6', '5', '3', '3', '2', '2', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1']]</p>
<p>How can I loop through multiple webpages but not get blocked?</p>
</div>
<div class="post-text" itemprop="text">
<p>Iterrows returns a tuple of (index,(columns)), so the solution is to parse it slightly differently:</p>
<pre><code>for _,(first_name, last_name) in names.iterrows():
    url = "https://zbmath.org/authors/?q={}+{}".format(first_name, 
    last_name)
    r = requests.get(url)
    html = BeautifulSoup(r.text)
    html=str(html)
    frequency = re.findall('Joint\sPublications"&gt;(.*?)&lt;/a&gt;', html)
    freq.append(frequency)

print(freq)
</code></pre>
</div>
<span class="comment-copy">First of all, you are likely violating the site's terms of service by hitting them with a bunch of automated requests very quickly. Second, they are likely rate-limiting you based on their DDOS filters. The way around this is to slow your requests to a reasonable amount of traffic, generally using <code>time.sleep</code> between <code>requests.get()</code> calls</span>
<span class="comment-copy">But why would the site block me when I'm iterating through a loop of length one?  In my code above I only hit the site with a single query and I'm still blocked.  (Also I have been using time.sleep and I'm still blocked.)</span>
<span class="comment-copy">Check the output of <code>itterrows</code>. It doesn't give you column values, it gives you tuples of <code>(index, (columns))</code> that you need to parse deeper</span>
<span class="comment-copy">Hm.  I don't think itterrows is the problem, because when I run iterrows and print the html, I still see a proper set of html, albeit one that has all of my desired data truncated.</span>
<span class="comment-copy">The only difference between the working and non-working calls is <code>url = "https://zbmath.org/authors/?q={}+{}".format(first_name,      last_name)</code> vs <code>url = "https://zbmath.org/authors/?q=robert+mccoy"</code>, so have you printed the url string to verify that it is indeed the same?</span>
