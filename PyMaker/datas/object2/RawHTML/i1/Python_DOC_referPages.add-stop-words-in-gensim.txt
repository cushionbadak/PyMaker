<div class="post-text" itemprop="text">
<p>Thanks for stopping by!  I had a quick question about appending stop words. I have a select few words that show up in my data set and I was hopping I could add them to gensims stop word list.  I've seen a lot of examples using nltk and I was hoping there would be a way to do the same in gensim.  I'll post my code below:</p>
<p><div class="snippet" data-babel="false" data-console="true" data-hide="false" data-lang="js">
<div class="snippet-code">
<pre class="snippet-code-html lang-html prettyprint-override"><code>def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) &gt; 3:
            nltk.bigrams(token)
            result.append(lemmatize_stemming(token))
    return result</code></pre>
</div>
</div>
</p>
</div>
<div class="post-text" itemprop="text">
<p>While <code>gensim.parsing.preprocessing.STOPWORDS</code> is pre-defined for your convenience, and happens to be a <code>frozenset</code> so it can't be directly added-to, you could easily make a larger set that includes both those words and your additions. For example:</p>
<pre class="lang-py prettyprint-override"><code>from gensim.parsing.preprocessing import STOPWORDS
my_stop_words = STOPWORDS.union(set(['mystopword1', 'mystopword2']))
</code></pre>
<p>Then use the new, larger <code>my_stop_words</code> in your subsequent stop-word-removal code. (The <code>simple_preprocess()</code> function of <code>gensim</code> doesn't automatically remove stop-words.)</p>
</div>
<div class="post-text" itemprop="text">
<p><div class="snippet" data-babel="false" data-console="true" data-hide="false" data-lang="js">
<div class="snippet-code">
<pre class="snippet-code-html lang-html prettyprint-override"><code>def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        newStopWords = ['stopword1','stopword2']
        if token not in gensim.parsing.preprocessing.STOPWORDS and token not in newStopWords and len(token) &gt; 3:
            nltk.bigrams(token)
            result.append(lemmatize_stemming(token))
    return result</code></pre>
</div>
</div>
</p>
</div>
<span class="comment-copy">Doing two <code>not in</code> tests (<code>token not in gensim.parsing.preprocessing.STOPWORDS and token not in newStopWords</code>) with the second being against a <code>list</code> (which requires a linear probe) will be less efficient than creating your own superset of all your stop-words, as described in my answer, and then doing a single <code>not in</code> test against that. (Membership <code>in</code> tests for <code>set</code> are most efficient, and generally don't become less-efficient against larger sets â€“ but multiple tests, or probes against lists, will slow as more <code>and</code>s or list-entries are added.)</span>
