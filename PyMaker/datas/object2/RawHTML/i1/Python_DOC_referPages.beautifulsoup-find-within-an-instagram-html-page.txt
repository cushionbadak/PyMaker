<div class="post-text" itemprop="text">
<hr/>
<h2>I have a problem to find something with bs4.</h2>
<p>I'm trying to automatically find some urls in an html instagram page and <em>(knowing that I'm a python noob)</em> I can't find the way to search automatically within the html source code the urls who are in the exemple after the <code>"display_url": http..."</code>. </p>
<blockquote>
<p>I want to make my script search multiples url who appears as next as "display_url" and download them.
  They have to be extracted as many times as they appear in the source code.</p>
</blockquote>
<hr/>
<p>With bs4 I tried the :</p>
<pre><code>f = urllib.request.urlopen(fileURL)
htmlSource = f.read()
soup = bs(htmlSource, 'html.parser')
metaTag = soup.find_all('meta', {'property': 'og:image'})
imgURL = metaTag[0]['content']
urllib.request.urlretrieve(imgURL, 'fileName.jpg')
</code></pre>
<p>But I can't make the <code>soup.find_all(...</code> work/search it.
Is there a way for me to find this part of the page with bs4 ?</p>
<p>Thanks a lot for your help.</p>
<p>Here is an exemple of my little (python) code as it is now : <a href="https://repl.it/@ClementJpn287/bs" rel="nofollow noreferrer">https://repl.it/@ClementJpn287/bs</a> </p>
<p><div class="snippet" data-babel="false" data-console="true" data-hide="false" data-lang="js">
<div class="snippet-code">
<pre class="snippet-code-html lang-html prettyprint-override"><code>&lt;!––cropped...............--&gt;

&lt;body class=""&gt;

  &lt;span id="react-root"&gt;&lt;svg width="50" height="50" viewBox="0 0 50 50" style="position:absolute;top:50%;left:50%;margin:-25px 0 0 -25px;fill:#c7c7c7"&gt;
      &lt;path
        d="

        &lt;!––deleted part for privacy --&gt;

         " /&gt;
      &lt;/svg&gt;&lt;/span&gt;


  &lt;script type="text/javascript"&gt;
    window._sharedData = {
      "config": {
        "csrf_token": "",
        "viewer": {
        
        &lt;!––deleted part for privacy --&gt;
   
        "viewerId": ""
      },
      "supports_es6": true,
      "country_code": "FR",
      "language_code": "fr",
      "locale": "fr_FR",
      "entry_data": {
        "PostPage": [{
          "graphql": {
            "shortcode_media": {
              "__typename": "GraphSidecar",
     
     &lt;!––deleted part for privacy --&gt;
     
              "dimensions": {
                "height": 1080,
                "width": 1080
              },
              "gating_info": null,
              "media_preview": null,

&lt;--There's the important part that have to be extracted as many times it appear in the source code--&gt;

              "display_url": "https://scontent-cdt1-1.cdninstagram.com/vp/",
              "display_resources": [{
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 640,
                "config_height": 640
              }, {
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 750,
                "config_height": 750
              }, {
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 1080,
                "config_height": 1080
              }],
              "is_video": false,
       
&lt;!––cropped...............--&gt;</code></pre>
</div>
</div>
</p>
<p><a href="https://i.stack.imgur.com/JksMN.jpg" rel="nofollow noreferrer">my newest code</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You could find the appropriate script tag and regex out the info. I have assumed the first script tag containing <code>window._sharedData =</code> is the appropriate one. You can fiddle as required.</p>
<pre><code>from bs4 import BeautifulSoup as bs
import re

html = '''
&lt;html&gt;
 &lt;head&gt;&lt;/head&gt;
 &lt;body class=""&gt; 
  &lt;span id="react-root"&gt;
   &lt;svg width="50" height="50" viewbox="0 0 50 50" style="position:absolute;top:50%;left:50%;margin:-25px 0 0 -25px;fill:#c7c7c7"&gt; 
    &lt;path d="

        &lt;!––deleted part for privacy --&gt;

         " /&gt; 
   &lt;/svg&gt;&lt;/span&gt; 
  &lt;script type="text/javascript"&gt;
    window._sharedData = {
      "config": {
        "csrf_token": "",
        "viewer": {

        &lt;!––deleted part for privacy --&gt;

        "viewerId": ""
      },
      "supports_es6": true,
      "country_code": "FR",
      "language_code": "fr",
      "locale": "fr_FR",
      "entry_data": {
        "PostPage": [{
          "graphql": {
            "shortcode_media": {
              "__typename": "GraphSidecar",

     &lt;!––deleted part for privacy --&gt;

              "dimensions": {
                "height": 1080,
                "width": 1080
              },
              "gating_info": null,
              "media_preview": null,

&lt;--There's the important part that have to be extracted as many times it appear in the source code--&gt;

              "display_url": "https://scontent-cdt1-1.cdninstagram.com/vp/",
              "display_resources": [{
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 640,
                "config_height": 640
              }, {
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 750,
                "config_height": 750
              }, {
                "src": "https://scontent-cdt1-1.cdninstagram.com/vp/",
                "config_width": 1080,
                "config_height": 1080
              }],
              "is_video": false,&lt;/script&gt;
 &lt;/body&gt;
&lt;/html&gt;
'''

soup = bs(html, 'lxml')
scripts = soup.select('script[type="text/javascript"]')
for script in scripts:
    if ' window._sharedData =' in script.text:
        data = script.text
        break
r = re.compile(r'"display_url":(.*)",')
print(r.findall(data))
</code></pre>
<hr/>
<p>Thanks to @t.h.adam it may be possible to shorten the above to:</p>
<pre><code>soup = bs(html, 'lxml')
r = re.compile(r'"display_url":(.*)",')
data = soup.find('script', text=r).text
print(r.findall(data))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The program advanced and it became something like this :</p>
<pre><code>thepage = urllib.request.urlopen(html)
    soup = BeautifulSoup(thepage, "html.parser")
    print(soup.title.text)
    txt = soup.select('script[type="text/javascript"]')[3] 
    texte = txt.get_text()
    f1 = open("tet.txt", 'w')
    f1.write(texte)
    f1.close() 
    with open('tet.txt','r') as f:
        data=''.join(f.readlines())
    print(data[data.index('"display_url":"'):data.index('","display_resources":')+1])
</code></pre>
<p>But now something new appeared :</p>
<ul>
<li>How to make the finding url part of the program (line 10, 11) repeat as long as the <strong>('</strong> "display_url":" <em>to --&gt;</em> ","display_resources": <strong>')</strong> appear in the <em>tet.txt</em> file ? </li>
<li>The <strong><em>while loop</em></strong> can be used but how to make it repeat the process ?</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<h2>Problem Solved</h2>
<p>Here's the code to download multiples images from an instagram url with Pythonista 3 on iOS:</p>
<pre><code>    from sys import argv
    import urllib
    import urllib.request
    from bs4 import BeautifulSoup 
    import re
    import photos
    import clipboard


    thepage = "your url"
#p.1
    thepage = urllib.request.urlopen(html)
    soup = BeautifulSoup(thepage, "html.parser")
    print(soup.title.text)
    txt = soup.select('script[type="text/javascript"]')[3] 
    texte = txt.get_text()
    fille = open("tet.txt", 'w')
    fille.write(texte)
    fille.close()
#p.2
    g = open('tet.txt','r')
    data=''.join(g.readlines())
    le1 = 0
    le2 = 0
    hturl = open('url.html', 'w')
    still_looking = True
    while still_looking:
        still_looking = False
        dat = data.find('play_url', le1)
        det = data.find('play_resources', le2)
        if dat &gt;= le1:
            #urls.append(dat)
            le1 = dat + 1
            still_looking = True                
        if det &gt;= le2:
            hturl.write(data[dat:det])
            le2 = det + 1
            still_looking = True
    hturl.close()
#p.3
    hturl2 = open('url.html', 'r')
    dete = ''.join(hturl2.readlines())
    le11 = 0
    le22 = 0
    urls = []
    still_looking2 = True
    while still_looking2:
        still_looking2 = False
        dat2 = dete.find('https://scontent-', le11)
        det2 = dete.find('","dis', le22)
        if dat2 &gt;= le11:
            urls.append(dat2)
            le11 = dat2 + 1
            still_looking2 = True                
        if det2 &gt;= le22:
            urls.append(dete[dat2:det2])
            le22 = det2 + 1
            still_looking2 = True   
    hturl2.close()
#p.4
    imgs = len(urls)
    nbind = imgs
    nbindr = 3 
    images = 1
    while nbindr &lt; imgs:
        urllib.request.urlretrieve(urls[nbindr], 'photo.jpg')
        photos.create_image_asset('photo.jpg')
        print ('Image ' + str(images) + ' downloaded')
        nbindr = nbindr +2
        images += 1
    print("OK")
</code></pre>
<p>It's a bit fastidious but it's working and rapidly too.
Thanks for your help.</p>
</div>
<span class="comment-copy">Do you have a couple of example urls to work with?</span>
<span class="comment-copy">Yes and no. Yes any page post page who contains multiples pictures (in the carousel style) but the pages are generated by intagram with our unique user token so I can't really pass it to you as they are... :(</span>
<span class="comment-copy">Yes so for that I tried to add an part of a source code... ^^</span>
<span class="comment-copy">grab the appropriate script tag and regex it</span>
<span class="comment-copy">You can make your code shorter if you use your regex as a <code>text</code> parameter in <code>.find()</code>, eg: <code>data = soup.find('script', text=r).text</code></span>
<span class="comment-copy">You're very welcome! Sometimes it's best to use <code>.find()</code>/<code>.find_all()</code> because they accept regular expressions and functions.</span>
<span class="comment-copy">Hi. As I tried the @t.h.adam idea in my software the outcome became : File "main.py", line 27, in &lt;module&gt;     soup = bs(soup1, 'lxml')   File "/home/runner/.site-packages/bs4/__init__.py", line 244, in <b>init</b>     markup = markup.read() TypeError: 'NoneType' object is not callable.</span>
<span class="comment-copy">is the data dynamically loaded? print soup and verify</span>
<span class="comment-copy">Can't print it because :    <code>in &lt;module&gt;     soup = bs(html, 'lxml')   File "/var/containers/Bundle/Application/93F4D70C-FD37-45C8-80BD-F48B0E2BCCB3/Pythonista3.app/Frameworks/Py3Kit.framework/pylib/site-packages/bs4/__init__.py", line 158, in __init__     % ",".join(features)) bs4.FeatureNotFound: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?</code></span>
