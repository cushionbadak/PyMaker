<div class="post-text" itemprop="text">
<p>I'm really enjoying using PyTorch for classification and regression. I have an interesting new problem to solve and I can't quite figure out the solution, I feel like I'm really close.</p>
<p>My problem:
I have created a network with three outputs, let's call them x, y and z
I have a function F(x, y, z) that returns a value between 0.0 and 100.0 where 100 is better
My custom loss thus is 100-F(x,y,z) at each step
The goal is to figure out the best combination of outputs for problem F(...)
(I know a genetic algorithm will outperform this, that's my project right now to prove it on an array of problems)</p>
<p>To implement the above, I force the network to have 1 piece of input data and a batch size of 1, and then in the loss we just completely ignore the 'true' and 'predicted' values and replace the loss with 100-F(x,y,z). Basically our weights and outputs will lead to one solution at every epoch, and the fitness of this solution is inverse from the maximum possible fitness to give a loss (ie. fitness 100 will result in loss 0, 100-100).</p>
<p>Outputs are rounded to integers since F(...) requires them. To prevent this from being an issue, I have a large momentum and learning rate. </p>
<p>The issue I'm having is that, although the loss function is running and my first [x,y,z] is being evaluated, the values never change. The network isn't learning from the results produced. </p>
<p>My code is as follows:
Note testnetwork() is too long to paste but it is the F(x,y,z) mentioned above - any dummy function can replace it eg. 'return x+z<em>y/2' etc. to minimise this function (100 - x+z</em>y/2)</p>
<pre><code>import torch
import torch.nn as nn

from testnetwork import *


n_in, n_h, n_out, batch_size = 10, 5, 3, 5

x = torch.randn(batch_size, n_in)
y = torch.tensor([[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [0.0], [1.0], [1.0]])

model = nn.Sequential(nn.Linear(n_in, n_h),
                     nn.ReLU(),
                     nn.ReLU()
                     )

def fitness(string):
    print(string)
    list = string.split(",")
    list[0] = (int(round(float(list[0]))))
    list[1] = (int(round(float(list[1]))))
    list[2] = (int(round(float(list[2]))))
    print(list)
    loss = 100 - testnetwork(list[0], list[1], list[2])
    return loss


def my_loss(output, target):
    table = str.maketrans(dict.fromkeys('tensor()'))
    ftn = fitness(str(output.data[0][0]).translate(table) + ", " + str(output.data[0][1]).translate(table) + ", " + str(output.data[0][2]).translate(table))


    loss = torch.mean((output - output)+ftn)

    return loss



#optimizer = torch.optim.SGD(model.parameters(), lr=1, momentum=2)
optimizer = torch.optim.Adam(model.parameters(), lr=1, momentum=2)

for epoch in range(10):
    # Forward Propagation
    y_pred = model(x)
    # Compute and print loss
    loss = my_loss(y_pred, y)
    print('epoch: ', epoch,' loss: ', loss.item())
    # Zero the gradients
    optimizer.zero_grad()

    # perform a backward pass (backpropagation)
    loss.backward(retain_graph=True)

    # Update the parameters
    optimizer.step()
</code></pre>
<p>Thank you so much for reading my post!</p>
<pre><code>epoch:  0  loss:  50.339725494384766
0., 0.0200, 0.6790
[0, 0, 1]
testing: [0, 0, 1]
epoch:  1  loss:  50.339725494384766
0., 0.0200, 0.6790
[0, 0, 1]
testing: [0, 0, 1]
epoch:  2  loss:  50.339725494384766
0., 0.0200, 0.6790
[0, 0, 1]
testing: [0, 0, 1]
epoch:  3  loss:  50.339725494384766
0., 0.0200, 0.6790
[0, 0, 1]
testing: [0, 0, 1]
epoch:  4  loss:  50.339725494384766
0., 0.0200, 0.6790
[0, 0, 1]
</code></pre>
<p>..and so on, nothing seems to change from epoch to epoch.</p>
</div>
<div class="post-text" itemprop="text">
<p>First off, applying two <code>ReLU</code>s after one another is useless and applying one is enough.</p>
<p>second, your problem is in this line</p>
<pre><code>ftn = fitness(str(output.data[0][0]).translate(table) + ", " + str(output.data[0][1]).translate(table) + ", " + str(output.data[0][2]).translate(table))
</code></pre>
<p>you are calling <code>.data</code> which is not a Tensor and can not record backprop operations, so essentially you are calculating your loss on a <code>detached</code> tensor</p>
<p>I think, I know what you are trying to achieve is. in this line:</p>
<pre><code>loss = torch.mean((output - output)+ftn)
</code></pre>
<p>you probably want to <code>detach</code> the second output, it is similar to the <code>stop_grad()</code> of TF.</p>
<pre><code>loss = torch.mean((output - output.detach())+ftn)
</code></pre>
</div>
<span class="comment-copy">For the fitness I just need the values at output so I use that first bit to send the three values to the fitness function (ie to see how that function performs with the three numerical outputs when rounded to an int since f() only accepts ints). How would I perform this action and still retain the backprop learning process? How do you mean to detach the second output, what will it do? output-output is to zero and then I add the fitness since just returning the fitness doesn't work. Would you possibly be able to show me the solution in code? Thank you very much for your suggestions.</span>
<span class="comment-copy">this is a pretty common pattern: <code>(output - output.detach())+ftn</code> here both ftn and detached_output are non-differentiable but output is backward compatible and everything should work (assuming ftn is based on output)</span>
<span class="comment-copy">Removing the ReLu, I just have a linear layer now. I have replaced my loss with the given code suggested in your comment, the weights now do change per epoch (thank you!), but they just keep going down even though after [1,2,0] and [1,1,0] were found to be the same loss, [0,0,0] has a loss of 100 and is worse. Even after this happens, they keep decreasing. The console output is here - <a href="https://pastebin.com/1q0S5MDC" rel="nofollow noreferrer">link</a> see how even though a rule is apparent that [0,0,0] is worse than the previous, the outputs keep decreasing</span>
<span class="comment-copy">ah I see, you are setting <code>loss</code> as <code>output - detached_output + ftn</code> and <code>ftn</code> is almost <code>100-output</code> so they have opposite signs, I think <code>detached-output+ftn</code> will solve your problem</span>
<span class="comment-copy">thanks for the suggestion, if I switch them around then the opposite issue occurs, the outputs simply increase according to learning rate and momentum. <code>ftn</code> is the 'true loss' which is equal to the output of the function where 0.0 is worst and 100.0 is best, the function takes in as arguments the outputs of the final layer. I think maybe I didn't explain the problem as well as I could have done. I would like the network to learn from the effects of the three numerical outputs on a function <code>f(output[0], output[1], output[2])</code></span>
