<div class="post-text" itemprop="text">
<p>This question concerns how to de-center and "restore" the data in a lower dimension after performing PCA.</p>
<p>I'm doing a simple <a href="https://scikit-learn.org/dev/modules/generated/sklearn.decomposition.PCA.html" rel="nofollow noreferrer">principal component analysis</a> with sklearn. As I understand it, the implementation should take care of (1) centering the data when creating components and (2) de-centering the data after transformation. However, after transforming the data it is still centered. How can I project the data to a lower dimensional space while preserving the characteristics of the original data? Given that I would do dimensionality reduction on high dimensional data, I wouldn't have the appropriate mean for each principal component, how can that be derived?</p>
<p>Reducing 3 dimensions to 2 dimensions:</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

X = np.array([[-1, -1, -1], [-2, -1, -1], [-3, -2, -3], [1, 1, 1], [2, 1, 2], [3, 2, 3]]) + 3
X.shape
</code></pre>
<blockquote>
<p>(6, 3)</p>
</blockquote>
<pre><code>fig = plt.figure(figsize=(10, 8), dpi= 80, facecolor='w', edgecolor='k')
ax = fig.add_subplot(111, projection='3d')
ax.scatter(X[:,0], X[:,1],X[:,2], '*')
plt.title('original')
plt.show()
</code></pre>
<p><a href="https://i.stack.imgur.com/JNpkp.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/JNpkp.png"/></a></p>
<p>PCA with 2 components:</p>
<pre><code>pca = PCA(n_components=2)
pca.fit(X)
X_trans =pca.transform(X)
X_trans.shape
</code></pre>
<blockquote>
<p>(6, 2)</p>
</blockquote>
<pre><code>plt.plot(X_trans[:,0], X_trans[:,1], '*')
plt.show()
</code></pre>
<p><a href="https://i.stack.imgur.com/DAQp2.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/DAQp2.png"/></a></p>
<p>What I would like to do at this stage is to "restore" my data in this lower dimension, such that the value of the data points correspond to the original data. It should still only have 2 dimensions, but not be centered around the mean. </p>
<p>Performing inverse transform, as suggested below, actually brings me back to 3 dimensions</p>
<pre><code>X_approx = pca.inverse_transform(X_trans) 
X_approx.shape
</code></pre>
<blockquote>
<p>(6, 3)</p>
</blockquote>
<p>I want to remain in 2 dimensions but still have my data as resemble it's original form as closely as possible and not be centered around the mean. </p>
</div>
<div class="post-text" itemprop="text">
<p>You are just fitting the data and plotting the transformed data. To get the original data back in a lower dimension, you need to use
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.inverse_transform" rel="nofollow noreferrer"><code>inverse_transform</code></a> which gives you the original data back as I show below in the plot. From the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.inverse_transform" rel="nofollow noreferrer">docs</a>:</p>
<blockquote>
<p><strong>inverse_transform(X)</strong></p>
<p>Transform data back to its original space.</p>
</blockquote>
<pre><code>pca = PCA(n_components=2)
pca.fit(X)

X_trans =pca.transform(X)
X_original = pca.inverse_transform(X_trans)
plt.plot(X_original[:,0], X_original[:,1], 'r*')
</code></pre>
<p><a href="https://i.stack.imgur.com/q7dz2.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/q7dz2.png"/></a></p>
</div>
<span class="comment-copy">I agree with the answer, but I think your actual goal is not to "restore" data but to somehow project the means into the lower dimensional space. Is that correct?</span>
<span class="comment-copy">@kazemakase: That's what is being done here I guess. The new restored data is the same data <b>but</b> projected in a 2-dimensional space because <code>n_components=2</code> during fit.</span>
<span class="comment-copy">changed my wording to "de-centering"</span>
<span class="comment-copy">@Mountain_sheep: I see the problem now. Read my comment and my edited answer</span>
<span class="comment-copy">Thanks, but the data is still centered around the y-axis...?</span>
<span class="comment-copy">@Mountain_sheep: The original data is just a relationship between the one independent variable with one dependent variable</span>
<span class="comment-copy">@Mountain_sheep: I see the problem now. You were just fitting using <code>pca.fit(X)</code> but then you have to apply the <code>pca</code> to the original data to transform it to <code>X_trans</code> using <code>transform</code>. Once you have transformed, you can transform back to original data using <code>inverse_transform</code></span>
<span class="comment-copy">Like I describe in the new edit this method gets me back to my original dimension, I want to stay in lower dimension but de-center my data.</span>
