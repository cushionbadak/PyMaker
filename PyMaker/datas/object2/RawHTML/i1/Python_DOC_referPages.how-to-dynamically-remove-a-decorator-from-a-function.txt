<div class="post-text" itemprop="text">
<p>I'd like to activate or deactivate a "cache" in some class method during execution.</p>
<p>I found a way to activate it with something like that:</p>
<pre><code>(...)
setattr(self, "_greedy_function", my_cache_decorator(self._cache)(getattr(self, "_greedy_function")))
(...)
</code></pre>
<p>where <code>self._cache</code> is a cache object of my own that stores the results of <code>self._greedy_function</code>.</p>
<p>It's working fine but now what if I want to deactivate the cache and "undecorate" <code>_greedy_function</code>?</p>
<p>I see a possible solution, storing the reference of <code>_greedy_function</code> before decorating it but maybe there is a way to retrieve it from the decorated function and that would be better.</p>
<p>As requested, here are the decorator and the cache object I'm using to cache results of my class functions:</p>
<pre><code>import logging
from collections import OrderedDict, namedtuple
from functools import wraps

logging.basicConfig(
    level=logging.WARNING,
    format='%(asctime)s %(name)s %(levelname)s %(message)s'
)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

CacheInfo = namedtuple("CacheInfo", "hits misses maxsize currsize")

def lru_cache(cache):
    """
    A replacement for functools.lru_cache() build on a custom LRU Class.
    It can cache class methods.
    """
    def decorator(func):
        logger.debug("assigning cache %r to function %s" % (cache, func.__name__))
        @wraps(func)
        def wrapped_func(*args, **kwargs):
            try:
                ret = cache[args]
                logger.debug("cached value returned for function %s" % func.__name__)
                return ret
            except KeyError:
                try:
                    ret = func(*args, **kwargs)
                except:
                    raise
                else:
                    logger.debug("cache updated for function %s" % func.__name__)
                    cache[args] = ret
                    return ret
        return wrapped_func
    return decorator

class LRU(OrderedDict):
    """
    Custom implementation of a LRU cache, build on top of an Ordered dict.
    """
    __slots__ = "_hits", "_misses", "_maxsize"

    def __new__(cls, maxsize=128):
        if maxsize is None:
            return None
        return super().__new__(cls, maxsize=maxsize)

    def __init__(self, maxsize=128, *args, **kwargs):
        self.maxsize = maxsize
        self._hits = 0
        self._misses = 0
        super().__init__(*args, **kwargs)

    def __getitem__(self, key):
        try:
            value = super().__getitem__(key)
        except KeyError:
            self._misses += 1
            raise
        else:
            self.move_to_end(key)
            self._hits += 1
            return value

    def __setitem__(self, key, value):
        super().__setitem__(key, value)
        if len(self) &gt; self._maxsize:
            oldest, = next(iter(self))
            del self[oldest]

    def __delitem__(self, key):
        try:
            super().__delitem__((key,))
        except KeyError:
            pass

    def __repr__(self):
        return "&lt;%s object at %s: %s&gt;" % (self.__class__.__name__, hex(id(self)), self.cache_info())

    def cache_info(self):
        return CacheInfo(self._hits, self._misses, self._maxsize, len(self))

    def clear(self):
        super().clear()
        self._hits, self._misses = 0, 0

    @property
    def maxsize(self):
        return self._maxsize

    @maxsize.setter
    def maxsize(self, maxsize):
        if not isinstance(maxsize, int):
            raise TypeError
        elif maxsize &lt; 2:
            raise ValueError
        elif maxsize &amp; (maxsize - 1) != 0:
            logger.warning("LRU feature performs best when maxsize is a power-of-two, maybe.")
        while maxsize &lt; len(self):
            oldest, = next(iter(self))
            print(oldest)
            del self[oldest]
        self._maxsize = maxsize
</code></pre>
<p><strong>Edit:</strong> I've updated my code using the __wrapped__ attribute suggested in comments and it's working fine! The whole thing is here: <a href="https://gist.github.com/fbparis/b3ddd5673b603b42c880974b23db7cda" rel="nofollow noreferrer">https://gist.github.com/fbparis/b3ddd5673b603b42c880974b23db7cda</a> (kik.set_cache() method...)</p>
</div>
<div class="post-text" itemprop="text">
<p>Modern versions of <code>functools.wraps</code> install the original function as an <strong>attribute <code>__wrapped__</code></strong> on the wrappers they create.  (One could search through <code>__closure__</code> on the nested functions typically used for the purpose, but other types could be used as well.)  It’s reasonable to expect whatever wrapper to follow this convention.</p>
<p>An alternative is to have a <strong>permanent</strong> wrapper that can be controlled by a <strong>flag</strong>, so that it can be enabled and disabled without removing and reinstating it.  This has the advantage that the wrapper can <strong>keep its state</strong> (here, the cached values).  The flag can be a separate variable (<em>e.g.</em>, another attribute on an object bearing the wrapped function, if any) or can be an attribute on the wrapper itself.</p>
</div>
<div class="post-text" itemprop="text">
<p>You have made things too complicated. The decorator can be simply removed by <code>del self._greedy_function</code>. There's no need for a <code>__wrapped__</code> attribute.</p>
<p>Here is a minimal implementation of the <code>set_cache</code> and <code>unset_cache</code> methods:</p>
<pre><code>class LRU(OrderedDict):
    def __init__(self, maxsize=128, *args, **kwargs):
        # ...
        self._cache = dict()
        super().__init__(*args, **kwargs)

    def _greedy_function(self):
        time.sleep(1)
        return time.time()

    def set_cache(self):
        self._greedy_function = lru_cache(self._cache)(getattr(self, "_greedy_function"))

    def unset_cache(self):
        del self._greedy_function
</code></pre>
<p>Using your decorator <code>lru_cache</code>, here are the results</p>
<pre><code>o = LRU()
o.set_cache()
print('First call', o._greedy_function())
print('Second call',o._greedy_function()) # Here it prints out the cached value
o.unset_cache()
print('Third call', o._greedy_function()) # The cache is not used
</code></pre>
<p>Outputs</p>
<pre><code>First call 1552966668.735025
Second call 1552966668.735025
Third call 1552966669.7354007
</code></pre>
</div>
<span class="comment-copy">"maybe there is a way to retrieve it from the decorated function" Maybe, unfortunately we don't know what the decorated function is.</span>
<span class="comment-copy">@Goyo The "decorated function" is <code>_greedy_function</code> which is generated by <code>my_cache_decorator</code>. So the question is already clearly defined. Although, it would be better if the PO can provide more context of the decorator.</span>
<span class="comment-copy">How is <code>lru_cache</code> used in your class? I don't see any reference to it after declaration.</span>
<span class="comment-copy">Usually wrappers provide the <code>__wrapped__</code> attribute for this purpose.  That said, I’d recommend using/making a wrapper that <i>provides</i> a switch, rather than removing and reinstating the wrapper.</span>
<span class="comment-copy">There’s no reason to use <code>setattr</code>/<code>getattr</code> with an identifier as a string literal.</span>
<span class="comment-copy">That’s certainly a clean approach when the function in question is a method.</span>
<span class="comment-copy">You put the _cache and _greedy function in the LRU Class but my LRU class is not intended for this, the stuff I want to cache is in other classes, that's why it's complicated... But maybe you're right so I'll review my code first...</span>
<span class="comment-copy">@fbparis Sorry that I didn't read through your 976 lines of codes in your Github-gist. I just took a look in your <code>kik._set_cache(...)</code>, which sets decorator for other methods of <code>kik</code>. My technique should work in that scenario, because the cache content is basically irrelevant. It can be located anywhere and set to anything.</span>
<span class="comment-copy">@gdlmx Thanks for your answer anyway, I think next time I'll go your way (the 976 lines of unreadable code I've posted are only to provide the context but I didn't expect people to read it :D)</span>
