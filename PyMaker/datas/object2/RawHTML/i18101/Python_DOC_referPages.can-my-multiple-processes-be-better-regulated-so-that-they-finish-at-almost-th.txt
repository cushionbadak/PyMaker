<div class="post-text" itemprop="text">
<p>I have the following multiprocessing code</p>
<pre><code>from multiprocessing import Pool
pool = Pool(maxtasksperchild=20)
likelihoods = pool.map_async(do_comparison, itertools.combinations(clusters, 2)).get()
condensed_score_matrix = [1 / float(l) if l != 0 and l &lt; 5 else 10 for l in likelihoods]
spectra_names = [c.get_names()[0] for c in clusters]
pool.close()
</code></pre>
<p>The problem with this code is that the different processes do not finish at the same time. I'm using eight processes. There can be 20-30+ minutes between the first process finishing and the last process finishing, with the last process running alone for a big part of that time. It would be much quicker if the workload would be redivided to processes that are finished, so that all cores are used the whole time. </p>
<p>Is there a way to accomplish this?</p>
</div>
<div class="post-text" itemprop="text">
<p>The way workload is divided can be controlled with the <code>chunksize</code> parameter of map_async.</p>
<p>By omitting it you are currently using the default behavior which is roughly <code>chunksize = num_tasks / (num_processes * 4)</code>, so on average each process will only receive 4 chunks.</p>
<p>You can start by setting the chunk size to 1 to validate that it properly distributes workload and then gradually increase it until you stop seeing a performance improvement.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can try to experiment with <code>.imap_unordered</code> using different <code>chunksize</code> values.
More <a href="http://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.imap_unordered" rel="nofollow">here</a>.</p>
</div>
