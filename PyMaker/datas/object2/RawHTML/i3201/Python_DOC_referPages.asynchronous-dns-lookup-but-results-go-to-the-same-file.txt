<div class="post-text" itemprop="text">
<p>I have to do a large number of DNS NAPTR lookups (think thousands per minute).
I run a Python script using dnspython, read a file and write back to another file. Request rate is ~ 300 requests/sec.
I tried to use asynchronous DNS with Python <a href="https://github.com/saghul/aiodns" rel="nofollow noreferrer">aiodns</a>, but numbers are the same.
It is possible that my script is flawed. Please see below. This is Python 3.4.</p>
<p>But if results have to go back to one file, is it even possible to do lookups asynchronously?</p>
<pre><code>import asyncio
import aiodns

...

loop = asyncio.get_event_loop()
resolver = aiodns.DNSResolver(loop=loop)
resolver.nameservers = ['x.y.w.z']

...

@asyncio.coroutine
def getsip(number):

    try:
        strQuery = str(dns.e164.from_e164("+" + number))
        answer = yield from resolver.query(strQuery, 'NAPTR')

        for rdata in answer:
            return rdata.regex

    except:
        return ""

with open(filename, 'r') as fread, open(filenameOut, 'w') as fwrite:
    reader = csv.DictReader(fread, delimiter='|', quoting=csv.QUOTE_NONE)
    reader.fieldnames = fieldnamesIn

    writer = csv.DictWriter(fwrite, fieldnames = fieldnamesOut, delimiter='|')

    for row in reader:
        sys.stdout.write("Processing record number: %d \r" % (total) )
        sys.stdout.flush()
        total+=1
        answer = loop.run_until_complete(getsip(row['NUM']))
        if answer == "":
            missingAnswers+=1

        writer.writerow({'NUM': row['NUM'], 'SIP': answer})

print("Records not found: " + str(missingAnswers) + " of total " +  str(total) + " records.")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>But if results have to go back to one file, is it even possible to do lookups asynchronously?</p>
</blockquote>
<p>If you don't care about the order of the results, it's straightforward to implement asynchronous lookups. For example, you can use <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed" rel="nofollow noreferrer"><code>asyncio.as_completed</code></a> to schedule all coroutines to run in parallel and get notified as each completes:</p>
<pre><code>@asyncio.coroutine
def process():
    with open(filename, 'r') as fread:
        reader = csv.DictReader(fread, delimiter='|', quoting=csv.QUOTE_NONE)
        reader.fieldnames = fieldnamesIn
        rows = list(reader)

    with open(filenameOut, 'w') as fwrite:
        writer = csv.DictWriter(fwrite, fieldnames=fieldnamesOut, delimiter='|')
        missingAnswers = 0

        loop = asyncio.get_event_loop()
        tasks = [loop.create_task(getsip(row['NUM'])) for row in rows]
        for done_coro in asyncio.as_completed(tasks):
            answer = yield from done_coro
            if answer == ""
                missingAnswers += 1
            writer.writerow({'NUM': row['NUM'], 'SIP': answer})

    print("Records not found: %d of total %d records"
          % (missingAnswers, len(rows)))

loop = asyncio.get_event_loop()
loop.run_until_complete(process())
</code></pre>
</div>
<span class="comment-copy"><code>loop.run_until_complete</code> is blocking, so you only process one request at a time. You should use something like <a href="https://docs.python.org/3.4/library/asyncio-task.html#asyncio.gather" rel="nofollow noreferrer"><code>asyncio.gather</code></a>.</span>
<span class="comment-copy">thanks, you put me on track and @user4815162342 answer nailed it.</span>
<span class="comment-copy">BTW I recommend upgrading to at least Python 3.6. The async def/await syntax is really nice, and asyncio has matured as well - for example, <code>get_event_loop</code> does the right thing in coroutines, so you don't have to pass <code>loop</code> everywhere.</span>
