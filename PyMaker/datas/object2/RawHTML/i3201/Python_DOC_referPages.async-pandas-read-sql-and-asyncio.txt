<div class="post-text" itemprop="text">
<p>Could someone please point me in the right direction on how to solve this following problem. I am trying to come up with a solution using pandas.read_sql and asyncio. I want to migrate table records from 1 database to another database.</p>
<p>I want to do the following:</p>
<pre><code>table 1
.
.
.
table n
</code></pre>
<p>I have the function:</p>
<pre><code>def extract(table):
    try:
        df = pd.DataFrame()
        df = pd.concat(
              [chunk for chunk in
                  pd.read_sql(sql,
                              con=CONNECTION,
                              chunksize=10**5)]
                    )
    except Exception as e:
        raise e
    else:
        return df
</code></pre>
<p>I want to run these in parallel and not one by one.</p>
<pre><code>extract(table1)
extract(table2)
.
.
extract(tablen)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>asyncio is about organizing non-blocking code into callbacks and coroutines. Running CPU-intensive code in parallel is a use case for threads:</p>
<pre><code>from concurrent.futures import ThreadPoolExecutor

with ThreadPoolExecutor() as executor:
    frames = list(executor.map(extract, all_tables))
</code></pre>
<p>Whether this will actually run faster than sequential code depends on whether <code>pd.read_sql</code> releases the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow noreferrer">GIL</a>.</p>
</div>
<span class="comment-copy">Is asyncio a hard requirement? Have you considered threads or multiprocessing?</span>
<span class="comment-copy">yeah, but maybe i could get some idea using threads or multiprocessing. but ive heard that theres a lot of problems that can occur using those methods.</span>
<span class="comment-copy">Even if asyncio were a hard requirement, an asyncio-based solution would still use threads under the hood to run <code>DataFrame.read_sql</code> in parallel. With that in mind, it is better to use <code>concurrent.futures</code>, which provides excellent tools for parallelizing code.</span>
<span class="comment-copy">is there any way to check or release it in python code? something like: while fetching: release GIL for other function to run in parallel?</span>
<span class="comment-copy">another question: can u manage the result immediately on a ThreadPoolExecutor or do you need to wait untill all the extract(tab1...tabn) are finished?</span>
<span class="comment-copy">@Maki You can't release the GIL in Python, but C extensions can do it when safe. (Panda's authors are <a href="https://pandas.pydata.org/pandas-docs/stable/whatsnew.html#releasing-the-gil" rel="nofollow noreferrer">aware</a> of this.) If you need to manage results as they arrive, look into executor's <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.submit" rel="nofollow noreferrer"><code>submit</code></a> method. It returns a <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future" rel="nofollow noreferrer"><code>Future</code></a> which you can manage in various ways, including registering a callback to be executed when the result is ready.</span>
<span class="comment-copy">@Maki Also see <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.as_completed" rel="nofollow noreferrer"><code>as_completed</code></a>, an iterator which accepts a bunch of futures and yields them as they finish.</span>
