<div class="post-text" itemprop="text">
<h2>The question</h2>
<p>Is there any efficient way (with particular attention to memory), either <strong>deterministic</strong> or <strong>probabilistic with arbitrary error</strong>, to determine if <em>i</em>-th element has already appeared or not in a stream of strings (such as the one modelled below)?</p>
<h2>Stream model</h2>
<p>The stream is modelled by the following generator of strings. In this model, the last <code>M=10000</code> values are the ones that appear twice. Obviously in the real application it is not known when a duplicate shall show itself.</p>
<pre><code>def binary(n):
    """Return a binary string representing the number."""
    return "{0:b}".format(n)

def stream():
    """Lazily yield the ith element of the stream."""
    N=10000000
    M=10000
    for i in range(N):
        yield binary(i)
    for i in range(M):
        yield binary(i)
</code></pre>
<h2>Current implementation</h2>
<p>My current implementation uses a form of dictionary, using either directly the <a href="https://docs.python.org/3/tutorial/datastructures.html#dictionaries" rel="nofollow noreferrer"><code>dict</code></a> or an implementation using <a href="https://github.com/fnl/patricia-trie" rel="nofollow noreferrer"><code>patricia-trie</code></a> customised in such a way to exploit eventual frequent substrings.</p>
<pre><code>elements = {}
already_seen = 0
for e in stream():
    if e not in elements:
        elements[e] = None
    else:
        already_seen += 1
</code></pre>
<p>The <code>already_seen</code> value should be <code>10000</code>.</p>
<p>The problem with the current implementation is that it requires to maintain in the main memory all the distinct items. Is there any other way?</p>
</div>
<div class="post-text" itemprop="text">
<p>Yes, it's called <a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="nofollow noreferrer">Bloom Filters</a>:</p>
<blockquote>
<p>Bloom filters are <strong>space-efficient</strong> <strong>probablistic</strong> data structures used to
  test whether an element is a member of a set.</p>
</blockquote>
<p>I used <code>pybloom-mirror</code> package to modify your code and set the bloom filter to capacity 20000 and error rate 0.01 (according <a href="https://hur.st/bloomfilter/?n=20000&amp;p=0.01&amp;m=&amp;k=" rel="nofollow noreferrer">BloomFilter calculator</a> the size of filter is around ~23.4kB). But it can give you false positives.</p>
<pre><code>from pybloom import BloomFilter

def binary(n):
    """Return a binary string representing the number."""
    return "{0:b}".format(n)

def stream():
    """Lazily yield the ith element of the stream."""
    N=10000
    M=100
    for i in range(N):
        yield binary(i)
    for i in range(M):
        yield binary(i)

def my_func():
    bf = BloomFilter(capacity=20000, error_rate=0.01)
    already_seen = 0
    for e in stream():
        if e in bf:
            already_seen += 1
        else:
            bf.add(e)
    print(already_seen)

my_func()
</code></pre>
<p>Output is:</p>
<pre><code>100
</code></pre>
<p>For capacity of 10 million and probability 0.01 the size is around 11.43MiB (there are lot's of variables to play with though, depends on your use case).</p>
<p>Edit:</p>
<p>For chaining Bloom Filters you could use this example:</p>
<pre><code>def bloom_filter_chain(n=3):

    # make bloom filters chain, each next chain is with lower error rate.
    bloom_filters = []
    for i in range(n):
        bloom_filters.append(BloomFilter(capacity=20000, error_rate=0.1 ** (i+1)))

    already_seen = 0

    for e in stream():
        we_have_seen = True
        for bf in bloom_filters:
            if e in bf: # might be false positive, continue down the chain
                continue
            else:
                we_have_seen = False
                bf.add(e)
                break
        if we_have_seen:
            already_seen += 1

    print(already_seen)
</code></pre>
</div>
<span class="comment-copy">aside: you could create a <code>set</code> instead of a <code>dict</code> for this. Your approach looks all right. I don't see what you need to improve. hashing is very efficent on integers BTW</span>
<span class="comment-copy">Sadly the current way requires to keep in main memory all unique elements, and with big streams it isn't feasible. Probably I should point out it more in the question, thank you for the set suggestion!</span>
<span class="comment-copy">a <code>set</code> consumes less memory that a <code>dict</code> already :) I don't think it's feasible to know if an element has already been yielded in the stream without memorizing it (if the order is random)</span>
<span class="comment-copy">there's a way without <code>set</code>: it's storing the elements in a sorted list. Search is <code>O(log(n))</code> vs <code>O(1)</code> for <code>set</code>, but there's no hash, only the elements stored once. So less memory, just slightly slower lookup</span>
<span class="comment-copy">Sure, there is no way to deterministically do so without memorising all the elements, but the question is about any way, including probabilistic approaches. The issue is quite similar to the <a href="https://en.wikipedia.org/wiki/Flajolet%E2%80%93Martin_algorithm" rel="nofollow noreferrer"><code>Flajoletâ€“Martin algorithm</code></a> one, so I thought there could be a similar known solution.</span>
<span class="comment-copy">Is there any way to lower the error even more? Maybe by chaining multiple filters?</span>
<span class="comment-copy">@LucaCappelletti yes, of course (the calculator <a href="https://hur.st/bloomfilter/?n=20000&amp;p=0.001&amp;m=&amp;k=" rel="nofollow noreferrer">hur.st/bloomfilter/?n=20000&amp;p=0.001&amp;m=&amp;k=</a> can give you an idea). All depends on quality of  hash function, your input data etc.</span>
<span class="comment-copy">Could you please include in your answer an approach at chaining a given <code>n</code> of BloomFilter objects, for future answer-seekers?</span>
<span class="comment-copy">@LucaCappelletti I edited my answer</span>
