<div class="post-text" itemprop="text">
<p>I've learned how to send tweets with Python, but I'm wondering if it's possible to send emojis or other special Unicode characters in the tweets.</p>
<p>For example, when I try to tweet u'1F430', it simply shows up as "1F430" in the tweet.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>&gt;&gt;&gt; len(u'1f430')
5
&gt;&gt;&gt; len(u'\U0001F430') 
1 # the latter might be equal to two in Python 2 on a narrow build (Windows, OS X)
</code></pre>
<p>The former is 5 characters, the latter is a single character.</p>
<p>If you want to specify the character in Python source code then you could use its name for readability:</p>
<pre><code>&gt;&gt;&gt; print(u"\N{RABBIT FACE}")
üê∞
</code></pre>
<p>Note: it might not work in Windows console. To <em>display</em> non-BMP Unicode characters there, you could use <a href="https://stackoverflow.com/questions/31846091/python-unicode-console-support-under-windows#comment51693479_31846091">win-unicode-console + ConEmu</a>.</p>
<p>If you are reading it from a file, network, etc then this character is no different from any other: to decode bytes into Unicode text, you should specify a character encoding e.g.:</p>
<pre><code>import io

with io.open('filename', encoding='utf-8') as file:
    text = file.read()
</code></pre>
<p>Which specific encoding to use depends on the source e.g., see <a href="https://stackoverflow.com/q/14592762/4279">A good way to get the charset/encoding of an HTTP response in Python</a></p>
</div>
<div class="post-text" itemprop="text">
<p>u'1F430' is the literal string "1F430". What character are you trying to get? In general you can get literal bytes into a python string using "\x20", e.g. </p>
<pre><code>&gt;&gt;&gt; print(b"#\x20#")
# #
</code></pre>
<p>The byte with hexadecimal value of 20 (decimal 32) in between 2 hashes. Bytes are decoded as ASCII by default, and ASCII char (hex) 20 is a space.</p>
<pre><code>&gt;&gt;&gt; print(u"#\u0020#")
# #
&gt;&gt;&gt; print(u"#\U0001F430#")
# #
</code></pre>
<p>Unicode codepoint 20 (a single space) in the middle of 2 hashes</p>
<p>See <a href="https://docs.python.org/3.3/howto/unicode.html" rel="nofollow">https://docs.python.org/3.3/howto/unicode.html</a> for more info. NB It can get a little confusing since python will implicitly convert between bytes and unicode (using the ASCII encoding) in a lot of cases, which can hide the issue from you for a while.</p>
</div>
<span class="comment-copy">'1F430' is still a series of five alphanumeric characters whether you mark it as unicode or not. What character are you actually trying to send?</span>
<span class="comment-copy">you probably mean <code>'\U0001F430'</code> (üê∞)?</span>
<span class="comment-copy">That was just an example, but that '1F430' should be a bunny emoji. How do I get a computer to read that as one character then?</span>
<span class="comment-copy">@mata, yes! How should I pass that into Python so that it reads it how I want it to? EDIT: Nevermind, your answer actually answers that. Thank you so much!</span>
<span class="comment-copy">@codycrossley do you use python2 or python3? there are a lot of differences regarding unicode handling between those versions, and there are different <a href="https://docs.python.org/3/howto/unicode.html#unicode-literals-in-python-source-code" rel="nofollow noreferrer">possible escape sequences</a>, which can be used depending on the needed byte size for the unicode code point...</span>
<span class="comment-copy">for this code point a 4-byte escape sequence isn't enough, you need a 8-byte (<code>\Uxxxxxxxx</code>). Also, if you use python2 syntax you shouldn't link to the documentation for python3 as that can be confusing for the readers.</span>
<span class="comment-copy">Good points, updated answer accordingly</span>
<span class="comment-copy">don't print text as bytes. Which encoding is used to decode bytes depends on context.</span>
