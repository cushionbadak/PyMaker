<div class="post-text" itemprop="text">
<p>I'm writing a small toy simulation in python. Granted, this simulations are slow. To my understanding, the major reason that python codes are slow is the fact that python is in interpreted language. I don't want to give up python since the clear syntax and the available library cut the writing time significantly. So is there a simple way for me to "compile" my python code? </p>
<p><strong>Edit</strong></p>
<p>I answer some questions:
Yes, I'm using numpy. It greatly simplify the code and I don't think I can improve performance writing the functions on my own. I use numpy for all my lists and and I add all of the beads together. Namely. I invoke</p>
<pre><code>pos += V*dt + forces*0.5*dt**2 
</code></pre>
<p>where ''pos'', 'V', and 'forces' are all <code>np.array</code> of <code>(2000,3)</code> dimensions. 
I'm quite certain that the slow part in the forces calculation. This is logical as I have to iterate over all my particles and check their position. For my real project (Ph.D. stuff) I have code of about roughly the same level of complexity, and I know that this is the expensive stuff. </p>
</div>
<div class="post-text" itemprop="text">
<p>Python is a slightly odd language in that it is both interpreted and compiled. Well sort of. When you run it is compiled to ".pyc" bytecode - so we can quickly get bogged down in semantic details here. Hell I don't even know if what I just said is strictly accurate. But at the end of the day you want to speed things up so...</p>
<ol>
<li>First, use <a href="http://docs.python.org/3/library/profile.html" rel="nofollow">the profiler</a> and <a href="http://docs.python.org/3/library/timeit.html" rel="nofollow">timeit</a> to work out where all the time is going</li>
<li>Second, rewrite your pure python code to improve the slow bits you've discovered</li>
<li>Third, see how it goes when <a href="http://docs.python.org/3/using/cmdline.html#cmdoption-OO" rel="nofollow">optimised</a></li>
<li>Now, depends on your scenario, but seriously think "Can I run it on a bigger CPU/memory" </li>
<li>Ok, try <a href="http://docs.python.org/3.3/extending/extending.html" rel="nofollow">rewriting those slow sections in C++</a></li>
<li>Screw it, write it all in C++</li>
</ol>
<p>If you get so far as the last option I dare say you're screwed and the savings aren't going to be significant.</p>
</div>
<div class="post-text" itemprop="text">
<p>If none of the solutions in the comment suffice, you can also take a look at cython.
For a quick tutorial &amp; example check:</p>
<p><a href="http://docs.cython.org/src/tutorial/cython_tutorial.html" rel="nofollow">http://docs.cython.org/src/tutorial/cython_tutorial.html</a></p>
<p>Used at the correct spots (e.g. around frequently called functions) it can easily speed things up by a factor of 10 - 100.</p>
</div>
<span class="comment-copy">Are you using <code>numpy</code> for your calculations? You could also try <a href="http://pypy.org/" rel="nofollow noreferrer">PyPy</a> which is a faster python interpreter than the "default" one written in C.</span>
<span class="comment-copy">Also, different ways of writing python can have large performance differences. There are also C extensions that can help in some areas. Can you show us some code?</span>
<span class="comment-copy">@Gjordis this does not really make sense. <code>py_compile</code> only manually does what every python-invocation does with source code - namely byte-compiling it.</span>
<span class="comment-copy">Have you profiled your application to figure out where its actually slow? Just "compiling it" may not solve your problem. If its stuck on I/O running it on the fastest compiled language won't help.</span>
<span class="comment-copy">Definitely profile your code. For the snippet you've shown I would consider trying <a href="https://github.com/pydata/numexpr" rel="nofollow noreferrer">github.com/pydata/numexpr</a></span>
<span class="comment-copy">Nothing "odd" about Python -- that's how many if not most programming languages work: source code gets parsed and transformed into bytecode which is then executed... sometimes the bytecode is machine specific in which case we call the result a <i>native binary</i>, sometimes the result requires a bytecode interpreter better known as a <i>virtual machine</i>.</span>
<span class="comment-copy">@miraculixx lols there's always one.</span>
<span class="comment-copy">Well, profiling my code, I learn that I call <code>numpy.zeros</code> sh*$load of times (actual <code>cProfile</code> output) with <code>cumtime</code> of 5.69 seconds(?) out of total of 78.108 seconds. So if there anything to reduce, for now, it is there. Can I improve it by doing this manually?  I don't think so since the ''percall'' value is 0</span>
