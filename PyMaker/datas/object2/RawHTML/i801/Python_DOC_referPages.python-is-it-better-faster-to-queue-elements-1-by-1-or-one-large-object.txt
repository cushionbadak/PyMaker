<div class="post-text" itemprop="text">
<p>When using multiprocessing.Queue, I've always wondered if it was better (faster) to:</p>
<p><strong>a)</strong> queue elements 1-by-1 or</p>
<p><strong>b)</strong> queue several larger objects (i.e. cache those smaller objects into a larger data structures in memory and then periodically queue the larger data structure).  </p>
<p>I would expect b) to be faster since multiprocessing.Queue.put()/get() involves pickling which is known to be slow.  </p>
<p>I'll share my test as an answer.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here's the results:</p>
<pre><code>$ time python test_smp_queues3.py 
test1: building a large object and sending
BuildObject  1823.68 ms
SendObject  0.73 ms
test2: sending a bunch of small objects, lots of times
SendSmallObjects  26608.62 ms
Child process is ending
Test is finished

real    0m29.085s
user    0m37.948s
sys 0m11.417s
</code></pre>
<p>So queueing one large object of 1million entries was about 14x times faster than queueing it 1 million times.  (maybe no surprise since queueing involves pickling)</p>
<p>And here's my code:</p>
<pre><code>import multiprocessing
from multiprocessing import Process, Queue
import random
import time

ITERATIONS = 1000000

def timeit(method):
   def timed(*args, **kw):
      ts = time.time()
      result = method(*args, **kw)
      te = time.time()
      print(('{}  {:.2f} ms'.format(method.__name__, (te - ts) * 1000)))
      return result
   return timed


class Child(Process):
   def __init__(self, name, q):
      super(Child, self).__init__(name=name)
      self.queue = q

   def run(self):
      while True:
         obj = self.queue.get(block=True)
         if obj is None:
            break
         #print(obj, end=" ")
         #print("{}: q_entry={}".format(
         #   self.name,
         #   obj,
         #))
      print("Child process is ending")

@timeit
def BuildObject():
   obj = []
   for _ in range(ITERATIONS):
      obj.append(
         random.randint(1,10)
      )
   return obj

@timeit
def SendObject(q, obj):
   q.put(obj)


@timeit
def SendSmallObjects(q):
   for _ in range(ITERATIONS):
      q.put(
         random.randint(1,10)
      )


if __name__ == '__main__':
   q = Queue()
   child = Child("child-1", q)
   child.start()

   print("test1: building a large object and sending")
   obj = BuildObject()   
   SendObject(q, obj)

   print("test2: sending a bunch of small objects, lots of times")   
   SendSmallObjects(q) 

   q.put(None)
   child.join()
   print("Test is finished")
</code></pre>
<p>It would be interesting to see how much of a speedup there would be with cPickle or dill pickle (<a href="https://pypi.org/project/dill/" rel="nofollow noreferrer">https://pypi.org/project/dill/</a>)</p>
<hr/>
<p>UPDATE:</p>
<p>@Chris brought up a good point about not making any assumptions here about pickling.  Here were the largest offenders (tottime) in cProfile:</p>
<pre><code>$ python3 -m cProfile -s tottime test_smp_queues3.py 
test1: building a large object and sending
BuildObject  5771.54 ms
SendObject  0.55 ms
test2: sending a bunch of small objects, lots of times
SendSmallObjects  22713.12 ms
Child process is ending
Test is finished
         33418376 function calls (33417995 primitive calls) in 29.336 seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
  1000002   15.620    0.000   15.620    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}
  4000000    2.468    0.000    5.793    0.000 random.py:174(randrange)
  4000024    2.260    0.000    3.325    0.000 random.py:224(_randbelow)
  1000002    1.883    0.000   19.981    0.000 queues.py:80(put)
  4000000    1.126    0.000    6.919    0.000 random.py:218(randint)
</code></pre>
</div>
<span class="comment-copy">What you did not explain in your question and your miraculously fast self-answer: why to use a queue in the first place if you hand in all data at once?</span>
<span class="comment-copy">@KlausD <a href="https://stackoverflow.blog/2011/07/01/its-ok-to-ask-and-answer-your-own-questions/">it's OK to ask and answer your own question</a>.</span>
<span class="comment-copy">The assumption that Pickle is the bottleneck seems incorrect on inspection. Try running your script with <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer"><code>cProfile</code></a> and see.</span>
<span class="comment-copy">Also it is usually better to run microbenchmarks with <a href="https://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer"><code>timeit</code></a>.</span>
<span class="comment-copy">@KlausD. Suppose I'm streaming lots of data from one process to another process.  The question is is it faster to stream that data object by object or, if the design allows, to send it over in larger chunks.  Also the purpose of answering your own question is to share answers to interesting/difficult questions that others might be interested in as well.</span>
