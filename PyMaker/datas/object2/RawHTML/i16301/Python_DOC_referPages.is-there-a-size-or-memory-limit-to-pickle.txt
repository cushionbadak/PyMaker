<div class="post-text" itemprop="text">
<p>a friend of mine wrote this little progam.
the <code>textFile</code> is 1.2GB in size (7 years worth of newspapers).
He successfully manages to create the dictionary but he cannot write it to a file using pickle(program hangs).</p>
<pre><code>import sys
import string
import cPickle as pickle

biGramDict = {}

textFile = open(str(sys.argv[1]), 'r')
biGramDictFile = open(str(sys.argv[2]), 'w')


for line in textFile:
   if (line.find('&lt;s&gt;')!=-1):
      old = None
      for line2 in textFile:
         if (line2.find('&lt;/s&gt;')!=-1):
            break
         else:
            line2=line2.strip()
            if line2 not in string.punctuation:
               if old != None:
                  if old not in biGramDict:
                     biGramDict[old] = {}
                  if line2 not in biGramDict[old]:
                     biGramDict[old][line2] = 0
                  biGramDict[old][line2]+=1
               old=line2

textFile.close()

print "going to pickle..."    
pickle.dump(biGramDict, biGramDictFile,2)

print "pickle done. now load it..."

biGramDictFile.close()
biGramDictFile = open(str(sys.argv[2]), 'r')

newBiGramDict = pickle.load(biGramDictFile)
</code></pre>
<p>thanks in advance.</p>
<p><strong>EDIT</strong><br/>
for anyone interested i will briefly explain what this program does.
assuming you have a file formated roughly like this:</p>
<pre><code>&lt;s&gt;
Hello
,
World
!
&lt;/s&gt;
&lt;s&gt;
Hello
,
munde
!
&lt;/s&gt;
&lt;s&gt;
World
domination
.
&lt;/s&gt;
&lt;s&gt;
Total
World
domination
!
&lt;/s&gt;
</code></pre>
<ul>
<li><code>&lt;s&gt;</code> are sentences separators. </li>
<li>one word per line.</li>
</ul>
<p>a biGramDictionary is generated for later use.<br/>
something like this:</p>
<pre><code>{
 "Hello": {"World": 1, "munde": 1}, 
 "World": {"domination": 2},
 "Total": {"World": 1},
}
</code></pre>
<p>hope this helps. right now the strategy changed to using mysql because sqlite just wasn't working (probably because of the size)</p>
</div>
<div class="post-text" itemprop="text">
<p>Pickle is only meant to write complete (small) objects. Your dictionary is a bit large to even hold in memory, you'd better use a database instead so you can store and retrieve entries one by one instead of all at once.</p>
<p>Some good and easily integratable singe-file database formats you can use from Python are <a href="https://docs.python.org/3/library/sqlite3.html" rel="nofollow noreferrer">SQLite</a> or one of the <a href="https://docs.python.org/3/library/dbm.html" rel="nofollow noreferrer">DBM variants</a>. The last one acts just like a dictionary (i.e. you can read and write key/value-pairs) but uses the disk as storage rather than 1.2 GBs of memory.</p>
</div>
<div class="post-text" itemprop="text">
<p>Do you really need the whole data in memory? You could split it in naive ways like one file for each year o each month if you want the dictionary/pickle approach.</p>
<p>Also, remember that the dictionaries are not sorted, you can have problems having to sort that ammount of data. In case you want to search or sort the data, of course...</p>
<p>Anyway, I think that the database approach commented before is the most flexible one, specially on the long run...</p>
</div>
<div class="post-text" itemprop="text">
<p>One solution is to use <a href="http://buzhug.sourceforge.net/" rel="nofollow noreferrer">buzhug</a> instead of pickle. It's a pure Python solution, and retains very Pythonic syntax. I think of it as the next step up from shelve and their ilk. It will handle the data sizes you're talking about. Its size limit is 2 GB per field (each field is stored in a separate file).</p>
</div>
<div class="post-text" itemprop="text">
<p>If your <em>really, really</em> want to use a dictionary like semantics, try SQLAlchemy's <code>associationproxy</code>. The following (rather long) piece of code translates your dictionary into <em>Key,Value-Pairs</em> in the <code>entries</code>-Table. I do not know how SQLAlchemy copes with your big dictionary, but SQLite should be able to handle it nicely.</p>
<pre><code>from sqlalchemy import create_engine, MetaData
from sqlalchemy import Table, Column, Integer, ForeignKey, Unicode, UnicodeText
from sqlalchemy.orm import mapper, sessionmaker, scoped_session, Query, relation
from sqlalchemy.orm.collections import column_mapped_collection
from sqlalchemy.ext.associationproxy import association_proxy
from sqlalchemy.schema import UniqueConstraint

engine = create_engine('sqlite:///newspapers.db')

metadata = MetaData()
metadata.bind = engine

Session = scoped_session(sessionmaker(engine))
session = Session()

newspapers = Table('newspapers', metadata,
    Column('newspaper_id', Integer, primary_key=True),
    Column('newspaper_name', Unicode(128)),
)

entries = Table('entries', metadata,
    Column('entry_id', Integer, primary_key=True),
    Column('newspaper_id', Integer, ForeignKey('newspapers.newspaper_id')),
    Column('entry_key', Unicode(255)),
    Column('entry_value', UnicodeText),
    UniqueConstraint('entry_key', 'entry_value', name="pair"),
)

class Base(object):

    def __init__(self, **kw):
        for key, value in kw.items():
            setattr(self, key, value)

    query = Session.query_property(Query)

def create_entry(key, value):
    return Entry(entry_key=key, entry_value=value)

class Newspaper(Base):

    entries = association_proxy('entry_dict', 'entry_value',
        creator=create_entry)

class Entry(Base):
    pass

mapper(Newspaper, newspapers, properties={
    'entry_dict': relation(Entry,
        collection_class=column_mapped_collection(entries.c.entry_key)),
})
mapper(Entry, entries)

metadata.create_all()

dictionary = {
    u'foo': u'bar',
    u'baz': u'quux'
}

roll = Newspaper(newspaper_name=u"The Toilet Roll")
session.add(roll)
session.flush()

roll.entries = dictionary
session.flush()

for entry in Entry.query.all():
    print entry.entry_key, entry.entry_value
session.commit()

session.expire_all()

print Newspaper.query.filter_by(newspaper_id=1).one().entries
</code></pre>
<p>gives</p>
<pre><code>foo bar
baz quux
{u'foo': u'bar', u'baz': u'quux'}
</code></pre>
</div>
<span class="comment-copy">if you are going to be messing with BIG files, why not use a database? also, i see you do for loop over the same file 2 times, that may be redundant and adds to processing cost. why not describe what you are doing with sample input files ?</span>
<span class="comment-copy">ghostdog74, you see 2 for statements, but there is only one loop over the file :) Iterating over a file is just reading lines (from actual position), it does not seek to the beginning of the file.</span>
<span class="comment-copy">Simply try <a href="https://pypi.python.org/pypi/sqlitedict" rel="nofollow noreferrer">sqlitedict</a> (your Python dict backed by DB on disk, not RAM).</span>
<span class="comment-copy">Sqlite is a fully relational database, while Berkeley DB is not, just key/value. If it's just storing, I think Berkeley is a better option, while if you want to make some queries and store the information in more organized way, sqlite it's more appropiate.</span>
<span class="comment-copy">BerkeleyDB is rather fickle and difficult to manage, especially with larger amounts of data. Even for a single string-&gt;string store (which is what BerkeleyDB would be) I would use SQLite, which will take care of all the BerkeleyDB management.</span>
<span class="comment-copy">SQLite does not act like a dictionary.</span>
<span class="comment-copy">The Python page for the bsddb moddule (<a href="http://www.python.org/doc/2.6/library/bsddb.html" rel="nofollow noreferrer">python.org/doc/2.6/library/bsddb.html</a>) says that it is deprecated.  Is there another non-deprecated Python option for a BSD DB?</span>
<span class="comment-copy"><a href="http://www.python.org/doc/2.6/library/persistence.html" rel="nofollow noreferrer">python.org/doc/2.6/library/persistence.html</a> lists a number of data persistence modules. The <code>gdbm</code> module looks very similar and still supported, I'd go for that one.</span>
