<div class="post-text" itemprop="text">
<p>I have a textfile <code>test.in</code> as such:</p>
<pre><code>english&lt;tab&gt;walawala
foo bar&lt;tab&gt;laa war
foo bar&lt;tab&gt;laa war
hello world&lt;tab&gt;walo lorl
hello world&lt;tab&gt;walo lorl
foo bar&lt;tab&gt;laa war
</code></pre>
<p>The desired output should be:</p>
<pre><code>english&lt;tab&gt;walawala&lt;tab&gt;0.1666
foo bar&lt;tab&gt;laa war&lt;tab&gt;0.5
hello world&lt;tab&gt;walo lorl&lt;tab&gt;0.3333
</code></pre>
<p>The new column is the count of the line divided by the total number of lines.</p>
<p>Currently i'm doing this:</p>
<pre><code>cat test.in | uniq -c | awk '{print $2"\t"$3"\t"$1}' &gt; test.out
</code></pre>
<p>But that only gives me the count of the lines not the probability. Also, my file is really huge, like 1,000,000,000 lines with at least 20 chars per column.</p>
<p><strong>How could I get the desired output correctly and quickly?</strong> </p>
<p><strong>Is there a pythonic solution that is as fast?</strong></p>
</div>
<div class="post-text" itemprop="text">
<p>Note that the uniq only counts repeated lines, and it must be preceded by sort for it to consider all lines in a file. For <code>sort | uniq -c</code>, the following code using <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="noreferrer">collections.Counter</a> is much more effective as it does not need to sort anything at all:</p>
<pre><code>from collections import Counter

with open('test.in') as inf:
    counts = sorted(Counter(line.strip('\r\n') for line in inf).items())
    total_lines = float(sum(i[1] for i in counts))
    for line, freq in counts:
         print("{}\t{:.4f}".format(line, freq / total_lines))
</code></pre>
<p>This script outputs</p>
<pre><code>english&lt;tab&gt;walawala&lt;tab&gt;0.1667
foo bar&lt;tab&gt;laa war&lt;tab&gt;0.5000
hello world&lt;tab&gt;walo lorl&lt;tab&gt;0.3333
</code></pre>
<p>for the input given in your description.</p>
<hr/>
<p>However if you need to coalesce only successive lines, like <strong><code>uniq -c</code></strong>, note that any solution using <code>Counter</code> gives the output given in your question, but your <code>uniq -c</code> approach will <strong>not</strong>. The output of <code>uniq -c will be</code>:</p>
<pre><code>  1 english&lt;tab&gt;walawala
  2 foo bar&lt;tab&gt;laa war
  2 hello world&lt;tab&gt;walo lorl
  1 foo bar&lt;tab&gt;laa war
</code></pre>
<p><strong>not</strong></p>
<pre><code>  1 english&lt;tab&gt;walawala
  3 foo bar&lt;tab&gt;laa war
  2 hello world&lt;tab&gt;walo lorl
</code></pre>
<p>If this is the behavior you <em>want</em>, you can use <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="noreferrer"><code>itertools.groupby</code></a>:</p>
<pre><code>from itertools import groupby

with open('foo.txt') as inf:
    grouper = groupby(line.strip('\r\n') for line in inf)
    items = [ (k, sum(1 for j in i)) for (k, i) in grouper ]
    total_lines = float(sum(i[1] for i in items))
    for line, freq in items:
        print("{}\t{:.4f}".format(line, freq / total_lines))
</code></pre>
<p>The difference is that given a <code>test.in</code> having the contents as you prescribe, the uniq pipe would <em>not</em> produce the output you gave in the example, instead you would get: </p>
<pre><code>english&lt;tab&gt;walawala&lt;tab&gt;0.1667
foo bar&lt;tab&gt;laa war&lt;tab&gt;0.3333
hello world&lt;tab&gt;walo lorl&lt;tab&gt;0.3333
foo bar&lt;tab&gt;laa war&lt;tab&gt;0.1667
</code></pre>
<p>As this is not what your input example said, it can be that you can't use <code>uniq</code> without <code>sort</code> to solve your problem - then you need to resort to my first example and Python will be most certainly faster than your Unix command line.</p>
<hr/>
<p>By the way, these work identically in all Pythons &gt; 2.6.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a pure AWK solution:</p>
<pre><code>&lt;test.in awk '{a[$0]++} END {for (i in a) {print i, "\t", a[i]/NR}}'
</code></pre>
<p>It uses AWK's arrays and the special variable <code>NR</code>, which keeps track of the number of lines.</p>
<p>Let's dissect the code.  The first block</p>
<pre><code>{a[$0]++}
</code></pre>
<p>is executed <em>once for each line</em> in the input.  Here <code>$0</code> represents every single line, and it is used as an index over the array <code>a</code>, which therefore just <em>counts the number of occurrences of each line</em>.</p>
<p>The second block</p>
<pre><code>END {for (i in a) {print i, "\t", a[i]/NR}}
</code></pre>
<p>is executed <em>at the end</em> of the input.  At this point, <code>a</code> contains the number of occurrences for each line in the input and is indexed by the lines themselves: hence by cycling over it we are able to print a table of lines and relative occurrences (we divide by the total number of lines, <code>NR</code>).</p>
</div>
<div class="post-text" itemprop="text">
<pre class="lang-python prettyprint-override"><code>from collections import Counter

with open('data.txt') as infile:
    # Counter will treat infile as an iterator and exhaust it
    counter = Counter(infile)

    # Don't know if you need sorting but this will sort in descending order
    counts = ((line.strip(), n) for line, n in counter.most_common())

    # Convert to proportional amounts
    total = sum(counter.values())
    probs = [(line, n / total) for line, n in counts]

    print("\n".join("{}{}".format(*p) for p in probs))
</code></pre>
<p>This has several advantages. It iterates through the lines in the file rather than loading the whole file, it takes advantage of existing <code>Counter</code> functionality, it can sort, and it's clear what's going on.</p>
</div>
<div class="post-text" itemprop="text">
<p>A solution in Python, but I'm not sure about performance on 1,000,000,000 lines.</p>
<pre><code>d = {}
s = "english&lt;tab&gt;walawala\nfoo bar&lt;tab&gt;laa war\nfoo bar&lt;tab&gt;laa war\nhello world&lt;tab&gt;walo lorl\nhello world&lt;tab&gt;walo lorl\nfoo bar&lt;tab&gt;laa war"
c = 0

for l in s.split("\n"):
  c += 1
  if d.has_key(l):
    d[l] += 1
  else:
    d[l] = 1

for k,v in d.items():
  print k + " -&gt; " + str(float(v)/float(c))
</code></pre>
<p>Output : </p>
<pre><code>english&lt;tab&gt;walawala -&gt; 0.166666666667
foo bar&lt;tab&gt;laa war -&gt; 0.5
hello world&lt;tab&gt;walo lorl -&gt; 0.333333333333
</code></pre>
<p>Edit : this solution can be improved using the Counter object in Python : <a href="https://docs.python.org/2/library/collections.html#collections.Counter" rel="nofollow">https://docs.python.org/2/library/collections.html#collections.Counter</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Maybe by using dictionaries in python that automatically can only have one value    </p>
<pre><code>from collections import defaultdict

my_dict_counter = defaultdict(float)
counter = 0

for line in open('test.in'):
    my_dict_counter[line] += 1
    counter += 1 

for line in my_dict_counter:
    print line.strip() + "\t" + str(my_dict_counter[line]/counter)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Another solution in Python:</p>
<pre><code>my_dict = {}
counter = 0 
with open('test.in') as f:
    for line in f:
        counter += 1
        try:
            my_dict[line] = (my_dict[line]+1)
        except:
            my_dict[line] = 1

for line in my_dict:
    print("%s%s%.4f" % (line[:-1], "&lt;tab&gt;", my_dict[line]/float(counter)))
</code></pre>
<p>Output:</p>
<pre><code>english&lt;tab&gt;walawala&lt;tab&gt;0.1667
hello world&lt;tab&gt;walo lorl&lt;tab&gt;0.3333
foo bar&lt;tab&gt;laa war&lt;tab&gt;0.5000
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>from collections import Counter
with open("test.in") as f:
    counts = Counter(f)
total = sum(counts.values())
for k, v in counts.items():
    print("{0}&lt;tab&gt;{1:0.4f}".format(k.strip(), v / total))
</code></pre>
<p>This does not sort on probability. The performance is O(3n) because of the three loops and this could be reduced to O(2n) by using a subclass of TexIOBase which keeps track of lines or a subclass of Counter that keeps track of total lines processed.</p>
</div>
<div class="post-text" itemprop="text">
<p>If it's too expensive to do all the processing in RAM, you could consider a simple database. sqlite comes with all installations of python. This example could easily be optimized, but I felt simplicity favored speed when demonstrating the approach:</p>
<pre><code>import sqlite3

conn = sqlite3.connect('counts.db')
c = conn.cursor()

c.execute('CREATE TABLE counts (phrase TEXT PRIMARY KEY, num INT)')
conn.commit()

recs = 0
with open('test.in') as fin:
    for line in fin:
        recs += 1

        # see if already exists
        c.execute("SELECT count(1) FROM counts WHERE phrase=?", (line,))
        count = int(c.fetchone()[0]) + 1
        if count == 1:
            # add new record
            c.execute("INSERT INTO counts VALUES(?,1)", (line,))
        else:
            # update record
            c.execute("UPDATE counts SET num=?", (count,))

        if recs % 10000 == 0:
            conn.commit()

conn.commit()

for row in c.execute("SELECT phrase,num FROM counts ORDER BY phrase"):
    print "%s\t%f" % (row[0], float(row[1]) / recs)
</code></pre>
</div>
<span class="comment-copy">Did you try <code>wc</code>?   <code>q=`cat test.in | wc -l`;cat test.in | uniq -c | awk '{print $2"\t"$3"\t"$1'/$q'}'</code></span>
<span class="comment-copy">@user189 <a href="http://en.m.wikipedia.org/wiki/Cat_(Unix)#Useless_use_of_cat" rel="nofollow noreferrer">useless use of cat</a> alert. :)</span>
<span class="comment-copy">@Dougal Thanks!</span>
<span class="comment-copy">Note that the floating point is rounded...</span>
<span class="comment-copy">Maybe you could use Counter?</span>
<span class="comment-copy">Yup didn't know about that tool. You can adapt my solution using this : <a href="https://docs.python.org/2/library/collections.html#collections.Counter" rel="nofollow noreferrer">docs.python.org/2/library/collections.html#collections.Counter</a></span>
<span class="comment-copy">loading 1,000,000,000 lines into memory is going to be painful...</span>
<span class="comment-copy">RAM is cheap nowadays :D</span>
<span class="comment-copy">@Jerk31 1 billion lines * 20 characters = 20 billion bytes = 20GB of ram. Probably excessive.</span>
