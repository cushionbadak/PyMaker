<div class="post-text" itemprop="text">
<p>We recently switched to Keras for TF 2.0, but when we compared it to the DNNClassifier Estimator on 2.0, we experienced around 4x slower speeds with Keras. But I cannot for the life of me figure out why this is happening. The rest of the code for both are identical, using an input_fn() that returns the same tf.data.Dataset, and using identical feature_columns. Been struggling with this problem for days now. Any help would be greatly greatly appreciated. Thank you</p>
<p>Estimator code:</p>
<pre><code>estimator = tf.estimator.DNNClassifier(
        feature_columns = feature_columns,
        hidden_units = [64,64],
        activation_fn = tf.nn.relu,
        optimizer = 'Adagrad',
        dropout = 0.4,
        n_classes = len(vocab),
        model_dir = model_dir,
        batch_norm = false)

estimator.train(input_fn=train_input_fn, steps=400)
</code></pre>
<p>Keras code:</p>
<pre><code>feature_layer = tf.keras.layers.DenseFeatures(feature_columns);

model = tf.keras.Sequential([
        feature_layer,
        layers.Dense(64, input_shape = (len(vocab),), activation = tf.nn.relu),
        layers.Dropout(0.4),
        layers.Dense(64, activation = tf.nn.relu),
        layers.Dropout(0.4),
        layers.Dense(len(vocab), activation = 'softmax')]);

model.compile(
        loss = 'sparse_categorical_crossentropy',
        optimizer = 'Adagrad'
        distribute = None)

model.fit(x = train_input_fn(),
          epochs = 1,
          steps_per_epoch = 400,
          shuffle = True)
</code></pre>
<p>UPDATE: To test further, I wrote a custom subclassed Model (See: <a href="https://www.tensorflow.org/alpha/tutorials/quickstart/advanced" rel="nofollow noreferrer">Get Started For Experts</a>), which runs faster than Keras but slower than Estimators. If Estimator trains in 100 secs, the custom model takes approx ~180secs, and Keras approx ~350secs. An interesting note is that Estimator runs slower with Adam() than Adagrad() while Keras seems to run faster. With Adam() Keras takes less than twice as long as DNNClassifier. Assuming I didn't mess up the custom code, I'm beginning to think that DNNClassifier just has a lot of backend optimization / efficiencies that make it run faster than Keras.</p>
<p>Custom code: </p>
<pre><code>class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.features = layers.DenseFeatures(feature_columns, trainable=False)
    self.dense = layers.Dense(64, activation = 'relu')
    self.dropout = layers.Dropout(0.4)
    self.dense2 = layers.Dense(64, activation = 'relu')
    self.dropout2 = layers.Dropout(0.4)
    self.softmax = layers.Dense(len(vocab_of_codes), activation = 'softmax')

  def call(self, x):
    x = self.features(x)
    x = self.dense(x)
    x = self.dropout(x)
    x = self.dense2(x)
    x = self.dropout2(x)
    return self.softmax(x)

model = MyModel()
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
optimizer = tf.keras.optimizers.Adagrad()

@tf.function
def train_step(features, label):
  with tf.GradientTape() as tape:
    predictions = model(features)
    loss = loss_object(label, predictions)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

itera = iter(train_input_fn())
for i in range(400):
  features, labels = next(itera)
  train_step(features, labels)
</code></pre>
<p>UPDATE: It possibly seems to be the dataset. When I print a row of the dataset within the train_input_fn(), in estimators, it prints out the non-eager Tensor definition. In Keras, it prints out the eager values. Going through the Keras backend code, when it receives a tf.data.dataset as input, it handles it eagerly (and ONLY eagerly), which is why it was crashing whenever I used tf.function on the train_input_fn(). Basically, my guess is DNNClassifier is training faster than Keras because it runs more dataset code in graph mode. Will post any updates/finds.</p>
</div>
<div class="post-text" itemprop="text">
<p>I believe it is slower because it is not being executed on the graph. In order to execute on the graph in TF2 you'll need a function decorated with the tf.function decorator. Check out <a href="https://www.tensorflow.org/alpha/guide/autograph#define_the_model" rel="nofollow noreferrer">this section</a> for ideas on how to restructure your code.</p>
</div>
<span class="comment-copy">Thank you for the response. ^^ I agree that this would be the most likely cause of the slowdown. I was only uncertain because I assumed Google / the TF team had written Keras's fit() and Estimator's train() to automatically use tf.function or graph code in the backend implementation.   I've been attempting to run the code in graph mode for most of the day, using either tf.function or tf.compat.v1.disable_eager_execution(). In graph mode, estimators train correctly, but Keras experiences a ton of strange errors in the DenseFeatures() layer. I will keep digging and post updates. Thank you. ^^</span>
<span class="comment-copy">Good luck, thanks for the update.</span>
<span class="comment-copy">Been digging around a bit more and found this: "Keras layers/models inherit from tf.train.Checkpointable and are integrated with @tf.function, which makes it possible to directly checkpoint or export SavedModels from Keras objects." (<a href="https://www.tensorflow.org/alpha/guide/effective_tf2" rel="nofollow noreferrer">Effective TF2</a>) So I'm gonna assume the code is already using graph mode. The only lead I have is our feature_columns are basically a 1million vocabulary indicator_column(categorical_column(...)). I'm thinking maybe Keras is just way slower on this size and type. Gonna keep on digging and will post any finds.</span>
<span class="comment-copy">Great find! Curious....</span>
