<div class="post-text" itemprop="text">
<p>I know that there are easy ways to generate lists of unique random integers (e.g. <code>random.sample(range(1, 100), 10)</code>).</p>
<p>I wonder whether there is some better way of generating a list of unique random floats, apart from writing a function that acts like a range, but accepts floats like this:</p>
<pre><code>import random

def float_range(start, stop, step):
    vals = []
    i = 0
    current_val = start
    while current_val &lt; stop:
        vals.append(current_val)
        i += 1
        current_val = start + i * step
    return vals

unique_floats = random.sample(float_range(0, 2, 0.2), 3)
</code></pre>
<p>Is there a better way to do this?</p>
</div>
<div class="post-text" itemprop="text">
<h2>Answer</h2>
<p>One easy way is to keep a set of all random values seen so far and reselect if there is a repeat:</p>
<pre><code>import random

def sample_floats(low, high, k=1):
    """ Return a k-length list of unique random floats
        in the range of low &lt;= x &lt;= high
    """
    result = []
    seen = set()
    for i in range(k):
        x = random.uniform(low, high)
        while x in seen:
            x = random.uniform(low, high)
        seen.add(x)
        result.append(x)
    return result
</code></pre>
<h2>Notes</h2>
<ul>
<li><p>This technique is how Python's own <em>random.sample()</em> is implemented.</p></li>
<li><p>The function uses a <a href="https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset" rel="noreferrer">set</a> to track previous selections because searching a set is O(1) while searching a list is O(n).</p></li>
<li><p>Computing the probability of a duplicate selection is equivalent to the famous <a href="https://en.wikipedia.org/wiki/Birthday_problem" rel="noreferrer">Birthday Problem</a>.  </p></li>
<li><p>Given 2**53 distinct possible values from <em>random()</em>, duplicates are infrequent. 
On average, you can expect a duplicate float at about 120,000,000 samples.</p></li>
</ul>
<h2>Variant:  Limited float range</h2>
<p>If the population is limited to just a range of evenly spaced floats, then it is possible to use <a href="https://docs.python.org/2.7/library/random.html#random.sample" rel="noreferrer"><em>random.sample()</em></a> directly.  The only requirement is that the population be a <a href="https://docs.python.org/2.7/glossary.html#term-sequence" rel="noreferrer">Sequence</a>:</p>
<pre><code>from __future__ import division
from collections import Sequence

class FRange(Sequence):
    """ Lazily evaluated floating point range of evenly spaced floats
        (inclusive at both ends)

        &gt;&gt;&gt; list(FRange(low=10, high=20, num_points=5))
        [10.0, 12.5, 15.0, 17.5, 20.0]

    """
    def __init__(self, low, high, num_points):
        self.low = low
        self.high = high
        self.num_points = num_points

    def __len__(self):
        return self.num_points

    def __getitem__(self, index):
        if index &lt; 0:
            index += len(self)
        if index &lt; 0 or index &gt;= len(self):
            raise IndexError('Out of range')
        p = index / (self.num_points - 1)
        return self.low * (1.0 - p) + self.high * p
</code></pre>
<p>Here is a example of choosing ten random samples without replacement from a range of 41 evenly spaced floats from 10.0 to 20.0.</p>
<pre><code>&gt;&gt;&gt; import random
&gt;&gt;&gt; random.sample(FRange(low=10.0, high=20.0, num_points=41), k=10)
[13.25, 12.0, 15.25, 18.5, 19.75, 12.25, 15.75, 18.75, 13.0, 17.75]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you need to guarantee uniqueness, it may be more efficient to</p>
<ol>
<li>Try and generate <code>n</code> random floats in <code>[lo, hi]</code> at once.</li>
<li>If the length of the unique floats is not <code>n</code>, try and generate however many floats are still needed </li>
</ol>
<p>and continue accordingly until you have enough, as opposed to generating them 1-by-1 in a Python level loop checking against a set.</p>
<p><strong>If you can afford NumPy</strong> doing so with <code>np.random.uniform</code> can be a huge speed-up.</p>
<pre><code>import numpy as np

def gen_uniq_floats(lo, hi, n):
    out = np.empty(n)
    needed = n
    while needed != 0:
        arr = np.random.uniform(lo, hi, needed)
        uniqs = np.setdiff1d(np.unique(arr), out[:n-needed])
        out[n-needed: n-needed+uniqs.size] = uniqs
        needed -= uniqs.size
    np.random.shuffle(out)
    return out.tolist()
</code></pre>
<p><strong>If you cannot use NumPy</strong>, it still may be more efficient depending on your data needs to apply the same concept of checking for dupes afterwards, maintaining a set.</p>
<pre><code>def no_depend_gen_uniq_floats(lo, hi, n):
    seen = set()
    needed = n
    while needed != 0:
        uniqs = {random.uniform(lo, hi) for _ in range(needed)}
        seen.update(uniqs)
        needed -= len(uniqs)
    return list(seen)
</code></pre>
<hr/>
<h3>Rough benchmark</h3>
<p><strong>Extreme degenerate case</strong> </p>
<pre><code># Mitch's NumPy solution
%timeit gen_uniq_floats(0, 2**-50, 1000)
<b>153 µs ± 3.71 µs per loop</b> (mean ± std. dev. of 7 runs, 10000 loops each)

# Mitch's Python-only solution
%timeit no_depend_gen_uniq_floats(0, 2**-50, 1000)
<b>495 µs ± 43.9 µs per loop</b> (mean ± std. dev. of 7 runs, 1000 loops each)

# Raymond Hettinger's solution (single number generation)
%timeit sample_floats(0, 2**-50, 1000)
<b>618 µs ± 13 µs per loop</b> (mean ± std. dev. of 7 runs, 1000 loops each)</code></pre>
<p><strong>More "normal" case</strong> (with larger sample)</p>
<pre><code># Mitch's NumPy solution
%timeit gen_uniq_floats(0, 1, 10**5)
<b>15.6 ms ± 1.12 ms per loop</b> (mean ± std. dev. of 7 runs, 100 loops each)

# Mitch's Python-only solution
%timeit no_depend_gen_uniq_floats(0, 1, 10**5)
<b>65.7 ms ± 2.31 ms per loop</b> (mean ± std. dev. of 7 runs, 10 loops each)

# Raymond Hettinger's solution (single number generation)
%timeit sample_floats(0, 1, 10**5)
<b>78.8 ms ± 4.22 ms per loop</b> (mean ± std. dev. of 7 runs, 10 loops each)</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can easily use your list of integers to generate floats:</p>
<pre><code>int_list = random.sample(range(1, 100), 10)
float_list = [x/10 for x in int_list]
</code></pre>
<p>Check out <a href="https://stackoverflow.com/questions/477486/how-to-use-a-decimal-range-step-value">this Stack Overflow question</a> about generating random floats.</p>
<p>If you want it to work with python2, add this import:</p>
<pre><code>from __future__ import division
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could just use <code>random.uniform(start, stop)</code>. With double precision floats, you can be relatively sure that they are unique if your set is small. If you want to generate a big number of random floats and need to avoid that you have a number twice, check before adding them to the list.</p>
<p>However, if you are looking for a selection of specific numbers, this is not the solution.</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>min_val=-5
max_val=15

numpy.random.random_sample(15)*(max_val-min_val) + min_val
</code></pre>
<p>or use uniform</p>
<pre><code>numpy.random.uniform(min_val,max_val,size=15)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>As stated in the documentation Python has the random.random() function:</p>
<pre><code>import random
random.random()
</code></pre>
<p>Then you will get a float val as: 0.672807098390448</p>
<p>So all you need to do is make a <code>for</code> loop and print out random.random():</p>
<pre><code>&gt;&gt;&gt; for i in range(10):
print(random.random())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://github.com/erikrose/more-itertools" rel="nofollow noreferrer"><code>more_itertools</code></a> has a generic <a href="https://more-itertools.readthedocs.io/en/latest/api.html?highlight=numeric#more_itertools.numeric_range" rel="nofollow noreferrer"><code>numeric_range</code></a> that handles both integers and floats.</p>
<pre><code>import random

import more_itertools as mit

random.sample(list(mit.numeric_range(0, 2, 0.2)), 3)
# [0.8, 1.0, 0.4]

random.sample(list(mit.numeric_range(10.0, 20.0, 0.25)), 10)
# [17.25, 12.0, 19.75, 14.25, 15.25, 12.75, 14.5, 15.75, 13.5, 18.25]
</code></pre>
</div>
<span class="comment-copy">Generate random ints, scale and translate.</span>
<span class="comment-copy">@PeterWood Agreed, but that isn't what you previously said - perhaps a misunderstanding.</span>
<span class="comment-copy">@logc Sampling from a continuous distribution is a <i>very</i> well known problem. See <a href="https://en.wikipedia.org/wiki/Pseudo-random_number_sampling#Continuous_distributions" rel="nofollow noreferrer">wiki</a>.</span>
<span class="comment-copy">What are you trying to do with your random floats?</span>
<span class="comment-copy">Note that "unique" by definition is something other than "random".</span>
<span class="comment-copy">this is what i would recommend ... set lookup is O(1) ... and random float is easy</span>
<span class="comment-copy">@ViníciusAguiar: Looking up <code>x in result</code> takes time proportional to the length of <code>result</code>. If you made <code>result</code> a set, it wouldn’t be unsorted.</span>
<span class="comment-copy">@RaymondHettinger And agreed! I don't know, I just get the impression 99% of people who believe they need "unique random floats" don't really need that "uniqueness", so I hope they don't get the wrong idea from this question/answer. Sampling without replacement from a continuous distribution isn't something I've ever come across - granted if you had a pathologically small interval it might be necessary for some reason.</span>
<span class="comment-copy">@StefanPochmann To go beyond 2^53, you need to use bits in the exponent.  That would cause the random floats to no longer be equidistributed.</span>
<span class="comment-copy">I second what Mitch said:  I don't think the code to sample unique floating point numbers from a continuous distribution is ever useful.  If you are OK with floats being arbitrarily close together, but they can't be the same, you are likely making some wrong assumptions.</span>
<span class="comment-copy">So the point is that <i>numpy</i> is faster than regular Python for numeric work?  And that you think there should be a <i>numpy</i> answer to a non-numpy question?</span>
<span class="comment-copy">@RaymondHettinger My point was moreso that if we have a fast way (i.e. <code>np.random.uniform</code>) to generate a whole bunch of random floats at once, it is faster to try to do it all at once and <i>then</i> check for dupes than proceed one at a time with <code>random.uniform</code>. So yes, I'm not sure how much of a performance gain you would see using <code>random.uniform</code> in a list comp. and updating a set (maybe just less set checks). but I think this could be useful for someone?</span>
<span class="comment-copy">Yes.  Cleaning out dups at the end works just as well.</span>
<span class="comment-copy">@RaymondHettinger I tried to flesh out my answer a bit to make the NumPy dependency more clear and added a Python example of what I was trying to say if I was talking in circles before :) thanks!</span>
<span class="comment-copy">This will only work as intended in Python 3.x, because in Python 2.x it will do integer division. You could explicitly write <code>x / 10.</code> to make it work on both</span>
<span class="comment-copy">@Graipher Thanks, added python2 compatibility</span>
<span class="comment-copy">If you're planning on checking for uniqueness before keeping a generated float, I would suggest using a set instead of a list to keep it O(n), as checking a list each time would make it O(n^2)</span>
<span class="comment-copy">Assurance of uniqueness is a <a href="https://en.wikipedia.org/wiki/Birthday_problem" rel="nofollow noreferrer">en.wikipedia.org/wiki/Birthday_problem</a> , so being "relatively sure that they are unique" isn't sound once the number of selections grows sufficiently large.</span>
<span class="comment-copy">with the number of floats searched given in the example, the risk of having double values is small. Nevertheless, you are right. Answer updated.</span>
<span class="comment-copy"><code>np.random.uniform</code> effectively does this for you.</span>
<span class="comment-copy">This doesn't guarantee uniqueness. Try for example <code>len(set(numpy.random.uniform(1, 1 + 2**-40, size=1000)))</code> and you'll get only about 887 instead of 1000.</span>
