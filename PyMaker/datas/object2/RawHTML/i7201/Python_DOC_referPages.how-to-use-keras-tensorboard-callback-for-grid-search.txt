<div class="post-text" itemprop="text">
<p>I'm using the Keras TensorBoard callback.
I would like to run a grid search and visualize the results of each single model in the tensor board.
The problem is that all results of the different runs are merged together and the loss plot is a mess like this:
<a href="https://i.stack.imgur.com/t7nhp.png" rel="noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/t7nhp.png"/></a></p>
<p>How can I rename each run to have something similar to this:
<a href="https://i.stack.imgur.com/molxs.jpg" rel="noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/molxs.jpg"/></a></p>
<p>Here the code of the grid search:</p>
<pre><code>df = pd.read_csv('data/prepared_example.csv')

df = time_series.create_index(df, datetime_index='DATE', other_index_list=['ITEM', 'AREA'])

target = ['D']
attributes = ['S', 'C', 'D-10','D-9', 'D-8', 'D-7', 'D-6', 'D-5', 'D-4',
       'D-3', 'D-2', 'D-1']

input_dim = len(attributes)
output_dim = len(target)

x = df[attributes]
y = df[target]

param_grid = {'epochs': [10, 20, 50],
              'batch_size': [10],
              'neurons': [[10, 10, 10]],
              'dropout': [[0.0, 0.0], [0.2, 0.2]],
              'lr': [0.1]}

estimator = KerasRegressor(build_fn=create_3_layers_model,
                           input_dim=input_dim, output_dim=output_dim)


tbCallBack = TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=False)

grid = GridSearchCV(estimator=estimator, param_grid=param_grid, n_jobs=-1, scoring=bug_fix_score,
                            cv=3, verbose=0, fit_params={'callbacks': [tbCallBack]})

grid_result = grid.fit(x.as_matrix(), y.as_matrix())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I don't think there is any way to pass a "per-run" parameter to <code>GridSearchCV</code>. Maybe the easiest approach would be to subclass <code>KerasRegressor</code> to do what you want.</p>
<pre><code>class KerasRegressorTB(KerasRegressor):

    def __init__(self, *args, **kwargs):
        super(KerasRegressorTB, self).__init__(*args, **kwargs)

    def fit(self, x, y, log_dir=None, **kwargs):
        cbs = None
        if log_dir is not None:
            params = self.get_params()
            conf = ",".join("{}={}".format(k, params[k])
                            for k in sorted(params))
            conf_dir = os.path.join(log_dir, conf)
            cbs = [TensorBoard(log_dir=conf_dir, histogram_freq=0,
                               write_graph=True, write_images=False)]
        super(KerasRegressorTB, self).fit(x, y, callbacks=cbs, **kwargs)
</code></pre>
<p>You would use it like:</p>
<pre><code># ...

estimator = KerasRegressorTB(build_fn=create_3_layers_model,
                             input_dim=input_dim, output_dim=output_dim)

#...

grid = GridSearchCV(estimator=estimator, param_grid=param_grid,
n_jobs=1, scoring=bug_fix_score,
                  cv=2, verbose=0, fit_params={'log_dir': './Graph'})

grid_result = grid.fit(x.as_matrix(), y.as_matrix())
</code></pre>
<p>Update:</p>
<p>Since <code>GridSearchCV</code> runs the same model (i.e. the same configuration of parameters) more than once due to cross-validation, the previous code will end up putting multiple traces in each run. Looking at the source (<a href="https://github.com/scikit-learn/scikit-learn/blob/0.19.X/sklearn/model_selection/_search.py" rel="nofollow noreferrer">here</a> and <a href="https://github.com/scikit-learn/scikit-learn/blob/0.19.X/sklearn/model_selection/_validation.py" rel="nofollow noreferrer">here</a>), there doesn't seem to be a way to retrieve the "current split id". At the same time, you shouldn't just check for existing folders and add subfixes as needed, because the jobs run (potentially at least, although I'm not sure if that's the case with Keras/TF) in parallel. You can try something like this:</p>
<pre><code>import itertools
import os

class KerasRegressorTB(KerasRegressor):

    def __init__(self, *args, **kwargs):
        super(KerasRegressorTB, self).__init__(*args, **kwargs)

    def fit(self, x, y, log_dir=None, **kwargs):
        cbs = None
        if log_dir is not None:
            # Make sure the base log directory exists
            try:
                os.makedirs(log_dir)
            except OSError:
                pass
            params = self.get_params()
            conf = ",".join("{}={}".format(k, params[k])
                            for k in sorted(params))
            conf_dir_base = os.path.join(log_dir, conf)
            # Find a new directory to place the logs
            for i in itertools.count():
                try:
                    conf_dir = "{}_split-{}".format(conf_dir_base, i)
                    os.makedirs(conf_dir)
                    break
                except OSError:
                    pass
            cbs = [TensorBoard(log_dir=conf_dir, histogram_freq=0,
                               write_graph=True, write_images=False)]
        super(KerasRegressorTB, self).fit(x, y, callbacks=cbs, **kwargs)
</code></pre>
<p>I'm using <code>os</code> calls for Python 2 compatibility, but if you are using Python 3 you may consider the nicer <a href="https://docs.python.org/3/library/pathlib.html" rel="nofollow noreferrer"><code>pathlib</code> module</a> for path and directory handling.</p>
<p>Note: I forgot to mention it earlier, but just in case, note that passing <code>write_graph=True</code> will log a graph <em>per run</em>, which, depending on your model, could mean a lot (relatively speaking) of this space. The same would apply to <code>write_images</code>, although I don't know the space that feature requires.</p>
</div>
<div class="post-text" itemprop="text">
<p>It's easy, just save logs to separate dirs with concatenated parameters string as dir name:</p>
<p>Here is example using date as name of run:</p>
<pre><code>datetime_str = ('{date:%Y-%m-%d-%H:%M:%S}'.format(date=datetime.now()))
callbacks = [
    ModelCheckpoint(model_filepath, monitor='val_loss', save_best_only=True, verbose=0),
    TensorBoard(log_dir='./logs/'+datetime_str, histogram_freq=0, write_graph=True, write_images=True),
]

history = model.fit_generator(
    generator=generator.batch_generator(is_train=True),
    epochs=config.N_EPOCHS,
    steps_per_epoch=100,
    validation_data=generator.batch_generator(is_train=False),
    validation_steps=10,
    verbose=1,
    shuffle=False,
    callbacks=callbacks)
</code></pre>
</div>
<span class="comment-copy">Thank you for the detailed suggestion. I'll try it later today and I'll let you know. Just one consideration: Does this solution create several folders? In that case am I able to display all the runs in a single tensorboard or I have to run several instances of it?</span>
<span class="comment-copy">@paolof89 Yes, it does create a directory per experiment, but, in fact, the "Runs" that you see in TensorBoard are really just subfolders with log information. If you open TensorBoard in the root of the logs (in the example <code>./Graph</code>) you will see one "run" per experiment, all of them together, or you can open TensorBoard in the directory of a specific run to take a closer look.</span>
<span class="comment-copy">I tested it, it works but there is one last issue. The GridSearchCV implements a k-fold tecnique, so in every folder you find k graph. The minimum k-fold value is 2 so my problem is not yet solved. Any idea about it?</span>
<span class="comment-copy">I'll open an issue on keras github in case some user had in the same issue</span>
<span class="comment-copy">@paolof89 I've updated the answer with a possible solution to that.</span>
