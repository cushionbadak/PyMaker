<div class="post-text" itemprop="text">
<p>So I'm a beginner 'scraper' with not a whole truckload of programming experience.</p>
<p>I'm using Python, in the Canopy environment, to scrape up some downloaded XML files and using the <strong>xml.dom</strong> parser to do so. I'm simply trying to scrape the tags from the very first <strong>us-bibliographic-patent-grant</strong> (which is why I'm using the <strong>[0]</strong>) just to see how I want to parse and store the entire dataset; rather than doing it all at once. An excerpt from the xml looks like this:</p>
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;!DOCTYPE us-patent-grant SYSTEM "us-patent-grant-v42-2006-08-23.dtd" [ ]&gt;
&lt;us-patent-grant lang="EN" dtd-version="v4.2 2006-08-23" file="USD0606726-20091229.XML" status="PRODUCTION" id="us-patent-grant" country="US" date-produced="20091214" date-publ="20091229"&gt;
&lt;us-bibliographic-data-grant&gt;
&lt;publication-reference&gt;
&lt;document-id&gt;
&lt;country&gt;US&lt;/country&gt;
&lt;doc-number&gt;D0606726&lt;/doc-number&gt;
&lt;kind&gt;S1&lt;/kind&gt;
&lt;date&gt;20091229&lt;/date&gt;
&lt;/document-id&gt;
&lt;/publication-reference&gt;
&lt;application-reference appl-type="design"&gt;
&lt;document-id&gt;
&lt;country&gt;US&lt;/country&gt;
&lt;doc-number&gt;29299001&lt;/doc-number&gt;
&lt;date&gt;20071217&lt;/date&gt;
</code></pre>
<p>My code so far looks like this:</p>
<pre><code>from xml.dom import minidom

filename = "C:/Users/SMOLENSK/Documents/Inventor Research/xml_2009/ipg091229.xml"

f = open(filename, 'r')

doc = f.read()

f.close()

xmldata = '&lt;root&gt;' + doc + '&lt;/root&gt;'

data = minidom.parse(xmldata)

US_Biblio = xmldata.getElementsByTagName("us-bibliographic-data-grant")[0]

pat_num = US_Biblio.getElementsByTagName("doc-number")[0]

dates = pat_num.getElementsByTagName("date")

for date in dates:
    print(date)
</code></pre>
<p>Now I have gotten some messages for Memory Errors after the code fully ran but it has only been able to run once and unfortunately I was unable to jot down what exactly happened. Due to the high load of data (this file alone being 4.6 million lines) the operation crashes most every time and I'm unable to replicate the Errors.</p>
<p>Is there anything anyone can see wrong with the code? My code is parsing the entire dataset before it starts storing each tag name but might there be a way to parse only a certain amount? Perhaps just make a new xml file with the first set.</p>
<p>If you're wondering I used the   to bypass the issue of the </p>
<blockquote>
<p>ExpatError: junk after line xxx</p>
</blockquote>
<p>I was getting beforehand. I know my coding skills aren't amazing so hopefully i did not make a simple and disgusting programming error.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try:</p>
<pre><code>with open(filename, 'r') as f:
    data = minidom.parse(f)
</code></pre>
<p>If you really need the  tag you may need to mess around a bit, maybe:</p>
<pre><code>data = minidom.parse(itertools.chain('&lt;root&gt;', f, '&lt;/root&gt;')
</code></pre>
</div>
<span class="comment-copy">You are duplicating the whole file to add the <code>&lt;root&gt;</code> tags. <code>minidom.parse</code> will take a <code>file</code> object. Try recasting using <code>with</code> and <code>data = minidom.parse(f)</code></span>
<span class="comment-copy">Hey, Mike. Sorry to say that although I do understand what you mean about my 'xmldata' that I'm unsure how to "recast using 'with'". Could you help clarify with an example by chance?</span>
<span class="comment-copy">... <a href="https://stackoverflow.com/q/7171140/2823755">Using Python Iterparse For Large XML Files</a> ... Maybe try lxml.  Also, minidomn has an <a href="https://docs.python.org/3/library/xml.dom.minidom.html#xml.dom.minidom.Node.unlink" rel="nofollow noreferrer">unlink</a> method that helps free up unused stuff.  Every time you narrow down the search and make a new assignment (e.g.<code>US_Biblio =...</code>, try deleting the previous variable, (e.g.( <code>del data </code>)</span>
<span class="comment-copy">Not what you asked, but have you considered sequentially reading line by line and using regex to find the <code>doc-number</code> and <code>date</code> fields? If that is all you want.</span>
<span class="comment-copy">When I use the <code>itertools.chain</code> outside of the <code>with</code> statement I'm given the same <i>ExpatError: junk after line xxx...</i> and within the <code>with</code> statement I get an error <i>AttributeError: 'itertools.chain' object has no attribute 'read'</i>  I'm assuming the first is again due to non-exact XML root elements repeating in the data itself but the attribute error happens because of?</span>
<span class="comment-copy">The parse must want a <code>file</code> object (that has a read method). The chain we are giving it  is an iterator that returns strings but obviously not what the parse wants.  Is the XML well formed? If not maybe try the <code>BeautifulSoup</code> package to parse it.</span>
<span class="comment-copy">Have a look at this (question)[<a href="https://stackoverflow.com/questions/45395811/parsing-xml-with-beautiful-soup]" title="parsing xml with beautiful soup%5d">stackoverflow.com/questions/45395811/â€¦</a>. It is a duplicate of your question.</span>
