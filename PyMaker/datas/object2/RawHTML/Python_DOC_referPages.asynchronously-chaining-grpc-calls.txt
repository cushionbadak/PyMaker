<div class="post-text" itemprop="text">
<p>Is there a straightforward way to asynchronously chain GRPC calls in Python? </p>
<p>This feels like the kind of things that "should" be feasible, but I can't seem to find it.</p>
<p>Here's a rough idea of what I feel I should be able to do:</p>
<pre><code>class MyServer(my_grpc.MyServicer):
  def __init__(self, child_stub):
    self.child_stub_ = child_stub

  def MyMethod(self, request, context):
    child_result = self.child_stub_.ChildMethod.future(my_grpc.ChildMethodParams())

    child_result.add_done_callback(something_that_completes_MyMethod)

    return presumably_something
</code></pre>
<p>Is there something I'm missing here? It feels like this would be a common use-case, yet I can't seem to find anything related to it in the docs.</p>
</div>
<div class="post-text" itemprop="text">
<p>Edit: I believe you're trying to send two response for one request on a unary request/response setup, which I don't believe to be possible.  Instead you should do a unary request and streaming responses, which will allow for many responses.</p>
<p>client</p>
<pre><code>import grpc
import test_pb2_grpc as pb_grpc
import test_pb2 as pb2

def test():
    channel = grpc.insecure_channel('localhost:50051')
    stub = pb_grpc.TestStub(channel=channel)

    for response in stub.Produce(pb2.Empty()):
        print(response.result)

if __name__ == '__main__':
    test()
</code></pre>
<p>Server</p>
<pre><code>import test_pb2_grpc as pb_grpc
import test_pb2 as pb2
import time
import grpc
from concurrent import futures


class test_servcie(pb_grpc.TestServicer):
    def Produce(self, request, context):
        my_method_results = [50, 200]
        for result in my_method_results:
            yield pb2.Resp(result=result)


def serve():
    server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
    pb_grpc.add_TestServicer_to_server(test_servcie(), server)
    server.add_insecure_port('[::]:50051')
    print("service started")
    server.start()
    try:
        while True:
            time.sleep(3600)
    except KeyboardInterrupt:
        server.stop(0)


if __name__ == '__main__':
    serve()
</code></pre>
<p>proto  </p>
<pre><code>syntax = "proto3";

package api;


service Test {
    rpc Produce (Empty) returns (stream Resp);
}

message Empty {}


message Resp{
    int32 result = 1;
}
</code></pre>
</div>
<span class="comment-copy">That's not "quite" what I'm looking for. I'm looking for a way to implement <code>DuckServer.Quack</code> in a way that would let me use something like your <code>RpcHandler</code> within it.</span>
<span class="comment-copy">So, rereading your original problem and your comment now, I believe you want a gRPC server that would receive a request and then asynchronously return that request and return something else.  To my knowledge that's not possible on a unary request/response in gRPC because in a unary setup, one request gets one response.  Now if you're wanting to receive a request then send more than one response, that sounds like a unary/stream setup and this is feasible.  If this is what you're after I can provide an example.</span>
<span class="comment-copy">See my updated answer, which is instead a unary request and streaming response.  In this example I return two separate responses.</span>
<span class="comment-copy">It's actually trivial to do with unary requests in c++ by using a completion queue, which is why I'm baffled at not having an equivalent in Python. Your updated answer solves nothing as gRPC will just keep invoking the generator.</span>
<span class="comment-copy">I'm not sure what you're after then, because in my example the server receives one request and sends two responses, which is what I thought you were after.</span>
