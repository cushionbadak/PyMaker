<div class="post-text" itemprop="text">
<p>I have a list of tuples with 3 members in each tuple as seen below:</p>
<pre><code>[(-5092793511388848640, 'test1', 1),
 (-5092793511388848639, 'test0', 0), 
 (-5092793511388848638, 'test3', 3), 
 (-5092793511388848637, 'test2', 2), 
 (-5092793511388848636, 'test5', 5)]
</code></pre>
<p>The tuples are ordered in ascending according to first element of each tuple - the hash value of each key (e.g <code>'test0'</code>). I want to find a quick way of searching through these tuples using binary search of their hash values to find a specific key. Problem is the quickest way I have found is using a for loop:</p>
<pre><code>def get(key, D, hasher=hash):
    '''
    Returns the value in the dictionary corresponding to the given key.

    Arguements:
    key -- desired key to retrieve the value of.
    D -- intended dictionary to retrieve value from.
    hasher -- the hash function to be used on the key.
    '''
    for item in D:
        if item[0] == hash(key):
            return item[2]
    raise TypeError('Key not found in the dictionary.')
</code></pre>
<p>The function I have written above seems to be very slow at searching through a much longer list of tuples, lets say a list of 6000 different tuples. It also breaks if there are any hash collisions. I was wondering if there was a more efficient/quick way of searching the list for the correct tuple?</p>
<p>Side note: I know using dictionaries will be a much quicker and easier way to solve my problem but I'd like to avoid using them.</p>
</div>
<div class="post-text" itemprop="text">
<p>You could modify  <code>bisect</code>  to just check the first element: </p>
<pre><code>def bisect_left(a, x, lo=0, hi=None):
    if lo &lt; 0:
        raise ValueError('lo must be non-negative')
    if hi is None:
        hi = len(a)
    while lo &lt; hi:
        mid = (lo+hi) // 2
        if a[mid][0] &lt; x:
            lo = mid+1
        else: hi = mid
    return lo

def get_bis(key, d):
    h = hash(key)
    ind = bisect_left(d, h)
    if ind == -1:
        raise KeyError()
    for i in xrange(ind, len(d)):
        if d[i][0] != h:
            raise KeyError()
        if d[i][1] == key:
            return d[i][2]
    raise KeyError()
</code></pre>
<p>replicating some collisions, it does what it should:</p>
<pre><code>In [41]: l = [(-5092793511388848640, 'test1', 1), (-5092793511388848639, 'test9', 0), (-5092793511388848639, 'test0', 3), (-5092793511388848637, 'test2', 2), (-5092793511388848636, 'test5', 5)]

In [42]: get("test0", l)
Out[42]: 3

In [43]: get("test1", l)
Out[43]: 1

In [44]: get(-5092793511388848639, l)
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
&lt;ipython-input-44-81e928da1ac8&gt; in &lt;module&gt;()
----&gt; 1 get(-5092793511388848639, l)

&lt;ipython-input-30-499e71432196&gt; in get(key, d)
      6     for sub in islice(d, ind, None):
      7         if sub[0] != h:
----&gt; 8             raise KeyError()
      9         if sub[1] == key:
     10             return sub

KeyError: 
</code></pre>
<p>Some timings:</p>
<pre><code>In [91]: l = sorted((hash(s), s,randint(1,100000)) for s in ("".join(sample(ascii_letters,randint(10,26))) for _ in xrange(1000000)))

In [92]: l[-1]
Out[92]: (9223342880888029755, 'FocWPinpYZXjHhBqRkJxQeGMa', 43768)

In [93]: timeit get_bis(l[-1][1],l)hed 
100000 loops, best of 3: 5.29 µs per loop

In [94]: l[250000]
Out[94]: (-4616437486317828880, 'qXsybdhFPLczWwCQkm', 86136)

In [95]: timeit get_bis(l[250000][1],l)
100000 loops, best of 3: 4.4 µs per loop

In [96]: l[750000]
Out[96]: (4623630109115829672, 'dlQewhpMoBGmn', 39904)

In [97]: timeit get_bis(l[750000][1],l)
100000 loops, best of 3: 4.46 µs per loop
</code></pre>
<p>To get a better idea you would have to throw in collisions but to find the section that the hash may belong is pretty efficient.</p>
<p>Just type casting a few variables and compiling with cython:</p>
<pre><code>def cython_bisect_left(a, long x, long lo=0):
   if lo &lt; 0:
       raise ValueError('lo must be non-negative')
   cdef long hi = len(a)
   while lo &lt; hi:
       mid = (lo + hi) // 2
       if a[mid][0] &lt; x:
           lo = mid + 1
       else:
           hi = mid
   return lo
def cython_get(str key, d):
   cdef long h = hash(key)
   cdef ind = cython_bisect_left(d, h)
   if ind == -1:
       raise KeyError()
   for i in xrange(ind, len(d)):
       if d[i][0] != h:
           raise KeyError()
       if d[i][1] == key:
           return d[i][2]
   raise KeyError()
</code></pre>
<p>Gets us almost down to 1 microsecond:</p>
<pre><code>In [13]: timeit cython_get(l[-1][1],l)
The slowest run took 40.77 times longer than the fastest. This could mean that an intermediate result is being cached 
1000000 loops, best of 3: 1.44 µs per loop

In [14]: timeit cython_get(l[250000][1],l)
1000000 loops, best of 3: 1.33 µs per loop

In [15]: timeit cython_get(l[750000][1],l)
1000000 loops, best of 3: 1.33 µs per loop
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First, prehash the key, don't do it over and over. Second, you can use <code>next</code> with an unpacking generator expression to optimize a bit:</p>
<pre><code>def get(key, D, hasher=hash):
    keyhash = hasher(key)
    try:
        return next(v for hsh, k, v in D if keyhash == hsh and key == k)
    except StopIteration:
        raise TypeError('Key not found in the dictionary.')
</code></pre>
<p>That said, you claim you want to do a binary search, but the above is still a linear search, just optimized to avoid redundant work and to stop when the desired key is found (it checks hash first, assuming key comparison is expensive, then checks key equality only on hash match, since you complained about issues with duplicates). If the goal is binary search, and <code>D</code> is sorted by hash code, you'd want to use <a href="https://docs.python.org/3/library/bisect.html" rel="nofollow noreferrer">the <code>bisect</code> module</a>. It's not trivial to do so (because <code>bisect</code> doesn't take a <code>key</code> argument like <code>sorted</code>), but if you could split <code>D</code> into two parts, one with just hash codes, and one with codes, keys and values, you could do:</p>
<pre><code>import bisect

def get(key, Dhashes, D, hasher=hash):
    keyhash = hasher(key)
    # Search whole list of hashes for beginning of range with correct hash
    start = bisect.bisect_left(Dhashes, keyhash)
    # Search for end point of correct hashes (limit to entries after start for speed)
    end = bisect.bisect_right(Dhashes, keyhash, start)
    try:
        # Linear search of only start-&gt;end indices for exact key
        return next(v for hsh, k, v in D[start:end] if key == k)
    except StopIteration:
        raise TypeError('Key not found in the dictionary.')
</code></pre>
<p>That gets you true binary search, but as noted, requires that the hash codes be separated from the complete <code>tuple</code>s of <code>hashcode, key, value</code> ahead of time, before the search. Splitting the hash codes at the time of each search wouldn't be worth it since the loop that split them off could have just found your desired value directly (it would only be worth splitting if you were performing many searches at once).</p>
<p>As Padraic notes in <a href="https://stackoverflow.com/a/34498372/364696">his answer</a>, at the expense of giving up the C accelerator code, you could copy and modify the pure Python implementation of <a href="https://hg.python.org/cpython/file/3.5/Lib/bisect.py#l24" rel="nofollow noreferrer"><code>bisect.bisect_right</code></a> and <a href="https://hg.python.org/cpython/file/3.5/Lib/bisect.py#l67" rel="nofollow noreferrer"><code>bisect.bisect_left</code></a> changing each use of <code>a[mid]</code> to <code>a[mid][0]</code> which would get you <code>bisect</code> code that doesn't require you to maintain a separate <code>list</code> of hashes. The memory savings might be worth the higher lookup costs. Don't use <code>itertools.islice</code> to perform the slicing though, as <code>islice</code> with a <code>start</code> index iterates the whole <code>list</code> up to that point; true slicing only reads and copies what you care about. If you want to avoid the second <code>bisect</code> operation though, you could always write your own <code>Sequence</code>-optimized <code>islice</code> and combine it with <code>itertools.takewhile</code> to get a similar effect without having to calculate the <code>end</code> index up front. Code for that might be something like:</p>
<pre><code>from itertools import takewhile

# Copied from bisect.bisect_left, with unused arguments removed and only
# index 0 of each tuple checked
def bisect_idx0_left(a, x):
    lo, hi = 0, len(a)
    while lo &lt; hi:
        mid = (lo+hi)//2
        if a[mid][0] &lt; x: lo = mid+1
        else: hi = mid
    return lo

def sequence_skipper(seq, start):
    return (seq[i] for i in xrange(start, len(seq)))

def get(key, D, hasher=hash):
    keyhash = hasher(key)
    # Search whole list of hashes for beginning of range with correct hash
    start = bisect_idx0_left(D, keyhash)
    # Make lazy iterator that skips start values in the list
    # and stops producing values when the hash stops matching
    hashmatches = takewhile(lambda x: keyhash == x[0], sequence_skipper(D, start))
    try:
        # Linear search of only indices with matching hashes for exact key
        return next(v for hsh, k, v in hashmatches if key == k)
    except StopIteration:
        raise TypeError('Key not found in the dictionary.')
</code></pre>
<p>Note: You could save even more work at the expense of more memory, by having <code>Dhashes</code> actually be <code>(hashcode, key)</code> pairs; assuming uniqueness, this would mean a single <code>bisect.bisect*</code> call, not two, and no need for a scan between indices for a <code>key</code> match; you either found it in the binary search or you didn't. Just for example, I generated 1000 key value pairs, storing them as either <code>(hashcode, key, value)</code> <code>tuple</code>s in a <code>list</code> (which I sorted on the <code>hashcode</code>), or a <code>dict</code> mapping <code>key</code>s-&gt;<code>value</code>s. The <code>key</code>s were all 65 bit <code>int</code>s (long enough that the hash code wasn't a trivial self-mapping). Using the linear search code I provided up top, it took ~15 microseconds to find the value located at index 321; with binary search (having copied hashes only to a separate <code>list</code>) it took just over 2 microseconds. Looking it up in the equivalent <code>dict</code> took ~55 _nano_seconds; the run time overhead even for binary search worked out to ~37x, and linear search ran ~270x higher. And that's before we get into the increased memory costs, increased code complexity, and increased overhead to maintain sorted order (assuming <code>D</code> is ever modified).</p>
<p>Lastly: You say "I'd like to avoid using [<code>dict</code>s]", but give no explanation as to why. <code>dict</code>s are the correct way to solve a problem like this; assuming no self-hashing (i.e. <code>key</code> is an <code>int</code> that hashes to itself, possibly saving the cost of the hash code), the memory overhead just for the <code>list</code> of <code>tuple</code>s (not including a separate <code>list</code> of hash codes) would be (roughly) twice that of a simple <code>dict</code> mapping keys to values. <code>dict</code> would also prevent accidentally storing duplicates, have ~<code>O(1)</code> insertion cost (even with <code>bisect</code>, insertion maintaining sorted order would have ~<code>O(log n)</code> lookup and <code>O(n)</code> memory move costs), ~<code>O(1)</code> lookup cost (vs. ~<code>O(log n)</code> with <code>bisect</code>), and beyond the big-O differences, would do all the work using C built-in functions that are heavily optimized, so the real savings would be greater.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try using list comprehensions. I'm not sure if it's the most efficient way, but it's the <strong>pythonic</strong> way and quite effective!</p>
<pre><code>  [ x for x in D if x[0] == hash(key) ]
</code></pre>
</div>
<span class="comment-copy">Dictionaries, "I'd like to avoid using them", why?</span>
<span class="comment-copy">I'm trying to recreate the dictionary function using only lists and tuples.</span>
<span class="comment-copy">@Ian: If the goal is "recreate the function of a <code>dict</code>", you wouldn't want to use linear or binary search, they're both algorithmically slower (<code>O(n)</code> and <code>O(log n)</code> respectively) than <code>dict</code> lookup (based on hashing, with average case <code>O(1)</code>, though theoretically <code>O(n)</code> if all the keys have the same hash code). Python <code>dict</code>s use open addressing to resolve hash collisions (which is more annoying to get right), but if you're trying to get similar results, a bucketed approach using collision chaining (<code>list</code> of <code>list</code> of <code>tuple</code>s) isn't too hard to implement.</span>
<span class="comment-copy">This is clever, but it does mean giving up the C accelerated implementation of CPython's <code>bisect</code> module (in brief testing, a C accelerated <code>bisect.bisect</code> on a <code>list</code> of 1000 hashes takes ~19% of the time of using this on the original <code>list</code> of <code>tuple</code>s); admittedly, not a completely unreasonable cost to pay). That said, this has the flaw that it does a linear scan of every index with a hash code &gt;= to the target code; if the target key exists, no problem, but if you search for a key that doesn't exist (particularly with a low value hash, e.g. <code>1</code>), then it's back to linear scan complexity.</span>
<span class="comment-copy">@ShadowRanger, if your hash is lower than anything in the list we don't search at all, if it is greater we at most search a single element. you could add more to it to stop when the hash is greater so you don't go further than needed using takewhile. As far as the speed goes the c implementation is used where available which is not everywhere. If speed were a concern a bit of cython would take care of that</span>
<span class="comment-copy"><code>islice</code> with a <code>start</code> index is implemented in a dumb way (it just iterates and discards <code>start</code> values), so you're still scanning from the beginning (admittedly in C with minimal work for each result) involving <code>O(n)</code> work to reach <code>ind</code> even before you begin the scan for an actual hit. <code>islice</code> with a <code>start</code> index is usually a bad idea when working with a <code>Sequence</code> type like <code>list</code> and you're skipping a large number of values. Also, you based your implementation on <code>bisect_right</code>, then subtracted <code>1</code> from the result; in the event of 2+ identical hashes, this can only find one of them.</span>
<span class="comment-copy">Actually, pretty sure if the hash is lower than anything in the <code>list</code>, <code>islice</code> throws a <code>ValueError</code> (because your <code>bisect</code> is returning <code>-1</code> and the <code>start</code> index for <code>islice</code> must be non-negative). Admittedly, you changed the "not found" exception type to <code>ValueError</code>, so that works (though the message would be confusing). If the hash is greater than all hashes, then <code>islice</code> iterates and discards everything (as I mentioned). And if the hash is neither too low, nor too high, but either the hash doesn't exist in the table or the hash exists but not the key, then it's scanning everything.</span>
