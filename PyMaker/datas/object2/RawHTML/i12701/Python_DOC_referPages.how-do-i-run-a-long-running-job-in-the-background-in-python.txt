<div class="post-text" itemprop="text">
<p>I have a web-service that runs long-running jobs (in the order of several hours). I am developing this using Flask, Gunicorn, and nginx.</p>
<p>What I am thinking of doing is to have the route which takes a long time to complete, call a function that creates a thread. The function will then return a guid back to the route, and the route will return a url (using the guid) that the user can use to check progress. I am making the thread a daemon (thread.daemon = True) so that the thread exits if my calling code exits (unexpectedly).</p>
<p>Is this the correct approach to use? It works, but that doesn't mean that it is correct.</p>
<pre><code>my_thread = threading.Thread(target=self._run_audit, args=())
my_thread.daemon = True
my_thread.start()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The more regular approch to handle such issue is extract the action from the base application and call it outside, using a task manager system like <a href="http://www.celeryproject.org/" rel="nofollow noreferrer">Celery</a>. </p>
<p>Using <a href="http://flask.pocoo.org/docs/1.0/patterns/celery/" rel="nofollow noreferrer">this</a> tutorial you can create your task and trigger it from your web application.</p>
<pre><code>from flask import Flask

app = Flask(__name__)
app.config.update(
    CELERY_BROKER_URL='redis://localhost:6379',
    CELERY_RESULT_BACKEND='redis://localhost:6379'
)
celery = make_celery(app)


@celery.task()
def add_together(a, b):
    return a + b
</code></pre>
<p>Then you can run:</p>
<pre><code>&gt;&gt;&gt; result = add_together.delay(23, 42)
&gt;&gt;&gt; result.wait()
65
</code></pre>
<p>Just remember you need to run worker separately:</p>
<pre><code>celery -A your_application worker
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Celery and RQ is overengineering for <strong>simple task</strong>.
Take a look at this docs - <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="noreferrer">https://docs.python.org/3/library/concurrent.futures.html</a></p>
<p>Also check example, how to run long-running jobs in background for Flask app - <a href="https://stackoverflow.com/a/39008301/5569578">https://stackoverflow.com/a/39008301/5569578</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Well, Although your approach is not incorrect, basicly it may lead your program run out of available threads. As <a href="https://stackoverflow.com/users/501979/ali-nikneshan">Ali</a> mentioned, a general approach is to use Job Queues like <code>RQ</code> or <code>Celery</code>.  However you don't need to extract functions to use those libraries.  For Flask, I recommend you to use <a href="https://github.com/mattupstate/flask-rq" rel="nofollow noreferrer">Flask-RQ</a>.  It's simple to start:</p>
<h2>RQ</h2>
<pre><code>pip install flask-rq
</code></pre>
<p>Just remember to install Redis before using it in your Flask app.</p>
<p>And simply use @Job Decorator in your Flask functions:</p>
<pre><code>from flask.ext.rq import job


@job
def process(i):
    #  Long stuff to process


process.delay(3)
</code></pre>
<p>And finally you need <code>rqworker</code> to start the worker:</p>
<blockquote>
<p>rqworker</p>
</blockquote>
<p>You can see <a href="http://python-rq.org/" rel="nofollow noreferrer">RQ docs</a> for more info.  RQ designed for simple long running processes.</p>
<h2>Celery</h2>
<p>Celery is more complicated, has huge list of features and is not recommended if you are new to job queues and distributed processing methods.</p>
<h2>Greenlets</h2>
<p>Greenlets have switches.  Let you to switch between long running processes.
You can use greenlets for running processes.  The benefit is you don't need Redis and other worker, instead you have to re-design your functions to be compatible:</p>
<pre><code>from greenlet import greenlet

def test1():
    print 12
    gr2.switch()
    print 34

def test2():
    print 56
    gr1.switch()
    print 78

gr1 = greenlet(test1)
gr2 = greenlet(test2)
gr1.switch()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Your approach is fine and will totally work, but why reinvent the background worker for python web applications when a widely accepted solution exists, namely celery.</p>
<p>I'd need to see a lot tests before I trusted any home rolled code for such an important task.</p>
<p>Plus celery gives you features like task persistence and the ability to distribute workers across multiple machines.</p>
</div>
<span class="comment-copy">I think the tutorial @ali-nikneshan was referencing is: <a href="http://flask.pocoo.org/docs/0.12/patterns/celery/" rel="nofollow noreferrer">flask.pocoo.org/docs/0.12/patterns/celery</a></span>
<span class="comment-copy">@cjohnson318 thanks, updated to 1.0</span>
<span class="comment-copy">Good point for futures, it's what grpc (among others) use to handle parallel requests</span>
