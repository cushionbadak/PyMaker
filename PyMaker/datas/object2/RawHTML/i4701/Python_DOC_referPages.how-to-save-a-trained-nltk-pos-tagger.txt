<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/14732465/nltk-tagging-spanish-words-using-a-corpus">NLTK Tagging spanish words using a corpus</a>
<span class="question-originals-answer-count">
                    3 answers
                </span>
</li>
</ul>
</div>
<p>I was wondering how to save a trained NLTK (Unigram)Tagger. I train a <code>Portuguese UnigramTagger</code> with the following code, depending on the corpus it may take a while for it to run, so I'd like to avoid rerunning it.</p>
<pre><code>import nltk
from nltk import mac_morpho

def get_unigram_tagger():
  p_train = 0.9
  tagged_sents = mac_morpho.tagged_sents()
  size = int(len(tagged_sents)*0.9)
  train_sents = tagged_sents[:size]
  test_sents = tagged_sents[size:]
  uni_tagger = nltk.UnigramTagger(train_sents)
  print "Test accuracy =", uni_tagger.evaluate(test_sents)
  return uni_tagger
</code></pre>
<p>So I get <code>uni_tagger</code> from this function and I have to recompute it if I'm running the program again. Maybe I can save <code>uni_tagger</code> somehow so that next time I just need to read it (weights and such) from a file.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use something like pickle to persist your model to disk.</p>
<pre><code>import nltk
import pickle
from nltk import mac_morpho
def get_unigram_tagger():
  p_train = 0.9
  tagged_sents = mac_morpho.tagged_sents()
  size = int(len(tagged_sents)*0.9)
  train_sents = tagged_sents[:size]
  test_sents = tagged_sents[size:]
  uni_tagger = nltk.UnigramTagger(train_sents)
  print "Test accuracy =", uni_tagger.evaluate(test_sents)
  return uni_tagge
tagger = unigram_tagger()
s = pickle.dumps(tagger)
model2 = pickle.loads(s)
</code></pre>
<p>You can also used sklearn's replacement of pickle <code>(joblib.dump</code> &amp; <code>joblib.load)</code></p>
<pre><code>from sklearn.externals import joblib
joblib.dump(tagger, 'filename.pkl') 
tagger3 = joblib.load('filename.pkl')
</code></pre>
<p>Sklearn claims that joblib is more efficient than pickle for larger numpy like model arrays.</p>
<p>You can read more here</p>
<p><a href="http://scikit-learn.org/stable/modules/model_persistence.html" rel="nofollow noreferrer">http://scikit-learn.org/stable/modules/model_persistence.html</a></p>
<p><a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer">https://docs.python.org/3/library/pickle.html</a></p>
</div>
<span class="comment-copy">Take a look at <a href="https://github.com/alvations/spaghetti-tagger/blob/master/spaghetti.py" rel="nofollow noreferrer">github.com/alvations/spaghetti-tagger/blob/master/spaghetti.py</a></span>
