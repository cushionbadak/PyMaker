<div class="post-text" itemprop="text">
<p>I use the two following class methods to request information from the Questrade API (<a href="http://www.questrade.com/api/documentation/rest-operations/market-calls/markets-quotes-id" rel="nofollow noreferrer">http://www.questrade.com/api/documentation/rest-operations/market-calls/markets-quotes-id</a>). I have over 11,000 stock symbols where I request the Questrade API with batches of 100 symbols. </p>
<pre><code>import  requests
from joblib import Parallel, delayed

def parallel_request(self, elem, result, url, key):
    response = requests.get(''.join((url, elem)), headers=self.headers)
    result.extend(response.json().get(key))

Parallel(n_jobs=-1, backend="threading")(
         delayed(self.parallel_request)(elem, self.symbol_ids_list, self.uri, 'symbols')\
         for elem in self.batch_result
     )
</code></pre>
<p>If I make over 110 HTTPS requests with Parallel class, then instead of getting 11,000 output I got 10,500 or 10,600. So I lost data with parallel processing.  Be aware that I used two python module here, i.e. joblib (<a href="https://github.com/joblib/joblib/issues/651" rel="nofollow noreferrer">https://github.com/joblib/joblib/issues/651</a>) and requests (<a href="https://github.com/requests/requests" rel="nofollow noreferrer">https://github.com/requests/requests</a>). </p>
<p>The following <code>for</code> loop worked perfectly, so I know my problem is with the Parallel class.</p>
<pre><code>for elem in self.batch_result:
       response = requests.get(''.join((self.uri, elem)), headers=self.headers)
       self.symbol_ids_list.extend(response.json().get('symbols'))
</code></pre>
<p>How could I increase the performance of the last <code>for</code> loop without losing data?</p>
<h2>UPDATE</h2>
<p>A sample of <code>self.batch_result</code> (simplified result) could be <code>['AAME,ABAC,ABIL,ABIO,ACERW,ACHN,ACHV,ACRX,ACST,ACTG,ADMA,ADMP,ADOM,ADXS,ADXSW,AEHR,AEMD,AETI,AEY,AEZS,AFMD,AGFSW,AGRX,AGTC,AHPAW,AHPI,AIPT,AKER,AKTX,ALIM,ALJJ,ALQA,ALSK,ALT,AMCN,AMDA,AMMA,AMRH,AMRHW,AMRN,AMRWW,AMTX,ANDAR,ANDAW,ANTH,ANY,APDN,APDNW,APOPW,APPS,APRI,APTO,APVO,APWC,AQB,AQMS,ARCI,ARCW,ARDM,AREX,ARGS,ARLZ,ARQL,ARTW,ARTX,ASFI,ASNA,ASRV,ASTC,ATACR,ATEC,ATHX,ATLC,ATOS,ATRS,AUTO,AVEO,AVGR,AVID,AVXL,AWRE,AXAS,AXON,AXSM,AYTU,AZRX,BASI,BBOX,BBRG,BCACR,BCACW,BCLI,BDSI,BHACR,BHACW,BIOC,BIOL,BIOS,BKEP,BKYI', 'BLDP,BLIN,BLNK,BLNKW,BLPH,BLRX,BMRA,BNSO,BNTC,BNTCW,BOSC,BOXL,BPTH,BRACR,BRACW,BRPAR,BRPAW,BSPM,BSQR,BUR,BURG,BVSN,BVXVW,BWEN,BYFC,CAAS,CADC,CALI,CAPR,CARV,CASI,CASM,CATB,CATS,CBAK,CBLI,CCCL,CCCR,CCIH,CDMO,CDTI,CELGZ,CERCW,CETV,CETX,CETXW,CFBK,CFMS,CFRX,CGEN,CGIX,CGNT,CHCI,CHEK,CHEKW,CHFS,CHKE,CHMA,CHNR,CIDM,CJJD,CKPT,CLDC,CLDX,CLIR,CLIRW,CLNE,CLRB,CLRBW,CLRBZ,CLSN,CLWT,CMSSR,CMSSW,CNACR,CNACW,CNET,CNIT,CNTF,CODA,CODX,COGT,CPAH,CPLP,CPRX,CPSH,CPSS,CPST,CREG,CRIS,CRME,CRNT,CSBR,CTHR,CTIB,CTIC,CTRV,CTXR,CTXRW,CUI', 'CUR,CVONW,CXDC,CXRX,CYCC,CYHHZ,CYRN,CYTR,CYTX,CYTXW,DARE,DCAR,DCIX,DELT,DEST,DFBG,DFFN,DGLY,DHXM,DLPN,DLPNW,DMPI,DOGZ,DOTAR,DOTAW,DRAD,DRIO,DRIOW,DRRX,DRYS,DSKEW,DSWL,DTEA,DTRM,DXLG,DXYN,DYNT,DYSL,EACQW,EAGLW,EARS,EASTW,EBIO,EDAP,EFOI,EGLT,EKSO,ELECW,ELGX,ELON,ELSE,ELTK,EMITF,EMMS,ENG,ENPH,ENT,EPIX,ESEA,ESES,ESTRW,EVEP,EVGN,EVK,EVLV,EVOK,EXFO,EXXI,EYEG,EYEGW,EYES,EYESW,FCEL,FCRE,FCSC,FFHL,FLGT,FLL,FMCIR,FMCIW,FNJN,FNTEW,FORD,FORK,FPAY,FRAN,FRED,FRSX,FSACW,FSNN,FTD,FTEK,FTFT,FUV,FVE,FWP,GALT,GASS,GCVRZ,GEC']</code></p>
<p>and <code>self.uri</code> is simply <code>'https://api01.iq.questrade.com/v1/symbols?names='</code> as seen in the above Questrade API link.</p>
<h2>UPDATE 2</h2>
<p>The Marat's answer was a good try but didn't give me a better result. The first test gave me 31,356 (or 10,452 if I divide that result by 3) instead of 10,900. The second test just gave me 0 or the process block completely.</p>
<p>I found out that the <code>Maximum allowed requests per second</code> is 20. Link : <a href="http://www.questrade.com/api/documentation/rate-limiting" rel="nofollow noreferrer">http://www.questrade.com/api/documentation/rate-limiting</a>. How could I increase the performance of the last <code>for</code> loop without losing data in considering that new information?</p>
</div>
<div class="post-text" itemprop="text">
<p>If you are not stuck with using <code>joblib</code> you could try some standard library parallel processing modules. In python2/3 <a href="https://docs.python.org/2/library/multiprocessing.html#multiprocessing.pool.multiprocessing.Pool" rel="nofollow noreferrer"><code>multiprocessing.Pool</code></a> is available and provides functions for mapping a task across parallel threads. A simplified version would look like this:</p>
<pre><code>from multiprocessing import Pool
import requests

HEADERS = {} # define headers here

def parallel_request(symbols):
    response = requests.get('https://api01.iq.questrade.com/v1/symbols?names={}'.format(symbols), headers=HEADERS)
    return response.json()

if __name__ == '__main__':
    p = Pool()
    batch_result = ['AAME,ABAC,ABIL,...',
                    'BLDP,BLIN,BLNK,...',
                    'CUR,CVONW,CXDC,...', 
                     ...]

    p.map(parallel_request, batch_result) # will return a list of len(batch_result) responses
</code></pre>
<p>There are asynchronous and iterable versions of <code>map</code> that you would probably want for larger sized jobs, and of course you could add parameters to your <code>parallel_requests</code> task to avoid hard coding things like I did. A caveat with using <code>Pool</code> is that any arguments passed to it have to be picklable.</p>
<p>In python3 the <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="nofollow noreferrer">concurrent.futures</a> module actually has a nice example of multithreaded url retrieval in the docs. With a little effort you could replace <code>load_url</code> in that example with your <code>parallel_request</code> function. There is a version of <code>concurrent.futures</code> backported to python2 as the <a href="https://pypi.python.org/pypi/futures" rel="nofollow noreferrer"><code>futures</code></a> module, as well.</p>
<p>These might require a bit more work in refactoring, so if there is a solution that sticks with <code>joblib</code> feel free to prefer that. On the off-chance that your problem is a bug in <code>joblib</code>, there are plenty of ways you could do this in a multithreaded fashion with standard library (albeit with some added boilerplate).</p>
</div>
<div class="post-text" itemprop="text">
<p>Most likely, it happens because some of HTTP calls fail due to network load. To test, change <code>parallel_request</code>:</p>
<pre><code>def parallel_request(self, elem, result, url, key):
    for i in range(3):  # 3 retries
        try:
            response = requests.get(''.join((url, elem)), headers=self.headers)
        except IOError: 
            continue
        result.extend(response.json().get(key))
        return
</code></pre>
<p>Much less likely: <code>list.extend</code> is not thread safe. If the snippet above didn't help, try guarding <code>extend</code> with a lock:</p>
<pre><code>import threading
...

lock = threading.Lock()

def parallel_request(self, elem, result, url, key):
    response = requests.get(''.join((url, elem)), headers=self.headers)
    lock.acquire()
    result.extend(response.json().get(key))
    lock.release()
</code></pre>
</div>
<span class="comment-copy">most likely the problem is that <code>self.parallel_request</code> is not thread safe. Can you add its code to the post?</span>
<span class="comment-copy">@Marat The code of <code>self.parallel_request</code> is already in the question. Could you specify your question?</span>
<span class="comment-copy">my bad. Indeed, it should be thread safe (but though <code>extend</code> is, <code>append</code> is not). I will post couple snippets to try</span>
<span class="comment-copy">I understand you may be using it for something else but if parallel processing in threads is all you need from <code>joblib</code>you might get the same result using standard library (<code>multiprocessing.Pool</code>), which is probably more well tested</span>
<span class="comment-copy">Are you up to make a full answer with that?</span>
<span class="comment-copy">I appreciate a lot your answer, but none of them fix my problem. The first test gave me 31356 (or 10,452 if I divide that result by 3) instead of    10,900. The second test just gave me 0 everytime I ran it.</span>
<span class="comment-copy">I found out that the <code>Maximum allowed requests per second</code> is 20. Link : <a href="http://www.questrade.com/api/documentation/rate-limiting" rel="nofollow noreferrer">questrade.com/api/documentation/rate-limiting</a>. How could I increase the performance of the last <code>for</code> loop without losing data?</span>
<span class="comment-copy">@Jeremie you have to implement a more sophisticated handler that will pause upon reaching the limit and wait for a second. Implementation of such handler is much more of a professional service complexity rather than a StackOverflow answer</span>
