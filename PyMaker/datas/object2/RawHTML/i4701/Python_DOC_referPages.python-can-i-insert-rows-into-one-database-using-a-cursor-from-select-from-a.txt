<div class="post-text" itemprop="text">
<p>I am trying to select data from our main database (postgres) and insert it into a temporary sqlite database for some comparision, analytics and reporting. Is there an easy way to do this in Python? I am trying to do something like this:</p>
<p>Get data from the main Postgres db:</p>
<pre><code>import psycopg2
postgres_conn = psycopg2.connect(connection_string)
from_cursor = postgres_conn.cursor()
from_cursor.execute("SELECT email, firstname, lastname FROM schemaname.tablename")
</code></pre>
<p>Insert into SQLite table:</p>
<pre><code>import sqlite3
sqlite_conn = sqlite3.connect(db_file)
to_cursor = sqlite_conn.cursor()
insert_query = "INSERT INTO sqlite_tablename (email, firstname, lastname) values %s"
to_cursor.some_insert_function(insert_query, from_cursor)
</code></pre>
<p>So the question is: is there a <code>some_insert_function</code> that would work for this scenario (either using pyodbc or using sqlite3)?</p>
<p>If yes, how to use it? Would the <code>insert_query</code> above work? or should it be modified?</p>
<p>Any other suggestions/approaches would also be appreciated in case a function like this doesn't exist in Python. Thanks in advance!</p>
</div>
<div class="post-text" itemprop="text">
<p>You can look at executemany from pyodbc or sqlite. If you can build a list of parameters from your select, you can pass the list to executemany. </p>
<p>Depending on the number of records you plan to insert, performance can be a problem as referenced in this open issue. <a href="https://github.com/mkleehammer/pyodbc/issues/120" rel="nofollow noreferrer">https://github.com/mkleehammer/pyodbc/issues/120</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You should pass the result of your select query to <code>execute_many</code>.</p>
<pre><code>insert_query = "INSERT INTO smallUsers values (?,?,?)"
to_cursor.executemany(insert_query, from_cursor.fetchall())
</code></pre>
<p>You should also use a parameterized query (? marks), as explained here: <a href="https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.execute" rel="nofollow noreferrer">https://docs.python.org/3/library/sqlite3.html#sqlite3.Cursor.execute</a></p>
<p>If you want to avoid loading the entire source database into memory, you can use the following code to process 100 rows at a time:</p>
<pre><code>while True:
    current_data = from_cursor.fetchmany(100)
    if not current_data:
        break
    to_cursor.exectutemany(insert_query, current_data)
    sqlite_conn.commit()
sqlite_conn.commit()
</code></pre>
</div>
<span class="comment-copy">Newer information re: pyodbc's <code>fast_executemany</code> property <a href="https://github.com/mkleehammer/pyodbc/wiki/Features-beyond-the-DB-API#fast_executemany" rel="nofollow noreferrer">here</a></span>
<span class="comment-copy">I was looking for a way to not use <code>fetchall()</code>, since it could create a huge list in memory depending on size of the data</span>
<span class="comment-copy">You can use fetchmany(100) instead. You can try the following:  <code>while True:     current_data = from_cursor.fetchmany(100)     if not current_data:         break     to_cursor.exectutemany(insert_query, current_data)</code></span>
