<div class="post-text" itemprop="text">
<p>I use the following function to chunk iterable python objects.  </p>
<pre><code>from itertools import islice

def chunked_iterable(iterable, chunk_size):
    it = iter(iterable)
    while True:
        chunk = tuple(islice(it, chunk_size))
        if not chunk:
            break
        yield chunk
</code></pre>
<p>I'm looking to do something similar with a basic JSON file.</p>
<pre><code>[
    {object1: 'object1'},
    {object2: 'object2'},
    {object3: 'object3'},
    {object4: 'object4'},
    {object5: 'object5'},
    {object6: 'object6'},
    etc...
]
</code></pre>
<p>Like this.</p>
<pre><code>from pathlib import Path
import json

def json_chunk(json_array_of_objects, object_count):
    # What goes here?

if __name__ == '__main__':
    with open(Path(__file__).parent / 'raw_data.json') as raw_data:
        json_data = json.load(raw_data)

    for json_array_with_five_objects in enumerate(json_chunk(json_data, 5)): 
        for object in json_array_with_five_objects:
            print(object[0])
</code></pre>
<p>Is the term I'm looking for "streaming" JSON data?<br/>
How do you stream JSON data?</p>
<p>As a learning exercise I'm trying to stick with base python functionality for now but answers using other packages are helpful too.</p>
</div>
<div class="post-text" itemprop="text">
<p>After further thought, using <code>object_hook</code> or <code>object_pairs_hook</code> arguments would require reading the entire file into memory first—so to avoid doing that, instead here's something that reads the file incrementally, line-by-line.</p>
<p>I had to modify your example JSON file to make it valid JSON (what you have in your question is a Python dictionary). Note that this code is format-specific in the sense that it assumes each JSON object in the array lies entirely on a single line—although it could be changed to handle multiline object definitions if necessary.</p>
<p>So here's a sample test input file with valid JSON contents:</p>
<pre class="lang-none prettyprint-override"><code>[
    {"thing1": "object1"},
    {"thing2": "object2"},
    {"thing3": "object3"},
    {"thing4": "object4"},
    {"thing5": "object5"},
    {"thing6": "object6"}
]
</code></pre>
<p>Code:</p>
<pre><code>from itertools import zip_longest
import json
from pathlib import Path

def grouper(n, iterable, fillvalue=None):
    """ s -&gt; (s0, s1...sn-1), (sn, sn+1...s2n-1), (s2n, s2n+1...s3n-1), ... """
    return zip_longest(*[iter(iterable)]*n, fillvalue=fillvalue)

def read_json_objects(fp):
    """ Read objects from file containing an array of JSON objects. """
    next(fp)  # Skip first line.
    for line in (line.strip() for line in fp):
        if line[0] == ']':  # Last line?
            break
        yield json.loads(line.rstrip(','))

def json_chunk(json_file_path, object_count):
    with open(json_file_path) as fp:
        for group in grouper(object_count, read_json_objects(fp)):
            yield(tuple(obj for obj in group if obj is not None))


if __name__ == '__main__':
    json_file_path = Path(__file__).parent / 'raw_data.json'

    for array in json_chunk(json_file_path, 5):
        print(array)
</code></pre>
<p>Output from processing test file:</p>
<pre class="lang-none prettyprint-override"><code>({'thing1': 'object1'}, {'thing2': 'object2'}, {'thing3': 'object3'}, {'thing4': 'object4'}, {'thing5': 'object5'})
({'thing6': 'object6'},)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>JSON is a text format that is completely language independent but uses
  conventions that are familiar to programmers of the C-family of
  languages, including C, C++, C#, Java, JavaScript, Perl, Python, and
  many others. These properties make JSON an ideal data-interchange
  language. -<a href="https://www.json.org/" rel="nofollow noreferrer">https://www.json.org/</a></p>
</blockquote>
<p>JSON is a string of text.  You would need to convert it back to python to be iteratable</p>
</div>
<span class="comment-copy">You can't do it for an arbitrary chunk of the data from the file, but the <code>json.JSONDecoder</code> class has optional <code>object_hook</code> and <code>object_pairs_hook</code> arguments which could allow you to effectively incrementally get "chunks" from the file where each represented a whole JSON object (which has been converted into a Python dictionary). Whether that would useful would depend on the exact structure of your JSON data.</span>
<span class="comment-copy">@martineau yes! That's exactly what I'm looking to do. "chunks" are actually whole JSON objects. eg. - from a JSON array of 100 objects, loop through the array in "chunks" of 5 objects.</span>
<span class="comment-copy">Are you trying to avoid loading all of 'raw_data.json' from disk at one time? If you're happy to load it in one pass (as your code currently does), then you can use your current code, which already creates an ordinary Python object. You can just iterate through it using your current <code>chunked_iterable</code> code.</span>
<span class="comment-copy">Thanks @martineau.  This was super helpful.</span>
<span class="comment-copy">GollyJer: Glad to hear that. One of your main take-ways from this is ought to be how the <code>grouper()</code> generator function, which is one of many given in the <code>itertools</code> module's <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer"><b>Itertools Recipes</b></a> section, simplified solving the problem.</span>
