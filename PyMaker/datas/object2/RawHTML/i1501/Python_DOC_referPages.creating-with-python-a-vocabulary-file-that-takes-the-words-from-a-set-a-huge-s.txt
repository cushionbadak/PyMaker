<div class="post-text" itemprop="text">
<p>I have this set of files .tsv (it's really big, 18k+ files) and i want to create a file (doesn't matter what format it is) called 'vocabulary' that will storage each word that appears in these files and assigns an identifier to each word. I don't want to count occurrences: if the word "house" appears 227 times in my files i want to save that word in my vocabulary just once.
I will use this vocabulary for a search engine, but this is another story...</p>
<p>Edit: I forgot that i also want to name each identifier in a specific way: 'term_id'. So i imagine the content of my output file something like:</p>
<pre><code>    house_id_1
    flower_id_2
    river_id_3
    and_id_4
    beautiful_id_5
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Are you using a Windows machine or a Linux/Unix/MacOS machine?</p>
<p>If latter, you don't really need Python - you can do it by chaining together shell commands - </p>
<p>If one of your files is called <code>abc.txt</code> - </p>
<pre><code>while read p; do printf "%s %s \n" $p `echo $p|md5sum`; done &lt;abc.txt |sort|uniq &gt; outputfile.txt
</code></pre>
<p>Note that the md5sum hashes the word - almost guarantees a unique ID for each of your words</p>
</div>
<div class="post-text" itemprop="text">
<p>You can do this - </p>
<pre><code>import csv
big_set_of_words = set()
with open("csvfile.csv") as csv_file:
  csv_reader = csv.reader(csv_file, delimiter=','newline='')
  for row in csv_reader:
    word_with_hash = (row[0], hash(row[0]))
    big_set_of_words.add(word_with_hash)

with open("outputfile.csv", mode = "w", newline='') as output_file:
  csv_writer = csv.writer(output_file, delimiter=',')
  for element in big_set_of_words:
    csv_writer.writerow(element)
</code></pre>
</div>
<span class="comment-copy">To read the <code>.tsv</code> files use <a href="https://stackoverflow.com/questions/46502943/reading-csv-files-in-a-loop-using-pandas-then-concatenating-them">loop</a> and to find the unique features use pandas <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.unique.html" rel="nofollow noreferrer">series.unique</a></span>
<span class="comment-copy">I'm using a windows machine and I'm working right now on a Jupyter notebook where i actually splitted a big .csv file in multiple .tsv for future purposes. So i can even take the words from a unique .csv file if it is less time consuming.</span>
<span class="comment-copy">How big is your <code>csv</code> file? Can you load the entire file into memory? By using <code>open("csvfile", "r")</code> in python, for example?</span>
<span class="comment-copy">Yes I can load it in memory. But I have to assign a specific identifier name to each word. Each word should be saved in the vocabulary like this: 'term_id'. I would imagine the content of my output file something like:     house_1    flower_2    river_3.....</span>
<span class="comment-copy">Thank you. But I got this error generated from the "for" iteration:          UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 1088: character maps to &lt;undefined&gt;  Probably I have to change the encode mode in the csv.reader function into "utf-8" but. But there is no encode field expected for that function. Any idea?</span>
<span class="comment-copy">You can try passing the encoding to the <code>open</code> function - <code>with open("csvfile.csv", encoding="utf8")</code></span>
<span class="comment-copy">Now it' giving me an error on the csv.writer():         argument 1 must have a "write" method</span>
<span class="comment-copy">I've corrected the error (my bad on renaming the output file). But the csv output file doesn't store words. This is the output content:   <a href="https://drive.google.com/file/d/18AWOZismdq_N9Pxy16RGB9jbs-u3o3hY/view?usp=sharing" rel="nofollow noreferrer">drive.google.com/file/d/18AWOZismdq_N9Pxy16RGB9jbs-u3o3hY/â€¦</a></span>
<span class="comment-copy">Based on the docs <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer">docs.python.org/3/library/csv.html</a> I have edited the answer a little - let me know if this works</span>
