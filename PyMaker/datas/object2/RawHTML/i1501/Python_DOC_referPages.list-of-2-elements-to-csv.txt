<div class="post-text" itemprop="text">
<p>I have been facing an issue parsing an horrible txt file, I have manage to extract to a list the information I need:</p>
<pre><code>['OS-EXT-SRV-ATTR:host', 'compute-0-4.domain.tld']
['OS-EXT-SRV-ATTR:hostname', 'commvault-vsa-vm']
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-4.domain.tld']
['OS-EXT-SRV-ATTR:instance_name', 'instance-00000008']
['OS-EXT-SRV-ATTR:root_device_name', '/dev/vda']
['hostId', '985035a85d3c98137796f5799341fb65df21e8893fd988ac91a03124']
['key_name', '-']
['name', 'Commvault_VSA_VM']
['OS-EXT-SRV-ATTR:host', 'compute-0-28.domain.tld']
['OS-EXT-SRV-ATTR:hostname', 'dummy-vm']
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-28.domain.tld']
['OS-EXT-SRV-ATTR:instance_name', 'instance-0000226e']
['OS-EXT-SRV-ATTR:root_device_name', '/dev/hda']
['hostId', '7bd08d963a7c598f274ce8af2fa4f7beb4a66b98689cc7cdc5a6ef22']
['key_name', '-']
['name', 'Dummy_VM']
['OS-EXT-SRV-ATTR:host', 'compute-0-20.domain.tld']
['OS-EXT-SRV-ATTR:hostname', 'mavtel-sif-vsifarvl11']
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-20.domain.tld']
['OS-EXT-SRV-ATTR:instance_name', 'instance-00001da6']
['OS-EXT-SRV-ATTR:root_device_name', '/dev/vda']
['hostId', 'dd82c20a014e05fcfb3d4bcf653c30fa539a8fd4e946760ee1cc6f07']
['key_name', 'mav_tel_key']
['name', 'MAVTEL-SIF-vsifarvl11']
</code></pre>
<p>I would like to have the element 0 as headers and 1 has rows, for example:</p>
<pre><code>OS-EXT-SRV-ATTR:host, OS-EXT-SRV-ATTR:hostname,...., name
compute-0-4.domain.tld, commvault-vsa-vm,....., Commvault_VSA_VM
compute-0-28.domain.tld, dummy-vm,...., Dummy_VM
</code></pre>
<p>Here is my code so far:</p>
<pre><code>import re

with open('metadata.txt', 'r') as infile:
    lines = infile.readlines()
    for line in lines:

        if re.search('hostId|properties|OS-EXT-SRV-ATTR:host|OS-EXT-SRV-ATTR:hypervisor_hostname|name', line):
            re.sub("[\t]+", " ", line)
            find = line.strip()
            format = ''.join(line.split()).replace('|', ',')
            list = format.split(',')
            new_list = list[1:-1]
</code></pre>
<p>I am very new at python, so sometimes I ran out of ideas on how to make things work.</p>
</div>
<div class="post-text" itemprop="text">
<p>Looking at your input file, I see that it contains what appears to be output from the openstack <code>nova show</code> command, mixed with other stuff. There are basically two types of lines: valid ones, and invalid ones (duh).</p>
<p>The valid ones have this structure:</p>
<pre><code>'| key                | value                 |'
</code></pre>
<p>and the invalid ones have anything else. </p>
<p>So we could define that every valid line </p>
<ul>
<li>can be split at the <code>|</code> into <em>exactly</em> four parts, of which</li>
<li>the first and the last part must be empty, and the other parts must be filled.</li>
</ul>
<p>Python can do this (it's called unpacking assignment):</p>
<pre><code>a, b, c, d = [1, 2, 3, 4]
a, b, c, d = some_string.split('|')
</code></pre>
<p>which will succeed when the right-hand side has exactly four parts, otherwise it will fail with a <code>ValueError</code>. When we now make sure that <code>a</code> and <code>d</code> are empty, and <code>b</code> and <code>c</code> are not empty - we have a valid line.</p>
<p>Furthermore we can say, if <code>b</code> equals <code>'Property'</code> and <code>c</code> equals <code>'Value'</code>, we have hit a header row and what follows must describe a "new record".</p>
<p>This function does exactly that:</p>
<pre><code>def parse_metadata_file(path):
    """ parses a data file generated by `nova show` into records """
    with open(path, 'r', encoding='utf8') as file:
        record = {}
        for line in file:
            try:
                # unpack line into 4 fields: "| key | val |"
                a, key, val, z = map(str.strip, line.split('|'))
                if a != '' or z != '' or key == '' or val == '':
                    continue
            except ValueError:
                # skip invalid lines
                continue
            if key == 'Property' and val == 'Value' and record:
                # output current record and start a new one
                yield record
                record = {}
            else:
                # write property to current record
                record[key] = val
    # output last record
    if record:
        yield record
</code></pre>
<p>It spits out a new dict for each record it finds and disregards all lines that do not pass the sanity check. Effectively this function <em>generates</em> a stream of dicts.</p>
<p>Now we can use the <code>csv</code> module to write this stream of dicts to a CSV file:</p>
<pre><code>import csv

# list of fields we are interested in
fields = ['hostId', 'properties', 'OS-EXT-SRV-ATTR:host', 'OS-EXT-SRV-ATTR:hypervisor_hostname', 'name']

with open('output.csv', 'w', encoding='utf8', newline='') as outfile:
    writer = csv.DictWriter(outfile, fieldnames=fields, extrasaction='ignore')
    writer.writeheader()
    writer.writerows(parse_metadata_file('metadata.txt'))
</code></pre>
<p>The CSV module has a <code>DictWriter</code> which is designed to accept dicts as input and write them—according to the given key names—to a CSV row. </p>
<ul>
<li>With <code>extrasaction='ignore'</code> it does not matter if the current record has more fields than required</li>
<li>With <code>fields</code> list it becomes extremely easy to extract a different set of fields.</li>
<li>Configure the writer to suit your needs (<a href="https://docs.python.org/3/library/csv.html#csv.DictWriter" rel="nofollow noreferrer">docs</a>).</li>
<li><p>This:</p>
<pre><code>writer.writerows(parse_metadata_file('metadata.txt'))
</code></pre>
<p>is a convenient shorthand for</p>
<pre><code>for record in parse_metadata_file('metadata.txt'):
    writer.writerow(record)
</code></pre></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>You can take a step by step approach to build a 2D array by keeping track of your headers and each entry in the text file. </p>
<pre><code>headers = list(set([entry[0] for entry in data])) # obtain unique headers
num_rows = 1
for entry in data: # figuring out how many rows we are going to need
    if 'name' in entry: # name is unique per row so using that
        num_rows += 1 

num_cols = len(headers)

mat = [[0 for _ in range(num_cols)] for _ in range(num_rows)]

mat[0] = headers # add headers as first row

header_lookup = {header: i for i, header in enumerate(headers)}

row = 1
for entry in data:
    header, val = entry[0], entry[1]
    col = header_lookup[header]

    mat[row][col] = val # add entries to each subsequent row

    if header == 'name':
        row += 1

print mat
</code></pre>
<p>output:</p>
<pre><code>[['hostId', 'OS-EXT-SRV-ATTR:host', 'name', 'OS-EXT-SRV-ATTR:hostname', 'OS-EXT-SRV-ATTR:instance_name', 'OS-EXT-SRV-ATTR:root_device_name', 'OS-EXT-SRV-ATTR:hypervisor_hostname', 'key_name'], ['985035a85d3c98137796f5799341fb65df21e8893fd988ac91a03124', 'compute-0-4.domain.tld', 'Commvault_VSA_VM', 'commvault-vsa-vm', 'instance-00000008', '/dev/vda', 'compute-0-4.domain.tld', '-'], ['7bd08d963a7c598f274ce8af2fa4f7beb4a66b98689cc7cdc5a6ef22', 'compute-0-28.domain.tld', 'Dummy_VM', 'dummy-vm', 'instance-0000226e', '/dev/hda', 'compute-0-28.domain.tld', '-'], ['dd82c20a014e05fcfb3d4bcf653c30fa539a8fd4e946760ee1cc6f07', 'compute-0-20.domain.tld', 'MAVTEL-SIF-vsifarvl11', 'mavtel-sif-vsifarvl11', 'instance-00001da6', '/dev/vda', 'compute-0-20.domain.tld', 'mav_tel_key']]
</code></pre>
<p>if you need to write the new 2D array to a file so its not as "horrible" :)</p>
<pre><code>with open('output.txt', 'w') as f:
    for lines in mat:
        lines_out = '\t'.join(lines)
        f.write(lines_out)
        f.write('\n')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Looks like a job for pandas:</p>
<pre><code>import pandas as pd 

list_to_export = [['OS-EXT-SRV-ATTR:host', 'compute-0-4.domain.tld'],
['OS-EXT-SRV-ATTR:hostname', 'commvault-vsa-vm'],
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-4.domain.tld'],
['OS-EXT-SRV-ATTR:instance_name', 'instance-00000008'],
['OS-EXT-SRV-ATTR:root_device_name', '/dev/vda'],
['hostId', '985035a85d3c98137796f5799341fb65df21e8893fd988ac91a03124'],
['key_name', '-'],
['name', 'Commvault_VSA_VM'],
['OS-EXT-SRV-ATTR:host', 'compute-0-28.domain.tld'],
['OS-EXT-SRV-ATTR:hostname', 'dummy-vm'],
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-28.domain.tld'],
['OS-EXT-SRV-ATTR:instance_name', 'instance-0000226e'],
['OS-EXT-SRV-ATTR:root_device_name', '/dev/hda'],
['hostId', '7bd08d963a7c598f274ce8af2fa4f7beb4a66b98689cc7cdc5a6ef22'],
['key_name', '-'],
['name', 'Dummy_VM'],
['OS-EXT-SRV-ATTR:host', 'compute-0-20.domain.tld'],
['OS-EXT-SRV-ATTR:hostname', 'mavtel-sif-vsifarvl11'],
['OS-EXT-SRV-ATTR:hypervisor_hostname', 'compute-0-20.domain.tld'],
['OS-EXT-SRV-ATTR:instance_name', 'instance-00001da6'],
['OS-EXT-SRV-ATTR:root_device_name', '/dev/vda'],
['hostId', 'dd82c20a014e05fcfb3d4bcf653c30fa539a8fd4e946760ee1cc6f07'],
['key_name', 'mav_tel_key'],
['name', 'MAVTEL-SIF-vsifarvl11']]



data_dict = {}

for i in list_to_export:
    if i[0] not in data_dict:
        data_dict[i[0]] = [i[1]]

    else:
        data_dict[i[0]].append(i[1])

pd.DataFrame.from_dict(data_dict, orient = 'index').T.to_csv('filename.csv')
</code></pre>
</div>
<span class="comment-copy">Looks like you need to "transpose" the data. That term should be about to help you read for a solution.</span>
<span class="comment-copy">Could you paste the (abbreviated) input file as well, please?</span>
<span class="comment-copy"><a href="https://drive.google.com/file/d/1uTB0RwU2RpySOVj8HreH5bIUkrmGe3Ft/view?usp=sharing" rel="nofollow noreferrer">drive.google.com/file/d/1uTB0RwU2RpySOVj8HreH5bIUkrmGe3Ft/…</a> here you go @Tomalak</span>
<span class="comment-copy">Not exactly abbreviated, but still helpful. See below!</span>
<span class="comment-copy">This works like a charm, I should had started that it was an "nova show" output from openstack, thanks a lot!</span>
<span class="comment-copy">Next time think of putting in more context details and you're good. :) Thanks for the feedback!</span>
<span class="comment-copy">Seems not to work, I tried differents ways using pandas but I am still struggling.</span>
<span class="comment-copy">What error do you get? The snippet above works.</span>
<span class="comment-copy">The output in the csv file only shows: ,0,1  ,s,[</span>
<span class="comment-copy">The code I post above works as intended. Not sure how you only get 0,1? How to do you read your original dataframe / crate your list of lists?</span>
<span class="comment-copy">I made it work, I did not noticed that you nested the stream of lists. It is now okay this is a valid workaround as well.</span>
