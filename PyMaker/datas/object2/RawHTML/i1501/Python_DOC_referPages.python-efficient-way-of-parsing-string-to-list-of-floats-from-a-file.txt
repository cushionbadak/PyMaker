<div class="post-text" itemprop="text">
<p>This document has a word and tens of thousands of floats per line, I want to transform it to a dictionary with the word as key and a vector with all the floats. 
That is how I am doing, but due to the size of the file (about 20k lines each one with about 10k values) the process is taking a bit too long. I could not find a more <strong>efficient</strong> way of doing the parsing. Just some alternative ways that were not guaranteed to decrease run time.</p>
<pre><code>with open("googlenews.word2vec.300d.txt") as g_file:
  i = 0;
  #dict of words: [lots of floats]
  google_words = {}

  for line in g_file:
    google_words[line.split()[0]] = [float(line.split()[i]) for i in range(1, len(line.split()))]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>In your solution you preform slow <code>line.split()</code> for every word, twice. Consider following modification:</p>
<pre><code>with open("googlenews.word2vec.300d.txt") as g_file:
    i = 0;
    #dict of words: [lots of floats]
    google_words = {}

    for line in g_file:
        word, *numbers = line.split()
        google_words[word] = [float(number) for number in numbers]
</code></pre>
<p>One advanced concept I used here is "unpacking":
<code>word, *numbers = line.split()</code></p>
<p>Python allows to unpack iterable values into multilple variables:</p>
<pre><code>a, b, c = [1, 2, 3]
# This is practically equivalent to
a = 1
b = 2
c = 3
</code></pre>
<p>The <code>*</code> is a shortcut for "take the leftovers, put them in the <code>list</code> and assign the list to the name":</p>
<pre><code>a, *rest = [1, 2, 3, 4]
# results in
a == 1
rest == [2, 3, 4]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just don't call <code>line.split()</code> more than once.</p>
<pre><code>with open("googlenews.word2vec.300d.txt") as g_file:
    i = 0;
    #dict of words: [lots of floats]
    google_words = {}

    for line in g_file:
        temp = line.split()
        google_words[temp[0]] = [float(temp[i]) for i in range(1, len(temp))]
</code></pre>
<p>Here's a simple generator of such file:</p>
<pre><code>s = "x"
for i in range (10000):
    s += " 1.2345"
print (s)
</code></pre>
<p>The former version takes some time.
The version with only one <code>split</code> call is instant.</p>
</div>
<div class="post-text" itemprop="text">
<p>You could also use the <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer">csv</a> module, which should be more efficient that what you are doing. </p>
<p>It would be something like:</p>
<pre><code>import csv

d = {}
with (open("huge_file_so_huge.txt", "r")) as g_file:
    for row in csv.reader(g_file, delimiter=" "):
        d[row[0]] = list(map(float, row[1:]))
</code></pre>
</div>
<span class="comment-copy">Define "taking a bit too long" better - how long is it taking, and being realistic how long would you like it to take?</span>
<span class="comment-copy">I'd probably call <code>line.split()</code> once, and assign it to a variable rather than keeping that call in your list comprehension. That way you can iterate over it specifically</span>
<span class="comment-copy">Just what I was going to say...</span>
<span class="comment-copy">Thanks! It works much better now. One noob question though, what is the * doing in *numbers? Is it a pointer like in C, C++?</span>
<span class="comment-copy">@VictorZuanazzi No, python doesn't have built-in pointers;) I explained this syntactic sugar in the updated answer.</span>
