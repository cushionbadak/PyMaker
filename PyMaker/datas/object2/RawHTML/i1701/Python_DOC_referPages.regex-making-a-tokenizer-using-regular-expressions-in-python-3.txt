<div class="post-text" itemprop="text">
<p>I've been trying to make a tokenizer for a language as an exercise . 
for example I'm trying to tokenize the code below</p>
<pre><code>num vecsum(vec A)
{
num n;
n = (5 + 2);
return n;
}
</code></pre>
<p>and I've been trying to use this regex </p>
<pre><code>re.findall("[\'\w\-]+",text)
</code></pre>
<p>but I get outputs like this one : vecsum(vec</p>
<p>while I want to get it like this : ["vecsum" , "(" , "vec" ]</p>
<p>I want it to understand that even if there isn't white space there it should split stuff like " ; " and " ( "</p>
</div>
<div class="post-text" itemprop="text">
<p>Tokenizing a C-like language requires more work than just splitting on whitespace (which is what you are doing right now).</p>
<p>There are <em>at least</em> 3 types of tokens in such languages:</p>
<ul>
<li>Single character tokens, such as <code>(</code>, <code>)</code>, <code>;</code>, <code>+</code> and <code>=</code></li>
<li>Multi-character tokens, identifiers, keywords, numbers.</li>
<li>Strings; everything between an opening quote and the matching closing quote (with support for escapes, and varying degrees of support for special kinds of strings that could, say, contain newlines).</li>
</ul>
<p>I'm ignoring comments here, which are either defined as running from a starting sequence until the end of a line (<code># ...</code>, <code>// ...</code>, etc.) or from starting sequence to ending sequence any number of lines away (<code>/* .... */</code>).</p>
<p>You could define a regex that can tokenize the first two types, and then perhaps use the output of that to handle strings (when you get a <code>"</code> token find the next <code>"</code> token without a <code>\</code> token right in front, then take everything in between (whitespace and all) as the string).</p>
<p>Such a tokenizer the needs at least two groups, for single characters and multi-character tokens. The multi-character tokens are a further group of options:</p>
<pre><code>r'(?:[\\(){}[\]=&amp;|^+&lt;&gt;/*%;.\'"?!~-]|(?:\w+|\d+))'
</code></pre>
<p>I used <a href="https://en.wikipedia.org/wiki/Operators_in_C_and_C%2B%2B" rel="nofollow noreferrer"><em>operators in C and C++</em> on Wikipedia</a> as a guide on what single-character tokens to look for.</p>
<p>For your sample input, this produces:</p>
<pre><code>['num', 'vecsum', '(', 'vec', 'A', ')', '{', 'num', 'n', ';', 'n', '=', '(', '5', '+', '2', ')', ';', 'return', 'n', ';', '}']
</code></pre>
<p>If you must parse multi-symbol operators as single tokens, then you also must include these as separate patterns in the regex, e.g.</p>
<pre><code>(
    r'(?:==|!=|&gt;=|&lt;=|&amp;&amp;|\|\||&lt;&lt;|&gt;&gt;|-&gt;|::|\+\+|--|+=|-='
    r'|\*=|/=|%=|&lt;&lt;=|&gt;&gt;=|&amp;=|\^=|\|='
    r'|[\\(){}[\]=&amp;|^+&lt;&gt;/*%;.\'"?!~-]|(?:\w+|\d+))'
)
</code></pre>
<p>but then you are half-way to a full-blown tokenizer that defines patterns for each type of literal and keyword and you may as well start breaking out this huge regex into such constituent parts. See the <a href="https://github.com/python/cpython/blob/v3.7.1/Lib/tokenize.py" rel="nofollow noreferrer">Python <code>tokenize</code> module source code</a> for an example of such a tokenizer; it <a href="https://github.com/python/cpython/blob/260ec2c36abd73bac51489108409160427979ede/Lib/tokenize.py#L107-L188" rel="nofollow noreferrer">builds up a large regex from component parts</a> to produce typed tokens.</p>
<p>The alternative is to stick with the super-simple 2-part tokenizer regex and use <a href="https://docs.python.org/3/library/re.html#re.finditer" rel="nofollow noreferrer"><code>re.finditer()</code></a> to make decisions about tokens in context. With a <code>start</code> and <code>end</code> position in the string, you can detect that <code>=</code> was directly preceded by <code>=</code>, and so know you have the <code>==</code> comparison operator rather than two assignments. I used this in a simple parser for a SQLite full-text search query language before, (look for the <code>_terms_from_query()</code> method in the <a href="https://stackoverflow.com/questions/52803014/sqlite-with-real-full-text-search-and-spelling-mistakes-ftsspellfix-together/52860714#52860714">code for this answer</a>), if you want to see an example.</p>
</div>
<span class="comment-copy"><code>'</code> is already part of <code>\S</code>, no need to add that separately.</span>
<span class="comment-copy">Make sure to use the <code>r</code> before strings that have literal backslashes.</span>
<span class="comment-copy">Do you mean this: <code>findall(r"\w+|[^\w\s]+", text)</code>? Or similar: <code>r"\S+?(?:\b|$)"</code>.</span>
<span class="comment-copy">@trincot: that still puts symbols together into one token: <code>if(foo){bar++;baz--}</code> would result in <code>['if', '(', 'foo', '){', 'bar', '++;', 'baz', '--}']</code>; note the joining of <code>++;</code> and <code>--}</code>.</span>
<span class="comment-copy">Just trying to get some info from PO who apparently chooses to remain silent. ;-)</span>
<span class="comment-copy">as u said i currently have this : re.findall("\w+(?:'\w+)?|[^\w\s]",text)  which works , but it doesn't recognise multi character tokens like == or &lt;= etc</span>
<span class="comment-copy">i tested your code and still had the same problem . it recognised == as 2 different tokens</span>
<span class="comment-copy">@mahditalebi I didn’t say my approach would recognise multi-character operators. You’d have to add those as separate groups <i>before</i> the single-character operator pattern. Serious regex-based tokensizers use a large number of specific patterns.</span>
