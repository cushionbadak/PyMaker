<div class="post-text" itemprop="text">
<p>I have a large file that contains some NULL characters. I'd like to read this file in Python, as if these NULLs aren't there. I could read the entire file into an in-memory string and do a <code>str.replace</code>, but this is inefficient, especially given its total size (which can be in the multiple GBs).</p>
<p>Is there an efficient way to read a file in Python, while dynamically dropping certain characters, or replacing them with others?</p>
</div>
<div class="post-text" itemprop="text">
<p>Open the file in binary mode and read it in chunks of suitable size. Remove from each chunk undesired characters and write the resulting bytes to another file opened for writing.</p>
<p>This will work for <code>\x00</code> bytes, but will certainly fail if it's a text file with utf-8 encoding, where a single letter can take several bytes.</p>
<p>This can be solved using <a href="https://docs.python.org/3/library/codecs.html#codecs.open" rel="nofollow noreferrer"><code>codecs.open</code></a>. The returned file-like object allows you to <a href="https://docs.python.org/3/library/codecs.html#codecs.StreamReader.read" rel="nofollow noreferrer"><code>read</code></a> approximate number of bytes in the given encoding.</p>
</div>
<span class="comment-copy">You can read it line by line, and do the replacing for each one before reading the next</span>
<span class="comment-copy">@bluesummers: yes, that's one idea I had, something like: <code>lines = (line.replace('\0', '') for line in file_object</code>, and then just use <code>lines</code> as the line iterator.</span>
<span class="comment-copy">Why/how is it inefficient to read the entire file?</span>
<span class="comment-copy">@wwii: the entire file can be several GBs in size. That's more RAM than I have. Also consider that doing <code>s = file(...).read(); ss = s.replace(...)</code> requires <i>twice</i> the size of the file in RAM, since you create an original string, and a modified duplicate.</span>
<span class="comment-copy">Have you considered using <code>.xreadlines()</code> to replace?</span>
<span class="comment-copy">Indeed that makes sense, but as you observed, it won't work for multibyte encodings like UTF-8. Any idea how to address that? Is there a way to read a file in N-byte chunks, while ensuring characters won't be cut off?</span>
<span class="comment-copy">If it's a text file without very long lines, just do <code>for line in file</code> and the process each line and write it.</span>
