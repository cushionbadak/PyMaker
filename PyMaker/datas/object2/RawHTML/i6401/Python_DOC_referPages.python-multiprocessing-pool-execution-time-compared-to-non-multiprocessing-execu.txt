<div class="post-text" itemprop="text">
<p>I am currently redesigning a program to use Python's multiprocessing pools. My first impression was that the execution time increased instead of decreased. Therefore, I got curious and wrote a little test script:</p>
<pre><code>import time
import multiprocessing

def simple(x):
    return 2*x

def less_simple(x):
    b = x
    for i in range(0, 100):
        b = b * i
    return 2*x

a = list(range(0,1000000))

print("without multiprocessing:")
before = time.time()
res = map(simple, a)
after = time.time()
print(str(after - before))

print("-----")

print("with multiprocessing:")
for i in range(1, 5):
    before = time.time()
    with multiprocessing.Pool(processes=i) as pool:
        pool.map(simple, a)
    after = time.time()
    print(str(i) + " processes: " + str(after - before))
</code></pre>
<p>I get the following results:</p>
<p>without multiprocessing:
2.384185791015625e-06</p>
<p>with multiprocessing:</p>
<p>1 processes: 0.35068225860595703</p>
<p>2 processes: 0.21297240257263184</p>
<p>3 processes: 0.21887946128845215</p>
<p>4 processes: 0.3474385738372803</p>
<p>When I replace simple with less_simple in lines 21 and 31, I get the following results:</p>
<p>without multiprocessing:
2.6226043701171875e-06</p>
<p>with multiprocessing:</p>
<p>1 processes: 3.1453816890716553</p>
<p>2 processes: 1.615351676940918</p>
<p>3 processes: 1.6125438213348389</p>
<p>4 processes: 1.5159809589385986</p>
<p>Honestly, I am a bit confused because the non-multiprocessing version is always some orders of magnitudes faster. Additionally, an increase of the process number seems to have little to no influence on the runtime. Therefore, I have a few questions:</p>
<ol>
<li>Do I make some mistake in the usage of multiprocessing?</li>
<li>Are my test functions to simple to get a positive impact from multiprocessing?</li>
<li>Is there a chance to estimate at which point multiprocessing has an advantage or do I have to test it?</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>I did some more research and basically, you are right. Both functions are rather small and somewhat artificial. However, there is a measurable time difference between non-multiprocessing and multiprocessing even for those functions, when you take into consideration how map works. The map function only returns an iterator yielding the results [1], i.e., in the above example, it only creates the iterator which is of course very fast.
Therefore, I replaced the map function with a traditional for loop:</p>
<pre><code>for elem in a:
    res = simple(a)
</code></pre>
<p>For the simple function, the execution is still faster without multiprocessing because the overhead is too big for such a small function:</p>
<ul>
<li><p>without multiprocessing:</p>
<ul>
<li>0.1392803192138672</li>
</ul></li>
<li><p>with multiprocessing:</p>
<ul>
<li>1 processes: 0.38080787658691406</li>
<li>2 processes: 0.22507309913635254</li>
<li>3 processes: 0.21307945251464844</li>
<li>4 processes: 0.2152390480041504</li>
</ul></li>
</ul>
<p>However, in case of the function less_simple, you can see an actual advantage of multiprocessing:</p>
<ul>
<li><p>without multiprocessing:</p>
<ul>
<li>3.2029929161071777</li>
</ul></li>
<li><p>with multiprocessing:</p>
<ul>
<li>1 processes: 3.4934208393096924</li>
<li>2 processes: 1.8259460926055908</li>
<li>3 processes: 1.9196875095367432</li>
<li>4 processes: 1.716357946395874</li>
</ul></li>
</ul>
<p>[1] <a href="https://docs.python.org/3/library/functions.html#map" rel="nofollow noreferrer">https://docs.python.org/3/library/functions.html#map</a></p>
</div>
<span class="comment-copy">For small tasks the cost of spawning new processes will outweigh the time spent doing work. And there's no need for it in the first place either.</span>
<span class="comment-copy">Your test functions are too simple. Spawning the processes and transfering the input and results is too expensive in relation to the actual computation.</span>
