<div class="post-text" itemprop="text">
<p>Here is my scrape:</p>
<pre><code>from bs4 import BeautifulSoup
import requests

url = 'http://www.baseballpress.com/lineups'

soup = BeautifulSoup(requests.get(url).text, 'html.parser')

for names in soup.find_all(class_="players"):
    print(names.text) 
</code></pre>
<p>I want to import my scrape to excel using xlwt. I used this code below to see if I could make an excel sheet using python:</p>
<pre><code>import xlwt  

wb = xlwt.Workbook()  
ws = wb.add_sheet("Batters")  
ws.write(0,0,"coding isn't easy")  
wb.save("myfirst_xlwt")
</code></pre>
<p>The code above worked. I would now like to apply it to my original scrape. How do I merge these two codes?</p>
<p>I am new so any help would be greatly appreciated. Thanks for your time! =)</p>
</div>
<div class="post-text" itemprop="text">
<p>I tried to run your code, but it doesn't find anything with class of <code>example</code>. It returns <code>[]</code>. </p>
<p>Regarding <code>xlwt</code>, basically, it just writes a cell (with the row and column parameter) using a string you specified. </p>
<pre><code>wb = xlwt.Workbook() 
ws = wb.add_sheet('sheet_name')
ws.write(0,0,"content") #Writes the first row, first col, in sheet called "sheet_name".
wb.save("example.xls")  
</code></pre>
<p>However, I think <code>pandas</code> is just better for that purpose. <code>xlwt</code> sometimes gets very messy if you lose track of row number and column number. If you can provide some non-empty result, I can write a simple script for you to export to Excel using pandas. </p>
<p>In order to use <code>pandas</code> for your example, here is the code.</p>
<pre><code>from bs4 import BeautifulSoup
import requests

url = 'http://www.baseballpress.com/lineups'

soup = BeautifulSoup(requests.get(url).text, 'html.parser')

all_games = []

for g in soup.find_all(class_="game"):
    players = g.find_all('a', class_='player-link')
    game = {
        'time': g.find(class_='game-time').text,
        'weather': g.find(target='forecast').text.strip(),
        'players': [_.text for _ in g.find_all('a', class_='player-link')],
    }
    all_games.append(game)

print(all_games) # This will print out a list of dict that contains the game information

import pandas as pd
df = pd.DataFrame.from_dict(all_games) # Construct dataframe from the list of dict
writer = pd.ExcelWriter('baseball.xlsx') # Init Pandas excel writer, using the file name 'baseball.xlsx'
df.to_excel(writer, 'baseball_sheet') # Writes to a sheet called 'baseball_sheet'. Format follows the Dataframe format.
writer.save() # Save excel
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The simplest way to merge the snippets would be to use <a href="http://xlwt.readthedocs.io/en/latest/api.html#xlwt.Worksheet.Worksheet.write" rel="nofollow noreferrer"><code>ws.write</code></a> any place you have a <a href="https://docs.python.org/3/library/functions.html#print" rel="nofollow noreferrer"><code>print</code></a> statement. You can use <a href="https://docs.python.org/3/library/functions.html#enumerate" rel="nofollow noreferrer"><code>enumerate</code></a> to keep track of your row index:</p>
<pre><code>from bs4 import BeautifulSoup
import requests
import xlwt  

wb = xlwt.Workbook()  
ws = wb.add_sheet("Batters")  

url = 'http://www.baseballpress.com/lineups'

soup = BeautifulSoup(requests.get(url).text, 'html.parser')

for row, name in enumerate(soup.find_all(class_="players")):
    ws.write(row, 0, name.text)
wb.save("myfirst_xlwt")
</code></pre>
</div>
<span class="comment-copy">I don't have xlwt here but you can try <a href="https://www.blog.pythonlibrary.org/2014/03/24/creating-microsoft-excel-spreadsheets-with-python-and-xlwt/" rel="nofollow noreferrer">this</a> tutorial</span>
<span class="comment-copy">Thanks @Nullman!</span>
<span class="comment-copy">I updated the code. Thank you so much @MartinLiu!</span>
<span class="comment-copy">Sure :) Would be great if you can accept the answer</span>
<span class="comment-copy">Edited my code. Pandas is simpler if you just want to export everything to Excel. All you need to do is to build a list of dicts, then convert it to a pandas DataFrame.</span>
<span class="comment-copy">Glad to help. Edited my code. Yeah the website structure is very straightforward, all you need to do is find the tag (&lt;a&gt; in this case), and some way to identify it (all of the players has <code>class</code> of "player-link")</span>
<span class="comment-copy">Maybe try to look for the directory you are in while using Python shell? Or you can add the absolute path in <code>writer = pd.ExcelWriter('baseball.xlsx')</code>.</span>
<span class="comment-copy">Ty!!! @MadPhysicist =) I appreciate the feedback a lot. I will test that out soon...</span>
<span class="comment-copy">Traceback (most recent call last):   File "C:/Users/xboss/Desktop/Baseball_Sheet_Code.py", line 12, in &lt;module&gt;     for row, name in soup.find_all(class_="players"): ValueError: not enough values to unpack (expected 2, got 0)</span>
<span class="comment-copy">Any idea why I would get that error @MadPhysicist? Sorry... I am a beginner.</span>
<span class="comment-copy">Because I forgot to add <code>enumerate</code> like I advertised. My mistake. Fixed now.</span>
<span class="comment-copy">Thank you sir for your time! I am very thankful for your help. =)</span>
