<div class="post-text" itemprop="text">
<p>How can I reduce the memory footprint for a dictionary containing 4M+ objects with strings?</p>
<p>It currently consumes about 1.5 GBytes of RAM, and I need to add several million more objects to it on systems that have limited resources due to prohibitive cost (cloud-based).</p>
<p>Here's some simplified code illustrating the gist of what I'm doing. Basically I fetch a set of about 4 million users from a database and put all the info into a local dict with all the users for quick access (I must work with a local copy of the user data for performance reasons).</p>
<h2>Simplified Code</h2>
<pre><code>import pymysql

class User:
    __slots__ = ['user_id', 'name', 'type']
    def __init__(self):
        user_id = None
        name = None
        type = None

cursor.execute("SELECT UserId, Username, Type FROM Users")
db_query_result = cursor.fetchall()

all_users = {}

for db_user in db_query_result:

    user_details = User()
    user_details.name = db_user[1]
    user_details.type = db_user[2]

    db_user_id = db_user[0]

    all_users[str(db_user_id)] = user_details
</code></pre>
<h3>Data Types</h3>
<ul>
<li>user_id: int</li>
<li>name: string, each one averaging maybe about 13 characters</li>
<li>type: int</li>
</ul>
<p>From some web searching, it seems to me User.name is consuming the majority of the space due to the large amount of memory required for string objects.</p>
<p>I already decreased the footprint from about 2GB down to 1.5GB by using <code>__slots__</code>, but I need to reduce it further.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you really need the data locally, consider saving it to a SQLite DB on the host, and letting SQLite load the hot dataset into memory for you, instead of keeping all of it in memory.</p>
<pre><code>db_conn = sqlite3.connect(path_to_sqlite_file)
db_conn.execute('PRAGMA mmap_size={};'.format(mmap_size))
</code></pre>
<p>If you really need all that data in memory, consider configuring swap space on the host as a cheaper alternative. The OS will swap colder memory pages to this swap space.</p>
<p>Of course, you can always compress your strings using gzip, if <code>name</code> is a large string. Other tricks include deduplication with an index, if there are repeated words in your names.</p>
<p>You can also use structs instead of classes.</p>
<pre><code>sys.getsizeof(u)  # 64 bytes
sys.getsizeof(struct.pack('HB13s', 10, 1, b'raymond'))  # 49 bytes
# unsigned short for user ID, unsigned byte for type, string with 13 bytes
</code></pre>
<p>If you know that your user IDs are contiguous, and you are using fixed length structs, you can also lookup simple array by counting byte offsets, instead of using the dict. (Numpy arrays would be useful here.)</p>
<pre><code>all_users = np.array([structs])
all_users = (struct0, struct1, struct2, ...)  # good old tuples are OK too e.g. all_users[user_id] would work
</code></pre>
<p>For something closer to production quality, you will want to have a data prep step that appends these structs to a file, which can later be read when you are actually using the data</p>
<pre><code># writing
with open('file.dat', mode='w+') as f:
    for user in users:
        f.write(user)  # where user is a fixed length struct

# reading
with open('file.dat', mode='r') as f:
    # given some index
    offset = index * length_of_struct
    f.seek(offset)
    struct = f.read(length_of_struct)
</code></pre>
<p>However, I am not convinced that this is the best design for the problem you actually have. Other alternatives include:</p>
<ul>
<li>inspecting your db design, especially your indexes</li>
<li>using memcache/redis to cache the most frequently used records</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>A 13-character string's actual string storage takes only 13 bytes if it's all Latin-1, 26 bytes if it's all BMP, 52 bytes if it's got characters from all over Unicode.</p>
<p>However, the overhead for a <code>str</code> object is another 52 bytes. So, assuming you've got mostly Latin-1, you're using about 5x as much storage as you need.</p>
<hr/>
<p>If your strings are, once encoded to UTF-8 or UTF-16-LE or whatever is best for your data, all around the same size, you probably want to store them in a big flat array and pull them out and decode them on the fly as needed, as shown in <a href="https://stackoverflow.com/a/51904236/908494">James Lim's answer</a>. Although I'd probably use a NumPy native structured dtype rather than use the <code>struct</code> module.</p>
<p>But what if you have a few huge strings, and you don't want to waste 88 bytes for each one when most of them are only 10 bytes long?</p>
<p>Then you want a string table. This is just a giant <code>bytearray</code> where all the (encoded) strings live, and you store indexes into that table instead of storing the strings themselves. Those indexes are just <code>int32</code> or at worst <code>int64</code> values that you can pack into an array with no problems.</p>
<p>For example, assuming none of your strings are more than 255 characters, we can store them as "Pascal strings", with a length byte followed by the encoded bytes:</p>
<pre><code>class StringTable:
    def __init__(self):
        self._table = bytearray()
    def add(self, s):
        b = s.encode()
        idx = len(self._table)
        self._table.append(len(b))
        self._table.extend(b)
        return idx
    def get(idx):
        stop = idx + self._table[idx]
        return self._table[idx+1:stop].decode()
</code></pre>
<p>So now:</p>
<pre><code>strings = StringTable()

for db_user in db_query_result:

    user_details = User()
    user_details.name = strings.add(db_user[1])
    user_details.type = strings.add(db_user[2])

    db_user_id = strings.add(str(db_user[0]))

    all_users[db_user_id] = user_details
</code></pre>
<p>Except, of course, you probably still want to replace that <code>all_users</code> with a numpy array.</p>
</div>
<div class="post-text" itemprop="text">
<p>Instead of using <code>cursor.fetchall()</code>, storing all the data in the client side, you should use an <code>SSCursor</code> to leave the result set on the server side:</p>
<pre><code>import pymysql
import pymysql.cursors as cursors

conn = pymysql.connect(..., cursorclass=cursors.SSCursor)
</code></pre>
<p>so that you can fetch the rows one by one:</p>
<pre><code>cursor = conn.cursor()
cursor.execute('SELECT UserId, Username, Type FROM Users')
for db_user in cursor:
    user_details = User()
    user_details.name = db_user[1]
    user_details.type = db_user[2]
    ...
</code></pre>
<p>And depending on what you want to do with the <code>all_users</code> dict, you may not need to store all user info in a dict either. If you can process each user one by one, do it directly inside the <code>for</code> loop above instead of building up a huge dict.</p>
</div>
<div class="post-text" itemprop="text">
<p>Do you actually need this cached <em>in memory</em>, or just <em>on the local system</em>?</p>
<p>If the latter, just use a local database.</p>
<p>Since you just want something that acts like a dict, you just want a <a href="https://en.wikipedia.org/wiki/Key-value_database" rel="nofollow noreferrer">key-value database</a>. The simplest KV database is a <a href="https://docs.python.org/3/library/dbm.html" rel="nofollow noreferrer"><code>dbm</code></a>, which Python supports out of the box. Using a <code>dbm</code> from Python looks exactly like using a dict, except that the data are on disk instead of in memory.</p>
<p>Unfortunately, <code>dbm</code> has two problems, but they're both solvable:</p>
<ul>
<li>Depending on the underlying implementation, a huge database might either not work, or go very slowly. You can use a modern variant like KyotoCabinet to solve that, but you'll need a third-party wrapper.</li>
<li><code>dbm</code> keys and values can only be <code>bytes</code>. Python's <code>dbm</code> module wraps things up to allow storing Unicode strings transparently, but nothing else. But Python comes with another module, <a href="https://docs.python.org/3/library/shelve.html" rel="nofollow noreferrer"><code>shelve</code></a>, which lets you transparently store any kind of value that can be pickled in a dbm.</li>
</ul>
<p>But you might want to instead use a more powerful key-value database like Dynamo or Couchbase.</p>
<p>In fact, you might even be able to get away with just using a KV database like Redis or Memcached purely in-memory, because they'll store the same data you're storing a lot more compactly.</p>
<p>Alternatively, you could just dump the data from the remote MySQL into a local MySQL, or even a local SQLite (and optionally throw an ORM in front of it).</p>
</div>
<span class="comment-copy">Not an answer, but those <code>user_id = None</code>, <code>name = None</code>, <code>type = None</code> assignments in <code>__init__</code> aren't initializing your object's instance attributes - you're missing the <code>self</code>.</span>
<span class="comment-copy">Also, what are you doing with this data? Are you sure pulling it out of the database is actually going to improve performance?</span>
<span class="comment-copy">@user2357112 There's an external data source (web API) with the same set of users, but it frequently gets modified. So basically I'm keeping my database content in sync with that external data source by pulling in my database's data, scanning the external source's user data sequentially, comparing that user data against my local model, and applying detected changes to my database. Minimizing the latency of this whole synchronization process is very important to the application.</span>
<span class="comment-copy">That really sounds like a job you should have the database handle.</span>
<span class="comment-copy">structs might do the trick here and save you a few bytes</span>
<span class="comment-copy">Nice variety of solutions here, thanks. I was hoping there would be another simple optimization, similar to when I added <b>slots</b> to the class, but if the memory consumption can't really be reduced then I'm probably leaning toward enabling OS swap (Ubuntu) on my system or perhaps using redis at this point</span>
