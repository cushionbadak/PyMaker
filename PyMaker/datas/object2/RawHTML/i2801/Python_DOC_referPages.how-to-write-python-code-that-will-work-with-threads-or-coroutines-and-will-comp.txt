<div class="post-text" itemprop="text">
<p>What I mean by "deterministic time"?  For example AWS offer a service "AWS Lambda". The process started as lambda function  has time limit, after that lambda function will stop execution and will assume that task was finished with error. And example task - send data to http endpoint. Depending of a network connection to http endpoint, or other factors, process of sending data can take a long time. If I need to send the same data to the many endpoints, then full process time will take <code>one process time</code> times <code>endpoints amount</code>. Which increase a chance that lambda function will be stopped before all data will be send to all endpoints.
To solve this I need to send data to different endpoints in parallel mode using threads.</p>
<p>The problem with threads - started thread can't be stopped. If http request will take more time than it dedicated by lambda function time limit, lambda function will be aborted and return error. So I need to use timeout with http request, to abort it, if it take more time than expected.</p>
<p>If http request will be canceled by timeout or endpoint will return error, I need to save not processed data somewhere to not lost the data. The time needed to save unprocessed data can be predicted, because I control the storage where data will be saved.</p>
<p>And the last part that consume time - procedure or loop where threads are scheduled <code>executor.submit()</code>. If there is only one endpoint or small number of them then the consumed time will be small. And there is no necessary to control this. But if I have deal with many endpoints, I have to take this into account.</p>
<p>So basically full time will consists of:</p>
<ul>
<li>scheduling threads</li>
<li>http request execution</li>
<li>saving unprocessed data</li>
</ul>
<p>There is example of how I can manage time using threads</p>
<pre><code>import concurrent.futures
from functools import partial

import requests
import time

start = time.time()

def send_data(data):
    host = 'http://127.0.0.1:5000/endpoint'
    try:
        result = requests.post(host, json=data, timeout=(0.1, 0.5))
        # print('done')
        if result.status_code == 200:
            return {'status': 'ok'}
        if result.status_code != 200:
            return {'status': 'error', 'msg': result.text}
    except requests.exceptions.Timeout as err:
        return {'status': 'error', 'msg': 'timeout'}


def get_data(n):
    return {"wait": n}


def done_cb(a, b, future):
    pass # save unprocessed data


def main():
    executor = concurrent.futures.ThreadPoolExecutor()
    futures = []
    max_time = 0.5

    for i in range(1):
        future = executor.submit(send_data, *[{"wait": 10}])
        future.add_done_callback(partial(done_cb, 2, 3))
        futures.append(future)
        if time.time() - s_time &gt; max_time:
            print('stopping creating new threads')
            # save unprocessed data
            break

    try:
        for item in concurrent.futures.as_completed(futures, timeout=1):
            item.result()
    except concurrent.futures.TimeoutError as err:
        pass
</code></pre>
<p>I was thinking of how I can use <code>asyncio</code> library instead of threads, to do the same thing. </p>
<pre><code>import asyncio
import time
from functools import partial

import requests

start = time.time()


def send_data(data):
    ...

def get_data(n):
    return {"wait": n}

def done_callback(a,b, future):
    pass # save unprocessed data

def main(loop):
    max_time = 0.5
    futures = []
    start_appending = time.time()
    for i in range(1):
        event_data = get_data(1)
        future = (loop.run_in_executor(None, send_data, event_data))
        future.add_done_callback(partial(done_callback, 2, 3))
        futures.append(future)

        if time.time() - s_time &gt; max_time:
            print('stopping creating new futures')
            # save unprocessed data
            break


    finished, unfinished = loop.run_until_complete(
        asyncio.wait(futures, timeout=1)
    )


_loop = asyncio.get_event_loop()
result = main(_loop)
</code></pre>
<p>Function <code>send_data()</code> the same as in previous code snipped.
Because request library is not async code I use <code>run_in_executor()</code> to create future object. The main problems I have is that <code>done_callback()</code> is not executed when the thread that started but executor done it's job. But only when the futures will be "processed" by <code>asyncio.wait()</code> expression. </p>
<p>Basically I seeking the way to start execute asyncio future, like <code>ThreadPoolExecutor</code> start execute threads, and not wait for <code>asyncio.wait()</code> expression to call <code>done_callback()</code>. If you have other ideas how to write python code that will work with threads or coroutines and will complete in deterministic time. Please share it, I will be glad to read them.</p>
<p>And other question. If thread or future done its job, it can return result, that I can use in <code>done_callback()</code>, for example to remove message from queue by id returned in result. But if thread or future was canceled, I don't have result. And I have to use <code>functools.partial()</code> pass in done_callback additional data, that can help me to understand for what data this callback was called. If passed data are small this is not a problem. If data will be big, I need to put data in array/list/dictionary and pass in callback only index of array or put "full data: in callback.</p>
<p>Can I somehow get access to variable that was passed to future/thread, from <code>done_callback()</code>, that was triggered on canceled future/thread?</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.wait_for" rel="nofollow noreferrer"><code>asyncio.wait_for</code></a> to wait for a future (or multiple futures, when combined with <code>asyncio.gather</code>) and cancel them in case of a timeout. Unlike threads, asyncio supports cancellation, so you can cancel a task whenever you feel like it, and it will be cancelled at the first blocking call it makes (typically a network call).</p>
<p>Note that for this to work, you should be using asyncio-native libraries such as <code>aiohttp</code> for HTTP. Trying to combine <code>requests</code> with asyncio using <code>run_in_executor</code> will appear to work for simple tasks, but it will not bring you the benefits of using asyncio, such as being able to spawn a massive number of tasks without encumbering the OS, or the possibility of cancellation.</p>
</div>
