<div class="post-text" itemprop="text">
<p>The following reproducible code produces an example data set that mimics my data on a much smaller scale. </p>
<pre><code>import numpy as np 
import pandas as pd

np.random.seed(142536)

df = pd.DataFrame({
        "vals": list(np.arange(12).reshape(3,4)),
        "idx" : list(np.random.choice([True, False], 12).reshape(3,4))})
df
</code></pre>
<p></p>
<pre><code>                           idx            vals
0   [False, True, True, False]    [0, 1, 2, 3]
1    [True, True, False, True]    [4, 5, 6, 7] 
2  [False, True, False, False]  [8, 9, 10, 11] 
</code></pre>
<p>The following reproducible code returns the results I want, but is very inefficient for large data sets.<br/>
How would I do this more efficiently?</p>
<pre><code>sel = []
for i in range(len(df.vals)):
    sel.append(df.vals[i][df.idx[i]])

df['sel'] = sel
df
</code></pre>
<p></p>
<pre><code>                           idx            vals        sel
0   [False, True, True, False]    [0, 1, 2, 3]     [1, 2]
1    [True, True, False, True]    [4, 5, 6, 7]  [4, 5, 7]
2  [False, True, False, False]  [8, 9, 10, 11]        [9]
</code></pre>
<p>I have tried <code>np.apply_along_axis()</code>, <code>np.where()</code>, <code>df.apply()</code>, and <code>df.transform()</code>, but can't get any of them to work for this case without errors.</p>
</div>
<div class="post-text" itemprop="text">
<p>If this is the <code>df</code>:</p>
<pre><code>             vals                         idx
0    [0, 1, 2, 3]   [True, False, True, True]
1    [4, 5, 6, 7]  [False, True, False, True]
2  [8, 9, 10, 11]   [True, True, True, False]
</code></pre>
<p>then your <code>sel</code> is:</p>
<pre><code>In [21]: sel
Out[21]: [array([0, 2, 3]), array([5, 7]), array([ 8,  9, 10])]
</code></pre>
<p>That is a list of arrays of differing sizes.</p>
<p>The <code>df</code> columns as arrays are:</p>
<pre><code>In [7]: vals = df['vals'].values
In [8]: idx = df['idx'].values
</code></pre>
<p>both are object arrays of arrays.  But we can convert them to 2d arrays with <code>stack</code> (or <code>vstack</code>):</p>
<pre><code>In [23]: vals = np.stack(vals)
In [24]: idx = np.stack(idx)
In [25]: vals
Out[25]: 
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
In [26]: idx
Out[26]: 
array([[ True, False,  True,  True],
       [False,  True, False,  True],
       [ True,  True,  True, False]])
</code></pre>
<p>We can simply index with the boolean mask - but the result is a 1d array:</p>
<pre><code>In [27]: vals[idx]
Out[27]: array([ 0,  2,  3,  5,  7,  8,  9, 10])
</code></pre>
<p><code>where</code> on <code>idx</code> produces the the equivalent tuple of indexing arrays:</p>
<pre><code>In [28]: np.where(idx)
Out[28]: (array([0, 0, 0, 1, 1, 2, 2, 2]), array([0, 2, 3, 1, 3, 0, 1, 2]))
</code></pre>
<p>We can also produce a masked array from these arrays:</p>
<pre><code>In [34]: mvals = np.ma.MaskedArray(vals, ~idx)
In [35]: mvals
Out[35]: 
masked_array(
  data=[[0, --, 2, 3],
        [--, 5, --, 7],
        [8, 9, 10, --]],
  mask=[[False,  True, False, False],
        [ True, False,  True, False],
        [False, False, False,  True]],
  fill_value=999999)
In [36]: mvals.compressed()
Out[36]: array([ 0,  2,  3,  5,  7,  8,  9, 10])
</code></pre>
<p>But to get the row by row values, we have to do some sort of iteration:</p>
<pre><code>In [37]: [row[i] for row,i in zip(vals, idx)]
Out[37]: [array([0, 2, 3]), array([5, 7]), array([ 8,  9, 10])]
</code></pre>
<p>And for this, the object arrays from <code>In[7]</code> and <code>In[8]</code> are just as good, if not better than the stacked 2d arrays.</p>
<pre><code>In [40]: [row[i] for row,i in zip(df['vals'], df['idx'])]
Out[40]: [array([0, 2, 3]), array([5, 7]), array([ 8,  9, 10])]
</code></pre>
<p>And your <code>range/append</code> loop is nearly as good (if not better).</p>
<p>The fact that your <code>sel</code> arrays vary in size (or at least in theory can vary), is a pretty good indication that 'vectorized', whole-array, operations are not possible.  But do you need such a list?  If you can't generate it with a fast array operation, you can't use it with one either. Both in creating and using you'll have to iterate on 'rows'.</p>
</div>
<div class="post-text" itemprop="text">
<p>The premise is bad because you shouldn't store data like this. You can at least speed this up by joining your data with <code>itertools.chain</code>, indexing, and then splitting the result with <code>np.array_split</code>.</p>
<pre><code>from itertools import chain

fn = lambda x: np.array(list(chain.from_iterable(x)))
df['sel'] = np.array_split(
    fn(df.vals)[fn(df.idx)], np.cumsum([sum(x) for x in df.idx][:-1]))
</code></pre>
<p></p>
<pre><code>                           idx            vals      sel
0   [True, False, True, False]    [0, 1, 2, 3]   [0, 2]
1  [False, False, False, True]    [4, 5, 6, 7]      [7]
2   [False, True, True, False]  [8, 9, 10, 11]  [9, 10]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using a list comprehension and numpy indexing:</p>
<pre><code>df.assign(sel=[x[y] for x, y in zip(df.vals, df.idx)])
</code></pre>
<p></p>
<pre><code>                           idx            vals      sel
0   [True, False, True, False]    [0, 1, 2, 3]   [0, 2]
1  [False, False, False, True]    [4, 5, 6, 7]      [7]
2   [False, True, True, False]  [8, 9, 10, 11]  [9, 10]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You shouldn't really use Pandas series to store lists. However, if this is unavoidable, you can use <a href="https://docs.python.org/3/library/itertools.html#itertools.compress" rel="nofollow noreferrer"><code>itertools.compress</code></a> with <code>map</code>, feeding <code>df['vals']</code> and <code>df['idx']</code> as separate arguments:</p>
<pre><code>from itertools import compress

df['sel'] = list(map(list, map(compress, df['vals'], df['idx'])))

print(df)

             vals                         idx        sel
0    [0, 1, 2, 3]   [False, True, True, True]  [1, 2, 3]
1    [4, 5, 6, 7]   [False, True, True, True]  [5, 6, 7]
2  [8, 9, 10, 11]  [True, False, False, True]    [8, 11]
</code></pre>
<p>If your <code>df['vals']</code> series is genuinely a NumPy array, you can use NumPy indexing:</p>
<pre><code>df['sel'] = [vals[idx] for vals, idx in zip(df['vals'], df['idx'])]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Apply should work fine if you unpack it a bit into a function. As for any speed increases, please report back on your use case/data as it might be rather costly to call the function over and over again:</p>
<pre><code>def return_indices(row):
    row_vals = row['vals']
    row_idx = row['idx']
    true_rows = np.where(row_idx == True)
    return list(row_vals[true_rows])

df['sel'] = df.apply(lambda x: return_indices(x), axis=1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Thank you everyone for the answers.</p>
<p>Below is what I came up with.  I have not (yet) compared timings with the other solutions.</p>
<pre><code>tmp = np.where(
        np.concatenate(df.idx.values).reshape(df.idx.values.shape[0],df.idx[0].shape[0] ), 
        np.concatenate(df.vals.values).reshape(df.vals.values.shape[0],df.vals[0].shape[0] ),
        np.nan)

df['sel'] = [*map(lambda a: [x for x in a if ~np.isnan(x)], tmp)]

df
</code></pre>
<p></p>
<pre><code>                           idx            vals              sel
0   [False, True, True, False]    [0, 1, 2, 3]       [1.0, 2.0]
1    [True, True, False, True]    [4, 5, 6, 7]  [4.0, 5.0, 7.0]
2  [False, True, False, False]  [8, 9, 10, 11]            [9.0]
</code></pre>
<p>I think this is better (though I have not tested) than the for loop I first presented in the OP, because this lambda function should be mapped (applied) to the <code>tmp</code> <code>np.array</code> in parallel and does not need to track the internal state of <code>i</code>.  Unless that is what python does with for loops anyway. </p>
<h1>EDIT:</h1>
<p>The for loop in the Original Post is <strong><em>significantly</em></strong> faster.  I don't have exact timings, but for my large data set the <code>map</code> function in this answer takes several minutes to complete, and the for loop in the OP takes seconds.</p>
<p>@hpaulj's comment "And your range/append loop is nearly as good (if not better)" is correct. </p>
</div>
<span class="comment-copy">Are all the rows in <code>vals</code> the same length?</span>
<span class="comment-copy">@user3483203 Yes they are.</span>
<span class="comment-copy">Chose this as the answer because it had the most thorough explanation, and is basically the same underlying approach I came up with.  It would be good though to compare the timings of all the solutions presented here.</span>
<span class="comment-copy">Careful, <code>df.vals</code> should be an array, not a list. In case it's a list, you'll need to do <code>np.array(x)[y]</code>.</span>
<span class="comment-copy">True, if his code is just for demonstration and he's actually using lists, this method wouldn't be that useful.</span>
<span class="comment-copy">I wouldn't expect this comprehension to significantly faster the append loop.  Use zip is a bit cleaner than the range indexing.</span>
