<div class="post-text" itemprop="text">
<p>Hey all I am using <a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="nofollow noreferrer">sklearn.ensemble.IsolationForest</a>, to predict outliers to my data. </p>
<p>Is it possible to train (fit) the model once to my clean data, and then save it to use it for later?
For example to save some attributes of the model, so the next time it isn't necessary to call again the fit function to train my model. </p>
<p>For example, for <code>GMM</code> I would save the <code>weights_</code>, <code>means_</code> and <code>covs_</code> of each component, so for later I wouldn't need to train the model again.</p>
<p>Just to make this clear, I am using this for online fraud detection, where this python script would be called many times for the same "category" of data, and I don't want to train the model EVERY time that I need to perform a predict, or test action.</p>
<p>Thanks in advance.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>sklearn</code> estimators implement methods to make it easy for you to save relevant trained properties of an estimator. Some estimators implement <code>__getstate__</code> methods themselves, but others, like the <code>GMM</code> just use the <a href="https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/base.py" rel="nofollow noreferrer">base implementation</a> which simply saves the objects inner dictionary:</p>
<pre><code>def __getstate__(self):
    try:
        state = super(BaseEstimator, self).__getstate__()
    except AttributeError:
        state = self.__dict__.copy()

    if type(self).__module__.startswith('sklearn.'):
        return dict(state.items(), _sklearn_version=__version__)
    else:
        return state
</code></pre>
<p>The recommended method to save your model to disc is to use the <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow noreferrer"><code>pickle</code></a> module:</p>
<pre><code>from sklearn import datasets
from sklearn.svm import SVC
iris = datasets.load_iris()
X = iris.data[:100, :2]
y = iris.target[:100]
model = SVC()
model.fit(X,y)
import pickle
with open('mymodel','wb') as f:
    pickle.dump(model,f)
</code></pre>
<p>However, you should save additional data so you can retrain your model in the future, or suffer dire consequences <strong>(such as being locked into an old version of sklearn)</strong>.</p>
<p>From the <a href="http://scikit-learn.org/stable/modules/model_persistence.html" rel="nofollow noreferrer">documentation</a>:</p>
<blockquote>
<p>In order to rebuild a similar model with future versions of
  scikit-learn, additional metadata should be saved along the pickled
  model: </p>
<p>The training data, e.g. a reference to a immutable snapshot </p>
<p>The python source code used to generate the model </p>
<p>The versions of scikit-learn and its dependencies </p>
<p>The cross validation score obtained on the training data</p>
</blockquote>
<p><strong>This is especially true for Ensemble estimators</strong> that rely on the <a href="https://github.com/scikit-learn/scikit-learn/blob/f3320a6f1ab2d060fd49c94a6e3386291a684ec7/sklearn/tree/_tree.pyx" rel="nofollow noreferrer"><code>tree.pyx</code></a> module written in Cython(such as <code>IsolationForest</code>), since it creates a coupling to the implementation, which is not guaranteed to be stable between versions of sklearn. It has seen backwards incompatible changes in the past.</p>
<p>If your models become very large and loading becomes a nuisance, you can also use the more efficient <code>joblib</code>. From the documentation:</p>
<blockquote>
<p>In the specific case of the scikit, it may be more interesting to use
  joblibâ€™s replacement of <code>pickle</code> (<code>joblib.dump</code> &amp; <code>joblib.load</code>), which is
  more efficient on objects that carry large numpy arrays internally as
  is often the case for fitted scikit-learn estimators, but can only
  pickle to the disk and not to a string:</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/2/library/pickle.html" rel="nofollow noreferrer">https://docs.python.org/2/library/pickle.html</a></p>
<p>Use Pickle library.</p>
<p>Fit your model.</p>
<p>Save it with  <code>pickle.dump(obj, file[, protocol])</code></p>
<p>Load it  with  <code>pickle.load(file)</code></p>
<p>Classify your outliers</p>
</div>
<span class="comment-copy">The best way is to use joblib: See more info <a href="https://stackoverflow.com/questions/10592605/save-classifier-to-disk-in-scikit-learn">in this thread</a>.</span>
