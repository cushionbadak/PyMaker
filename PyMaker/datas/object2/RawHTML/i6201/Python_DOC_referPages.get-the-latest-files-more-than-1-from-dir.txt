<div class="post-text" itemprop="text">
<p>i'm trying to extract the latest 'apple','pear' and other .csv stored in a directory in python. The new files get stored with the same prefix but with different frequency (e.g, apple_gets an update every 5 days or so).  Looking at something like <code>latestfile = max(filenames, key=os.path.getctime)</code> but category <code>.startwith</code>? specific - so i'd pull the only melon_ csv if there is one even though it was saved months ago. </p>
<pre><code>    """
fileDir contains csv files such as:

pear_20171102_report2.csv
apple_20171027_report2.csv
orange_20171101_report2.csv
kiwi 20171102 report2.csv
pear_20171101_report2.csv
cherry 20171101 report2.csv
kiwi 20171101 report2.csv
cherry 20171031_report2.csv
mango 20171001 report2.csv
apple_20171101_report2.csv
apple_20171102_report2.csv
...
"""

import glob
import os
import re

fileDir = r'\\ac2knyc05\TestData/'

filenames = glob.glob(fileDir+'*')
regex = re.compile(r'\d{8}')
dates = []
prefix = []

for filename in filenames:
    try:
        date = regex.search(filename).group()
        dates.append(date)
        prefix.append(filename.split(date)[0])

    except AttributeError:
        print(filename)

latestfile = max(filenames, key=os.path.getctime)

print(set(prefix)) 
</code></pre>
<p>stuck here, not sure how to proceed, maybe pandas? </p>
</div>
<div class="post-text" itemprop="text">
<p>No need for pandas, you can use <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer">itertools groupby</a>:</p>
<pre><code>from itertools import groupby

def key(filename):
    return filename.replace(" ", "_").split("_")[0]

{k: max(g, key=os.path.getctime)
     for k, g in groupby(sorted(filenames, key=key), key)}
</code></pre>
<p>while get you a dictionary of category to the latest file.</p>
<hr/>
<p>Note: You can get this in a single pass with a for loop:</p>
<pre><code>res = {}
for f in filenames:
    k, t = key(f), os.path.getctime(f)
    if k not in res:
        res[k] = f, t
    else:
        _, t_ = res[k]
        if t &gt; t_:
            res[k] = f, t

[f for f, _ in res.values()]  # list of the latest file for each category
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>No need for pandas. You could simply put those filenames in a dict of lists:</p>
<pre><code>filenames = """pear_20171102_report2.csv
apple_20171027_report2.csv
orange_20171101_report2.csv
kiwi 20171102 report2.csv
pear_20171101_report2.csv
cherry 20171101 report2.csv
kiwi 20171101 report2.csv
cherry 20171031_report2.csv
mango 20171001 report2.csv
apple_20171101_report2.csv
apple_20171102_report2.csv"""

categories = {}
for filename in filenames.split("\n"):
    start_with = filename.split(' ')[0].split('_')[0]
    categories.setdefault(start_with, []).append(filename)

print(categories)
# {'pear': ['pear_20171102_report2.csv', 'pear_20171101_report2.csv'], 'apple': ['apple_20171027_report2.csv', 'apple_20171101_report2.csv', 'apple_20171102_report2.csv'], 'orange': ['orange_20171101_report2.csv'], 'kiwi': ['kiwi 20171102 report2.csv', 'kiwi 20171101 report2.csv'], 'cherry': ['cherry 20171101 report2.csv', 'cherry 20171031_report2.csv'], 'mango': ['mango 20171001 report2.csv']}
</code></pre>
<p>For each category, you now have list which you can sort by <code>ctime</code>.</p>
</div>
<span class="comment-copy">Are these filenames placed inside another file? You need to be more specific about what you're asking.</span>
<span class="comment-copy">what is the input &amp; the expected output? it's not clear what you want</span>
<span class="comment-copy">@EricDuminil good point, also added way to do in a single pass.</span>
<span class="comment-copy">@Vrun: Sure you can.</span>
<span class="comment-copy">thanks.  filenames.split("\n"):  does not seem to work  as my filenames from glob is a list of paths while you assigning to a string</span>
<span class="comment-copy">@Vrun: Indeed, that was just an example on how to initialize <code>filenames</code> without having to create a fake directory.</span>
