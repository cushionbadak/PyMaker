<div class="post-text" itemprop="text">
<p>I am new to programming and am trying to build my first little web crawler in python. </p>
<p><strong>Goal:</strong> Crawling a product list page - scraping brand name, article name, original price and new price - saving in CSV file</p>
<p><strong>Status:</strong> I've managed to get the brand name, article name as well as original price and put them into correct order into a list (e.g. 10 products). As there is a brand name, description and price for all items, my code get them in correct order into the csv.  </p>
<p><strong>Code:</strong></p>
<pre><code>    import bs4 
    from urllib.request import urlopen as uReq
    from bs4 import BeautifulSoup as soup

    myUrl = 'https://www.zalando.de/rucksaecke-herren/'

    #open connection, grabbing page, saving in page_html and closing connection 
    uClient = uReq(myUrl)
    page_html = uClient.read()
    uClient.close()

    #Datatype, html paser
    page_soup = soup(page_html, "html.parser")

    #grabbing information
    brand_Names = page_soup.findAll("div",{"class": "z-nvg-cognac_brandName-2XZRz z-nvg-cognac_textFormat-16QFn"})
    articale_Names = page_soup.findAll ("div",{"class": "z-nvg-cognac_articleName--arFp z-nvg-cognac_textFormat-16QFn"})
    original_Prices = page_soup.findAll("div",{"class": "z-nvg-cognac_originalPrice-2Oy4G"})
    new_Prices = page_soup.findAll("div",{"class": "z-nvg-cognac_promotionalPrice-3GRE7"})

    #opening a csv file and printing its header
    filename = "XXX.csv"
    file = open(filename, "w")
    headers = "BRAND, ARTICALE NAME, OLD PRICE, NEW PRICE\n"
    file.write(headers)

    #How many brands on page?
    products_on_page = len(brand_Names)

    #Looping through all brands, atricles, prices and writing the text into the CSV 
    for i in range(products_on_page): 
            brand = brand_Names[i].text
            articale_Name = articale_Names[i].text
            price = original_Prices[i].text
            new_Price = new_Prices[i].text
            file.write(brand + "," + articale_Name + "," + price.replace(",",".") + new_Price.replace(",",".") +"\n")

    #closing CSV
    file.close()
</code></pre>
<p><strong>Problem:</strong> I am struggling with getting the discounted prices into my csv at the right place. Not every item has a discount and I currently see two issues with my code: </p>
<ol>
<li><p>I use .findAll to look for the information on the website - as there are less discounted products then total products, my new_Prices contains fewer prices (e.g. 3 prices for 10 products). If i would be able to add them to the list, I assume they would show up in the first 3 rows. How can i make sure to add the new_Prices to the right prodcuts?</p></li>
<li><p>I am getting "Index Error: list index out of range" Error, which i assume is caused by the fact that i am looping through 10 products, however for new_Prices i am reaching the end quicker then for my other lists? Does that make sense and is that my assumption correct? </p></li>
</ol>
<p>I am very much appreciating any help. </p>
<p>Thank, </p>
<p>Thorsten</p>
</div>
<div class="post-text" itemprop="text">
<p>Since some items don't have a <code>'div.z-nvg-cognac_promotionalPrice-3GRE7'</code> tag you can't use the list index reliably.<br/>
However you can select all the container tags (<code>'div.z-nvg-cognac_infoContainer-MvytX'</code>) and use <code>find</code> to select tags on each item.  </p>
<pre><code>from urllib.request import urlopen
from bs4 import BeautifulSoup as soup
import csv

my_url = 'https://www.zalando.de/sporttaschen-reisetaschen-herren/'
client = urlopen(my_url)
page_html = client.read().decode(errors='ignore')
page_soup = soup(page_html, "html.parser")

headers = ["BRAND", "ARTICALE NAME", "OLD PRICE", "NEW PRICE"]
filename = "test.csv"
with open(filename, 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(headers)

    items = page_soup.find_all(class_='z-nvg-cognac_infoContainer-MvytX')
    for item in items:
        brand_names = item.find(class_="z-nvg-cognac_brandName-2XZRz z-nvg-cognac_textFormat-16QFn").text
        articale_names = item.find(class_="z-nvg-cognac_articleName--arFp z-nvg-cognac_textFormat-16QFn").text
        original_prices = item.find(class_="z-nvg-cognac_originalPrice-2Oy4G").text
        new_prices = item.find(class_="z-nvg-cognac_promotionalPrice-3GRE7")
        if new_prices is not None: 
            new_prices = new_prices.text 
        writer.writerow([brand_names, articale_names, original_prices, new_prices])
</code></pre>
<hr/>
<p>If you want to get more than 24 items per page you have to use a client that runs js, like <a href="http://selenium-python.readthedocs.io/" rel="nofollow noreferrer"><code>selenium</code></a>.  </p>
<pre><code>from selenium import webdriver
from bs4 import BeautifulSoup as soup
import csv

my_url = 'https://www.zalando.de/sporttaschen-reisetaschen-herren/'
driver = webdriver.Firefox()
driver.get(my_url)
page_html = driver.page_source
driver.quit()
page_soup = soup(page_html, "html.parser")
...
</code></pre>
<p>Footnotes:<br/>
The <a href="https://www.python.org/dev/peps/pep-0008/#naming-conventions" rel="nofollow noreferrer">naming conventions</a> for functions and variables is lowercase with underscores.<br/>
When reading  or writting csv files it's best to use the <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer"><code>csv</code></a> lib.<br/>
When handling files you can use the <a href="https://docs.python.org/3/reference/compound_stmts.html#with" rel="nofollow noreferrer"><code>with</code></a> statement.</p>
</div>
<span class="comment-copy">Please do not post screenshots of your code, copy relevant code into code blocks.</span>
<span class="comment-copy">post a input example too</span>
<span class="comment-copy">@bgse updated with code into blocks</span>
<span class="comment-copy">@Guilherme not sure if i understand, could you please elaborate? What do you mean with input example</span>
<span class="comment-copy">@ThorsteinTorento I believe that Guilherme is asking you to post a link to the site in question. It would help us to understand what isn't working in your code</span>
<span class="comment-copy">Hi @t.m.adam, much appreciated your feedback and suggestions! I've finally gotten there myself but your code looks much neater! One think i noticed is that the page must have changed as there are now more then 24 items on the page. Oddly when running the crawler it only picks up 24 items. Any idea why?</span>
<span class="comment-copy">Yes, the rest of the items are loaded by js. You can test this if you disable js in your browser and visit the page. You can get all the items with <code>selenium</code> or sometimes via ajax api. I will post an example when i have some free time.</span>
<span class="comment-copy">Hi @t.m.adam, great! Thanks! Out of interest, why would the page be set up in that way (Loading those 24 items and then the rest via JS)? Thanks, T</span>
<span class="comment-copy">I have no idea, first time i see something like this. It should be either static html or  js for all items in the same group. Anyway, did you manage to get results with selenium?</span>
<span class="comment-copy">Hi @t.m.adam interesting! :) I will give it a try once i am off work - just had a look at it in my lunch break! I will keep you posted</span>
