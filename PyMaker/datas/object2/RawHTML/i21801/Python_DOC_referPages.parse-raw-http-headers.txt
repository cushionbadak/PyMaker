<div class="post-text" itemprop="text">
<p>I have a string of raw HTTP and I would like to represent the fields in an object. Is there any way to parse the individual headers from an HTTP string?</p>
<pre><code>'GET /search?sourceid=chrome&amp;ie=UTF-8&amp;q=ergterst HTTP/1.1\r\nHost: www.google.com\r\nConnection: keep-alive\r\nAccept: application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.45 Safari/534.13\r\nAccept-Encoding: gzip,deflate,sdch\r\nAvail-Dictionary: GeNLY2f-\r\nAccept-Language: en-US,en;q=0.8\r\n
[...]'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are excellent tools in the Standard Library both for parsing RFC 821 headers, and also for parsing entire HTTP requests. Here is an example request string (note that Python treats it as one big string, even though we are breaking it across several lines for readability) that we can feed to my examples:</p>
<pre><code>request_text = (
    'GET /who/ken/trust.html HTTP/1.1\r\n'
    'Host: cm.bell-labs.com\r\n'
    'Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.3\r\n'
    'Accept: text/html;q=0.9,text/plain\r\n'
    '\r\n'
    )
</code></pre>
<p>As @TryPyPy points out, you can use <code>mimetools.Message</code> to parse the headers — though we should add that the resulting <code>Message</code> object acts like a dictionary of headers once you are done creating it:</p>
<pre><code># Ignore the request line and parse only the headers

from mimetools import Message
from StringIO import StringIO
request_line, headers_alone = request_text.split('\r\n', 1)
headers = Message(StringIO(headers_alone))

print len(headers)     # -&gt; "3"
print headers.keys()   # -&gt; ['accept-charset', 'host', 'accept']
print headers['Host']  # -&gt; "cm.bell-labs.com"
</code></pre>
<p>But this, of course, ignores the request line, or makes you parse it yourself. It turns out that there is a much better solution.</p>
<p>The Standard Library will parse HTTP for you if you use its <code>BaseHTTPRequestHandler</code>. Though its documentation is a bit obscure — a problem with the whole suite of HTTP and URL tools in the Standard Library — all you have to do to make it parse a string is (a) wrap your string in a <code>StringIO()</code>, (b) read the <code>raw_requestline</code> so that it stands ready to be parsed, and (c) capture any error codes that occur during parsing instead of letting it try to write them back to the client (since we do not have one!).</p>
<p>So here is our specialization of the Standard Library class:</p>
<pre><code>from BaseHTTPServer import BaseHTTPRequestHandler
from StringIO import StringIO

class HTTPRequest(BaseHTTPRequestHandler):
    def __init__(self, request_text):
        self.rfile = StringIO(request_text)
        self.raw_requestline = self.rfile.readline()
        self.error_code = self.error_message = None
        self.parse_request()

    def send_error(self, code, message):
        self.error_code = code
        self.error_message = message
</code></pre>
<p>Again, I wish the Standard Library folks had realized that HTTP parsing should be broken out in a way that did not require us to write nine lines of code to properly call it, but what can you do? Here is how you would use this simple class:</p>
<pre><code># Using this new class is really easy!

request = HTTPRequest(request_text)

print request.error_code       # None  (check this first)
print request.command          # "GET"
print request.path             # "/who/ken/trust.html"
print request.request_version  # "HTTP/1.1"
print len(request.headers)     # 3
print request.headers.keys()   # ['accept-charset', 'host', 'accept']
print request.headers['host']  # "cm.bell-labs.com"
</code></pre>
<p>If there is an error during parsing, the <code>error_code</code> will not be <code>None</code>:</p>
<pre><code># Parsing can result in an error code and message

request = HTTPRequest('GET\r\nHeader: Value\r\n\r\n')

print request.error_code     # 400
print request.error_message  # "Bad request syntax ('GET')"
</code></pre>
<p>I prefer using the Standard Library like this because I suspect that they have already encountered and resolved any edge cases that might bite me if I try re-implementing an Internet specification myself with regular expressions.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>mimetools</code> has been deprecated since Python 2.3 and totally removed from Python 3 (<a href="https://docs.python.org/2/library/mimetools.html" rel="noreferrer">link</a>).</p>
<p>Here is how you should do in Python 3:</p>
<pre><code>import email
import io
import pprint

# […]

request_line, headers_alone = request_text.split('\r\n', 1)
message = email.message_from_file(io.StringIO(headers_alone))
headers = dict(message.items())
pprint.pprint(headers, width=160)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This seems to work fine if you strip the <code>GET</code> line:</p>
<pre><code>import mimetools
from StringIO import StringIO

he = "Host: www.google.com\r\nConnection: keep-alive\r\nAccept: application/xml,application/xhtml+xml,text/html;q=0.9,text/plain;q=0.8,image/png,*/*;q=0.5\r\nUser-Agent: Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_6; en-US) AppleWebKit/534.13 (KHTML, like Gecko) Chrome/9.0.597.45 Safari/534.13\r\nAccept-Encoding: gzip,deflate,sdch\r\nAvail-Dictionary: GeNLY2f-\r\nAccept-Language: en-US,en;q=0.8\r\n"

m = mimetools.Message(StringIO(he))

print m.headers
</code></pre>
<p>A way to parse your example and add information from the first line to the object would be:</p>
<pre><code>import mimetools
from StringIO import StringIO

he = 'GET /search?sourceid=chrome&amp;ie=UTF-8&amp;q=ergterst HTTP/1.1\r\nHost: www.google.com\r\nConnection: keep-alive\r\n'

# Pop the first line for further processing
request, he = he.split('\r\n', 1)    

# Get the headers
m = mimetools.Message(StringIO(he))

# Add request information
m.dict['method'], m.dict['path'], m.dict['http-version'] = request.split()    

print m['method'], m['path'], m['http-version']
print m['Connection']
print m.headers
print m.dict
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using python3.7, <code>urllib3.HTTPResponse</code>, <code>http.client.parse_headers</code>, and with <a href="https://explainshell.com/explain?cmd=curl+-i+-L+-X+GET+%22http%3A%2F%2Fhttpbin.org%2Frelative-redirect%2F3%22+" rel="nofollow noreferrer">curl flag explanation here</a>:</p>
<pre><code>curl -i -L -X GET "http://httpbin.org/relative-redirect/3" |  python -c '
import sys
from io import BytesIO
from urllib3 import HTTPResponse
from http.client import parse_headers

rawresponse = sys.stdin.read().encode("utf8")
redirects = []

while True:
    header, body = rawresponse.split(b"\r\n\r\n", 1)
    if body[:4] == b"HTTP":
        redirects.append(header)
        rawresponse = body
    else:
        break

f = BytesIO(header)
# read one line for HTTP/2 STATUSCODE MESSAGE
requestline = f.readline().split(b" ")
protocol, status = requestline[:2]
headers = parse_headers(f)

resp = HTTPResponse(body, headers=headers)
resp.status = int(status)

print("headers")
print(resp.headers)

print("redirects")
print(redirects)
'
</code></pre>
<p>Output:</p>
<pre><code>  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
100   215  100   215    0     0    435      0 --:--:-- --:--:-- --:--:--   435

headers
HTTPHeaderDict({'Connection': 'keep-alive', 'Server': 'gunicorn/19.9.0', 'Date': 'Thu, 20 Sep 2018 05:39:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '215', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Via': '1.1 vegur'})
redirects
[b'HTTP/1.1 302 FOUND\r\nConnection: keep-alive\r\nServer: gunicorn/19.9.0\r\nDate: Thu, 20 Sep 2018 05:39:24 GMT\r\nContent-Type: text/html; charset=utf-8\r\nContent-Length: 0\r\nLocation: /relative-redirect/2\r\nAccess-Control-Allow-Origin: *\r\nAccess-Control-Allow-Credentials: true\r\nVia: 1.1 vegur',
 b'HTTP/1.1 302 FOUND\r\nConnection: keep-alive\r\nServer: gunicorn/19.9.0\r\nDate: Thu, 20 Sep 2018 05:39:24 GMT\r\nContent-Type: text/html; charset=utf-8\r\nContent-Length: 0\r\nLocation: /relative-redirect/1\r\nAccess-Control-Allow-Origin: *\r\nAccess-Control-Allow-Credentials: true\r\nVia: 1.1 vegur',
 b'HTTP/1.1 302 FOUND\r\nConnection: keep-alive\r\nServer: gunicorn/19.9.0\r\nDate: Thu, 20 Sep 2018 05:39:24 GMT\r\nContent-Type: text/html; charset=utf-8\r\nContent-Length: 0\r\nLocation: /get\r\nAccess-Control-Allow-Origin: *\r\nAccess-Control-Allow-Credentials: true\r\nVia: 1.1 vegur']
</code></pre>
<p>notes:</p>
<ul>
<li><a href="https://urllib3.readthedocs.io/en/latest/reference/#urllib3.response.HTTPResponse" rel="nofollow noreferrer">https://urllib3.readthedocs.io/en/latest/reference/#urllib3.response.HTTPResponse</a></li>
<li><a href="https://github.com/python/cpython/blob/master/Lib/http/client.py#L193" rel="nofollow noreferrer">parse_headers()</a></li>
</ul>
</div>
<span class="comment-copy">This is awesome, thanks! However, I need to maintain the order of HTTP header filed info (dictionaries do not maintain order). Is there anyway to do this?</span>
<span class="comment-copy">I am not sure! Deep inside of the <code>Message</code> and request classes that Python uses to do this parsing should be, I suppose, a line of code that creates the dictionary of headers. If it could be told to instead use an <code>OrderedDict</code> instead of a plain <code>dict</code> then you would know the order — but, having just toured the code briefly, I could not tell where the header dictionary was created.</span>
<span class="comment-copy">@jeffrey: Starting from Python 3.6, the order of the dict is the insertion order: <a href="https://docs.python.org/3/library/stdtypes.html#typesmapping" rel="nofollow noreferrer">docs.python.org/3/library/stdtypes.html#typesmapping</a></span>
<span class="comment-copy"><code>email.message_from_file(io.StringIO(headers_alone))</code> could be replaced with <code>email.message_from_string(headers_alone)</code>.</span>
<span class="comment-copy">Is there a way to do this in python3?</span>
<span class="comment-copy">mimetools is deprecated since 2.3</span>
<span class="comment-copy">@Broseph See Gowtham's answer.</span>
