<div class="post-text" itemprop="text">
<p>Setting the default output encoding in Python 2 is a well-known idiom:</p>
<pre><code>sys.stdout = codecs.getwriter("utf-8")(sys.stdout)
</code></pre>
<p>This wraps the <code>sys.stdout</code> object in a codec writer that encodes output in UTF-8.</p>
<p>However, this technique does not work in Python 3 because <code>sys.stdout.write()</code> expects a <code>str</code>, but the result of encoding is <code>bytes</code>, and an error occurs when <code>codecs</code> tries to write the encoded bytes to the original <code>sys.stdout</code>.</p>
<p>What is the correct way to do this in Python 3?</p>
</div>
<div class="post-text" itemprop="text">
<p>Since Python 3.7 you can change the encoding of standard streams with <a href="https://docs.python.org/3/library/io.html#io.TextIOWrapper.reconfigure" rel="noreferrer"><code>reconfigure()</code></a>:</p>
<pre><code>sys.stdout.reconfigure(encoding='utf-8')
</code></pre>
<p>You can also modify how encoding errors are handled by adding an <code>errors</code> parameter.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python 3.1 added <code>io.TextIOBase.detach()</code>, with a note in the documentation for <a href="http://docs.python.org/py3k/library/sys.html#sys.stdout"><code>sys.stdout</code></a>:</p>
<blockquote>
<p>The standard streams are in text mode by default. To write or read binary data to these, use the underlying binary buffer. For example, to write bytes to <code>stdout</code>, use <code>sys.stdout.buffer.write(b'abc')</code>. Using <code>io.TextIOBase.detach()</code> streams can be made binary by default. This function sets <code>stdin</code> and <code>stdout</code> to binary:</p>
<pre><code>def make_streams_binary():
    sys.stdin = sys.stdin.detach()
    sys.stdout = sys.stdout.detach()
</code></pre>
</blockquote>
<p>Therefore, the corresponding idiom for Python 3.1 and later is:</p>
<pre><code>sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I found this thread while searching for solutions to the same error,</p>
<p>An alternative solution to those already suggested is to set the <code>PYTHONIOENCODING</code> environment variable <strong>before</strong> Python starts, for my use - this is less trouble then swapping <code>sys.stdout</code> after Python is initialized:</p>
<pre><code>PYTHONIOENCODING=utf-8:surrogateescape python3 somescript.py
</code></pre>
<p>With the advantage of not having to go and edit the Python code.</p>
</div>
<div class="post-text" itemprop="text">
<p>Other answers seem to recommend using <code>codecs</code>, but <code>open</code> works for me:</p>
<pre><code>import sys
sys.stdout = open(sys.stdout.fileno(), mode='w', encoding='utf8', buffering=1)
print("日本語")
# Also works with other methods of writing to stdout:
sys.stdout.write("日本語\n")
sys.stdout.buffer.write("日本語\n".encode())
</code></pre>
<p>This works even when I run it with <code>PYTHONIOENCODING="ascii"</code>.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>Setting the default output encoding in Python 2 is a well-known idiom</p>
</blockquote>
<p>Eek! Is that a well-known idiom in Python 2? It looks like a dangerous mistake to me.</p>
<p>It'll certainly mess up any script that tries to write binary to stdout (which you'll need if you're a CGI script returning an image, for example). Bytes and chars are quite different animals; it's not a good idea to monkey-patch an interface that is specified to accept bytes with one that only takes chars.</p>
<p>CGI and HTTP in general explicitly work with bytes. You should only be sending bytes to sys.stdout. In Python 3 that means using <code>sys.stdout.buffer.write</code> to send bytes directly. Encoding page content to match its <code>charset</code> parameter should be handled at a higher level in your application (in cases where you are returning textual content, rather than binary). This also means <code>print</code> is no good for CGI any more.</p>
<p>(To add to the confusion, wsgiref's CGIHandler has been broken in py3k until very recently, making it impossible to deploy WSGI to CGI that way. With PEP 3333 and Python 3.2 this is finally workable.)</p>
</div>
<div class="post-text" itemprop="text">
<p>Using <code>detach()</code> causes the interpreter to print a warning when it tries to close stdout just before it exits:</p>
<pre><code>Exception ignored in: &lt;_io.TextIOWrapper mode='w' encoding='UTF-8'&gt;
ValueError: underlying buffer has been detached
</code></pre>
<p>Instead, this worked fine for me:</p>
<pre><code>default_out = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
</code></pre>
<p>(And, of course, writing to <code>default_out</code> instead of stdout.)</p>
</div>
<div class="post-text" itemprop="text">
<p>sys.stdout is in text mode in Python 3. Hence you write unicode to it directly, and the idiom for Python 2 is no longer needed.</p>
<p>Where this would fail in Python 2:</p>
<pre><code>&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.stdout.write(u"ûnicöde")
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
UnicodeEncodeError: 'ascii' codec can't encode character u'\xfb' in position 0: ordinal not in range(128)
</code></pre>
<p>However, it works just dandy in Python 3:</p>
<pre><code>&gt;&gt;&gt; import sys
&gt;&gt;&gt; sys.stdout.write("Ûnicöde")
Ûnicöde7
</code></pre>
<p>Now if your Python doesn't know what your stdouts encoding actually is, that's a different problem, most likely in the build of the Python. </p>
</div>
<span class="comment-copy">2to3 is a useful tool for questions like these.</span>
<span class="comment-copy">@dan_waterworth: I didn't think of trying that before, but I just tried <code>2to3</code> now and it didn't suggest any changes for the given code.</span>
<span class="comment-copy">If the new code doesn't work then I'd suggest you add this as a bug.</span>
<span class="comment-copy">Wow, this causes a lot of fun in an interactive shell - try <code>sys.stdout = codecs.getwriter("hex")(sys.stdout)</code> in <code>ipython</code> to see what I mean...</span>
<span class="comment-copy">I'd use <code>PYTHONIOENCODING</code>; otherwise <code>io.TextIOWrapper</code> might be better alternative than <code>codecs</code> to handle newlines properly.</span>
<span class="comment-copy">This totally changes the behavior of <code>sys.stdout</code>. The <code>StreamWriter</code> returned by <code>codecs.getwriter</code> is not line-buffered anymore, e.g..</span>
<span class="comment-copy">Thumbs-upping mainly because PYTHONIOENCODING=utf-8 solved my problem, after many hours of searching.</span>
<span class="comment-copy">This worked for me for dealing with an error caused by importing a module that I could not change.  On a pretty vanilla Linux system that defaulted to LC_ALL = C, my program generated <code>'ascii' code can't encode character .... ordinal not in range(128)</code> when code from the imported module tried to print something. I could not rely on users of my program changing LC_ALL to 'en_US.UTF-8'. This hack solved it. I know it's an ugly approach, but I could not find another solution.</span>
<span class="comment-copy">This comment needs to be updated, concerning 3.3 and upcoming 3.4  Python release. Thank you</span>
<span class="comment-copy">My context was running the Python script as a CGI under Apache, where the default output encoding wasn't what I needed (I needed UTF-8). I think it's better for the script to ensure that its output is in the correct encoding, rather than relying on external settings (such as environment variables like PYTHONIOENCODING).</span>
<span class="comment-copy">Yet another proof that using stdout for process communication is big mistake. I realize you may have no choice than to use CGI in this case though so that's not your fault. :-)</span>
<span class="comment-copy">While it is true that <code>sys.stdout</code> is a <i>binary</i> file in Python 2 and a <i>text</i> file in Python 3, I think your Python 2 example fails because the unicode string <code>u"ûnicöde"</code> that gets implicitly encoded in the <code>sys.stdout.write</code> method has characters outside the ASCII range. If you change your <code>LC_CTYPE</code>, <code>LANG</code> or <code>PYTHONIOENCODING</code> environment variables to an encoding that has all the characters in the unicode string you should not get any error. (I have tried on Python 2.7.)</span>
