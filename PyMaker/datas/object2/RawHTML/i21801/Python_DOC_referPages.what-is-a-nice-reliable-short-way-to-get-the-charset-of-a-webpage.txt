<div class="post-text" itemprop="text">
<p>I'm a bit surprised that it's so complicated to get a charset of a webpage with Python. Am I missing a way? The HTTPMessage has loads of functions, but not this.</p>
<pre><code>&gt;&gt;&gt; google = urllib2.urlopen('http://www.google.com/')
&gt;&gt;&gt; google.headers.gettype()
'text/html'
&gt;&gt;&gt; google.headers.getencoding()
'7bit'
&gt;&gt;&gt; google.headers.getcharset()
Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
AttributeError: HTTPMessage instance has no attribute 'getcharset'
</code></pre>
<p>So you have to get the header, and split it. Twice.</p>
<pre><code>&gt;&gt;&gt; google = urllib2.urlopen('http://www.google.com/')
&gt;&gt;&gt; charset = 'ISO-8859-1'
&gt;&gt;&gt; contenttype = google.headers.getheader('Content-Type', '')
&gt;&gt;&gt; if ';' in contenttype:
...     charset = contenttype.split(';')[1].split('=')[1]
&gt;&gt;&gt; charset
'ISO-8859-1'
</code></pre>
<p>That's a surprising amount of steps for such a basic function. Am I missing something?</p>
</div>
<div class="post-text" itemprop="text">
<p>Have you checked this?</p>
<p><a href="https://stackoverflow.com/questions/1495627/how-to-download-any-webpage-with-correct-charset-in-python">How to download any(!) webpage with correct charset in python?</a></p>
</div>
<div class="post-text" itemprop="text">
<p>I did some research and came up with this solution:</p>
<pre><code>response = urllib.request.urlopen(url)
encoding = response.headers.get_content_charset()
</code></pre>
<p>This is how I would do it in Python 3. I haven't tested it in Python 2 but I am guessing that you would have to use <code>urllib2.request</code> instead of <code>urllib.request</code>.</p>
<p>Here is how it works, since the official Python documentation doesn't explain it very well: the result of <a href="https://docs.python.org/3/library/urllib.request.html#urllib.request.urlopen" rel="nofollow"><code>urlopen</code></a> is an <a href="https://docs.python.org/3/library/http.client.html#httpresponse-objects" rel="nofollow"><code>http.client.HTTPResponse</code></a> object. The <code>headers</code> property of this object is an <a href="https://docs.python.org/3/library/http.client.html#httpmessage-objects" rel="nofollow"><code>http.client.HTTPMessage</code></a> object, which, according to the documentation, "is implemented using the <a href="https://docs.python.org/3/library/email.message.html#email.message.Message" rel="nofollow"><code>email.message.Message</code></a> class", which has a method called <a href="https://docs.python.org/3/library/email.message.html#email.message.Message.get_content_charset" rel="nofollow"><code>get_content_charset</code></a>, which tries to determine and return the character set of the response.</p>
<p>By default, this method returns <code>None</code> if it is unable to determine the character set, but you can override this behavior instead by passing a <code>failobj</code> parameter:</p>
<pre><code>encoding = response.headers.get_content_charset(failobj="utf-8")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You're not missing anything. It's doing the right thing - encoding of a HTTP response is a subpart of Content-Type.</p>
<p>Note also that some pages might send only <code>Content-Type: text/html</code> and then set the encoding via <code>&lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt;</code> - that's an ugly hack though (on the part of the page author) and is not too common.</p>
</div>
<div class="post-text" itemprop="text">
<p>I would go with <a href="http://pypi.python.org/pypi/chardet" rel="nofollow">chardet</a> Universal Encoding Detector.</p>
<pre><code>&gt;&gt;&gt; import urllib
&gt;&gt;&gt; urlread = lambda url: urllib.urlopen(url).read()
&gt;&gt;&gt; import chardet
&gt;&gt;&gt; chardet.detect(urlread("http://google.cn/"))
{'encoding': 'GB2312', 'confidence': 0.99}
</code></pre>
<p>You are doing right but your approach would fail for pages where charset is declared on <code>meta</code> tag or is not declared at all.<br/>
If you look closer at Chardet sources, it has a <code>charsetprober/charsetgroupprober</code> modules that deals with this problem nicely.</p>
</div>
<span class="comment-copy">From RFC 2616 (HTTP1.1) <code>The "charset" parameter is used with some media types to define the character set (section 3.4) of the data. When no explicit charset parameter is provided by the sender, media subtypes of the "text" type are defined to have a default charset value of "ISO-8859-1" when received via HTTP.</code>, as a side-note to your default being ASCII.</span>
<span class="comment-copy">@plundra: Well, ISO-8859-1 is a superset of ASCII, but you're correct - it's a different encoding.</span>
<span class="comment-copy">@Piskvor: And if one were to use the <code>charset</code> from above with s.decode() for example, things will break (with pages sending iso-8859-1 and relying on implicit)</span>
<span class="comment-copy">Ah, so I should check for the type, and if it's text it should default to latin-1, and otherwise it's presumably binary and shouldn't be decoded at all. :) Yet another step of complexity.</span>
<span class="comment-copy">No, I had not. Thanks!</span>
<span class="comment-copy">So I had missed something, namely <code>.headers.getparam('charset')</code>, which simplifies a lot.</span>
<span class="comment-copy"><code>get_content_charset</code> isn't available in Python 2. You should be able to use <code>headers.getparam("charset")</code> instead (Python 2 only; Python 3 renames it to <code>get_param</code>).</span>
<span class="comment-copy">For me, this is not a good answer: chardet is "guessing the encoding of [the HTML] file" (see <a href="https://github.com/erikrose/chardet" rel="nofollow noreferrer">github.com/erikrose/chardet</a>). You should, of course, first start by looking in the headers if it's declared. See the question pointed to by Leniel.</span>
