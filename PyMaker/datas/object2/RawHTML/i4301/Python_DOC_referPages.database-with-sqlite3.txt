<div class="post-text" itemprop="text">
<p>I am creating a stock price database with Sqlite3 python library. But my code is taking ages to run, not sure why it is slow. Any idea how I can speed it up? Am I doing something wrong?</p>
<p>I am using Python 3.x, Anaconda</p>
<pre><code>import pandas as pd
from googlefinance.client import get_price_data, get_prices_data, get_prices_time_data
import sqlite3
db = sqlite3.connect('database.db')
c = db.cursor()

param = {'q':'MMM', 'i':"86400",'x':"NYSE",'p':"25Y"}
end_of_day = pd.DataFrame(get_price_data(param))
end_of_day['Time']=end_of_day.index
count= len(end_of_day['Time'])

c.execute('CREATE TABLE IF NOT EXISTS MMM(date,open,high,low,close,volume)')

for i in range(0,count):
    c.execute('INSERT INTO MMM(date,open,high,low,close,volume) VALUES(?,?,?,?,?,?)',
              (str(end_of_day.iloc[i][5]),str(end_of_day.iloc[i][0]),str(end_of_day.iloc[i][1]),
              str(end_of_day.iloc[i][2]),str(end_of_day.iloc[i][3]),str(end_of_day.iloc[i][4])))
    db.commit()

c.close()
db.close()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming <code>count</code> is large, that loop will really be slowing things down. You can use <code>executemany()</code> to speed things up. Try replacing your loop with this:</p>
<pre><code>params = end_of_day.apply(tuple).tolist()  # Convert dataframe to list of tuples
c.executemany('INSERT INTO MMM(open,high,low,close,volume,date) VALUES(?,?,?,?,?,?)', params)
db.commit()
</code></pre>
<p>See <a href="https://docs.python.org/3/library/sqlite3.html" rel="nofollow noreferrer">documentation</a> for more info on <code>executemany()</code>.</p>
<p>An even easier option might be to simply use the built-in Pandas function <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html" rel="nofollow noreferrer"><code>to_sql()</code></a>:</p>
<pre><code>end_of_day.to_sql('MMM', db)
</code></pre>
<p>You might have to rearrange your column order a little in Pandas before doing this, but it is a very convenient function to be aware of.</p>
</div>
<div class="post-text" itemprop="text">
<p>Your code is taking time is because you are using commit for every insert and using execute whereas for bulk inserts you can use executemany().</p>
<p>Try to bind all the data in tuple and then append to list then use executemany for fast bulk inserts:</p>
<pre><code>_list=[]
for i in range(0,count):
    _tuple=(str(end_of_day.iloc[i][5]),str(end_of_day.iloc[i][0]),str(end_of_day.iloc[i][1]),
     str(end_of_day.iloc[i][2]),str(end_of_day.iloc[i][3]),str(end_of_day.iloc[i][4])))
    _list.append(_tuple)
    _tuple=()

c.executemany('INSERT INTO MMM(date,open,high,low,close,volume) VALUES(?,?,?,?,?,?)',(_list))
db.commit()
</code></pre>
</div>
<span class="comment-copy">How large is <code>count</code>?</span>
<span class="comment-copy">Your insert query has two parts. First part defines fields array and second part defines values array. use must loop second part only to make it a values array buffering it in a string variable. currently your loop is executing insert query on every iteration. this is making it slow. then execute insert query after the loop by concatenating fields part and values part.</span>
<span class="comment-copy">You can use Pandas to write into SQLite directly</span>
<span class="comment-copy">The real problem is the commit. The Sqlite3 documentation states that multiple INSERT are not a problem, but multiple COMMIT are...</span>
