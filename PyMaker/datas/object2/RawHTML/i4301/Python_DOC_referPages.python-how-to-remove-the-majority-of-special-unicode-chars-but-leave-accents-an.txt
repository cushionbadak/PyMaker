<div class="post-text" itemprop="text">
<p>I am scraping text from a webpage in Python.</p>
<p>The text contains all kinds of special unicode chars such as hearts, smilies and other wild stuff.</p>
<p>By using <code>content.encode('ascii', 'ignore')</code> I am able to convert everything to ASCII but that means all accented chars and mutated vowels such as '√§' or '√ü' are gone as well.</p>
<p>How can leave the "normal" chars such as '√§' or '√©' intact but can remove all the other stuff?</p>
<p>(I must admit I am quite a newbie in Python and I never really got behind all the magic behind character encoding).</p>
</div>
<div class="post-text" itemprop="text">
<p>It's not entirely clear from your question where you draw the line between the ‚Äúgood‚Äù and the ‚Äúbad‚Äù characters, but you probably don't know that yet, either.
Unicode contains a lot of different kinds of characters, and you might not be aware of the diversity.</p>
<p>Unicode assigns a <a href="https://en.wikipedia.org/wiki/Unicode_character_property#General_Category" rel="nofollow noreferrer">category</a> to each character, such as ‚ÄúLetter, lowercase‚Äù or ‚ÄúPunctuation, final quote‚Äù or ‚ÄúSymbol, other‚Äù.
Python's std-lib module <code>unicodedata</code> gives you convenient access to this information:</p>
<pre><code>&gt;&gt;&gt; import unicodedata as ud
&gt;&gt;&gt; ud.category('√§')
'Ll'
&gt;&gt;&gt; ud.category('üôÉ')
'So'
</code></pre>
<p>From your examples it seems like you think <em>letters</em> are good, while <em>symbols</em> are bad.
But you'll have to sort out the rest too.
You probably want to keep blanks (‚Äúseparators‚Äù) and punctuation as well.
And you <em>might</em> need the marks too, as they include the <a href="https://en.wikipedia.org/wiki/Combining_character" rel="nofollow noreferrer">combining characters</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Few steps:</p>
<p>You should normalize unicode, with <code>unicodedata.normalize('NFC', my_text)</code>. Not really on the question, but you must have a common ground, let's have the same character to have the same encoding.</p>
<p>Then you should check every character to see if you allow it or not:</p>
<pre><code>new_text = []
for c in my_normalized_text:
    if ord(c) &lt; 128:
        # this is optional, it add ascii character as they are
        # possibly you want to tokenize (see later, how we replace punctuation)
        new_text.append(c)
        continue
    cat = unicodedata.category(c)
    if cat in {'Lu', 'Ll', 'Lt', 'Lm', 'Lo', 'Nd'}:
        new_text.append(c)
    elif cat in {'Mc', 'Pc', 'Pd', 'Ps', 'Pe', 'Pi', 'Of', 'Po', 'Zs', 'Zl', 'Zp'}:
        # this tokenize
        new_text.append(' ')
    # else: do not append. You may still append ' ' and remove above check.
</code></pre>
<p>You should adapt according your next processing methods: See <a href="https://docs.python.org/3/howto/unicode.html" rel="nofollow noreferrer">Python Unicode HOWTO</a> and the linked page <a href="http://www.unicode.org/reports/tr44/#General_Category_Values" rel="nofollow noreferrer">Unicode character categories</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Well, I finally used this:</p>
<pre><code>    # create translation map for non-bmp charactes
    non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)

    # strip unwanted unicode images
    question = question.translate(non_bmp_map)

    # convert to latin-1 to remove all stupid unicode characters
    # you may want to adapt this to your personal needs
    #
    # for some strange reason I have to first transform the string to bytes with latin-1
    # encoding and then do the reverse transform from bytes to string with latin-1 encoding as
    # well... maybe has to be revised later
    bQuestion = question.encode('latin-1', 'ignore')
    question = bQuestion.decode('latin-1', 'ignore')
</code></pre>
<p>Thanks to anybody who answered</p>
</div>
<span class="comment-copy">Can you provide an example input and expected output and also show what you tried so far.</span>
<span class="comment-copy">Why can't you use unicode?</span>
<span class="comment-copy">Possible duplicate of <a href="https://stackoverflow.com/questions/2700859/how-to-replace-unicode-characters-by-ascii-characters-in-python-perl-script-giv">How to replace unicode characters by ascii characters in Python (perl script given)?</a></span>
<span class="comment-copy"><code>content.encode('latin1','ignore')</code> will keep the common Western European accented characters.  You'll still lose Russian, Japanese, Chinese, etc.</span>
<span class="comment-copy">@J√∂rgF. you can't. Edit your question instead of creating illegible comments.</span>
