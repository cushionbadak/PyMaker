<div class="post-text" itemprop="text">
<p>[PYTHON 3.x]
Hello everyone,
I am working on a project in Natural language processing and need some help. 
I have created a vocabulary (list) of distinct words from all the documents. I want to create a vector of each document against this vocabulary list. 
(Doc_POS_words contains 100 documents, in this form Doc_POS_words[0] = 1st doc,Doc_POS_words[1] = 2nd doc and so on.)</p>
<p>Output:</p>
<pre><code># Doc_POS_words = [contains all the words of each document as below]

Doc_POS_words = [
  ['war','life','travel','live','night'], 
  ['books','stuent','travel','study','yellow'],
  ]

# myVoc = [distinct words from all the documents as below]

myVoc = [
  'war',
  'life', 
  'travel',
  'live',
  'night',
  'books',
  'student',
  'study',
  'yellow'
]

# myVoc_vector = [ need this as well ]

# Doc_POS_words_BoW = [need this for each document]
</code></pre>
<p>PS: I am not using NLTK because I am not working on any of the supported languages by NLTK </p>
<p>Thanks. </p>
</div>
<div class="post-text" itemprop="text">
<p>Check <code>TfidfVectorizer</code></p>
<pre><code>from sklearn.feature_extraction.text import TfidfVectorizer
corpus = ["Doc 1 words",
          "Doc 2 words"]
vectorizer = TfidfVectorizer(min_df=1)
vectors = vectorizer.fit_transform(corpus)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I'm still not sure what you are asking so I will give you some general help.  I think what you need is to use python sets.</p>
<p><a href="https://docs.python.org/3/tutorial/datastructures.html#sets" rel="nofollow noreferrer">https://docs.python.org/3/tutorial/datastructures.html#sets</a></p>
<p>Here are some examples for you, <strong>using the data in your question:</strong></p>
<pre><code># create a set of the whole word list
myVocSet = set(myVoc)

for doc_words in Doc_POS_words:
  # convert from list to set
  doc_words = set(doc_words)  

  # want to find words in the doc also in the vocabulary list?
  print(myVocSet.intersection(doc_words))

  # want to find words in your doc not in the vocabulary list?
  print(doc_words.difference(myVocSet))

  # want to find words in the vocab list not used in your doc?
  print(MyVocSet.difference(myVocSet))
</code></pre>
<hr/>
<p>Here is some more to help:</p>
<pre><code>&gt;&gt;&gt; x = set(('a', 'b', 'c', 'd'))
&gt;&gt;&gt; y = set(('c', 'd', 'e', 'f'))
&gt;&gt;&gt;
&gt;&gt;&gt; x.difference(y)
{'a', 'b'}
&gt;&gt;&gt; y.difference(x)
{'f', 'e'}
&gt;&gt;&gt; x.intersection(y)
{'c', 'd'}
&gt;&gt;&gt; y.intersection(x)
{'c', 'd'}
&gt;&gt;&gt; x.union(y)
{'a', 'b', 'd', 'f', 'e', 'c'}
&gt;&gt;&gt; x.symmetric_difference(y)
{'a', 'b', 'f', 'e'}
</code></pre>
</div>
<span class="comment-copy">Your question is not clear.  Please edit to make clear what is in each variable so we can help you.</span>
<span class="comment-copy">I have updated the question with an example. I hope it is more understandable now.</span>
<span class="comment-copy">Thanks for replying. I have already tried TfidfVectorizer but it is not working with my data and keeps showing the following message:  ERROR: return lambda x: strip_accents(x.lower()) AttributeError: 'list' object has no attribute 'lower'  PS: I have words similar to ARABIC language words.</span>
