<div class="post-text" itemprop="text">
<p>I currently have a program which uses a <code>while</code> loop to receive messages as a subscriber from a <strong><code>zmq_socket</code></strong>. Every time I get a new message, I need to make an HTTP request to a server, which will then send a response. This call takes around 1 second to make. I would like to have a way to call the HTTP request and then loop again, get another message from <code>zmq_socket</code>, and call another HTTP request without waiting for the first one.</p>
<p>The pseudo-code would look something like this:</p>
<pre><code>url = 'http://example.com'

def callback(message):
    r = requests.post(url, data = message)
    # store r in class variable (not sure how to do this asynchronously) 

while True:
    message = zmq_socket.recv_json()
    callback(message)
    # do other stuff
    # continue without waiting for callback to finish
</code></pre>
<h2>Is there any way to do this in Python?</h2>
<p>I've looked into libraries like <code>tornado</code> and <code>asyncio</code> as well as looking at <code>multithreading</code> and I haven't figured out a solution.</p>
</div>
<div class="post-text" itemprop="text">
<h2>Yes, there are several ways to do this in Python :</h2>
<p>Their main difference is the cost-of-operations and performance.</p>
<p><strong>A )</strong><br/>
The simplest and cheapest ever is to use Tkinter-native infrastructure of independent <strong><code>.mainloop()</code></strong>-orchestrated processing, where independent serial-processing cheaply takes place in a co-orchestrated manner, with additional soft-real-time benefits, if one may wish to use them. Given this option, one may soft-schedule the <strong><code>callback</code></strong> using either an <strong><code>.after()</code></strong> or even <strong><code>.after_idle()</code></strong> ( as your code regularly goes into a blocking-mode of the <code>.recv()</code> receiver ) scheduling methods.</p>
<p><strong>B )</strong><br/>
Another, way smarter Tkinter-native infrastructure tool may do a similar job more efficiently, given the <strong><code>message</code></strong> would actually become a Tkinter's <strong><code>StringVar</code></strong>-instance, that has been equipped with a <code>&lt;aVarTRACER&gt;:&lt;aTracedVarEventHANDLER&gt;</code>-monitoring-tool. This way any value-change of the <strong><code>message</code></strong> will auto-trigger a <strong><code>callback</code></strong>, without the code taking any further steps ( but the correct setup of such <code>StringVar</code> monitor ). I love this Tkinter-tool, indeed for many powerful Live-GUI designs.</p>
<pre><code> ##########
 # THEORY :
 # .trace_variable( &lt;mode&gt;, &lt;aTracedVarEventHANDLER&gt; )
 #                  &lt;mode&gt; := { "w": WRITE-DELTA-TRACER    |
 #                              "r": READ-ACCESS-TRACER    |
 #                              "u": UNDEFINE-DELETE-TRACER
 #                               }

 #########
 # SETUP :
 pass;             aMessageVAR = StringVar()
 id_W            = aMessageVAR.trace_variable( "w", \ 
 onWriteChange_var_aMessageVAR ) #             "WRITE"-DELTA-Event &lt;~ callback()
 # + any change of aMessageVAR auto-triggers  onWriteChange_var_aMessageVAR()
 #                                             with 3 params:
 #                                                  aTkNameOfVAR,
 #                                                  aTkArrayIndex,
 #                                                  aTkAccessMode {"w"|"r"|"u"}
 #
 #                                             global       aMessageVAR
 #                                             aLocalCopy = aMessageVAR.get()
 #                                             #LocalCopy content b4 next .set()

 ############
 # ORIGINAL :
 #____________________________________________ original while-loop:
 while True:
                   aMessageVAR.set( zmq_socket.recv_json() )
                   #                                     ^__blocks, better
                   #                                        design
                   #                                        non-blocking .poll()
                   #                                        scheduled with
                   #                                        .after( nMS, aPoll )
                   #                                        + .set() on POSACK'd
 #########
 # FINALLY:
 pass;             aMessageVAR.trace_vdelete( "w", id_W ) # CLEAN THE TRACER
</code></pre>
<p><strong>C )</strong><br/>
Last, but not least, one may design a scalable performance ZeroMQ workflow from inside of your <strong><code>while</code></strong>-loop, where any such received <code>message</code> gets marshalled into a pool of remote-workers over another <code>zmq_task_to_pool_of_workers_socket</code>. This approach can help easily "mask" the worker-side processing latency by adding more remote-workers into the pool of workers, besides the elementary trick of getting the async <code>.post()</code>-method and other associated work done "outside" of the said <code>while</code>-loop. The almost linear performance scaling + latency masking of this option may go beyond the shared GIL-lock stepping, so if these are the core design-features, this is the way to go.</p>
</div>
<span class="comment-copy">You can use a <a href="https://docs.python.org/3/library/queue.html#queue.Queue" rel="nofollow noreferrer">docs.python.org/3/library/queue.html#queue.Queue</a> to pass <code>message</code> to a <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">docs.python.org/3/library/threading.html</a> that executes <code>callback</code>.</span>
