<div class="post-text" itemprop="text">
<p>I initialize three numpy arrays, because I need to feed some random data into an algorithm.</p>
<p>My second array has about a hundred times the values, and takes about a hundred times the time.</p>
<p>The third, for some reason, takes almost 1800 times the amount of time as the second does.</p>
<pre><code>nparray = np.random.randint(0, 256, (1024, 800, 3)) #0.03125357627868652
nparray = np.random.randint(0, 256, (100, 1024, 800, 3) #2.9687747955322266
nparray = np.random.randint(0, 256, (10, 100, 1024, 800, 3)) #5339.585757017136
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming numpy uses <code>dtype('int64')</code> for these arrays, i.e. 8 bytes per element:</p>
<ul>
<li>The 1st array is 2457600 elements (~20 Megabytes)</li>
<li>The 2nd array is 245760000 elements (~2 Gigabytes)</li>
<li>The 3rd array is 2457600000 elements (~20 Gigabytes)</li>
</ul>
<p>If you have a reasonably average machine, the first and second cases can likely work entirely in RAM.  The third array is huge and will almost surely require swapping data to disk, which is significantly slower.</p>
<p>You can check the sizes of an objects in Python by using <a href="https://docs.python.org/3/library/sys.html#sys.getsizeof" rel="nofollow noreferrer"><code>sys.getsizeof(obj)</code></a>.  Check memory available with <code>free</code> (Linux) or <code>vm_stat</code> (macOS).  </p>
</div>
