<div class="post-text" itemprop="text">
<p>I have a dictionary with information about single positions: <code>position_info</code>, and info about features <code>feature_info</code>. I have to find in which features (can be multiple) the positions are located, so that I can annotate the positions. What I use now is:</p>
<pre><code>feature_info = [[1, 10, 'a'],[15, 30, 'b'],[40, 60, 'c'],[55, 71, 'd'],[73, 84, 'e']]
position_info = {5:'some info', 16:'some other info', 75:'last info'}
for pos in position_info.keys():
    for info in feature_info:
        if info[0] &lt;= pos &lt; info[1]:
            print(pos, position_info[pos], info[2])
</code></pre>
<p>The problem is that <code>feature_info</code> contains 800k+ features, and <code>position_info</code> 150k positions, and this is quite slow. I can optimize it myself a little bit, but probably there are already methods that do it better than I can, but I have not found them. </p>
<h2>EDIT</h2>
<p>So for example this is one way I can think of to speed it up:</p>
<pre><code>for info in feature_info:
    for pos in position_info.keys():
        if info[0] &lt;= pos &lt; info[1]:
            print(pos, position_info[pos], info[2])
        if pos &gt; info[1]:
            break
</code></pre>
<p>if I order the positions I can break when the position is larger than an end position of a feature (if I make sure those are ordered too). However, there must be a better way to do this. </p>
<p>How can I implement this in the fastest way?</p>
<h2>Comparison of the 3 answers</h2>
<pre><code>import timeit

setup = """
from bisect import bisect
import pandas as pd
import random
import numpy as np

position_info = {}

random_number = random.sample(range(9000), 8000)
random_feature_start = random.sample(range(90000), 5000)
random_feature_length = np.random.choice(1000, 5000, replace=True)

for i in random_number:
    position_info[i] = 'test'
feature_info = []
for index, i in enumerate(random_feature_start):
    feature_info.append([i, i+random_feature_length[index],'test'])

"""

p1 = """
sections = sorted(r for a, b, c in feature_info for r in (a,b))
for pos in position_info:
    feature_info[int(bisect(sections, pos) / 2)]
"""

p2 = """
# feature info to dataframe
feature_df = pd.DataFrame(feature_info)

# rename feature df columns
feature_df.rename(index=str, columns={0: "start", 1: "end",2:'name'}, inplace=True)

# positions to dataframe
position_df = pd.DataFrame.from_dict(position_info, orient='index')
position_df['key'] = position_df.index

# merge dataframes
feature_df['merge'] = 1
position_df['merge'] = 1
merge_df = feature_df.merge(position_df, on='merge')
merge_df.drop(['merge'], inplace=True, axis=1)

# filter where key between start and end
merge_df = merge_df.loc[(merge_df.key &gt; merge_df.start) &amp; (merge_df.key &lt; merge_df.end)] 
"""

p3 = """
feature_df = pd.DataFrame(feature_info)
position_df = pd.DataFrame(position_info, index=[0])
hits = position_df.apply(lambda col: (feature_df [0] &lt;= col.name) &amp; (col.name &lt; feature_df [1])).values.nonzero()
for f, p in zip(*hits):
    position_info[position_df.columns[p]]
    feature_info[f]
"""

print('bisect:',timeit.timeit(p1, setup=setup, number = 3))
print('panda method 1:',timeit.timeit(p2, setup=setup, number = 3))
print('panda method 2:',timeit.timeit(p3, setup=setup, number = 3))
</code></pre>
<p>bisect: 0.08317881799985116<br/>
panda method 1: 29.6151025639997<br/>
panda method 2: 16.90901438500032  </p>
<p>However, the bisect method only works if there are no overlapping features, e.g. </p>
<pre><code>feature_info = [[1, 10, 'a'],[15, 30, 'b'],[40, 60, 'c'],[55, 71, 'd'],[2, 8, 'a_new']]
</code></pre>
<p>does not work, which does work with the pandas solution. </p>
</div>
<div class="post-text" itemprop="text">
<p>The fastest way is probably to use a fast library: <a href="https://pandas.pydata.org/" rel="nofollow noreferrer">pandas</a>. Pandas vectorizes your operations to make them speedy.</p>
<pre><code>feature_df = pd.DataFrame(feature_info)
position_df = pd.DataFrame(position_info, index=[0])
hits = position_df.apply(lambda col: (feature_df[0] &lt;= col.name) &amp; (col.name &lt; feature_df[1])).values.nonzero()
for feature, position in zip(*hits):
    print(position_info[position_df.columns[p]], "between", feature_info[f])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://docs.python.org/3/library/bisect.html" rel="nofollow noreferrer"><code>bisect</code></a> library and function is amazing for things like this.</p>
<p>We basically create a sorted list of ranges that a feature will fall under. Let me know if you need additional logic for checking if a position doesn't fall within a feature range.</p>
<p>Since <code>feature_info[n][0:1]</code> is a range of 2 values, we need to divide the bisect result (which is an index position) by 2.</p>
<pre><code>from bisect import bisect

feature_info = [[1, 10, 'a'],[15, 30, 'b'],[40, 60, 'c'],[55, 71, 'd'],[73, 84, 'e']]
position_info = {5:'some info', 16:'some other info', 75:'last info'}
sections = sorted(r for a, b, c in feature_info for r in (a,b))

for pos in position_info:
  print(pos, feature_info[bisect(sections, pos) / 2])
</code></pre>
<p>This will print the following (you should be able to get all the info you need from this, but I wanted to show the basic result):</p>
<pre><code>(16, [15, 30, 'b'])
(75, [73, 84, 'e'])
(5, [1, 10, 'a'])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Is a textual description OK?</p>
<p>Preprocessing:</p>
<ul>
<li>sort the positions</li>
<li>convert list of features into a list of "boundaries" (as in, start indices and end indices for each feature) - these will be triples of (<code>index</code>, <code>start/end</code>, <code>feature</code>). Sort this list by index.</li>
</ul>
<p>Algorithm (two nested for loops):</p>
<ul>
<li>start with empty set of 'current features'</li>
<li>for each feature boundary:

<ul>
<li>for each position from the range of: from the next position after last-visited position, until the position of current boundary's position:

<ul>
<li>output that this position belongs to each of current features</li>
</ul></li>
<li>if the current boundary is a start, add it to the current features</li>
<li>if the current boundary is an end, remove it from the current features</li>
</ul></li>
</ul>
<p>Note that:</p>
<ul>
<li>the outer for loop will execute exactly once for each boundary,</li>
<li>the inner for loop will execute (in total) exactly once for each position.</li>
</ul>
<p>This will be fast because you don't need to look at any position or any feature twice in both loops. It will actually approach O(N+M) complexity if the positions don't overlap often (so that the current_features set remains small).</p>
<p>I assumed that there are no duplicate positions; handling these would add a little more complexity but the general approach would still work.</p>
</div>
<div class="post-text" itemprop="text">
<p>Also using pandas. First converts them to dataframes, then merges, then filters where position info key is between feature info columns.</p>
<pre><code>import pandas as pd

feature_info = [[1, 10, 'a'],[15, 30, 'b'],[40, 60, 'c'],[55, 71, 'd'],[73, 84, 'e']]
position_info = {5:'some info', 16:'some other info', 75:'last info'}

# feature info to dataframe
feature_df = pd.DataFrame(feature_info)

# rename feature df columns
feature_df.rename(index=str, columns={0: "start", 1: "end",2:'name'}, inplace=True)

# positions to dataframe
position_df = pd.DataFrame.from_dict(position_info, orient='index')
position_df['key'] = position_df.index

# merge dataframes
feature_df['merge'] = 1
position_df['merge'] = 1
merge_df = feature_df.merge(position_df, on='merge')
merge_df.drop(['merge'], inplace=True, axis=1)

# filter where key between start and end
merge_df = merge_df.loc[(merge_df.key &gt; merge_df.start) &amp; (merge_df.key &lt; merge_df.end)] 
</code></pre>
</div>
<span class="comment-copy">Just to be sure, the code works as intended, just needs to be optimized?</span>
<span class="comment-copy">Yes the output is correct, but because it has to loop through all the features for every position it is slow when those both get big. @SunnyPatel I added code of one optimization I can think of that also works (the one I had previously did not)</span>
<span class="comment-copy">Can't you use a binary search to find a feature position that fits? Other positions will be next to it (assuming all is sorted)</span>
<span class="comment-copy">About <code>feature_info</code>, are all the ranges in index 0 and 1 non-overlapping and discrete? I was going to give you a solution using binary search.</span>
<span class="comment-copy">No, features can be overlapping, they are all discrete.</span>
<span class="comment-copy">I forgot to mention that bisect is blazing fast for large data sets because it does operate using binary search.</span>
