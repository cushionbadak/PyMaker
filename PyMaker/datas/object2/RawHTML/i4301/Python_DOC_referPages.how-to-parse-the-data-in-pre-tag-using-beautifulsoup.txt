<div class="post-text" itemprop="text">
<p>when I am trying to scrape the data from the following website </p>
<p>url = <a href="https://bedbathandbeyond.ugc.bazaarvoice.com/2009-en_us/1061083288/reviews.djs?format=embeddedhtml&amp;page=4&amp;scrollToTop=true" rel="nofollow noreferrer">https://bedbathandbeyond.ugc.bazaarvoice.com/2009-en_us/1061083288/reviews.djs?format=embeddedhtml&amp;page=4&amp;scrollToTop=true</a></p>
<p>I got this from bedbathbeyond website and if I use request and beautifulsoup, I can't get anything. Why is that?</p>
<p>code:</p>
<pre><code>r = requests.get(url)
soup = BeautifulSoup(r.content,'lxml')
soup.find_all('span', class_ = 'BVRRReviewAbbreviatedText')
</code></pre>
<p>the return value is empty: []</p>
</div>
<div class="post-text" itemprop="text">
<p>I used <a href="https://github.com/PiotrDabkowski/Js2Py" rel="nofollow noreferrer"><code>js2py</code></a>, since <code>materials</code> object contains several keys (<code>BVRRRatingSummarySourceID</code>, <code>BVRRSecondaryRatingSummarySourceID</code> and <code>BVRRSourceID</code>) and getting the HTML from its values with regex would be much harder in case you need it all.</p>
<pre><code>from bs4 import BeautifulSoup
import js2py
import requests

r = requests.get('https://bedbathandbeyond.ugc.bazaarvoice.com/2009-en_us/1061083288/reviews.djs?format=embeddedhtml')

pattern = (r'var'
           r'\s+'
           r'materials'
           r'\s*=\s*'
           r'{"BVRRRatingSummarySourceID".*}')

js_materials = re.search(pattern, r.text).group()
obj = js2py.eval_js(js_materials).to_dict()
html = obj['BVRRSourceID']
soup = BeautifulSoup(html, 'lxml')
spans = soup.select('span.BVRRReviewAbbreviatedText')
</code></pre>
<pre><code>&gt;&gt;&gt; len(spans)
5
</code></pre>
<p>In the example below I only used the HTML under the <code>BVRRSourceID</code> key, but you can use the entire HTML by join the values together:</p>
<pre><code>html = ''.join(obj.values())
</code></pre>
<p>Don't forget to install <code>js2py</code>: <code>pip install js2py</code> and <code>pip install lxml</code> if you want to use <code>lxml</code> parser.</p>
</div>
<div class="post-text" itemprop="text">
<p>You could use selenium webdriver in order to get the html content that you are interested. For example, </p>
<pre><code>from selenium import webdriver


def get_html(url):
    driver = webdriver.Chrome()
    driver.maximize_window()
    driver.get(url)

    time.sleep(5)
    html_content = driver.page_source.strip()
    return html_content
</code></pre>
</div>
<span class="comment-copy">That's because the HTML is inside an AJAX call, so BeautifulSoup won't be able to parse content.</span>
<span class="comment-copy">Even tho I didn't quite understand some parts of the answer, it worked! Thanks a lot!</span>
<span class="comment-copy">You can read about regular expressions <a href="https://docs.python.org/3/howto/regex.html" rel="nofollow noreferrer">here</a>.</span>
<span class="comment-copy">Hi, thanks for answering. after saving the result to a variable, let say "a=get_html(url)", then I tried to parse it using Beautifulsoup: soup = Beautifulsoup(a,'lxml'), then 'soup.find_all('span', class = 'BVRRReviewText'), still can not retrieve anything. Why is that?</span>
