<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/960733/python-creating-a-dictionary-of-lists">Python creating a dictionary of lists</a>
<span class="question-originals-answer-count">
                    6 answers
                </span>
</li>
</ul>
</div>
<p>My list of list looks something like this:</p>
<pre><code>[[4,'apples'],[3,'oranges'],[4,'bananas'],[2,'apples'],[2,'pineapple'],[3,'apples']]
</code></pre>
<p>I want to create a dictionary from this, where the values of each item is listed:
for example, I want the following output:</p>
<pre><code>{4:'apples','bananas', 3:'oranges','apples', 2:'apples', 'pineapple'}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/library/stdtypes.html#dict.setdefault" rel="nofollow noreferrer"><code>dict.setdefault</code></a> can help here if you don't want to use <a href="https://docs.python.org/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>collections.defaultdict</code></a>:</p>
<pre><code>lst = [[4,'apples'],[3,'oranges'],[4,'bananas'],[2,'apples'],[2,'pineapple'],[3,'apples']]

dct = {}

for num, name in lst:
    dct.setdefault(num, []).append(name)

print(dct)
#{2: ['apples', 'pineapple'],
# 3: ['oranges', 'apples'],
# 4: ['apples', 'bananas']}
</code></pre>
<p>However <code>defaultdict</code> is generally the better and more general solution.</p>
</div>
<div class="post-text" itemprop="text">
<p>Code agency at your service:</p>
<pre><code>lst = [['4','apples'],['3','oranges'],['4','bananas'],['2','apples'],['2','pineapple'],['3','apples']]

result = {}
for item in lst:
    key = item[0]
    try:
        result[key].append(item[1])
    except:
        result[key] = [item[1]]

print(result)
# {'3': ['oranges', 'apples'], '2': ['apples', 'pineapple'], '4': ['apples', 'bananas']}
</code></pre>
<p>As stated by @Jean-Francois Fabre, this solutions is rather slow: 3,5 seconds bs 5.7 seconds for 100000 iterations with 3,5 being the solution with <code>defaultdict</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Using <code>collections.defaultdict</code>:</p>
<pre><code>result = defaultdict(list)
for key, value in [[4,apples],[3,oranges],[4,bananas],[2,apples],[2,pineapple],[3,apples]]:
    result[key].append(value)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><code>collections.defaultdict</code> might be useful to you.</p>
<pre><code>from collections import defaultdict


items =  [
    [4, "apples"],
    [3, "oranges"],
    [4, "bananas"],
    [2, "apples"],
    [2, "pineapple"],
    [3, "apples"]
]

mapping = defaultdict(list)
for number, name in items:
    mapping[number].append(name)
</code></pre>
<p>Examples of official document of <code>defaultdict</code> would be helpful to you.</p>
<p><a href="https://docs.python.org/3/library/collections.html#defaultdict-examples" rel="nofollow noreferrer">https://docs.python.org/3/library/collections.html#defaultdict-examples</a></p>
</div>
<span class="comment-copy"><code>4:['apples','bananas']</code>?</span>
<span class="comment-copy">and I benched it just by curiosity and it's faster than defaultdict, even if you create a list at each iteration that is sometimes not needed.</span>
<span class="comment-copy">@Jean-FrançoisFabre It's not always faster, to further optimize it one use a bound method <code>dctsetdefault = dct.setdefault</code> and use that inside the loop! But the actual timing depends on the length of the list and the number of duplicate keys (maybe even on other stuff as well). If speed is a concern use <code>iteration_utilities.groupedby(lst, key=operator.itemgetter(0), keep=operator.itemgetter(1))</code> (but requires importing the <code>operator</code>-module and an external library).</span>
<span class="comment-copy">@Jean-FrançoisFabre: You have a comparison?</span>
<span class="comment-copy">yes and it's slower, as expected because of exceptions. You may want to work on bigger data to see that, but with existing data, I get 3,5 seconds bs 5.7 seconds for 100000 iterations with your solution.</span>
<span class="comment-copy">@Jean-FrançoisFabre: Thanks for the hint, I'll update the answer to reflect your thoughts.</span>
<span class="comment-copy">actually it's more like 1000000 iterations. Also you could directly unpack key &amp; values instead of accessing by index. Maybe it slows down execution too.</span>
