<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/14258984/most-pythonic-way-to-build-dictionary-from-single-list">Most Pythonic Way to Build Dictionary From Single List</a>
<span class="question-originals-answer-count">
                    2 answers
                </span>
</li>
</ul>
</div>
<p>Is there a faster way in generating a dictionary with a certain default value?  I basically want an equavalent of</p>
<pre><code>arrays = [True] * (n+1)
</code></pre>
<p>but for dictionary.  I currently have:</p>
<pre><code>dicts = dict([(i,True) for i in range(0,n+1)])
</code></pre>
<p>The problem is with n = 1000000, the times I am getting with this implementation is 0.016s for the array and 0.318 for the dicts.  Is there a faster way to do this for the dictionary?</p>
</div>
<div class="post-text" itemprop="text">
<p>Yup. <a href="https://docs.python.org/3/library/stdtypes.html#dict.fromkeys" rel="nofollow noreferrer"><code>dict.fromkeys</code> is designed for this exact use case</a>. Your example <code>dicts</code> could be made directly with:</p>
<pre><code>dicts = dict.fromkeys(range(n + 1), True)
</code></pre>
<p>Slightly slower, but more flexible, are <code>dict</code> comprehensions (2.7/3.1+):</p>
<pre><code>dicts = {i: True for i in range(n + 1)}
</code></pre>
<p>That will be a little slower in 3.x, and slower than that in 2.x (because <code>True</code> is a keyword in 3.x and doesn't invoke LEGB lookup, but it's only a normal built-in name in 2.x and therefore has to perform multiple <code>dict</code> lookups under the hood on each use, just in case it's been reassigned). <code>dict.fromkeys</code> will be just as fast in either case, because <code>True</code> is only looked up once.</p>
</div>
<span class="comment-copy"><code>dict.fromkeys(range(n + 1), True)</code></span>
<span class="comment-copy">That takes 0.177 seconds for 1 million keys. You can't get much faster, as hashing and slotting 1 million keys into a hash table takes more time than building an array of 1 million references.</span>
<span class="comment-copy">Ok thanks, this works.  Thanks for the info</span>
<span class="comment-copy">ok, thanks for the explanations</span>
