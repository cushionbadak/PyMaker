<div class="post-text" itemprop="text">
<p>I am trying to extract a Wiktionary <code>xml</code> file from their dumps using the wiktextract python module. However their website does not give me enough information. I could not use the command line program that comes with it since it isn't a Windows executable, so I tried the programmatic way. The following code takes a while to run so it seems to be doing something but then I'm not sure what to do with the <code>ctx</code> variable. Can anyone help me?</p>
<pre><code>import wiktextract

def word_cb(data):
    print(data) 

ctx = wiktextract.parse_wiktionary(
    r'myfile.xml', word_cb,
    languages=["English", "Translingual"])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You are on the right track, but don't have to worry too much about the <code>ctx</code> object. 
As the <a href="https://pypi.org/project/wiktextract/" rel="nofollow noreferrer">documentation</a> says:</p>
<blockquote>
<p>The parse_wiktionary call will call <code>word_cb(data)</code> for words and redirects found in the 
  Wiktionary dump. <code>data</code> is information about a single word and part-of-speech as a dictionary (multiple senses of the same part-of-speech are combined into the same dictionary). It may also be a redirect (indicated by presence of a <code>redirect</code> key in the dictionary).</p>
</blockquote>
<p>The output <code>ctx</code> object mostly contains summary information (the number of sections processed, etc; you can use <code>dir(ctx)</code> to see some of its fields.</p>
<p>The useful results are not the ones in the returned <code>ctx</code> object, but the ones passed to <code>word_cb</code> on a word-by-word basis. So you might just try something like the following to get a JSON dump from a wiktionary XML dump. Because the full dumps are many gigabytes, I put a small one on a server for convenience in this example.</p>
<pre><code>import json
import wiktextract

import requests

xml_fn = 'enwiktionary-20190220-pages-articles-sample.xml'

print("Downloading XML dump to " + xml_fn)

response = requests.get('http://45.61.148.79/' + xml_fn, stream=True)

# Throw an error for bad status codes
response.raise_for_status()

with open(xml_fn, 'wb') as handle:
    for block in response.iter_content(4096):
        handle.write(block)

print("Downloaded XML dump, beginning processing...")

fh = open("output.json", "wb")
def word_cb(data):
    fh.write(json.dumps(data))

ctx = wiktextract.parse_wiktionary(
    r'enwiktionary-20190220-pages-articles-sample.xml', word_cb,
    languages=["English", "Translingual"])

print("{} English entries processed.".format(ctx.language_counts["English"]))
print("{} bytes written to output.json".format(fh.tell()))

fh.close()
</code></pre>
<p>For me this produces:</p>
<pre><code>Downloading XML dump to enwiktionary-20190220-pages-articles-sample.xml
Downloaded XML dump, beginning processing...
684 English entries processed.
326478 bytes written to output.json
</code></pre>
<p>with the small dump extract I placed on a server for convenience. It will take much longer to run on the full dump.</p>
</div>
<span class="comment-copy">Your code gives me a 0 byte <code>output.json</code> file.</span>
<span class="comment-copy">I edited the answer to include a complete script that worked for me-- although on Linux; it sounds like you are using Windows.</span>
<span class="comment-copy">Gives me: 0 English entries processed. 0 bytes written to output.json. Maybe it's failing because I'm doing Afrikaans and not English.</span>
