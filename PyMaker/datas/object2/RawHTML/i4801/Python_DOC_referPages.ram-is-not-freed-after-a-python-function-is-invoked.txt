<div class="post-text" itemprop="text">
<p>I'm using an in-house Python library for scientific computing. I need to consecutively copy an object, modify it, and then delete it. The object is huge which causes my machine to run out of memory after a few cycles.</p>
<p>The first problem is that I use python's <code>del</code> to delete the object, which apparently only dereferences the object, rather than freeing up RAM.</p>
<p>The second problem is that even when I encapsulate the whole process in a function, after the function is invoked, the RAM is still not freed up. Here's a code snippet to better explain the issue.</p>
<pre><code>ws = op.core.Workspace()
net = op.network.Cubic(shape=[100,100,100], spacing=1e-6)
proj = net.project

def f():
    for i in range(5):
        clone = ws.copy_project(proj)
        result = do_something_with(clone)
        del clone

f()
gc.collect()

&gt;&gt;&gt; ws
{'sim_01': [&lt;openpnm.network.Cubic object at 0x7fed1c417780&gt;],
 'sim_02': [&lt;openpnm.network.Cubic object at 0x7fed1c417888&gt;],
 'sim_03': [&lt;openpnm.network.Cubic object at 0x7fed1c417938&gt;],
 'sim_04': [&lt;openpnm.network.Cubic object at 0x7fed1c417990&gt;],
 'sim_05': [&lt;openpnm.network.Cubic object at 0x7fed1c4179e8&gt;],
 'sim_06': [&lt;openpnm.network.Cubic object at 0x7fed1c417a40&gt;]}
</code></pre>
<p>My question is how do I completely delete a Python object?</p>
<p>Thanks!</p>
<p>PS. In the code snippet, each time <code>ws.copy_project</code> is called, a copy of <code>proj</code> is stored in <code>ws</code> dictionary.</p>
</div>
<div class="post-text" itemprop="text">
<p>There are some really smart python people on here.  They may be able to tell you better ways to keep your memory clear, but I have used leaky libraries before, and found one (so-far) foolproof way to guarantee that your memory gets cleared after use: execute the memory hog in another process.</p>
<p>To do this, you'd need to arrange for an easy way to make your long calculation be executable separately.  I have done this by adding special flags to my existing python script that tells it just to run that function; you may find it easier to put that function in a separate .py file, e.g.:</p>
<h3>do_something_with.py</h3>
<pre><code>import sys
def do_something_with(i)
    # Your example is still too vague.  Clearly, something differentiates
    # each do_something_with, otherwise you're just taking the
    # same inputs 5 times over.
    # Whatever the difference is, pass it in as an argument to the function

    ws = op.core.Workspace()
    net = op.network.Cubic(shape=[100,100,100], spacing=1e-6)
    proj = net.project

    # You may not even need to clone anymore?
    clone = ws.copy_project(proj)
    result = do_something_with(clone)

# Whatever arg(s) you need to get to the function, just pass it in on the command line
if __name__ == "__main__":
    sys.exit(do_something_with(sys.args[1:]))
</code></pre>
<p>You can do this using any of the python tools that handle subprocesses.  In python 3.5+, the recommended way to do this is <a href="https://docs.python.org/3/library/subprocess.html#subprocess.run" rel="nofollow noreferrer">subprocess.run</a>.  You could change your bigger function to something like this:</p>
<pre><code>import subprocess

invoke_do_something(i):
    completed_args = subprocess.run(["python", "do_something_with.py", str(i)], check=False)
    return completed_args.returncode

results = map(invoke_do_something, range(5))
</code></pre>
<p>You'll obviously need to tailor this to fit your own situation, but by running in a subprocess, you're guaranteed to not have to worry about the memory getting cleaned up.  As an added bonus, you could potentially use multiprocess.Pool.map to use multiple processors at one time.  (I deliberately coded this to use map to make such a transition simple.  You could still use your for loop if you prefer, and then you don't need the <code>invoke...</code> function.)  Multiprocessing could speed up your processing, but since you're already worried about memory, is almost certainly a bad idea - with multiple processes of the big memory hog, your system itself will likely quickly run out of memory and kill your process.</p>
<p>Your example is fairly vague, so I've written this at a high level.  I can answer some questions if you need.</p>
</div>
<span class="comment-copy">I could use some clarification on your code.  You're saying that <code>proj</code> is big and causing memory issues, right?  But the loop you show in <code>f</code> simply has you adding ten copies of <code>proj</code> into a list.  Do you have something that acts on the data and can give you a smaller result, or that can store the big data in a file?  Given either of those, I can come up with a solution.  Just given "this is big, and I want ten of them," I can't help you.  (While simplified code is great to get us going, this seems to be simplified to the point of being full of errors.)</span>
<span class="comment-copy">@ScottMermelstein Thanks for your reply. I edited the question. Just to clarify, the problem is that even though I'm deleting <code>clone</code> after each iteration, RAM doesn't get freed.</span>
