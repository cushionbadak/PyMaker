<div class="post-text" itemprop="text">
<p>Let's assume a very simple data structure. In the below example, IDs are unique. "date" and "id" are strings, and "amount" is an integer.</p>
<pre><code>data = [[date1, id1, amount1], [date2, id2, amount2], etc.]
</code></pre>
<p>If <code>date1 == date2</code> and <code>id1 == id2</code>, I'd like to merge the two entries into one and basically add up amount1 and amount2 so that data becomes:</p>
<pre><code>data = [[date1, id1, amount1 + amount2], etc.]
</code></pre>
<p>There are many duplicates.</p>
<p>As data is very big (over 100,000 entries), I'd like to do this as efficiently as possible. What I did is a created a new "common" field that is basically date + id combined into one string with metadata allowing me to split it later (<code>date + id + "_" + str(len(date)</code>).</p>
<p>In terms of complexity, I have four loops:</p>
<ol>
<li>Parse and load data from external source (it doesn't come in lists) | O(n)</li>
<li>Loop over data and create and store "common" string (date + id + metadata) - I call this "prepared data" where "common" is my encoded field | O(n)</li>
<li>Use the Counter() object to dedupe "prepared data" | O(n)</li>
<li>Decode "common" | O(n)</li>
</ol>
<p>I don't care about memory here, I only care about speed. I could make a nested loop and avoid steps 2, 3 and 4 but that would be a time-complexity disaster (O(nÂ²)).</p>
<p>What is the fastest way to do this?</p>
</div>
<div class="post-text" itemprop="text">
<p>Using <a href="https://pandas.pydata.org/" rel="nofollow noreferrer"><code>pandas</code></a> makes this really easy:</p>
<pre><code>import pandas as pd
df = pd.DataFrame(data, columns=['date', 'id', 'amount'])
df.groupby(['date','id']).sum().reset_index()
</code></pre>
<p>For more control you can use <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.agg.html" rel="nofollow noreferrer"><code>agg</code></a> instead of <code>sum()</code>:</p>
<pre><code>df.groupby(['date','id']).agg({'amount':'sum'})
</code></pre>
<p>Depending on what you are doing with the data, it may be easier/faster to go this way just because so much of pandas is built on compiled C extensions and optimized routines that make it super easy to transform and manipulate.</p>
</div>
<div class="post-text" itemprop="text">
<p>Consider a <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>defaultdict</code></a> for aggregating data by a unique key:</p>
<p><strong>Given</strong></p>
<p>Some random data</p>
<pre><code>import random
import collections as ct


random.seed(123)

# Random data
dates = ["2018-04-24", "2018-05-04", "2018-07-06"]
ids = "A B C D".split()
amounts = lambda: random.randrange(1, 100)

ch = random.choice
data = [[ch(dates), ch(ids), amounts()] for _ in range(10)]
data
</code></pre>
<p>Output</p>
<pre><code>[['2018-04-24', 'C', 12],
 ['2018-05-04', 'C', 14],
 ['2018-04-24', 'D', 69],
 ['2018-07-06', 'C', 44],
 ['2018-04-24', 'B', 18],
 ['2018-05-04', 'C', 90],
 ['2018-04-24', 'B', 1],
 ['2018-05-04', 'A', 77],
 ['2018-05-04', 'A', 1],
 ['2018-05-04', 'D', 14]]
</code></pre>
<p><strong>Code</strong></p>
<pre><code>dd = ct.defaultdict(int)
for date, id_, amt in data:
    key = "{}{}_{}".format(date, id_, len(date))
    dd[key] += amt
dd
</code></pre>
<p>Output</p>
<pre><code>defaultdict(int,
            {'2018-04-24B_10': 19,
             '2018-04-24C_10': 12,
             '2018-04-24D_10': 69,
             '2018-05-04A_10': 78,
             '2018-05-04C_10': 104,
             '2018-05-04D_10': 14,
             '2018-07-06C_10': 44})
</code></pre>
<hr/>
<p><strong>Details</strong></p>
<p>A <code>defaultdict</code> is a dictionary that calls a <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict.default_factory" rel="nofollow noreferrer">default factory</a> (a specified function) for any missing keys.  It this case, every <code>date</code> + <code>id</code> combination is uniquely added to the dict.  The <code>amounts</code> are added to values if existing keys are found.  Otherwise an integer (<code>0</code>) initializes a new entry to the dict.  </p>
<p>For illustration, you can visualize the aggregated values using a <code>list</code> as the default factory.</p>
<pre><code>dd = ct.defaultdict(list)
for date, id_, val in data:
    key = "{}{}_{}".format(date, id_, len(date))
    dd[key].append(val)
dd
</code></pre>
<p>Output</p>
<pre><code>defaultdict(list,
            {'2018-04-24B_10': [18, 1],
             '2018-04-24C_10': [12],
             '2018-04-24D_10': [69],
             '2018-05-04A_10': [77, 1],
             '2018-05-04C_10': [14, 90],
             '2018-05-04D_10': [14],
             '2018-07-06C_10': [44]})
</code></pre>
<p>We see three occurrences of duplicate keys where the values were appropriately summed.  Regarding efficiency, notice:</p>
<ol>
<li>keys are made with <code>format()</code>, which should be a bit better the string concatenation and calling <code>str()</code></li>
<li>every key and value is computed in the same iteration</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>You could import the data into a structure that prevents duplicates and than convert it to a list.</p>
<pre><code>data = {
    date1: {
        id1: amount1,
        id2: amount2,
    },
    date2: {
        id3: amount3,
        id4: amount4,
        ....
}
</code></pre>
<p>The program's skeleton:</p>
<pre><code>ddata = collections.defaultdict(dict)
for date, id, amount in DATASOURCE:
    ddata[date][id] = amount
data = [[d, i, a] for d, subd in ddata.items() for i, a in subd.items()]
</code></pre>
</div>
