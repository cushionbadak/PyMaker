<div class="post-text" itemprop="text">
<p>I need to write some files that take inputs from two different and very large lists. The following python code works, but due to the size of the lists and other variables involved takes a long time to run:</p>
<pre><code>for n,seq in enumerate(ugFA):    
    with open("locusFASTAs/"+loci[n], 'a') as outFA:
        SeqIO.write(ugSeqs[seq.id], outFA, 'fasta')
        for m,i in enumerate(wantedContigs):
            if f[m].id==seq.id:
                SeqIO.write(MergeSeqs[i], outFA, 'fasta')
            else: continue
</code></pre>
<p>Data structures in the above code:</p>
<ul>
<li>ugFA is a list</li>
<li>loci is a list</li>
<li>ugSeqs is a dictionary</li>
<li>wantedContigs is a list</li>
<li>f is a list</li>
<li>MergeSeqs is a dictionary</li>
</ul>
<p>I have attempted to parallelise the code using <code>multiprocessing</code>. The following code <strong>does the job</strong>, but <em>(i)</em> doesn't run any quicker, <em>(ii)</em> doesn't seem to use more than 100% CPU, and <em>(iii)</em> spits out the error message shown below when finished, even though it completes the tasks in the loop:</p>
<pre><code>def extractContigs(ugFA, loci, ugSeqs, wantedContigs, f, MergeSeqs):
    from Bio import SeqIO
    for n,seq in enumerate(ugFA):    
        with open("locusFASTAs/"+loci[n], 'a') as outFA:
            SeqIO.write(ugSeqs[seq.id], outFA, 'fasta')
            for m,i in enumerate(wantedContigs):
                if f[m].id==seq.id:
                    SeqIO.write(MergeSeqs[i], outFA, 'fasta')
                else: continue

pool = multiprocessing.Pool(processes=p)
r = pool.map(extractContigs(ugFA, loci, ugSeqs, wantedContigs, MergeSeqs))

Traceback (most recent call last):
  File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: map() takes at least 3 arguments (2 given)
</code></pre>
<p>Is there something I have done wrong in the construction of my code? I can I properly construct it to fully utilise the expediency of the <code>multiprocessing</code> module?</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem is</p>
<pre><code>r = pool.map(extractContigs(ugFA, loci, ugSeqs, wantedContigs, MergeSeqs))
</code></pre>
<p>is calling the function <code>extractContigs</code> (in the main thread, hence the 100% CPU) and then passing the results as an argument to <code>pool.map</code>.  <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map" rel="nofollow noreferrer">The correct signature</a> is</p>
<pre><code>pool.map(func, iterable)
</code></pre>
<p>For this to work in your case, you would need to rewrite the <code>extractContigs</code> function to take only one argument.  From the looks of it, you'd need to significantly refactor your code to do this.  Writing to the same file simultaneously might be a concern.</p>
<p>Your previous version could be appropriately modified:</p>
<pre><code>def writeLocus(n):
    seq = ugFa[n]  
    with open("locusFASTAs/"+loci[n], 'a') as outFA:
        SeqIO.write(ugSeqs[seq.id], outFA, 'fasta')
        for m,i in enumerate(wantedContigs):
            if f[m].id==seq.id:
                SeqIO.write(MergeSeqs[i], outFA, 'fasta')
            else: continue

pool.map(writeLocus, range(len(ugFa)))
</code></pre>
<p>Please make sure to verify that things aren't getting garbled in the output due to the parallel writing identical files.  Ideally, it would be best to have each worker write to its own file(s), and merge afterward.</p>
</div>
