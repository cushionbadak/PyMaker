<div class="post-text" itemprop="text">
<p>I need to generate a very large text file. Each line has a simple format:</p>
<pre><code>Seq_num&lt;SPACE&gt;num_val
12343234 759
</code></pre>
<p>Let's assume I am going to generate a file with 100million lines.
I tried 2 approaches and surprisingly they are giving very different time performance. </p>
<ol>
<li><p>For loop over 100m. In each loop I make short string of <code>seq_num&lt;SPACE&gt;num_val</code>, and then I write that to a file. 
This approach takes <strong>a lot</strong> of time.</p>
<pre><code>## APPROACH 1  
for seq_id in seq_ids:
    num_val=rand()
    line=seq_id+' '+num_val
    data_file.write(line)
</code></pre></li>
<li><p>For loop over 100m. In each loop I make short string of <code>seq_num&lt;SPACE&gt;num_val</code>, and then I append this to a list.
When loop finishes, I iterate over list items and write each item to a file.
This approach takes <strong>far less</strong> time. </p>
<pre><code>## APPROACH 2  
data_lines=list()
for seq_id in seq_ids:
    num_val=rand()
    l=seq_id+' '+num_val
    data_lines.append(l)
for line in data_lines:
    data_file.write(line)
</code></pre></li>
</ol>
<p>Note that:</p>
<ul>
<li>Approach 2 has 2 loops instead of 1 loop.</li>
<li>I write to file in loop for both approach 1 and approach 2. So this step must be same for both.</li>
</ul>
<p>So approach 1 must take less time. Any hints what I am missing?</p>
</div>
<div class="post-text" itemprop="text">
<p>Considering APPROACH 2, I think I can assume you have the data for all the lines (or at least in big chunks) <em>before</em> you need to write it to the file.</p>
<p>The other answers are great and it was really formative to read them, but both focused on optimizing the file writing or avoiding the first for loop replacing with list comprehension (that is known to be faster).</p>
<p>They missed the fact that you are iterating in a for loop to write the file, which is not really necessary.</p>
<p>Instead of doing that, by increasing the use of memory (in this case is affordable, since a 100 million line file would be about 600 MB), you can create just one string in a more efficient way by using the formatting or join features of python str, and then write the big string to the file. Also relying on list comprehension to get the data to be formatted.</p>
<p>With loop1 and loop2 of @Tombart 's answer, I get  <code>elapsed time 0:00:01.028567</code> and <code>elapsed time 0:00:01.017042</code>, respectively.</p>
<p>While with this code:</p>
<pre><code>start = datetime.now()

data_file = open('file.txt', 'w')
data_lines = ( '%i %f\n'%(seq_id, random.random()) 
                            for seq_id in xrange(0, 1000000) )
contents = ''.join(data_lines)
data_file.write(contents) 

end = datetime.now()
print("elapsed time %s" % (end - start))
</code></pre>
<p>I get <code>elapsed time 0:00:00.722788</code> which is about a 25% faster.</p>
<p>Notice that <code>data_lines</code> is a generator expression, so the list is not really stored in memory, and the lines are generated and consumed on demand by the <code>join</code> method. This implies the only variable that is significantly occupying memory is <code>contents</code>. This also reduces slightly the running times.</p>
<p>If the text is to large to do all the work in memory, you can always separate in chunks. That is, formatting the string and writing to the file every million lines or so.</p>
<p><strong>Conclusions:</strong> </p>
<ul>
<li>Always try to do list comprehension instead of plain for loops (list comprehension is even faster than <code>filter</code> for filtering lists <a href="https://stackoverflow.com/questions/3013449/list-filtering-list-comprehension-vs-lambda-filter">see here</a>).</li>
<li>If possible by memory or implementation constraints, try to create and encode string contents at once, using the <code>format</code> or  <code>join</code> functions.</li>
<li>If possible and the code remains readable, use built-in functions to avoid <code>for</code> loops. For example, using <code>extend</code> function of a list instead of iterating and using <code>append</code>. In fact, both previous points can be seen as examples of this remark.</li>
</ul>
<p><strong>Remark.</strong>
Although this answer can be considered useful on its own, it does not completely address the question, which is why the <em>two loops</em> option in the question seems to run faster in some environments. For that, perhaps the @Aiken Drum's answer below can bring some light on that matter. </p>
</div>
<div class="post-text" itemprop="text">
<p><strong>A lot</strong> and <strong>far less</strong> are technically very vague terms :) Basically if you can't measure it, you can't improve it.</p>
<p>For simplicity let's have a simple benchmark, <code>loop1.py</code>:</p>
<pre><code>import random
from datetime import datetime

start = datetime.now()
data_file = open('file.txt', 'w')
for seq_id in range(0, 1000000):
        num_val=random.random()
        line="%i %f\n" % (seq_id, num_val)
        data_file.write(line)

end = datetime.now()
print("elapsed time %s" % (end - start))
</code></pre>
<p><code>loop2.py</code> with 2 for loops:</p>
<pre><code>import random
from datetime import datetime

start = datetime.now()
data_file = open('file.txt', 'w')
data_lines=list()
for seq_id in range(0, 1000000):
    num_val=random.random()
    line="%i %f\n" % (seq_id, num_val)
    data_lines.append(line)
for line in data_lines:
    data_file.write(line)

end = datetime.now()
print("elapsed time %s" % (end - start))
</code></pre>
<p>When I run these two scripts on my computers (with SSD drive) I'm getting something like:</p>
<pre><code>$ python3 loop1.py 
elapsed time 0:00:00.684282
$ python3 loop2.py 
elapsed time 0:00:00.766182
</code></pre>
<p>Each measurement might be slightly different, but as would intuition suggest, the second one is slightly slower.</p>
<p>If we want to optimize writing time, we need to check <a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow noreferrer">the manual how Python implements writing into files</a>. For text files the <code>open()</code> function should use <a href="https://docs.python.org/2/library/io.html#io.BufferedWriter" rel="nofollow noreferrer"><code>BufferedWriter</code></a>.The <code>open</code> function accepts 3rd arguments that is the buffer size. Here's the interesting part:</p>
<blockquote>
<p>Pass 0 to switch buffering off (only allowed in binary mode), 1 to
  select line buffering (only usable in text mode), and an integer &gt; 1
  to indicate the size in bytes of a fixed-size chunk buffer. When no
  buffering argument is given, the default buffering policy works as
  follows:</p>
<p>Binary files are buffered in fixed-size chunks; the size of the buffer
  is chosen using a heuristic trying to determine the underlying
  device’s “block size” and falling back on io.DEFAULT_BUFFER_SIZE. On
  many systems, the buffer will typically be 4096 or 8192 bytes long.</p>
</blockquote>
<p>So, we can modify the <code>loop1.py</code> and use line buffering:</p>
<pre><code>data_file = open('file.txt', 'w', 1)
</code></pre>
<p>this turns out to be very slow:</p>
<pre><code>$ python3 loop3.py 
elapsed time 0:00:02.470757
</code></pre>
<p>In order to optimize writing time, we can adjust the buffer size to our needs. First we check the line size in bytes: <code>len(line.encode('utf-8'))</code>, that gives me <code>11</code> bytes.</p>
<p>After updating the buffer size to our expected line size in bytes:</p>
<pre><code>data_file = open('file.txt', 'w', 11)
</code></pre>
<p>I'm getting quite fast writes:</p>
<pre><code>elapsed time 0:00:00.669622
</code></pre>
<p>Based on the details you've provided it's hard to estimate what's going on. Maybe the heuristic for estimating block size doesn't work well on your computer. Anyway if you're writing fixed line length, it's easy to optimize the buffer size. You could further optimize writing to files by leveraging <a href="https://docs.python.org/2/library/io.html#io.IOBase.flush" rel="nofollow noreferrer"><code>flush()</code></a>.</p>
<p><strong>Conclusion</strong>: Generally for faster writes into a file you should try to write a bulk of data that corresponds to a block size on your file system - which is exactly what is the Python method <code>open('file.txt', 'w')</code> is trying to do. In most cases you're safe with the defaults, differences in microbenchmarks are insignificant.</p>
<p>You're allocating large number of string objects, that needs to be collected by the GC. As suggested by @kevmo314, in order to perform a fair comparison you should disable the GC for <code>loop1.py</code>:</p>
<pre><code>gc.disable()
</code></pre>
<p>As the GC might try to remove string objects while iterating over the loop (you're not keeping any reference). While the seconds approach keeps references to all string objects and GC collects them at the end.</p>
</div>
<div class="post-text" itemprop="text">
<p>Below is an extension to the elegant answer by @Tombart and a few further observations.</p>
<p>With one goal in mind: optimizing the process of reading data from loop(s) and then writing it into a file, let's begin:</p>
<p>I will use the <code>with</code> statement to open/close the file <code>test.txt</code> in all cases. This statement automatically closes the file when the code block within it is executed.</p>
<p>Another important point to consider is the way Python processes text files based on Operating system. From the <a href="https://docs.python.org/3/library/functions.html#open" rel="nofollow noreferrer">docs</a>: </p>
<blockquote>
<p><strong>Note</strong>: Python doesn’t depend on the underlying operating system’s notion of text files; all the processing is done by Python itself, and is therefore platform-independent. </p>
</blockquote>
<p>This means that these results may only slightly vary when executed on a Linux/Mac or Windows OS. 
The slight variation may result from other processes using the same file at the same time or multiple IO processes happening on the file during the script execution, general CPU processing speed among others. </p>
<p>I present 3 cases with execution times for each and finally find a way to further optimize the most efficient and quick case:</p>
<p><strong>First case: Loop over range(1,1000000) and write to file</strong></p>
<pre><code>import time
import random

start_time = time.time()
with open('test.txt' ,'w') as f:
    for seq_id in range(1,1000000):
        num_val = random.random()    
        line = "%i %f\n" %(seq_id, num_val)
        f.write(line)

print('Execution time: %s seconds' % (time.time() - start_time)) 

#Execution time: 2.6448447704315186 seconds
</code></pre>
<p><strong>Note</strong>: In the two <code>list</code> scenarios below, I have initialized an empty list <code>data_lines</code> like:<code>[]</code> instead of using <code>list()</code>. The reason is: <code>[]</code> is about 3 times faster than <code>list()</code>. Here's an explanation for this behavior: <a href="https://stackoverflow.com/questions/30216000/why-is-faster-than-list">Why is [] faster than list()?</a>. The main crux of the discussion is: While <code>[]</code> is created as <em><a href="https://docs.python.org/3.6/glossary.html#term-bytecode" rel="nofollow noreferrer">bytecode</a></em> objects and is a <em>single instruction</em>, <code>list()</code> is a separate Python object that also needs name resolution, global function calls and the stack has to be involved to push arguments.</p>
<p>Using the timeit() function in the timeit module, here's the comparison:</p>
<pre><code>import timeit                 import timeit                     
timeit.timeit("[]")           timeit.timeit("list()")
#0.030497061136874608         #0.12418613287039193
</code></pre>
<p><strong>Second Case: Loop over range(1,1000000), append values to an empty list and then write to file</strong></p>
<pre><code>import time
import random

start_time = time.time()
data_lines = []
with open('test.txt' ,'w') as f:
    for seq_id in range(1,1000000):
        num_val = random.random()    
        line = "%i %f\n" %(seq_id, num_val)
        data_lines.append(line)
    for line in data_lines:
        f.write(line)

print('Execution time: %s seconds' % (time.time() - start_time)) 

#Execution time: 2.6988046169281006 seconds
</code></pre>
<p><strong>Third Case: Loop over a list comprehension and write to file</strong></p>
<p>With Python's powerful and compact list comprehensions, it is possible to optimize the process further:</p>
<pre><code>import time
import random

start_time = time.time()

with open('test.txt' ,'w') as f: 
        data_lines = ["%i %f\n" %(seq_id, random.random()) for seq_id in range(1,1000000)]
        for line in data_lines:
            f.write(line)

print('Execution time: %s seconds' % (time.time() - start_time))

#Execution time: 2.464804172515869 seconds
</code></pre>
<p>On multiple iterations, I've always received a lower execution time value in this case as compared to the previous two cases. </p>
<pre><code>#Iteration 2: Execution time: 2.496004581451416 seconds
</code></pre>
<p>Now the question arises: why are list comprehensions( and in general lists ) faster over sequential <code>for</code> loops?</p>
<p>An interesting way to analyze what happens when sequential <code>for</code> loops execute and when <code>list</code>s execute, is to <code>dis</code>assemble the <code>code</code> object generated by each and examine the contents. Here is an example of a list comprehension code object disassembled:</p>
<pre><code>#disassemble a list code object
import dis
l = "[x for x in range(10)]"
code_obj = compile(l, '&lt;list&gt;', 'exec')
print(code_obj)  #&lt;code object &lt;module&gt; at 0x000000058DA45030, file "&lt;list&gt;", line 1&gt;
dis.dis(code_obj)

 #Output:
    &lt;code object &lt;module&gt; at 0x000000058D5D4C90, file "&lt;list&gt;", line 1&gt;
  1           0 LOAD_CONST               0 (&lt;code object &lt;listcomp&gt; at 0x000000058D5D4ED0, file "&lt;list&gt;", line 1&gt;)
          2 LOAD_CONST               1 ('&lt;listcomp&gt;')
          4 MAKE_FUNCTION            0
          6 LOAD_NAME                0 (range)
          8 LOAD_CONST               2 (10)
         10 CALL_FUNCTION            1
         12 GET_ITER
         14 CALL_FUNCTION            1
         16 POP_TOP
         18 LOAD_CONST               3 (None)
         20 RETURN_VALUE
</code></pre>
<p>Here's an example of a <code>for</code> loop code object disassembled in a function <code>test</code>:</p>
<pre><code>#disassemble a function code object containing a `for` loop
import dis
test_list = []
def test():
    for x in range(1,10):
        test_list.append(x)


code_obj = test.__code__ #get the code object &lt;code object test at 0x000000058DA45420, file "&lt;ipython-input-19-55b41d63256f&gt;", line 4&gt;
dis.dis(code_obj)
#Output:
       0 SETUP_LOOP              28 (to 30)
              2 LOAD_GLOBAL              0 (range)
              4 LOAD_CONST               1 (1)
              6 LOAD_CONST               2 (10)
              8 CALL_FUNCTION            2
             10 GET_ITER
        &gt;&gt;   12 FOR_ITER                14 (to 28)
             14 STORE_FAST               0 (x)

  6          16 LOAD_GLOBAL              1 (test_list)
             18 LOAD_ATTR                2 (append)
             20 LOAD_FAST                0 (x)
             22 CALL_FUNCTION            1
             24 POP_TOP
             26 JUMP_ABSOLUTE           12
        &gt;&gt;   28 POP_BLOCK
        &gt;&gt;   30 LOAD_CONST               0 (None)
             32 RETURN_VALUE
</code></pre>
<p>The above comparison shows more "activity", if I may, in the case of a <code>for</code> loop. For instance, notice the additional function calls to the <code>append()</code> method in the<code>for</code> loop function call. To know more about the parameters in the <code>dis</code> call output, here's the official <a href="https://docs.python.org/3.6/library/dis.html" rel="nofollow noreferrer">documentation</a>. </p>
<p>Finally, as suggested before, I also tested with <code>file.flush()</code> and the execution time is in excess of <code>11 seconds</code>. I add f.flush() before the <code>file.write()</code> statement:</p>
<pre><code>import os
.
.
.
for line in data_lines:
        f.flush()                #flushes internal buffer and copies data to OS buffer
        os.fsync(f.fileno())     #the os buffer refers to the file-descriptor(fd=f.fileno()) to write values to disk
        f.write(line)
</code></pre>
<p>The longer execution time using <code>flush()</code> can be attributed to the way data is processed. This function copies the data from the program buffer to the  operating system buffer. This means that if a file(say <code>test.txt</code> in this case), is being used by multiple processes and large chunks of data is being added to the file, you will not have to wait for the whole data to be written to the file and the information will be readily available. But to make sure that the buffer data is actually written to disk, you also need to add: <code>os.fsync(f.fileno())</code>. Now, adding <code>os.fsync()</code> increases the execution time atleast <strong>10 times</strong>(I didn't sit through the whole time!) as it involves copying data from buffer to hard disk memory. For more details, go <a href="https://stackoverflow.com/questions/7127075/what-exactly-the-pythons-file-flush-is-doing">here</a>.</p>
<p><strong>Further Optimization</strong>: It is possible to further optimize the process. There are libraries available that support <code>multithreading</code>, create <code>Process Pools</code> and perform <code>asynchronous</code> tasks . This is particularly useful when a function performs a CPU-intensive task &amp; writes to file at the same time. For instance, a combination of <code>threading</code> and <code>list comprehensions</code> gives the <strong>fastest</strong> possible result(s):</p>
<pre><code>import time
import random
import threading

start_time = time.time()

def get_seq():
    data_lines = ["%i %f\n" %(seq_id, random.random()) for seq_id in range(1,1000000)]
    with open('test.txt' ,'w') as f: 
        for line in data_lines:
            f.write(line)

set_thread = threading.Thread(target=get_seq)
set_thread.start()

print('Execution time: %s seconds' % (time.time() - start_time))

#Execution time: 0.015599966049194336 seconds
</code></pre>
<p><strong>Conclusion</strong>: List comprehensions offer better performance in comparison to sequential <code>for</code> loops and <code>list</code> <code>append</code>s. The primary reason behind this is <strong><em>single instruction bytecode execution</em></strong> in the case of list comprehensions which is faster than the <strong><em>sequential iterative calls to append items to list</em></strong> as in the case of <code>for</code> loops. There is scope for further optimization using <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer">asyncio</a>, <a href="https://docs.python.org/3.4/library/threading.html" rel="nofollow noreferrer">threading</a> &amp; <a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor" rel="nofollow noreferrer">ProcessPoolExecutor()</a>. You could also use combination of these to achieve faster results. Using <code>file.flush()</code> depends upon your requirement. You may add this function when you need asynchronous access to data when a file is being used by multiple processes. Although, this process may take a long time if you are also writing the data from the program's buffer memory to the OS's disk memory using <code>os.fsync(f.fileno())</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>The other answers here give good advice, but I think the actual problem may be different:</p>
<p><strong>I think the real issue here is the generational garbage collector is running more often with the single-loop code.</strong> The generational GC exists alongside the refcounting system, to periodically check for orphaned objects with nonzero self/cyclic-references.</p>
<p>The reason why this would be happening is probably complex, but my best guess is this:</p>
<ul>
<li><p>With the single-loop code, each iteration is implicitly allocating a new string, then sending it off to be written to a file, after which it is abandoned, its refcount goes to zero, and thus it is deallocated. I believe cumulative alloc/dealloc traffic is part of the heuristic that decides when GC is done, so this behavior would be sufficient to set that flag every so many iterations. The flag, in turn, is probably checked any time your thread is going to be forced to wait for something anyway, because that's an excellent opportunity to fill wasted time with a garbage collection. Synchronous file writes are exactly that kind of opportunity.</p></li>
<li><p>With the dual-loop code, you are creating a string and adding it to the list, over and over, nothing else.  Allocate, allocate, allocate.  If you run out of memory, you're going to trigger a GC, but otherwise I doubt you're doing anything that's set up to check for opportunities to GC. There's nothing there to cause a thread wait, a context switch, etc.  The second loop calls into the synchronous file I/O, where I think opportunistic GC can occur, but only the first call might trigger one, because there is no further memory allocation/deallocation at that point.  Only after the entire list is written is the list itself deallocated, all at once.</p></li>
</ul>
<p>I'm not in a position to test the theory myself right now, unfortunately, but you could try disabling the generational garbage collection and see whether or not it changes the execution speed of the single-loop version:</p>
<pre><code>import gc
gc.disable()
</code></pre>
<p>I think that's all you'd need to do to confirm or disprove my theory.</p>
</div>
<div class="post-text" itemprop="text">
<p>It could reduce time cost around half by changing the follows</p>
<pre><code>for line in data_lines:
    data_file.write(line)
</code></pre>
<p>into:</p>
<pre><code>data_file.write('\n'.join(data_lines))
</code></pre>
<p>Here is my test run range(0, 1000000)</p>
<pre><code>elapsed time 0:00:04.653065
elapsed time 0:00:02.471547

2.471547 / 4.653065 = 53 %
</code></pre>
<p>However if 10 times the above range, there is no much difference.</p>
</div>
<span class="comment-copy">Do you have 2 nested loops in approach 1? Can you provide at least some very simplified code?</span>
<span class="comment-copy">No nested loops. Sequential loops. I added pseudo-codes</span>
<span class="comment-copy">Have you tried disabling the garbage collector with <code>gc.disable()</code>?</span>
<span class="comment-copy">Your two programs differ in when garbage collection is handled. In the former, python will garbage collect periodically as the string is freed immediately, whereas in the latter the garbage collector only runs at the end of the script.</span>
<span class="comment-copy">May I ask why you are writing such a large text file? All answers so far are about 2 orders of magnitudes slower than writing the data directly to binary files... The fastest way is always to avoid TextIO, which is often possible.</span>
<span class="comment-copy">This prints: <code>%i %f %i %f %i %f %i %f</code> to the text file. The <code>%i %f</code> values are not replaced by <code>seq_id</code> and <code>random.random()</code></span>
<span class="comment-copy">Thank you for catching the bug! I corrected the answer. The short times should have made me suspect that something was wrong.</span>
<span class="comment-copy">This is definitely faster with the use of <code>join</code>. One point to notice: <code>xrange</code> is Python 2.7. For Python 3, use <code>range</code>. The <code>contents</code> variable may not be necessary, it works this way too: <code>data_file.write(''.join(data_lines))</code></span>
<span class="comment-copy">I left <code>xrange</code> because python version was not required, and it is better to raise the exception and correct it in python 3 rather than leaving a <code>range</code> in python 2.7. About the need of the variable, you are right, but the code is more readable I think.</span>
<span class="comment-copy">I also noticed that you used a generator function instead of a <code>list comprehension</code>. This also improved the performance. Great answer!</span>
<span class="comment-copy">Your Third approach is incorrect:  you move random calculation out of the loop, which can impact significantly</span>
<span class="comment-copy">This answer started with the goal of optimizing the process of generating large text files. The third case also achieves the same result as the first two cases(it generates a large text file in the format requested) albeit faster. If the <code>random()</code> function is outside the list comprehension but improves performance, isn't that still meeting the goal? In general, <code>for</code> loops are slower than <code>list comprehensions</code> for the reasons explained. You can test this on your own too.</span>
<span class="comment-copy">No,  1. it changes the data generated. Although we don't know what's the OP's rand() function, it is clear that <code>rand</code> means random, and that each id should be paired with new random number.</span>
<span class="comment-copy">Thank you for pointing this out. I noticed that the <code>random()</code> value remains constant after num_val is called in the third case. This is because it is not part of the loop. I am editing the answer now.</span>
<span class="comment-copy">Answer to No.1: I've added <code>random.random()</code> to the list comprehension loop. This will make sure that a random number is generated on every iteration. I've tested this and it still gives better performance than the first two cases.</span>
<span class="comment-copy">After reading the question carefully, I realized this is the correct answer (provided the tests support the theory). Although the "chasing red herrings" phrase is a little impolite :)</span>
<span class="comment-copy">... "thanks for bringing it to my intention" - ah, Freud, you strike again.</span>
<span class="comment-copy">Aiken, please, don't worry, I'm really not offendended at all. I though the little smile at the end of my comment would make that clear. I just highlighted that because I know there are some people here in SO that is rather sensitive.</span>
<span class="comment-copy">@eguaio - Ah, thank you for letting me off of the hook. :)  I have a history of saying things without enough consideration for how they will be heard.  For several years, I have been making an effort to correct this character flaw.  I'm glad to hear I didn't trouble you too much, but it's still a good reminder for me to take care.  Cheers.  :)</span>
<span class="comment-copy">@eguaio - Ah, it happens. I'd be chuffed to get the bounty, I guess, but I'm really not concerned. I'm just a pseudonym next to a picture of a gigantic rubber duck anyway; I don't care too much how large the number under my pseudonym is. I just have fun helping people figure out solutions to their problems. I read the bounty section because that's where the most interesting problems usually are.  :) Most rewarding for me would be having the OP come back and confirm I'd gotten it right, honestly. XD</span>
<span class="comment-copy">This is exactly one of the points of my answer, posted yesterday.</span>
