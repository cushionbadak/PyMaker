<div class="post-text" itemprop="text">
<p>In Python &gt;= 3.3, in order to help troubleshoot Unicode encoding and decoding issues, I would like to be able to examine, from Python code, the actual internal data stored in strings. How do I do that?</p>
<p>There is a str.encode() method, which returns a bytes representation, but in general this is a byte sequence as translated by a particular codec (selected by the "encoding" argument), not the actual raw bytes stored in the str object. </p>
<p>There is a "unicode_internal" encoding option, but it's deprecated, and it's not clear whether, in 3.3, it returns the real internal data (organized how?), or some translation of it.</p>
<p>PEP 393 describes the internal structure of Unicode data, from which it appears that access to this from Python would need to report string kind (1/2/4 byte), representation (ASCII/compact) and also an array of bytes containing the string contents, (whose format is ASCII, UCS1, 2, or 4, I think).</p>
<p>I've not found methods on the str type that offer this access within Python. </p>
<p>Is there some other approach? Perhaps a clever way to use struct? Or a C library that exposes these string internals? </p>
<p>Update 2014-03-13:</p>
<p>Thanks to all who have responded with advice about why one should not want to access a string's internal structure. This is certainly valid advice for a normal Python program. </p>
<p>Nonetheless, my question is: how to do it? </p>
<p>To expand on the rationale: it is in order to troubleshoot encoding-decoding problems, where one function (in some library perhaps) creates and returns a str, and another function (perhaps in some other library) is supposed to do something with that str. </p>
<p>I want to inspect the exact contents of that intermediate str,  (ie: I want to split the problem space in half), and to do so without introducing the further variable of having one or another python function transform that data into some other form (like ASCII with escape sequences). </p>
<p>Amongst other reasons, I want to know the exact internal data in case one of another of the libraries is actually sensitive to the internal data format. Said libraries might well be written in C, have access to that data, and handling it incorrectly.</p>
<p>Also, it is indeed supposed to be the case that a str should be treatable as a sequence of code points with internal internal representation of no concern. But if there is actually a bug in string handling, I don't want to be misled by it, and if there isn't, I'd like the confidence that there isn't. Given the complexity of the string library, zero bugs would be quite an achievement.</p>
<p>So: How might I inspect the string's internal structure?</p>
</div>
<div class="post-text" itemprop="text">
<p>A Unicode string in Python should be considered as a sequence of Unicode code points.  How this is represented internally is completely immaterial to encoding and decoding issues.</p>
<p>You can access the numerical values of the Unicode code points by using the <code>ord()</code> function on the individual characters of the string:</p>
<pre><code>&gt;&gt;&gt; list(map(ord, "abc â‚¬"))
[97, 98, 99, 32, 8364]
</code></pre>
<p>I don't think this is particular helpful for debugging encoding issues (or for anything else), but it might clarify what a Unicode string is conceptually.</p>
</div>
<div class="post-text" itemprop="text">
<p>The internal switch to a more space-efficient storage for unicode values <a href="http://www.python.org/dev/peps/pep-0393/" rel="nofollow">introduced by PEP-393</a> were made for <strong>performance reasons</strong> only.</p>
<p>As such they have zero impact on how encoding from and decoding to unicode <code>str</code> values works in Python code. There is absolutely <em>no point</em> in accessing the internal representation from Python. The character <code>A</code> is either stored as <code>41</code>, <code>4100</code> or <code>41000000</code>, depending on how much space the highest codepoint in the string demands, but it'll still be encoded to <code>41</code> in ASCII, Latin-1 or UTF-8.</p>
<p>Unless you are writing a C extension that has to deal with this internal representation, there is absolutely no need to worry about how Python actually stored the data.</p>
<p>To debug encoding or decoding issues, I'd use the <a href="http://docs.python.org/3/library/functions.html#ascii" rel="nofollow"><code>ascii()</code> function</a> to represent a string using only ASCII codepoints and Python string literal escapes, or you can use the <a href="http://docs.python.org/3/library/functions.html#ord" rel="nofollow"><code>ord()</code> function</a> for turning individual characters into an integer for each codepoint.</p>
<p>For bytes values, the <a href="http://docs.python.org/3/library/binascii.html#binascii.hexlify" rel="nofollow"><code>binascii.hexlify()</code> function</a> also comes in handy to quickly turn a series of bytes into their hex representations.</p>
</div>
<span class="comment-copy">How would the internal representation help you troubleshoot encoding or decoding issues? I'd stick with <code>ascii()</code> when trying to determine the contents.</span>
<span class="comment-copy">Unless you are writing C extensions that need to deal with the <code>str</code> type internals, there is absolutely no need to deal with the internal C structures. That's like trying to handle the internal hash table of the <code>dict</code> type; it has no bearing on encoding or decoding issues from Python code.</span>
<span class="comment-copy">Either encoded or not you are looking for a <i>particular interpretation of bytes by an encoding</i>. If I don't recall wrong, I saw a while ago that Python's unicode are stored as UTF-16 internally. I'll check this. But just to mention, even Unicode needs a way to store itself in memory which ultimately translate to bytes from a specific encoding.</span>
<span class="comment-copy">@PauloBu: <a href="http://docs.python.org/3/whatsnew/3.3.html#pep-393" rel="nofollow noreferrer">Python 3.3 and up will use Latin-1, UCS-2 or UCS-4</a>, depending on the actual contents of the string, to safe memory. However, <i>this is entirely transparent</i> to Python code, and has no bearing on what happens when you try to encode such a value to bytes.</span>
<span class="comment-copy">@PauloBu: UCS-2 and UTF-16 are different encodings.  The confusion between those to has caused a lot of pain for programmers already.</span>
<span class="comment-copy">Yes, I am well aware that the Python 3.3+ model of string is that it is a sequence of code points, with internal representation intended to be of no concern to Python code (though, of course, it may still be a concern in terms of space consumption, copy speed, and so on).  I have added to my question statement the rationale for wanting nonetheless to inspect the internal structure's data -- conceptually, to check that this "no concern" is fulfilled, both by the Python libraries, and other libraries that handle strings.</span>
<span class="comment-copy">Thanks Martijn for your response pertaining to normal Python programs. I have added to my question the rationale for why I do actually want to inspect the internal representation of a string. The suggestions regarding ascii and ord are useful for problems in this neighborhood, but don't transparently reveal the internal structure actually used for a particular string. Ie: One is still dependent on an additional library function to transform the string internal rep to ASCII, from which one might infer what rep was used.</span>
<span class="comment-copy">For your hypothetical situation, you'd test it with building strings that according to the PEP would result in different internal structures and test with those to see if the 3rd party library behaviour changes. <b>This is an extreme edgecase however</b>, and in my opinion, a straw man. There is no access to the internals from Python because such edgecases are entirely in the realm of C and you'd use C debuggers to deal with that. You can then study the Python source code and API documentation if you want to deal with that situation.</span>
<span class="comment-copy">If this class of problems is uninteresting to you, that's fine, but that doesn't mean it's uninteresting to others, or that it's universally a straw man. I concur that one could investigate using test cases, a C debugger etc. That said, if there is a rationale for investigating using a C debugger, then why would one be uninterested in methods to investigate them directly from Python?  The point of my question is to find out if indeed there is such a way. It sounds like you've not needed one, and don't imagine needing one -- OK fair enough.</span>
<span class="comment-copy">No, I am telling you why there is no such access from Python to the internals. It's not that I am not interested, but <b>there is no such API in Python</b> to see that internal representation.</span>
<span class="comment-copy">Thanks for your answer.  In line with shielding Python code from string internals, I did expect that there would be no direct API to the internal representation provided out-of-the-box (or that it would be a relatively obtuse byte-inspecting API). That led to the suggestion in my question that there might exist a C library that somebody had cooked up to facilitate such inspection.</span>
