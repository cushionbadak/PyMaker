<div class="post-text" itemprop="text">
<p>The <code>subprocess.Popen</code> mechanism uses an underlying file descriptor, instead of a file-like object, to write its <code>stdout/stderr</code>. I need to capture both the <code>stdout</code> and <code>stderr</code> while still displaying them to the console.</p>
<p>How can I create a file descriptor that Popen can use that will allow me to do this?</p>
</div>
<div class="post-text" itemprop="text">
<p>Just a bit of context: <code>subprocess</code> <a href="https://github.com/python/cpython/blob/master/Lib/subprocess.py#L1306" rel="nofollow noreferrer">uses the raw file descriptors</a> of the <em>stdin</em>, <em>stdout</em>, <em>stderr</em> objects you specify, because <a href="https://github.com/python/cpython/blob/master/Modules/_posixsubprocess.c#L391" rel="nofollow noreferrer">it passes them down to POSIX</a>. If you use <code>subprocess.PIPE</code>, then it will create a new pipe with <code>os.pipe()</code>. Also, <code>Popen.communicate</code> reads until the end of the stream, which may not be desirable if you want to pipe the data somewhere else.</p>
<p>Since you want to print the output to <em>stdout</em>, I assume it's text output. You will need to use <code>encoding</code>, <code>errors</code> or <code>universal_newlines</code> in <code>Popen</code> for <code>subprocess</code> to treat the file as text (see <a href="https://docs.python.org/3/library/subprocess.html#subprocess.Popen.stdout" rel="nofollow noreferrer">docs</a>).</p>
<pre><code>import subprocess

p = subprocess.Popen(
    '/usr/bin/whoami',
    stdout=subprocess.PIPE,  # Control stdout
    universal_newlines=True  # Files opened in text mode
)

# Pipe the data somewhere else too, e.g.: a log file
with open('subprocess.log', 'w') as logfile:
    # p.poll() returns the return code when `p` exits
    while p.poll() is None:
        line = p.stdout.readline()
        # one to our stdout (readline includes the \n)
        print(line, end='')
        # one to the logfile
        logfile.write(line)
</code></pre>
<p>The same technique can be used for manipulating <em>stderr</em>, for example, by passing <code>file=sys.stderr</code> to <code>print</code>. Note that you can also pipe from your own <em>stdin</em> just by passing it directly:</p>
<pre><code>subprocess.Popen('/usr/bin/whoami', stdin=sys.stdin, stdout=subprocess.PIPE, ...)
</code></pre>
<p>After all, the standard streams just wrap file descriptors. If reading until the end of the line is unsuitable for the type of output you are expecting, you can just <code>read</code> a very short buffer.</p>
<h2>Working simultaneously with <em>stderr</em> and <em>stdout</em></h2>
<p>If you need both <em>stdout</em> and <em>stderr</em>, you come to the problem that you can only read from one at a time.<br/>
One possibility would be to use <code>os.set_blocking</code> to make the pipes non-blocking, so that any <code>read</code> method returns immediately if there is no data. This allows you to alternate between the streams.<br/>
Another possibility, is to have two separate threads process <em>stdout</em> and <em>stderr</em>; but there is a simpler way to achieve this by means of the <a href="https://docs.python.org/3/library/asyncio-subprocess.html#subprocess-using-transport-and-protocol" rel="nofollow noreferrer"><code>aysncio</code> module</a>:</p>
<pre><code>import asyncio
import sys

PROCESS_PATH = '/bin/mixed_output'

class MultiplexProtocol(asyncio.SubprocessProtocol):
    def __init__(self, exit_future):
        self.exit_future = exit_future

    def pipe_data_received(self, fd, data):
        if fd == sys.stdout.fileno():
            print(data.decode('utf-8'), file=sys.stdout, end='')
        elif fd == sys.stderr.fileno():
            print(data.decode('utf-8'), file=sys.stderr, end='')

    def process_exited(self):
        self.exit_future.set_result(True)


async def launch_subprocess(loop):
    # Future marking the end of the process
    exit_future = asyncio.Future(loop=loop)
    # Use asyncio's subprocess
    create_subp = loop.subprocess_exec(
        lambda: MultiplexProtocol(exit_future),
        PROCESS_PATH,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
        stdin=None
    )
    transport, protocol = await create_subp
    await exit_future
    # Close the pipes
    transport.close()


loop = asyncio.get_event_loop()
loop.run_until_complete(launch_subprocess(loop))
</code></pre>
<p>This is much less CPU consuming than constantly looping in the host process to pipe data to other streams, as <code>MultiplexProtocol.pipe_data_received</code> is called only when needed.</p>
</div>
<span class="comment-copy">what about capturing using subprocess.Popen and then printing them back to all fd you need</span>
<span class="comment-copy">No can do; I can't buffer the actual output to the stderr/stdout streams; the user might be interacting with the process.</span>
<span class="comment-copy">I <a href="http://stackoverflow.com/questions/4984549/merge-and-sync-stdout-and-stderr/5188359#5188359">answered to another similar question</a> which you may be able to modify to read the stdout/stderr together incrementally while also printing them to <code>sys.stdout</code> and <code>sys.stderr</code> respectively.</span>
