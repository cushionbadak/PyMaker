<div class="post-text" itemprop="text">
<p>I am using URL's as a key so I need them to be consistant and clean. I need a python function that will take a URL and clean it up so that I can do a get from the DB. For example, it will take the following:</p>
<pre><code>example.com
example.com/
http://example.com/
http://example.com
http://example.com?
http://example.com/?
http://example.com//
</code></pre>
<p>and output a clean consistant version:</p>
<pre><code>http://example.com/
</code></pre>
<p>I looked through std libs and github and couldn't find anything like this</p>
<p><strong>Update</strong></p>
<p>I couldn't find a Python library that implements everything discussed here and in the RFC:</p>
<p><a href="http://en.wikipedia.org/wiki/URL_normalization" rel="nofollow">http://en.wikipedia.org/wiki/URL_normalization</a></p>
<p>So I am writing one now. There is a lot more to this than I initially imagined.</p>
</div>
<div class="post-text" itemprop="text">
<p>Take a look at <a href="https://docs.python.org/2/library/urlparse.html" rel="nofollow noreferrer"><code>urlparse.urlparse()</code></a>. I've had good success with it.</p>
<hr/>
<p><em>note</em>: This answer is from 2011 and is specific to Python2. In Python3 the <code>urlparse</code> module has been named to <code>urllib.parse</code>.  The corresponding Python3 documentation for <code>urllib.parse</code> can be found here:</p>
<p><a href="https://docs.python.org/3/library/urllib.parse.html" rel="nofollow noreferrer">https://docs.python.org/3/library/urllib.parse.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>It's done in <a href="http://scrapy.org/" rel="noreferrer">scrapy</a>:</p>
<p><a href="http://nullege.com/codes/search/scrapy.utils.url.canonicalize_url" rel="noreferrer">http://nullege.com/codes/search/scrapy.utils.url.canonicalize_url</a></p>
<blockquote>
<p>Canonicalize the given url by applying the following procedures:</p>
<ul>
<li>sort query arguments, first by key, then by value</li>
<li>percent encode paths and query arguments. non-ASCII characters are   percent-encoded using UTF-8 (RFC-3986)</li>
<li>normalize all spaces (in query arguments) '+' (plus symbol)</li>
<li>normalize percent encodings case (%2f -&gt; %2F)</li>
<li>remove query arguments with blank values (unless keep_blank_values is True)</li>
<li>remove fragments (unless keep_fragments is True)</li>
</ul>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>Have you considered using regular xpressions? They will help you check for malformed URLs. I have used this in one of my applications</p>
<p>"^[, .a-zA-Z0-9]*$"</p>
</div>
<span class="comment-copy">The standardized cleaned up form should be <code>http://example.com/</code> rather than <code>http://example.com</code>, an HTTP URL without a path component is technically not well formed.</span>
<span class="comment-copy">You need to define clean. Does it mean an absolute URL? Or a canonical URL?</span>
<span class="comment-copy">What I really mean is normalize, which is the word that didn't really come to me when I typed this up at 5am. The urlparse() looks like what I want, I didn't notice the normalizing aspects of that function when I was reading through the docs early this morning.</span>
<span class="comment-copy">see this post <a href="http://stackoverflow.com/questions/5371992/comparing-two-urls-in-python/18690955#18690955" title="comparing two urls in python">stackoverflow.com/questions/5371992/â€¦</a></span>
<span class="comment-copy">possible duplicate of <a href="http://stackoverflow.com/questions/120951/how-can-i-normalize-a-url-in-python">How can I normalize a URL in python</a></span>
<span class="comment-copy">Along with urlparse.urlunparse().</span>
<span class="comment-copy">Thanks for that - for some reason I missed the normalization aspect of that function when I was reading the docs early this morning. Took me a few minutes to implement</span>
<span class="comment-copy">scratch that - the normalization fails on 70%+ of my test cases (I have 50 tests now). For some reason the python community was against implementing normalization per the RFC and per how browsers handle it:  <a href="http://en.wikipedia.org/wiki/URL_normalization" rel="nofollow noreferrer">en.wikipedia.org/wiki/URL_normalization</a>  I found this python bug:  <a href="http://bugs.python.org/issue4191" rel="nofollow noreferrer">bugs.python.org/issue4191</a></span>
<span class="comment-copy">to add, the urlparse normalization will not find those above URL's in the question to all be equal to each other, which is what is important.</span>
<span class="comment-copy">The Link is dead</span>
<span class="comment-copy">At least these days Scrapy imports this function from the <a href="http://w3lib.readthedocs.io/en/latest/w3lib.html#w3lib.url.canonicalize_url" rel="nofollow noreferrer">w3lib package</a>.</span>
<span class="comment-copy">It does not answer the question.</span>
