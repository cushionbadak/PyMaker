<div class="post-text" itemprop="text">
<p>I have two folders for training and testing dataset of images but both contains different labels like this,</p>
<pre><code>training-
         |-a  -img1.png
               img2.png
         |-as -img1.png
               img2.png
         |-are-img1.png
testing -
         |-as -img1.png
         |-and-img1.png
               img1.png
</code></pre>
<p>How can i create ytrain and ytest with this dataset?</p>
<p>i tried the following code,</p>
<pre><code>datagen = ImageDataGenerator(rescale=1. / 255)  
generator = datagen.flow_from_directory(train_data_dir,  
target_size=(img_width, img_height),  
batch_size=batch_size,  
class_mode=None,  
shuffle=False)  

nb_train_samples = len(generator.filenames)  
num_classes = len(generator.class_indices)  
</code></pre>
<p>Found 316 images belonging to 68 classes.</p>
<pre><code>generator = datagen.flow_from_directory(  
test_data_dir,  
target_size=(img_width, img_height),  
batch_size=batch_size,  
class_mode=None,  
shuffle=False)  
nb_test_samples = len(generator.filenames)
</code></pre>
<p>Found 226 images belonging to 48 classes.<br/>
<strong>Is this the correct way to do labelling??</strong>
Because both dataset contains different folder names (a,as,are) and (as, and)</p>
<p>When i build the model, i'm getting 0% accuracy</p>
<pre><code>model = Sequential()  
model.add(Flatten(input_shape=train_data.shape[1:]))  
model.add(Dense(256, activation='relu'))  
model.add(Dropout(0.5))  
model.add(Dense(num_classes, activation='sigmoid'))  

model.compile(optimizer='rmsprop',  
          loss='categorical_crossentropy', metrics=['accuracy'])  

history = model.fit(train_data, 
train_labels,epochs=epochs,batch_size=batch_size,test_data=(test_data, test_labels))  

model.save_weights(top_model_weights_path)  

(eval_loss, eval_accuracy) = model.evaluate(  
 test_data, test_labels, batch_size=batch_size, verbose=1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I would recommend you to merge both data sets, shuffle them and then split them again to get the train and test data sets with equal labels. That's the correct way of labeling because the model need to "see" all the possible labels and them compare them with the test data set.</p>
<p>For this you can use <code>gapcv</code>:</p>
<p>Install the library:</p>
<p><code>pip install gapcv</code></p>
<p>mix folders:</p>
<pre><code>from gapcv.utils.img_tools import ImgUtils
gap = ImgUtils(root_path='root_folder{}/training'.format('_t2'))
gap.transf='2to1'
gap.transform()
</code></pre>
<p>This will create a folder with the following structure:</p>
<pre><code>root_folder-
         |-a  -img1.png
               img2.png
         |-as -img1.png
               img2.png
         |-are-img1.png
         |-and-img1.png
               img1.png
</code></pre>
<p><strong>Option 1</strong></p>
<p>Use <code>gapcv</code> to pre-process your data set into and shareable <code>h5</code> file and use to fit images into your <code>keras</code> model:</p>
<pre><code>import os
if not os.path.isfile('name_data_set.h5'):
    # this will create the `h5` file if it doesn't exist
    images = Images('name_data_set', 'root_folder', config=['resize=(224,224)', 'store'])

# this will stream the data from the `h5` file so you don't overload your memory
images = Images(config=['stream'], augment=['flip=both', 'edge', 'zoom=0.3', 'denoise']) # augment if it's needed if not use just Images(config=['stream']), norm 1.0/255.0 by default.
images.load('name_data_set')

#Metadata

print('images train')
print('Time to load data set:', images.elapsed)
print('Number of images in data set:', images.count)
print('classes:', images.classes)
</code></pre>
<p>generator:</p>
<pre><code>images.split = 0.2
images.minibatch = 32
gap_generator = images.minibatch
X_test, Y_test = images.test
</code></pre>
<p>Fit <code>keras</code> model:</p>
<pre><code>model.fit_generator(generator=gap_generator,
                    validation_data=(X_test, Y_test),
                    epochs=epochs,
                    steps_per_epoch=steps_per_epoch)
</code></pre>
<p>why use gapcv? well it's twice faster fitting the model than <code>ImageDataGenerator()</code> :)</p>
<p><strong>Option 2</strong></p>
<p>Use <code>gapcv</code> to shuffle and split the data set with equal labels:</p>
<pre><code>gap = ImgUtils(root_path='root_folder')

# Tree 2
gap.transform(shufle=True, img_split=0.2)
</code></pre>
<p>keep using <code>keras</code> <code>ImageDataGenerator()</code> as usual.</p>
<p><strong>Documentation:</strong></p>
<p>Training <a href="https://github.com/andrewferlitsch/Gap/blob/master/train/session%206.ipynb" rel="nofollow noreferrer">notebook</a> to mix and split folders.<br/>
<a href="https://gapml.github.io/CV/" rel="nofollow noreferrer">gapcv</a> documentation.</p>
<p>Let me know how it goes. :)</p>
</div>
<div class="post-text" itemprop="text">
<p>Gap is pretty flexible for these types of issues. My favorite way to combine a separated Training and Test dataset is to use Gap's dataset merge feature (+= operator) as follows:</p>
<pre><code># load the images from the Training directory
images = Images('name_of_dataset', 'training', config=['resize=(224,224)', 'store'])

# load the images from the Testing directory and merge them with the Training data
images += Images('name_of_dataset', 'testing', config=['resize=(224,224)', 'store'])
</code></pre>
</div>
