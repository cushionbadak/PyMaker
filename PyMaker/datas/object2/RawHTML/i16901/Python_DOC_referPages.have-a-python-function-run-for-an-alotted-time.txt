<div class="post-text" itemprop="text">
<p>I have a python script that pulls from various internal network sources. With how our systems are set up we will initiate a urllib pull from a network location and it will get hung up waiting forever for a response on certain parts of the network. I would like my script to check that if it hasnt finished the pull in lets say 5 minutes it will pass the function and attempt to pull from the next address, and record it to a bad directory repository(so we can go check out which systems get hung up, there's like over 20,000 IP addresses we are checking some with some older scripts running on them that no longer work but will still try and run when requested, and they never stop trying to run)</p>
<p>Im familiar with having a script pause at a certain point</p>
<pre><code>import time
time.sleep(300)
</code></pre>
<p>What Im thinking from a psuedo code perspective (not proper python just illustrating the idea)</p>
<pre><code>import time
import urllib2
url_dict = ['http://1', 'http://2', 'http://3', ...]
fail_log_path = 'C:/Temp/fail_log.txt'
for addresses in url_dict:
    clock_value = time.start()
    while clock_value &lt;= 300:
        print str(clock_value)
        res = urllib2.retrieve(url)
    if res != []:
        pass
    else:
        fail_log = open(fail_log_path, 'a')
        fail_log.write("Failed to pull from site location: " + str(url) + "\n")
        faile_log.close
</code></pre>
<p>Update: a specific option for this dealing with urls <a href="https://stackoverflow.com/questions/2084782/timeout-for-urllib2-urlopen-in-pre-python-2-6-versions">timeout for urllib2.urlopen() in pre Python 2.6 versions</a></p>
<p>Found this answer which is more in line with the overall problem of my question:
<a href="https://stackoverflow.com/questions/6068361/kill-a-function-after-a-certain-time-in-windows">kill a function after a certain time in windows</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Your code as is doesn't seem to describe what you were saying. It seems you want the <code>if</code>/<code>else</code> check inside your while loop. On top of that, you would want to loop over the ip addresses and not over a time period as your code is currently written (otherwise you will keep requesting the same ip address every time). Instead of keeping track of time yourself, I would suggest reading up on <a href="https://docs.python.org/3/library/urllib.request.html#urllib.request.urlopen" rel="nofollow"><code>urllib.request.urlopen</code></a> - specifically the <code>timeout</code> parameter. Once set, that function call will throw a <a href="https://docs.python.org/3.4/library/socket.html#socket.timeout" rel="nofollow"><code>socket.timeout</code></a> exception once the time limit is reached. Surround that with a <code>try</code>/<code>except</code> block catching that error and then handle it appropriately.</p>
</div>
<span class="comment-copy">Note that if you're using Python 2.x, you want urllib2.urlopen.</span>
<span class="comment-copy">Yup, same idea though. Here's that link: <a href="https://docs.python.org/2.7/library/urllib2.html#urllib2.urlopen" rel="nofollow noreferrer">docs.python.org/2.7/library/urllib2.html#urllib2.urlopen</a>.</span>
<span class="comment-copy">Thanks for the help, wasnt sure there was a handler built in for that. Found the specific code in this answer.  <a href="http://stackoverflow.com/questions/2084782/timeout-for-urllib2-urlopen-in-pre-python-2-6-versions" title="timeout for urllib2 urlopen in pre python 2 6 versions">stackoverflow.com/questions/2084782/â€¦</a></span>
<span class="comment-copy">@AlienAnarchist: What is your Python version? Why can't you use <code>response = urllib2.urlopen(url, timeout=300)</code>?</span>
<span class="comment-copy">J.F. Sebastian yes that would absolutely work, didnt know that urllib contained a paramter for that aspect. Appreciate the input.</span>
