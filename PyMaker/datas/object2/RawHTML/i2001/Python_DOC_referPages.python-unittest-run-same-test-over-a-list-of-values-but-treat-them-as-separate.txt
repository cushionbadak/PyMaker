<div class="post-text" itemprop="text">
<p>I'm writing a test to validate that my program is able to solve the problem at hand for different levels of complexity. The expected outcome is always the same (solution is complete), so a single test definition works for all problems.</p>
<p><strong>How do I run the <em>same test</em> for a list of values read from a file, but tell unittest to <em>treat each of these problems as a separate test</em> so I can pinpoint all failing/passing cases?</strong> (Preferably no external libraries)</p>
<p>To avoid explicitly having <code>test_solution_1, test_solution_2... test_solution_n</code>, my initial thought was to have a for loop run through each item of the list, and run the assertions one at a time:</p>
<pre><code>class TestProblem(unittest.TestCase):
    def test_all(self):
        results = Counter()
        rng = 50
        for i in range(rng):
            p = Problem(matrix_index=i)  # generate instance of problem.
            p.solve()
            results[p.is_complete()] += 1  # log result of test.
            self.assertTrue(p.is_complete(), msg="Failed at %s" % str(i))
        # Now ensure all instances passed (useful when above assertion not included).
        self.assertEqual(results[True], rng, msg="SCORE: %s / %s" % (results[True], rng))
</code></pre>
<p>The problem with this approach is that the first failure stops the rest from running, so its more difficult to get a complete picture of what is wrong.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use the <strong><a href="https://docs.python.org/3/library/unittest.html#distinguishing-test-iterations-using-subtests" rel="nofollow noreferrer">subTest()</a></strong> context manager to distinguish tests inside a single test body. (Python 3.4+)</p>
<pre><code>    def test_all(self):
        results = Counter()
        rng = 50
        for i in range(rng):
            with self.subTest(i=i):  # &lt;----------------------
                p = Problem(matrix_index=i)  # generate instance of problem.
                p.solve()
                results[p.is_complete()] += 1  # log result of test.
                self.assertTrue(p.is_complete())
        self.assertEqual(results[True], rng, msg="SCORE: %s / %s" % (results[True], rng))
</code></pre>
<p>Result from PyCharm:</p>
<p><a href="https://i.stack.imgur.com/4jStw.png" rel="nofollow noreferrer"><img alt="PyCharm unittest subTest results" src="https://i.stack.imgur.com/4jStw.png"/></a></p>
<p>You can see individual results for each case and see all failed cases at once. Notice that its still treated as a single logical test ("<em>Ran 1 test</em>"), which makes sense since its testing the same functionality. Each case is treated as a sub test.</p>
<hr/>
<p>Other things to consider:</p>
<ul>
<li>If using an older version of Python or you want to use another library, you can look at <a href="https://github.com/datadriventests/ddt" rel="nofollow noreferrer">ddt</a> to add test data via decorator <code>@data(3, 4, 12, 23)</code>.</li>
</ul>
</div>
