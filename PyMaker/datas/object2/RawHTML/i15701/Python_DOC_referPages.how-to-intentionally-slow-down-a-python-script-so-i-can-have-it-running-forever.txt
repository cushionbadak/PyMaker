<div class="post-text" itemprop="text">
<p>So basically I have a list of 300 values and different averages associated with each one.</p>
<p>I have a <strong><code>for</code></strong>-loop that generates a list of ten of these values at random, and writes it to excel if certain conditions are met based on their averages.</p>
<p>The code runs fine if I loop through 10 million times or less, but that is orders of magnitudes too small. Even if I just double the for loop counter to 20 million my computer becomes unusable while it is running. </p>
<p>I want to iterate the loop 100 million or 1 billion times even. I want it to run slowly in the background, I don't care if it takes 24 hours to get to the results. I just want to use my computer while it's working. Currently, if the for loop goes past 10 million the memory and disk usage of my laptop go to 99%. </p>
<p><strong>Using</strong> <code>pyScripter</code> and python 3.3</p>
<p><strong>Comp specs:</strong> Intel Core i7 4700HQ (2.40GHz) 8GB Memory 1TB HDD NVIDIA GeForce GTX 850M 2GB GDDR3</p>
<p><strong>Code snippet:</strong></p>
<pre><code>for i in range( 0, cycles ):
    genRandLineups( Red );                     #random team gens
    genRandLineups( Blue );
    genRandLineups( Purple );
    genRandLineups( Green );

    if          sum( teamAve[i] )    &lt;= 600
        and ( ( sum( teamValues[i] ) &gt;  currentHighScore )
            or  sum( teamValues[i] ) &gt;  1024 
            ):
        teamValuesF.append( teamValues[i] )


        sheetw.write( q, 0, str( teamValues[i] ) )
        ts = time.time()
        workbookw.save( "Data_Log.xls" )
        st = datetime.datetime.fromtimestamp( ts ).strftime( '%Y-%m-%d %H:%M:%S' )
        sheetw.write( q, 3, st )
        q = q + 1

        if sum( teamValues[i] ) &gt; currentHighScore:
            currentHighScore = sum( teamValues[i] )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First, I suspect your <em>real</em> problem is that you're just retaining too much memory, causing your computer to run into VM swap, which makes your entire computer slow to a crawl. You should really look into fixing that instead of just trying to make it happen periodically throughout the day instead of constantly.</p>
<p>In particular, it sounds like you're keeping a list of 10N values around forever. Do you really need to do that?</p>
<p>If not, start freeing them. (Or don't store them in the first place. One common problem a lot of people have is that they need 1 billion values, but only one at a time, once through a loop, and they're storing them in a list when they could be using an iterator. This is basically the generic version of the familiar <code>readlines()</code> problem.)</p>
<p>If so, look into some efficient disk-based storage instead of memory, or something more compact like a NumPy array instead of a list.</p>
<hr/>
<p>But meanwhile, if you want to reduce the priority of a program, the easiest way to do that may be externally. For example, on most platforms besides Windows, you can just launch your script with <code>nice 20 python myscript.py</code> and the OS will give everything else more CPU time than your program.</p>
<hr/>
<p>But to answer your direct question, if you want to slow down your script from inside, that's pretty easy to do: Just call <a href="https://docs.python.org/3/library/time.html#time.sleep" rel="nofollow"><code>sleep</code></a> every so often. This asks the OS to suspend your program and not give you any resources until the specified number of seconds have expired. That may be only approximate rather than absolutely nothing for exactly N seconds, but it's close enough (and as good as you can do).</p>
<p>For example:</p>
<pre><code>for i in range(reps):
    do_expensive_work():
    if i % 100 == 99:
        time.sleep(10)
</code></pre>
<p>If <code>do_expensive_work</code> takes 18ms, you'll burn CPU for 1.8 seconds then sleep for 10 and repeat. I doubt that's exactly the behavior you want (or that it takes 18ms), but you can tweak the numbers. Or, if the timing is variable, and you want the sleep percentage to be consistent, you can measure times and sleep every N seconds since the last sleep, instead of every N reps.</p>
</div>
<div class="post-text" itemprop="text">
<h2>Do not slow down. Rather re-design &amp; step in for HPC</h2>
<p>For high performance processing on just "a few" items ( <em>list of 300 values</em> )
the best would consist of:</p>
<ol>
<li><p><strong>avoid</strong> file access ( even if sparse as noted in OP ) -- cache TruePOSITIVEs in <code>anOutputSTRING</code> that is being <code>fileIO</code>-ed at the end or upon a string length limit or marshalled to another, remote, logging machine.</p></li>
<li><p><strong>move</strong> all highly iterative processing, said to span <code>10E+006</code> -- <code>10E+009</code> cycles, onto massively-parallel GPU/CUDA kernel-processing on GPU you already have in the laptop, both to free your CPU-resources and to get benefits of <strong>640-threads delivering about 1.15 TFLOPs</strong> of a parallel-engine computing horsepower, as opposed to just a few, GUI-shared, MFLOPs from the CPU-cores.</p></li>
</ol>
</div>
<span class="comment-copy">Buy a laptop with 2 or more cores? And what OS are you using?</span>
<span class="comment-copy">What does your code look like? What platform are you on?</span>
<span class="comment-copy">Are you computing all of the 10-20 million items at once, up front? Or are you saving the results of all of the 10-20 million averages all the way to the end? If you don't need to do that, don't! Use generators or overwrite variables so that your memory usage remains steady regardless of the length of your loop. Without seeing any code, that's about as close to an answer as you're likely to get.</span>
<span class="comment-copy">First, I suspect your <i>real</i> problem is that you're just retaining too much memory, causing your computer to run into VM swap, which makes your entire computer slow to a crawl. You should really look into fixing that instead of just trying to make it happen periodically throughout the day instead of constantly. For example, it sounds like you're keeping a list of 10N values around forever. Do you really need to do that? If not, start freeing them. If so, look into some efficient disk-based storage instead of memory, or something more compact like a NumPy array instead of a list.</span>
<span class="comment-copy">But meanwhile, if you want to reduce the priority of a program, the easiest way to do that may be externally. For example, on most platforms besides Windows, you can just launch your script with <code>nice 20 python myscript.py</code> and the OS will give everything else more CPU time than your program.</span>
<span class="comment-copy">Okay, I think I want to do your first suggestion. I generate 10mil items but only need to keep them if certain conditions are met. Generally at the end of 10 mil cycles I only have 20 values I keep. How do I tell python not to keep the ones that don't meet my criteria?</span>
<span class="comment-copy">@ACD: Without seeing all of the relevant code, it's hard to answer that. But it may be a matter of breaking your loop up into an inner loop over 10000000 and an outer loop over N/10000000, and just reassign an empty list to the list you were building (in other words, <code>spam = []</code> at the top of the outer loop, instead of outside both loops).</span>
<span class="comment-copy">So I generate these random combinations, and if they don't meet the criteria I want to throw it away, and try again with a new random list. How do I do that efficiently?</span>
<span class="comment-copy">@ACD: From what I can tell from the code you posted, the only reason you're not throwing it away is that you're appending it to a list that you never use. If that's true, the answer is pretty simple: Just stop appending to that list.</span>
