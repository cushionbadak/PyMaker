<div class="post-text" itemprop="text">
<p>We have a python program that reads around 120,000 XML files, parses them(using <code>ElementTree</code>), extracts tag values(<code>fromstring().findall()</code>) etc. This is taking a loooong time. We thought of parallelizing the program using threads. But <code>top</code> shows the CPU consumption of this single process to be around 100%. So, my question is will threading really help. My intuition is that threading helps only when there is spare CPU left.</p>
<p>My system config is -</p>
<pre><code>pavan8085@Xeek:/media/pavan8085/Projects/Pavan/CompBio$ lscpu
Architecture:          x86_64
CPU op-mode(s):        32-bit, 64-bit
Byte Order:            Little Endian
CPU(s):                4
On-line CPU(s) list:   0-3
Thread(s) per core:    2
Core(s) per socket:    2
Socket(s):             1
NUMA node(s):          1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 69
Stepping:              1
CPU MHz:               782.000
BogoMIPS:              3392.44
Virtualization:        VT-x
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              3072K
NUMA node0 CPU(s):     0-3
</code></pre>
<p><strong>PS</strong>: I am totally new to Python. So there may be some language specific tricks that can help improve speed. I'll be glad to provide more info if that is the problem. </p>
</div>
<div class="post-text" itemprop="text">
<p>Definitely because the most likely bottleneck here is actually I/O not CPU. So what you are doing here is processing each file sequentially, so each time you wait for the file to be read from disk you have a bottleneck which blocks everything from happening. If you used multiple threads you can have multiple files being processed simultaneously and while one is waiting for I/O the rest can be processed. </p>
<p>This is a good explanation as to why I/O blocking can cause high CPU utilization <a href="http://www.chileoffshore.com/en/interesting-articles/126-linux-wait-io-problem" rel="nofollow">http://www.chileoffshore.com/en/interesting-articles/126-linux-wait-io-problem</a></p>
<p>Just because it's 100% it doesn't mean it's actually doing computation work during that time.</p>
</div>
<div class="post-text" itemprop="text">
<p>Three things right off the bat about Python and concurrency, and Python and XML processing:</p>
<ol>
<li>Python's multithreading capabilities are limited to working around IO-bound operations. For more explanation, look up "Global Interpreter Lock" or "GIL". Instead, to split up and concurrently work on CPU-bound work when you have multiple CPUs, use the <code>multiprocessing</code> module</li>
<li>When processing large XML files needs to be faster, you don't want to use <code>ElementTree</code> which is implemented in pure Python. CPython ships with an implementation of the same API written in C under the name <code>cElementTree</code>. It will execute much faster.</li>
<li>While cElementTree is fast, the world standard <code>lxml</code> library which also implements the elementtree API is faster still. It is relatively straightforwards to install, depending upon your operating system.</li>
</ol>
<p>Take a look at <a href="https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers" rel="nofollow">https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers</a> for a straightforward way of spreading the work out across a pool of worker processes.</p>
</div>
<div class="post-text" itemprop="text">
<p>It's unlikely that multithreading will help in this situation assuming you are using the standard CPython implementation because it has a global interpreter lock and threads in Python cannot run simultaneously. Thus you can't utilize more than a single CPU core.</p>
<p>XML parsing is actually quite expensive and the built-in parsers are not the fastest ones available. <a href="http://lxml.de/" rel="nofollow">Lxml</a> is known to be faster, but there are even faster options if you are willing to write your own bindings to a C or C++ library.</p>
<p>You might want to <a href="http://xmlbench.sourceforge.net/results/benchmark/" rel="nofollow">look here</a> or come up with your own benchmark.</p>
<p>You'll want to profile your code, but be careful when using Python profiling tools as they can often get confused by extension modules which it is likely if you are parsing XML that you are using an extension module.</p>
<p>Also depending on the structure of your XML, parsing an XML file is not typically conducive to parallelism. You will probably have a lot of shared state. If you are <strong>processing</strong> the XML and performing some operations on each of the elements that is much more likely to be parallelizable work as you can do each operation independently. I would spend my effort there depending on what your profiling shows.</p>
</div>
<span class="comment-copy"><a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">Do some profiling</a> to see where the time is going first.</span>
<span class="comment-copy">Also, make sure you're not using too much memory. The fact that you're using fromstring implies that you're reading at least one file at a time entirely into memory, which there's no reason to do. If you're reading in all of them, your time could all be spent swapping.</span>
<span class="comment-copy">Point #2 is only true in Python 2.x; in 3.x, ElementTree automatically uses the C accelerator.</span>
<span class="comment-copy">Also, while lxml is usually faster than the stdlib's C implementation, it isn't always, so it's worth trying both and testing.</span>
