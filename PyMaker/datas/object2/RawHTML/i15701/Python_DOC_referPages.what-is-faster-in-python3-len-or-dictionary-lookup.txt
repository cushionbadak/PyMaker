<div class="post-text" itemprop="text">
<p>What is faster (Python3)?</p>
<pre><code>if len(interval) &lt;= 2:
  return 1
</code></pre>
<p>or:</p>
<pre><code>if interval in intervaldict:
  return intervaldict[interval]
</code></pre>
<p>Does in depend on the length of the string or the length of the dictionary? I did some simple test and it looks like <code>len</code> is more expensive, which seems counterintuitive to me.</p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>len</code> solution is marginally slower because there is more involved.  You can see this by breaking down the code with <a href="https://docs.python.org/3/library/dis.html#dis.dis" rel="nofollow"><code>dis.dis</code></a>:</p>
<pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; dct = {1:1, 2:2}
&gt;&gt;&gt; dis.dis('1 in dct')
  1           0 LOAD_CONST               0 (1)
              3 LOAD_NAME                0 (dct)
              6 COMPARE_OP               6 (in)
              9 RETURN_VALUE
&gt;&gt;&gt; dis.dis('len(dct) &lt;= 2')
  1           0 LOAD_NAME                0 (len)
              3 LOAD_NAME                1 (dct)
              6 CALL_FUNCTION            1 (1 positional, 0 keyword pair)
              9 LOAD_CONST               0 (2)
             12 COMPARE_OP               1 (&lt;=)
             15 RETURN_VALUE
&gt;&gt;&gt;
</code></pre>
<p>Notice that the <code>len</code> solution has an extra name lookup for <code>len</code> as well as a function call.  These each take time.  But, as you can see from the <a href="https://docs.python.org/3/library/timeit.html#timeit.timeit" rel="nofollow"><code>timeit.timeit</code></a> tests below, the performance difference is pretty insignificant:</p>
<pre><code>&gt;&gt;&gt; import timeit
&gt;&gt;&gt; dct = {1:1, 2:2}
&gt;&gt;&gt; timeit.timeit('1 in dct', 'from __main__ import dct')
0.24376701508152573
&gt;&gt;&gt; timeit.timeit('len(dct) &lt;= 2', 'from __main__ import dct')
0.4435952055358978
&gt;&gt;&gt;
</code></pre>
<p>Also, these stats will not change depending on the dictionary's length because both <code>len</code> and <code>in</code> have <code>O(1)</code> (constant) complexity with dictionaries.</p>
</div>
<div class="post-text" itemprop="text">
<p>See <a href="https://wiki.python.org/moin/TimeComplexity" rel="nofollow">Python's Time Complexity</a></p>
<p><code>len</code> on a list is <em>O(1)</em> in all cases whereas lookup in a dictionary is <em>amortized worst case O(n)</em>. Complexity and runtime are <strong>different</strong>. For some situation a dictionary look up will take longer, but it may happen so rarely and only for such large size dictionaries that it will not be the most performant for your uses.</p>
</div>
<span class="comment-copy">try running it and timing it?</span>
<span class="comment-copy">its not that easy as I think it may depend on various conditions as the length of the structures etc. Indeed, if you read mu question properly, you would know I have tried already.</span>
<span class="comment-copy">wow, is this such a stupid question? :)</span>
<span class="comment-copy">I'd suggest being more explicit about your datatypes -- your accepted answer is comparing length of a dictionary to lookup in a dictionary, whereas your question appears to ask about length of a <i>string</i>.</span>
<span class="comment-copy">...for that matter, the answer based on bytecode dissassembly will be most certainly wrong for any JIT-based Python implementation (such as PyPy). Not necessarily wrong in terms of the actual performance variance being in the different direction, but wrong in the sense of having no bearing on the actual implementation.</span>
<span class="comment-copy">I didn't know dis, thanks.</span>
