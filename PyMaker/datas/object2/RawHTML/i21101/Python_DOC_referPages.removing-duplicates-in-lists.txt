<div class="post-text" itemprop="text">
<p>Pretty much I need to write a program to check if a list has any duplicates and if it does it removes them and returns a new list with the items that werent duplicated/removed. This is what I have but to be honest I do not know what to do.</p>
<pre><code>def remove_duplicates():
    t = ['a', 'b', 'c', 'd']
    t2 = ['a', 'c', 'd']
    for t in t2:
        t.append(t.remove())
    return t
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The common approach to get a unique collection of items is to use a <a href="http://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset" rel="noreferrer"><code>set</code></a>. Sets are <em>unordered</em> collections of <em>distinct</em> objects. To create a set from any iterable, you can simply pass it to the built-in <a href="http://docs.python.org/3/library/functions.html#func-set" rel="noreferrer"><code>set()</code></a> function. If you later need a real list again, you can similarly pass the set to the <a href="http://docs.python.org/3/library/functions.html#func-list" rel="noreferrer"><code>list()</code></a> function.</p>
<p>The following example should cover whatever you are trying to do:</p>
<pre><code>&gt;&gt;&gt; t = [1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; t
[1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; list(set(t))
[1, 2, 3, 5, 6, 7, 8]
&gt;&gt;&gt; s = [1, 2, 3]
&gt;&gt;&gt; list(set(t) - set(s))
[8, 5, 6, 7]
</code></pre>
<p>As you can see from the example result, the original order is not maintained. As mentioned above, sets themselves are unordered collections, so the order is lost. When converting a set back to a list, an arbitrary order is created.</p>
<p>If order is important to you, then you will have to use a different mechanism. A very common solution for this is to rely on <a href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" rel="noreferrer"><code>OrderedDict</code></a> to keep the order of keys during insertion:</p>
<pre><code>&gt;&gt;&gt; from collections import OrderedDict
&gt;&gt;&gt; list(OrderedDict.fromkeys(t))
[1, 2, 3, 5, 6, 7, 8]
</code></pre>
<p>Note that this has the overhead of creating a dictionary first, and then creating a list from it. So if you don’t actually need to preserve the order, you’re better off using a set. Check out <a href="https://stackoverflow.com/q/480214/216074">this question</a> for more details and alternative ways to preserve the order when removing duplicates.</p>
<hr/>
<p>Finally note that both the <code>set</code> as well as the <code>OrderedDict</code> solution require your items to be <em>hashable</em>. This usually means that they have to be immutable. If you have to deal with items that are not hashable (e.g. list objects), then you will have to use a slow approach in which you will basically have to compare every item with every other item in a nested loop.</p>
</div>
<div class="post-text" itemprop="text">
<p><strong>In Python 2.7</strong>, the new way of removing duplicates from an iterable while keeping it in the original order is:</p>
<pre><code>&gt;&gt;&gt; from collections import OrderedDict
&gt;&gt;&gt; list(OrderedDict.fromkeys('abracadabra'))
['a', 'b', 'r', 'c', 'd']
</code></pre>
<p><strong>In Python 3.5</strong>, the OrderedDict has a C implementation. My timings show that this is now both the fastest and shortest of the various approaches for Python 3.5.</p>
<p><strong>In Python 3.6</strong>, the regular dict became both ordered and compact.  (This feature is holds for CPython and PyPy but may not present in other implementations).  That gives us a new fastest way of deduping while retaining order:</p>
<pre><code>&gt;&gt;&gt; list(dict.fromkeys('abracadabra'))
['a', 'b', 'r', 'c', 'd']
</code></pre>
<p><strong>In Python 3.7</strong>, the regular dict is guaranteed to both ordered across all implementations.  <strong>So, the shortest and fastest solution is:</strong></p>
<pre><code>&gt;&gt;&gt; list(dict.fromkeys('abracadabra'))
['a', 'b', 'r', 'c', 'd']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It's a one-liner: <code>list(set(source_list))</code> will do the trick.</p>
<p>A <code>set</code> is something that can't possibly have duplicates.</p>
<p>Update: an order-preserving approach is two lines:</p>
<pre><code>from collections import OrderedDict
OrderedDict((x, True) for x in source_list).keys()
</code></pre>
<p>Here we use the fact that <code>OrderedDict</code> remembers the insertion order of keys, and does not change it when a value at a particular key is updated. We insert <code>True</code> as values, but we could insert anything, values are just not used. (<code>set</code> works a lot like a <code>dict</code> with ignored values, too.)</p>
</div>
<div class="post-text" itemprop="text">
<pre><code>&gt;&gt;&gt; t = [1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; t
[1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; s = []
&gt;&gt;&gt; for i in t:
       if i not in s:
          s.append(i)
&gt;&gt;&gt; s
[1, 2, 3, 5, 6, 7, 8]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you don't care about the order, just do this:</p>
<pre><code>def remove_duplicates(l):
    return list(set(l))
</code></pre>
<p>A <code>set</code> is guaranteed to not have duplicates.</p>
</div>
<div class="post-text" itemprop="text">
<p>To make a new list  retaining the order of first elements of duplicates in <code>L</code></p>
<p><code>newlist=[ii for n,ii in enumerate(L) if ii not in L[:n]]</code></p>
<p>for example <code>if L=[1, 2, 2, 3, 4, 2, 4, 3, 5]</code> then <code>newlist</code> will be <code>[1,2,3,4,5]</code></p>
<p>This checks each new element has not appeared previously in the list before adding it. 
Also it does not need imports. </p>
</div>
<div class="post-text" itemprop="text">
<p>A colleague have sent the accepted answer as part of his code to me for a codereview today.
While I certainly admire the elegance of the answer in question, I am not happy with the performance.
I have tried this solution (I use <em>set</em> to reduce lookup time)</p>
<pre><code>def ordered_set(in_list):
    out_list = []
    added = set()
    for val in in_list:
        if not val in added:
            out_list.append(val)
            added.add(val)
    return out_list
</code></pre>
<p>To compare efficiency, I used a random sample of 100 integers - 62 were unique</p>
<pre><code>from random import randint
x = [randint(0,100) for _ in xrange(100)]

In [131]: len(set(x))
Out[131]: 62
</code></pre>
<p>Here are the results of the measurements</p>
<pre><code>In [129]: %timeit list(OrderedDict.fromkeys(x))
10000 loops, best of 3: 86.4 us per loop

In [130]: %timeit ordered_set(x)
100000 loops, best of 3: 15.1 us per loop
</code></pre>
<p>Well, what happens if set is removed from the solution?</p>
<pre><code>def ordered_set(inlist):
    out_list = []
    for val in inlist:
        if not val in out_list:
            out_list.append(val)
    return out_list
</code></pre>
<p>The result is not as bad as with the <em>OrderedDict</em>, but still more than 3 times of the original solution</p>
<pre><code>In [136]: %timeit ordered_set(x)
10000 loops, best of 3: 52.6 us per loop
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Another way of doing:</p>
<pre><code>&gt;&gt;&gt; seq = [1,2,3,'a', 'a', 1,2]
&gt;&gt; dict.fromkeys(seq).keys()
['a', 1, 2, 3]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are also solutions using Pandas and Numpy. They both return numpy array so you have to use the function <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.tolist.html" rel="noreferrer"><code>.tolist()</code></a> if you want a list.</p>
<pre><code>t=['a','a','b','b','b','c','c','c']
t2= ['c','c','b','b','b','a','a','a']
</code></pre>
<h2>Pandas solution</h2>
<p>Using Pandas function <a href="https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.unique.html" rel="noreferrer"><code>unique()</code></a>:</p>
<pre><code>import pandas as pd
pd.unique(t).tolist()
&gt;&gt;&gt;['a','b','c']
pd.unique(t2).tolist()
&gt;&gt;&gt;['c','b','a']
</code></pre>
<h2>Numpy solution</h2>
<p>Using numpy function <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html" rel="noreferrer"><code>unique()</code></a>.</p>
<pre><code>import numpy as np
np.unique(t).tolist()
&gt;&gt;&gt;['a','b','c']
np.unique(t2).tolist()
&gt;&gt;&gt;['a','b','c']
</code></pre>
<p><strong>Note that numpy.unique() also sort the values</strong>. So the list <code>t2</code> is returned sorted. If you want to have the order preserved use as in <a href="https://stackoverflow.com/questions/15637336/numpy-unique-with-order-preserved">this answer</a>:</p>
<pre><code>_, idx = np.unique(t2, return_index=True)
t2[np.sort(idx)].tolist()
&gt;&gt;&gt;['c','b','a']
</code></pre>
<p>The solution is not so elegant compared to the others, however, compared to pandas.unique(), numpy.unique() allows you also to check if nested arrays are unique along one selected axis.</p>
</div>
<div class="post-text" itemprop="text">
<p>Simple and easy:</p>
<pre><code>myList = [1, 2, 3, 1, 2, 5, 6, 7, 8]
cleanlist = []
[cleanlist.append(x) for x in myList if x not in cleanlist]
</code></pre>
<p>Output:</p>
<pre><code>&gt;&gt;&gt; cleanlist 
[1, 2, 3, 5, 6, 7, 8]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I had a dict in my list, so I could not use the above approach. I got the error:</p>
<pre><code>TypeError: unhashable type:
</code></pre>
<p>So if you care about <strong>order</strong> and/or some items are <strong>unhashable</strong>. Then you might find this useful:</p>
<pre><code>def make_unique(original_list):
    unique_list = []
    [unique_list.append(obj) for obj in original_list if obj not in unique_list]
    return unique_list
</code></pre>
<p>Some may consider list comprehension with a side effect to not be a good solution. Here's an alternative:</p>
<pre><code>def make_unique(original_list):
    unique_list = []
    map(lambda x: unique_list.append(x) if (x not in unique_list) else False, original_list)
    return unique_list
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Try using sets:</p>
<pre><code>import sets
t = sets.Set(['a', 'b', 'c', 'd'])
t1 = sets.Set(['a', 'b', 'c'])

print t | t1
print t - t1
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could also do this:</p>
<pre><code>&gt;&gt;&gt; t = [1, 2, 3, 3, 2, 4, 5, 6]
&gt;&gt;&gt; s = [x for i, x in enumerate(t) if i == t.index(x)]
&gt;&gt;&gt; s
[1, 2, 3, 4, 5, 6]
</code></pre>
<p>The reason that above works is that <code>index</code> method returns only the first index of an element. Duplicate elements have higher indices. Refer to <a href="https://docs.python.org/3/tutorial/datastructures.html#more-on-lists" rel="noreferrer">here</a>:</p>
<blockquote>
<p><strong>list.index(x[, start[, end]])</strong><br/>
  Return zero-based index in the list of
  the first item whose value is x.    Raises a ValueError if there is no
  such item.</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>All the order-preserving approaches I've seen here so far either use naive  comparison (with O(n^2) time-complexity at best) or heavy-weight <code>OrderedDicts</code>/<code>set</code>+<code>list</code> combinations that are limited to hashable inputs. Here is a hash-independent O(nlogn) solution:</p>
<p><strong>Update</strong> added the <code>key</code> argument, documentation and Python 3 compatibility.</p>
<pre><code># from functools import reduce &lt;-- add this import on Python 3

def uniq(iterable, key=lambda x: x):
    """
    Remove duplicates from an iterable. Preserves order. 
    :type iterable: Iterable[Ord =&gt; A]
    :param iterable: an iterable of objects of any orderable type
    :type key: Callable[A] -&gt; (Ord =&gt; B)
    :param key: optional argument; by default an item (A) is discarded 
    if another item (B), such that A == B, has already been encountered and taken. 
    If you provide a key, this condition changes to key(A) == key(B); the callable 
    must return orderable objects.
    """
    # Enumerate the list to restore order lately; reduce the sorted list; restore order
    def append_unique(acc, item):
        return acc if key(acc[-1][1]) == key(item[1]) else acc.append(item) or acc 
    srt_enum = sorted(enumerate(iterable), key=lambda item: key(item[1]))
    return [item[1] for item in sorted(reduce(append_unique, srt_enum, [srt_enum[0]]))] 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Reduce variant with ordering preserve:</p>
<p>Assume that we have list:</p>
<pre><code>l = [5, 6, 6, 1, 1, 2, 2, 3, 4]
</code></pre>
<p>Reduce variant (unefficient):</p>
<pre><code>&gt;&gt;&gt; reduce(lambda r, v: v in r and r or r + [v], l, [])
[5, 6, 1, 2, 3, 4]
</code></pre>
<p>5 x faster but more sophisticated</p>
<pre><code>&gt;&gt;&gt; reduce(lambda r, v: v in r[1] and r or (r[0].append(v) or r[1].add(v)) or r, l, ([], set()))[0]
[5, 6, 1, 2, 3, 4]
</code></pre>
<p>Explanation:</p>
<pre><code>default = (list(), set())
# user list to keep order
# use set to make lookup faster

def reducer(result, item):
    if item not in result[1]:
        result[0].append(item)
        result[1].add(item)
    return result

reduce(reducer, l, default)[0]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Best approach of removing duplicates from a list is using <strong>set()</strong> function, available in python, again converting that <strong>set into list</strong></p>
<pre><code>In [2]: some_list = ['a','a','v','v','v','c','c','d']
In [3]: list(set(some_list))
Out[3]: ['a', 'c', 'd', 'v']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Without using set </p>
<pre><code>data=[1, 2, 3, 1, 2, 5, 6, 7, 8]
uni_data=[]
for dat in data:
    if dat not in uni_data:
        uni_data.append(dat)

print(uni_data) 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use the following function: </p>
<pre><code>def rem_dupes(dup_list): 
    yooneeks = [] 
    for elem in dup_list: 
        if elem not in yooneeks: 
            yooneeks.append(elem) 
    return yooneeks
</code></pre>
<p><strong>Example</strong>: </p>
<pre><code>my_list = ['this','is','a','list','with','dupicates','in', 'the', 'list']
</code></pre>
<p><strong>Usage:</strong></p>
<pre><code>rem_dupes(my_list)
</code></pre>
<p>['this', 'is', 'a', 'list', 'with', 'dupicates', 'in', 'the']</p>
</div>
<div class="post-text" itemprop="text">
<p>This one cares about the order without too much hassle (OrderdDict &amp; others). Probably not the most Pythonic way, nor shortest way, but does the trick:</p>
<pre><code>def remove_duplicates(list):
    ''' Removes duplicate items from a list '''
    singles_list = []
    for element in list:
        if element not in singles_list:
            singles_list.append(element)
    return singles_list
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>below code is simple for removing duplicate in list</p>
<pre><code>def remove_duplicates(x):
    a = []
    for i in x:
        if i not in a:
            a.append(i)
    return a

print remove_duplicates([1,2,2,3,3,4])
</code></pre>
<p>it returns [1,2,3,4]</p>
</div>
<div class="post-text" itemprop="text">
<p>There are many other answers suggesting different ways to do this, but they're all batch operations, and some of them throw away the original order. That might be okay depending on what you need, but if you want to iterate over the values in the order of the first instance of each value, and you want to remove the duplicates on-the-fly versus all at once, you could use this generator:</p>
<pre><code>def uniqify(iterable):
    seen = set()
    for item in iterable:
        if item not in seen:
            seen.add(item)
            yield item
</code></pre>
<p>This returns a generator/iterator, so you can use it anywhere that you can use an iterator.</p>
<pre><code>for unique_item in uniqify([1, 2, 3, 4, 3, 2, 4, 5, 6, 7, 6, 8, 8]):
    print(unique_item, end=' ')

print()
</code></pre>
<p>Output:</p>
<pre><code>1 2 3 4 5 6 7 8
</code></pre>
<hr/>
<p>If you do want a <code>list</code>, you can do this:</p>
<pre><code>unique_list = list(uniqify([1, 2, 3, 4, 3, 2, 4, 5, 6, 7, 6, 8, 8]))

print(unique_list)
</code></pre>
<p>Output:</p>
<pre><code>[1, 2, 3, 4, 5, 6, 7, 8]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>One more better approach could be,</p>
<pre><code>import pandas as pd

myList = [1, 2, 3, 1, 2, 5, 6, 7, 8]
cleanList = pd.Series(myList).drop_duplicates().tolist()
print(cleanList)

#&gt; [1, 2, 3, 5, 6, 7, 8]
</code></pre>
<p>and the order remains preserved.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here's the fastest pythonic solution comaring to others listed in replies.</p>
<p>Using implementation details of short-circuit evaluation allows to use list comprehension, which is fast enough. <code>visited.add(item)</code> always returns <code>None</code> as a result, which is evaluated as <code>False</code>, so the right-side of <code>or</code> would always be the result of such an expression.</p>
<p>Time it yourself</p>
<pre><code>def deduplicate(sequence):
    visited = set()
    adder = visited.add  # get rid of qualification overhead
    out = [adder(item) or item for item in sequence if item not in visited]
    return out
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using <strong><em>set</em></strong> :</p>
<pre><code>a = [0,1,2,3,4,3,3,4]
a = list(set(a))
print a
</code></pre>
<p>Using <strong><em>unique</em></strong> :</p>
<pre><code>import numpy as np
a = [0,1,2,3,4,3,3,4]
a = np.unique(a).tolist()
print a
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Very simple way in Python 3:</p>
<pre><code>&gt;&gt;&gt; n = [1, 2, 3, 4, 1, 1]
&gt;&gt;&gt; n
[1, 2, 3, 4, 1, 1]
&gt;&gt;&gt; m = sorted(list(set(n)))
&gt;&gt;&gt; m
[1, 2, 3, 4]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is an example, returning list without repetiotions preserving order. Does not need any external imports.</p>
<pre><code>def GetListWithoutRepetitions(loInput):
    # return list, consisting of elements of list/tuple loInput, without repetitions.
    # Example: GetListWithoutRepetitions([None,None,1,1,2,2,3,3,3])
    # Returns: [None, 1, 2, 3]

    if loInput==[]:
        return []

    loOutput = []

    if loInput[0] is None:
        oGroupElement=1
    else: # loInput[0]&lt;&gt;None
        oGroupElement=None

    for oElement in loInput:
        if oElement&lt;&gt;oGroupElement:
            loOutput.append(oElement)
            oGroupElement = oElement
    return loOutput
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Check this if you want to remove duplicates (in-place edit rather than returning new list) without using inbuilt set, dict.keys, uniqify, counter</p>
<pre><code>&gt;&gt;&gt; t = [1, 2, 3, 1, 2, 5, 6, 7, 8]
&gt;&gt;&gt; for i in t:
...     if i in t[t.index(i)+1:]:
...         t.remove(i)
... 
&gt;&gt;&gt; t
[3, 1, 2, 5, 6, 7, 8]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think converting to set is the easiest way to remove duplicate:</p>
<pre><code>list1 = [1,2,1]
list1 = list(set(list1))
print list1
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <code>set</code> to remove duplicates:</p>
<pre><code>mylist = list(set(mylist))
</code></pre>
<p>But note the results will be unordered. If that's an issue:</p>
<pre><code>mylist.sort()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>To remove the duplicates, make it a SET and then again make it a LIST and print/use it.
A set is guaranteed to have unique elements. For example : </p>
<pre><code>a = [1,2,3,4,5,9,11,15]
b = [4,5,6,7,8]
c=a+b
print c
print list(set(c)) #one line for getting unique elements of c
</code></pre>
<p>The output will be as follows (checked in python 2.7)</p>
<pre><code>[1, 2, 3, 4, 5, 9, 11, 15, 4, 5, 6, 7, 8]  #simple list addition with duplicates
[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 15] #duplicates removed!!
</code></pre>
</div>
<span class="comment-copy">Your description says you check "a list" for duplicates, but your code checks two lists.</span>
<span class="comment-copy">Can anyone post an answer using loops. I get that it would be "unpythonic" but as a new student of python it would be really helpful.</span>
<span class="comment-copy">It should be noted that this kills the original order.</span>
<span class="comment-copy">It should be noted also that it doesn't work if you have dicts on the list.</span>
<span class="comment-copy">This isn't helpful if list order is important to you.</span>
<span class="comment-copy">And most importantly, the content of the original list must be hashable.</span>
<span class="comment-copy">Actually the fourth comment is inclusive and more general than the second comment. It does not simply re-state the second comment as dicts are only one example of unhashable objects. Lists and sets are other examples of unhashable objects.</span>
<span class="comment-copy">I think this is the only way to keep the items in order.</span>
<span class="comment-copy">@HerberthAmaral: That is very far from true, see <a href="http://stackoverflow.com/q/480214">How do you remove duplicates from a list in Python whilst preserving order?</a></span>
<span class="comment-copy">@MartijnPieters Correcting: I think this is the only <i>simple</i> way to keep items in order.</span>
<span class="comment-copy">For this too, the content of the original list must be hashable</span>
<span class="comment-copy">As @Davide mentioned, the original list must hashable. This means, that this does not work for a list of dictionaries. <code>TypeError: unhashable type: 'dictlist'</code></span>
<span class="comment-copy">Note that this method works in O(n^2) time and is thus very slow on large lists.</span>
<span class="comment-copy">However this works fine for non-hashable content</span>
<span class="comment-copy">@Davide Use a <code>frozenset</code> for non-hashable content</span>
<span class="comment-copy">for me was the best solution</span>
<span class="comment-copy">how to convert this code to list comprehension?</span>
<span class="comment-copy">This has a time complexity of <b>O(n ^ 2)</b>. The answers with <code>set</code> and <code>OrderedDict</code> may have lower amortized time complexity.</span>
<span class="comment-copy">I used in my code this solution and worked great but I think it is time consuming</span>
<span class="comment-copy">@blubberdiblub can you explain what more code efficient mechanism exists in set and OrderedDict that could make them less time consuming? (excluding the overhead of loading them)</span>
<span class="comment-copy">@iliasiliadis The usual implementations of <b>set</b> and <b>dict</b> use hashes or (some form of balanced) trees. You have to consider building the <b>set</b> or <b>dict</b> and searching in it (multiple times), but their amortized complexity usually is still lower than <b>O(n ^ 2)</b>. "Amortized" in simple terms means on average (they can have worst cases with higher complexity than the average case). This is only relevant when you have a big number of items.</span>
<span class="comment-copy">Nice using set quick lookup to speed up the looped comparison.   If order does not matter list(set(x)) is still 6x faster than this</span>
<span class="comment-copy">@Joop, that was my first question for my colleague - the order does matter; otherwise, it would have been trivial issue</span>
<span class="comment-copy">Note that in modern Python versions (2.7+ I think, but I don't recall for sure), <code>keys()</code> returns a dictionary view object, not a list.</span>
<span class="comment-copy">This will convert the list to numpy array which is a mess and won't work for strings.</span>
<span class="comment-copy">@user227666 thanks for your review but that's not true it works even with string and you can add .tolist if you want to get a list...</span>
<span class="comment-copy">I think this is kinda like trying to kill a bee with a sledgehammer. Works, sure! But, importing a library for just this purpose might be a little overkill, no?</span>
<span class="comment-copy">@DebosmitRay it could be useful if you work in Data Science where usually you work with numpy and many times you need to work with numpy array.</span>
<span class="comment-copy">quadratic complexity nonetheless - <code>in</code> is O(n) operation and your <code>cleanlist</code> will have at most <code>n</code> numbers =&gt; worst-case ~O(n^2)</span>
<span class="comment-copy">list comprehensions shouldn't be used for side effects.</span>
<span class="comment-copy"><code>map</code> with a side effect is even more misleading than a listcomp with a side effect. Also, <code>lambda x: unique_list.append(x)</code> is just a clunkier and slower way to pass <code>unique_list.append</code>.</span>
<span class="comment-copy">Very useful way to append elements in just one line, thanks!</span>
<span class="comment-copy">@ZLNK please, don't ever use that. Apart from being conceptually ugly, it's also extremely inefficient, because you actually create a potentially large list and throw it away just to perform basic iteration.</span>
<span class="comment-copy">This is horribly inefficient. <code>list.index</code> is a linear-time operation, making your solution quadratic.</span>
<span class="comment-copy">You're right. But also I believe it's fairly obvious the solution is intended to be a one liner that preserves the order. Everything else is already in here.</span>
<span class="comment-copy">Yet, this solution requires orderable elements. I will use it uniquify my list of lists: it is a pain to <code>tuple()</code> lists and to hash them.  | | | | - Generally speaking, the hash process takes a time proportional to the size of the whole data, while this solution takes a time O(nlog(n)), depending only on the length of the list.</span>
<span class="comment-copy">I think that the set-based approach is equally cheap (O(n log n)), or cheaper, than sorting + detection of uniques. (This approach would parallelize much better, though.) It also does not exactly preserve the initial order, but it gives a predictable order.</span>
<span class="comment-copy">@9000 That is true. I've never mentioned time-complexity of a hash-table-based approach, which is obviously O(n). Here you can find many answers incorporating hash-tables. They are not universal, though, because they require objects to be hashable. Moreover, they are a lot more memory-intensive.</span>
<span class="comment-copy">This should be the accepted answer since the question is <i>how to remove duplicates from a list</i>.</span>
<span class="comment-copy">Why the down-vote?</span>
<span class="comment-copy">It works flawlessly!</span>
<span class="comment-copy">@MeetZaveri glad.!</span>
<span class="comment-copy">1. You should never shadow builtin names (at least, as important as <code>list</code>); 2. Your method scales extremely bad: it is quadratic in the number of elements in <code>list</code>.</span>
<span class="comment-copy">1. Correct, but this was an example; 2. Correct, and that's exactly the reason why I offered it. All solutions posted here have pros and cons. Some sacrifice simplicity or order, mine sacrifices scalability.</span>
<span class="comment-copy">If you don't care about order, then this takes significantly longer. <code>list(set(..))</code> (over 1 million passes) will beat this solution by about 10 whole seconds - whereas this approach takes about 12 seconds, <code>list(set(..))</code> only takes about 2 seconds!</span>
<span class="comment-copy">@dylnmc this is also a duplicate of a significantly older <a href="https://stackoverflow.com/a/25622503/3846213">answer</a></span>
<span class="comment-copy"><code>seen = set(iterable); for item in seen: yield item</code> is almost certainly faster. (I haven't tried this specific case, but that would be my guess.)</span>
<span class="comment-copy">@dylnmc, that's a batch operation, and it also loses the ordering. My answer was specifically intended to be on-the-fly and in order of first occurrence. :)</span>
<span class="comment-copy">Though this might work well, using a heavy library like <i>pandas</i> for this purpose seems like an overkill.</span>
<span class="comment-copy"><code>sorted(list(...))</code> is redundant (<code>sorted</code> already implicitly converts its argument to a new <code>list</code>, sorts it, then returns the new <code>list</code>, so using both means making an unnecessary temporary <code>list</code>). Use only <code>list</code> if the result need not be sorted, use only <code>sorted</code> if the result needs to be sorted.</span>
<span class="comment-copy">Yeah, you are right!</span>
<span class="comment-copy">Use <code>enumerate()</code> to get the index faster: <code>for i, value in enumerate(t): if value in t[i + 1:]: t.remove(value)</code></span>
<span class="comment-copy">won't work if 3 values are same - e.g. <code>[1,1,1]</code></span>
<span class="comment-copy">You can just do: mylist = sorted(list(set(mylist)))</span>
