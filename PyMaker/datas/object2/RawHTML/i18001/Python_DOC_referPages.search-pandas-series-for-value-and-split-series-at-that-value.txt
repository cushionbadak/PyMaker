<div class="post-text" itemprop="text">
<p>Python 3.3.3
Pandas 0.12.0</p>
<p>I have a single column .csv file with hundreds of float values separated by an arbitrary string (the string contains letters edit: <em>and will vary run to run</em>). I'm a pandas beginner, hoping to find a way to load that .csv file and split the float values into two columns at the level of that string.</p>
<p>I'm so stuck at the first part (searching for the string) that I haven't yet been able to work on the second, which I thought should be much easier.</p>
<p>So far, I've been trying to use <code>raw = pandas.read_csv('myfile.csv', squeeze=True)</code>, then something like <code>raw.str.findall('[a-z]')</code>, but I'm not having much luck. I'd really appreciate if someone could lend a hand. I'm planning to use this process on a number of similar .csv files, so I'd hope to find a fairly automated way of performing the task.</p>
<p>Example input.csv:</p>
<pre><code>123.4932
239.348
912.098098989
49391.1093
....
This is a fake string that splits the data.
....
1323.4942
2445.34223
914432.4
495391.1093090
</code></pre>
<p>Desired eventual DataFrame:</p>
<pre><code>Column A         Column B
123.4932         1323.4942
239.348          2445.34223
912.098098989    914432.4
49391.1093       495391.1093090
...              ...
</code></pre>
<p>Thanks again if you can point me in the right direction.</p>
<hr/>
<p>20131123
EDIT: Thank you for the responses thus far. Updated to reflect that the splitting string will not remain constant, hence my statement that I'd been trying to find a solution employing a regex <code>raw.str.findall('[a-z]')</code> instead of using <code>.contains</code>.</p>
<p>My solution at this point is to just read the .csv file and split with <code>re</code>, accumulate into lists, and load those into pandas. </p>
<pre><code>import pandas as pd
import re

raw = open('myfile.csv', 'r').read().split('\n')
df = pd.DataFrame()
keeper = []
counter = 0

# Iterate through the rows. Consecutive rows that can be made into float are accumulated.
for row in raw:
    try:
        keeper.append(float(row))
    except:
        if keeper:
            df = pd.concat([df, pd.DataFrame(keeper, columns = [counter] )], axis = 1)
            counter += 1            
        keeper = []

# Get the last column, assuming the file hasn't ended on a line
# that will trigger the exception in the above loop.
if keeper:
    df = pd.concat([df, pd.DataFrame(keeper, columns = [counter] )], axis = 1)

df.describe()
</code></pre>
<p>Thank you for any further suggestions.</p>
<p>20180729 EDIT2: One other possible solution using <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer"><code>itertools.groupby</code></a>:</p>
<pre><code>import io
import itertools
import re

import numpy as np
import pandas as pd

txt = """123.4932
239.348
912.098098989
49391.1093
This is a fake string that splits the data.
1323.4942
2445.34223
914432.4
495391.1093090
fake again
31323.4942
42445.34223
2914432.4
5495391.1093090
23423432""".splitlines()

groups = itertools.groupby(
        txt,
        key=lambda x: not re.match('^[\d.]+$', x)
)
df = pd.concat(
    (pd.Series(list(g)) for k, g in groups if not k),
    axis=1
)
print(df)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>use <code>numpy.split()</code>:</p>
<pre><code>import io
import numpy as np
import pandas as pd

txt = """123.4932
239.348
912.098098989
49391.1093
This is a fake string that splits the data.
1323.4942
2445.34223
914432.4
495391.1093090
fake again
31323.4942
42445.34223
2914432.4
5495391.1093090
23423432"""

s = pd.read_csv(io.BytesIO(txt), header=None, squeeze=True)
mask = s.str.contains("fake")
pos = np.where(mask)[0]
pos -= np.arange(len(pos))

arrs = [s.reset_index(drop=True) for s in np.split(s[~mask], pos)]
pd.concat(arrs, axis=1, ignore_index=True).astype(float)
</code></pre>
<p>output:</p>
<pre><code>               0               1                2
0       123.4932       1323.4942       31323.4942
1        239.348      2445.34223      42445.34223
2  912.098098989        914432.4        2914432.4
3     49391.1093  495391.1093090  5495391.1093090
4            NaN             NaN         23423432
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you know you only have two columns, then you could do something like</p>
<pre><code>&gt;&gt;&gt; ser = pd.read_csv("colsplit.csv", header=None, squeeze=True)
&gt;&gt;&gt; split_at = ser.str.contains("fake string that splits").idxmax()
&gt;&gt;&gt; parts = [ser[:split_at], ser[split_at+1:]]
&gt;&gt;&gt; parts = [part.reset_index(drop=True) for part in parts]
&gt;&gt;&gt; df = pd.concat(parts, axis=1)
&gt;&gt;&gt; df.columns = ["Column A", "Column B"]
&gt;&gt;&gt; df
        Column A            Column B
0       123.4932                ....
1        239.348           1323.4942
2  912.098098989          2445.34223
3     49391.1093            914432.4
4           ....      495391.1093090
5            NaN  extra test element
</code></pre>
<p>If you have an arbitrary number of places to split at, then you can use a boolean Series/shift/cumsum/groupby pattern, but if you can get away without it, so much the better.</p>
<p>(PS: I'm sure there's a better way than <code>idxmax</code>, but for the life of me I can't remember the idiom to find the first True right now.  <code>split_at[split_at].index[0]</code> would do it, but I'm not sure that's much better.)</p>
</div>
<span class="comment-copy">What is the delimiter, actually?</span>
<span class="comment-copy">Unfortunately the lineterminator arg for read_csv doesn't let you do this (yet?) <code>ValueError: Only length-1 line terminators supported</code></span>
<span class="comment-copy">Yeah, unfortunately, pandas still has trouble with data that is quite <i>that</i> unstructured. In cases like these, the solution involves a text editor or (more conveniently) Unix command line tools.</span>
<span class="comment-copy">This would be yet another use case for my contiguous groupby <a href="https://github.com/pydata/pandas/issues/5494" rel="nofollow noreferrer">enhancement</a>, although we can do this one without too much trouble without it.</span>
<span class="comment-copy">The actual delimiter varies but will always be a sentence that starts with several words, possibly a few numbers and symbols. Should always fail a <code>.match('\d+')</code>.</span>
