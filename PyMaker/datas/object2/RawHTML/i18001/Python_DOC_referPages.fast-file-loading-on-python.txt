<div class="post-text" itemprop="text">
<p>I have two problems with loading data on python, both the scipts work properly but they need too much time to run and sometimes "Killed" is the result (with the first one).</p>
<ol>
<li><p>I have a big zipped text file and I do something like this:</p>
<pre><code>import gzip
import cPickle as pickle

f = gzip.open('filename.gz','r')
tab={}

for line in f:
        #fill tab

with open("data_dict.pkl","wb") as g:
        pickle.dump(tab,g)

f.close()
</code></pre></li>
<li><p>I have to do some operations on the dictionary I created in the previous script</p>
<pre><code>import cPickle as pickle

with open("data_dict.pkl", "rb") as f:
        tab = pickle.load(f)
f.close()

#operations on tab (the dictionary)
</code></pre></li>
</ol>
<p>Do you have other solutionsin mind? Maybe not the ones involving YAML or JSON...</p>
</div>
<div class="post-text" itemprop="text">
<p>If the data you are pickling is primitive and simple, you can try <code>marshal</code> module: <a href="http://docs.python.org/3/library/marshal.html#module-marshal" rel="nofollow">http://docs.python.org/3/library/marshal.html#module-marshal</a>. That's what Python uses to serialize its bytecode, so it's pretty fast.</p>
</div>
<div class="post-text" itemprop="text">
<p>First one comment, in:</p>
<pre><code>with open("data_dict.pkl", "rb") as f:
        tab = pickle.load(f)
f.close()
</code></pre>
<p><code>f.close()</code> is not necessary, the context manager (<code>with</code> syntax) does that automatically.</p>
<p>Now as for speed, I don't think you're going to get too much faster than cPickle for the purpose of reading in something from disk directly as a Python object. If this script needs to be run over and over I would try using <code>memchached</code> via <code>pylibmc</code> to keep the object stored persistently in memory so you can access it lightning fast:</p>
<pre><code>import pylibmc

mc = pylibmc.Client(["127.0.0.1"], binary=True,behaviors={"tcp_nodelay": True,"ketama": True})
d = range(10000)          ## some big object
mc["some_key"] = d        ## save in memory
</code></pre>
<p>Then after saving it once you can access and modify it, it stays in memory even after the previous program finishes its execution:</p>
<pre><code>import pylibmc
mc = pylibmc.Client(["127.0.0.1"], binary=True,behaviors={"tcp_nodelay": True,"ketama": True})
d = mc["some_key"]        ## load from memory
d[0] = 'some other value' ## modify
mc["some_key"] = d        ## save to memory again
</code></pre>
</div>
<span class="comment-copy">Pickle is slow and can be pretty insecure. But you should at least add the hint to use the fastest pickle protocol (see docs):  pickle.HIGHEST_PROTOCOL as a third parameter to your dump. Depending on what you really do, there are lots of other options to speed things up. (e.g. use an sqlite db for example).</span>
<span class="comment-copy">Is the issue that you're loading everything into memory, rather than streaming? If so, you might want to check out streaming pickle (<a href="https://code.google.com/p/streaming-pickle/" rel="nofollow noreferrer">code.google.com/p/streaming-pickle</a>).</span>
