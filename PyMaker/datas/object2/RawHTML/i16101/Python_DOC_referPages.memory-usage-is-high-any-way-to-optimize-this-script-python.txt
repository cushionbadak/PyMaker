<div class="post-text" itemprop="text">
<p>I am trying to compare each record with all other records, while comparing i am returning the index of the elements which are different in both records. </p>
<pre><code>def combinations(records):
    import itertools
    return(itertools.combinations(records,2))

mytuples = tokenize("C:\\Users\\***\\Desktop\\***.data")
data = combinations(mytuples)
new = [([i] for i, t in enumerate(zip(*pair)) if t[0]!=t[1]) for pair in data]
</code></pre>
<p>Initially i thought, reading the file to python takes time and so i tried to execute my code with only reading part, it took only seconds. But when i add this comparison part, its taking lot of memory as it has to compare each record and each element in it. I could see my computer memory usage goes high and reaches the limit (8GB). And my CPU usage is within 50%, so i guess i can assume that the computation is not that intense and so not required to parallelize the process (Correct me if i am wrong).</p>
<p>Is there any way, i can optimize this?</p>
<p>Added after the comment</p>
<pre><code>def tokenize(filename):
    import csv
    with open(filename,'r') as f:
        f_csv = csv.reader(f, delimiter='\t')
        headers = next(f_csv)
        tuple_attr = tuple(headers)
        mytuples = tuple(tuple(x) for x in f_csv)
        return(tuple_attr,mytuples)

def combinations(records):
    import itertools
    return(itertools.combinations(records,2))


tuple_attr,mytuples = tokenize("C:\\****\\trial.data")
data = combinations(mytuples)
new = ((tuple_attr[i] for i, t in enumerate(zip(*pair)) if t[0]!=t[1]) for pair in data)
#print(new)
skt = set(frozenset(temp) for temp in new)
print(skt)
newset = set(s for s in skt if not any(p &lt; s for p in skt))
print(newset)
</code></pre>
<p>Here is my data.. </p>
<pre><code>Age Workclass   Fnlwgt  Education   Education-num
39   State-gov  77516    Bachelors  13
50   Self-emp-not-inc   83311    Bachelors  13
38   Private    215646   HS-grad    9
</code></pre>
<p>And this is my output.</p>
<p>{frozenset({'Age', 'Workclass', 'Fnlwgt'}), frozenset({'Age', 'Workclass', 'Education-num', 'Fnlwgt', 'Education'})}</p>
<p>{frozenset({'Age', 'Workclass', 'Fnlwgt'})}</p>
</div>
<div class="post-text" itemprop="text">
<p>The only massive amount of memory you're using here is the list that you're trying to build.</p>
<blockquote>
<p>the data is 3.5mb, it has 35000 records and each record has 15 elements.</p>
</blockquote>
<p>If <code>mytuples</code> is a list of 35000 15-tuples, then <code>combinations</code> is going to iterate over 612,517,500 pairs of 15-tuples.</p>
<p>The "comparison part", where you unzip that pair of 15-tuples into an iterator over 15 2-tuples, is not going to run out of memory. That's a few KB at worst, not 8GB.</p>
<p>But the fact that you're trying to store a list of a few hundred million single-element lists whose elemnets are integers… well, in 64-bit CPython 3.4, each integer (up to 1&lt;&lt;62) is 28 bytes, and a list takes 8 bytes per element plus a 64-byte header, so you're talking 100 bytes per value, so as soon as you get to around 80 million, that's 8GB.</p>
<p>Your updated version is instead storing a giant list of generators (why?!); generators are at least 64 bytes, or more depending on how much state they have, so it's going to be in the same ballpark.</p>
<hr/>
<p>You can reduce that by storing them in a more compact object. An <a href="https://docs.python.org/3/library/array.html" rel="nofollow"><code>array.array('I')</code></a> or a numpy <a href="http://www.numpy.org/" rel="nofollow"><code>np.ndarray('I4')</code></a> will only use 4 bytes per value instead of 36, so you can get to 2 billion (more than you have) before you run out of memory.</p>
<p>Of course this will only work to store an array of integers, not an array of lists of integers, or an array of generators that yield lists of integers. If you really need lists of integers, you can do that with a 2D array in numpy, but not in <code>array.array</code>. If you really need generators of lists of integers, neither one works.</p>
<p>But I think you can eliminate the top level entirely. What do you need <code>new</code> for?</p>
<blockquote>
<p>I need my results to be in a set of sets. I am converting them after this using skt = set(frozenset(temp) for temp in new)</p>
</blockquote>
<p>If the only thing you're ever doing with <code>new</code> is iterating over it once, you can just use an iterator instead of a list. The easiest way to do that is to change the list comprehension into a generator expression (that is, change those outer square brackets <code>[…]</code> into parentheses <code>(…)</code>). Then you won't be using <em>any</em> memory, except for the memory for the current value and a bit of iterator state.</p>
<p>Given that in the latest versions, you're just storing a bunch of generators, which can only each be iterated once, I can't imagine why you'd need to iterate the collection of them more than once or access them in random order.</p>
<p>But if you can't do this for some reason, and can restructure things, just write the appropriate generator expression and pass it to the <code>array.array</code> constructor or the <code>np.fromiter</code> function. (If you want, <code>array.array</code> can be appended to just like a list, so you could write an explicit <code>for</code> statement, but I don't think you need to.)</p>
<hr/>
<p>So, maybe this is what you want:</p>
<pre><code>new = (([i] for i, t in enumerate(zip(*pair)) if t[0]!=t[1]) for pair in data)
</code></pre>
<p>Or maybe one of these:</p>
<pre><code>new = (i for pair in data for i, t in enumerate(zip(*pair)) if t[0]!=t[1])

new = (i for pair in data for i, t in enumerate(zip(*pair)) if t[0]!=t[1])
new = array.array('I', new)

new = (i for pair in data for i, t in enumerate(zip(*pair)) if t[0]!=t[1])
new = np.fromiter(new, np.int32)
</code></pre>
<p>Or maybe the last one reshaped to be a 2D Nx1 array instead of a 1D array.</p>
</div>
<span class="comment-copy">Do you actually need the results in a list, or just in something you can iterate over?</span>
<span class="comment-copy">Also, how big is <code>data</code>?</span>
<span class="comment-copy">This cannot be the code you are actually running, because there is a syntax error in the last line (mismatched parentheses). <b>Please post the actual, correct code you are running; we can't help you if we don't know what it is.</b></span>
<span class="comment-copy">@DanLenski: The <code>pair</code> is a 2-element tuple, but those elements are 15-element tuples. So it will yield <code>[0][0], [1][0]</code>, then <code>[0][1], [1][1]</code>, … <code>[0][14], [1][14]</code>.</span>
<span class="comment-copy">@Jeeva: I don't understand that question. But I can explain this: a <code>namedtuple</code> acts just like a tuple, except that it also has 15 named attributes, so <code>t.age</code> and <code>t[0]</code> are the same thing <code>t.workclass</code> and <code>t[1]</code> are the same thing, etc. You can compare two values of the same <code>namedtuple</code> type and they'll automatically compare element by element, because they're tuples.</span>
<span class="comment-copy">I changed the list comprehension to generator expression and now the memory usage is low, thats a good part. Thanks for the explanation. But CPU is still in 50% when i try to convert it in to sets. Obviously it was not considered as a problem initially, but i am just wondering if there is any optimized approach to handle this situation.</span>
<span class="comment-copy">@abarnert, am I crazy or do your three possible snippets contain the same mismatched parenthesis syntax error as the original version of the question? They all appear to need an extra <code>(</code> at the beginning of the outer generator expression.</span>
<span class="comment-copy">@DanLenski It was my initial mistake and i corrected it after you asked it. I guess abarnert using the same. No worries, i corrected it now.. :)</span>
<span class="comment-copy">@DanLenski: Sorry, I kept changing it to match the original post, and then stopped at some point, and I guess I last copied it when it was broken, rather than after it was fixed… anyway, it actually needs more of a change than that, because after incorporating one of the fixes it doesn't actually make sense anymore. I'll accept the edit and then edit some more…</span>
<span class="comment-copy">@Jeeva: For an optimized approach… well, what exactly are you trying to optimize here? Is the process taking more time than seems reasonable for comparing 600 million pairs of tuples?</span>
