<div class="post-text" itemprop="text">
<p>I'm trying to write a script in Python for sorting through files (photos, videos), checking metadata of each, finding and moving all duplicates to a separate directory. Got stuck with the metadata checking part. Tried os.stat - doesn't return True for duplicate files. Ideally, I should be able to do something like :  </p>
<pre><code>if os.stat("original.jpg")== os.stat("duplicate.jpg"):  
    shutil.copy("duplicate.jpg","C:\\Duplicate Folder") 
</code></pre>
<p>Pointers anyone?</p>
</div>
<div class="post-text" itemprop="text">
<p>There's a few things you can do. You can compare the contents or hash of each file or you can check a few select properties from the os.stat result, ex</p>
<pre><code>def is_duplicate(file1, file2):
    stat1, stat2 = os.stat(file1), os.stat(file2)
    return stat1.st_size==stat2.st_size and stat1.st_mtime==stat2.st_mtime
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A basic loop using a <code>set</code> to keep track of already encountered files:</p>
<pre><code>import glob
import hashlib

uniq = set()
for fname in glob.glob('*.txt'):
    with open(fname,"rb") as f:
        sig = hashlib.sha256(f.read()).digest()
        if sig not in uniq:
            uniq.add(sig)
            print fname
        else:
            print fname, " (duplicate)"
</code></pre>
<p>Please note as with any hash function there is a slight chance of <a href="http://en.wikipedia.org/wiki/Collision_%28computer_science%29" rel="nofollow noreferrer">collision</a>. That is two different files having the same digest. Depending your needs, this is acceptable of not.</p>
<p>According to <a href="https://stackoverflow.com/a/4014407/2363712">Thomas Pornin in an other answer</a> : </p>
<blockquote>
<p>"For instance, with SHA-256 (<em>n=256</em>) and one billion messages (<em>p=10<sup>9</sup></em>) then the probability [of collision] is about <em>4.3*10<sup>-60</sup></em>."</p>
</blockquote>
<hr/>
<p>Given your need, if you have to check for additional properties in order to identify "true" duplicates, change the <code>sig = ....</code>line to whatever suits you. For example, if you need to check for "same content" and "same owner" (<code>st_uid</code>as returned by <a href="https://docs.python.org/2/library/os.html#os.stat" rel="nofollow noreferrer"><code>os.stat()</code></a>), write:</p>
<pre><code>    sig = ( hashlib.sha256(f.read()).digest(), 
            os.stat(fname).st_uid )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If two files have the same <code>md5</code> they are exact duplicates. </p>
<pre><code>from hashlib import md5
with open(file1, "r") as original:
    original_md5 = md5(original.read()).hexdigest()
    with open(file2, "r") as duplicate:
       duplicate_md5 = md5(duplicate.read()).hexdigest()
       if original_md5 == duplicate_md5:
          do_stuff()
</code></pre>
<p>In your example you're using <code>jpg</code> file in that case you want to call the method <code>open</code> with its second argument equals to <code>rb</code>. For that see the documentation for <a href="https://docs.python.org/2/library/functions.html#open" rel="nofollow">open</a></p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/2/library/stat.html" rel="nofollow">os.stat</a> offers information about some file's metadata and features, including the <strong>creation time</strong>. That is not a good approach in order to find out if two files are the same. </p>
<p>For instance: Two files can be the same and have different time creation. Hence, comparing stats will fail here. <em>Sylvain Leroux</em> approach is the best one when combining performance and accuracy, since it is very rare two different files has the same hash.</p>
<p>So, unless you have an incredibly large amount of data and a repeated file will  cause a system fatality, this is the way to go.</p>
<p>If that your case (it not seems to be), well ...  the only way you can be 100% sure two file are the same is iterating and perform a comparison byte per byte.</p>
</div>
<span class="comment-copy">Would it be enough to use <a href="https://docs.python.org/3/library/hashlib.html" rel="nofollow noreferrer">hashlib</a>?</span>
<span class="comment-copy"><i>"checking metadata of each"</i> What are exactly "duplicates" for you? Same content ? Or same content and same meta data (which ones?)</span>
<span class="comment-copy">whats your os ?</span>
<span class="comment-copy">Duplicates would be files with the same content, so I assumed they would also have the same metadata (in all fields). I might be wrong. My os is Windows 7 Home Basic</span>
<span class="comment-copy">Take a look at the <code>filecmp</code> module in the standard library. It should do what you want.</span>
<span class="comment-copy">“If two files have the same <code>md5</code> they are exact duplicates.” <a href="http://th.informatik.uni-mannheim.de/people/lucks/HashCollisions/" rel="nofollow noreferrer">Demonstrably false.</a></span>
