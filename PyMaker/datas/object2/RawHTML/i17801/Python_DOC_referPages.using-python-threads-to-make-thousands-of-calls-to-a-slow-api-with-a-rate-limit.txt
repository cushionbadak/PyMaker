<div class="post-text" itemprop="text">
<p>I want to make thousands of calls to an API which is kind of slow -- tens of seconds to get a response. The only limit is that I can make at most one request per second. What's the best way to do this? I think the following code works, but I feel I should be able to make better use of the threading library somehow. I'm using python 3.3</p>
<pre><code>last_job = datetime.now()
for work in work_list:
    while (datetime.now()-last_job).total_seconds() &lt; 1 or threading.active_count() &gt;= max_threads:
        time.sleep(.1)
    threading.Thread(target=work_function, args=[work]).start()
    last_job = datetime.now()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you want to run a bunch of jobs using a fixed-size thread pool, you can use <a href="http://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor" rel="nofollow noreferrer"><code>concurrent.futures.ThreadPoolExecutor</code></a>, like this:</p>
<pre><code>from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=5) as executor:
    for work in work_list:
        executor.submit(work_function, work)
</code></pre>
<p>If you want to ensure that you make at most one API call a second, then you need to do this from inside your <code>work_function</code>. You can't do it when submitting the job, because you don't know how long the job will queue up waiting for a thread to become available.</p>
<p>If it were me, I'd put the rate limiting code into its own class so that it's reusable:</p>
<pre><code>from collections import Iterator
from threading import Lock
import time

class RateLimiter(Iterator):
    """Iterator that yields a value at most once every 'interval' seconds."""
    def __init__(self, interval):
        self.lock = Lock()
        self.interval = interval
        self.next_yield = 0

    def __next__(self):
        with self.lock:
            t = time.monotonic()
            if t &lt; self.next_yield:
                time.sleep(self.next_yield - t)
                t = time.monotonic()
            self.next_yield = t + self.interval

api_rate_limiter = RateLimiter(1)

def work_function(work):
    next(api_rate_limiter)
    call_api(...)
</code></pre>
<p><a href="https://docs.python.org/3/library/time.html#time.monotonic" rel="nofollow noreferrer"><code>time.monotonic</code></a> was introduced in Python 3.3; in older versions of Python you could use <a href="https://docs.python.org/3/library/time.html#time.time" rel="nofollow noreferrer"><code>time.time</code></a> but this can jump backwards when the system clock changes, so you would need to ensure that this doesn't cause overlong sleeps:</p>
<pre><code>                time.sleep(min(self.next_yield - t, self.interval))
</code></pre>
</div>
<span class="comment-copy">Did I get right that you can make a request per second, so while you wait 20 secs for 1st query result, you can instantiate another 19? Won't those additional 19 queries slow down response for the first one?</span>
<span class="comment-copy">Why not use Celery to queue the jobs and set the rate limit?</span>
<span class="comment-copy">@adam isn't it a bit overkill for this task?</span>
<span class="comment-copy">@alko based on my experience of working with other people's API, I find it very beneficial to log whether there is a valid response or why the request failed, especially when something starts to go south. Celery can also keep track of these things.</span>
<span class="comment-copy">@alko instantiating 19 more requests does not appear to slow down the first one.</span>
<span class="comment-copy">This works beautifully, thank you.</span>
<span class="comment-copy">When I implement this solution, I get the error "TypeError: Can't instantiate abstract class RateLimiter with abstract methods next"</span>
<span class="comment-copy">@Greg: You are using Python 2.7, is that right? The method was called <code>next</code> in Python 2.</span>
