<div class="post-text" itemprop="text">
<p><strong>What is the big O of del my_list[:]?</strong> This command deletes all elements in the list. My understanding is that it will be O(n). n being the length of the list.</p>
<p><strong>Therefore the big O of this code would be bigO(n^2), correct?</strong></p>
<p>Note this is not for school, but rather for my understanding while I practice for interviews.</p>
<pre><code>from copy import deepcopy
class Solution:
    # @param A : list of integers
    # @return an integer
    def removeDuplicates(self, A):
        copy_array = deepcopy(A)
        del A[:]

        for j in copy_array:
            if j in A:
                pass
            else:
                A.append(j)

        return len(A)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The <code>del</code> doesn't impact big-O here, the loop is order <code>n</code> and the <code>j in A</code> test is order <code>n</code>, so the nested loop is <code>O(n**2)</code>; the <code>del</code> is <code>O(n)</code>, but it's not part of the loop, and since it's a lower order of work, it's ignored.</p>
<p>Side-note: A <code>O(n)</code> solution for this would be to use <a href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" rel="noreferrer"><code>collections.OrderedDict</code></a> to dedup, preserving order, making the body of the method just:</p>
<pre><code>A[:] = collections.OrderedDict.fromkeys(A)
return len(A)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>def removeDuplicates(self, A):
    copy_array = deepcopy(A)        --&gt; O(N)
    del A[:]                        --&gt; O(N)

    for j in copy_array:            --&gt; O(N)
        if j in A:                  --&gt; O(N)
            pass
        else:
            A.append(j)             --&gt; O(1)

    return len(A)                   --&gt; O(1)
</code></pre>
<p>The complexity would be 2O(N)+O(N)*O(N)+O(1) = O(2N+N^2+1) = O(N^2)</p>
</div>
<div class="post-text" itemprop="text">
<p>as noted in the comment and other answers, in your case it doesn't matter whether the deletion is O(n), because this is a once-only operation, and your loop is already O(n^2).</p>
<p>Still, your question about <code>del A[:]</code> is interesting and worth addressing:</p>
<p>According to the Python wiki's <a href="https://wiki.python.org/moin/TimeComplexity" rel="nofollow noreferrer">page on time complexity</a>, deleting a slice from a list is indeed O(n). </p>
<p>However, since lists are represented internally as arrays, and operations on <code>[:]</code> are essentially reassigning the entire array, and the old array can be garbage-collected at some later point, I think it's probably possible that this case can actually be optimized in the implementation so that the <em><code>del</code> statement itself</em> is O(1), and the actual cleanup of the old array is delayed The algorithmic cost may still be O(n), but this could nevertheless have the advantage of deferring some of the work to remove it from a computational "hot spot" in your program.</p>
<p>Per the first comment below, though, the main implementation of Python, CPython, uses reference-counting; this means that <code>del</code> must actually decrement the reference count for each item contained in the list, which is O(n).</p>
<p>PyPy, however, <a href="https://pypy.readthedocs.io/en/release-2.4.x/garbage_collection.html" rel="nofollow noreferrer">has configurable garbage collection</a>, and all of the supported collectors seem to be based on a generational-copying scheme, which <strong>does</strong> permit the optimization. Moreover, in a copying scheme, the memory containing the old objects can typically just be ignored rather than properly de-allocated, so the actual deferred cost might actually be <em>free</em> (in the sense that the <code>del</code> statement makes the next generational-copy <em>cheaper</em>, since the original array no longer needs to be copied). The data allocated for the "ignored" objects may still be <em>cleared</em> (and indeed the PyPy link indicates that its generational GC does do this), but since the entire old memory space is cleared, I am not sure that it matters how much of this space is actually populated.</p>
<p><strong>NOTE</strong>, however, that objects that require special cleanup operations, i.e. objects that implement <code>__del__</code>, are a special case and <strong>cannot</strong> simply be "ignored" during the generational copy, so de-allocating an array of objects with <code>__del__</code> <strong>must</strong> always be O(n). The linked page has a few details on how these objects are handled.</p>
</div>
<span class="comment-copy">As far as I can tell, it's quadratic, but because of the membership test on A, not because of the <code>del A[:]</code> since that happens outside of the loop.</span>
<span class="comment-copy">Ahh yes, completely forgot that it won't count since it's a lower order. And the one liner is quite neat. Thanks so much.</span>
<span class="comment-copy">CPython <i>can't</i> do this, it's reference counted, so it must individually decrement the reference count on every item in the <code>list</code> (so definitely <code>O(n)</code>). Even on a GC system, this would count as <code>O(n)</code> because the per-item cost must be paid eventually; sure, the cost may not be paid now, but you can't cheat your way out of big-O by deferring costs; launching a thread to do your work doesn't mean you didn't do the work after all. :-)</span>
<span class="comment-copy">@ShadowRanger Thanks; I hadn't really looked into it. I've added some details indicating that CPython uses reference counting (which prohibits the optimization) but PyPy uses generational gc. I think (and have written above) that generational gc <i>does</i> allow precisely the "cheating" that you describe, <i>except</i> in the case of objects requiring cleanup with <code>__del__</code>. I've explained why in the edit--if you think my reasoning is faulty, please let me know!</span>
