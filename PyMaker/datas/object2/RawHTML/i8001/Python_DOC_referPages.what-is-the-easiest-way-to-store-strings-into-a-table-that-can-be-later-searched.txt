<div class="post-text" itemprop="text">
<p>I download different links, I do not control which links are downloaded, so I want my program to be able to tell if that link has been downloaded before, if it has, then skip the link and keep going with the loop that it is currently in.</p>
<pre><code>while True:
    print("--Sleeping for 30 seconds")
    time.sleep(30)

    submissions = r.get_subreddit(sub).get_random_submission()

    print('--Submission Found in ' + sub)
    print("--Submission.url: ", submissions.url)

    if submissions.url in urlArray.urllist:
        print("--This url has already been downloaded")
        continue

    print("--Adding url to array")
    urlArray.urllist.append(submissions.url)



    url = urllib.parse.unquote(submissions.url)
    #if url doesnt have jpg and doesnt have "gallery" or "/a/"
    if(not jpg in url and imgur in url and not "gallery" in url and not "/a/" in url):
        print("--Url without jpg format: ", url)
        jpgURL = submissions.url + ".jpg"
        print("--Remade url is: ", jpgURL)
        imgur_name2 = id_gen()
        newurl2 = jpgURL.split('/')[-1].split('.')[0]
        im.get_image(newurl2).download(path="C:\\Users\\KEVIN\\Pictures\\temp_pics", name=imgur_name2, overwrite=False, size=None)
        print("--Downloaded remade url")

    if jpg in url and imgur in url:


        newurl = url.split('/')[-1].split('.')[0]
        imgur_name = id_gen()
        temp_pic = imgur_name + ".jpg"
        print("--Downloading Image through Imgur")
        im.get_image(newurl).download(path="C:\\Users\\KEVIN\\Pictures\\temp_pics", name=imgur_name, overwrite=False, size=None)



    if reddit in url:
        reddit_gen = id_gen()
        reddit_pic = reddit_gen + ".jpg"
        print("\n" + "--Downloading through I.Reddit")
        request.urlretrieve(url, "C:\\Users\\KEVIN\\Pictures\\temp_pics\\" + reddit_pic)

    if not reddit in url and not redd in url and not imgur in url and jpg in url:
        print("--Not reddit or imgur but I can download the image")
        randomGen = id_gen()
        request.urlretrieve(url, "C:\\Users\\KEVIN\\Pictures\\temp_pics\\" + randomGen + ".jpg")
        print("--Downloaded", "This image ID is: ", randomGen)
</code></pre>
<p>Here in this loop I am using an array to handle URL duplicates, but as you already know, as soon as I restart the program everything is erased.</p>
</div>
<div class="post-text" itemprop="text">
<p>Save it to a csv.  This is what I do when I need to be able to keep information from one code execution to another.  Then you can just load the csv in when the program executes again.</p>
<pre><code>import csv

websites = ["www.example.com/1","www.example.com/2"]

with open('history.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(websites)

with open('history.csv', newline='') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)
</code></pre>
<p>See <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer">https://docs.python.org/3/library/csv.html</a> for more details on using csv.</p>
</div>
<div class="post-text" itemprop="text">
<p>If performance is an issue, I would hash the normalized URL and save the hash to a database or a list using the bisect module to keep it ordered. Comparing hashes is faster than comparing strings and more space efficient.</p>
</div>
<span class="comment-copy">So you're saving these in the <code>urlArray</code>, you're just having problems storing it for when you start the script backup?  You could always use <a href="https://docs.python.org/2/library/pickle.htm" rel="nofollow noreferrer">pickle</a>.</span>
<span class="comment-copy">In general, just drop the strings into a <code>set</code>.  When you get a new URL, see whether it's <code>in</code> the set already.</span>
