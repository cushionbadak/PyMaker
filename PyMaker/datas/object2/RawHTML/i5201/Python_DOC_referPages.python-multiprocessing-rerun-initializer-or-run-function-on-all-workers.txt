<div class="post-text" itemprop="text">
<p>With multiprocessing, it is possible to execute the same function on all workers at creation time of the pool with the <code>initializer</code> and <code>initargs</code> options in the <code>Pool</code> factory function.</p>
<p>Is it possible to run something, with a guarantee, on all workers?  I would like to do this periodically, but realize it is not a very popular use case and may not be possible without re-implementing Pool based on multiprocessing primitives...</p>
</div>
<div class="post-text" itemprop="text">
<p>You can simply use a <a href="https://docs.python.org/3/library/threading.html#timer-objects" rel="nofollow noreferrer"><code>Timer</code></a> to ensure the initializer is called once again after a given interval. </p>
<p>This is a pretty standard way to re-schedule an action periodically.</p>
<pre><code>from threading import Timer
from multiprocessing import Pool

def initializer(interval: float):
    update_global_state()

    timer = Timer(interval, initializer, args=[interval])
    timer.start()

pool = Pool(initializer=initializer, initargs=[STATE_UPDATE_INTERVAL])
</code></pre>
<p>Each worker of the <code>Pool</code> will update its state periodically and independently.</p>
<p>EDIT:</p>
<p>The <code>Pool</code> design paradigm goal is to abstract the management of tasks and workers de-coupling the main loop from the execution of the jobs. While doing so, it restricts the access to the workers to protect the overall logic.</p>
<p>If what you need is to share and update the state among the workers, the only feasible approach is to let the workers poll for state updates. You can either use the above approach or let the worker check the state at any new job.</p>
<p>As a <code>Pool</code> is asynchronous by design, there is no way to synchronously provide information to the workers. </p>
</div>
<div class="post-text" itemprop="text">
<p>If what you want to run has nothing to do with the task submitted to pool, you can simply replace <code>Pool.Process</code> with your own version, which add initializer at first.</p>
<pre><code>from multiprocessing.pool import Pool as PoolCls
from multiprocessing import Pool, Process


class MyProcess(Process):
    def start(self):
        print 'do something you want...'
        super(MyProcess, self).start()

# use our own Process instead, should before creating pool
PoolCls.Process = MyProcess
</code></pre>
<p>Note that the statements added in <code>start()</code> are ran in current process, not the work process. Overwrite <code>run()</code> if you want to run in each work process.</p>
</div>
<span class="comment-copy">Please explain better what you are trying to achieve. What do you mean by "run something, with a guarantee"?</span>
<span class="comment-copy">A pool can have <code>map</code> or <code>map_async</code> or the apply variants of those used to submit jobs to be completed.  If, for example, I have a 4-process pool and submit 4 jobs, there is no guarantee that all 4 processes are done.  Thus, I cannot duplicate the work <code>num_processes</code> times and have the program work every time.  I use a pool to do some heavy lifting with some read-only global state (similar to a Value object but without the penalty of locks).  Periodically, I would like to update that global state without destroying the pool and making a new one.</span>
<span class="comment-copy">By "periodically" I meant "on demand" - so the spawning / producer process would send a signal to each worker.  I would something like <code>p = Pool(...); p.map(func, [args]); p.run_on_all_workers(func, args);</code></span>
<span class="comment-copy">From the parent process you have no easy way to ensure the workers won't be busy at the time the signal is delivered which means you might end up with inconsistent state across the workers. The safest way would be waiting for the workers to be idle and update the state. Though it would not make a great difference from re-creating a new Pool with updated state.</span>
<span class="comment-copy">On windows, all of <code>__main__</code> is rerun on each worker when the pool spawns, this can be quite expensive.  I believe if you only use pool.map to distribute work, the state cannot go out of sync.</span>
