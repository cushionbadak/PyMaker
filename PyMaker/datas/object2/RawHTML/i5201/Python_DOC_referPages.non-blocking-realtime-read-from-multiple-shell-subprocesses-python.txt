<div class="post-text" itemprop="text">
<p>I'm building real time multiple videostream monitoring using <a href="https://ffmpeg.org/ffmpeg.html" rel="nofollow noreferrer">ffmpeg</a> and <a href="https://docs.python.org/3/library/subprocess.html" rel="nofollow noreferrer">subrocess</a>. 
I currently have the following code, inspired by <a href="https://fredrikaverpil.github.io/2017/06/20/async-and-await-with-subprocesses/" rel="nofollow noreferrer">"Async and await with subprocesses" post</a>.</p>
<p>The problem is that after a certain period of time the output stops printing and the processes go into zombie mode. I guess that this problem is related to the overload of PIPE or deadlock. Help needed.</p>
<pre><code>"""Async and await example using subprocesses

Note:
    Requires Python 3.6.
"""

import os
import sys
import time
import platform
import asyncio

async def run_command_shell(command):
    """Run command in subprocess (shell)

    Note:
        This can be used if you wish to execute e.g. "copy"
        on Windows, which can only be executed in the shell.
    """
    # Create subprocess
    process = await asyncio.create_subprocess_shell(
        command,
        stderr=asyncio.subprocess.PIPE)

    # Status
    print('Started:', command, '(pid = ' + str(process.pid) + ')')

    # Wait for the subprocess to finish
    stdout, stderr = await process.communicate()

    # Progress
    if process.returncode == 0:
        print('Done:', command, '(pid = ' + str(process.pid) + ')')
    else:
        print('Failed:', command, '(pid = ' + str(process.pid) + ')')

    # Result
    result = stderr.decode().strip()

    # Real time print
    print(result)

    # Return stdout
    return result


def make_chunks(l, n):
    """Yield successive n-sized chunks from l.

    Note:
        Taken from https://stackoverflow.com/a/312464
    """
    if sys.version_info.major == 2:
        for i in xrange(0, len(l), n):
            yield l[i:i + n]
    else:
        # Assume Python 3
        for i in range(0, len(l), n):
            yield l[i:i + n]


def run_asyncio_commands(tasks, max_concurrent_tasks=0):
    """Run tasks asynchronously using asyncio and return results

    If max_concurrent_tasks are set to 0, no limit is applied.

    Note:
        By default, Windows uses SelectorEventLoop, which does not support
        subprocesses. Therefore ProactorEventLoop is used on Windows.
        https://docs.python.org/3/library/asyncio-eventloops.html#windows
    """

    all_results = []

    if max_concurrent_tasks == 0:
        chunks = [tasks]
    else:
        chunks = make_chunks(l=tasks, n=max_concurrent_tasks)

    for tasks_in_chunk in chunks:
        if platform.system() == 'Windows':
            loop = asyncio.ProactorEventLoop()
            asyncio.set_event_loop(loop)
        else:
            loop = asyncio.get_event_loop()

        commands = asyncio.gather(*tasks_in_chunk)  # Unpack list using *
        results = loop.run_until_complete(commands)
        all_results += results
        loop.close()
    return all_results


if __name__ == '__main__':

    start = time.time()

    if platform.system() == 'Windows':
        # Commands to be executed on Windows
        commands = [
            ['hostname']
        ]
    else:
        # Commands to be executed on Unix
        commands = [
            ['du', '-sh', '/var/tmp'],
            ['hostname'],
        ]
    cmds = [["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx  -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"],
            ["ffmpeg -y -i udp://xxx.xx.xx.xxx:xxxx -f null -"]]

    tasks = []
    for command in cmds:
        tasks.append(run_command_shell(*command))


    # # Shell execution example
    # tasks = [run_command_shell('copy c:/somefile d:/new_file')]

    # # List comprehension example
    # tasks = [
    #     run_command(*command, get_project_path(project))
    #     for project in accessible_projects(all_projects)
    # ]

    results = run_asyncio_commands(tasks, max_concurrent_tasks=20)  # At most 20 parallel tasks
    print('Results:', results)

    end = time.time()
    rounded_end = ('{0:.4f}'.format(round(end-start,4)))
    print('Script ran in about', str(rounded_end), 'seconds')
</code></pre>
<p>Related: <a href="https://stackoverflow.com/questions/17667004/non-blocking-read-from-multiple-subprocesses-python">Non-blocking read from multiple subprocesses (Python)</a></p>
</div>
<div class="post-text" itemprop="text">
<p>It turned out that the problem is <em>probably not related</em> to code optimization through <em>multithreading</em>, <em>asyncio</em>, etc.</p>
<p>The reason may be server limitations, such as maximum number of open files / file descriptors (FD), firewall, other config files.</p>
<h1>If you stumbled upon a similar problem:</h1>
<hr/>
<h2>Install htop</h2>
<p><a href="https://www.tecmint.com/install-htop-linux-process-monitoring-for-rhel-centos-fedora/" rel="nofollow noreferrer">Htop</a> is an interactive real time process monitoring application for Linux/Unix like systems and also a handy alternative to <a href="https://www.tecmint.com/12-top-command-examples-in-linux/" rel="nofollow noreferrer"><code>top</code></a> command, which is default process monitoring tool that comes with pre-installed on all Linux operating systems.</p>
<p>This may be useful for clarifying the reasons.</p>
<hr/>
<h2>Test single ffmpeg command</h2>
<p>As jfs said, I need <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a> . So we start with a very minimal: test one process.</p>
<pre><code>ffmpeg -y -i udp://224.10.0.123:1234  -f null -
</code></pre>
<blockquote>
<p>In my case it turned out that any multicast will hang in 2:10 - 2:20
  minutes. Process alive but in zombie mode. This is very strange,
  because a couple of days ago everything worked perfectly.</p>
</blockquote>
<hr/>
<h2>Test another soft (<a href="https://www.videolan.org/projects/multicat.html" rel="nofollow noreferrer">VLC's multicat</a>)</h2>
<p>The latest official version of Multicat is numbered 2.2, and is available <a href="https://get.videolan.org/multicat/2.2/multicat-2.2.tar.bz2" rel="nofollow noreferrer">here</a>.</p>
<p>Get it and don't forget, that <a href="https://www.videolan.org/developers/bitstream.html" rel="nofollow noreferrer">biTStream</a> needs to be installed at build-time.</p>
<p>Check the stream using the command to record video from the stream:</p>
<pre><code>timeout 10 multicat -uU @224.10.0.123:1234 test.ts
</code></pre>
<blockquote>
<p>In my case, the same thing happened on the 2nd minute. The command does not stop executing, but the file ceased to be recorded.</p>
</blockquote>
<hr/>
<h2>Check Maximum number of open files / file descriptors <em><a href="https://www.cyberciti.biz/faq/linux-increase-the-maximum-number-of-open-files/" rel="nofollow noreferrer">more info</a></em></h2>
<p>Use the following command command to display maximum number of open file descriptors:</p>
<pre><code>cat /proc/sys/fs/file-max
</code></pre>
<p>To see the hard and soft values, issue the command as follows:</p>
<pre><code>ulimit -Hn
ulimit -Sn
</code></pre>
<blockquote>
<p>At some point in the execution of one of my python scripts, I saw a similar error, but the increase in this parameter did not help me.</p>
</blockquote>
<hr/>
<h2>Summary</h2>
<p>So the problem is not related to the parallel execution of my scripts. Verification on another virtual machine was successful. I contacted the person who set up this virtual machine and explained to him that something broke during the last couple of days, suggested that the problem is in the firewall. He said that he did not touch anything. But after this call everything began to work perfectly. <em>(I'm almost sure that he broke it)</em> :D</p>
<p>GL everyone!</p>
</div>
<span class="comment-copy">Create a <i>minimal</i> code example that demonstrates the problem. If you can reproduce it with a single <code>run_command_shell()</code> then drop other calls.  If you can reproduce it with a dummy python script instead of <code>ffmpeg</code> with an unknown video stream then use that. <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a>¶ You don't need more than one loop here, move the loop creation code into <code>if __name__ == "__main__"</code>. <code>loop.close()</code> should be the very last thing in your program¶ You don't need the shell here. You can run commands directly¶  You read all output at once waiting until child processes end — it is not "non-blocking realtime read"</span>
<span class="comment-copy">a simple way to run <code>n</code> parallel processes at a time is a thread pool. <a href="https://stackoverflow.com/q/23611396/4279">Python: execute cat subprocess in parallel</a>. In an <code>asyncio</code> solution, you could <a href="https://stackoverflow.com/a/31795242/4279">use a <code>Semaphore()</code> to limit the number of concurrent tasks</a></span>
