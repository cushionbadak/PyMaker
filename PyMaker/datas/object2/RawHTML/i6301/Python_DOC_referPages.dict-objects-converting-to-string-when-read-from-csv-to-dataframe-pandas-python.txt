<div class="post-text" itemprop="text">
<p>I have a csv file, which has got many columns. One column contains data in the form of dict objects as well as strings.</p>
<p>For eg: Column contains data like : {"a":5,"b":6,"c":8},"usa","india",{"a":9,"b":10,"c":11}</p>
<p>When I read this csv into a dataframe using :</p>
<pre><code>df = pd.read_csv(path)
</code></pre>
<p>this column data is <strong>recognised as string</strong> when i did <code>df.applymap(type)</code>
to check the type of each element stored in this particular column.</p>
<p>But data does not have quotes around it neither in csv nor in the dataframe. But still dict objects are converted to string and stored in dataframe.</p>
<p>On checking type of column, it turns out to be object.</p>
<p>Please suggest how to read from csv into dataframe such that dict objects are recognised as dict and strings as strings in this particular column.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can convert the strings that should be dicts (or other types) using <a href="https://docs.python.org/3/library/ast.html#ast.literal_eval" rel="nofollow noreferrer"><code>literal_eval</code></a>:</p>
<pre><code>from ast import literal_eval

def try_literal_eval(s):
    try:
        return literal_eval(s)
    except ValueError:
        return s
</code></pre>
<p>Now you can apply this to your DataFrame:</p>
<pre><code>In [11]: df = pd.DataFrame({'A': ["hello","world",'{"a":5,"b":6,"c":8}',"usa","india",'{"d":9,"e":10,"f":11}']})

In [12]: df.loc[2, "A"]
Out[12]: '{"a":5,"b":6,"c":8}'

In [13]: df
Out[13]:
                       A
0                  hello
1                  world
2    {"a":5,"b":6,"c":8}
3                    usa
4                  india
5  {"d":9,"e":10,"f":11}


In [14]: df.applymap(try_literal_eval)
Out[14]:
                            A
0                       hello
1                       world
2    {'a': 5, 'b': 6, 'c': 8}
3                         usa
4                       india
5  {'d': 9, 'e': 10, 'f': 11}

In [15]: df.applymap(try_literal_eval).loc[2, "A"]
Out[15]: {'a': 5, 'b': 6, 'c': 8}
</code></pre>
<p>Note: This is pretty expensive (time-wise) as far as other calls go, however when you're dealing with dictionaries in DataFrames/Series you're necessarily defaulting back to python objects so things are going to be relatively slow... It's probably a good idea to denormalize i.e. get the data back as columns e.g. using <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.json.json_normalize.html" rel="nofollow noreferrer"><code>json_normalize</code></a>.</p>
</div>
<span class="comment-copy">That's how pandas represents complex data types.</span>
<span class="comment-copy">@cᴏʟᴅsᴘᴇᴇᴅ This came from an earlier question, where the entries happened to be strings rather than dicts. I guess the subtle difference that could have highlighted that was "a" rather than 'a'!</span>
<span class="comment-copy">@AndyHayden Yes, I just saw that. Thank you for the enriching answers, I've learned a lot from them.</span>
<span class="comment-copy">I guess the json_normalize advice is somewhat unnecessary since you are coming from this question <a href="https://stackoverflow.com/a/46856679/1240268">stackoverflow.com/a/46856679/1240268</a></span>
<span class="comment-copy">i need to remove all the string rows and convert dict objects to columns. So, for this conversion in need to make use of json_normalize.  As said, I have many columns in dataframe but I want to do apply map thing on a particular column, how do i do that 'df.applymap(try_literal_eval)' in this code. like specifying my column name</span>
<span class="comment-copy">@NikitaGupta e.g <code>df.A.apply(try_literal_eval)</code></span>
