<div class="post-text" itemprop="text">
<p>Using Python 3, how does the following return <code>True</code> ?</p>
<pre><code>a = 2/3
b = 4/6
print(a == b)
</code></pre>
<p>I have an algorithm that requires sorting a list of numbers which are each of the form x/y where x and y are integers. (y != 0).</p>
<p>I was concerned that the numerical precision of the division would result in instability and arbitrary ordering of cases such as above. <a href="https://stackoverflow.com/questions/5595425/what-is-the-best-way-to-compare-floats-for-almost-equality-in-python">This being an example of relevant comments.</a>But, as per the example and for larger integers as well, it does not seem to be an issue.</p>
<p>Does Python remove the common factor of 2 from the numerator and denominator of b, and retain information that a and b are not just floats?</p>
</div>
<div class="post-text" itemprop="text">
<p>Python follows the <a href="https://en.wikipedia.org/wiki/IEEE_754" rel="nofollow noreferrer">IEEE 754</a> floating point specification.*  (64-bit) IEEE floats are essentially a form of base 2 <a href="https://en.wikipedia.org/wiki/Scientific_notation" rel="nofollow noreferrer">scientific notation</a>, broken down as follows:</p>
<ul>
<li>One bit for the sign (positive or negative)</li>
<li>53 bits for the mantissa or significand, including the implied leading one.</li>
<li>11 bits for the exponent.</li>
</ul>
<p>Multiplying or dividing a floating point value by two, or any power of two, only affects the exponent, and not the mantissa.**  As a result, it is normally a fairly "stable" operation by itself, so 2/3 should yield the same result as 4/6.  However, IEEE floats still have the following problems:</p>
<ul>
<li>Most operations are not associative (e.g. <code>(a * b) * c != a * (b * c)</code> in the general case).</li>
<li>More complicated operations are not required to be correctly rounded (however, as Tim Peters points out, division certainly is not a "more complicated" operation and will be correctly rounded).***</li>
<li>Intermediate results are always rounded to 53 bits.</li>
</ul>
<p>You should be prepared to handle these issues and assume that most mathematically-equivalent floating point expressions will not result in identical values.  In Python specifically, you can use <a href="https://docs.python.org/3/library/math.html#math.isclose" rel="nofollow noreferrer"><code>math.isclose()</code></a> to estimate whether two floats are "close enough" to be "probably the same value."</p>
<hr/>
<p>* Actually, this is a lie.  Python follows C's <code>double</code>, which nearly always follows IEEE 754 in some fashion, but might deviate from it on sufficiently exotic architectures.  In such cases the C standard provides few or no guarantees, so you will have to look to your architecture or compiler's floating point documentation.</p>
<p>** Provided the exponent does not overflow or underflow.  If it does, then you will typically land on an appropriately-signed infinity or zero, respectively, or you might underflow to a <a href="https://en.wikipedia.org/wiki/Denormal_number" rel="nofollow noreferrer">denormal number</a> depending on architecture and/or how Python was compiled.</p>
<p>*** The exact set of "more complicated" operations varies somewhat because IEEE 754 <a href="https://en.wikipedia.org/wiki/IEEE_754#Recommended_operations" rel="nofollow noreferrer">made a lot of operations optional while still demanding precision</a>. As a result, it is seldom obvious whether a given operation conforms to IEEE 754 or only conforms to the notoriously lax C standard.  In some cases, an operation may conform to no standard whatsoever.</p>
</div>
<div class="post-text" itemprop="text">
<p>Just noting that so long as integers <code>x</code> and <code>y</code> are exactly representable as Python floats, <code>x / y</code> is - on all current machines - the correctly rounded value of the infinitely precise quotient.  That's what the IEEE 754 floating-point standard requires, and all current machines support that.</p>
<p>So the important part in your specific example isn't that the numerator and denominator in <code>b = 4/6</code> have a factor of (specifically!) 2 in common, it's that (a) they have <em>some</em> factor in common; and, (b) 4 and 6 are both exactly representable as Python floats.</p>
<p>So, for example, it's guaranteed that</p>
<pre><code>(2 * 9892837) / (3 * 9892837) == 2 / 3
</code></pre>
<p>is also true.  Because the infinitely precise value of <code>(2 * 9892837) / (3 * 9892837)</code> is the same as the infinitely precisely value of <code>2/3</code>, and IEEE 754 division acts as if the infinitely precise quotient were computed.  And you can replace 9892837 with any other non-zero integer in that, provided that the products remain exactly representable as Python floats.</p>
</div>
<div class="post-text" itemprop="text">
<p>2/3 is the same as 4/6. (2/3)*(2/2) = 2/2 = 1, the identity element.  The response is correct. </p>
</div>
<span class="comment-copy">Sorry I couldnt get your question. Isnt it right!? What is there to be concerned here?</span>
<span class="comment-copy">I think you are talking about different things: identity and equality, 2/3 equals 4/6,  thus <code>2/3==4/6</code> returns <code>True</code>. Now, <code>2/3 is 4/6</code> returns <code>False</code> as they are different elements. Assign a variable to each and compare their <code>id()</code> and you shall see. More info: <a href="https://stackoverflow.com/questions/2239737/is-it-better-to-use-is-or-for-number-comparison-in-python" title="is it better to use is or for number comparison in python">stackoverflow.com/questions/2239737/â€¦</a></span>
<span class="comment-copy">@tokenizer_fsj: OP is asking about floating point accuracy, not object identity.  They're already using the correct comparison operator, so I don't see why you feel the need to correct them anyway.</span>
<span class="comment-copy">Thanks Kevin, that's just what I wanted to know. In reality it's just lucky that for simple enough cases they remain equal but any reliance on this will lead to brittle code in general.</span>
<span class="comment-copy">2 and 2.0 really have nothing to do with why this example works.  <code>(n*x)/(n*y) == x/y</code> for any integers such that <code>n*y</code> isn't 0, and <code>n*x</code> and <code>n*y</code> are both exactly representable as Python floats.</span>
<span class="comment-copy">Yeah, I realized that.  I was confusing your "infinitely precise quotient" with the infinitely precise integers that are going into the divisor and dividend.</span>
<span class="comment-copy">This does not answer the actual question being asked.  The question being asked is about the precision and possible instability between the two expressions.  It's certainly equivalent in theory, but can you guarantee that this is the same for these kinds of expressions on your CPU?  Kevin's answer above actually answers the question at hand.</span>
