<div class="post-text" itemprop="text">
<p>I'm trying to implement an efficient way of creating a frequency table in python, with a rather large numpy input array of <code>~30 million</code> entries. Currently I am using a <code>for-loop</code>, but it's taking far too long.</p>
<p>The input is an ordered <code>numpy array</code> of the form </p>
<pre><code>Y = np.array([4, 4, 4, 6, 6, 7, 8, 9, 9, 9..... etc])
</code></pre>
<p>And I would like to have an output of the form:</p>
<pre><code>Z = {4:3, 5:0, 6:2, 7:1,8:1,9:3..... etc} (as any data type)
</code></pre>
<p>Currently I am using the following implementation:</p>
<pre><code>Z = pd.Series(index = np.arange(Y.min(), Y.max()))

for i in range(Y.min(), Y.max()):
  Z[i] = (Y == i).sum()
</code></pre>
<p>Is there a quicker way of doing this or a way without <code>iterating</code> through a loop? Thanks for helping, and sorry if this has been asked before!</p>
</div>
<div class="post-text" itemprop="text">
<p>You can simply do this using Counter from collections module. Please see the below code i ran for your test case.</p>
<pre><code>import numpy as np
from collections import Counter
Y = np.array([4, 4, 4, 6, 6, 7, 8, 9, 9, 9,10,5,5,5])
print(Counter(Y))
</code></pre>
<p>It gave the following output</p>
<pre><code>Counter({4: 3, 9: 3, 5: 3, 6: 2, 7: 1, 8: 1, 10: 1})
</code></pre>
<p>you can easily use this object for further. I hope this helps.</p>
</div>
<div class="post-text" itemprop="text">
<p>If your input array <code>x</code> is sorted, you can do the following to get the counts in linear time:</p>
<pre><code>diff1 = np.diff(x)
# get indices of the elements at which jumps occurred
jumps = np.concatenate([[0], np.where(diff1 &gt; 0)[0] + 1, [len(x)]])
unique_elements = x[jumps[:-1]]
counts = np.diff(jumps)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think numpy.unique is your solution.</p>
<p><a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html" rel="nofollow noreferrer">https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.unique.html</a></p>
<pre><code>import numpy as np
t = np.random.randint(0, 1000, 100000000)
print(np.unique(t, return_counts=True))
</code></pre>
<p>This takes ~4 seconds for me.
The collections.Counter approach takes ~10 seconds.</p>
<p>But the numpy.unique returns the frequencies in an array and the collections.Counter returns a dictionary. It's up to convenience.</p>
<p>Edit. I cannot comment on other posts so I'll write here that @lomereiters solution is lightning fast (linear) and should be the accepted one.</p>
</div>
<span class="comment-copy">use <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer">collections.counter?</a></span>
<span class="comment-copy">Do you want the count from the time when you query the dictionary? Or do you want a snapshot at a particular time?</span>
<span class="comment-copy">I think it's not. Counter is better.</span>
<span class="comment-copy">I saw the "(as any data type)" in the OP and I thought that an array would be acceptable. Is there any other reason why this is not as good?</span>
<span class="comment-copy"><code>And I would like to have an output of the form:</code></span>
<span class="comment-copy">You might be faster to <i>build</i> the array, but might be slower to do lookups... especially if you're doing many.</span>
