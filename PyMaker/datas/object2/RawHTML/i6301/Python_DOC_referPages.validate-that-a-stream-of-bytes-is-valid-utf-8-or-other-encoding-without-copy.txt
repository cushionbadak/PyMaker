<div class="post-text" itemprop="text">
<p>This is perhaps a micro-optimization, but I would like to check that a stream of given bytes is valid UTF-8 as it passes through my application, but I don't want to keep the resulted decoded code points.  In other words, if I were to call <code>large_string.decode('utf-8')</code>, assuming the encoding succeeds I have no desire to keep the unicode string returned by decoding, and would prefer not to waste memory on it.</p>
<p>There are various ways I could do this, for example read a few bytes at a time, attempt to <code>decode()</code>, then append more bytes until <code>decode()</code> succeeds (or I've exhausted the maximum number of bytes for a single character in the encoding).  But ISTM it should be possible to use the existing decoder in a way that simply throws away the decoded unicode characters and not have to roll my own.  But nothing immediately comes to mind scouring the stdlib docs.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use the <em>incremental</em> decoder provided by the <a href="https://docs.python.org/3/library/codecs.html#codecs.getincrementaldecoder" rel="nofollow noreferrer"><code>codecs</code> module</a>:</p>
<pre><code>utf8_decoder = codecs.getincrementaldecoder('utf8')()
</code></pre>
<p>This is a <a href="https://docs.python.org/3/library/codecs.html#codecs.IncrementalDecoder" rel="nofollow noreferrer"><code>IncrementalDecoder()</code> instance</a>. You can then feed this decoder data <em>in order</em> and validate the stream:</p>
<pre><code># for each partial chunk of data:
    try:
        utf8_decoder.decode(chunk)
    except UnicodeDecodeError:
        # invalid data
</code></pre>
<p>The decoder returns the data decoded so far (minus partial multi-byte sequences, those are kept as state for the next time you decode a chunk). Those smaller strings are cheap to create and discard, you are not creating a large string here.</p>
<p>You can't feed the above loop partial data, because UTF-8 is a format using a variable number of bytes; a partial chunk is liable to have invalid data at the start.</p>
<p>If you can't validate from the start, then your first chunk <em>may</em> start with up to three continuation bytes. You <em>could</em> just remove those first:</p>
<pre><code>first_chunk = b'....'
for _ in range(3):
    if first_chunk[0] &amp; 0xc0 == 0x80:
        # remove continuation byte
        first_chunk = first_chunk[1:]
</code></pre>
<p>Now, UTF-8 is structured enough so you could also validate the stream entirely in Python code using more such binary tests, but you simply are not going to match the speed that the built-in decoder can decode at. </p>
</div>
<span class="comment-copy">Can you divide the long string/stream up into "chunks" in a way that you're sure doesn't divide a valid multi-byte trf8 encoded character across a pair of them?</span>
<span class="comment-copy"><code>utf8_decoder.decode(chunk)</code> decodes and returns the resulting decoded object (which your code ignores). How is that better than just using <code>string.decode('utf-8')</code> and ignoring its return value (within a <code>try/except</code> of course)?</span>
<span class="comment-copy">@martineau: because this lets you pass in partial data, discarding the result along the way. The decoder holds enough state to handle the next partial block, etc.</span>
<span class="comment-copy">@martineau: so the partial decodes are <i>smaller</i>.</span>
<span class="comment-copy">OK, I understand...but I think perhaps your answer needs more elaborate example code as well as a more complete explanation.</span>
<span class="comment-copy">@martineau: that requires the OP to share how they get their blocks of data, really.</span>
