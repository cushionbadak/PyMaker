<div class="post-text" itemprop="text">
<p>After creating a NumPy array, and saving it as a Django context variable, I receive the following error when loading the webpage:</p>
<pre><code>array([   0,  239,  479,  717,  952, 1192, 1432, 1667], dtype=int64) is not JSON serializable
</code></pre>
<p>What does this mean?</p>
</div>
<div class="post-text" itemprop="text">
<p>I regularly "jsonify" np.arrays. Try using the ".tolist()" method on the arrays first, like this: </p>
<pre><code>import numpy as np
import codecs, json 

a = np.arange(10).reshape(2,5) # a 2 by 5 array
b = a.tolist() # nested lists with same data, indices
file_path = "/path.json" ## your path variable
json.dump(b, codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4) ### this saves the array in .json format
</code></pre>
<p>In order to "unjsonify" the array use: </p>
<pre><code>obj_text = codecs.open(file_path, 'r', encoding='utf-8').read()
b_new = json.loads(obj_text)
a_new = np.array(b_new)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Store as JSON a numpy.ndarray or any nested-list composition.</p>
<pre><code>class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

a = np.array([[1, 2, 3], [4, 5, 6]])
print(a.shape)
json_dump = json.dumps({'a': a, 'aa': [2, (2, 3, 4), a], 'bb': [2]}, cls=NumpyEncoder)
print(json_dump)
</code></pre>
<p>Will output:</p>
<pre><code>(2, 3)
{"a": [[1, 2, 3], [4, 5, 6]], "aa": [2, [2, 3, 4], [[1, 2, 3], [4, 5, 6]]], "bb": [2]}
</code></pre>
<p>To restore from JSON:</p>
<pre><code>json_load = json.loads(json_dump)
a_restored = np.asarray(json_load["a"])
print(a_restored)
print(a_restored.shape)
</code></pre>
<p>Will output:</p>
<pre><code>[[1 2 3]
 [4 5 6]]
(2, 3)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.to_json.html" rel="noreferrer">Pandas</a>:</p>
<pre><code>import pandas as pd
pd.Series(your_array).to_json(orient='values')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I found the best solution if you have nested numpy arrays in a dictionary:</p>
<pre><code>import json
import numpy as np

class NumpyEncoder(json.JSONEncoder):
    """ Special json encoder for numpy types """
    def default(self, obj):
        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,
            np.int16, np.int32, np.int64, np.uint8,
            np.uint16, np.uint32, np.uint64)):
            return int(obj)
        elif isinstance(obj, (np.float_, np.float16, np.float32, 
            np.float64)):
            return float(obj)
        elif isinstance(obj,(np.ndarray,)): #### This is the fix
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)

dumped = json.dumps(data, cls=NumpyEncoder)

with open(path, 'w') as f:
    json.dump(dumped, f)
</code></pre>
<p>Thanks to <a href="https://github.com/mpld3/mpld3/issues/434#issuecomment-340255689" rel="noreferrer">this guy</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>This is not supported by default, but you can make it work quite easily! There are several things you'll want to encode if you want the exact same data back:</p>
<ul>
<li>The data itself, which you can get with <code>obj.tolist()</code> as @travelingbones mentioned. Sometimes this may be good enough.</li>
<li>The data type. I feel this is important in quite some cases.</li>
<li>The dimension (not necessarily 2D), which could be derived from the above if you assume the input is indeed always a 'rectangular' grid.</li>
<li>The memory order (row- or column-major). This doesn't often matter, but sometimes it does (e.g. performance), so why not save everything?</li>
</ul>
<p>Furthermore, your numpy array could part of your data structure, e.g. you have a list with some matrices inside. For that you could use a custom encoder which basically does the above.</p>
<p>This should be enough to implement a solution. Or you could use <a href="https://github.com/mverleg/pyjson_tricks" rel="nofollow noreferrer">json-tricks</a> which does just this (and supports various other types) (disclaimer: I made it).</p>
<pre><code>pip install json-tricks
</code></pre>
<p>Then</p>
<pre><code>data = [
    arange(0, 10, 1, dtype=int).reshape((2, 5)),
    datetime(year=2017, month=1, day=19, hour=23, minute=00, second=00),
    1 + 2j,
    Decimal(42),
    Fraction(1, 3),
    MyTestCls(s='ub', dct={'7': 7}),  # see later
    set(range(7)),
]
# Encode with metadata to preserve types when decoding
print(dumps(data))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A Lot of the other numpy encoders seem a bit overly complicated.</p>
<p>check if the object if from the module numpy, if so either use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tolist.html" rel="nofollow noreferrer"><code>ndarray.tolist</code></a> for a <code>ndarray</code> or use <code>.item</code> for any other numpy specific type.</p>
<p>Use the <code>json.dumps</code> <a href="https://docs.python.org/3/library/json.html#basic-usage" rel="nofollow noreferrer"><code>default</code></a> kwarg:</p>
<blockquote>
<p>default should be a function that gets called for objects that canâ€™t otherwise be serialized.</p>
</blockquote>
<pre><code>import numpy as np

def default(obj):
    if type(obj).__module__ == np.__name__:
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return obj.item()
    raise TypeError('Unknown type:', type(obj))

dumped = json.dumps(data, default=default)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I had a similar problem with a nested dictionary with some numpy.ndarrays in it. </p>
<pre><code>def jsonify(data):
    json_data = dict()
    for key, value in data.iteritems():
        if isinstance(value, list): # for lists
            value = [ jsonify(item) if isinstance(item, dict) else item for item in value ]
        if isinstance(value, dict): # for nested lists
            value = jsonify(value)
        if isinstance(key, int): # if key is integer: &gt; to string
            key = str(key)
        if type(value).__module__=='numpy': # if value is numpy.*: &gt; to python list
            value = value.tolist()
        json_data[key] = value
    return json_data
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could also use <code>default</code> argument for example:</p>
<pre><code>def myconverter(o):
    if isinstance(o, np.float32):
        return float(o)

json.dump(data, default=myconverter)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Also, some very interesting information further on lists vs. arrays in Python ~&gt; <a href="https://stackoverflow.com/questions/176011/python-list-vs-array-when-to-use">Python List vs. Array - when to use?</a></p>
<p>It could be noted that once I convert my arrays into a list before saving it in a JSON file, in my deployment right now anyways, once I read that JSON file for use later, I can continue to use it in a list form (as opposed to converting it back to an array). </p>
<p>AND actually looks nicer (in my opinion) on the screen as a list (comma seperated) vs. an array (not-comma seperated) this way. </p>
<p>Using @travelingbones's .tolist() method above, I've been using as such (catching a few errors I've found too):</p>
<p>SAVE DICTIONARY</p>
<pre><code>def writeDict(values, name):
    writeName = DIR+name+'.json'
    with open(writeName, "w") as outfile:
        json.dump(values, outfile)
</code></pre>
<p>READ DICTIONARY</p>
<pre><code>def readDict(name):
    readName = DIR+name+'.json'
    try:
        with open(readName, "r") as infile:
            dictValues = json.load(infile)
            return(dictValues)
    except IOError as e:
        print(e)
        return('None')
    except ValueError as e:
        print(e)
        return('None')
</code></pre>
<p>Hope this helps!</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is an implementation that work for me and removed all nans (assuming these are simple object (list or dict)):</p>
<pre><code>from numpy import isnan

def remove_nans(my_obj, val=None):
    if isinstance(my_obj, list):
        for i, item in enumerate(my_obj):
            if isinstance(item, list) or isinstance(item, dict):
                my_obj[i] = remove_nans(my_obj[i], val=val)

            else:
                try:
                    if isnan(item):
                        my_obj[i] = val
                except Exception:
                    pass

    elif isinstance(my_obj, dict):
        for key, item in my_obj.iteritems():
            if isinstance(item, list) or isinstance(item, dict):
                my_obj[key] = remove_nans(my_obj[key], val=val)

            else:
                try:
                    if isnan(item):
                        my_obj[key] = val
                except Exception:
                    pass

    return my_obj
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is a different answer, but this might help to help people who are trying to save data and then read it again.<br/>
There is hickle which is faster than pickle and easier.<br/>
I tried to save and read it in pickle dump but while reading there were lot of problems and wasted an hour and still didn't find solution though I was working on my own data to create a chat bot. </p>
<p><code>vec_x</code> and <code>vec_y</code> are numpy arrays:</p>
<pre><code>data=[vec_x,vec_y]
hkl.dump( data, 'new_data_file.hkl' )
</code></pre>
<p>Then you just read it and perform the operations:</p>
<pre><code>data2 = hkl.load( 'new_data_file.hkl' )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>May do simple for loop with checking types:</p>
<pre><code>with open("jsondontdoit.json", 'w') as fp:
    for key in bests.keys():
        if type(bests[key]) == np.ndarray:
            bests[key] = bests[key].tolist()
            continue
        for idx in bests[key]:
            if type(bests[key][idx]) == np.ndarray:
                bests[key][idx] = bests[key][idx].tolist()
    json.dump(bests, fp)
    fp.close()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><strong>TypeError: array([[0.46872085, 0.67374235, 1.0218339 , 0.13210179, 0.5440686 , 0.9140083 , 0.58720225, 0.2199381 ]], dtype=float32) is not JSON serializable</strong></p>
<p>The above-mentioned  error was thrown when i tried to pass of list of data to model.predict() when i  was expecting the response in json format.</p>
<pre><code>&gt; 1        json_file = open('model.json','r')
&gt; 2        loaded_model_json = json_file.read()
&gt; 3        json_file.close()
&gt; 4        loaded_model = model_from_json(loaded_model_json)
&gt; 5        #load weights into new model
&gt; 6        loaded_model.load_weights("model.h5")
&gt; 7        loaded_model.compile(optimizer='adam', loss='mean_squared_error')
&gt; 8        X =  [[874,12450,678,0.922500,0.113569]]
&gt; 9        d = pd.DataFrame(X)
&gt; 10       prediction = loaded_model.predict(d)
&gt; 11       return jsonify(prediction)
</code></pre>
<p>But luckily found the hint to resolve the error that was throwing 
  The serializing of the objects is applicable only for the following conversion
  Mapping should be in following way
  object - dict
  array - list
  string - string
  integer - integer</p>
<p>If you scroll up to see the line number 10 
  prediction = loaded_model.predict(d)  where this line of code was generating the output 
  of type array datatype , when you try to convert array to json format its not possible</p>
<p>Finally i found the solution just by converting obtained output to the type list by 
  following lines of code</p>
<blockquote>
<p>prediction = loaded_model.predict(d)<br/>
  listtype = prediction.tolist()
  return jsonify(listtype)</p>
</blockquote>
<p>Bhoom! finally got the expected output, 
  <a href="https://i.stack.imgur.com/T8WpJ.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/T8WpJ.png"/></a></p>
</div>
<span class="comment-copy">It means that somewhere, something is trying to dump a numpy array using the <code>json</code> module.  But <code>numpy.ndarray</code> is not a type that <code>json</code> knows how to handle.  You'll either need to write your own serializer, or (more simply) just pass <code>list(your_array)</code> to whatever is writing the json.</span>
<span class="comment-copy">Note <code>list(your_array)</code> will not always work as it returns numpy ints, not native ints. Use <code>your_array.to_list()</code> instead.</span>
<span class="comment-copy">a note about  @ashishsingal's comment, it should be your_array.tolist(), not to_list().</span>
<span class="comment-copy">Why can it only be stored as a list of lists?</span>
<span class="comment-copy">I don't know but i expect np.array types have metadata that doesn't fit into json (e.g. they specify the data type of each entry like float)</span>
<span class="comment-copy">I tried your method, but it seems that the program stucked at <code>tolist()</code>.</span>
<span class="comment-copy">Not sure how to help you with the given info. Please try to makes sure <code>a</code> is a numpy array. Then <code>a.tolist()</code> is just the method that transforms it into a list with the same structure.</span>
<span class="comment-copy">@frankliuao I found the reason is that <code>tolist()</code> takes a huge amount of time when the data is large.</span>
<span class="comment-copy">This should be way higher up the board, it's the generalisable and properly abstracted way of doing this. Thanks!</span>
<span class="comment-copy">Is there a simple way to get the ndarray back from the list ?</span>
<span class="comment-copy">@DarksteelPenguin are you looking for <a href="https://docs.scipy.org/doc/numpy-1.10.4/reference/generated/numpy.asarray.html" rel="nofollow noreferrer"><code>numpy.asarray()</code></a>?</span>
<span class="comment-copy">This should be the accepted answer, much tidier way of doing things.</span>
<span class="comment-copy">This IS the answer. Great work</span>
<span class="comment-copy">Great! And I think for 2D np.array it will be something like <code>pd.DataFrame(your_array).to_json('data.json', orient='split')</code>.</span>
<span class="comment-copy">@yurenzhong: What data?  Maybe you should post a question of your own?</span>
<span class="comment-copy">Thanks for the helpful answer!  I wrote the attributes to a json file, but am now having trouble reading back the parameters for Logistic Regression.  Is there a 'decoder' for this saved json file?</span>
<span class="comment-copy">Of course, to read the <code>json</code> back you can use this: <code>with open(path, 'r') as f:</code> <code>data = json.load(f)</code> , which returns a dictionary with your data.</span>
<span class="comment-copy">That's for reading the <code>json</code> file and then to deserialize it's output you can use this: <code>data = json.loads(data)</code></span>
