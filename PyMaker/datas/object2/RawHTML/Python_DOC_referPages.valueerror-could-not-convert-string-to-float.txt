<div class="post-text" itemprop="text">
<p>I have a (2M, 23) dimensional <code>numpy</code> array <code>X</code>. It has a dtype of <code>&lt;U26</code>, i.e. unicode string of 26 characters. </p>
<pre><code>array([['143347', '1325', '28.19148936', ..., '61', '0', '0'],
   ['50905', '0', '0', ..., '110', '0', '0'],
   ['143899', '1325', '28.80434783', ..., '61', '0', '0'],
   ...,
   ['85', '0', '0', ..., '1980', '0', '0'],
   ['233', '54', '27', ..., '-1', '0', '0'],
   ['���', '�', '�����', ..., '�', '��', '���']], dtype='&lt;U26')
</code></pre>
<p>When I convert it to a float datatype, using</p>
<pre><code>X_f = X.astype(float)
</code></pre>
<p>I get the error as shown above. I am trying to find how to solve this string formatting error for '���'.</p>
<p>What does it mean (what is it called?) and how do I solve this error?</p>
<p>EDIT: Information on how the data was read:-</p>
<h3>importing relevant packages</h3>
<pre><code>from pyspark import SparkContext
from pyspark.sql import SQLContext
from pyspark.sql.functions import col
</code></pre>
<h3>loading the dataset in a pyspark dataframe</h3>
<pre><code>def loading_data(dataset):
    dataset=sql_sc.read.format('csv').options(header='true', inferSchema='true').load(dataset)
    # #changing column header name
    dataset = dataset.select(*[col(s).alias('Label') if s == ' Label' else s for s in dataset.columns])
    #to change datatype
    dataset=dataset.drop('External IP')
    dataset = dataset.filter(dataset.Label.isNotNull())
    dataset=dataset.filter(dataset.Label!=' Label')#filter Label from label
    print(dataset.groupBy('Label').count().collect())
    return dataset

# invoking
ds_path = '../final.csv'
dataset=loading_data(ds_path)
</code></pre>
<h3>check type of dataset.</h3>
<pre><code>type(dataset)
</code></pre>
<p>pyspark.sql.dataframe.DataFrame</p>
<h3>convert to np array</h3>
<pre><code>import numpy as np
np_dfr = np.array(data_preprocessing(dataset).collect())
</code></pre>
<h3>split features and labels</h3>
<pre><code>X = np_dfr[:,0:22]
Y = np_dfr[:,-1]
</code></pre>
<h3>show X</h3>
<pre><code>&gt;&gt; X
array([['143347', '1325', '28.19148936', ..., '61', '0', '0'],
       ['50905', '0', '0', ..., '110', '0', '0'],
       ['143899', '1325', '28.80434783', ..., '61', '0', '0'],
       ...,
       ['85', '0', '0', ..., '1980', '0', '0'],
       ['233', '54', '27', ..., '-1', '0', '0'],
       ['���', '�', '�����', ..., '�', '��', '���']], dtype='&lt;U26')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It means that string(���) dimension is not fixed in the graph and it can vary between run calls
The Question mark Symbol indicates <code>tf.TensorShape</code> 
Any tensor returned by Session.run or eval is a NumPy array.</p>
<pre><code>&gt;&gt;&gt; print(type(tf.Session().run(tf.constant([1,2,3]))))
&lt;class 'numpy.ndarray'&gt;
</code></pre>
<p>Or:</p>
<pre><code>&gt;&gt;&gt; sess = tf.InteractiveSession()
&gt;&gt;&gt; print(type(tf.constant([1,2,3]).eval()))
&lt;class 'numpy.ndarray'&gt;
</code></pre>
<p>Or, equivalently:</p>
<pre><code>&gt;&gt;&gt; sess = tf.Session()
&gt;&gt;&gt; with sess.as_default():
&gt;&gt;&gt;    print(type(tf.constant([1,2,3]).eval()))
&lt;class 'numpy.ndarray'&gt;
</code></pre>
<p><strong>Not</strong> any tensor returned by Session.run or eval() is a NumPy array. Sparse Tensors for example are returned as SparseTensorValue:</p>
<pre><code>&gt;&gt;&gt; print(type(tf.Session().run(tf.SparseTensor([[0, 0]],[1],[1,2]))))
&lt;class 'tensorflow.python.framework.sparse_tensor.SparseTensorValue'&gt;
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Though not the best solution, I found some success by converting it into pandas dataframe and working along.</p>
<h3>code snippet</h3>
<pre><code># convert X into dataframe
X_pd = pd.DataFrame(data=X)
# replace all instances of URC with 0 
X_replace = X_pd.replace('�',0, regex=True)
# convert it back to numpy array
X_np = X_replace.values
# set the object type as float
X_fa = X_np.astype(float)
</code></pre>
<h3>input</h3>
<pre><code>array([['85', '0', '0', '1980', '0', '0'],
       ['233', '54', '27', '-1', '0', '0'],
       ['���', '�', '�����', '�', '��', '���']], dtype='&lt;U5')
</code></pre>
<h3>output</h3>
<pre><code>array([[ 8.50e+01,  0.00e+00,  0.00e+00,  1.98e+03,  0.00e+00,  0.00e+00],
       [ 2.33e+02,  5.40e+01,  2.70e+01, -1.00e+00,  0.00e+00,  0.00e+00],
       [ 0.00e+00,  0.00e+00,  0.00e+00,  0.00e+00,  0.00e+00,  0.00e+00]])
</code></pre>
</div>
<span class="comment-copy">How do you read that data?<code>�</code> is the Unicode replacement character, used when ASCII text is read using the wrong codepage. Looks like the source contained non-numeric data that was read using the wrong codepage. Even if the correct codepage was used, the text would still be invalid</span>
<span class="comment-copy">If you were the Python interpreter, how would you convert <code>'���'</code> to float? Which number would that represent? What is your desired result?</span>
<span class="comment-copy">@PanagiotisKanavos: i read it from a pyspark dataframe using <code>collect()</code> method.</span>
<span class="comment-copy">@zvone: exactly! I wish I knew what the URC(???) was before. Desired result is a numpy array of float values.</span>
