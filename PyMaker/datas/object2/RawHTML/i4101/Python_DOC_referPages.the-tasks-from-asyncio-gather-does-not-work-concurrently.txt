<div class="post-text" itemprop="text">
<p>I want to scrape data from a website concurrently, but I found that the following program is NOT executed concurrently.</p>
<pre><code>async def return_soup(url):
    r = requests.get(url)
    r.encoding = "utf-8"
    soup = BeautifulSoup(r.text, "html.parser")

    future = asyncio.Future()
    future.set_result(soup)
    return future

async def parseURL_async(url):    
    print("Started to download {0}".format(url))
    soup = await return_soup(url)
    print("Finished downloading {0}".format(url))

    return soup

loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
t = [parseURL_async(url_1), parseURL_async(url_2)]
loop.run_until_complete(asyncio.gather(*t))
</code></pre>
<p>However, this program starts to download the second content only after the first one finishes. If my understanding is correct, the <code>await</code> keyword on the <code>await return_soup(url)</code> awaits for the function to be complete, and while waiting for the completion, it returns back the control to the event loop, which enables the loop to start the second download. </p>
<p>And once the function finally finishes the execution, the future instance within it gets the result value.</p>
<p>But why does this not work concurrently? What am I missing here?</p>
</div>
<div class="post-text" itemprop="text">
<p>Using asyncio is different from using threads in that you cannot add it to an existing code base to make it concurrent. Specifically, code that runs in the asyncio event loop <em>must not block</em> - all blocking calls must be replaced with non-blocking versions that yield control to the event loop. In your case, <code>requests.get</code> blocks and defeats the parallelism implemented by asyncio.</p>
<p>To avoid this problem, you need to use an http library that is written with asyncio in mind, such as <a href="https://github.com/aio-libs/aiohttp" rel="nofollow noreferrer"><code>aiohttp</code></a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>I'll add a little more to user4815162342's response. The asyncio framework uses coroutines that must cede control of the thread while they do the long operation. See the diagram at the end of <a href="https://docs.python.org/3/library/asyncio-task.html#example-chain-coroutines" rel="nofollow noreferrer">this section</a> for a nice graphical representation. As user4815162342 mentioned, the requests library doesn't support asyncio. I know of two ways to make this work concurrently. First, is to do what user4815162342 suggested and switch to a library with native support for asynchronous requests. The second is to run this synchronous code in separate threads or processes. The latter is easy because of the <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.AbstractEventLoop.run_in_executor" rel="nofollow noreferrer"><code>run_in_executor</code></a> function.</p>
<pre><code>loop = asyncio.get_event_loop()

async def return_soup(url):
    r = await loop.run_in_executor(None, requests.get, url)
    r.encoding = "utf-8"
    return BeautifulSoup(r.text, "html.parser")

async def parseURL_async(url):    
    print("Started to download {0}".format(url))
    soup = await return_soup(url)
    print("Finished downloading {0}".format(url))

    return soup

t = [parseURL_async(url_1), parseURL_async(url_2)]
loop.run_until_complete(asyncio.gather(*t))
</code></pre>
<p>This solution removes some of the benefit of using asyncio, as the long operation will still probably be executed from a fixed size thread pool, but it's also much easier to start with.</p>
</div>
<span class="comment-copy">Thanks and I misunderstood the library! I found that the use of <code>run_in_executor()</code> could solve it.</span>
<span class="comment-copy">@Blaszard Yes, although you can get the same effect without asyncio, e.g. using <code>concurrent.futures</code>. <code>run_in_executor</code> is meant for pieces of code that are blocking by design (e.g. because they do a calculation, such as the invocation of <code>BeautifulSoup</code> in your case), or those that have no asynchronous counter-part (e.g. host name resolution on a typical POSIX system). Using <code>run_in_executor</code> for everything defeats much of the purpose of asyncio, which is having <i>light-weight</i> tasks rather than threads.</span>
