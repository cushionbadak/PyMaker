<div class="post-text" itemprop="text">
<p>I am new to python and using python 2.7.  I am writing a program to parse  raw re files . I have written a function which calls a file and puts every 4 line in a list . My file is big say 4 GB of raw dna data.</p>
<pre><code>def filerd(f):
           identifier = []
           with open(f,'r') as inputfile:
            count = 1
            for line in inputfile:
              if count%4 == 1:
                identifier.append(line)
                count = count + 1
              else:
                count = count + 1
              return identifier
</code></pre>
<p>Now how can i parallelize this function so that i can get speedup.
Is there any way when i can run this function on 5 cores of my server?</p>
</div>
<div class="post-text" itemprop="text">
<p>As I mentioned in my comment above, you can likely gain a lot of speed just from optimizing your function. I suggest to try the following:</p>
<pre><code>import itertools

def filerd(f):
    with open(f, "r") as inputfile:
        return list(itertools.islice(inputfile, None, None, 4))
</code></pre>
<p>If you do not need the return value to be a list, but are fine with an iterator, you can remove the <code>list()</code>. Then, quite likely the slowest part will be loading the data from disk, which you need to do anyway.</p>
</div>
<span class="comment-copy">What would be your idea of what parallelization might look like?</span>
<span class="comment-copy">I am specifically looking for "for loop paralleism" :Comparing with C , the for loop can  be parallelized   openmp for loop directive .</span>
<span class="comment-copy">Well, you will need to split your data into several chunks. Then you can use <code>multiprocessing</code> to process each of these chunks in a parallel process.</span>
<span class="comment-copy">However, I believe that your code can be made much more efficient and faster, e.g. using <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice</code></a>.</span>
<span class="comment-copy">So that means the process of splitting data into chunks can not be parallelized in python ? i have large file just need to iterate through it and create a list based on certain conditions? This iteration can not be parallelized?</span>
