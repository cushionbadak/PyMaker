<div class="post-text" itemprop="text">
<p>I am creating a bag of words from a text corpus and am trying to limit the size of my vocabulary because the program freezes when I try to convert my list to a pandas dataframe. I am using Counter to count the number occurrences of each word:</p>
<pre><code>from collections import Counter
bow = []
# corpus is list of text samples where each text sample is a list of words with variable length
for tokenized_text in corpus:
    clean_text = [tok.lower() for tok in tokenized_text if tok not in punctuation and tok not in stopwords]
    bow.append(Counter(clean_text))
# Program freezes here
df_bows = pd.DataFrame.from_dict(bow)
</code></pre>
<p>My input would be a list of tokens of length num_samples where each text sample is a list of tokens. For my output I want a pandas DataFrame with shape (num_samples, 10000) where 10000 is the size of my vocabulary. Before, my <code>df_bows</code> vocabulary size (<code>df_bows.shape[1]</code>) would get very large (greater than 50,000.
How can I choose the 10,000 most frequently occurring words from my <code>bow</code> list of Counter objects and place then in a DataFrame while preserving number of text samples?</p>
</div>
<div class="post-text" itemprop="text">
<p>To find the overall top 10000 words, the easiest way would be <a href="https://docs.python.org/2/library/collections.html#collections.Counter" rel="nofollow noreferrer"><code>update</code> a global <code>Counter</code></a>:</p>
<pre><code>from collections import Counter
global_counter = Counter() # &lt;- create a counter
for tokenized_text in corpus:
    clean_text = [tok.lower() for tok in tokenized_text if tok not in punctuation and tok not in stopwords]
    global_counter.update(clean_text) # &lt;- update it
</code></pre>
<p>At this point, you could just use</p>
<pre><code>import pandas as pd
df = pd.DataFrame(global_counter.most_common(10000))
</code></pre>
<hr/>
<p>If you would like to find the count of the words for the specific entries, add now the following code (after the previous one).</p>
<pre><code>most_common = set([t[0] for t in global_counter.most_common(10000)])
occurrences = []
for tokenized_text in corpus:
    clean_text = dict(collections.Counter([tok.lower() for tok in tokenized_text if tok not in punctuation and tok not in stopwords]))
    occurrences.append({c: clean_text.get(c, 0) for c in most_common})
</code></pre>
<p>Now just use</p>
<pre><code>pd.DataFrame(occurrences)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><code>Counter.most_common(n)</code> returns you the most common n elements.</p>
<p>Here : <a href="https://docs.python.org/3/library/collections.html#collections.Counter.most_common" rel="nofollow noreferrer">https://docs.python.org/3/library/collections.html#collections.Counter.most_common</a></p>
<pre><code>from collections import Counter

myStr = "It was a very, very good presentation, was it not?"
C = Counter(myStr.split())
C.most_common(2)

# [('was', 2), ('It', 1)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>you can most frequently occuring words by using counter most_comman helping function:</p>
<pre><code>from collections import Counter
clean_text = [tok.lower() for tok in tokenized_text if tok not in punctuation and tok not in stopwords]
counter = Counter(clean_text)
counter.most_common(10000)
</code></pre>
</div>
<span class="comment-copy">From your code, it looks like you're trying to compute the term frequency matrix. If that's the case, you can use CountVectorizer from sklearn. <a href="http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html" rel="nofollow noreferrer">scikit-learn.org/stable/modules/generated/â€¦</a></span>
<span class="comment-copy">@ThirupathiThangavel Thanks, I thought about that but was trying to avoid relying on sci-kit learn.</span>
<span class="comment-copy">The <code>global_counter</code> doesn't separate the different text samples though. After trying this I get a (10000, 2) dataframe with words in one column and their counts in another</span>
<span class="comment-copy">@CrashingWater Maybe you could update your question with a short example of input and requested output? I don't quite understand your above comment.</span>
<span class="comment-copy">I updated my question @Ami Tavory</span>
<span class="comment-copy">@AmiTavory isn't set going to remove duplicates? you will loose the counts for in vocabulary tokens, won't you?</span>
<span class="comment-copy">@kenzie That is an excellent point - thanks. I thought the OP was after a binary matrix; will update the answer.</span>
