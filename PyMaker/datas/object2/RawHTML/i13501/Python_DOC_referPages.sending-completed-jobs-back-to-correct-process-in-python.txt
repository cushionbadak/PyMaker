<div class="post-text" itemprop="text">
<p>I'd like to create a set of processes with the following structure:</p>
<ul>
<li><code>main</code>, which dequeues requests from an external source. <code>main</code> generates a variable number of worker processes.</li>
<li><code>worker</code> which does some preliminary processing on job requests, then sends data to <code>gpuProc</code>. </li>
<li><code>gpuProc</code>, which accepts job requests from <code>worker</code> processes. When it has received enough requests, it sends the batch to a process that runs on the GPU. After getting the results back, it has to then send back the completed batch of requests back to the <code>worker</code> processes such that <em>the worker that requested it receives it back</em> </li>
</ul>
<p>One could envision doing this with a number of queues. Since the number of <code>worker</code> processes is variable, it would be ideal if <code>gpuProc</code> had a single input queue into which <code>worker</code>s put their job request and their specific return queue as a tuple. However, this isn't possible--you can only share vanilla queues in python via inheritance, and <code>manager.Queues()</code> fail with:</p>
<pre><code>RemoteError: 
---------------------------------------------------------------------------
Unserializable message: ('#RETURN', ('Worker 1 asked proc to do some work.', &lt;Queue.Queue instance at 0x7fa0ba14d908&gt;))
---------------------------------------------------------------------------
</code></pre>
<p>Is there a pythonic way to do this without invoking some external library?</p>
</div>
<div class="post-text" itemprop="text">
<p><code>multiprocessing.Queue</code> is implemented with a pipe, a deque and a thread.</p>
<p>When you call queue.put() the objects ends up in the deque and the thread takes care of pushing it into the pipe.</p>
<p>You cannot share threads within processes for obvious reasons. Therefore you need to use something else.</p>
<p>Regular pipes and sockets can be easily shared.</p>
<p>Nevertheless I'd rather use a different architecture for your program.</p>
<p>The <code>main</code> process would act as an orchestrator routing the tasks to two different Pools of processes, one for CPU bound jobs and the other to GPU bound ones. This would imply you need to share more information within the workers but it's way more robust and scalable.</p>
<p>Here you get a draft:</p>
<pre><code>from multiprocessing import Pool

def cpu_worker(job_type, data):
    if job_type == "first_computation":
        results do_cpu_work()
    elif job_type == "compute_gpu_results":
        results = do_post_gpu_work()

    return results

def gpu_worker(data):
    return do_gpu_work()

class Orchestrator:
    def __init__(self):
        self.cpu_pool = Pool()
        self.gpu_pool = Pool()

    def new_task(self, task):
        """Entry point for a new task. The task will be run by the CPU workers and the results handled by the cpu_job_done method."""
        self.cpu_pool.apply_async(cpu_worker, args=["first_computation", results], callback=self.cpu_job_done)

    def cpu_job_done(self, results):
        """Once the first CPU computation is done, send its results to a GPU worker. Its results will be handled by the gpu_job_done method."""
        self.gpu_pool.apply_async(gpu_worker, args=[results], callback=self.gpu_job_done)

    def gpu_job_done(self, results):
        """GPU computation done, send the data back for the last CPU computation phase. Results will be handled by the task_done method."""
        self.cpu_pool.apply_async(cpu_worker, args=["compute_gpu_results", results], callback=self.task_done)

    def task_done(self, results):
        """Here you get your final results for the task."""
        print(results)
</code></pre>
</div>
<span class="comment-copy">Your modifications are probably trying to send something unserializable (or <a href="https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled" rel="nofollow noreferrer">un<code>pickle</code>able</a>) through channels. You're gonna have to show some of your code. Have you checked the <a href="https://docs.python.org/3/library/multiprocessing.html#exchanging-objects-between-processes" rel="nofollow noreferrer">ways to communicate with <code>multiprocessing</code></a>?</span>
