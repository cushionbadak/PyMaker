<div class="post-text" itemprop="text">
<p>I'm making my own rhymer is Python using NLTK. The CMU-dict has over 130,000 entries in a format like this:</p>
<pre><code>[['griffon', ['G', 'R', 'IH1', 'F', 'AH0', 'N']],
 ['griffy', ['G', 'R', 'IH1', 'F', 'IY0']],
 ['grigas', ['G', 'R', 'AY1', 'G', 'AH0', 'Z']]]
</code></pre>
<p>These are word, pron(unciation) pairs. I manipulate the prons (maybe switch a 'G' for a 'T') and check if that's a word. I do this by using this function:</p>
<pre class="lang-py prettyprint-override"><code>all_word_prons = get_word_pron_pairs_in_cmu_dict()

def pron_is_a_word(pronunciation):
    for word, pron in all_word_prons:
        if pronunciation == pron:
            return True
        else:
            return False
</code></pre>
<p>all_word_prons is a Python Pickle file that is 10mb and contains all 130k entries</p>
<p>If I perform this look up 1000 times, it will take around 23 seconds, which isn't completely bad considering the task but there has to be a better algorithm. I've seen people recommend sets on bisects on other topics but those apply to simple string lookup. This is more or less checking to see if a list is equal, not a string.</p>
<p>I did implment some tree-like structure that contains data like this (using the example from above):</p>
<pre><code>{'G': {'R': {'IH1': {'F': {'IY0': {0: 'griffy'}, 'AH0': {'N': {0: 'griffon'}}}}, 'AY1': {'G': {'AH0': {'Z': {0: 'grigas'}}}}}}}
</code></pre>
<p>This for some reason takes even longer than iterating through it simply. Perhaps my implementation is wrong. If you're curious:</p>
<pre class="lang-py prettyprint-override"><code>def build_fast_idict_tree():
    from nltk.corpus import cmudict
    entries = cmudict.entries()
    idict = {}
    for entry in entries:
        word, pronunciation = entry
        idict_level = idict
        for syl in pronunciation:
            if syl not in idict_level:
                idict_level[syl] = {}
            idict_level = idict_level[syl]
        idict_level[0] = word
    return idict

def get_fast_idict_tree():
    filename = "fast_idict_tree.pickle"
    if os.path.isfile(filename):
        list = pickle.load(open(filename, "rb"))
    else:
        list = build_fast_idict_tree()
        pickle.dump(list, open(filename, "wb"))
    return list

def lookup_in_fast_idict_tree(syls):
    idict = get_fast_idict_tree()
    for syl in syls:
        if syl not in idict:
            return False
        idict= idict[syl]
    return idict[0] if 0 in idict else False
</code></pre>
<h1>TL:DR</h1>
<p>What is the fastest way to do this sort of lookup (matching a list) in Python 3 in the year 2015?</p>
</div>
<div class="post-text" itemprop="text">
<p>If I understand correctly, you want to check to see whether some <code>pronunciation</code> is in your data set. From your first code block, it doesn't seem like you care what <code>word</code> the match came from.</p>
<p>Therefore, I think we could do:</p>
<pre><code>pron_set = {tuple(pron) for word, pron in all_word_prons}
# do something to get a list of pronunciations to check
for pronunciation in pronunciation_list:
    if tuple(pronunciation) in pron_set:
        print('pronunctiation')
</code></pre>
<p>We construct <code>pron_set</code> from <code>tuple</code>s because <code>list</code>s are not hashable (and can't be used as set members).</p>
<p>Set lookup should be much faster than iterating through the list. I would recommend being familiar with the <a href="https://wiki.python.org/moin/TimeComplexity" rel="nofollow">Python data structures</a>; you never know when a <code>deque</code> might save you lots of time.</p>
</div>
<div class="post-text" itemprop="text">
<p>Have you considered using Python List Comprehensions as outlined here?</p>
<p><a href="https://docs.python.org/3/tutorial/datastructures.html" rel="nofollow noreferrer">https://docs.python.org/3/tutorial/datastructures.html</a></p>
<p>In certain cases, list comprehensions can be faster than plain for-loops however it still executes a byte-code level loop.  If you're not certain what I mean, checkout this thread: 
 <a href="https://stackoverflow.com/questions/22108488/are-list-comprehensions-and-functional-functions-faster-than-for-loops">Are list-comprehensions and functional functions faster than "for loops"?</a></p>
<p>It may be worth a shot to see if this would be faster.</p>
</div>
<span class="comment-copy">Is there any particular reason that you aren't converting the pronunciations into <code>tuple</code> (so that you can hash them) and then tossing them into a <code>set</code>? Or a <code>dict</code> if you'd like to still map them to the original word.</span>
<span class="comment-copy">In other words, is this just a <a href="http://stackoverflow.com/questions/6509647/efficient-alternative-to-in/6509683">duplicate of this</a>?</span>
<span class="comment-copy">No. That's completely right. I suppose I didn't think dictionaries would be much faster. I was wrong. They are WAY faster (less than a second for 1000 lookups...).  Converting the pronunciations to tuples then making them the keys and using .get(pronunciation, False) to do some sort of error reporting. Works like a charm. Thanks.</span>
