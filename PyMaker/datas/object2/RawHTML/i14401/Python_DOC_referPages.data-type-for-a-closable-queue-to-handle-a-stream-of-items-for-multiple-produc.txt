<div class="post-text" itemprop="text">
<p>Is there a specific type of Queue that is "closable", and is suitable for when there are multiple producers, consumers, and the data comes from a stream (so its not known when it will end)?</p>
<p>I've been unable to find a queue that implements this sort of behavior, or a name for one, but it seems like a integral type for producer-consumer type problems.</p>
<p>As an example, ideally I could write code where (1) each producer would tell the queue when it was done, (2) consumers would blindly call a blocking get(), and (3) when all consumers were done, and the queue was empty, all the producers would unblock and receive a "done" notification:</p>
<p>As code, it'd look something like this:</p>
<pre><code>def produce():
  for x in range(randint()):
    queue.put(x)
    sleep(randint())
  queue.close()  # called once for every producer

def consume():
  while True:
    try:
      print queue.get()
    except ClosedQueue:
      print 'done!'
      break

num_producers = randint()
queue = QueueTypeThatICantFigureOutANameFor(num_producers)
[Thread(target=produce).start() for _ in range(num_producers)]
[Thread(target=consume).start() for _ in range(random())
</code></pre>
<p>Also, I'm <em>not</em> looking for the "Poison Pill" solution, where a "done" value is added to the queue for every consumer -- I don't like the inelegance of producers needing to know how many consumers there are.</p>
</div>
<div class="post-text" itemprop="text">
<p>I'd call that a self-latching queue.</p>
<p>For your primary requirement, combine the queue with a condition variable check that gracefully latches (shuts down) the queue when all producers have vacated:</p>
<pre><code>class SelfLatchingQueue(LatchingQueue):
  ...
  def __init__(self, num_producers):
    ...

  def close(self):
    '''Called by a producer to indicate that it is done producing'''

    ... perhaps check that current thread is a known producer? ...

    with self.a_mutex:
      self._num_active_producers -= 1
      if self._num_active_producers &lt;= 0:
        # Future put()s throw QueueLatched. get()s will empty the queue
        # and then throw QueueEmpty thereafter
        self.latch() # Guess what superclass implements this?
</code></pre>
<p>For your secondary requirement (#3 in the original post, finished producers apparently block until all consumers are finished), I'd perhaps use a <a href="https://docs.python.org/3/library/threading.html#barrier-objects" rel="nofollow">barrier</a> or just another condition variable.  This could be implemented in a subclass of the SelfLatchingQueue, of course, but without knowing the codebase I'd keep this behavior separate from the automatic latching.</p>
</div>
<span class="comment-copy">Yeah, I ended up going that route. I ended up subclassing Queue.Queue and having to copy and subtly modify <code>get()</code> and <code>put()</code> from Python 2.7's Queue.Queue. I think Python 3.x's queue would have been more amenable, but I'm currently stuck on 2.7</span>
