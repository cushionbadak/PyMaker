<div class="post-text" itemprop="text">
<p>How do I...</p>
<p>1) Parse JSON objects from API queries in Python 3</p>
<p>2) Parse multiple requests into a list, and</p>
<p>3) Output the list into a JSON file</p>
</div>
<div class="post-text" itemprop="text">
<p>I prefer using <a href="http://python-requests.org/" rel="nofollow"><code>requests</code></a> for all API programming. Here is a one-liner that fetches the results of several API calls, puts them in a list, and writes that list to a JSON file:</p>
<pre><code>json.dump([requests.get(url).json() for url in URLs], fp)
</code></pre>
<p>Here is a complete test program:</p>
<pre><code>import requests
import json

URLs = [
    # Some URLs that return JSON objects
    'http://httpbin.org/ip',
    'http://httpbin.org/user-agent',
    'http://httpbin.org/headers'
]

with open('result.json', 'w') as fp:
    json.dump([requests.get(url).json() for url in URLs], fp, indent=2)
</code></pre>
<p>If you are allergic to <code>requests</code> for some reason, here is equivalent Python3 code, using only the standard library.</p>
<pre><code>from urllib.request import urlopen
import json

URLs = [
    # Some URLs that return JSON objects
    'http://httpbin.org/ip',
    'http://httpbin.org/user-agent',
    'http://httpbin.org/headers'
]

json_list = []
for url in URLs:
    resp = urlopen(url)
    resp = resp.read().decode(resp.headers.get_content_charset() or 'ascii')
    json_list.append(json.loads(resp))
with open('result.json', 'w') as fp:
    json.dump(json_list, fp, indent=2)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><strong>1a) Parsing JSON from API (Python 2)</strong> </p>
<p>In Python 2 it was easier to implement JSON parsing:</p>
<pre><code>import urllib2

json_data = urllib2.urlopen(url)
data = json.load(json_data)            # load() from file
</code></pre>
<p>. </p>
<p><strong>1b) Parsing JSON from API (Python 3)</strong> </p>
<p>Python 3 dropped urllib2 and instead moved to a new standard for urllib:</p>
<pre><code>import urllib.request

json_data = urllib.request.urlopen(url)
</code></pre>
<p>However the data returned from this function can't be processed in the same way as before. As the type is 'HTTPResponse' we must first read and decode it into something we can use.</p>
<pre><code># returns a utf-8 'bytes' object which still can't be processed
json_data = urllib.request.urlopen(url).read()

# decode into a string
str_json_data = json_data.decode('utf-8')
</code></pre>
<p>Now that we have a string, we can use the loads() function to process it into a valid JSON dictionary.</p>
<pre><code>json_dict = json.loads(str_json_data)        # loads() from string
</code></pre>
<p>Notice the difference between the json.load() and json.loads() functions.</p>
<p>.</p>
<p><strong>2) Parse multiple requests into list</strong></p>
<p>Append to list as normal</p>
<pre><code>data.append(json_dict)
</code></pre>
<p>.</p>
<p><strong>3) Output to file</strong></p>
<pre><code>file = open("file.json", "w")
file.write(json.dumps(data))
file.close()
</code></pre>
<p>You can add indentation for formatting purposes:</p>
<pre><code>file.write(json.dumps(data, indent=4, sort_keys=True)
</code></pre>
</div>
<span class="comment-copy">My answer was working around a solution using the base language.  I wanted to avoid installing external packages as I'm a python newbie. That said, this does simplify the process. So thank you!</span>
<span class="comment-copy">My advice: always use  <code>requests</code>. Even the <a href="https://docs.python.org/3/library/urllib.request.html#module-urllib.request" rel="nofollow noreferrer">documentation for <code>urllib</code></a> recommends it! But, see my recent edit for a standard-library-only alternative.</span>
<span class="comment-copy">Advice and edit much appreciated</span>
