<div class="post-text" itemprop="text">
<p>So right now I've hardcoded 4 if/elif/else statements.  There there a more dynamic way to do this?  For example if I wanted to do a 10 or eve a 40 way merge?</p>
<pre><code>#4-way merge sort, sorted page files
outfile="fullsorted.txt"
of=open(outfile,"w")
f1=open("temp0-sorted.txt","r")
f2=open("temp1-sorted.txt","r")
f3=open("temp2-sorted.txt","r")
f4=open("temp3-sorted.txt","r")

f1_line=f1.readline()
f2_line=f2.readline()
f3_line=f3.readline()
f4_line=f4.readline()

while len(f1_line)&gt;0 and len(f2_line)&gt;0 and len(f3_line)&gt;0 and len(f4_line)&gt;0:
  if f1_line &lt; f2_line and f1_line &lt; f3_line and f1_line &lt; f4_line and len(f1_line)&gt;0:
    of.write(f1_line)
    f1_line=f1.readline()
  elif f2_line &lt; f3_line and f1_line &lt; f4_line and len(f2_line)&gt;0:
    of.write(f2_line)
    f2_line=f2.readline()
  elif f3_line &lt; f4_line and len(f3_line)&gt;0:
    of.write(f3_line)
    f3_line=f3.readline()
  else:
    of.write(f4_line)
    f4_line=f4.readline()

of.close()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just use <a href="https://docs.python.org/3/library/heapq.html#heapq.merge"><code>heapq.merge</code></a>:</p>
<pre><code>import heapq

#4-way merge sort, sorted page files
outfile="fullsorted.txt"

with open("temp0-sorted.txt","r") as f1,\
     open("temp1-sorted.txt","r") as f2,\
     open("temp2-sorted.txt","r") as f3,\
     open("temp3-sorted.txt","r") as f4,\
     open(outfile,"w") as of:
    of.writelines(heapq.merge(f1, f2, f3, f4))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using your own code pattern, extend it to a list-based approach like this:</p>
<pre><code>outfile="fullsorted.txt"
of=open(outfile,"w")
files = ["temp0-sorted.txt", "temp1-sorted.txt","temp2-sorted.txt","temp3-sorted.txt"]

filehandles = [open(f, "r") for f in files]

lines = [f.readline() for f in filehandles]

while len(filehandles) &gt; 0:
    smallest = min(lines)
    smallestposition = lines.index(smallest)
    of.write(smallest)
    lines[smallestposition] = filehandles[smallestposition].readline()
    if lines[smallestposition] == "":
        filehandles[smallestposition].close()
        filehandles.pop(smallestposition)
        lines.pop(smallestposition)

of.close()
</code></pre>
<p>Note that this will merge the entire files, rather than stopping as soon as one file runs out.</p>
</div>
<div class="post-text" itemprop="text">
<p>Thanks for the tips everyone, here's my solution:</p>
<pre><code>sorted_files=[]

strings=[]
for i in xrange(files+1):
  sorted_files.append(open("temp"+str(i)+"-sorted.txt","r"))
  strings.append(sorted_files[i].readline())

print len(sorted_files)
print strings
eofs=0
while eofs != 1:
  small_str=min(filter(lambda x: x != "", strings))
  str_index=strings.index(small_str)
  of.write(small_str)
  strings[str_index]=sorted_files[str_index].readline()
  if all(i =="" for i in strings):
    eofs=1
</code></pre>
<p>As a benchmark I tested this in a file with about 6.5 million lines (~700MB), paging it into 500,000 line files, then quick-sorting those in lexicographical order, and sort-merging (well just merging really) those with the code above, so about 128 files were merged, ( I had a 2 billion line file but accidentally deleted it, when deleting the pages files), and it sorted the file and found duplicates in 16 min: </p>
<pre><code>real    15m54.375s
user    15m52.096s
sys 0m3.000s
</code></pre>
<p>This was my first script of this nature, I'd be very happy if you could give me some feed back as if that page size was appropriate, and if the sort methods used were correct.  The page files were generated and sorted quickly, however the merging the most time.</p>
</div>
<span class="comment-copy">First, imagine a list: <code>l = [f1, f2, f3...]</code>.</span>
<span class="comment-copy">@DSM: Doesn't need modern Python; <code>heapq.merge</code> has been around since 2.6.</span>
<span class="comment-copy">@ShadowRanger: ah, you're right!  Then in terms of simplification that'll probably be the best across the board.</span>
<span class="comment-copy">I'm trying to do it without a built-in merge function, thanks for that tip though  (Also the files are too big for memory, so I'm reading them 1 line at a time)</span>
<span class="comment-copy">@TomFranks: <code>heapq.merge</code> is a generator function (reads its inputs lazily and writes them lazily; it's written surprisingly similarly to what your code is trying to do), and <code>writelines</code> writes lazily, so memory isn't an issue here.</span>
<span class="comment-copy">You can easily experiment with different page sizes and post the details yourself. It would also be useful to separately compare it against a run that uses the built in heapq.merge. I suspect that doing the temporary paging in memory (StringIO) will yield the most benefits. Just do a profiling run and see the results. Why ask others to speculate when you can easily determine the results on your machine yourself :)</span>
<span class="comment-copy">I can do limited for testing with now, IE, I only have 1 file size that is large.  And #2, there probably a better way to code it to make it more efficient, as I said this was my first program.  Here are the results from that: Results on a file with 64 million strings:   * 500000 line page files (128 files) = 15 min 46 sec   * 1000000 line page files (64 files) = 11 min 19 sec   * 2500000 line page files (26 files) = 8 min 28 sec   * 8000000 line page files (8 files) = 7 min 49 sec   * 16000000 line page files (4 files) = 7 min 58 sec</span>
