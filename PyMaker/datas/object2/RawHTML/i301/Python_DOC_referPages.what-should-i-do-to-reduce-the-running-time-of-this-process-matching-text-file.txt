<div class="post-text" itemprop="text">
<p>I am using the following code in which I have a dictionary file,  Dictionary.txt, and a search text file, SearchText.csv, and I am using regex to find and store the matching keywords and count them.</p>
<p>I have a problem: some of the files are thousands or hundreds of thousands of keywords and it takes too much time to process. I run the code on one dictionary which has 300,000 keywords and after an hour it hasn't written a single row.</p>
<p>So, what should I do to reduce the running time of this process?</p>
<pre><code>import csv
import time
import re
allCities = open('Dictionary.txt', encoding="utf8").readlines()
timestr = time.strftime("%Y-%m-%d-(%H-%M-%S)")
with open('SearchText.csv') as descriptions,open('Result---' + str(timestr) + '.csv', 'w', newline='') as output:
    descriptions_reader = csv.DictReader(descriptions)
    fieldnames = ['Sr_Num', 'Search', 'matched Keywords', 'Total matches']
    output_writer = csv.DictWriter(output, delimiter='|', fieldnames=fieldnames)
    output_writer.writeheader()
    line=0
    for eachRow in descriptions_reader:
        matches = 0
        Sr_Num = eachRow['Sr_Num']
        description = eachRow['Text']
        citiesFound = set()
        for eachcity in allCities:
            eachcity=eachcity.strip()
            if re.search('\\b'+eachcity+'\\b',description,re.IGNORECASE):
                citiesFound.add(eachcity)
                matches += 1
        if len(citiesFound)==0:
            output_writer.writerow({'Sr_Num': Sr_Num, 'Search': description, 'matched Keywords': " - ", 'Total matches' : matches})

        else:
            output_writer.writerow({'Sr_Num': Sr_Num, 'Search': description, 'matched Keywords': " , ".join(citiesFound), 'Total matches' : matches})
        line += 1
        print(line)

print(" Process Complete ! ")
</code></pre>
<p>Here is an example of some rows from Dictionary.txt:</p>
<pre><code>les Escaldes
Andorra la Vella
Umm al Qaywayn
Ras al Khaimah
Khawr Fakkn
Dubai
Dibba Al Fujairah
Dibba Al Hisn
Sharjah
Ar Ruways
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Your biggest time waster if this line:</p>
<pre><code>if re.search('\\b'+eachcity+'\\b',description,re.IGNORECASE):
</code></pre>
<p>You are searching the whole <code>description</code> for each <code>eachcity</code>. That's a lot of searching. Consider pre-splitting <code>description</code> into words with <code>nltk.word_tokenize()</code>, converting it to a set, converting <code>allCities</code> into a set as well, and taking a set intersect. Something like this:</p>
<pre><code>citiesFound = set(nltk.word_tokenize(description)) &amp; set(allCities)
</code></pre>
<p>No inner loop required.</p>
</div>
<div class="post-text" itemprop="text">
<p>Perform operations which only need to be executed once only once:</p>
<p>Instead of </p>
<pre><code>eachcity.strip()
</code></pre>
<p>and</p>
<pre><code>re.IGNORECASE
</code></pre>
<p>in the loop do</p>
<pre><code>allCities = [city.strip().lower() for city in allCities]
</code></pre>
<p>outside of the loop, and convert description to lowercase.</p>
<p>You can remove <code>matches += 1</code> as well, (it's the same as <code>len(citiesFound)</code>), but that will not give much improvement.</p>
<p>If you do not know where your bottleneck really is, look at the tips <a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips" rel="nofollow noreferrer">here</a> and <a href="https://www.python.org/doc/essays/list2str/" rel="nofollow noreferrer">here</a>. Also, <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">run a profiler on your code</a> to find the real culprit. <a href="https://stackoverflow.com/questions/582336/how-can-you-profile-a-python-script">There is also a SO question regarding profiling which is very useful</a>.</p>
<p>Another possibility is to use C or languages which are more optimized for text handling, like <code>awk</code> or <code>sed</code>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use databases instead of the file system.</p>
<p>In your case I'd probably use Elasticsearch or MongoDB.
Those systems are made for handling large amounts of data.</p>
</div>
<div class="post-text" itemprop="text">
<p>In addition to <a href="https://stackoverflow.com/a/54860406/1168212">Jan Christoph Terasa answer</a></p>
<h3>1. <code>allCities</code> - are candidate for <code>set</code></h3>
<p>So: </p>
<pre><code>allCities = set([city.strip().lower() for city in allCities])
</code></pre>
<p>and even more:</p>
<h3>2. Use <code>set</code> of precompiled regular expressions</h3>
<pre><code>allCities = set([re.compile( '\\b'+ city.strip().lower() + '\\b') for city in allCities])
</code></pre>
</div>
<span class="comment-copy"><code>csv.DictWriter</code> is buffered. The <code>.writerow()</code> method does not immediately write the results into the disk file. The fact that the file is empty does not mean that there is no progress. Consider printing something to the console to track the execution.</span>
<span class="comment-copy">I like the <code>set</code> approach here. Could use a <code>Counter</code> after that to get counts of cities matched.</span>
<span class="comment-copy">@TammoHeeren Sure. (Thought not required in the OP.)</span>
<span class="comment-copy">Correct. Thought OP was looking for individual counts, but was looking for total count only.</span>
