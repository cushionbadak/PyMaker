<div class="post-text" itemprop="text">
<p>I have a list of dicts:</p>
<pre class="lang-py prettyprint-override"><code>list1 = [
  { 'T': 1234, 'V': 10, 'O': 1 },
  { 'T': 2345, 'V': 50, 'O': 5 },
  { 'T': 2345, 'V': 30, 'O': 3 },
  { 'T': 3456, 'V': 40, 'O': 91 },
]
</code></pre>
<p>I need to sort these uniquely:</p>
<ul>
<li><code>T</code> should be unique</li>
<li>Whichever dict's <code>V</code> is larger should take precedence</li>
</ul>
<p>Which should produce:</p>
<pre><code>[
  {'T': 1234, 'V': 10, 'O': 1}, 
  {'T': 2345, 'V': 50, 'O': 5}, 
  {'T': 3456, 'V': 40, 'O': 91}
]
</code></pre>
<p>I came up with this:</p>
<pre class="lang-py prettyprint-override"><code>interm = {o['T']: o for o in list1}
for o in list1:
  if o['V'] &gt; interm[o['T']]['V']:
    interm[o['T']] = o
</code></pre>
<p>However I am effectively iterating the list twice, and setting the dictionary values multiple times. This feels like it could be improved, but I have no idea how I can do so.</p>
<p>Is there any faster way to accomplish this with the constraints given?</p>
</div>
<div class="post-text" itemprop="text">
<p>Assuming your list is already sorted by <code>T</code>, you could simply just keep track of the maximum <code>V</code> element in one pass, and replace the maximum if found:</p>
<pre><code>list1 = [
    { 'T': 1234, 'V': 10, 'O': 1 },
    { 'T': 2345, 'V': 50, 'O': 5 },
    { 'T': 2345, 'V': 30, 'O': 3 },
    { 'T': 3456, 'V': 40, 'O': 91 },
] 

unique = {}
for dic in list1:
    key = dic['T']
    found = unique.get(key)

    # If value found and doesn't exceed current maximum, just ignore
    if found and dic['V'] &lt;= found['V']:
        continue

    # otherwise just update normally
    unique[key] = dic

print(list(unique.values()))
# [{'T': 1234, 'V': 10, 'O': 1}, {'T': 2345, 'V': 50, 'O': 5}, {'T': 3456, 'V': 40, 'O': 91}]
</code></pre>
<p>If your list is not guaranteed to be sorted by <code>T</code>, you can apply sorting with <code>T</code> as the sorting <code>key</code> beforehand:</p>
<pre><code>from operator import itemgetter

sorted(list1, key=itemgetter('T'))
</code></pre>
<p>Using <a href="https://docs.python.org/3/library/operator.html#operator.itemgetter" rel="nofollow noreferrer"><code>operator.itemgetter</code></a> above is the same as using:</p>
<pre><code>sorted(list1, key=lambda x: x['T'])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Assuming <code>list1</code> is already sorted by <code>T</code> you can use <code>itertools.groupby</code>. </p>
<pre><code>from itertools import groupby

li = [
  { 'T': 1234, 'V': 10, 'O': 1 },
  { 'T': 2345, 'V': 50, 'O': 5 },
  { 'T': 2345, 'V': 30, 'O': 3 },
  { 'T': 3456, 'V': 40, 'O': 91 },
]

output = [max(group, key=lambda d: d['V'])
          for _, group in groupby(li, key=lambda d: d['T'])]

print(output)
# [{'T': 1234, 'V': 10, 'O': 1}, {'T': 2345, 'V': 50, 'O': 5}, {'T': 3456, 'V': 40, 'O': 91}]
</code></pre>
<p>In case it is not, <code>groupby</code> can still be used with <code>sort</code> in order to achieve an O(nlogn) solution</p>
<pre><code>order_by_t = lambda d: d['T']

li.sort(key=order_by_t)

output = [max(group, key=lambda d: d['V'])
          for _, group in groupby(li, key=order_by_t)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is the step by step approach. It iterates your list once and builds a new one:</p>
<pre><code>list1 = [
  { 'T': 1234, 'V': 10, 'O': 1 },
  { 'T': 2345, 'V': 50, 'O': 5 },
  { 'T': 2345, 'V': 30, 'O': 3 },
  { 'T': 3456, 'V': 40, 'O': 91 },
]

# add this step if not already sorted by T
# list1 = sorted(list1, key = lambda x: x["T"]) 

list2 = []
for e in list1:
    t, v, o = e["T"], e["V"], e["O"]

    # we already stored something and same T
    if list2 and list2[-1]["T"] == t:

        # smaller V ?
        if list2[-1]["V"] &lt; v:
            # overwrite dict elements
            list2[-1]["V"] = v
            list2[-1]["O"] = o

    # did not store anything or other T
    else:
        list2.append(e)

print(list2)
</code></pre>
<p>Output:</p>
<pre><code>[{'T': 1234, 'O': 1, 'V': 10}, 
 {'T': 2345, 'O': 5, 'V': 50}, 
 {'T': 3456, 'O': 91, 'V': 40}]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Question asked for "fastest" way - I timed the current approches with given data - seems RoadRunners works fastest on this dataset, mine comes second and DeepSpace's solution third. </p>
<pre><code>&gt;&gt;&gt; import timeit
&gt;&gt;&gt; timeit.timeit(p1,setup=up)        # https://stackoverflow.com/a/54957067/7505395
2.5858893489556913
&gt;&gt;&gt; timeit.timeit(p2,setup=up)        # https://stackoverflow.com/a/54957090/7505395
0.8051884429499854
&gt;&gt;&gt; timeit.timeit(p3,setup=up)        # https://stackoverflow.com/a/54957156/7505395
0.7680418536661247
</code></pre>
<hr/>
<p>Testcode:</p>
<pre><code>up = """from itertools import groupby

li = [
{ 'T': 1234, 'V': 10, 'O': 1 },
{ 'T': 2345, 'V': 50, 'O': 5 },
{ 'T': 2345, 'V': 30, 'O': 3 },
{ 'T': 3456, 'V': 40, 'O': 91 },
]"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957067/7505395">https://stackoverflow.com/a/54957067/7505395</a></p>
<pre><code>p1 = """
# li.sort(key=lambda x:x["T"]) # for the random data
output = [max(group, key=lambda d: d['V'])
        for _, group in groupby(li, key=lambda d: d['T'])]
"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957090/7505395">https://stackoverflow.com/a/54957090/7505395</a></p>
<pre><code>p2 = """
# li.sort(key=lambda x:x["T"]) # for the random data
list2 = []
for e in li:
    t, v, o = e["T"], e["V"], e["O"]

    # we already stored something and same T
    if list2 and list2[-1]["T"] == t:

        # smaller V ?
        if list2[-1]["V"] &lt; v:
            # overwrite dict elements
            list2[-1]["V"] = v
            list2[-1]["O"] = o

    # did not store anything or other T
    else:
        list2.append(e)
"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957156/7505395">https://stackoverflow.com/a/54957156/7505395</a></p>
<pre><code>p3 = """
unique = {}
for dic in li:
    key = dic['T']
    found = unique.get(key)

    # If value found and doesn't exceed current maximum, just ignore
    if found and dic['V'] &lt;= found['V']:
        continue

    # otherwise just update normally
    unique[key] = dic 
"""
</code></pre>
<hr/>
<p><strong>Edit (random 10k data - sorted and unsorted) to see if it is data dependent:</strong></p>
<p>Randomized data: 10000 datapoints with <code>T [1,100] - V [10,20,..,200] - "O" [1,1000000]</code></p>
<pre><code>up = """
from itertools import groupby
import random

random.seed(42)

def r():
    # few T so we get plenty of dupes
    return {"T":random.randint(1,100), "V":random.randint(1,20)*10, 
            "O":random.randint(1,1000000)}
li = [ r() for _ in range(10000)]

# li.sort(key=lambda x:x["T"])  # uncommented for pre-sorted run

"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957067/7505395">https://stackoverflow.com/a/54957067/7505395</a></p>
<pre><code>p1 = """
li.sort(key=lambda x:x["T"])  # needs sorting, commented for pre-sorted run
output = [max(group, key=lambda d: d['V'])
        for _, group in groupby(li, key=lambda d: d['T'])]
"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957090/7505395">https://stackoverflow.com/a/54957090/7505395</a></p>
<pre><code>p2 = """ 
li.sort(key=lambda x:x["T"])  # needs sorting, commented for pre-sorted run
list2 = []
for e in li:
    t, v, o = e["T"], e["V"], e["O"]

    # we already stored something and same T
    if list2 and list2[-1]["T"] == t:

        # smaller V ?
        if list2[-1]["V"] &lt; v:
            # overwrite dict elements
            list2[-1]["V"] = v
            list2[-1]["O"] = o

    # did not store anything or other T
    else:
        list2.append(e)
"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957156/7505395">https://stackoverflow.com/a/54957156/7505395</a></p>
<pre><code>p3 = """
unique = {}
for dic in li:
    key = dic['T']
    found = unique.get(key)

    # If value found and doesn't exceed current maximum, just ignore
    if found and dic['V'] &lt;= found['V']:
        continue

    # otherwise just update normally
    unique[key] = dic 
"""
</code></pre>
<hr/>
<p>Source: <a href="https://stackoverflow.com/a/54957363/7505395">https://stackoverflow.com/a/54957363/7505395</a></p>
<pre><code>p4 = """ 
t_v = {}
result = []
for row in li:
    if not t_v.get(row['T']):
        t_v[row['T']] = (row['V'], len(result))
        result.append(row)
        continue

    if row['V'] &gt; t_v[row['T']][0]:
        t_v[row['T']] = (row['V'], t_v[row['T']][1])
        result[t_v[row['T']][1]] = row
"""
</code></pre>
<hr/>
<p><strong>Results with sorting inside p1/p2:</strong> </p>
<pre><code>import timeit
timeit.timeit(p1,setup=up, number=100)       0.4958197257468498      4th
timeit.timeit(p2,setup=up, number=100)       0.4506078658396253      3rd
timeit.timeit(p3,setup=up, number=100)       0.24399979946368378     1st
timeit.timeit(p4,setup=up, number=100)       0.2561938286132954      2nd
</code></pre>
<p><strong>Results on presorted data:</strong></p>
<pre><code>timeit.timeit(p1,setup=up, number=100)       0.3046940103986765      3rd
timeit.timeit(p2,setup=up, number=100)       0.33943337437485366     4th
timeit.timeit(p3,setup=up, number=100)       0.2795306502784811      1st
timeit.timeit(p4,setup=up, number=100)       0.29027710723995326     2nd
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>To do this is in a single loop on an unsorted table, I created a lookup table to store information about the current result array. The lookup table stores 'T' as a key with the 'V' value and the index of the item in the result list. </p>
<p>When looping through the data you can check the 'T' value against the lookup table key. </p>
<p>If the key doesn't exist, add it. </p>
<p>If it does compare its value against the rows 'V' value. </p>
<p>You can use the stored index to replace the previous row if the current row 'V' is greater.</p>
<pre><code>arr = [
    {'T': 2345, 'V': 50, 'O': 5},
    {'T': 1234, 'V': 10, 'O': 1},
    {'T': 2345, 'V': 30, 'O': 3},
    {'T': 3456, 'V': 40, 'O': 91},
]


def filter_out_lowest_values(arr):
lookup = {}
result = []
for row in arr:
    row_key, row_value = row['T'], row['V']
    if not lookup.get(row_key):
        lookup[row_key] = (row_value, len(result))
        result.append(row)
        continue

    lookup_value, result_index = lookup[row_key][0], lookup[row_key][1]
    if row_value &gt; lookup_value:
        lookup[row_key] = (row_value, result_index)
        result[result_index] = row

return result


print(filter_out_lowest_values(arr))
</code></pre>
<p>Result:</p>
<pre><code>&gt; [{'T': 1234, 'V': 40, 'O': 91}, {'T': 2345, 'V': 150, 'O': 5}, {'T': 3456, 'V': 40, 'O': 91}]
</code></pre>
<p>To answer the question of what is the fastest way to uniquify the list please see the benchmarks below. </p>
<p>It is highly dependent on the data that is provided. The length of the list, whether or not it is sorted and the amount of unique keys all play a part.</p>
<p>From my benchmarks I found Patrick Artners to be the fastest on a sorted list. While my own is the fastest on an unsorted list once it's lookup table is fully populated.</p>
<h2>Benchmark Comparisons</h2>
<p>Each script has been run 100 times for each <code>n</code> value, the fastest (min) runtime has been plotted. </p>
<p><a href="https://i.stack.imgur.com/bCuXt.png" rel="nofollow noreferrer"><img alt="Unsorted Data Benchmarks" src="https://i.stack.imgur.com/bCuXt.png"/></a></p>
<pre><code>Unsorted Benchmarks
N = 10
------
|  min          |  avg          |  max          |  func                      |  name            |
|---------------|---------------|---------------|----------------------------|------------------|
|  0.000006437  |  0.000007293  |  0.000022173  |  sarcoma                   |  sarcoma         |
|  0.000007153  |  0.000007646  |  0.000017881  |  road_runner_with_sort     |  RoadRunner      |
|  0.000007868  |  0.000008337  |  0.000013351  |  patrick_artner_with_sort  |  Patrick_Artner  |
|  0.000015497  |  0.000017719  |  0.000026703  |  deep_space_with_sort      |  DeepSpace       |

N = 100
------
|  min          |  avg          |  max          |  func                      |  name            |
|---------------|---------------|---------------|----------------------------|------------------|
|  0.000043154  |  0.000045519  |  0.000057936  |  road_runner_with_sort     |  RoadRunner      |
|  0.000053883  |  0.000056396  |  0.000069141  |  sarcoma                   |  sarcoma         |
|  0.000055075  |  0.000057223  |  0.000063181  |  patrick_artner_with_sort  |  Patrick_Artner  |
|  0.000135660  |  0.000145028  |  0.000174046  |  deep_space_with_sort      |  DeepSpace       |

N = 1000
------
|  min          |  avg          |  max          |  func                      |  name            |
|---------------|---------------|---------------|----------------------------|------------------|
|  0.000294447  |  0.000559096  |  0.000992775  |  road_runner_with_sort     |  RoadRunner      |
|  0.000327826  |  0.000374844  |  0.000650883  |  patrick_artner_with_sort  |  Patrick_Artner  |
|  0.000344276  |  0.000605364  |  0.002207994  |  sarcoma                   |  sarcoma         |
|  0.000758171  |  0.001031160  |  0.002290487  |  deep_space_with_sort      |  DeepSpace       |

N = 10000
------
|  min          |  avg          |  max          |  func                      |  name            |
|---------------|---------------|---------------|----------------------------|------------------|
|  0.003607988  |  0.003875387  |  0.005285978  |  road_runner_with_sort     |  RoadRunner      |
|  0.003780127  |  0.004181504  |  0.005370378  |  sarcoma                   |  sarcoma         |
|  0.003986597  |  0.004258037  |  0.006756544  |  patrick_artner_with_sort  |  Patrick_Artner  |
|  0.007097244  |  0.007444410  |  0.009983778  |  deep_space_with_sort      |  DeepSpace       |

N = 25000
------
|  min          |  avg          |  max          |  func                      |  name            |
|---------------|---------------|---------------|----------------------------|------------------|
|  0.009672165  |  0.010055504  |  0.011536598  |  sarcoma                   |  sarcoma         |
|  0.019844294  |  0.022260010  |  0.027792931  |  road_runner_with_sort     |  RoadRunner      |
|  0.020462751  |  0.022415347  |  0.029330730  |  patrick_artner_with_sort  |  Patrick_Artner  |
|  0.024955750  |  0.027981100  |  0.031506777  |  deep_space_with_sort      |  DeepSpace  
</code></pre>
<p><a href="https://i.stack.imgur.com/wo2xs.png" rel="nofollow noreferrer"><img alt="Sorted Data Benchmarks" src="https://i.stack.imgur.com/wo2xs.png"/></a></p>
<pre><code>Sorted Benchmarks
N = 10
------
|  min          |  avg          |  max          |  func            |  name            |
|---------------|---------------|---------------|------------------|------------------|
|  0.000002861  |  0.000003138  |  0.000005960  |  road_runner     |  RoadRunner      |
|  0.000002861  |  0.000003231  |  0.000012398  |  patrick_artner  |  Patrick_Artner  |
|  0.000004292  |  0.000004461  |  0.000007629  |  sarcoma         |  sarcoma         |
|  0.000008821  |  0.000009136  |  0.000011921  |  deep_space      |  DeepSpace       |

N = 100
------
|  min          |  avg          |  max          |  func            |  name            |
|---------------|---------------|---------------|------------------|------------------|
|  0.000020027  |  0.000020833  |  0.000037909  |  road_runner     |  RoadRunner      |
|  0.000021458  |  0.000024126  |  0.000087738  |  patrick_artner  |  Patrick_Artner  |
|  0.000033140  |  0.000034373  |  0.000049591  |  sarcoma         |  sarcoma         |
|  0.000072241  |  0.000073054  |  0.000085592  |  deep_space      |  DeepSpace       |

N = 1000
------
|  min          |  avg          |  max          |  func            |  name            |
|---------------|---------------|---------------|------------------|------------------|
|  0.000200748  |  0.000207791  |  0.000290394  |  patrick_artner  |  Patrick_Artner  |
|  0.000207186  |  0.000219207  |  0.000277519  |  road_runner     |  RoadRunner      |
|  0.000333071  |  0.000369296  |  0.000570774  |  sarcoma         |  sarcoma         |
|  0.000635624  |  0.000721800  |  0.001362801  |  deep_space      |  DeepSpace       |

N = 10000
------
|  min          |  avg          |  max          |  func            |  name            |
|---------------|---------------|---------------|------------------|------------------|
|  0.002717972  |  0.002925014  |  0.003932238  |  patrick_artner  |  Patrick_Artner  |
|  0.002796888  |  0.003489044  |  0.004799843  |  road_runner     |  RoadRunner      |
|  0.004704714  |  0.005460148  |  0.008680582  |  sarcoma         |  sarcoma         |
|  0.005549192  |  0.006385834  |  0.009561062  |  deep_space      |  DeepSpace       |

N = 25000
------
|  min          |  avg          |  max          |  func            |  name            |
|---------------|---------------|---------------|------------------|------------------|
|  0.010142803  |  0.011239243  |  0.015279770  |  patrick_artner  |  Patrick_Artner  |
|  0.011211157  |  0.012368391  |  0.014696836  |  road_runner     |  RoadRunner      |
|  0.014389753  |  0.015374193  |  0.022623777  |  sarcoma         |  sarcoma         |
|  0.016021967  |  0.016560717  |  0.019297361  |  deep_space      |  DeepSpace       |

     |

</code></pre>
<p>Benchmark scripts can be found at: <a href="https://github.com/sarcoma/python-script-benchmark-tools/blob/master/examples/filter_out_lowest_duplicates.py" rel="nofollow noreferrer">https://github.com/sarcoma/python-script-benchmark-tools/blob/master/examples/filter_out_lowest_duplicates.py</a></p>
</div>
<span class="comment-copy">is <code>list1</code> already going to be sorted by <code>T</code>?</span>
<span class="comment-copy">Ideally yes, but it can't be guaranteed.</span>
<span class="comment-copy">I've been playing around a lot with benchmarking Python scripts lately, I've added some further analysis of the scripts. Please see my updated answer for more info.</span>
<span class="comment-copy">Oh this is interesting, I must have messed up trying to time it myself.</span>
<span class="comment-copy">for reference: <a href="https://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer">docs.python.org/3/library/timeit.html</a>  - you can put functions in the code as well - but then you need to put the function call including its parameters below that definition so it gets called as well. And you do not want to put "print" in the timeit - they are slow and falsify the results because they take most of the time needed</span>
<span class="comment-copy">One thing to note, there is a bias as mine benefits from the small range of <code>'T'</code>, due to the look up table. I generated <code>'T'</code> from 1000-9999 and ran 100000, which balances it out a bit.</span>
<span class="comment-copy">Experiment with the code given - if you copy/concatenate the parts it should be a <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a> to experiment with :) I simply copy all and paste it into the interactive python console - you might need to remove some &gt;&gt;&gt; or ... first or remove the outputs I pasted directly behind the calls.</span>
<span class="comment-copy">Updated my answer. From my tests your script is the fastest on sorted data, mine is the fastest on unsorted data that greater than the necessary size of the lookup table, ie it becomes faster once the lookup table is fully populated. RoadRunners script without converting to <code>list(unique.values)</code> produces:  <code>{3456: {'O': 91, 'V': 40, 'T': 3456}, 2345: {'O': 5, 'V': 50, 'T': 2345}, 1234: {'O': 1, 'V': 10, 'T': 1234}}</code>, so my tests include the conversion.</span>
