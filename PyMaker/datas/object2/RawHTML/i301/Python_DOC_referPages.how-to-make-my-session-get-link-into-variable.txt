<div class="post-text" itemprop="text">
<p>My goal is to scrape multiple profile links and then scrape specific data on each of these profiles.</p>
<p>Here is my code to get multiple profile links (it should work fine):</p>
<pre><code>from bs4 import BeautifulSoup
from requests_html import HTMLSession
import re
session = HTMLSession()
r = session.get('https://www.khanacademy.org/computing/computer-science/algorithms/intro-to-algorithms/v/what-are-algorithms')
r.html.render(sleep=5)

soup=BeautifulSoup(r.html.html,'html.parser')

profiles = soup.find_all(href=re.compile("/profile/kaid"))

for links in profiles:
    links_no_list = links.extract()
    text_link = links_no_list['href']
    text_link_nodiscussion = text_link[:-10]
    final_profile_link ='https://www.khanacademy.org'+text_link_nodiscussion
    print(final_profile_link)
</code></pre>
<p>Now here is my code to get the specific data on just one profile (it should work fine too):</p>
<pre><code>from bs4 import BeautifulSoup
from requests_html import HTMLSession
session = HTMLSession()
import re
r = session.get('https://www.khanacademy.org/profile/Kkasparas/')
r.html.render(sleep=5)

soup=BeautifulSoup(r.html.html,'html.parser')

user_info_table=soup.find('table', class_='user-statistics-table')

if user_info_table is not None:
    dates,points,videos=[tr.find_all('td')[1].text for tr in user_info_table.find_all('tr')]
else:
    dates=points=videos='NA'

user_socio_table=soup.find_all('div', class_='discussion-stat')

data = {}
for gettext in user_socio_table:
   category = gettext.find('span')
   category_text = category.text.strip()
   number = category.previousSibling.strip()
   data[category_text] = number

full_data_keys=['questions','votes','answers','flags raised','project help requests','project help replies','comments','tips and thanks']
for header_value in full_data_keys:
    if header_value not in data.keys():
        data[header_value]='NA'

user_calendar = soup.find('div',class_='streak-calendar-scroll-container')

if user_calendar is not None:
    #for getdate in user_calendar:
    last_activity = user_calendar.find('span',class_='streak-cell filled')
    last_activity_date = last_activity['title']
    #print(last_activity)
    #print(last_activity_date)
else:
    last_activity_date='NA'


filename = "khanscraptry1.csv"
f = open(filename, "w")
headers = "date_joined, points, videos, questions, votes, answers, flags, project_request, project_replies, comments, tips_thx, last_date\n"
f.write(headers)
f.write(dates + "," + points.replace("," , "") + "," + videos + "," + data['questions'] + "," + data['votes'] + "," + data['answers'] + "," + data['flags raised'] + "," + data['project help requests'] + "," + data['project help replies'] + "," + data['comments'] + "," + data['tips and thanks'] + "," + last_activity_date + "\n")
f.close()
</code></pre>
<p>My question is : how can I automate my scripts? 
In other words: How can I merge these two scripts? </p>
<p>The goal is to create a sort of variable that is going to be a different profile link every time. </p>
<p>And then for each profile link to get the specific data and then put it into the csv file (a new row for each profile).</p>
</div>
<div class="post-text" itemprop="text">
<p>It is fairly very straight forward to do this. I instead of printing the profile links store them to  a <a href="https://docs.python.org/3/tutorial/introduction.html#lists" rel="nofollow noreferrer"><em>list variable</em></a>. Then loop through the list variable to scrap each link and then write to the <em>csv</em> file. Some pages do not have all the details so you have to <a href="https://docs.python.org/3/tutorial/errors.html#handling-exceptions" rel="nofollow noreferrer">handle</a> those exceptions as well. In the code below I have marked them also as 'NA', following the convention used in your code. One other note for future is to consider using the python's inbuilt <em><a href="https://docs.python.org/3.7/library/csv.html" rel="nofollow noreferrer">csv module</a></em> for reading and writing csv files. </p>
<p><em>Merged Script</em></p>
<pre><code>from bs4 import BeautifulSoup
from requests_html import HTMLSession
import re
session = HTMLSession()
r = session.get('https://www.khanacademy.org/computing/computer-science/algorithms/intro-to-algorithms/v/what-are-algorithms')
r.html.render(sleep=5)
soup=BeautifulSoup(r.html.html,'html.parser')
profiles = soup.find_all(href=re.compile("/profile/kaid"))
profile_list=[]
for links in profiles:
    links_no_list = links.extract()
    text_link = links_no_list['href']
    text_link_nodiscussion = text_link[:-10]
    final_profile_link ='https://www.khanacademy.org'+text_link_nodiscussion
    profile_list.append(final_profile_link)
filename = "khanscraptry1.csv"
f = open(filename, "w")
headers = "date_joined, points, videos, questions, votes, answers, flags, project_request, project_replies, comments, tips_thx, last_date\n"
f.write(headers)
for link in profile_list:
    print("Scrapping ",link)
    session = HTMLSession()
    r = session.get(link)
    r.html.render(sleep=5)
    soup=BeautifulSoup(r.html.html,'html.parser')
    user_info_table=soup.find('table', class_='user-statistics-table')
    if user_info_table is not None:
        dates,points,videos=[tr.find_all('td')[1].text for tr in user_info_table.find_all('tr')]
    else:
        dates=points=videos='NA'
    user_socio_table=soup.find_all('div', class_='discussion-stat')
    data = {}
    for gettext in user_socio_table:
        category = gettext.find('span')
        category_text = category.text.strip()
        number = category.previousSibling.strip()
        data[category_text] = number
    full_data_keys=['questions','votes','answers','flags raised','project help requests','project help replies','comments','tips and thanks']
    for header_value in full_data_keys:
        if header_value not in data.keys():
            data[header_value]='NA'
    user_calendar = soup.find('div',class_='streak-calendar-scroll-container')
    if user_calendar is not None:
        last_activity = user_calendar.find('span',class_='streak-cell filled')
        try:
            last_activity_date = last_activity['title']
        except TypeError:
            last_activity_date='NA'
    else:
        last_activity_date='NA'
    f.write(dates + "," + points.replace("," , "") + "," + videos + "," + data['questions'] + "," + data['votes'] + "," + data['answers'] + "," + data['flags raised'] + "," + data['project help requests'] + "," + data['project help replies'] + "," + data['comments'] + "," + data['tips and thanks'] + "," + last_activity_date + "\n")
f.close()
</code></pre>
<p><em>Sample Output from khanscraptry1.csv</em></p>
<pre><code>date_joined, points, videos, questions, votes, answers, flags, project_request, project_replies, comments, tips_thx, last_date
6 years ago,1527829,1123,25,100,2,0,NA,NA,0,0,Saturday Jun 4 2016
6 years ago,1527829,1123,25,100,2,0,NA,NA,0,0,Saturday Jun 4 2016
6 years ago,3164708,1276,164,2793,348,67,16,3,5663,885,Wednesday Oct 31 2018
6 years ago,3164708,1276,164,2793,348,67,16,3,5663,885,Wednesday Oct 31 2018
NA,NA,NA,18,NA,0,0,NA,NA,0,NA,Monday Dec 24 2018
NA,NA,NA,18,NA,0,0,NA,NA,0,NA,Monday Dec 24 2018
5 years ago,240334,56,7,42,6,0,2,NA,12,2,Tuesday Nov 20 2018
5 years ago,240334,56,7,42,6,0,2,NA,12,2,Tuesday Nov 20 2018
...
</code></pre>
</div>
<span class="comment-copy">Hello Bitto, I have two questions : how can you make the script work faster ? (without omitting profiles links or data) and how could I improve the script to avoid getting the same profile link multiple times? It seems that the script is getting every profile link twice. It might generate bias when I will do statistical analysis with the database. Do you know how to improve that? Thanks again for your huge help :) !</span>
<span class="comment-copy">@Robz The links are present twice in you selection. That is why you are getting that output.  Change the looping statement to <code>for link in profile_list[::2]:</code> to scrap only the second links. This alone will reduce the time by approximately half.</span>
<span class="comment-copy">@RobZ Read this : <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/#improving-performance" rel="nofollow noreferrer">crummy.com/software/BeautifulSoup/bs4/doc/â€¦</a></span>
<span class="comment-copy">I would like to get more profile links by clicking <code>show more button</code> and <code>see more replies</code> buttons, still on <code>'https://www.khanacademy.org/computing/computer-science/algorithms/intro-to-algorithms/v/what-are-algorithms'</code>. It looks like I should use Selenium to do that. My question: is there a way to implement that in the merged script you provided? Or should I just re-do the entire code with selenium?</span>
<span class="comment-copy">I created a question for it: <code>https://stackoverflow.com/q/54953671/10972294</code></span>
