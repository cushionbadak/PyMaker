<div class="post-text" itemprop="text">
<p>I was just checking the size of some datatypes in Python 3 and I observed this.</p>
<pre><code>import sys

val = None
print(sys.getsizeof(val))
</code></pre>
<p>The output was <code>16</code> as expected.</p>
<p>I tried making a list of 1000 locations of <code>None</code> and I expected the size to be <code>16*1000 = 16000</code> or more. But the result I got was different.</p>
<pre><code>import sys

val = [None]*1000

print(sys.getsizeof(val))
</code></pre>
<p>The output was <code>8064</code>. Nearly the half of the size I expected. </p>
<p>What is the reason for this.? Why memory allocated is less.? </p>
</div>
<div class="post-text" itemprop="text">
<pre><code>import sys

val = None

print(sys.getsizeof(val))

Answer:

16

val = []

print(sys.getsizeof(val))

Answer: 

72

val = [None]

print(sys.getsizeof(val))

Answer:

80

so [None]*1000 = 1000* 8 + 72 = 8072
</code></pre>
<p>Note: <em>No of bytes may vary depending on the environment</em></p>
</div>
<div class="post-text" itemprop="text">
<p>There is just a single <code>None</code> object referenced a thousand times.  So the situation is this:</p>
<pre><code>l[0]   ----&gt; None
         /    ^
l[1]   -/     |
….            |
l[999]  -----/
</code></pre>
<p>And not this:</p>
<pre><code>l[0]   ----&gt; None

l[1]   ----&gt; None
….
l[999] ----&gt; None
</code></pre>
<p>This is more visible when repeating a mutable object, like this:</p>
<pre><code>&gt;&gt;&gt; l = [set()] * 3
&gt;&gt;&gt; print(l)
[set(), set(), set()]
&gt;&gt;&gt; l[0].add(1)
&gt;&gt;&gt; print(l)
[{1}, {1}, {1}]
</code></pre>
<p>There is just a single, shared <code>set</code> object referenced three times, so changes to the set at <code>l[0]</code> also affect <code>l[1]</code> and <code>l[2]</code>.</p>
<p>Python data structures such as <code>list</code>, <code>set</code> and <code>dict</code> are reference-based.  In your case, most of the 8064 bytes you observed come from the object references (8 bytes per list element).</p>
</div>
<span class="comment-copy"><code>sys.getsizeof</code> returns only the size of the <i>container</i> (so, the container overhead and for the list the array of Py_Object pointers, on a 64-bit system, 8 bytes per pointer), not the objects inside the list. In this case, however, since <code>None</code> is a singleton, the total size is simply <code>sys.getsizeof(val) + sys.getsizeof(None)</code>. In general, if a list references all unique objects, you have to get <code>sys.getsizeof(my_list) + sum(map(sys.getsizeof, my_list))</code>. Often, it is between these two extremes.</span>
<span class="comment-copy">@juanpa.arrivillaga Great Explanation. Thanks</span>
<span class="comment-copy">Note, from the <a href="https://docs.python.org/3/library/sys.html#sys.getsizeof" rel="nofollow noreferrer">docs</a>: "Only the memory consumption directly attributed to the object is accounted for, not the memory consumption of objects it refers to." It also provides a <a href="https://code.activestate.com/recipes/577504" rel="nofollow noreferrer">link to a recursive sizeof recipe</a> which will handle most complex objects (for example, caching based on identity).</span>
<span class="comment-copy">On my system, <code>sys.getsizeof([]) == 64</code>, like in the OP. (Though I guess it varies.)</span>
<span class="comment-copy">You're undercounting by 8 bytes here.</span>
<span class="comment-copy">So what if I used a list and appended None to 1000 loations.?</span>
<span class="comment-copy">Same result because there is only a single <code>None</code> object.</span>
<span class="comment-copy">upvotes for the ascii art :)</span>
<span class="comment-copy">@SreeramTP <code>None</code> is a singleton, the same with <code>True</code> and <code>False</code>.</span>
<span class="comment-copy">@juanpa.arrivillaga Got it. Thanks</span>
