<div class="post-text" itemprop="text">
<p>I was writing a code in python to find factor pairs for an integer. But making pairs resulted in reverse pairs as well. I want to eliminate those reverse pairs using a simple method without importing any modules.
for eg.</p>
<p><code>[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]</code></p>
<p>the output should be:</p>
<pre><code>[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
<p>This is what I've got so far:</p>
<pre><code>N = []
J = []
F = []
Z = []
S = []
num = input("Enter no. of elements in list")
print ('Enter numbers')
prod = 1
for i in range(int(num)):
    n = input("num :")
    N.append(int(n))
for x in N:
    prod = prod*x
print (prod)
k = input("Enter no. of splits:")
for o in range(1,prod+1):
    if prod%o == 0:
        J.append(o)
        F.append(o)
print (J)

Z = [[a, b] for a in J for b in F if a*b == prod]
print (Z)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>&gt;&gt;&gt; l = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]
&gt;&gt;&gt; new_l = []
&gt;&gt;&gt; for e in l:
...     if e not in new_l and sorted(e) not in new_l:
...         new_l.append(e)
... 
&gt;&gt;&gt; new_l
[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
&gt;&gt;&gt; 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Using <code>set</code> to remove duplicates.</p>
<p><strong>Ex:</strong></p>
<pre><code>lst = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]
lst = set([tuple(sorted(i)) for i in lst])      #Sort inner list and then use set
lst = list(map(list, lst))                      #Converting back to list
print(lst)
</code></pre>
<p><strong>Output:</strong></p>
<pre><code>[[8, 25], [4, 50], [1, 200], [10, 20], [2, 100], [5, 40]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the input is large, there is a significant performance advantage by using sets instead of lists.</p>
<pre><code>&gt;&gt;&gt; unique = set(map(frozenset, pairs))
&gt;&gt;&gt; unique
{frozenset({1, 200}),
 frozenset({10, 20}),
 frozenset({5, 40}),
 frozenset({2, 100}),
 frozenset({8, 25}),
 frozenset({4, 50})}
</code></pre>
<p>The inner sets must be <code>frozenset</code> because regular sets are mutable, and sets can only contain immutable children.</p>
<p>To convert back to a list of lists.</p>
<pre><code>&gt;&gt;&gt; list(map(list, unique))
[[200, 1], [10, 20], [40, 5], [2, 100], [8, 25], [50, 4]]
</code></pre>
<p>Sets are iterable, so depending on your usage, this step might not be needed.</p>
<p>Here's a function that does both steps and returns the result as a nested list.</p>
<pre><code>def unique_pairs(pairs): 
    return list(map(list,set(map(frozenset, pairs))))
</code></pre>
<p>Note that converting a list into a set will convert a list containing an identical pairs (for example <code>[20,20]</code>) to a single element set (<code>{20}</code>). So if your input can contain identical pairs, you might want to do an extra final step to expand singletons back to pairs.</p>
<pre><code>def unique_pairs(pairs):
    return [(2*[*p])[:2] for p in set(map(frozenset,pairs))]
</code></pre>
<p>This will work with bot twin pairs and mixed pairs.</p>
<pre><code>&gt;&gt;&gt; pairs = [[10, 2], [2, 10], [10, 10], [2, 2]]
&gt;&gt;&gt; unique_pairs(pairs)
[[10, 10], [2, 2], [10, 2]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can keep a set to keep track of what has been seen, and use a <a href="https://docs.python.org/3/library/stdtypes.html#frozenset" rel="nofollow noreferrer"><code>frozenset()</code></a> to hash the lists into the seen set:</p>
<pre><code>seen = set()
result = []
for sublst in lst:
    curr = frozenset(sublst)
    if curr not in seen:
        seen.add(curr)
        result.append(sublst)

print(result)
</code></pre>
<p>Which Outputs:</p>
<pre><code>[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
<p>If you later want to use libraries, you could use a <a href="https://docs.python.org/3/library/collections.html#collections.OrderedDict" rel="nofollow noreferrer"><code>collections.OrderedDict()</code></a>:</p>
<pre><code>lst = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]

d = OrderedDict()
for sublist in lst:
    d.setdefault(frozenset(sublist), sublist)

print(list(d.values()))
# [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>myList = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]
newList = myList.copy()
for i, j in newList:
    newList.remove([j,i])

print (newList)
#[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="http://toolz.readthedocs.io/en/latest/api.html#toolz.itertoolz.unique" rel="nofollow noreferrer"><code>toolz.unique</code></a> to maintain ordering at the outer level. If you don't have access to the 3rd party <code>toolz</code> library, you can use the <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer"><code>unique_everseen</code></a> recipe from the official docs.</p>
<pre><code>L = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20],
     [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]

from toolz import unique

res = list(unique(map(tuple, map(sorted, L))))

print(res)

[(1, 200), (2, 100), (4, 50),
 (5, 40), (8, 25), (10, 20)]
</code></pre>
<p>Tuple conversion is required since <code>unique</code> uses hashing; and tuples are hashable while lists are not. If it's important you have a list of lists, you can apply an extra conversion:</p>
<pre><code>res = list(map(list, unique(map(tuple, map(sorted, L)))))
</code></pre>
<p>At this stage, it's not particularly readable, so I suggest you split into a few steps:</p>
<pre><code>sorter = map(sorted, L)
uniquify = unique(map(tuple, sorter))
res = list(map(list, uniquify))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I am expecting downvote because my answer seems abit off topic.</p>
<p>In the first place, you only have to check value up to int((prod+1)**0.5)+1 which ensures no duplicates.</p>
<pre><code>N = []
J = []
F = []
Z = []
S = []
num = input("Enter no. of elements in list: ")
print ('Enter numbers')
prod = 1
for i in range(int(num)):
    n = input("num :")
    N.append(int(n))
for x in N:
    prod = prod*x
print (prod)
k = input("Enter no. of splits:")
for o in range(1,int(prod**0.5)+1):
    if prod%o == 0:
        Z.append([o,prod//o])
print (Z)
</code></pre>
<p>Result:</p>
<pre><code>Enter no. of elements in list: 1
Enter numbers
num :200
Enter no. of splits:0
[1, 2, 4, 5, 8, 10]
[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think in this case you can use some domain knowledge here. Specifically, you will get the pairs <code>[x, y]</code> (I recommend you make this a tuple (specifically a 2-tuple, otherwise known as a <em>pair</em>) not an array), and <code>[y,x]</code> except when <code>x=y</code> where you get it only once. So you can write a simple function:</p>
<pre><code>def unique_factors(all_factors):
  [ [a,b] for [a,b] in all_factors if a &lt;= b ]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It's actually quite tricky to get that right in a general way.</p>
<p>It essentially boils down to two basic problems:</p>
<ul>
<li>Checking if two lists contain the same elements</li>
<li>Remove all lists that contain the same elements</li>
</ul>
<p>I'll tackle these separately.</p>
<h2>Check if two lists contain the same elements</h2>
<p>I best to refer to Raymond Hettingers answer from <a href="https://stackoverflow.com/a/7829388/5393381">here</a>:</p>
<blockquote>
<p><strong>O(n)</strong>:  The <em><a href="https://docs.python.org/library/collections.html#collections.Counter" rel="nofollow noreferrer">Counter()</a></em> method is best (if your objects are hashable):</p>
<pre><code>from collections import Counter
def compare(s, t):
    return Counter(s) == Counter(t)
</code></pre>
<p><strong>O(n log n)</strong>:  The <em><a href="https://docs.python.org/library/functions.html#sorted" rel="nofollow noreferrer">sorted()</a></em> method is next best (if your objects are orderable):</p>
<pre><code>def compare(s, t):
    return sorted(s) == sorted(t)
</code></pre>
<p><strong>O(n * n)</strong>: If the objects are neither hashable, nor orderable, you can use equality:</p>
<pre><code>def compare(s, t):
    t = list(t)   # make a mutable copy
    try:
        for elem in s:
            t.remove(elem)
    except ValueError:
        return False
    return not t
</code></pre>
</blockquote>
<p>In your case you don't want any imports so you could replace <code>collections.Counter</code> with:</p>
<pre><code>def count(it):
    d = {}
    for item in it:
        try:
            d[item] += 1
        except KeyError:
            d[item] = 1
    return d
</code></pre>
<p>Just in case the items are hashable and you don't care about the count of the items (for example <code>[1,1,2]</code> should be interpreted as equal to <code>[1,2,2]</code>) or they will always be unique then you could also use <code>set</code>s:</p>
<pre><code>def compare(s, t):
    return set(s) == set(t)
</code></pre>
<p>So that way you can check if two sublists contain the same elements. There are possible optimizations in case you <em>might</em> have lists of different lengths, then it could be worthwhile to add a:</p>
<pre><code>if len(s) != len(t):
    return False
</code></pre>
<p>At the beginning of each of these functions.</p>
<h2>Removing duplicates from the list</h2>
<p>That also depends on assumptions about the result (should the non-duplicates keep their relative order or not) and the contents (again, can you hash the contents or can they be ordered).</p>
<p>If the items are hashable (or could be converted to something hashable) you could use a <code>set</code> call to remove duplicates. If you care about the order you can still use a set but only for lookups, for example the recipe from the itertools documentation <a href="https://docs.python.org/library/itertools.html#itertools-recipes" rel="nofollow noreferrer"><code>unique_everseen</code></a>:</p>
<pre><code>from itertools import filterfalse

def unique_everseen(iterable, key=None):
    "List unique elements, preserving order. Remember all elements ever seen."
    # unique_everseen('AAAABBBCCDAABBB') --&gt; A B C D
    # unique_everseen('ABBCcAD', str.lower) --&gt; A B C D
    seen = set()
    seen_add = seen.add
    if key is None:
        for element in filterfalse(seen.__contains__, iterable):
            seen_add(element)
            yield element
    else:
        for element in iterable:
            k = key(element)
            if k not in seen:
                seen_add(k)
                yield element
</code></pre>
<p>You mentioned no imports but fortunately we don't need the <code>key is None</code> part anyway (see below) so you can simple use:</p>
<pre><code>def unique_everseen(iterable, key):
    seen = set()
    seen_add = seen.add
    for element in iterable:
        k = key(element)
        if k not in seen:
            seen_add(k)
            yield element
</code></pre>
<p>Note that the approaches to compare the inner lists use sets, dictionaries and lists which are unhashable. But all of them can be converted to a hashable collections, like frozensets or tuples:</p>
<pre><code># for sets
frozenset(s)

# for dictionaries
frozenset(d.items())

# for lists
tuple(l)
</code></pre>
<p>However the last approach (if the items are unhashable and cannot be ordered) can't be used with this approach so let's ignore it for now.</p>
<p>Basically you could then use <code>unique_everseen</code> like this:</p>
<pre><code>list(unique_everseen(your_list, key=lambda sublist: frozenset(count(sublist).items())))
# Or with collections.Counter instead of count
</code></pre>
<p>Or if you don't care about the duplicates (or there will be no duplicates) inside your sublists:</p>
<pre><code>list(unique_everseen(your_list, key=frozenset))
</code></pre>
<p>Or if they are not hashable but can be ordered:</p>
<pre><code>list(unique_everseen(your_list, key=lambda sublist: tuple(sorted(sublist))))
</code></pre>
<p>Just the approach in case the items in your sublist are not hashable and not orderable cannot be done using that fast <code>unique_everseen</code> approach. You'll have to use a slower variant:</p>
<pre><code>def compare(s, t):
    t = list(t)   # make a mutable copy
    try:
        for elem in s:
            t.remove(elem)
    except ValueError:
        return False
    return not t

def unique_everseen_slow(iterable):
    seen = []
    for element in iterable:
        for already_seen_item in seen:
            if compare(element, already_seen_item):
                break  # We found a match, so stop looking
        else:
            seen.append(element)
            yield element

list(unique_everseen_slow(your_list))
</code></pre>
<p>The <code>else</code> clause belongs to the <code>for</code> loop and is only entered when there was no <code>break</code>. You could instead also check for <a href="https://docs.python.org/library/functions.html#any" rel="nofollow noreferrer"><code>any</code></a> to avoid this <code>for</code>-<code>else</code>:</p>
<pre><code>def unique_everseen_slow(iterable):
    seen = []
    for element in iterable:
        if not any(compare(element, seen_element) for seen_element in seen):
            seen.append(element)
            yield element
</code></pre>
<hr/>
<p>In your case it's actually very easy because the integers in the sublists are hashable and orderable. But this can become very complex for more general cases.</p>
<p>However in your case you could even avoid creating duplicate factors by simply checking that the factors are sorted (and if not stop):</p>
<pre><code>def factors(number):
    for candidate in range(1, number + 1):
        if number % candidate == 0:
            other_factor = number // candidate
            if candidate &gt; other_factor:
                return
            yield [candidate, other_factor]
</code></pre>
<p>For example:</p>
<pre><code>&gt;&gt;&gt; list(factors(200))
[[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>lst = [[1, 200], [2, 100], [4, 50], [5, 40], [8, 25], [10, 20], [20, 10], [25, 8], [40, 5], [50, 4], [100, 2], [200, 1]]

[list(i) for i in set([tuple(sorted(i)) for i in l]))]
</code></pre>
<p>Answer: </p>
<pre><code>[(8, 25), (4, 50), (1, 200), (10, 20), (2, 100), (5, 40)]
</code></pre>
<p>Explanation: </p>
<p>First we need to sort each list so that we can make duplicate list look similar. Then we need to convert each list into tuple so that we can use set() to eliminate duplicates.</p>
<p>We can use use List as it is since elements of list has to be hashable to use set().</p>
<pre><code>set([tuple(sorted(i)) for i in l]) 
</code></pre>
<p>this gives us the set of all the elements with out duplicates. But its a set and each element is a tuple but they should be lists.</p>
<p>we can use list comprehension to convert the tuple elements into lists.</p>
</div>
<span class="comment-copy">You should share the code that produced your results.</span>
<span class="comment-copy">Why don't you make sure that your algorithm does not produce the reverse pairs in the first place, by e.g. making sure that you only accept <code>[a, b]</code> when <code>a &lt; b</code>?</span>
<span class="comment-copy">Why not iterate up to the square root of num instead of generating more numbers than necessary and then filtering? Seems wasteful to me</span>
<span class="comment-copy">list reversal will not work for triple element lists. For eg. [1,2,1] as a case of [2,1,1]/[1,1,2].</span>
<span class="comment-copy">Updated the answer to use <code>sorted</code> instead of <code>reversed</code>. Can you check if this fixes your issue</span>
<span class="comment-copy">This time it worked well. Last time I tried, it just gave the same list. But still, I am having a hard time figuring out how this line works.and why did it didn't work for <code>Sorted(Z)</code> and instead worked out for list(sorted(e))</span>
<span class="comment-copy">If performance matters, this solution is not ideal. O(n^2) compared to O(n) for solutions using a set instead of a list. If your input is small, this might not be noticeable, but for large inputs this can be very slow.</span>
<span class="comment-copy">are there any other ways to achieve this??</span>
<span class="comment-copy">I am not sure what you mean?</span>
<span class="comment-copy">Modifying the thing you're iterating over is the stuff of my nightmares.</span>
<span class="comment-copy">Instead of the "o not in F" check, you could check for only divisibility and iterate values of o only up to the square root of prod rounded up + 1 (since any factors greater than the square root of the product will necessarily have been appended to F).  This saves both loop iterations and repeated searches within the values in F (both of which could cause this code to run slowly for large values of prod).</span>
<span class="comment-copy">@ redyoshi49q, correct, updated.</span>
<span class="comment-copy">Your edit throws an error; you can't use a float value as a bound for a range statement (I tested using <a href="http://www.pythontutor.com/visualize.html" rel="nofollow noreferrer">pythontutor.com/visualize.html</a> set to emulate Python 3.6).  Using range(1,int(round(prod**0.5))+1) works as expected.</span>
<span class="comment-copy">@redyoshi49q,ya, updated, forget the bound should be an integer.</span>
<span class="comment-copy">Also note that Using range(1,int(round((prod+1)**0.5))) will /not/ work for edge cases.  For instance, when prod=36, we want to iterate over the elements 1 through 6 inclusive; however, prod+1 == 37, and the square root of that rounds to 6, which range will /exclude/.</span>
<span class="comment-copy">What if I don't have pairs and have triplets and quadruples instead</span>
<span class="comment-copy">If we’re still talking about factorisations then I’d map over your list of factorisations, sorting each one and then make a set out of the whole thing.</span>
