<div class="post-text" itemprop="text">
<p>I am new to selenium in python (and all web-interface applications of python) and I have a task to complete for my present internship.</p>
<p>My script successfully navigates to an online database and inputs information from my data tables, but then the webpage in question takes anywhere from 30 seconds to several minutes to compute an output.</p>
<p>How do I go about instructing python to re-check the page every 30 seconds until the output appears so that I can parse it for the data I need? For instance, which functions might be I start with?</p>
<p>This will be part of a loop repeated for over 200 entries, and hundreds more if I am successful so it is worth my time to automate it.</p>
<p>Thanks</p>
</div>
<div class="post-text" itemprop="text">
<p>You should use Seleniums Waits as pointed by G_M and Sam Holloway.
One which I most use is the <a href="http://selenium-python.readthedocs.io/waits.html" rel="nofollow noreferrer">expected_conditions</a>:</p>
<pre><code>from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

driver = webdriver.Firefox()
driver.get("http://somedomain/url_that_delays_loading")
try:
    element = WebDriverWait(driver, 10).until(
        EC.presence_of_element_located((By.ID, "myDynamicElement"))
    )
finally:
    driver.quit()
</code></pre>
<p>It will wait until there is an element with id "myDynamicElement" and then execute the try block, which should contain the rest of your work. 
I prefer to use the the class By.XPATH, but if you use By.XPATH with the method presence_of_element_located add another () so it will be the required tuple as noted in <a href="https://stackoverflow.com/questions/23661734/selenium-visibility-of-element-located-init-takes-exactly-2-arguments">this answer</a>:</p>
<pre><code>from selenium.webdriver.common.by import By

driver.find_element(By.XPATH, '//button[contains(text(),"Some text")]')
driver.find_element(By.XPATH, '//div[@id="id1"]')
driver.find_elements(By.XPATH, '//a')
</code></pre>
<p>The easiest way to find (for me) the XPATH of an element is going to the developer mode in chrome (F12), pressing ctrl+F, and using the mouse with inspect, trying to compose the proper XPATH, which will be specific enough to find just the expected element, or the least number of elements as possible.</p>
<p>All the examples are from (or based) the <a href="http://selenium-python.readthedocs.io/waits.html" rel="nofollow noreferrer">great selenium documentation</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you just want to space out checks, the <a href="https://docs.python.org/3/library/time.html" rel="nofollow noreferrer"><code>time.sleep()</code></a> function should work.</p>
<p>However, as G_M's comment says, you should look into <a href="https://selenium-python.readthedocs.io/waits.html" rel="nofollow noreferrer">Selenium waits</a>. Think about this: is there an element on the page that will indicate that the result is loaded? If so, use a Selenium wait on that element to make sure your program is only pausing until the result is loaded and not wasting any time afterwards.</p>
</div>
<span class="comment-copy"><a href="https://selenium-python.readthedocs.io/waits.html" rel="nofollow noreferrer">selenium-python.readthedocs.io/waits.html</a> ?</span>
<span class="comment-copy">is selenium the right tool here?  if the web page in question provides an API, it might be better for you to write a script that will create multiple threads, submit your requests, then query for the results directly through the API.  Just a thought.</span>
<span class="comment-copy">Thanks, before reading this post I did in fact try Selenium Waits and it works very well, although my code is probably not as robust as this and finds an element by ID instead of XPATH.</span>
<span class="comment-copy">The code is from the official documentation, the second block it was a small adaptation, but it is good to use try, except and finally when working in a unstable task as web scraping. Also, you should accept the best answer for your question.</span>
<span class="comment-copy">Terrific, I will look into those functions and see if I can get them to work</span>
