<div class="post-text" itemprop="text">
<p>When speaking about asynchronous I/O, I want to understand the difference between <a href="http://man7.org/linux/man-pages/man7/aio.7.html" rel="nofollow noreferrer">POSIX</a> interface used in Linux and <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">concurrent.futures</a> interface used in Python. I use the former one when I want to achieve asynchronous I/O in <code>C</code> code and the latter one in <code>python</code> code. I understand that <code>concurrent.futures</code> in python is a thread-based technique that attaches a callback to a thread so that it can be polled later for its status. However, I don't know how POSIX works! Is it also thread based as well?</p>
<p>Thank you</p>
</div>
<div class="post-text" itemprop="text">
<p><code>concurrent.futures</code> is not specifically thread based (there are thread and process based executors available), nor is it specifically about async I/O; it's general parallelism. You <em>could</em> parallelize I/O with it, but it's the worker tasks that are async, with the I/O being a specific thing that can be parallelized.</p>
<p>As it happens, for I/O, you would <em>want</em> to use the <code>ThreadPoolExecutor</code>; <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow noreferrer">CPython's GIL</a> isn't a problem for I/O bound tasks, and the IPC necessary to return results from a <code>ProcessPoolExecutor</code>'s worker processes would largely eliminate the benefits of parallelizing the I/O. I just wanted to be clear that <code>concurrent.futures</code> is not purely about threads.</p>
<p>POSIX AIO is, at least on Linux, just a user space library wrapping threads (roughly equivalent to using <code>concurrent.futures.ThreadPoolExecutor</code> to perform your I/O tasks), per <a href="http://man7.org/linux/man-pages/man7/aio.7.html#NOTES" rel="nofollow noreferrer">the NOTES in the man page you linked</a>:</p>
<blockquote>
<p>The current Linux POSIX AIO implementation is provided in user space by glibc.  This has a number of limitations, most notably that maintaining multiple threads to perform I/O operations is expensive and scales poorly.  Work has been in progress for some time on a kernel state-machine-based implementation of asynchronous I/O (see io_submit(2), io_setup(2), io_cancel(2), io_destroy(2), io_getevents(2)), but this implementation hasn't yet matured to the point where the POSIX AIO implementation can be completely reimplemented using the kernel system calls.</p>
</blockquote>
<p>Point is, in both cases, it's fundamentally about dispatching I/O requests in background threads with handles of some sort to allow polling and retrieval of results.</p>
<p>Kernel supported async I/O could avoid or limit threading by any of the following:</p>
<ol>
<li>Internally managing the I/O request queues, perhaps merely dispatching them serially, working with the disk driver to order the requests such that the head seeks across them and pulls them efficiently</li>
<li>Dispatching in parallel, and responding to device interrupts to signal completion</li>
<li>Using a shared thread pool (similar to user space, but lower overhead since the whole OS can share the pool)</li>
</ol>
<p>but none of these techniques are actually used in Linux's implementation of POSIX AIO, and if any of them were used in Python via <code>concurrent.futures</code>, it would be a hand-rolled solution (since as mentioned, <code>concurrent.futures</code> performs arbitrary parallelism, it doesn't specifically support I/O).</p>
</div>
<span class="comment-copy"><code>concurrent.futures</code> also includes a <code>ProcessPoolExecutor</code> which will execute <i>tasks</i> in other processes.</span>
<span class="comment-copy"><code>concurrent.futures</code> isn't about I/O <i>at all</i>, so we're thoroughly apples-and-oranges here.</span>
<span class="comment-copy">Very well written post. Thank you for clarification</span>
