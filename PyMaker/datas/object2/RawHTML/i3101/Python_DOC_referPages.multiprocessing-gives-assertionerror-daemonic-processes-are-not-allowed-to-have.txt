<div class="post-text" itemprop="text">
<p>I am trying to use multiprocessing for the first time. So I thought I would make a very simple test example which factors 100 different numbers.</p>
<pre><code>from multiprocessing import Pool
from primefac import factorint
N = 10**30
L = range(N,N + 100)
pool = Pool()
pool.map(factorint, L)
</code></pre>
<p>This gives me the error:</p>
<pre><code>Traceback (most recent call last):
  File "test.py", line 8, in &lt;module&gt;
    pool.map(factorint, L)
  File "/usr/lib/python2.7/multiprocessing/pool.py", line 251, in map
    return self.map_async(func, iterable, chunksize).get()
  File "/usr/lib/python2.7/multiprocessing/pool.py", line 567, in get
    raise self._value
AssertionError: daemonic processes are not allowed to have children
</code></pre>
<p>I see that <a href="https://stackoverflow.com/questions/6974695/python-process-pool-non-daemonic">Python Process Pool non-daemonic?</a> discusses this problem but I don't understand why it is relevant to my simple toy example.  What am I doing wrong?</p>
</div>
<div class="post-text" itemprop="text">
<p>The problem appears to be that <code>primefac</code> uses its own <code>multiprocessing.Pool</code>. Unfortunately, while PyPI is down, I can't find the source to the module—but I did find various forks on GitHub, like <a href="https://github.com/elliptic-shiho/primefac-fork/blob/master/primefac.py" rel="nofollow noreferrer">this one</a>, and they all have <code>multiprocessing</code> code.</p>
<p>So, your apparently simple example isn't all that simple—because it's importing and running non-simple code.</p>
<p>By default, all <code>Pool</code> processes are daemonic, so you can't create more child processes from inside another <code>Pool</code>. Usually, attempting to do so is a mistake. </p>
<p>If you really do want to multiprocess the factors even though some of them are going to multiprocess their own work (quite possibly adding more contention overhead without adding any parallelism), then you just have to subclass <code>Pool</code> and override that—as explained in <a href="https://stackoverflow.com/questions/6974695/python-process-pool-non-daemonic">the related question that you linked</a>.</p>
<p>But the simplest thing is to just not use <code>multiprocessing</code> here, if <code>primefac</code> is already using your cores efficiently. (If you need quasi-concurrency, getting answers as they come in instead of getting them in sequence, I suppose you could do that with a <em>thread</em> pool, but I don't think there's any advantage to that here—you're not using <code>imap_unordered</code> or explicit <code>AsyncResult</code> anywhere.)</p>
<p>Alternatively, if it's <em>not</em> using all of your cores most of the time, only doing so for the "tricky remainders" at the end of factoring some numbers, while you've got 7 cores sitting idle for 60% of the time… then you probably want to prevent <code>primefac</code> from using <code>multiprocessing</code> at all. I don't know if the module has a public API for doing that. If so, of course, just use it. If not… well, you may have to subclass or monkeypatch some of its code, or, at worst, monkeypatching its import of <code>multiprocessing</code>, and that may not be worth doing.</p>
<p>The <em>ideal</em> solution would probably be to refactor <code>primefac</code> to push the "tricky remainder" jobs onto the same pool you're already using. But that's probably by far the most work, and not that much more benefit.</p>
<hr/>
<p>As a side note, this isn't your problem, but you should have a <code>__main__</code> guard around your top-level code, like this:</p>
<pre><code>from multiprocessing import Pool
from primefac import factorint

if __name__ == '__main__':
    N = 10**30
    L = range(N,N + 100)
    pool = Pool()
    pool.map(factorint, L)
</code></pre>
<p>Otherwise, when run with the <code>spawn</code> or <code>forkserver</code> startmethods—and notice that <code>spawn</code> is the only one available on Windows—each pool process is going to try to create another pool of children. So, if you run your code on Windows, you would get this same assertion—as a way for <code>multiprocessing</code> to protect you from accidentally forkbombing your system.</p>
<p>This is explained under <a href="https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods" rel="nofollow noreferrer">safe importing of main module</a> in the "programming guidelines" section of the <code>multiprocessing</code> docs.</p>
</div>
<span class="comment-copy">Are you on Windows?</span>
<span class="comment-copy">@abarnert Ubuntu 16.04.4 and 2.7.12</span>
<span class="comment-copy">OK, so that's not the issue. You <i>should</i> do the <code>__main__</code> guard anyway, but failing to do so won't break anything on linux.</span>
<span class="comment-copy">Next question: what's that <code>primefac</code> module? Is it trying to use a <code>multiprocessing.Pool</code> internally? (Sorry; I think it's a common library on PyPI, so normally I'd just go check it myself, but <a href="https://status.python.org/" rel="nofollow noreferrer">PyPI is down for maintenance at the moment…</a>)</span>
<span class="comment-copy">@abarnert I just did <code>pip install primefac</code> . It is from <a href="https://pypi.org/project/primefac/" rel="nofollow noreferrer">pypi.org/project/primefac</a> . I don't know how it works internally sadly.</span>
<span class="comment-copy">Your code gives the same error for me in python 2.7.12. <code>Traceback (most recent call last):   File "test.py", line 8, in &lt;module&gt;     pool.map(factorint, L)   File "/usr/lib/python2.7/multiprocessing/pool.py", line 251, in map     return self.map_async(func, iterable, chunksize).get()   File "/usr/lib/python2.7/multiprocessing/pool.py", line 567, in get     raise self._value AssertionError: daemonic processes are not allowed to have children</code></span>
<span class="comment-copy">The answer seems to be just to use ThreadPool as a drop in replacement!</span>
<span class="comment-copy">@Anush As I said in the answer, you can do that, but I don't think you'll get any benefit, unless you want to get the results as they come in rather than in-order. I suppose it's possible that the threads spend just enough time in multiprocessing but not too much, so it would significantly improve concurrency, but it doesn't seem all that likely you'd get that lucky.'</span>
