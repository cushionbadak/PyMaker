<div class="post-text" itemprop="text">
<pre><code>import multiprocessing as mp

if __name__ == '__main__':

    #pool = mp.Pool(M)

    p1 = mp.Process(target= target1, args= (arg1,))
    p2 = mp.Process(target= target2, args= (arg1,))
    ...
    p9 = mp.Process(target= target9, args= (arg9,))
    p10 = mp.Process(target= target10, args= (arg10,))
    ...
    pN = mp.Process(target= targetN, args= (argN,))

    processList = [p1, p2, .... , p9, p10, ... ,pN]
</code></pre>
<p>I have N different target functions which consume unequal non-trivial amount of time to execute. </p>
<p>I am looking for a way to execute them in parallel such that M (1 &lt; M &lt; N) processes are running simultaneously. And as soon as a process is finished next process should start from the list, until all the processes in <code>processList</code> are completed.</p>
<p>As I am not calling the same target function, I could not use <code>Pool</code>.</p>
<p>I considered doing something like this:</p>
<pre><code>    for i in range(0, N, M):
        limit = i + M
        if(limit &gt; N):
            limit = N
        for p in processList[i:limit]:
            p.join()
</code></pre>
<p>Since my target functions consume unequal time to execute, this method is not really efficient.</p>
<p>Any suggestions? Thanks in advance.</p>
<p>EDIT:
Question title has been changed to 'Execute a list of process without multiprocessing pool map' from 'Execute a list of process without multiprocessing pool'.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is a way to do it in Python 3.4, which could be adapted for Python 2.7 :</p>
<pre><code>targets_with_args = [
    (target1, arg1),
    (target2, arg2),
    (target3, arg3),
    ...
]

with concurrent.futures.ProcessPoolExecutor(max_workers=20) as executor:
    futures = [executor.submit(target, arg) for target, arg in targets_with_args]
    results = [future.result() for future in concurrent.futures.as_completed(futures)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow">proccess Pool</a>:</p>
<pre><code>#!/usr/bin/env python
# coding=utf-8

from multiprocessing import Pool
import random
import time


def target_1():
    time.sleep(random.uniform(0.5, 2))
    print('done target 1')

def target_2():
    time.sleep(random.uniform(0.5, 2))
    print('done target 1')

def target_3():
    time.sleep(random.uniform(0.5, 2))
    print('done target 1')

def target_4():
    time.sleep(random.uniform(0.5, 2))
    print('done target 1')


pool = Pool(2) # maximum two processes at time.
pool.apply_async(target_1)
pool.apply_async(target_2)
pool.apply_async(target_3)
pool.apply_async(target_4)
pool.close()
pool.join()
</code></pre>
<p>Pool is created specifically for what you need to do - execute many tasks in limited number of processes.</p>
<p>I also suggest you take a look at <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"><code>concurrent.futures</code></a> library and it's <a href="https://pypi.python.org/pypi/futures" rel="nofollow">backport to Python 2.7</a>. It has a <a href="https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor" rel="nofollow"><code>ProcessPoolExecutor</code></a>, which has roughly same capabilities, but it's methods returns <a href="https://docs.python.org/3/library/concurrent.futures.html#future-objects" rel="nofollow"><code>Future</code></a> objects, and they has a nicer API.</p>
</div>
<div class="post-text" itemprop="text">
<p>I would use a <code>Queue</code>. adding processes to it from <code>processList</code>, and as soon as a process is finished i would remove it from the queue and add another one.</p>
<p>a pseudo code will look like:</p>
<pre><code>from Queue import Queue
q = Queue(m)

# add first process to queue
i = 0
q.put(processList[i])
processList[i].start()
i+=1

while not q.empty():
    p=q.get()

    # check if process is finish. if not return it to the queue for later checking
    if p.is_alive():
        p.put(t)

    # add another process if there is space and there are more processes to add
    if not q.full() and i &lt; len(processList):
        q.put(processList[i])
        processList[i].start()
        i+=1
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A simple solution would be to wrap the functions target{1,2,...N} into a single function forward_to_target that forwards to the appropriate target{1,2,...N} function according to the argument that is passed in. If you cannot infer the appropriate target function from the arguments you currently use, replace each argument with a tuple (argX, X), then in the forward_to_target function unpack the tuple and forward to the appropriate function indicated by the X.</p>
</div>
<div class="post-text" itemprop="text">
<p>You could have two <code>list</code>s of targets and arguments, <code>zip</code> the two together - and send them to a runner function (here it's <code>run_target_on_args</code>):</p>
<pre><code>#!/usr/bin/env python

import multiprocessing as mp

# target functions
targets = [len, str, len, zip]

# arguments for each function
args = [["arg1"], ["arg2"], ["arg3"], [["arg5"], ["arg6"]]]

# applies target function on it's arguments
def run_target_on_args(target_args):
    return target_args[0](*target_args[1])

pool = mp.Pool()
print pool.map(run_target_on_args, zip(targets, args))
</code></pre>
</div>
<span class="comment-copy">You could rearrange your code to have only one target.</span>
<span class="comment-copy">Yes, rearranging could solve the problem. I am reluctant to do that because my targets belong to different modules and it is a part of a 'big' project. Thank you @BenjaminToueg!</span>
<span class="comment-copy">You can do this using a pool. Having different functions only precludes you from using <code>Pool.map</code>. See Gill Bates answer.</span>
<span class="comment-copy">I only now noticed that you asking <code>...without multiprocessing pool</code>, why you have this requirement? You will end up implementing your own pool or executor with a queue.</span>
<span class="comment-copy">do you need to "replace" the pool's logic ?</span>
<span class="comment-copy">This seems to be a better solution than using a single function.</span>
<span class="comment-copy">See my answer for <code>ProcessPoolExecutor</code></span>
