<div class="post-text" itemprop="text">
<p>I am using scrapy to crawl a site which seems to be appending random values to the query string at the end of each URL. This is turning the crawl into a sort of an infinite loop.</p>
<p>How do i make scrapy to neglect the query string part of the URL's?</p>
</div>
<div class="post-text" itemprop="text">
<p>See <a href="http://docs.python.org/release/3.1.3/library/urllib.parse.html">urllib.urlparse</a></p>
<p>Example code:</p>
<pre><code>from urlparse import urlparse
o = urlparse('http://url.something.com/bla.html?querystring=stuff')

url_without_query_string = o.scheme + "://" + o.netloc + o.path
</code></pre>
<p>Example output:</p>
<pre><code>Python 2.6.1 (r261:67515, Jun 24 2010, 21:47:49) 
[GCC 4.2.1 (Apple Inc. build 5646)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from urlparse import urlparse
&gt;&gt;&gt; o = urlparse('http://url.something.com/bla.html?querystring=stuff')
&gt;&gt;&gt; url_without_query_string = o.scheme + "://" + o.netloc + o.path
&gt;&gt;&gt; print url_without_query_string
http://url.something.com/bla.html
&gt;&gt;&gt; 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There is a function <code>url_query_cleaner</code> in <code>w3lib.url</code> module (used by scrapy itself) to clean urls keeping only a list of allowed arguments.</p>
</div>
<div class="post-text" itemprop="text">
<p>Provide some code, so we can help you.</p>
<p>If you are using <code>CrawlSpider</code> and <code>Rule</code>'s with <code>SgmlLinkExtractor</code>, provide custom function to <code>proccess_value</code> parameter of <code>SgmlLinkExtractor</code> constructor.</p>
<p>See documentation for <a href="http://doc.scrapy.org/en/latest/topics/link-extractors.html#basesgmllinkextractor" rel="noreferrer">BaseSgmlLinkExtractor</a></p>
<pre><code>def delete_random_garbage_from_url(url):
    cleaned_url = ... # process url somehow
    return cleaned_url

Rule(
    SgmlLinkExtractor(
         # ... your allow, deny parameters, etc
         process_value=delete_random_garbage_from_url,
    )
)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use the <a href="https://docs.python.org/3/library/urllib.parse.html" rel="nofollow noreferrer"><code>urllib.parse.urlsplit()</code> function</a>. The result is a <a href="https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object" rel="nofollow noreferrer"><em>structured parse result</em></a>, a named tuple with added functionality.</p>
<p>Use the <code>namedtuple._replace()</code> method to alter the parsed result values, then use the <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urllib.parse.SplitResult.geturl" rel="nofollow noreferrer"><code>SplitResult.geturl()</code> method</a> to get a URL string again.</p>
<p>To remove the query string, set the <code>query</code> value to <code>None</code>:</p>
<pre><code>from urllib.parse import urlsplit

updated_url = urlsplit(url)._replace(query=None).geturl()
</code></pre>
<p>Demo:</p>
<pre><code>&gt;&gt;&gt; from urllib.parse import urlsplit
&gt;&gt;&gt; url = 'https://example.com/example/path?query_string=everything+after+the+questionmark'
&gt;&gt;&gt; urlparse.urlsplit(url)._replace(query=None).geturl()
'https://example.com/example/path'
</code></pre>
<p>For Python 2, the same function is available under the <a href="https://docs.python.org/2/library/urlparse.html#urlparse.urlsplit" rel="nofollow noreferrer"><code>urlparse.urlsplit()</code> name</a>.</p>
<p>You could also use the <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse" rel="nofollow noreferrer"><code>urllparse.parse.urlparse()</code> function</a>; for URLs without any <a href="https://tools.ietf.org/html/rfc2396.html#section-3.3" rel="nofollow noreferrer">path parameters</a>, the result would be the same. The two functions differ in how path parameters are handled; <code>urlparse()</code> only supports path parameters for the last segment of the path, while <code>urlsplit()</code> leaves path parameters in place in the path, leaving parsing of such parameters to other code. Since path parameters are rarely used these days [later URL RFCs have dropped the feature altogether), the difference is academical. <code>urlparse()</code> uses <code>urlsplit()</code> and without parameters, doesn't add anything other than extra overhead. It is better to just use <code>urlsplit()</code> directly.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you are using BaseSpider, before yielding a new request, remove manually random values from the query part of the URL using <a href="http://docs.python.org/library/urlparse.html" rel="nofollow">urlparse</a>:</p>
<pre><code>def parse(self, response):
    hxs = HtmlXPathSelector(response)
    item_urls = hxs.select(".//a[@class='...']/@href").extract()
    for item_url in item_urls:
        # remove the bad part of the query part of the URL here
        item_url = urlparse.urljoin(response.url, item_url)
        self.log('Found item URL: %s' % item_url)
        yield Request(item_url, callback = self.parse_item)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>use this method to remove query string from url</p>
<pre><code>urllink="http://url.something.com/bla.html?querystring=stuff"
url_final=urllink.split('?')[0]
print(url_final)
</code></pre>
<p>output will be:
<a href="http://url.something.com/bla.html" rel="nofollow noreferrer">http://url.something.com/bla.html</a></p>
</div>
<span class="comment-copy">Should this be: <code>from urllib.parse import urlparse</code> ?</span>
<span class="comment-copy">@RyanCady yes <code>from urllib.parse import urlparse</code> worked for me.</span>
<span class="comment-copy">@RyanCady: In Python 3, yes, but in Python 2 it should not.</span>
<span class="comment-copy">Don't manually reconstruct. Use <code>o._replace(query=None).geturl()</code></span>
<span class="comment-copy">Both the first and second answercombined seem to solve my problem.I am not sure how i can mark both answers are correct</span>
