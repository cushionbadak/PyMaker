<div class="post-text" itemprop="text">
<p>I have several test modules that are all invoked together via a driver script that can take a variety of arguments.  The tests themselves are written using the python unittest module.  </p>
<pre><code>import optparse
import unittest
import sys
import os

from tests import testvalidator
from tests import testmodifier
from tests import testimporter

#modify the path so that the test modules under /tests have access to the project root
sys.path.insert(0, os.path.dirname(__file__))

def run(verbosity):
    if verbosity == "0":
            sys.stdout = open(os.devnull, 'w')

    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(testvalidator.TestValidator))
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(testmodifier.TestModifier))
    test_suite.addTest(unittest.TestLoader().loadTestsFromTestCase(testimporter.TestDataImporter))

    unittest.TextTestRunner(verbosity=int(verbosity)).run(test_suite)

if __name__ == "__main__":

    #a simple way to control output verbosity
    parser = optparse.OptionParser()
    parser.add_option("--verbosity", "--verbosity", dest="verbosity", default="0")
    (options, args) = parser.parse_args()

    run(options.verbosity)
</code></pre>
<p>My issue is that, within these test modules, I have certain tests I'd like to skip based on different parameters passed to the driver. I'm aware that unittest provides a family of decorators meant to do this, but I don't know the best way to pass this information on to the individual modules.  If I had a <code>--skip-slow</code> argument, for example, how could I then annotate tests as slow, and have them skipped?</p>
<p>Thank you for your time.</p>
</div>
<div class="post-text" itemprop="text">
<p>I had in fact been wondering this myself, and finally found the solution.</p>
<p>main file...</p>
<pre><code>...
if __name__ == '__main__':
    args = argparser()

    from tests import *

    ...
</code></pre>
<p>And in your test modules, just do:</p>
<pre><code>from __main__ import args

print args
</code></pre>
<p>I tested this out, and it worked rather nicely. Nice thing is how simple it is, and it's not too much of a hack at all.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="http://readthedocs.org/docs/nose/en/latest/" rel="nofollow">nose</a> test runner with the <a href="http://readthedocs.org/docs/nose/en/latest/plugins/attrib.html" rel="nofollow">attrib</a> plugin that lets you select test cases based on attributes. In particular, the example in the plugin documentation uses <code>@attr(slow)</code> to mark slow test cases.</p>
<p>After that, from the command line:</p>
<ul>
<li><p>To select all the test cases marked as <code>slow</code>:</p>
<p><code>$ nosetests -a slow</code></p></li>
<li><p>To select all the test cases not marked as <code>slow</code>:</p>
<p><code>$ nosetests -a '!slow'</code></p></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>Here's how I solved this problem. At the bottom of my module, I put this code to set a global variable based on the presence of a <code>--slow</code> argument in <code>argv</code>:</p>
<pre><code>if __name__ == "__main__":
    try:
        i = sys.argv.index("--slow")
        run_slow_tests=True
        del sys.argv[i]
    except ValueError:
        pass

    unittest.main()
</code></pre>
<p>Then at the beginning of test functions which would be slow to run, I put this statement. It raises the <a href="https://docs.python.org/3/library/unittest.html#skipping-tests-and-expected-failures" rel="nofollow noreferrer"><strong>unittest.SkipTest()</strong> exception</a> if the flag isn't set to include slow tests.</p>
<pre><code>if not run_slow_tests:
    raise unittest.SkipTest('Slow test skipped, unless --slow given in sys.argv.')
</code></pre>
<p>Then when I invoke the module normally, the slow tests are skipped. </p>
<pre><code>% python src/my_test.py -v       
test_slow (__main__.Tests) ... skipped 'Slow test skipped, unless --slow given in sys.argv.'

----------------------------------------------------------------------
Ran 1 test in 0.000s

OK (skipped=1)
</code></pre>
<p>And when I add the <code>--slow</code>, the slow tests in that module run:</p>
<pre><code>% python src/my_test.py -v --slow
test_slow (__main__.Tests) ... ok

----------------------------------------------------------------------
Ran 1 test in 10.110s

OK
</code></pre>
<p>Unfortunately, this doesn't work with <a href="https://docs.python.org/3/library/unittest.html#test-discovery" rel="nofollow noreferrer">Unittest's test discovery</a>. </p>
<pre><code>% python -m unittest discover src "*_test.py" --slow
usage: python -m unittest discover [-h] [-v] [-q] [--locals] [-f] [-c] [-b]
                                   [-k TESTNAMEPATTERNS] [-s START]
                                   [-p PATTERN] [-t TOP]
python -m unittest discover: error: unrecognized arguments: --slow
</code></pre>
<p>It also didn't work to use the <strong>@unittest.SkipUnless()</strong> decorator. I suspect this is because the decorator evaluates its arguments at module definition time, but the argument isn't set to the correct value until module run time, which is later.</p>
<p>It isn't perfect, but it lets me work within the Python standard library. A requirement like this is a good reason to adopt a better framework, such as <a href="http://readthedocs.org/docs/nose/en/latest/" rel="nofollow noreferrer"><strong>nose tests</strong></a>. For my current project, I prefer to avoid installing any outside modules. </p>
</div>
<span class="comment-copy">I may have found a solution you can use. Check my answer.</span>
<span class="comment-copy">I probably need to acquaint myself with nose, as it seems unittest may not be up to this.  I was holding out hope I wouldn't have to add a dependency.</span>
<span class="comment-copy">You can create you own <code>attr</code> decorator based on <code>unittest.skipIf</code>/<code>unittest.skipUnless</code> and some environment variable that is used in the condition that the skip decorators check, but I wouldn't say it's worth the effort when you have something that already works out of the box.</span>
