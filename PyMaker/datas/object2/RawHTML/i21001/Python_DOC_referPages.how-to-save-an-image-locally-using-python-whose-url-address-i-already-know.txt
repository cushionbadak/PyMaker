<div class="post-text" itemprop="text">
<p>I know the URL of an image on Internet.</p>
<p>e.g. <a href="http://www.digimouth.com/news/media/2011/09/google-logo.jpg" rel="noreferrer">http://www.digimouth.com/news/media/2011/09/google-logo.jpg</a>, which contains the logo of Google.</p>
<p>Now, how can I download this image using Python without actually opening the URL in a browser and saving the file manually.</p>
</div>
<div class="post-text" itemprop="text">
<h1>Python 2</h1>
<p>Here is a more straightforward way if all you want to do is save it as a file:</p>
<pre><code>import urllib

urllib.urlretrieve("http://www.digimouth.com/news/media/2011/09/google-logo.jpg", "local-filename.jpg")
</code></pre>
<p>The second argument is the local path where the file should be saved.</p>
<h1>Python 3</h1>
<p>As SergO suggested the  code below should work with Python 3.</p>
<pre><code>import urllib.request

urllib.request.urlretrieve("http://www.digimouth.com/news/media/2011/09/google-logo.jpg", "local-filename.jpg")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import urllib
resource = urllib.urlopen("http://www.digimouth.com/news/media/2011/09/google-logo.jpg")
output = open("file01.jpg","wb")
output.write(resource.read())
output.close()
</code></pre>
<p><code>file01.jpg</code> will contain your image. </p>
</div>
<div class="post-text" itemprop="text">
<p>I wrote <a href="https://github.com/nateberman/Python-WebImageScraper">a script that does just this</a>, and it is available on my github for your use. </p>
<p>I utilized BeautifulSoup to allow me to parse any website for images. If you will be doing much web scraping (or intend to use my tool) I suggest you <code>sudo pip install BeautifulSoup</code>. Information on BeautifulSoup is available <a href="http://www.crummy.com/software/BeautifulSoup/">here</a>.</p>
<p>For convenience here is my code:</p>
<pre><code>from bs4 import BeautifulSoup
from urllib2 import urlopen
import urllib

# use this image scraper from the location that 
#you want to save scraped images to

def make_soup(url):
    html = urlopen(url).read()
    return BeautifulSoup(html)

def get_images(url):
    soup = make_soup(url)
    #this makes a list of bs4 element tags
    images = [img for img in soup.findAll('img')]
    print (str(len(images)) + "images found.")
    print 'Downloading images to current working directory.'
    #compile our unicode list of image links
    image_links = [each.get('src') for each in images]
    for each in image_links:
        filename=each.split('/')[-1]
        urllib.urlretrieve(each, filename)
    return image_links

#a standard call looks like this
#get_images('http://www.wookmark.com')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A solution which works with Python 2 and Python 3:</p>
<pre><code>try:
    from urllib.request import urlretrieve  # Python 3
except ImportError:
    from urllib import urlretrieve  # Python 2

url = "http://www.digimouth.com/news/media/2011/09/google-logo.jpg"
urlretrieve(url, "local-filename.jpg")
</code></pre>
<p>or, if the additional requirement of <a href="http://docs.python-requests.org/en/master/" rel="nofollow noreferrer"><code>requests</code></a> is acceptable and if it is a http(s) URL:</p>
<pre><code>def load_requests(source_url, sink_path):
    """
    Load a file from an URL (e.g. http).

    Parameters
    ----------
    source_url : str
        Where to load the file from.
    sink_path : str
        Where the loaded file is stored.
    """
    import requests
    r = requests.get(source_url, stream=True)
    if r.status_code == 200:
        with open(sink_path, 'wb') as f:
            for chunk in r:
                f.write(chunk)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I made a script expanding on Yup.'s script. I fixed some things. It will now bypass 403:Forbidden problems. It wont crash when an image fails to be retrieved. It tries to avoid corrupted previews. It gets the right absolute urls. It gives out more information. It can be run with an argument from the command line. </p>
<pre><code># getem.py
# python2 script to download all images in a given url
# use: python getem.py http://url.where.images.are

from bs4 import BeautifulSoup
import urllib2
import shutil
import requests
from urlparse import urljoin
import sys
import time

def make_soup(url):
    req = urllib2.Request(url, headers={'User-Agent' : "Magic Browser"}) 
    html = urllib2.urlopen(req)
    return BeautifulSoup(html, 'html.parser')

def get_images(url):
    soup = make_soup(url)
    images = [img for img in soup.findAll('img')]
    print (str(len(images)) + " images found.")
    print 'Downloading images to current working directory.'
    image_links = [each.get('src') for each in images]
    for each in image_links:
        try:
            filename = each.strip().split('/')[-1].strip()
            src = urljoin(url, each)
            print 'Getting: ' + filename
            response = requests.get(src, stream=True)
            # delay to avoid corrupted previews
            time.sleep(1)
            with open(filename, 'wb') as out_file:
                shutil.copyfileobj(response.raw, out_file)
        except:
            print '  An error occured. Continuing.'
    print 'Done.'

if __name__ == '__main__':
    url = sys.argv[1]
    get_images(url)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><strong>Python 3</strong></p>
<p><a href="https://docs.python.org/3/library/urllib.request.html?highlight=urlretrieve#urllib.request.urlretrieve" rel="noreferrer">urllib.request â€” Extensible library for opening URLs</a></p>
<pre><code>from urllib.error import HTTPError
from urllib.request import urlretrieve

try:
    urlretrieve(image_url, image_local_path)
except FileNotFoundError as err:
    print(err)   # something wrong with local path
except HTTPError as err:
    print(err)  # something wrong with url
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This can be done with requests. Load the page and dump the binary content to a file.</p>
<pre><code>import os
import requests

url = 'https://apod.nasa.gov/apod/image/1701/potw1636aN159_HST_2048.jpg'
page = requests.get(url)

f_ext = os.path.splitext(url)[-1]
f_name = 'img{}'.format(f_ext)
with open(f_name, 'wb') as f:
    f.write(page.content)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is very short answer.</p>
<pre><code>import urllib
urllib.urlretrieve("http://photogallery.sandesh.com/Picture.aspx?AlubumId=422040", "Abc.jpg")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h2>Version for Python 3</h2>
<p>I adjusted the code of @madprops for Python 3</p>
<pre><code># getem.py
# python2 script to download all images in a given url
# use: python getem.py http://url.where.images.are

from bs4 import BeautifulSoup
import urllib.request
import shutil
import requests
from urllib.parse import urljoin
import sys
import time

def make_soup(url):
    req = urllib.request.Request(url, headers={'User-Agent' : "Magic Browser"}) 
    html = urllib.request.urlopen(req)
    return BeautifulSoup(html, 'html.parser')

def get_images(url):
    soup = make_soup(url)
    images = [img for img in soup.findAll('img')]
    print (str(len(images)) + " images found.")
    print('Downloading images to current working directory.')
    image_links = [each.get('src') for each in images]
    for each in image_links:
        try:
            filename = each.strip().split('/')[-1].strip()
            src = urljoin(url, each)
            print('Getting: ' + filename)
            response = requests.get(src, stream=True)
            # delay to avoid corrupted previews
            time.sleep(1)
            with open(filename, 'wb') as out_file:
                shutil.copyfileobj(response.raw, out_file)
        except:
            print('  An error occured. Continuing.')
    print('Done.')

if __name__ == '__main__':
    get_images('http://www.wookmark.com')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>img_data=requests.get('https://apod.nasa.gov/apod/image/1701/potw1636aN159_HST_2048.jpg')

with open(str('file_name.jpg', 'wb') as handler:
    handler.write(img_data)
</code></pre>
</div>
<span class="comment-copy">Possible duplicate of <a href="http://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python">How do I download a file over HTTP using Python?</a></span>
<span class="comment-copy">A good way to get filename from link is <code>filename = link.split('/')[-1]</code></span>
<span class="comment-copy">with urlretrieve I just get a 1KB file with a dict and 404 error text inside.Why? If I enter url into my browser I can get the picture</span>
<span class="comment-copy">@Yebach: The site you are downloading from may be using cookies, the User-Agent or other headers to determine what content to serve you. These will be different between your browser and Python.</span>
<span class="comment-copy"><b><a href="https://docs.python.org/3/library/urllib.request.html?highlight=urlretrieve#urllib.request.urlretrieve" rel="nofollow noreferrer">Python 3</a>:</b> <code>import urllib.request</code> and <code>urllib.request.urlretrieve()</code>, accordingly.</span>
<span class="comment-copy">@SergO - can you add the Python 3 part to the original answer?</span>
<span class="comment-copy">You should open the file in binary mode: <code>open("file01.jpg", "wb")</code> Otherwise you may corrupt the image.</span>
<span class="comment-copy"><code>urllib.urlretrieve</code> can save the image directly.</span>
<span class="comment-copy">Welcome to Stack Overflow!  While you may have solved this user's problem, code-only answers are not very helpful to users who come to this question in the future.  Please edit your answer to explain why your code solves the original problem.</span>
<span class="comment-copy"><code>TypeError: a bytes-like object is required, not 'Response'</code>. It must be <code>handler.write(img_data.content)</code></span>
