<div class="post-text" itemprop="text">
<p>I'm new to multiprocessing in Python. I have a simple program like:</p>
<pre><code>class test:
    ...
    def func():
        return something

inst1 = test(init1, ...)
inst2 = test(init2, ...)
inst3 = test(init3, ...)

x = []
while(some_condition):
    a = inst1.func()
    b = inst2.func()
    c = inst3.func()
    x.append(do_something(a, b, c))
</code></pre>
<p>With func being CPU-intensive and returning a different value each time they are called.</p>
<p>I have a machine with 2 8-core CPUs with Ubuntu and Python 2.6.5 installed (can't update, unfortunately), and another machine with a single i7 processor and Python 2.7.5 (also, can't update). I also am unable to install new packages.</p>
<p>I believe I could gain some performance if all 3 methods were to be ran at the same time (the OS in theory should allocate them to different cores), but I'm not sure how to proceed. The documentation is cryptic at best for multiprocessing.</p>
<p>Could you please point me to some examples or give me some advice on how to accomplish that? Thanks</p>
</div>
<div class="post-text" itemprop="text">
<p>Doug Hellmans "Module of the Week" often have good examples:</p>
<p><a href="http://pymotw.com/2/multiprocessing/basics.html" rel="nofollow">http://pymotw.com/2/multiprocessing/basics.html</a></p>
<p>His book on the Standard library is worth the money as well.</p>
</div>
<div class="post-text" itemprop="text">
<p>Well, this is very close to one of the examples in the docs… But I think this would be easier with a <code>Pool</code> than with explicit processes, and even easier with <code>Futures</code> than with a simple pool. Plus, the <a href="http://docs.python.org/3/library/concurrent.futures.html" rel="nofollow"><code>futures</code></a> module's docs are a whole simpler than the <code>multiprocessing</code> docs. So, let's do it that way:</p>
<pre><code>x = []
with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:
    while some_condition:
        a = executor.submit(func1)
        b = executor.submit(func2)
        c = executor.submit(func3)
        concurrent.futures.wait((a, b, c))
        x.append(do_something(a.result(), b.result(), c.result()))
</code></pre>
<p>If you're using Python 2.5-3.1, you won't have this module in the stdlib, so you'll need to install <a href="https://pypi.python.org/pypi/futures" rel="nofollow">the backport</a>.</p>
<hr/>
<p>For comparison, here's what it would look like using an explicit <code>multiprocessing.Process</code> for each function:</p>
<pre><code>def background(f):
    q = multiprocessing.Queue()
    def wrapped(q):
        q.put(f())
    p = multiprocess.Process(target=wrapped, args=q)
    p.start()
    return p, q

x = []
while some_condition:
    pa, qa = background(func1)
    pb, qb = background(func2)
    pc, qc = background(func3)
    pa.join()
    pb.join()
    pc.join()
    x.append(do_something(qa.get(), qb.get(), qc.get())
</code></pre>
</div>
<span class="comment-copy">Your solution works ok for functions, but I meant methods, I'm sorry.</span>
<span class="comment-copy">@user2329994: The same basic thing works for methods. A bound method like <code>inst.func</code> is a value that can be passed around, and called, just like a function can. You may run into issues with pickling, but those are usually very simple to work around—and anyway, you can cross that bridge when you come to it.</span>
