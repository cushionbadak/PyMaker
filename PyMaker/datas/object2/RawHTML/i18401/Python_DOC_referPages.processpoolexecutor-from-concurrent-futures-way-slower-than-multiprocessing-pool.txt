<div class="post-text" itemprop="text">
<p>I was experimenting with the new shiny <a href="http://docs.python.org/3.3/library/concurrent.futures.html">concurrent.futures</a> module introduced in Python 3.2, and I've noticed that, almost with identical code, using the Pool from concurrent.futures is <em>way</em> slower than using <a href="http://docs.python.org/3.3/library/multiprocessing.html#multiprocessing.pool.Pool">multiprocessing.Pool</a>.</p>
<p>This is the version using multiprocessing:</p>
<pre><code>def hard_work(n):
    # Real hard work here
    pass

if __name__ == '__main__':
    from multiprocessing import Pool, cpu_count

    try:
        workers = cpu_count()
    except NotImplementedError:
        workers = 1
    pool = Pool(processes=workers)
    result = pool.map(hard_work, range(100, 1000000))
</code></pre>
<p>And this is using concurrent.futures:</p>
<pre><code>def hard_work(n):
    # Real hard work here
    pass

if __name__ == '__main__':
    from concurrent.futures import ProcessPoolExecutor, wait
    from multiprocessing import cpu_count
    try:
        workers = cpu_count()
    except NotImplementedError:
        workers = 1
    pool = ProcessPoolExecutor(max_workers=workers)
    result = pool.map(hard_work, range(100, 1000000))
</code></pre>
<p>Using a naïve factorization function taken from this <a href="http://eli.thegreenplace.net/2013/01/16/python-paralellizing-cpu-bound-tasks-with-concurrent-futures/">Eli Bendersky article</a>, these are the results on my computer (i7, 64-bit, Arch Linux):</p>
<pre><code>[juanlu@nebulae]─[~/Development/Python/test]
└[10:31:10] $ time python pool_multiprocessing.py 

real    0m10.330s
user    1m13.430s
sys 0m0.260s
[juanlu@nebulae]─[~/Development/Python/test]
└[10:31:29] $ time python pool_futures.py 

real    4m3.939s
user    6m33.297s
sys 0m54.853s
</code></pre>
<p>I cannot profile these with the Python profiler because I get pickle errors. Any ideas?</p>
</div>
<div class="post-text" itemprop="text">
<p>When using <code>map</code> from <code>concurrent.futures</code>, each element from the iterable <a href="http://hg.python.org/cpython/file/3.3/Lib/concurrent/futures/_base.py#l538">is submitted</a> separately to the executor, which creates a <code>Future</code> object for each call. It then returns an iterator which yields the results returned by the futures.<br/>
<a href="http://hg.python.org/cpython/file/3.3/Lib/concurrent/futures/_base.py#l279"><code>Future</code></a> objects are rather heavyweight, they do a lot of work to allow all the features they provide (like callbacks, ability to cancel, check status, ...).</p>
<p>Compared to that, <code>multiprocessing.Pool</code> has much less overhead. It submits jobs in batches (reducing IPC overhead), and directly uses the result returned by the function. For big batches of jobs, multiprocessing is definitely the better options.</p>
<p>Futures are great if you want to sumbit long running jobs where the overhead isn't that important, where you want to be notified by callback or check from time to time to see if they're done or be able to cancel the execution individually.</p>
<p><em>Personal note</em>:</p>
<p>I can't really think of much reasons to use <code>Executor.map</code> - it doesn't give you any of the features of futures - except for the ability to specify a timeout. If you're just interested in the results, you're better off using one of <code>multiprocessing.Pool</code>'s map functions.</p>
</div>
<span class="comment-copy">I love your naming convention, especially <code>workers</code> and <code>hard_work</code> :P</span>
<span class="comment-copy">Cool, innit? :P</span>
<span class="comment-copy">Thank you very much for your answer! Probably the submitting in batches is the key thing here.</span>
<span class="comment-copy">For what it's worth, in Python 3.5, <code>ProcessPoolExecutor.map</code> will accept a <code>chunksize</code> keyword argument, which will alleviate the IPC overhead issue somewhat.  See this <a href="http://bugs.python.org/issue11271" rel="nofollow noreferrer">bug</a> for more info.</span>
<span class="comment-copy">Also, In Python 3.2 you can set <i>maxtasksperchild</i> for a multiprocess Pool which, in my case, helped to clean up resources after each worker finished its workload. <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow noreferrer">link</a></span>
<span class="comment-copy">I prefer the <code>ProcessPoolExecutor.map()</code> because of <a href="https://stackoverflow.com/a/24894997/786559">this bug</a> in <code>mp.Pool.map()</code></span>
