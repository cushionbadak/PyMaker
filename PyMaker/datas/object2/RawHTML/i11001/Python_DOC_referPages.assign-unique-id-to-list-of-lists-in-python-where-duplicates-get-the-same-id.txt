<div class="post-text" itemprop="text">
<p>I have a list of lists (which can contain up to 90k elements)</p>
<pre><code>[[1,2,3], [1,2,4], [1,2,3], [1,2,4], [1,2,5]]
</code></pre>
<p>I would like to assign an id to each elements, where the id is unique, except when the item is duplicated. So for the list above, I'd need this back:</p>
<pre><code>[0,1,0,1,2]
</code></pre>
<p>What is the most effective way to do this?</p>
</div>
<div class="post-text" itemprop="text">
<p>Keep a map of already seen elements with the associated id.</p>
<pre><code>from itertools import count
from collections import defaultdict


mapping = defaultdict(count().__next__)
result = []
for element in my_list:
    result.append(mapping[tuple(element)])
</code></pre>
<p>you could also use a list-comprehension:</p>
<pre><code>result = [mapping[tuple(element)] for element in my_list]
</code></pre>
<p>Unfortunately <code>list</code>s aren't hashable so you have to convert them to a <code>tuple</code> when storing them as keys of the mapping.</p>
<hr/>
<p>Note the trick of using <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="noreferrer"><code>defaultdict</code></a>, and <a href="https://docs.python.org/3.5/library/itertools.html#itertools.count" rel="noreferrer"><code>count().__next__</code></a> to provide unique increasing ids. On python2 you have to replace <code>.__next__</code> with <code>.next</code>.</p>
<p>The <code>defaultdict</code> will assign a default value when it cannot find a key. The default value is obtained by calling the function provided in the constructor.
In this case the <code>__next__</code> method of the <code>count()</code> generator yields increasing numbers.</p>
<p>As a more portable alternative you could do:</p>
<pre><code>from functools import partial

mapping = defaultdict(partial(next, count()))
</code></pre>
<hr/>
<p>An alternative solution, as proposed in the comments, is to just use the index as unique id:</p>
<pre><code>result = [my_list.index(el) for el in my_list]
</code></pre>
<p>This is imple however:</p>
<ul>
<li>It takes O(N^2) time instead of O(N)</li>
<li>The ids are unique, increasing but not consecutive (which may or may not be a problem)</li>
</ul>
<p>For comparison of the two solutions see:</p>
<pre><code>In [1]: from itertools import count
   ...: from collections import defaultdict

In [2]: def hashing(seq):
   ...:         mapping = defaultdict(count().__next__)
   ...:         return [mapping[tuple(el)] for el in seq]
   ...: 

In [3]: def indexing(seq):
   ...:    return [seq.index(i) for i in seq]
   ...: 

In [4]: from random import randint

In [5]: seq = [[randint(1, 20), randint(1, 20), randint(1, 20)] for _ in range(90000)]

In [6]: %timeit hashing(seq)
10 loops, best of 3: 37.7 ms per loop

In [7]: %timeit indexing(seq)
1 loop, best of 3: 26 s per loop
</code></pre>
<p>Note how for a 90k element list the mapping solution takes less 40 <em>milliseconds</em> while the indexing solution takes 26 <strong>seconds</strong>. </p>
</div>
<div class="post-text" itemprop="text">
<p>This is how I approached it:</p>
<pre><code>from itertools import product
from random import randint
import time

t0 = time.time()
def id_list(lst):
    unique_set = set(tuple(x) for x in lst)
    unique = [list(x) for x in unique_set]
    unique.sort(key = lambda x: lst.index(x))

    result = [unique.index(i[1]) for i in product(lst, unique) if i[0] == i[1]]

    return result

seq = [[randint(1, 5), randint(1, 5), randint(1, 5)] for i in range(90000)]

print(id_list(seq))

t1 = time.time()

print("Time: %.4f seconds" % (t1-t0))
</code></pre>
<p>Which prints out the sequence of ids, along with an approximate time it took to compute a sequence of random integers in a list between <strong>1</strong> and <strong>4</strong>, <strong>90000</strong> times. </p>
<pre><code>Time: 2.3397 seconds  # Will slightly differ from computation to computation
</code></pre>
<p>The actual time will always be a bit higher, since it needs to be accounted for in the print statement at the end, but it should not be too much of a difference. </p>
<p>I also used the <a href="https://docs.python.org/2/library/time.html" rel="nofollow"><code>time</code></a> library to label the time intervals between the start and the end of the code block.</p>
<pre><code>import time

t0 = time.time()

# code block here

t1 = time.time()

# Difference in time: t1 - t0 
</code></pre>
<p>The <a href="https://docs.python.org/2.7/library/itertools.html" rel="nofollow"><code>itertools</code></a> library along with <a href="https://docs.python.org/2.7/library/itertools.html#itertools.product" rel="nofollow"><code>product</code></a> used in the code segment will speed up the computation too.</p>
</div>
<div class="post-text" itemprop="text">
<p>I slight modification of Bakuriu's solution that works only with numpy arrays, it works better in terms of memory footprint and computation (as it does need to cast arrays to tuples):</p>
<pre><code>from itertools import count
from collections import defaultdict
from functools import partial

def hashing_v1(seq):
    mapping = defaultdict(partial(next, count()))
    return [mapping[tuple(el)] for el in seq]

def hashing_v2(seq):
    mapping = defaultdict(partial(next, count()))
    result = []
    for le in seq:
        le.flags.writeable = False
        result.append(mapping[le.data])
    return result

In [4]: seq = np.random.rand(50000, 2000)

In [5]: %timeit hashing_v1(seq)
1 loop, best of 3: 14.1 s per loop

In [6]: %timeit hashing_v2(seq)
1 loop, best of 3: 1.2 s per loop
</code></pre>
</div>
<span class="comment-copy">Do the ids have to be sequential? you could easily abuse the <code>index</code> method of lists if not: <code>def get_ids(li):  return [li.index(i) for i in li];</code> which returns <code>[0, 1, 0, 1, 4]</code> for <code>[[1,2,3], [1,2,4], [1,2,3], [1,2,4], [1,2,5]]</code></span>
<span class="comment-copy">@DeepSpace That takes O(N^2) time. It could be improved by computing a sorted copy of the list and use <code>bisect</code> to efficiently associate an index with it, making the time O(N log N) which is the lowerbound for solving this problem using comparisons.</span>
<span class="comment-copy">As an alternative functional based approach for first solution <code>operator.itemgetter(*map(tuple, my_list))(mapping)</code></span>
<span class="comment-copy">To make <code>defaultdict</code> 2.6+ compatible, you can use <code>defaultdict(lambda c=count(): next(c))</code> instead of having to rely on the actual method name or using <code>functools.partial</code>...</span>
<span class="comment-copy">@JonClements Do you mean compatible with python 2.5? Because both <code>partial</code> and the <code>next</code> built-in functions are available in python2.6 so that's already python2.6 compatible.</span>
<span class="comment-copy">@Kasramvd Interestingly your functional approach has a much smaller memory print, still the same performance.</span>
<span class="comment-copy">@jamborta I thinks you've tested it in pyhton 3.X and if it's so, it's because that <code>map()</code> returns an iterator and consumes much less memory than a list. And the unpacking just pass the items to <code>itemgetter()</code>.</span>
