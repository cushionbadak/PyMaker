<div class="post-text" itemprop="text">
<p>I tried every <code>'User-Agent'</code> in <a href="http://wolfprojects.altervista.org/articles/change-urllib-user-agent/" rel="nofollow noreferrer">here</a>, still I get <code>urllib.error.HTTPError: HTTP Error 400: Bad Request</code>. I also tried <a href="https://stackoverflow.com/questions/26894320/again-urllib-error-httperror-http-error-400-bad-request">this</a>, but I get <code>urllib.error.URLError: File Not Found</code>. I have no idea what to do, my current codes are;</p>
<pre><code>from bs4 import BeautifulSoup
import urllib.request,json,ast

with open ("urller.json") as f:
    cc = json.load(f) #the file I get links, you can try this link instead of this
    #cc = ../games/index.php?g_id=23521&amp;game=0RBITALIS 

for x in ast.literal_eval(cc): #cc is a str(list) so I have to convert
    if x.startswith("../"):

        r = urllib.request.Request("http://www.game-debate.com{}".format(x[2::]),headers={'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'})
        #x[2::] because I removed '../' parts from urlls

        rr = urllib.request.urlopen(r).read()
        soup = BeautifulSoup(rr)

        for y in soup.find_all("ul",attrs={'class':['devDefSysReqList']}):
            print (y.text)
</code></pre>
<p><strong>Edit</strong>: If you try only 1 link probably it won't show any error, since I get the error every time at 6th link.</p>
</div>
<div class="post-text" itemprop="text">
<p>A quick fix is to replace the space with <code>+</code>:</p>
<pre><code>url = "http://www.game-debate.com"
r = urllib.request.Request(url + x[2:] ,headers={'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'})
</code></pre>
<p>A better option may be to let urllib <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.quote" rel="nofollow">quote</a> the params:</p>
<pre><code>from bs4 import BeautifulSoup
import urllib.request,json,ast
from urllib.parse import quote, urljoin

with open ("urller.json") as f:
    cc = json.load(f) #the file I get links, you can try this link instead of this
    url = "http://www.game-debate.com"


    for x in ast.literal_eval(cc):  # cc is a str(list) so I have to convert
        if x.startswith("../"):
            r = urllib.request.Request(urljoin(url, quote(x.lstrip("."))), headers={
                'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; it; rv:1.8.1.11) Gecko/20071127 Firefox/2.0.0.11'})

            rr = urllib.request.urlopen(r).read()
            soup = BeautifulSoup(rr)
            print(rr.decode("utf-8"))

            for y in soup.find_all("ul", attrs={'class':['devDefSysReqList']}):
                print (y.text)
</code></pre>
<p>Spaces in a url are not valid and need to be percent encoded as <code>%20</code> or replaced with <code>+</code>.</p>
</div>
<span class="comment-copy">Do you <i>have</i> to use <code>urllib</code>? I just tried <code>requests.get("http://www.game-debate.com/games/index.php?g_id=23521&amp;game=0RBITALIS")</code> and it works perfectly. <code>requests</code> is far superior in virtually every respect.</span>
<span class="comment-copy">@AkshatMahajan but I edited the question, if you try only 1 link probably it will be ok since I get that bad request error every time at 6th link from json file</span>
<span class="comment-copy">Have you tried printing each URL before making the request?  Perhaps the URL is malformed in some obvious way.</span>
<span class="comment-copy">@JohnGordon the link that I get the error is <code>../games/index.php?g_id=23255&amp;game=12 Labours of Hercules II: The Cretan Bull</code></span>
<span class="comment-copy">Those embedded spaces may be causing the issue.  I don't believe literal spaces are allowed in a URL.</span>
