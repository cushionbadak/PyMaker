<div class="post-text" itemprop="text">
<p>I have a program with an object of the form</p>
<pre><code>class MyObj(object):
    def __init__(self, a, b):
        self.__a = a
        self.__b = b
        self.cache = very_expensive_computation(a, b)
</code></pre>
<p>where <code>a,b</code> are immutable and the space of possible parameters <code>a,b</code> is very small. These objects are created and go out of scope constantly during the execution of the program, so unsurprisingly a lot of time is spent recomputing <code>self.cache</code> for the same values <code>a,b</code>. Since the <code>very_expensive_computation</code> is very expensive, it seems it would be better to just avoid garbage collecting these items and have the constructor return references to the already existing objects if possible, kinda like string interning.</p>
<p>The obvious way to do this to me seems to be to add a dictionary to the class and override <code>__new__</code> and <code>__init__</code> so that they check the dictionary and return already existing instances if possible, but at the same time this feels kinda unsatisfactory since it would have to be done to each class separately and since detecting whether you are an actual new object in <code>__init__</code> would probably be pretty hacky.</p>
<p>Any other suggestions?</p>
</div>
<div class="post-text" itemprop="text">
<p>I'd memoize the <code>very_expensive_computation</code> storing the results in an LRU cache to guarantee an upper bound on the amount of memory used:</p>
<pre><code>_very_expensive_computation_cache = RecentlyUsedContainer(100)

def cached_very_expensive_computation(a, b):
   if (a, b) not in _very_expensive_computation_cache:
      _very_expensive_computation_cache[(a, b)] = very_expensive_computation(a, b)
  return _very_expensive_computation_cache[(a, b)]
</code></pre>
<p>Where the <code>RecentlyUsedContainer</code> could be this one: <a href="https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/collections_.py#L12" rel="nofollow">https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/collections_.py#L12</a></p>
<p>You could also simplify the code with a decorator:</p>
<pre><code>from unstdlib.standard.functools_ import memoized

@memoized(cache=RecentlyUsedContainer(100))
def cached_very_expensive_comptuation(a, b):
    return very_expensive_computation(a, b)
</code></pre>
<p>See: <a href="https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/functools_.py#L59" rel="nofollow">https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/functools_.py#L59</a></p>
<p>I prefer to keep the memoized versions of functions separate from the "real" versions so callers can explicitly see that they could be getting a cached result, and it can make testing easier. This is largely personal preference, though.</p>
<p><strong>Edit</strong>: as pointed out in the comments, Python 3 ships with <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow"><code>functools.lru_cache</code></a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can also accomplish this with class and instance variables:</p>
<pre><code>class BaseMyObj(object):
    result_store = {}

class MyObj(BaseMyObj):
    def __init__(self, a, b):
        self.__a = a
        self.__b = b
        try:
            self.cache = BaseMyObj.result_store[(a,b)]
        except KeyError:
            self.cache = very_expensive_computation(a, b)
            BaseMyObj.result_store[(a,b)] = self.cache

def very_expensive_computation(a, b):
    print('did calc')
    return a+b

item = MyObj(2, 9)
&gt;did calc

item2 = MyObj(2, 9)

item3 = MyObj(1, 4)
&gt;did calc
</code></pre>
</div>
<span class="comment-copy">I would consider just caching <code>very_expensive_computation</code>, or adding a class method that can return saved instances instead of having <code>MyObj()</code> return old instances. Making <code>MyObj()</code> return saved instances can get messy.</span>
<span class="comment-copy">Considering that the question is tagged Python 3, if you want an LRU cache, you could just use <code>functools.lru_cache</code> from the standard library.</span>
<span class="comment-copy">The actual program does a fair bit of validation in <code>__init__</code>, so I was worried that merely memoizing <code>very_expensive_computation</code> would not suffice, but after trying it I got about a 12x speedup, which is more than enough.</span>
<span class="comment-copy">What's the point of <code>BaseMyObj</code> here? Why not just store the cache on <code>MyObj</code> or at module level?</span>
<span class="comment-copy">In case <code>very_expensive_function</code> isn't limited to this one type of instance.  In his sample code he called <code>very_expensive_function</code>, not <code>self.very_expensive_function</code>, so I wasn't sure.  Now it can be inherited by whatever needs it.</span>
<span class="comment-copy">Why would you use <i>inheritance</i> for that?</span>
