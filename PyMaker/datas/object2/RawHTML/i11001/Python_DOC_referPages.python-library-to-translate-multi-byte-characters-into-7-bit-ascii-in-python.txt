<div class="post-text" itemprop="text">
<p>Is there a python library that provides translation of multi-byte non-ASCII characters into some reasonable form of 7-bit displayable ASCII.  This is intended to avoid hard-coding the <code>charmap</code> as given in the <a href="https://stackoverflow.com/a/38178064/257924">answer</a> to <a href="https://stackoverflow.com/questions/38176258/translating-multi-byte-characters-into-7-bit-ascii-in-python">Translating multi-byte characters into 7-bit ASCII in Python</a></p>
<p>EDIT: I am currently using Python 2.7.11 or greater and not yet Python 3 but answers giving Python 3 solutions will be considered and found helpful.</p>
<p>The reason is this: As I do the translation manually, I will miss some:</p>
<p>My script is:</p>
<pre><code>#!/bin/bash
# -*- mode: python; -*-

import os
import re
import requests

url = "https://system76.com/laptops/kudu"

#
# Load the text from request as a true unicode string:
#
r = requests.get(url)
r.encoding = "UTF-8"
data = r.text  # ok, data is a true unicode string

# translate offending characters in unicode:

charmap = {
    0x2014: u'-',   # em dash
    0x201D: u'"',   # comma quotation mark, double
    # etc.
}
data = data.translate(charmap)
tdata = data.encode('ascii')
</code></pre>
<p>The error I get is:</p>
<pre><code>./simple_wget
Traceback (most recent call last):
  File "./simple_wget.py", line 25, in &lt;module&gt;
    tdata = data.encode('ascii')
UnicodeEncodeError: 'ascii' codec can't encode character u'\u2013' in position 10166: ordinal not in range(128)
</code></pre>
<p>This will be a never-ending battle to update the <code>charmap</code> for newly discovered characters. Is there a python library that provides this charmap so I don't have to hardcode it in this manner?</p>
</div>
<div class="post-text" itemprop="text">
<p>You may consider the <a href="https://docs.python.org/2/library/unicodedata.html" rel="nofollow">unicodedata</a> python package. I think one of the methods you may find interesting is <code>normalize</code> (see also example of usage given by <a href="https://www.peterbe.com/plog/unicode-to-ascii" rel="nofollow">peterbe.come</a>):</p>
<pre><code>import unicodedata

foo = 'abcdéfg'
unicodedata.normalize(foo).encode('ascii','ignore')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><code>str.encode()</code> has an optional 'error' parameter that can replace un-encodable characters instead of throwing an error. Is that what you are looking for?</p>
<p><a href="https://docs.python.org/3/howto/unicode.html#converting-to-bytes" rel="nofollow">https://docs.python.org/3/howto/unicode.html#converting-to-bytes</a></p>
</div>
<div class="post-text" itemprop="text">
<p>(Note: This answer pertains to Python 2.7.11+.)</p>
<p>The answer at <a href="https://stackoverflow.com/a/1701378/257924">https://stackoverflow.com/a/1701378/257924</a> refers to the Unidecode package and is what I was looking for. In using that package, I also discovered the ultimate source of my confusion which is elaborated in-depth at <a href="https://pythonhosted.org/kitchen/unicode-frustrations.html#frustration-3-inconsistent-treatment-of-output" rel="nofollow noreferrer">https://pythonhosted.org/kitchen/unicode-frustrations.html#frustration-3-inconsistent-treatment-of-output</a> and specifically this section:</p>
<blockquote>
<h2>Frustration #3: Inconsistent treatment of output</h2>
<p>Alright, since the python community is moving to using unicode strings everywhere, we might as well convert everything to unicode strings and use that by default, right? Sounds good most of the time but
  there’s at least one huge caveat to be aware of. Anytime you output text to the terminal or to a file, the text has to be converted into a byte str. Python will try to implicitly convert from unicode to
  byte str... but it will throw an exception if the bytes are non-ASCII:</p>
</blockquote>
<p>The following is my demonstration script to use it. The characters listed in the <code>names</code> variable are the characters I do need to have translated into something readable, and not removed, for the types of web pages I am analyzing.</p>
<pre><code>#!/bin/bash
# -*- mode: python; coding: utf-8 -*-
# The above coding is needed to to avoid this error: SyntaxError: Non-ASCII character '\xe2' in file ./unicodedata_normalize_test.py on line 9, but no encoding declared; see http://python.org/dev/peps/pep-0263/ for details

import os
import re
import unicodedata
from unidecode import unidecode

names = [
    'HYPHEN-MINUS',
    'EM DASH',
    'EN DASH',
    'MINUS SIGN',
    'APOSTROPHE',
    'LEFT SINGLE QUOTATION MARK',
    'RIGHT SINGLE QUOTATION MARK',
    'LATIN SMALL LETTER A WITH ACUTE',
]

for name in names:
    character = unicodedata.lookup(name)
    unidecoded = unidecode(character)
    print
    print 'name      ',name
    print 'character ',character
    print 'unidecoded',unidecoded
</code></pre>
<p>Sample output of the above script is:</p>
<pre><code>censored@censored:~$ unidecode_test

name       HYPHEN-MINUS
character  -
unidecoded -

name       EM DASH
character  —
unidecoded --

name       EN DASH
character  –
unidecoded -

name       MINUS SIGN
character  −
unidecoded -

name       APOSTROPHE
character  '
unidecoded '

name       LEFT SINGLE QUOTATION MARK
character  ‘
unidecoded '

name       RIGHT SINGLE QUOTATION MARK
character  ’
unidecoded '

name       LATIN SMALL LETTER A WITH ACUTE
character  á
unidecoded a
</code></pre>
<p>The following more elaborate script loads several web pages with many unicode characters. See the comments in the script below:</p>
<pre><code>#!/bin/bash
# -*- mode: python; coding: utf-8 -*-

import os
import re
import subprocess
import requests
from unidecode import unidecode

urls = [
    'https://system76.com/laptops/kudu',
    'https://stackoverflow.com/a/38249916/257924',
    'https://www.peterbe.com/plog/unicode-to-ascii',
    'https://stackoverflow.com/questions/227459/ascii-value-of-a-character-in-python?rq=1#comment35813354_227472',
    # Uncomment out the following to show that this script works without throwing exceptions, but at the expense of a huge amount of diff output:
    ###'https://en.wikipedia.org/wiki/List_of_Unicode_characters',
]

# The following variable settings represent what just works without throwing exceptions.
# Setting re_encode to False and not_encode to True results in the write function throwing an exception of
#
#    Traceback (most recent call last):
#      File "./simple_wget.py", line 52, in &lt;module&gt;
#        file_fp.write(data[ext])
#    UnicodeEncodeError: 'ascii' codec can't encode character u'\xe9' in position 33511: ordinal not in range(128)
#
# This is the crux of my confusion and is explained by https://pythonhosted.org/kitchen/unicode-frustrations.html#frustration-3-inconsistent-treatment-of-output
# So this is why we set re_encode to True and not_encode to False below:
force_utf_8 = False
re_encode = True
not_encode = False
do_unidecode = True

for url in urls:
    #
    # Load the text from request as a true unicode string:
    #
    r = requests.get(url)
    print "\n\n\n"
    print "url:",url
    print "current encoding:",r.encoding

    data = {}

    if force_utf_8:
        # The next two lines do not work. They cause the write to fail:
        r.encoding = "UTF-8"
        data['old'] = r.text  # ok, data is a true unicode string

    if re_encode:
        data['old'] = r.text.encode(r.encoding)

    if not_encode:
        data['old'] = r.text

    if do_unidecode:
        # translate offending characters in unicode:
        data['new'] = unidecode(r.text)

    html_base = re.sub(r'[^a-zA-Z0-9_-]+', '__', url)
    diff_cmd = "diff "
    for ext in [ 'old', 'new' ]:
        if ext in data:
            print "ext:",ext
            html_file = "{}.{}.html".format(html_base, ext)
            with open(html_file, 'w') as file_fp:
                file_fp.write(data[ext])
                print "Wrote",html_file
            diff_cmd = diff_cmd + " " + html_file

    if 'old' in data and 'new' in data:
        print 'Executing:',diff_cmd
        subprocess.call(diff_cmd, shell=True)
</code></pre>
<p>The <a href="https://gist.github.com/bgoodr/1f085ef942fb71ba6af2cd7268f480f7" rel="nofollow noreferrer">gist showing the output</a> of the above script. This shows the execution of the Linux <code>diff</code> command on the "old" and "new" html files so as to see the translations. There is going to be mistranslation of languages like German etc., but that is fine for my purposes of getting some lossy translation of single and double quote types of characters and dash-like characters.</p>
</div>
<span class="comment-copy">In other words, you're looking for a library that will try to replace non-ASCII characters with acceptable ASCII equivalents?</span>
<span class="comment-copy">Are you perhaps trying to reinvent <a href="http://unicode.org/reports/tr15/" rel="nofollow noreferrer">normalization</a>?</span>
<span class="comment-copy">@LexScarisbrick No, the OP is asking for a lossy translation, which Unicode normalization is not (though e.g. stripping diacritics can be accomplished via NFD normalization followed by discarding any combining characters).</span>
<span class="comment-copy">@TannerSwett: yes</span>
<span class="comment-copy">@LexScarisbrick: Not sure as I'm trying to understand things, but probably no.</span>
<span class="comment-copy">The <code>normalize</code> function takes two arguments, but even if I supply the arguments, I cannot get it to work under my Python, either with the <code>foo = 'abcdéfg'</code> value or using the EM DASH character. See <a href="https://gist.githubusercontent.com/bgoodr/b701b1652555b5439ab7ffb6136c9db8/raw/44f61b3e96f7acfd05280eeec2ad79655e1cac19/unicodedata_normalize_attempt_1.txt" rel="nofollow noreferrer">my gist</a></span>
<span class="comment-copy">In the gist above, I had the syntax incorrect: the <code>form</code> argument is the first one. See my <a href="https://gist.github.com/bgoodr/7a3b187d144887ce6f82ecdd05b503bd" rel="nofollow noreferrer">corrected gist</a> that shows the output of the <code>unicodedata.normalize</code> method. But this is not what I want as it removes the character. What I need is a translation of EM DASH and EN DASH and any other "dash-like" code points into APOSTROPHE.  However, your answer was instrumental in allowing me to discover the solution I found, which I will post.</span>
<span class="comment-copy">Not specifically what I was looking for since I would like to translate some of the more obvious characters into 7-bit ASCII such as Unicodes <code>EM DASH</code> character "—", into the 7-bit ASCII dash character "-" (Unicode <code>HYPHEN-MINUS</code> character).  Yes, I know the characters are not grammaticalily the same. This is a lossy translation with no desire to reverse the process.  See <a href="https://gist.githubusercontent.com/bgoodr/4f83d150b109f657b34b6f587f218e66/raw/390791e9d1db9eeaf7bb1884d2998ccac79a3d86/attempt_at_using_str_encode_2.txt" rel="nofollow noreferrer">my second gist</a> which uses Python 2.</span>
