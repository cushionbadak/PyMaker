<div class="post-text" itemprop="text">
<p>I'm relatively new to all of the things mentioned in the title, so bear with me.</p>
<p>Currently I'm stuck with the conversion between python and C. Since CUDA kernels are written in C, so I can't just look at it the python way.</p>
<p>As the documentation is rather limited, and overly complex for a beginner, <strong>I'd like to ask how pyCuda actually converts python(or numpy) arrays for use in C.</strong></p>
<p>For example, a string "stuff" is an array of characters in C, but in python it's an immutable string. However I can do the following:</p>
<pre><code>stuff = "stuff"
d_stuff = cuda.mem_alloc(len(stuff))
cuda.memcpy_htod(d_stuff, stuff)
</code></pre>
<p>And in the CUDA kernel, now I can use it as a char* d_stuff.</p>
<p>However I cannot get it back the same way, as a python string is immutable. So doing the following will obviously raise an error:</p>
<pre><code>newstuff = ""
cuda.memcpy_dtoh(newstuff, d_stuff)
</code></pre>
<p>I know that these can be written as </p>
<pre><code>d_stuff = gpuarray.to_gpu(numpy.array(stuff)) # I need numpy, as the to_gpu expects an array
newstuff = d_stuff.get()
</code></pre>
<p>But I have no idea how it works, and what it does behind the scenes, <strong>so I would really appreciate, if anyone could explain how the conversions work briefly.</strong> (E.g. how does the second example give back a string)</p>
<p>Also I have questions about arrays created with numpy. I've seen that they're widely used for GPUs but I don't know how they work.</p>
<p><strong>Does giving numpy a string create an array of characters in terms of C code, if yes, does an array of strings become char, or something else?</strong> (when translated to C of course)</p>
<p>Writing CUDA code probably would be better with C only, but I'd like to explore the features of python, and I'm doing all this for learning purposes.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>I'd like to ask how PyCUDA actually converts python(or numpy) arrays for use in C.</p>
</blockquote>
<p>It doesn't. PyCUDA simply takes any object which supports the Python <a href="https://docs.python.org/3/c-api/buffer.html" rel="nofollow noreferrer">buffer protocol</a> (typically a numpy array) and directly accesses its host memory buffer to transfer data to and from the GPU. No type conversion or data manipulation is <em>ever</em> performed. Types are directly inferred from the <a href="https://docs.python.org/3/library/ctypes.html#data-types" rel="nofollow noreferrer">CTypes interface</a>, (typically via a numpy <a href="https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.dtypes.html" rel="nofollow noreferrer">dtype</a>, given that numpy arrays are the usual data source).</p>
<blockquote>
<p>Does giving numpy a string create an array of characters in terms of C code, if yes, does an array of strings become char, or something else?</p>
</blockquote>
<p>That depends. For example doing this:</p>
<pre><code>ttt = np.asarray([ "stuff" + str(i)  for i in range(0,20) ])

print( ttt.dtype, type(ttt[0]) ) 
|S7 &lt;type 'numpy.string_'&gt;
</code></pre>
<p>Here numpy uses a special fixed length string data type whose length is calculated from the input data. This is effective a C ordered array of <code>char[7]</code>. See more <a href="https://stackoverflow.com/q/30086936/681865">here</a>. PyCUDA automagically understands how to handle this because of the buffer protocol and the underlying direct mapping to a native C type.</p>
<p>However you can also do this:</p>
<pre><code>ttt = np.asarray([ "stuff" + str(i)  for i in range(0,20) ], dtype=object)

print( ttt.dtype, type(ttt[0]) )
object &lt;type 'str'&gt;
</code></pre>
<p>Here, the numpy array created contains Python objects (in this case a string). This is not something which can be used in PyCUDA, because the Python object doesn't have a direct representation in C.</p>
</div>
<span class="comment-copy">Did you have an actual question to ask?</span>
<span class="comment-copy">2 questions in fact, I'll highlight them, in case they're hard to spot.</span>
<span class="comment-copy">Thank you a lot! Your answer has pretty much everything I was looking for.   Also I originally tried to use char** in a kernel which didn't work, and thought that there was some conversion going on, but I found out that it's in fact a limitation of CUDA due to how data sharing works.</span>
