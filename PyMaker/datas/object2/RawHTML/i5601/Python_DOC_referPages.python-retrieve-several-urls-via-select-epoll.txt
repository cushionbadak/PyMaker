<div class="post-text" itemprop="text">
<p>I have an event oriented server which already uses <a href="https://docs.python.org/2/library/select.html#select.epoll" rel="nofollow noreferrer">select.epoll()</a>.</p>
<p>Now a new requirement should be solved: URLs should get fetched (async).</p>
<p>Up to now I always used the requests library, and I always used it synchronous, never asynchronous.</p>
<p>How can I use the requests library (or a different urllib) combined with linux epoll?</p>
<p>The requests library docs has a note about this, but there only async-frameworks are mentioned (not select.epoll()): <a href="http://docs.python-requests.org/en/master/user/advanced/#blocking-or-non-blocking" rel="nofollow noreferrer">http://docs.python-requests.org/en/master/user/advanced/#blocking-or-non-blocking</a></p>
<p>I am not married with select.epoll(). It worked up to now. I can use a different solution, if feasible. </p>
<p>Background: The bigger question is "Should I use select.epoll() or one of the many async frameworks which python has?". But questions at StackOverflow must not be too broad. That's why this question focuses on "Retrieve several URLs via select.epoll()". If you have hints to the bigger question, please leave a comment.</p>
<p>If you are curious, this question is needed for a small project which I develop in my spare time: <a href="https://github.com/guettli/ipo" rel="nofollow noreferrer">https://github.com/guettli/ipo</a> (IPO is an open source asynchronous job queue which is based on PostgreSQL.)</p>
</div>
<div class="post-text" itemprop="text">
<h2>How can I use the requests library (or a different urllib) combined with linux epoll?</h2>
<p>Unfortunately you can’t unless such a library has been built with this integration in mind. <strong>epoll</strong>, as well as <strong>select</strong>/<strong>poll</strong>/<strong>kqueue</strong> and others are <em>I/O multiplexing</em> system calls and the overall program architecture needs to be built around it. </p>
<p>Simply put, a typical program structure boils down to the following</p>
<ul>
<li>one needs to have a bunch of file descriptors (sockets in non-blocking mode  in your case)</li>
<li>a system call (<strong>man epoll_wait</strong> in case of <strong>epoll</strong>) blocks until a specified event occurs on one or multiple descriptors</li>
<li>information of the descriptors available for I/O is returned</li>
</ul>
<p>After that this is the outer code’s job to handle these descriptors i.e. figure out how much data has become available, call some callbacks etc. </p>
<p>If the library uses regular <em>blocking</em> sockets the only way to parallelize it is to use <em>threads</em>/<em>processes</em>
Here’s a good <a href="https://eklitzke.org/blocking-io-nonblocking-io-and-epoll" rel="nofollow noreferrer">article</a> on the subject, the examples use C and that’s good as it’s easier to understand what’s actually happening under the hood</p>
<h2>Async frameworks &amp; requests library</h2>
<p>Lets check out what’s suggested <a href="http://docs.python-requests.org/en/master/user/advanced/#blocking-or-non-blocking" rel="nofollow noreferrer">here</a></p>
<blockquote>
<p>If you are concerned about the use of blocking IO, there are lots of
  projects out there that combine Requests with one of Python's
  asynchronicity frameworks. Some excellent examples are
  requests-threads, grequests, and requests-futures).</p>
</blockquote>
<p><strong>requests-threads</strong> - uses threads</p>
<p><strong>grequests</strong> - integration with gevent (it’s a different story, see below)</p>
<p><strong>requests-futures</strong> - in fact also threads/processes</p>
<p>neither of them has anything to do with true asynchronicity </p>
<h2>Should I use select.epoll() or one of the many async frameworks which python has</h2>
<p>Please note, <strong>epoll</strong> is <em>linux-specific</em> beast and it won’t work i.e. on OS X that has a different mechanism called <strong>kqueue</strong>. As you appear to be writing a general-purpose job queue it doesn’t seem to be a good solution. </p>
<p>Now back to python. You’ve got the following options:</p>
<p><strong>threads/processes/concurrent.futures</strong> - unlikely is it something you’re aiming at as your app is a typical <a href="http://www.kegel.com/c10k.html" rel="nofollow noreferrer">C10K</a> server</p>
<p><strong>epoll/kqueue</strong> - you’ll have to do everything yourself. In case of fetching an HTTP urls you’ll need to deal with not only http/ssl but also with asynchronous DNS resolution. Also consider using <a href="https://docs.python.org/3/library/asyncore.html" rel="nofollow noreferrer">asyncore</a>[] that provides some basic infrastructure</p>
<p><strong>twisted/tornado</strong> - callback-based frameworks that already do all the low-level stuff for you</p>
<p><strong>gevent</strong> - this is something you might like if you’re going to reuse existing blocking libraries (urllib, requests etc) and use both python 2.x and python 3.x. But this solution is a hack by design. For an app of your size it might be ok, but I wouldn’t use it for anything bigger that should be rock-solid and run in prod</p>
<p><strong>asyncio</strong></p>
<blockquote>
<p>This module provides infrastructure for writing single-threaded
  concurrent code using coroutines, multiplexing I/O access over sockets
  and other resources, running network clients and servers, and other
  related primitives</p>
</blockquote>
<p>It has everything you might need.
There’s also a bunch of libraries working with popular RDBMs and http
<a href="https://github.com/aio-libs" rel="nofollow noreferrer">https://github.com/aio-libs</a></p>
<p>But it lacks support of python 2.x. There are <a href="https://pypi.python.org/pypi/trollius" rel="nofollow noreferrer">ports</a> of asyncio to python 2.x but not sure how stable they are</p>
<h3>Finally</h3>
<p>So if I could sacrifice python 2.x I’d personally go with asyncio &amp; related libraries</p>
<p>If you really really need python 2.x use one of the approaches above depending on the stability required and assumed peak load</p>
</div>
<div class="post-text" itemprop="text">
<p>when doing high performance development,we always choose weapons based on our situation.So it still too broad to answer.</p>
<p>But your bigger question is a easier one.only the IO-bound program is suit for Async.</p>
<p>what is the purpose of epoll and asynchronous?Avoiding the CPU waiting for IO and doing nothing.CPU waiting for IO blocks,IO blocks because NO DATA TO READ or NO space to write.</p>
<p>Buffer is introduced to reduce the system call.When you call read on a stream,you actually read from the buffer.(concepts,not very accurate)</p>
<p>Select or epoll are nonblocking busy polling(epoll implement by interruption underlying).it just essentially something like below</p>
<pre><code>while true {
  for i in stream[]{
    if i has data
          read until unavailable
    }
}
</code></pre>
<p>it's silly,so there is select and epoll.
Everytime you read from buffer,there are data waiting for you,it's high speed IO,then epoll/select is your best choice.And when the buffer is always empty,it's a slow stream,IO-bound,async is very suit for this situation.</p>
<p>I don't know async very well,for me it's just soft interruption internally and a lot of callback.</p>
</div>
<div class="post-text" itemprop="text">
<p>The main point above is correct, you cannot technically do this with a blocking call meant for multiplexed I/O such as <code>select()</code>, <code>epoll()</code>, and the BSD/iOS, Windows variants. These calls allow a timeout specification, so you can come close by repeated polling on short intervals, then passing work to an asynch handler off of the main thread. In that case, the reading is done on the main thread, multiple reads can signal that they're ready, and the main thread is primarily devoted to that task.</p>
<p>If the scale of your problem is small to medium then nothing is going to beat an <code>epoll()...read()</code> or even <code>select()...read()</code>. If your problem (number of read channels) is on the small side. So I'd encourage you to think about that - get as much work off the main thread which can be devoted to the requests. </p>
<p>If you are looking for an async solution, one of your best options is the <code>grequests</code> library, both for ease of use and performance. To get an idea, run the following client-server pair. Note that the use of tornado is irrelevant here and only on the server side whereas your concern is the client.</p>
<p>Try this - the performance difference is night and day.</p>
<p><strong>A solution for you is represented by the client.py class below</strong>; it uses <code>grequests</code> to issue <code>get()</code> requests asynchronously.</p>
<p><strong>server.py</strong></p>
<pre><code>from tornado import (httpserver, options,
                     ioloop, web, gen)
import time

import ujson as json
from collections import defaultdict

class Check(web.RequestHandler):

    @gen.coroutine
    def get(self):
        try:
            data = int(self.get_argument('data'))
        except ValueError:
            raise web.HTTPError(400, reason='Invalid value for data')

        delay = 100
        start = time.time()
        print('Processed: {!r}'.format(data))

       yield gen.Task(ioloop.IOLoop.instance().add_timeout, start + delay / 1000.)

        self.write('.')
        end = time.time()
        self.finish()


if __name__ == '__main__':
    port = 4545

    application = web.Application([
        (r'/get', Check)
        ])

    http_server = httpserver.HTTPServer(application)
    http_server.listen(port)
    print('Listening on port: {}'.format(port))
    ioloop.IOLoop.instance().start()
</code></pre>
<p><strong>client.py</strong></p>
<pre><code>import grequests
from tornado.httpclient import HTTPClient
import time

def call_serial(num, httpclient):
    url = 'http://127.0.0.1:4545/get?data={}'.format(num)
    response = httpclient.fetch(url)
    print('Added: {!r}'.format(num))

def call_async(mapper):
    futures = (grequests.get(url) for url,_ in mapper)
    responses = grequests.map(futures)
    for response, (url,num) in zip(responses, mapper):
        print('Added: {!r}'.format(num))

def check(num):
    if num % 2 == 0:
        return False
    return True

def serial_calls(httpclient, up_to):
    for num in range(up_to):
        if check(num):
            call_serial(num, httpclient)

def async_calls(httpclient, up_to):
    mapper = []

    for num in range(up_to):
        if check(num):
            url = 'http://127.0.0.1:4545/get?data={}'.format(num)    
            mapper.append((url,num))

    call_async(mapper)


if __name__ == '__main__':

    httpclient = HTTPClient()

    print('SERIAL CALLS')
    serial_calls(httpclient, 100)

    print('ASYNC CALLS')
    async_calls(httpclient, 100)
    httpclient.close()
</code></pre>
<p>This is a true async solution, or as close as one can get in CPython/python. No pollers used. </p>
</div>
<span class="comment-copy">you have to show how your event loop works.</span>
<span class="comment-copy">@georgexsh here is how my event loop works: <a href="https://github.com/guettli/ipo/blob/master/ipo/management/commands/ipo_server.py#L17" rel="nofollow noreferrer">github.com/guettli/ipo/blob/master/ipo/management/commands/…</a></span>
<span class="comment-copy">To your bigger question,the principle of IO is Polling for high speed IO and interruption for slow IO.</span>
<span class="comment-copy">@obgnaw you say "the principle of IO is Polling for high speed IO and interruption for slow IO". I would like to optimize later. How can I know if the connection to an URL is slow or high speed? In my case the URLs will be from servers which are very close to the daemon. Thank you for the hint. I guess I will start with epoll() first. What do you think?</span>
<span class="comment-copy">@guettli what python versions does your project need to support?</span>
<span class="comment-copy">thank you for your in depth answer. My current feeling is to go with asyncio and drop Python2 support.</span>
<span class="comment-copy">I am not married with select.epoll(). It worked up to now. I can use a different solution, if feasible.</span>
<span class="comment-copy">Tornado looks good. Thank you for your answer.</span>
<span class="comment-copy">Just to make sure - Tornado is on the server side, only necessary for the server of the server-client pair. The logic that issues the <code>get()</code> requests uses grequests which I've found to be a good if not the best choice.</span>
<span class="comment-copy">about grequests: "Note: You should probably use requests-threads or requests-futures instead." from <a href="https://github.com/kennethreitz/grequests" rel="nofollow noreferrer">github.com/kennethreitz/grequests</a>. Why does the author suggest to use something else?</span>
<span class="comment-copy">I did not notice that as I installed with <code>pip</code>. Let me think about that.</span>
<span class="comment-copy">yes, thinking about it again sound good.</span>
