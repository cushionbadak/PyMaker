<div class="post-text" itemprop="text">
<p>I want to sum all the value in one column based on a range of date in two column:</p>
<pre><code>Start_Date  Value_to_sum  End_date
2017-12-13    2          2017-12-13
2017-12-13    3          2017-12-16 
2017-12-14    4          2017-12-15
2017-12-15    2          2017-12-15
</code></pre>
<p>A simple groupby won't do it since it would only add the value for a specific date. </p>
<p>We could do an embeeded for loop but it would take forever to run:</p>
<pre><code>unique_date = carry.Start_Date.unique()
carry = pd.DataFrame({'Date':unique_date})
carry['total'] = 0
for n in tqdm(range(len(carry))):
    tr = data.loc[data['Start_Date'] &gt;= carry['Date'][n]]
    for i in tr.index:
        if carry['Date'][n] &lt;= tr['End_date'][i]:
                carry['total'][n] += tr['Value_to_sum'][i]
</code></pre>
<p>Something like that would work but like I said would take forever.</p>
<p>The expected output is unique date with the total for each day.</p>
<p>Here it would be</p>
<pre><code>2017-12-13 = 5, 2017-12-14 = 7, 2017-12-15 = 9.
</code></pre>
<p>How do I compute the sum based on the date ranges?</p>
</div>
<div class="post-text" itemprop="text">
<p>First, group by ["Start_Date", "End_date"] to save some operations.</p>
<pre><code>from collections import Counter
c = Counter()
df_g = df.groupby(["Start_Date", "End_date"]).sum().reset_index()

def my_counter(row):
    s, v, e = row.Start_Date, row.Value_to_sum, row.End_date
    if s == e:
        c[pd.Timestamp(s, freq="D")] += row.Value_to_sum
    else:
         c.update({date: v for date in pd.date_range(s, e)})

df_g.apply(my_counter, axis=1) 
print(c)
"""
Counter({Timestamp('2017-12-15 00:00:00', freq='D'): 9,
     Timestamp('2017-12-14 00:00:00', freq='D'): 7,
     Timestamp('2017-12-13 00:00:00', freq='D'): 5,
     Timestamp('2017-12-16 00:00:00', freq='D'): 3})
"""
</code></pre>
<p>Tools used:</p>
<blockquote>
<p>Counter.update([iterable-or-mapping]):
  Elements are counted from an iterable or added-in from another mapping (or counter). Like dict.update() but <strong>adds counts instead of replacing them</strong>. Also, the iterable is expected to be a sequence of elements, not a sequence of (key, value) pairs. -- Cited from <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow noreferrer">Python 3 Documentation</a></p>
</blockquote>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.date_range.html" rel="nofollow noreferrer">pandas.date_range</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Unfortunately, I don't believe there's a way to do this without involving at least one loop.  You are trying see if a date is between your start and end date.  If it is, you want to sum the <code>Value_to_Sum</code> column.  We can make your loop more efficient.</p>
<p>You can create a mask for each unique date and find all rows that match your criteria.  You then apply that mask and take the sum of all matching rows. This should be much faster than iterating over each row individually and determining what date counters to increase.</p>
<pre><code>unique_date = df.Start_Date.unique()
for d in unique_date:
    # create a mask which will give us all the rows 
    # that we want to sum over
    # then apply the mask and take the sum of the Value_to_sum column
    m = (df.Start_Date &lt;= d) &amp; (df.End_date &gt;= d)
    print(d, df[m].Value_to_sum.sum())
</code></pre>
<p>This gives you the output you want:</p>
<pre><code>2017-12-13 5
2017-12-14 7
2017-12-15 9
</code></pre>
<p>Someone else might be able to come up with a clever way to vectorize the entire thing, but I'm not seeing a way to do it.</p>
</div>
<div class="post-text" itemprop="text">
<p>if you want the sum to be part of the original dataframe you can use apply to iterate on each row (but this might not might the most optimized code as you are calculating the sum on every row)</p>
<pre><code>carry['total'] = carry.apply(lambda current_row: carry.loc[(carry['Start_Date'] &lt;= current_row.Start_Date) &amp; (carry['End_date'] &gt;= current_row.Start_Date)].Value_to_sum.sum(),axis=1)
</code></pre>
<p>above will result to</p>
<pre><code>&gt;&gt;&gt; print(carry)
     End_date  Start_Date  Value_to_sum  total
0  2017-12-13  2017-12-13             2      5
1  2017-12-16  2017-12-13             3      5
2  2017-12-15  2017-12-14             4      7
3  2017-12-15  2017-12-15             2      9
</code></pre>
</div>
<span class="comment-copy">Sorry my first language is french, you know you can edit my question for language related issue :)</span>
<span class="comment-copy">I already did a little bit of that. This change seemed drastic enough that I wanted to make sure you didn't really mean "recursive".</span>
<span class="comment-copy">what is your expected out put</span>
<span class="comment-copy">No problem, sorry my error</span>
<span class="comment-copy">I have added my expected output</span>
<span class="comment-copy">Nice answer and very clean</span>
<span class="comment-copy">Nice answer but since my data is huge and I need quick execution I doubt I can use your solution :)</span>
<span class="comment-copy">How large are we talking?  How many unique dates do you have?</span>
<span class="comment-copy">Also, are your date columns just strings, or are they Python datetimes?</span>
<span class="comment-copy">about 4000 dates but there is multiple process before and after. This solution is already much faster then what I had but without any loop would be the best</span>
<span class="comment-copy">datetime , do you think string would be faster ?</span>
