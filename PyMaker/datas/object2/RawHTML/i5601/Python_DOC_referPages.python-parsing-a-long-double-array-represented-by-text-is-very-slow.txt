<div class="post-text" itemprop="text">
<p>I'd delete this question, as it turns out to be my mistake. The bottleneck I had was related to network latency.</p>
<hr/>
<p>I have a Python application that gets as an input a text file that contains 4096 real numbers. It looks like this:</p>
<pre><code>0.3421,0.1215,..........,1.242
</code></pre>
<p>No matter what approach I try, it takes Python about a whole second to parse the text into an actual Python array of floats.</p>
<p>Note that I am using Python 3.5</p>
<p>So far I tried:</p>
<p><strong>Parsing manually and creating the list using list comprehensions:</strong></p>
<pre><code>arr = [float(val) for val in text.split(',')]
</code></pre>
<p><strong>Appending '[' and ']' wrapping signs and using <code>eval</code> function:</strong></p>
<pre><code>arr = eval('[' + text + ']')
</code></pre>
<p><strong>Appending '[' and ']' wrapping signs and using <code>json.loads</code> function:</strong></p>
<pre><code>import json
arr = json.loads('[' + text + ']')
</code></pre>
<p><strong>Creating a Numpy array of strings and converting its data type to float:</strong></p>
<pre><code>import numpy as np
arr = np.array(text.split(',')).astype(np.float)
</code></pre>
<p><strong>Using Numpy's <code>fromstring</code> method</strong></p>
<pre><code>import numpy as np
arr = np.fromstring(text, sep=',')
</code></pre>
<p>None of these options worked faster than a whole second.</p>
<p>How do I get it to convert faster?</p>
</div>
<div class="post-text" itemprop="text">
<p>I think you mistested somehow.  Here's my results:</p>
<pre><code>import timeit

timeit.timeit('eval(s)', number=1000,
              setup="import random;"
                    " s = '[' + ','.join(str(random.random())"
                                        " for _ in range(4096)) + ']'")
</code></pre>
<p>results in</p>
<pre><code>4.92162881999684
</code></pre>
<p>This means that using a simple <code>eval</code> of the string takes ~5ms.</p>
<p>With JSON it gets a little faster:</p>
<pre><code>timeit.timeit('json.loads(s)', number=1000,
              setup="import random, json;"
                    " s = '[' + ','.join(str(random.random())"
                                        " for _ in range(4096)) + ']'")
</code></pre>
<p>results in</p>
<pre><code>1.1105524039994634
</code></pre>
<p>i. e. ~1.1ms</p>
</div>
<div class="post-text" itemprop="text">
<p>Python has it's limits like all other computer applications, as shown <a href="https://wiki.python.org/moin/PythonSpeed/PerformanceTips" rel="nofollow noreferrer">here</a>. 1 second is actually a great time for computing an array of 4096 numbers, considering it goes through a value every 1/4096 of a second.</p>
</div>
<span class="comment-copy">Why isn't "a second" fast enough? Also, keep in mind that it is possible that the bottle neck is not even the Python code itself.</span>
<span class="comment-copy">I work with a lot of requests at a time. I do huge computations that I worked hard so that they take a fraction of a second with Numpy, and now my problem is some stupid parsing that takes 100 times more than all the computations together</span>
<span class="comment-copy">Did you <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">profile</a> the process to see where the actual bottleneck is?</span>
<span class="comment-copy">I don't do a conventional profiling, but I print stuff to <code>stdout</code> and I see that it takes about a second until the array is parsed, then the rest of the steps are performed instantly</span>
<span class="comment-copy">You are doing the opposite direction. You are converting floats to strings, while I am converting strings to floats</span>
<span class="comment-copy">No I'm not.  I build a large string <i>once</i> — just to have test data — and then parse it 1000 times, once using <code>eval()</code> or <code>json.loads()</code>.</span>
<span class="comment-copy">Yes, now I see that. Thanks!</span>
<span class="comment-copy">You were right. What I am actually doing is to read that string from a query. Looks like the bottleneck is on receiving the whole data from the client. Didn't think that it is going to take so long to get such data.. Thanks!!</span>
<span class="comment-copy">No, actually that would be a pretty bad value.  PO mistested somehow.</span>
