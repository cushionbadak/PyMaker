<div class="post-text" itemprop="text">
<p>I have written a script to remove all unique elements from a list and print the list with only repeated elements:</p>
<p>Below are some examples how the output list for an input list should be</p>
<pre><code>Input list1:
1,2,1,1,3,5,3,4,3,1,6,7,8,5

Output List1:
1,1,1,3,5,3,3,1,5

Input list2:
1,2,1,1,3,3,4,3,1,6,5

Output List2:
1,1,1,3,3,3,1

#! /bin/python

def remove_unique(*n):
    dict1={}
    list1=[]
    for i in range(len(n)):
        for j in range(i+1,len(n)):
            if n[i] == n[j]:
               dict1[j]=n[j]
               dict1[i]=n[i]
    for x in range(len(n)):
        if x in dict1.keys():
           list1.append(dict1[x])
    return list1

lst1=remove_unique(1,2,1,1,3,5,3,4,3,1,6,7,8,5)
for n in lst1:
    print(n, end=" ")
</code></pre>
<p>The script above works exactly as expected when tested with few smaller lists. However I want some ideas on how to optimize the script (both time and space complexities considered) for input lists with bigger lengths ( 50000 &lt;=len(list) &lt;= 50M )</p>
</div>
<div class="post-text" itemprop="text">
<p>your script has a number of issues:</p>
<ul>
<li>the classical <code>if x in dict1.keys()</code> =&gt; <code>if x in dict1</code> to be sure to use the dictionary check instead of linear</li>
<li>no list comprehension: <code>append</code> in a loop, not as performant.</li>
<li><code>O(n^2)</code> complexity because of the double loop</li>
</ul>
<p>My approach:</p>
<p>You could count your elements using <code>collections.Counter</code>, then filter out a new list using a list comprehension using a filter on the number of ocurrences:</p>
<pre><code>from collections import Counter

list1 = [1,2,1,1,3,5,3,4,3,1,6,7,8,5]

c = Counter(list1)
new_list1 = [k for k in list1 if c[k]&gt;1]

print(new_list1)
</code></pre>
<p>result:</p>
<pre><code>[1, 1, 1, 3, 5, 3, 3, 1, 5]
</code></pre>
<p>I may be wrong but, the complexity of this approach is (roughly) <code>O(n*log(n))</code> (linear scan of the list plus the hashing of the keys in the dictionary and the lookup in the list comprehension). So, it's good performance-wise.</p>
</div>
<span class="comment-copy">Jean-Fran√ßois has given you an efficient solution to this problem, but for future reference, <code>x in dict1</code> is better than <code>x in dict1.keys()</code>. It's tolerable in Python 3, since <code>.keys()</code> returns a <a href="https://docs.python.org/3/library/stdtypes.html#dict-views" rel="nofollow noreferrer">View object</a> on the dictionary, but in Python 2 it's bad because it has to scan the dict and create a list of the keys. And then it has to do a linear scan of the <code>.keys()</code> list to perform the <code>in</code> test. And constructing that list on <i>every</i> iteration of the <code>for x in range(len(n)):</code> loop is <i>extremely</i> inefficient.</span>
<span class="comment-copy">Fabre :  Thanks for the explanatory answer</span>
