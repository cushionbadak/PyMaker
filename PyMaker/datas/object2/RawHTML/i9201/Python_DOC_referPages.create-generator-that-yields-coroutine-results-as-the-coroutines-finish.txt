<div class="post-text" itemprop="text">
<p>Currently, I have an inefficient synchronous generator that makes many HTTP requests in sequence and yields the results. I'd like to use <a href="https://docs.python.org/3/library/asyncio.html" rel="noreferrer"><code>asyncio</code></a> and <a href="http://aiohttp.readthedocs.io/en/stable/" rel="noreferrer"><code>aiohttp</code></a> to parallelise the requests and thereby speed up this generator, but I want to keep it as an ordinary generator (not a <a href="https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-pep525" rel="noreferrer">PEP 525 async generator</a>) so that the non-async code that calls it doesn't need to be modified. How can I create such a generator?</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed" rel="noreferrer"><code>asyncio.as_completed()</code></a>, currently barely documented, takes an iterable of coroutines or futures and returns an iterable of futures in the order that the input futures complete. <em>Normally</em>, you'd loop over its result and <code>await</code> the members from inside an <code>async</code> function...</p>
<pre><code>import asyncio

async def first():
    await asyncio.sleep(5)
    return 'first'

async def second():
    await asyncio.sleep(1)
    return 'second'

async def third():
    await asyncio.sleep(3)
    return 'third'

async def main():
    for future in asyncio.as_completed([first(), second(), third()]):
        print(await future)

loop = asyncio.get_event_loop()

# Prints 'second', then 'third', then 'first'
loop.run_until_complete(main())
</code></pre>
<p>... but for the purpose of this question, what we want is to be able to yield these results from an ordinary generator, so that normal synchronous code can consume them without ever knowing that <code>async</code> functions are being used under the hood. We can do that by calling <code>loop.run_until_complete()</code> on the futures yielded by our <code>as_completed</code> call...</p>
<pre><code>import asyncio

async def first():
    await asyncio.sleep(5)
    return 'first'

async def second():
    await asyncio.sleep(1)
    return 'second'

async def third():
    await asyncio.sleep(3)
    return 'third'

def ordinary_generator():
    loop = asyncio.get_event_loop()
    for future in asyncio.as_completed([first(), second(), third()]):
        yield loop.run_until_complete(future)

# Prints 'second', then 'third', then 'first'
for element in ordinary_generator():
    print(element)
</code></pre>
<p>In this way, we've exposed our async code to non-async-land in a manner that doesn't require callers to define any functions as <code>async</code>, or to even know that <code>ordinary_generator</code> is using <code>asyncio</code> under the hood.</p>
<p>As an alternative implementation of <code>ordinary_generator()</code> that offers more flexibility in some circumstances, we can repeatedly call <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.wait" rel="noreferrer"><code>asyncio.wait()</code></a> with the <code>FIRST_COMPLETED</code> flag instead of looping over <code>as_completed()</code>:</p>
<pre><code>import concurrent.futures

def ordinary_generator():
    loop = asyncio.get_event_loop()
    pending = [first(), second(), third()]
    while pending:
        done, pending = loop.run_until_complete(
            asyncio.wait(
                pending,
                return_when=concurrent.futures.FIRST_COMPLETED
            )
        )
        for job in done:
            yield job.result()
</code></pre>
<p>This approach, maintaining a list of <code>pending</code> jobs, has the advantage that we can adapt it to add jobs to the <code>pending</code> list on the fly. This is useful in use cases where our async jobs can add an unpredictable number of further jobs to the queue - like a web spider that follows all links on each page that it visits.</p>
</div>
<span class="comment-copy">Do these need a <code>loop.close()</code>?</span>
