<div class="post-text" itemprop="text">
<p>I'm trying to create a text-delimited file containing the data from the "Actions" table on webpages like this one: <a href="http://stats.swehockey.se/Game/Events/300978" rel="nofollow noreferrer">http://stats.swehockey.se/Game/Events/300978</a></p>
<p>I would like each line to include the game # (from the end of the URL) and then the text from the line on the table. For example:</p>
<pre><code>300972 | 60:00 | GK Out | OHK | 33. Hudacek, Julius
</code></pre>
<p>I haven't been able to get each row to actually separate. I've tried parsing through each row and column, using a list of stripped strings, and searching by different tags, classes, and styles.</p>
<p>Here's what I currently have: </p>
<pre><code>from bs4 import BeautifulSoup
import urllib.request

def createtext():
    gamestr = urlstr + "|" 
    #Find all table lines. Create one pipe-delimited line for each.
    aptext = gamestr
    for el in soup.find_all('tr'):
        playrow = el.find_all('td', 'tdOdd')
        for td in playrow:
            if(td.find(text=True)) not in ("", None, "\n"):
                aptext = aptext + ''.join(td.text) + "|"
        aptext = aptext + "\n" + gamestr

    #Creates file with Game # as filename and writes the data to the file
    currentfile = urlstr + ".txt"
    with open(currentfile, "w") as f:
        f.write(str(aptext))                        

#Grabs the HTML file and creates the soup
urlno = 300978
urlstr = str(urlno)
url = ("http://stats.swehockey.se/Game/Events/" + urlstr)
request = urllib.request.Request(url)
response = urllib.request.urlopen(request)
pbpdoc = response.read().decode('utf-8')
soup = BeautifulSoup(pbpdoc)
createtext()
</code></pre>
<p>Thanks for any help or guidance!</p>
</div>
<div class="post-text" itemprop="text">
<p>First of all, <em>you don't have to construct the CSV data manually</em>, Python provides a built-in <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer"><code>csv</code> module</a> for that.</p>
<p>Then, since you are up to "actions" only, I'd identify the "actions" table and find the events-only rows. This can be done with the help of a filtering function checking the first cell to not be empty: </p>
<pre><code>import csv

from bs4 import BeautifulSoup
import requests


def only_action_rows(tag):
    if tag.name == 'tr':
        first_cell = tag.find('td', class_='tdOdd')
        return first_cell and first_cell.get_text(strip=True)


event_id = 300978
url = "http://stats.swehockey.se/Game/Events/{event_id}".format(event_id=event_id)
response = requests.get(url)

soup = BeautifulSoup(response.text, "html.parser")

actions_table = soup.find("h2", text="Actions").find_parent("table")
data = [[event_id] + [td.get_text(strip=True) for td in row.find_all('td', class_='tdOdd')]
        for row in actions_table.find_all(only_action_rows)]

with open("output.csv", "w") as f:
    writer = csv.writer(f)
    writer.writerows(data)
</code></pre>
<p>Note that I'm using <a href="http://docs.python-requests.org/en/master/" rel="nofollow noreferrer"><code>requests</code></a> here.</p>
</div>
<span class="comment-copy">Thanks for the reply and the code! I hit this error when I tried to use it: 'NoneType' object has no attribute 'find_parent'</span>
<span class="comment-copy">@NotDave okay, looks like you have an old bs4 version - try with <code>text</code> instead of <code>string</code>.</span>
<span class="comment-copy">That did the trick! Thanks a lot!</span>
