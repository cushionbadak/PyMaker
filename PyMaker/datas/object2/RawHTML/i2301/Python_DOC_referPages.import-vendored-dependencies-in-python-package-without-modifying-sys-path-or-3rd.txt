<div class="post-text" itemprop="text">
<h3>Summary</h3>
<p>I am working on a series of add-ons for <a href="http://ankisrs.net/" rel="noreferrer">Anki</a>, an open-source flashcard program. Anki add-ons are shipped as Python packages, with the basic folder structure looking as follows:</p>
<pre><code>anki_addons/
    addon_name_1/
        __init__.py
    addon_name_2/
        __init__.py
</code></pre>
<p><code>anki_addons</code> is appended to <code>sys.path</code> by the base app, which then imports each add_on with <code>import &lt;addon_name&gt;</code>.</p>
<p>The problem I have been trying to solve is to find a reliable way to <strong>ship packages and their dependencies with my add-ons while not polluting global state or falling back to manual edits of the vendored packages</strong>.</p>
<h3>Specifics</h3>
<p>Specifically, given an add-on structure like this...</p>
<pre><code>addon_name_1/
    __init__.py
    _vendor/
        __init__.py
        library1
        library2
        dependency_of_library2
        ...
</code></pre>
<p>...I would like to be able to import any arbitrary package that is included in the <code>_vendor</code> directory, e.g.:</p>
<pre><code>from ._vendor import library1
</code></pre>
<p>The main difficulty with relative imports like this is that they do not work for packages that also depend on other packages imported through absolute references (e.g. <code>import dependency_of_library2</code> in the source code of <code>library2</code>)</p>
<h3>Solution attempts</h3>
<p>So far I have explored the following options:</p>
<ol>
<li>Manually updating the third-party packages, so that their import statements point to the fully qualified module path within my python package (e.g. <code>import addon_name_1._vendor.dependency_of_library2</code>). But this is tedious work that is not scalable to larger dependency trees and not portable to other packages.</li>
<li>Adding <code>_vendor</code> to <code>sys.path</code> via <code>sys.path.insert(1, &lt;path_to_vendor_dir&gt;)</code> in my package init file. This works, but it introduces a global change to the module look-up path which will affect other add-ons and even the base app itself. It just seems like a hack that could result in a pandora's box of issues later down the line (e.g. conflicts between different versions of the same package, etc.).</li>
<li><a href="https://stackoverflow.com/questions/17211078/how-to-temporarily-modify-sys-path-in-python">Temporarily modifying sys.path for my imports</a>; but this fails to work for third-party modules with method-level imports.</li>
<li>Writing a <a href="https://www.python.org/dev/peps/pep-0302/" rel="noreferrer">PEP302</a>-style custom importer based off an example I found in <a href="https://github.com/pypa/setuptools/blob/master/setuptools/extern/__init__.py" rel="noreferrer">setuptools</a>, but I just couldn't make head nor tail of that.</li>
</ol>
<hr/>
<p>I've been stuck on this for quite a few hours now and I'm beginning to think that I'm either completely missing an easy way to do this, or that there is something fundamentally wrong with my entire approach.</p>
<p><strong>Is there no way I can ship a dependency tree of third-party packages with my code, without having to resort to <code>sys.path</code> hacks or modifying the packages in question?</strong></p>
<hr/>
<p>Edit:</p>
<p>Just to clarify: I don't have any control over how add-ons are imported from the anki_addons folder. anki_addons is just the directory provided by the base app where all add-ons are installed into. It is added to the sys path, so the add-on packages therein pretty much just behave like any other python package located in Python's module look-up paths.</p>
</div>
<div class="post-text" itemprop="text">
<p>First of all, I'd advice against vendoring; a few major packages did use vendoring before but have switched away to avoid the pain of having to handle vendoring. One such example is the <a href="https://github.com/requests/requests/issues/4031" rel="nofollow noreferrer"><code>requests</code> library</a>. If you are relying on people using <code>pip install</code> to install your package, then <em>just use dependencies</em> and tell people about virtual environments. Don't assume you need to shoulder the burden of keeping dependencies untangled or need to stop people from installing dependencies in the global Python <code>site-packages</code> location.</p>
<p>At the same time, I appreciate that a plug-in environment of a third-party tool is something different, and if adding dependencies to the Python installation used by that tool is cumbersome or impossible vendorizing may be a viable option. I see that Anki distributes extensions as <code>.zip</code> files without setuptools support, so that's certainly such an environment.</p>
<p>So if you choose to vendor dependencies, then use a script to manage your dependencies and update their imports. This is your option #1, but <em>automated</em>. </p>
<p>This is the path that the <code>pip</code> project has chosen, see their <a href="https://github.com/pypa/pip/tree/master/tasks" rel="nofollow noreferrer"><code>tasks</code> subdirectory</a> for their automation, which builds on the <a href="https://www.pyinvoke.org/" rel="nofollow noreferrer"><code>invoke</code> library</a>. See the pip project <a href="https://github.com/pypa/pip/blob/master/src/pip/_vendor/README.rst" rel="nofollow noreferrer">vendoring README</a> for their policy and rationale (chief among those is that <code>pip</code> needs to <em>bootstrap</em> itself, e.g. have their dependencies available to be able to install anything).</p>
<p>You should not use any of the other options; you already enumerated the issues with #2 and #3.</p>
<p>The issue with option #4, using a custom importer, is that <em>you still need to rewrite imports</em>. Put differently, the custom importer hook used by <code>setuptools</code> doesn't solve the vendorized namespace problem at all, it instead makes it possible to dynamically import top-level packages if the vendorized packages are missing (a problem that <a href="https://github.com/pypa/pip/tree/master/src/pip/_vendor#debundling" rel="nofollow noreferrer"><code>pip</code> solves with a <em>manual</em> debundling process</a>). <code>setuptools</code> actually uses option #1, where they rewrite the source code for vendorized packages. See for example <a href="https://github.com/pypa/setuptools/blob/c2f72efd261bf89372dfa27b1c115012e74bd525/setuptools/_vendor/packaging/requirements.py#L9-L12" rel="nofollow noreferrer">these lines in the <code>packaging</code> project</a> in the <code>setuptools</code> vendored subpackage; the <code>setuptools.extern</code> namespace is handled by the custom import hook, which then redirects either to <code>setuptools._vendor</code> or the top-level name if importing from the vendorized package fails.</p>
<p>The <code>pip</code> automation to update vendored packages takes the following steps:</p>
<ul>
<li>Delete <em>everything</em> in the <code>_vendor/</code> subdirectory except the documentation, the <code>__init__.py</code> file and the requirements text file.</li>
<li>Use <code>pip</code> to install all vendored dependencies into that directory, using a dedicated requirements file named <code>vendor.txt</code>, avoiding compilation of <code>.pyc</code> bytecache files and ignoring transient dependencies (these are assumed to be listed in <code>vendor.txt</code> already); the command used is <code>pip install -t pip/_vendor -r pip/_vendor/vendor.txt --no-compile --no-deps</code>.</li>
<li>Delete everything that was installed by <code>pip</code> but not needed in a vendored environment, i.e. <code>*.dist-info</code>, <code>*.egg-info</code>, the <code>bin</code> directory, and a few things from installed dependencies that <code>pip</code> would never use.</li>
<li>Collect all installed directories and added files sans <code>.py</code> extension (so anything not in the whitelist); this is the <code>vendored_libs</code> list.</li>
<li>Rewrite imports; this is simply a series of regexes, where every name in <code>vendored_lists</code> is used to replace <code>import &lt;name&gt;</code> occurrences with <code>import pip._vendor.&lt;name&gt;</code> and every <code>from &lt;name&gt;(.*) import</code> occurrence with <code>from pip._vendor.&lt;name&gt;(.*) import</code>.</li>
<li>Apply a few patches to mop up the remaining changes needed; from a vendoring perspective, only the <code>pip</code> <a href="https://github.com/pypa/pip/blob/master/tasks/vendoring/patches/requests.patch" rel="nofollow noreferrer">patch for <code>requests</code></a> is interesting here in that it updates the <code>requests</code> library backwards compatibility layer for the vendored packages that the <code>requests</code> library had removed; this patch is quite meta!</li>
</ul>
<p>So in essence, the most important part of the <code>pip</code> approach, the rewriting of vendored package imports is quite simple; paraphrased to simplify the logic and removing the <code>pip</code> specific parts, it is simply the following process:</p>
<pre><code>import shutil
import subprocess
import re

from functools import partial
from itertools import chain
from pathlib import Path

WHITELIST = {'README.txt', '__init__.py', 'vendor.txt'}

def delete_all(*paths, whitelist=frozenset()):
    for item in paths:
        if item.is_dir():
            shutil.rmtree(item, ignore_errors=True)
        elif item.is_file() and item.name not in whitelist:
            item.unlink()

def iter_subtree(path):
    """Recursively yield all files in a subtree, depth-first"""
    if not path.is_dir():
        if path.is_file():
            yield path
        return
    for item in path.iterdir():
        if item.is_dir():
            yield from iter_subtree(item)
        elif item.is_file():
            yield item

def patch_vendor_imports(file, replacements):
    text = file.read_text('utf8')
    for replacement in replacements:
        text = replacement(text)
    file.write_text(text, 'utf8')

def find_vendored_libs(vendor_dir, whitelist):
    vendored_libs = []
    paths = []
    for item in vendor_dir.iterdir():
        if item.is_dir():
            vendored_libs.append(item.name)
        elif item.is_file() and item.name not in whitelist:
            vendored_libs.append(item.stem)  # without extension
        else:  # not a dir or a file not in the whilelist
            continue
        paths.append(item)
    return vendored_libs, paths

def vendor(vendor_dir):
    # target package is &lt;parent&gt;.&lt;vendor_dir&gt;; foo/_vendor -&gt; foo._vendor
    pkgname = f'{vendor_dir.parent.name}.{vendor_dir.name}'

    # remove everything
    delete_all(*vendor_dir.iterdir(), whitelist=WHITELIST)

    # install with pip
    subprocess.run([
        'pip', 'install', '-t', str(vendor_dir),
        '-r', str(vendor_dir / 'vendor.txt'),
        '--no-compile', '--no-deps'
    ])

    # delete stuff that's not needed
    delete_all(
        *vendor_dir.glob('*.dist-info'),
        *vendor_dir.glob('*.egg-info'),
        vendor_dir / 'bin')

    vendored_libs, paths = find_vendored_libs(vendor_dir, WHITELIST)

    replacements = []
    for lib in vendored_libs:
        replacements += (
            partial(  # import bar -&gt; import foo._vendor.bar
                re.compile(r'(^\s*)import {}\n'.format(lib), flags=re.M).sub,
                r'\1from {} import {}\n'.format(pkgname, lib)
            ),
            partial(  # from bar -&gt; from foo._vendor.bar
                re.compile(r'(^\s*)from {}(\.|\s+)'.format(lib), flags=re.M).sub,
                r'\1from {}.{}\2'.format(pkgname, lib)
            ),
        )

    for file in chain.from_iterable(map(iter_subtree, paths)):
        patch_vendor_imports(file, replacements)

if __name__ == '__main__':
    # this assumes this is a script in foo next to foo/_vendor
    here = Path('__file__').resolve().parent
    vendor_dir = here / 'foo' / '_vendor'
    assert (vendor_dir / 'vendor.txt').exists(), '_vendor/vendor.txt file not found'
    assert (vendor_dir / '__init__.py').exists(), '_vendor/__init__.py file not found'
    vendor(vendor_dir)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>How about making your <code>anki_addons</code> folder a package and importing the the required libraries to <code>__init__.py</code> in the main package folder.</p>
<p>So it'd be something like </p>
<pre><code>anki/
__init__.py
</code></pre>
<p>In <code>anki.__init__.py</code> :</p>
<pre><code>from anki_addons import library1
</code></pre>
<p>In <code>anki.anki_addons.__init__.py</code> :</p>
<pre><code>from addon_name_1 import *
</code></pre>
<p>I'm new at this, so please bear with me here. </p>
</div>
<div class="post-text" itemprop="text">
<p>The best way to bundle dependencies is to use a <code>virtualenv</code>. The <code>Anki</code> project should at least be able to install inside one.</p>
<p>I think what you are after is <code>namespace packages</code>.</p>
<p><a href="https://packaging.python.org/guides/packaging-namespace-packages/" rel="nofollow noreferrer">https://packaging.python.org/guides/packaging-namespace-packages/</a></p>
<p>I would imagine that the main Anki project has a <code>setup.py</code> and every add-on has its own <code>setup.py</code> and can be installed from its own source distribution. Then the add-ons can list their dependencies in their own <code>setup.py</code> and pip will install them in <code>site-packages</code>.</p>
<p>Namespace packages only solves part of the problem and as you said you don't have any control over how add-ons are imported from the anki_addons folder. I think designing how add-ons are imported and packaging them goes hand-in-hand.</p>
<p>The <code>pkgutil</code> module provides a way for the main project to discovered the installed add-ons. 
<a href="https://packaging.python.org/guides/creating-and-discovering-plugins/" rel="nofollow noreferrer">https://packaging.python.org/guides/creating-and-discovering-plugins/</a></p>
<p>A project that uses this extensively is Zope. <a href="http://www.zope.org" rel="nofollow noreferrer">http://www.zope.org</a></p>
<p>Have a look here:
<a href="https://github.com/zopefoundation/zope.interface/blob/master/setup.py" rel="nofollow noreferrer">https://github.com/zopefoundation/zope.interface/blob/master/setup.py</a></p>
</div>
<span class="comment-copy">The recommended method is to <b>not vendorize</b>. Use a virtualenv to install your package into instead. Major projects that did vendorize before explicitly stepped away from the practice.</span>
<span class="comment-copy">@MartijnPieters I would love to be able to do that, but I don't see how add-on specific virtualenvs could work (in the context of the add-on system described above). I do appreciate the general advice, though.</span>
<span class="comment-copy">Is <code>iter_subtree</code> different than <a href="https://docs.python.org/3/library/os.html#os.walk" rel="nofollow noreferrer"><code>os.walk(topdown=False)</code></a>?</span>
<span class="comment-copy">@Ben: <code>os.walk()</code> doesn't give you <code>pathlib</code> paths, only strings; <code>iter_subtree()</code> works exclusively with <code>pathlib.Path</code> instances.</span>
<span class="comment-copy">I see. So you're writing it to avoid creating a new Path from each string returned? Thanks for the explanation</span>
<span class="comment-copy">Thank you, Martijn! Your answer was very insightful and helped clear up a lot of the confusion I had on these different approaches. If anything, it saved me from going down even more of a rabbit-hole trying to find the perfect solution I envisioned which obviously does not exist. I also very much appreciate that you even took the time to modify the pip script to get me started with automating my  own vendoring. I haven't had a chance to give it a try, yet, but it looks very promising! I just awarded you the bounty as your answer absolutely deserved it. Thanks again!</span>
<span class="comment-copy">Thanks for the response! Really appreciate it. Just to clarify: I don't have any control over how add-ons are imported from the <code>anki_addons</code> folder. <code>anki_addons</code> is just the directory provided by the base app where all add-ons are installed into. It is added to the sys path, so the add-on packages therein pretty much just behave like any other python package located in Python's module look-up paths.</span>
<span class="comment-copy">But to follow along with your train of thought: The failure point always occurs when Python tries to import a package through an unresolvable absolute import. E.g.: Importing library1 would fail because its dependency, library2, would not be found in the module look-up path. And as Python 3 no longer supports implicit relative imports, even moving library2 into library1's package folder would not work without adjusting library1's source code for explicit relative imports.</span>
<span class="comment-copy">Even worse, a lot of packages will use their own package name for in-package imports (e.g. <code>import library1.module1</code> within <code>library1/__init__.py</code>). So even without any dependencies, packaging third-party packages can fail.</span>
<span class="comment-copy">Thanks for clarifying. Really appreciate it. If <a href="https://stackoverflow.com/questions/38243682/whats-the-standard-way-to-package-a-python-project-with-dependencies">this</a> could be of some help.</span>
<span class="comment-copy">In my experience, we've used conda and sometimes even pipenv, but those were smaller projects. I'm not sure if they could be of help in your case, but just putting it out there.</span>
<span class="comment-copy">No, this is not what the OP Is asking for. They are not looking for a <code>toplevel.packagename</code> setup, they are asking how to best bundle a series of dependent packages and <b>not</b> install them in <code>site-packages</code> at the top level.</span>
<span class="comment-copy">@MartijnPieters The best way to bundle dependencies is to use a <code>virtualenv</code>.</span>
<span class="comment-copy">@EddyPronk: yes, that's certainly something I'm advocating in my answer. But what has that got to do with namespace packages?</span>
