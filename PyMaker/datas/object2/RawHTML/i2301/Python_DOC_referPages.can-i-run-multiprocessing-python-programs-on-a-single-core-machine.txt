<div class="post-text" itemprop="text">
<p>So this is more or less a theoretical question. I have a single core machine which is supposedly powerful but nevertheless only one core. Now I have two choices to make :</p>
<ol>
<li><p>Multithreading: As far as my knowledge is concerned I cannot make use of multiple cores in my machines even if I had them because of GIL. Hence in this situation, it does not make any difference.</p></li>
<li><p>Multiprocessing: This is where I have a doubt. Can I do multiprocessing on a single core machine? Or everytime I have to check the cores available in my machine and then run exactly the same or less number of processes?</p></li>
</ol>
<p>Can someone please guide me on the relation between multiprocessing and cores in a machine. </p>
<p>I know this is a theoretical question but my concepts are not very clear on this.</p>
</div>
<div class="post-text" itemprop="text">
<p>This is a big topic but here are some pointers.</p>
<ul>
<li>Think of threads as processes that share the same address space and can access the same memory. Communication is done by shared variables. Multiple threads can run within the same process.</li>
<li>Processes (in this context, and roughly speaking) have their own private data and if two processes want to communicate that communication has to be done more explicitly.</li>
<li>When you are writing a program where the bottleneck is CPU cycles, neither threads or processes will give you a speedup on a single core machine.</li>
<li>Processes and threads are still useful for multitasking (rapid switching between (sub)programs) - this is what your operating system does because it runs far more processes than you have cores.</li>
<li>Processes and threads (or even coroutines!) can give you considerable speedup even on a single core machine if the tasks you are executing are I/O bound - think of fetching data from a network. For example, instead of actively waiting for data to be sent or to arrive, another process or thread can initiate the next network operation.</li>
<li>Threads are preferable over processes when you don't need explicit encapsulation due to their lower overhead. For most CPU-bound concurrent problems, and especially the large subset of "<a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel" rel="nofollow noreferrer">embarassingly parallel</a>" ones, it does not make much sense to spawn more processes than you have processors.</li>
<li>The Python GIL prevents two threads in the same process from running in parallel, i.e. from multiple cores  executing instructions literally at the same time.</li>
<li>Therefore threads in Python are relatively useless for speeding up CPU-bound tasks, but can still be very useful for I/O bound tasks, because blocking operations (e.g. waiting for network data) release the GIL such that another thread can run while the other waits.</li>
<li>If you have multiple processors, you can have true parallelism by spawning multiple processes despite the GIL. This is only worth it for CPU bound tasks, and often you have to consider the overhead of spawning processes and the communication cost between processes.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>You CAN use both multithreading and multiprocessing in single core systems.</p>
<p>The GIL limits the usefulness of multithreading in pure Python for computation-bound tasks, no matter your underlying architecture. For I/O-bound tasks, they do work perfectly fine. Had they had not any use, they would not have been implemented in the first place, probably.</p>
<p>For pure Python software, multiprocessing is always a safer choice when it comes to parallel computing. Of course, multiple processes are more expensive than multiple threads (since processes do not share memory, contrarily to threads; also, processes come with slightly higher overhead compared to threads).</p>
<p>For single processor machines, however, multiprocessing (and multithreading) buys you little to no extra speed for computationally heavy tasks, and they should actually even slow you down a bit. But, if the OS supports them (which is pretty common for desktop, workstation, clusters, etc, but may not be common for embedded systems), they allow you to effectively run simultaneously multiple I/O-bound programs.</p>
<p>Long story short, it depends a bit on what you are doing...</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/3.7/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing</a> module basically spawns up multiple instances of python interpreter, so there is no worry of GIL.</p>
<p>multiprocessing uses the same API used by <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">threading</a> module if you have used it previously.</p>
<hr/>
<p>You seem to be confused between multiprocessing, threading <em>(you referring as multithreading)</em> and X-core processor. </p>
<ul>
<li>No matter what, when you start Python <em>(CPython implementation)</em> it will only use one core of your processor.</li>
<li>Threading is distributing the load between the different component of the script. Suppose you have to interact with an external API, your script has to wait for communication to finish until it proceeds next. You have are making multiple similar calls, it will take linear time. Whereas if you use threading, you can do those calls parallelly.</li>
</ul>
<p>See also: <a href="https://stackoverflow.com/q/12166268/939986">PyPy implementation of Python</a></p>
</div>
<span class="comment-copy">You can answer that for forself: check the number of programs running on your system and compare that with number of cores.</span>
<span class="comment-copy">Probably i was not able to get my question across clearly enough. Since i have one core and i spin up 3 computationally intensive process, the OS would have to do context switch between them. So with one core running 3 process in parallel can in no way be achieved. Kindly let me know if my understanding is correct</span>
<span class="comment-copy">@user1867151 you understood correctly. Concurreny is about dealing with lots of things at once and can be achieved by context switching, parallelism on the other side is about doing lots of things at exactly the same time. For true parellelism, you need more than one processor.</span>
