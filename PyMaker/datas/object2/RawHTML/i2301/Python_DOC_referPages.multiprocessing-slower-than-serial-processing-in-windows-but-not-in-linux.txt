<div class="post-text" itemprop="text">
<p>I'm trying to parallelize a <code>for loop</code> to speed-up my code, since the loop processing operations are all independent. Following online tutorials, it seems the standard <code>multiprocessing</code> library in Python is a good start, and I've got this working for basic examples.</p>
<p>However, for my actual use case, I find that parallel processing (using a dual core machine) is actually a little (&lt;5%) slower, when run on Windows. Running the same code on Linux, however, results in a parallel processing speed-up of ~25%, compared to serial execution.</p>
<p>From the docs, I believe this may relate to Window's lack of fork() function, which means the process needs to be initialised fresh each time. However, I don't fully understand this and wonder if anyone can confirm this please?</p>
<p>Particularly,</p>
<p>--&gt; Does this mean that all code in the calling python file gets run for each parallel process on Windows, even initialising classes and importing packages? </p>
<p>--&gt; If so, can this be avoided by somehow passing a copy (e.g. using deepcopy) of the class into the new processes?</p>
<p>--&gt; Are there any tips / other strategies for efficient parallelisation of code design for both unix and windows.</p>
<p>My exact code is long and uses many files, so I have created a pseucode-style example structure which hopefully shows the issue.</p>
<pre><code># Imports
from my_package import MyClass
imports many other packages / functions

# Initialization (instantiate class and call slow functions that get it ready for processing)
my_class = Class()
my_class.set_up(input1=1, input2=2)

# Define main processing function to be used in loop
def calculation(_input_data):
    # Perform some functions on _input_data
    ......
    # Call method of instantiate class to act on data
    return my_class.class_func(_input_data)

input_data = np.linspace(0, 1, 50)
output_data = np.zeros_like(input_data)

# For Loop (SERIAL implementation)
for i, x in enumerate(input_data):
    output_data[i] = calculation(x)

# PARALLEL implementation (this doesn't work well!)
with multiprocessing.Pool(processes=4) as pool:
    results = pool.map_async(calculation, input_data)
    results.wait()
output_data = results.get()
</code></pre>
<p>EDIT: I do not believe the question is a duplicate of the one suggested, since this relates to a difference in Windows and Linunx, which is not mentioned at all in the suggested duplicate question.</p>
</div>
<div class="post-text" itemprop="text">
<p>NT Operating Systems lack the UNIX <code>fork</code> primitive. When a new process is created, it starts as a blank process. It's responsibility of the parent to instruct the new process on how to bootstrap.</p>
<p>Python <code>multiprocessing</code> APIs abstracts the process creation trying to give the same feeling for the <code>fork</code>, <code>forkserver</code> and <code>spawn</code> start methods. </p>
<p>When you use the <code>spawn</code> starting method, this is what happens under the hood.</p>
<ol>
<li>A blank process is created</li>
<li>The blank process starts a brand new Python interpreter</li>
<li>The Python interpreter is given the MFA (Module Function Arguments) you specified via the <code>Process</code> class initializer</li>
<li>The Python interpreter loads the given module resolving all the imports</li>
<li>The <code>target</code> function is looked up within the module and called with the given <code>args</code> and <code>kwargs</code></li>
</ol>
<p>The above flow brings few implications. </p>
<p>As you noticed yourself, it is a much more taxing operation compared to <code>fork</code>. That's why you notice such a difference in performance.</p>
<p>As the module gets imported from scratch in the child process, all import side effects are executed anew. This means that constants, <a href="https://stackoverflow.com/questions/49961490/multiprocessing-event-not-working/49975240#49975240">global variables</a>, <a href="https://stackoverflow.com/questions/49936735/a-timeout-decorator-class-with-multiprocessing-gives-a-pickling-error/49940260#49940260">decorators</a> and first level instructions will be executed again.</p>
<p>On the other side, initializations made during the parent process execution will not be propagated to the child. See <a href="https://stackoverflow.com/questions/49782749/processpoolexecutor-logging-fails-to-log-inside-function-on-windows-but-not-on-u/49791106#49791106">this</a> example.</p>
<p>This is why in the <code>multiprocessing</code> documentation they added a specific paragraph for Windows in the <a href="https://docs.python.org/3/library/multiprocessing.html?highlight=process#the-spawn-and-forkserver-start-methods" rel="nofollow noreferrer">Programming Guidelines</a>. I highly recommend to read the Programming Guidelines as they already include all the required information to write portable multi-processing code.</p>
</div>
<span class="comment-copy">Possible duplicate of <a href="https://stackoverflow.com/questions/48489753/why-doesnt-multiprocessing-pool-map-speed-up-compared-to-serial-map">Why doesn't multiprocessing pool map speed up compared to serial map?</a></span>
