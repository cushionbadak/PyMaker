<div class="post-text" itemprop="text">
<p>Let's say I have the following class defined:</p>
<pre><code>class Animal:
    def __init__(self):
        self.isAlive = True
</code></pre>
<p>Along with the following function:</p>
<pre><code>def Kill_Animal(animal):
    animal.isAlive = False
</code></pre>
<p>Now, if I create a List of animals, as follows:</p>
<pre><code>AnimalsList = [Animal() for i in range(0,5)]
</code></pre>
<p>If the function is applied to any instance of the Animal Class inside the list, the isAlive attribute gets changed to False. However, if I wanted to apply this function to this list and change its contents via the multiprocessing library, what would be the correct way to do it?</p>
<p>I have tried the following:</p>
<pre><code>from multiprocessing import Process, Pool

pool = Pool()
pool.map(Kill_Animal, AnimalsList[0:3])
</code></pre>
<p>However, if i try checking the attribute for all the elements inside the list, the result is as follows:</p>
<pre><code>[print(animal.isAlive) for animal in AnimalsList]
</code></pre>
<p>Output: True True True True True</p>
<p>Additionally, if I try checking the ID of the object that is passed to the Kill_Animal function during runtime via the Pool.Map, it does not match with the object's own ID. I am familiar with Python's call-by-object reference, but what is happening here? </p>
</div>
<div class="post-text" itemprop="text">
<p>After studying the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing documentation</a>, I understood the misinterpretation of the concept.</p>
<p>With <strong>multiprocessing</strong>, even if an instance of a class is passed as an argument, it makes sense that the ID is different from the one in the calling method, since now we are working in a different <strong>Process</strong> altogether, and therefore this object is a copy of the original object, and does not correspond to the same place in memory. Because of that, whatever changes made in the copy have no impact on its original instance.</p>
<p>In order to use parallellism and share states, a different concept must be applied, the one of <strong>multithreading</strong>, as available in the <a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">thread-based parallellism documentation</a>. The difference between multithreading and multiprocessing has been thoroughly discussed here: <a href="https://stackoverflow.com/questions/3044580/multiprocessing-vs-threading-python">Multiprocessing vs Threading Python</a></p>
<p>Returning to the original question, two easy ways could be achieved to loop through the List and apply the function:</p>
<h1>1. Using the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing.dummy</a>:</h1>
<blockquote>
<p>multiprocessing.dummy replicates the API of multiprocessing but is no more than a wrapper around the threading module.</p>
</blockquote>
<p>So the answer could be written as:</p>
<pre><code>import multiprocessing.dummy as mp
p = mp.Pool(3) # With 3 being the number of threads.
p.map(Kill_Animal, AnimalsList)
p.close()
p.join()

[print(animal.isAlive) for animal in AnimalsList]
</code></pre>
<p>Output: False False False False False</p>
<h1>2. Using a <a href="https://docs.python.org/3/library/queue.html" rel="nofollow noreferrer">Queue</a>:</h1>
<pre><code>from queue import Queue
from threading import Thread

# Creates the hunter thread.
def hunter():
    while True:
        animal = q.get()
        Kill_Animal(animal)
        q.task_done()

num_hunter_threads = 3
q = Queue()

#Initialize the threads
for i in range(num_hunter_threads):
    t = Thread(target=hunter)
    t.daemon = True
    t.start()

#Adds each animal in the list to the Queue.
for animal in AnimalsList:
    q.put(animal)

#Execute the jobs in the queue.
q.join()

[print(animal.isAlive) for animal in AnimalsList)
</code></pre>
<p>Output: False False False False False</p>
</div>
<span class="comment-copy"><code>multiprocessing</code> does not share state. It is literally multiple different python processes.</span>
<span class="comment-copy">@juanpa.arrivillaga I see. So what would be the correct way to do this, if I wanted to modify an instance of a class (not replace it) with multiprocessing?</span>
<span class="comment-copy">The ideal way is to refactor your code <i>not</i> to require shared state. I would read through the <a href="https://docs.python.org/3.7/library/multiprocessing.html#sharing-state-between-processes" rel="nofollow noreferrer">documentation</a> to see what options you do have for sharing state.</span>
<span class="comment-copy">@juanpa.arrivillaga Thank you. Yes, I have a class with a large number of modules for selenium web-parsing, and the serial execution works like a charm. I have been trying to add parallelism to it for improving the performance by running multiple browsers at once, but perhaps I've been looking at it through a wrong angle.</span>
<span class="comment-copy">You <i>can</i> share state across processes using various methods including multiprocessing's queues and managers, but as far as Selenium, you'll probably want to send job details to your processes and have them instantiate their own resources independently rather than attempting to pass objects around like this. Of course, be careful about this, since too many headless browsers is an easy way to invoke the ire of the OOM killer.</span>
