<div class="post-text" itemprop="text">
<p>I have a large collection of DAT files that need to be converted (eventually to a unique file type). The DAT's have a mixed amount of whitespace between fields, and the column headers are on different lines. Any advice?</p>
<pre class="lang-none prettyprint-override"><code>                    ALT_RAD
                                               ALT_RAD2
                 DIRECT        D_GLOBAL        U_GLOBAL          Zenith
Year Mn Dy Hr Mi        DIFFUSE2            D_IR            U_IR
2004  9  1  0  1    1.04   79.40   78.67  303.58   61.06  310.95  85.142
2004  9  1  0  2    0.71   74.36   73.91  303.80   57.82  310.92  85.171
2004  9  1  0  3    0.67   71.80   71.64  304.25   56.84  310.98  85.199
2004  9  1  0  4    0.75   74.35   74.83  304.21   59.68  310.89  85.227
</code></pre>
<p>I have a basic script:</p>
<pre><code>import sys
with open(sys.argv[1], r) as input_file:
    newLines = []
    for line in input_file:
            newLines.append(newLine)
</code></pre>
<p>Which I will certainly change to account for mixed whitespace, but I don't know how to work with the wonky column headers.</p>
<p>Eventually I want my headers to just be:</p>
<pre class="lang-none prettyprint-override"><code>Year Month Day Hour Minute Direct Diffuse2 D_Global D_IR U_Global U_IR Zenith
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Treat those header lines in the input file with all the disdain they deserve. (Or, in other words, read them and discard them.)</p>
<pre><code>headers='Year Month Day Hour Minute Direct Diffuse2 D_Global D_IR U_Global U_IR Zenith'
with open ( 'temp.dat') as input_file:
    with open ('temp_2.csv', 'w') as output_file:
        output_file.write('"%s"\n'%'","'.join(headers.split()))
        for count, line in enumerate(input_file):
            if count&lt;4: continue
            outLine = ','.join(line.split())
            output_file.write(outLine + '\n')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is answer for "Python - download and convert .dat to .csv [duplicate]". I couldn't post there so FYI you can get you exact output from here.</p>
<pre><code>import urllib2
import csv
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'
response = urllib2.urlopen(url)
readData = response.read()
strObj = filter(None,readData.splitlines())

strObj = [w.replace('\t', '  ') for w in strObj]

listB = []
for i in strObj:
    listB.append(filter(None,i.split("  ")))
with open(r'c:/data2.csv','a') as f:
    writer = csv.writer(f)
    writer.writerows(listB)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It looks like you can combine the header rows dynamically based on a word's position in the line. You can skip the first two lines, and combine the next two. If you do it right, you will be left with an iterator over a file stream that you can use to process the remainder of the data as you wish. You can convert it to a different format, or even import it into a pandas DataFrame directly.</p>
<p>To get the headers:</p>
<pre><code>import re

def get_words_and_positions(line):
    return [(match.start(), match.group()) in re.finditer(r'[\w.]+', line)]

with open('file.dat') as file:
    iterator = iter(file)
    # Skip two lines
    next(iterator)
    next(iterator)
    # Get two header lines
    header = get_words_and_positions(next(iterator)) + \
             get_words_and_positions(next(iterator))
    # Sort by positon
    header.sort()
    # Extract words
    header = [word for pos, word in header]
</code></pre>
<p>You can now convert the file to a true CSV, or do something else with it. The important thing here is that you have <code>iterator</code> pointing to the actual data in the file stream, and a bunch of dynamically loaded column headers.</p>
<p>To write the remainder to a CSV file, without having to load the entire thing into memory at once, use <a href="https://docs.python.org/3/library/csv.html#csv.writer" rel="nofollow noreferrer"><code>csv.writer</code></a> and the iterator from above:</p>
<pre><code> import csv
 ...
 with ...:
 ...
    with open('outfile.csv', 'w') as output:
        writer = csv.writer(output)
        writer.writerow(header)
        for line in iterator:
            writer.writerow(re.split(r'\s+', line))
</code></pre>
<p>You can combine the nested output <code>with</code> and the outer input <code>with</code> into a single outer block to reduce the nesting levels:</p>
<pre><code>with open('file.dat') as file, open('outputfile.csv', 'w') as output:
    ....
</code></pre>
<p>To read in a pandas DataFrame, you can just pass the <code>file</code> object to <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" rel="nofollow noreferrer"><code>pandas.read_csv</code></a>. Since the file stream is past the headers at this point, it will not give you any issues:</p>
<pre><code>import pandas as pd
...
with ...:
    ...
    df = pd.read_csv(file, sep=r'\s'+, header=None, names=header)
</code></pre>
</div>
<span class="comment-copy">Is there are file format specification for DAT?</span>
<span class="comment-copy">Thank you Bill, super helpful. Can you explain 'output_file.write('"%s"\n'%'","'.join(headers.split()))' and the "for" loop body? Is "count" supposed to be going through each field?</span>
<span class="comment-copy"><b>'output_file.write('"%s"\n'%'","'.join(headers.split()))</b>   Takes the header words as supplied in your question as a string, splits the string on whitespaces, puts commas and double-quotes between the words, then double quotes at each end of that and write this out with a new line in the csv file.</span>
<span class="comment-copy">Other question: Notice the <b>enumerate</b>. This means that <b>count</b> starts with zero when the first line is read from input_file. Each time a line is read count is incremented. In other words, count is ... wait for it ... a count. It's the number of lines read. Since there are four header lines the <b>if</b> statement watches for count to be four or more before it allows the loop to proceed with line content processing.</span>
<span class="comment-copy">If not clear, please ask.</span>
<span class="comment-copy">You should probably stick that <code>urlopen</code> in a <code>with</code> block.</span>
<span class="comment-copy">You can combine the list comprehension and the <code>filter</code> into a single line: <code>strObj = [w.replace('\t', '  ') for w in readData.splitlines() if w]</code></span>
<span class="comment-copy">The main issue here is that you can A) use regex to get rid of most of these loops, and B) import directly into pandas if that is your end goal.</span>
<span class="comment-copy">#Thanks Mad Ph. Yeah! I shall use regex but sooner I post it for getting a result. As per R&amp;D code can be more optimized and I am also looking for it.</span>
