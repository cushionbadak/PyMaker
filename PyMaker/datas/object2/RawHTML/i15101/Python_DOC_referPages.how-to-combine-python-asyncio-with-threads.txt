<div class="post-text" itemprop="text">
<p>I have successfully built a <a href="https://github.com/fxstein/SentientHome/blob/develop/engine/event.engine.py" rel="noreferrer">RESTful microservice</a> with Python asyncio and aiohttp that listens to a POST event to collect realtime events from various feeders.</p>
<p>It then builds an in-memory structure to cache the last 24h of events in a nested defaultdict/deque structure.</p>
<p>Now I would like to periodically checkpoint that structure to disc, preferably using pickle.</p>
<p>Since the memory structure can be &gt;100MB I would like to avoid holding up my incoming event processing for the time it takes to checkpoint the structure.</p>
<p>I'd rather create a snapshot copy (e.g. deepcopy) of the structure and then take my time to write it to disk and repeat on a preset time interval.</p>
<p>I have been searching for examples on how to combine threads (and is a thread even the best solution for this?) and asyncio for that purpose but could not find something that would help me.</p>
<p>Any pointers to get started are much appreciated!</p>
</div>
<div class="post-text" itemprop="text">
<p>It's pretty simple to delegate a method to a thread or sub-process using <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor" rel="noreferrer"><code>BaseEventLoop.run_in_executor</code></a>:</p>
<pre><code>import asyncio
import time
from concurrent.futures import ProcessPoolExecutor

def cpu_bound_operation(x):
    time.sleep(x) # This is some operation that is CPU-bound

@asyncio.coroutine
def main():
    # Run cpu_bound_operation in the ProcessPoolExecutor
    # This will make your coroutine block, but won't block
    # the event loop; other coroutines can run in meantime.
    yield from loop.run_in_executor(p, cpu_bound_operation, 5)


loop = asyncio.get_event_loop()
p = ProcessPoolExecutor(2) # Create a ProcessPool with 2 processes
loop.run_until_complete(main())
</code></pre>
<p>As for whether to use a <code>ProcessPoolExecutor</code> or <code>ThreadPoolExecutor</code>, that's kind of hard to say; pickling a large object will definitely eat some CPU cycles, which initially would you make think <code>ProcessPoolExecutor</code> is the way to go. However, passing your 100MB object to a <code>Process</code> in the pool would require pickling the instance in your main process, sending the bytes to the child process via IPC, unpickling it in the child, and then pickling it <em>again</em> so you can write it to disk. Given that, my guess is the pickling/unpickling overhead will be large enough that you're better off using a <code>ThreadPoolExecutor</code>, even though you're going to take a performance hit because of the GIL.</p>
<p>That said, it's very simple to test both ways and find out for sure, so you might as well do that.</p>
</div>
<div class="post-text" itemprop="text">
<p>I also used <code>run_in_executor</code>, but I found this function kinda gross under most circumstances, since it requires <code>partial()</code> for keyword args and I'm never calling it with anything other than a single executor and the default event loop. So I made a convenience wrapper around it with sensible defaults and automatic keyword argument handling.</p>
<pre><code>from time import sleep
import asyncio as aio
loop = aio.get_event_loop()

class Executor:
    """In most cases, you can just use the 'execute' instance as a
    function, i.e. y = await execute(f, a, b, k=c) =&gt; run f(a, b, k=c) in
    the executor, assign result to y. The defaults can be changed, though,
    with your own instantiation of Executor, i.e. execute =
    Executor(nthreads=4)"""
    def __init__(self, loop=loop, nthreads=1):
        from concurrent.futures import ThreadPoolExecutor
        self._ex = ThreadPoolExecutor(nthreads)
        self._loop = loop
    def __call__(self, f, *args, **kw):
        from functools import partial
        return self._loop.run_in_executor(self._ex, partial(f, *args, **kw))
execute = Executor()

...

def cpu_bound_operation(t, alpha=30):
    sleep(t)
    return 20*alpha

async def main():
    y = await execute(cpu_bound_operation, 5, alpha=-2)

loop.run_until_complete(main())
</code></pre>
</div>
<span class="comment-copy">I have used dano's suggestions and built a very simple multi threaded setup that checkpoints the in-memory event store every 60 seconds to disk. Here is a link to the git repo file that contains the entire logic: <a href="https://github.com/fxstein/SentientHome/blob/master/engine/event.engine.py" rel="nofollow noreferrer">github.com/fxstein/SentientHome/blob/master/engine/â€¦</a></span>
<span class="comment-copy">Thank you dano! This was a lot easier after all. You are correct I took the path of using ThreadPoolExecutor and it works fine. Writing checkpoints ever 60 sec now without holding up any of the event processing.</span>
