<div class="post-text" itemprop="text">
<p>I have a matrix of size (61964, 25). Here is a sample:</p>
<pre><code>array([[  1.,   0.,   0.,   4.,   0.,   1.,   0.,   0.,   0.,   0.,   3.,
          0.,   2.,   1.,   0.,   0.,   3.,   0.,   3.,   0.,  14.,   0.,
          2.,   0.,   4.],
       [  0.,   0.,   0.,   1.,   2.,   0.,   0.,   0.,   0.,   0.,   1.,
          0.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   5.,   0.,
          0.,   0.,   1.]])
</code></pre>
<p>Scikit-learn provides a useful function provided that our data are normally distributed:</p>
<pre><code>from sklearn import preprocessing

X_2 = preprocessing.scale(X[:, :3])
</code></pre>
<p>My problem, however, is that I have to work on a row basis - which does not consist of 25 observations only - and so the normal distribution is not applicable here. The solution is to use t-distribution but how can I do that in Python?</p>
<p>Normally, values go from 0 to, say, 20. When I see unusually high numbers, I filter out the whole row. The following histogram shows what my actual distribution looks like:</p>
<p><img alt="enter image description here" src="https://i.stack.imgur.com/NujhC.png"/> </p>
</div>
<div class="post-text" itemprop="text">
<p><code>scipy.stats</code> has the function <a href="https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.stats.zscore.html#scipy.stats.zscore" rel="nofollow noreferrer"><code>zscore</code></a> which allows you to calculate how many standard deviations a value is above the mean (often refered to as the <em>standard score</em> or <em>Z score</em>).</p>
<p>If <code>arr</code> is the example array from your question, then you can compute the Z score across each row of 25 as follows:</p>
<pre><code>&gt;&gt;&gt; import scipy.stats as stats
&gt;&gt;&gt; stats.zscore(arr, axis=1)
array([[-0.18017365, -0.52666143, -0.52666143,  0.8592897 , -0.52666143,
        -0.18017365, -0.52666143, -0.52666143, -0.52666143, -0.52666143,
         0.51280192, -0.52666143,  0.16631414, -0.18017365, -0.52666143,
        -0.52666143,  0.51280192, -0.52666143,  0.51280192, -0.52666143,
         4.32416754, -0.52666143,  0.16631414, -0.52666143,  0.8592897 ],
       [-0.43643578, -0.43643578, -0.43643578,  0.47280543,  1.38204664,
        -0.43643578, -0.43643578, -0.43643578, -0.43643578, -0.43643578,
         0.47280543, -0.43643578,  1.38204664, -0.43643578, -0.43643578,
        -0.43643578, -0.43643578, -0.43643578, -0.43643578, -0.43643578,
         4.10977027, -0.43643578, -0.43643578, -0.43643578,  0.47280543]])
</code></pre>
<p>This calculation uses the population mean and standard deviation for each row. To use the sample variance instead (as with the t-statistic), additionally specify <code>ddof=1</code>:</p>
<pre><code>stats.zscore(arr, axis=1, ddof=1)
</code></pre>
</div>
<span class="comment-copy">Python 3.4 has a new module [statistics][1], which will do the trick for you:    [1]: <a href="https://docs.python.org/3/library/statistics.html" rel="nofollow noreferrer">docs.python.org/3/library/statistics.html</a></span>
<span class="comment-copy">Hi, thank you very much for your reply! I didn't know about this function! Btw, are you sure that I should you use <code>ddof=1</code>? Also, why do I get skewed results; in fact, on the positive side? Any ideas? Can it be because of the many zeros in the initial table? How can I avoid that?</span>
<span class="comment-copy">I also updated my original question, please have a look :)</span>
<span class="comment-copy">Only use <code>ddof=1</code> if you want to correct for the sample bias - <code>zscore</code> uses <code>ddof=0</code> by default (i.e. the population SD). Regarding your edit, I'm not sure I follow what you're trying to do in your edit... you want to filter out rows which have anomalously high values?</span>
