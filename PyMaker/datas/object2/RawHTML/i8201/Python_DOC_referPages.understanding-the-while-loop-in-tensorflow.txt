<div class="post-text" itemprop="text">
<p>I am using the <a href="https://www.tensorflow.org/api_docs/python/" rel="noreferrer">Python API for Tensorflow</a>. I am trying to implement the <a href="https://www.sfu.ca/~ssurjano/rosen.html" rel="noreferrer">Rosenbrock function</a> given below without the use of a Python loop:</p>
<p><a href="https://i.stack.imgur.com/9AdOH.png" rel="noreferrer"><img alt="Rosenbrock function" src="https://i.stack.imgur.com/9AdOH.png"/></a></p>
<p>My current implementation is as follows:</p>
<pre><code>def rosenbrock(data_tensor):
    columns = tf.unstack(data_tensor)

    summation = 0
    for i in range(1, len(columns) - 1):
        first_term = tf.square(tf.subtract(columns[i + 1], tf.square(columns[i])))
        second_term = tf.square(tf.subtract(columns[i], 1.0))
        summation += tf.add(tf.multiply(100.0, first_term), second_term)

    return summation
</code></pre>
<p>I have tried implementing the summation in a <a href="https://www.tensorflow.org/api_docs/python/tf/while_loop" rel="noreferrer"><code>tf.while_loop()</code></a>; however, I found the API somewhat unintuitive when it comes to using an index integer that is meant to remain separate from the data. The example given in the <a href="https://www.tensorflow.org/api_docs/python/tf/while_loop" rel="noreferrer">documentation</a> uses the data as the index (or vice-versa):</p>
<pre><code>i = tf.constant(0)
c = lambda i: tf.less(i, 10)
b = lambda i: tf.add(i, 1)
r = tf.while_loop(c, b, [i])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This can be achieved using the <code>tf.while_loop()</code> and standard <a href="https://docs.python.org/3/tutorial/datastructures.html#tuples-and-sequences" rel="noreferrer">tuples</a> as per the second example in the <a href="https://www.tensorflow.org/api_docs/python/tf/while_loop" rel="noreferrer">documentation</a>. </p>
<pre><code>def rosenbrock(data_tensor):
    columns = tf.unstack(data_tensor)

    # Track both the loop index and summation in a tuple in the form (index, summation)
    index_summation = (tf.constant(1), tf.constant(0.0))

    # The loop condition, note the loop condition is 'i &lt; n-1'
    def condition(index, summation):
        return tf.less(index, tf.subtract(tf.shape(columns)[0], 1))

    # The loop body, this will return a result tuple in the same form (index, summation)
    def body(index, summation):
        x_i = tf.gather(columns, index)
        x_ip1 = tf.gather(columns, tf.add(index, 1))

        first_term = tf.square(tf.subtract(x_ip1, tf.square(x_i)))
        second_term = tf.square(tf.subtract(x_i, 1.0))
        summand = tf.add(tf.multiply(100.0, first_term), second_term)

        return tf.add(index, 1), tf.add(summation, summand)

    # We do not care about the index value here, return only the summation
    return tf.while_loop(condition, body, index_summation)[1]
</code></pre>
<p>It is important to note that the index increment should occur in the body of the loop similar to a standard while loop. In the solution given, it is the first item in the tuple returned by the <code>body()</code> function. </p>
<p>Additionally, the loop condition function must allot a parameter for the summation although it is not used in this particular example.</p>
</div>
<span class="comment-copy">Is it appropriate to just use the for loop? What's the benefit of employing while_loop? Or is it necessary?</span>
<span class="comment-copy">In his code above, the for loop will execute python code. If we call the body of his for loop "f", then you can think of the python code as executing f,f,f,f,f,... f. So it will call that "body" function N times, and the graph of the function will thus have that function N times. If you use a tf.while_loop, then you will only see that function once in the graph.</span>
<span class="comment-copy">The advantage of the tf.while_loop is: 1) you can run iterations in parallel and 2) you can have runtime constants in your condition statements. For instance, if you wanted to run an optimizer until a certain tolerance is met, then you have to use the tf.while_loop variant because python cannot initially evaluate the condition</span>
<span class="comment-copy">@bremen_matt, If iterations have sequential dependencies then how parallel computation works?</span>
<span class="comment-copy">Check this out. I found it very helpful <a href="https://github.com/tensorflow/tensorflow/issues/1984" rel="nofollow noreferrer">github.com/tensorflow/tensorflow/issues/1984</a></span>
