<div class="post-text" itemprop="text">
<p>I made a simple test code that generates a lot of integers and writes them into a compressed file using the <a href="https://docs.python.org/3/library/gzip.html" rel="nofollow noreferrer">gzip</a> module.</p>
<pre><code>import gzip
for idx in range(100000):
    with gzip.open('output.gz', 'ab') as f:
        line = (str(idx) + '\n').encode()
        f.write(line)
</code></pre>
<p>The compressed file is created but when I decompress it, the raw data are actually a lot smaller:</p>
<pre><code>$ ls -l
  588890 output
 3288710 output.gz
</code></pre>
<p>Can you please explain what am I doing wrong here?</p>
</div>
<div class="post-text" itemprop="text">
<p>The assumption that append mode would append to the existing stream is wrong. Instead it concatenates a new stream to the existing gzip file. When decompressing these are then concatenated transparently as if you had compressed a single file. But each stream contains its own <a href="https://en.wikipedia.org/wiki/Gzip#File_format" rel="nofollow noreferrer">header and footer</a> and those add up. Inspecting your file reveals</p>
<pre><code> % hexdump -C output.gz|head -n5
00000000  1f 8b 08 08 2e e7 03 5b  02 ff 6f 75 74 70 75 74  |.......[..output|
00000010  00 33 e0 02 00 12 cd 4a  7e 02 00 00 00 1f 8b 08  |.3.....J~.......|
00000020  08 2e e7 03 5b 02 ff 6f  75 74 70 75 74 00 33 e4  |....[..output.3.|
00000030  02 00 53 fc 51 67 02 00  00 00 1f 8b 08 08 2e e7  |..S.Qg..........|
00000040  03 5b 02 ff 6f 75 74 70  75 74 00 33 e2 02 00 90  |.[..output.3....|
</code></pre>
<p>Note the repetition of the magic number <code>1f 8b</code>, which marks the beginning of a new stream.</p>
<p>In general it's usually a bad idea to repeatedly open a file in append mode in a loop. Instead open the file once for writing and write the contents in a loop:</p>
<pre><code>with gzip.open('output.gz', 'wb') as f:
    for idx in range(100000):
        line = (str(idx) + '\n').encode()
        f.write(line)
</code></pre>
<p>The resulting file is around 200 kiB, compared to the original 3 MiB.</p>
</div>
<span class="comment-copy">You're appending 100000 separate times to the gzip instead of zipping 100000 items. Swap the order of the with-statement and for-loop, which results in file size of 212863.</span>
<span class="comment-copy">@IljaEverilä How does that differ? I expected that every time I append into the compressed file, it decompresses, the data are appended and the result is compressed back again.</span>
<span class="comment-copy">It's more akin to concatenating 100000 separate gzip files together. Their headers etc. will start to count. Take your favourite hex-editor and have a look at the file's contents. You should be seeing a ton of "output" strings etc.</span>
<span class="comment-copy">@IljaEverilä As a funny sidenote: The compressed result is about 200 kB but when I compress the raw data manually using 7z or tar.xz method, the size reduces to about 17 kB. I should look for some better module than gzip.</span>
<span class="comment-copy">I had no idea that your and my code (a simple interchange of <code>with</code> and <code>for</code> statements) can result in a different output. Very interesting. Thank you for this deep explanation of what's actually happening behind the code.</span>
