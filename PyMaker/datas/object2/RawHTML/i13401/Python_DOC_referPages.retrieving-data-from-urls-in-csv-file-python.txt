<div class="post-text" itemprop="text">
<p>How do I modify this code to use the url list from the csv, go to those pages, and then execute the last section of the code to retrieve the correct data?<br/><br/>
I've got the feeling the code section that goes to the csv-stored links and retrieves data from them is way off, but I've got a csv with the urls I'm targeting listed one per row, and the last section of this code that targets the contact details etc is working correctly as well.</p>
<pre><code>import requests
import re
from bs4 import BeautifulSoup
import csv

#Read csv
csvfile = open("gymsfinal.csv")
csvfilelist = csvfile.read()

#Get data from each url
def get_page_data():
    for page_data in csvfilelist:
        r = requests.get(page_data.strip())
        soup = BeautifulSoup(r.text, 'html.parser')
        return soup

pages = get_page_data()
'''print pages'''

#The work performed on scraped data
print soup.find("span",{"class":"wlt_shortcode_TITLE"}).text
print soup.find("span",{"class":"wlt_shortcode_map_location"}).text
print soup.find("span",{"class":"wlt_shortcode_phoneNum"}).text
print soup.find("span",{"class":"wlt_shortcode_EMAIL"}).text

th = soup.find('b',text="Category")
td = th.findNext()
for link in td.findAll('a',href=True):
    match = re.search(r'http://(\w+).(\w+).(\w+)', link.text)
    if match:
        print link.text

gyms = [name,address,phoneNum,email]
gym_data_list.append(gyms)

#Saving specific listing data to csv
with open ("xgyms.csv", "wb") as file:
    writer = csv.writer(file)
    for row in gym_data_list:
        writer.writerow(row)
</code></pre>
<p>Snippet of gymsfinal.csv:</p>
<pre><code>http://www.gym-directory.com/listing/green-apple-wellness-centre/
http://www.gym-directory.com/listing/train-247-fitness-prahran/
http://www.gym-directory.com/listing/body-club/
http://www.gym-directory.com/listing/training-glen/
</code></pre>
<p>Changed to <code>writer.writerow([row])</code> in order to have csv data saved without commas between each letter.</p>
</div>
<div class="post-text" itemprop="text">
<p>There are a couple of issues here. First of all, you never close your first file object, which is a big no-no. You should be using the <code>with</code> syntax that you use towards the bottom of your code snippet for the reading of the csv as well. </p>
<p>You're getting the error <code>requests.exceptions.MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?</code> because when you read the csv in, you're just reading it in as one big string, complete with newlines. So when you iterate over it with <code>for page_data in csvfilelist:</code>, it's iterating through each character in the string (strings are iterable in Python). Obviously that isn't a valid url, so requests throws an exception. When you read your file in, it should look something like this</p>
<pre><code>with open('gymsfinal.csv') as f:
    reader = csv.reader(f)
    csvfilelist = [ row[0] for row in reader ]
</code></pre>
<p>You should also change how you return your url(s) from <code>get_page_data()</code>. Currently, you're only going to return the first soup. In order to make it return a generator of all the soups, all you need to do is change that <code>return</code> into a <code>yield</code>. <a href="https://www.jeffknupp.com/blog/2013/04/07/improve-your-python-yield-and-generators-explained/" rel="nofollow">Good resource on yield and generators</a>.</p>
<p>You're also going to have a problem with your print statments. they should either go inside a for loop that looks like <code>for soup in pages:</code> or they should go inside <code>get_page_data()</code>. There is no variable <code>soup</code> defined in the context of those prints.</p>
</div>
<span class="comment-copy">9th line should be <code>r = requests.get(page_data.strip())</code>. This assumes your file has one url per line. If it's actually a csv, better use the <a href="https://docs.python.org/3/library/csv.html" rel="nofollow noreferrer">csv module</a>.</span>
<span class="comment-copy">Post a snippet of gymsfinal.csv please?</span>
<span class="comment-copy">Made changes to the way csv is written, but still getting this:  <code>requests.exceptions.MissingSchema: Invalid URL 'h': No schema supplied. Perhaps you meant http://h?</code></span>
