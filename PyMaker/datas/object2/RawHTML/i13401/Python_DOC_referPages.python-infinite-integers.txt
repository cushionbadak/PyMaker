<div class="post-text" itemprop="text">
<p>Python 3 integers have <a href="https://docs.python.org/3/library/stdtypes.html#numeric-types-int-float-complex" rel="nofollow">unlimited precision</a>. In practice, this is limited by a computer's memory.</p>
<p>Consider the followng code:</p>
<pre><code>i = 12345
while True:
    i = i * 123
</code></pre>
<p>This will obviously fail. But what will be the result of this? The entire RAM (and the page file) filled with this one integer (except for the space occupied by other processes)?</p>
<p>Or is there a safeguard to catch this before it gets that far?</p>
</div>
<div class="post-text" itemprop="text">
<p>You could check what happens without risking to fill all available memory. You could <a href="https://stackoverflow.com/a/14024198/4279">set the memory limit explicitly</a>:</p>
<pre><code>#!/usr/bin/env python
import contextlib
import resource

@contextlib.contextmanager
def limit(limit, type=resource.RLIMIT_AS):
    soft_limit, hard_limit = resource.getrlimit(type)
    resource.setrlimit(type, (limit, hard_limit)) # set soft limit
    try:
        yield
    finally:
        resource.setrlimit(type, (soft_limit, hard_limit)) # restore

with limit(100 * (1 &lt;&lt; 20)): # 100MiB
    # do the thing that might try to consume all memory
    i = 1
    while True:
        i &lt;&lt;= 1
</code></pre>
<p>This code consumes 100% CPU (on a single core) and the consumed memory grows very very slowly.</p>
<p>In principle, you should get <code>MemoryError</code> at some point whether it happens before your computer turns to dust is unclear. <a href="https://github.com/python/cpython/blob/db2dc5e31cc8e309457d6dd0795b55acab79fbb4/Include/longintrepr.h#L74-L92" rel="nofollow noreferrer">CPython uses a continuous block of memory to store the digits</a> and therefore you may get the error even if there is RAM available but fragmented.</p>
<p>Your specific code shouldn't trigger it but in general you could also get <a href="https://github.com/python/cpython/blob/db2dc5e31cc8e309457d6dd0795b55acab79fbb4/Objects/longobject.c#L176-L203" rel="nofollow noreferrer"><code>OverflowError</code> if you try to construct an integer larger than <code>sys.maxsize</code> bytes</a>.</p>
</div>
<span class="comment-copy">You will hit a MemoryError</span>
<span class="comment-copy">So, most of RAM and pagefile will be overwritten?</span>
<span class="comment-copy">Depends on what the OS allows, and whether <code>i</code> started off as zero or not.</span>
<span class="comment-copy">A non-zero <code>i</code>. So how far do you think this will get before a typical Windows system considers the process a runaway and throws a MemoryError?</span>
<span class="comment-copy">@coding4fun Read this: <a href="http://effbot.org/pyfaq/why-doesnt-python-release-the-memory-when-i-delete-a-large-object.htm" rel="nofollow noreferrer">effbot.org/pyfaq/â€¦</a></span>
<span class="comment-copy">So, no spillage into pagefile then, because it would not be continuous.</span>
<span class="comment-copy">@coding4fun: python doesn't care where the memory comes from. Whether OS uses pagefile or not is completely transparent for python. It looks like the algorithm is too slow to fill the memory anyway.</span>
