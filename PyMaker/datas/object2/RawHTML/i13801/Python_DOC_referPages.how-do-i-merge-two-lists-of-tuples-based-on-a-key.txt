<div class="post-text" itemprop="text">
<p>I have two lists of tuples that I need to merge. This would be comparable to a JOIN in database terms. The order of the tuples in each list may change. The order of the items in the tuple will not change. The count of items in A should equal the count in B but there may be a difference.</p>
<p>Here are my two lists of tuples. There will be 10,000+ of these tuples in each list so performance is a concern. The first element in each tuple is the key common to each list.</p>
<pre><code>listA = [(u'123', u'a1', u'a2', 123, 789), (u'124', u'b1', u'b2', 456, 357), (u'125', u'c1', u'c2', 156, 852)]
listB = [(u'125', u'd1', u'N', u'd2', 1), (u'123', u'f1', u'Y', u'f2', 2)]
</code></pre>
<p>The desired output is:</p>
<pre><code>listC = [(u'123', u'a1', u'a2', 123, 789, u'f1', u'Y', u'f2', 2), (u'125', u'c1', u'c2', 156, 852, u'd1', u'N', u'd2', 1)]
</code></pre>
<p>Here's the code that I threw together for testing the concept. It works but as you can see, performance is an issue. The performance of this code when running with real data (10K items in each list) is unacceptable as it would take ,potentially, hours to complete.</p>
<p>Here's the code:</p>
<pre><code>for row in listA:
    for item in listB:
        if item[0] == row[0]:
            item = list(item)
            del item[0]
            row = list(row)
            merged.append(tuple(row + item))
</code></pre>
<p>How can I merge / join the two lists and achieve better performance?</p>
</div>
<div class="post-text" itemprop="text">
<p>Inner join two lists of tuples on the first (unique in each list) column using <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer"><code>itertools.groupby()</code></a> <a href="https://stackoverflow.com/questions/31887447/how-do-i-merge-two-lists-of-tuples-based-on-a-key#comment51692436_31887447">suggested by @CoryKramer in the comments</a>:</p>
<pre><code>from itertools import groupby
from operator import itemgetter

def inner_join(a, b):
    L = a + b
    L.sort(key=itemgetter(0)) # sort by the first column
    for _, group in groupby(L, itemgetter(0)):
        row_a, row_b = next(group), next(group, None)
        if row_b is not None: # join
            yield row_a + row_b[1:] # cut 1st column from 2nd row
</code></pre>
<p>Example:</p>
<pre><code>result = list(inner_join(listA, listB))
assert result == listC
</code></pre>
<p>This solution has <code>O(n*log n)</code> time complexity (your solution (in the question) is <code>O(n*n)</code> that is much worse for <code>n ~ 10000</code>).</p>
<p>It doesn't matter for a small <code>n</code> such as <code>10**4</code> in the question but in Python 3.5+ you could use <code>heapq.merge()</code> with <code>key</code> parameter to avoid allocating new list i.e., for <code>O(1)</code>  constant memory solution:</p>
<pre><code>from heapq import merge # merge has key parameter in Python 3.5

def inner_join(a, b):
    key = itemgetter(0)
    a.sort(key=key) 
    b.sort(key=key)
    for _, group in groupby(merge(a, b, key=key), key):
        row_a, row_b = next(group), next(group, None)
        if row_b is not None: # join
            yield row_a + row_b[1:] # cut 1st column from 2nd row
</code></pre>
<p>Here's a dict-based solution. It is <code>O(n)</code> linear in time and space algorithm:</p>
<pre><code>def inner_join(a, b):
    d = {}
    for row in b:
        d[row[0]] = row
    for row_a in a:
        row_b = d.get(row_a[0])
        if row_b is not None: # join
            yield row_a + row_b[1:]
</code></pre>
<p>Here's <a href="https://docs.python.org/2/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>collections.defaultdict</code></a>-based solution <a href="https://stackoverflow.com/a/31887486/4279">mentioned by @Padraic Cunningham</a></p>
<pre><code>from collections import defaultdict
from itertools import chain

def inner_join(a, b):
    d = defaultdict(list)
    for row in chain(a, b):
        d[row[0]].append(row[1:])
    for id, rows in d.iteritems():
        if len(rows) &gt; 1:
            assert len(rows) == 2
            yield (id,) + rows[0] + rows[1]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Have you used pandas before? This seems to give your desired output: </p>
<pre><code>n [41]:
import pandas as pd
listA = [(u'123', u'a1', u'a2', 123, 789), (u'124', u'b1', u'b2', 456, 357), (u'125', u'c1', u'c2', 156, 852)]
listB = [(u'125', u'd1', u'N', u'd2', 1), (u'123', u'f1', u'Y', u'f2', 2)]

A = pd.DataFrame(listA)
B = pd.DataFrame(listB)

A.merge(B, on=0)
Out[41]:
    0   1_x     2_x     3_x     4_x     1_y     2_y     3_y     4_y
0   123     a1  a2  123     789     f1  Y   f2  2
1   125     c1  c2  156     852     d1  N   d2  1
</code></pre>
<p>`A' and 'B' are pandas dataframes which have some of the SQL like functionality built into them, such as merge. If you haven't used pandas, let me know if you need further explanation. </p>
<p>See <a href="http://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging" rel="nofollow">Database-style DataFrame joining/merging</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can group by the first element using an OrderedDict, appending each tuple then only keep and join the tuples where the value list has a length &gt; 1:</p>
<pre><code>from itertools import chain
from collections import OrderedDict

od = OrderedDict()

for ele in chain(listA,listB):
    od.setdefault(ele[0], []).append(ele[1:])

print([(k,) + tuple(chain.from_iterable(v)) for k,v in od.iteritems() if len(v) &gt; 1])
</code></pre>
<p>Output:</p>
<pre><code>[('123', 'a1', 'a2', 123, 789, 'f1', 'Y', 'f2', 2), ('125', 'c1', 'c2', 156, 852, 'd1', 'N', 'd2', 1)]
</code></pre>
<p>If order does not matter a <code>collections.defaultdict</code> will be faster, either way this will be significantly faster than your own approach.</p>
<p>Or storing <code>itertools.islice</code> objects using a flag to find matched keys:</p>
<pre><code>from itertools import chain, islice
from collections import OrderedDict

od = OrderedDict()

for ele in chain(listA, listB):
    k = ele[0]
    if k in od:
        od[k]["v"].append(islice(ele, 1, None))
        od[k]["flag"] = True
    else:
        od.setdefault(k, {"flag": False, "v": []})["v"].append(islice(ele, 1, None))

print([(k,) + tuple(chain.from_iterable(v["v"])) for k, v in od.items() if v["flag"]])
</code></pre>
<p>Output:</p>
<pre><code>[('123', 'a1', 'a2', 123, 789, 'f1', 'Y', 'f2', 2), ('125', 'c1', 'c2', 156, 852, 'd1', 'N', 'd2', 1)]
</code></pre>
</div>
<span class="comment-copy">Look at <code>itertools.groupby</code> using a <code>lambda</code>. *Disclaimer the list must be sorted first.</span>
<span class="comment-copy">Why not use some other data structure like <code>dict of list</code></span>
<span class="comment-copy">The end results needs to be a list of tuples because that's what the destination application requires.</span>
<span class="comment-copy">Then covert <code>dict of list</code> to <code>list of tuples</code> as final operation would be more friendly in logic.</span>
<span class="comment-copy">The <code>heapq.merge</code> is neat, I did not see it before.</span>
<span class="comment-copy">why would the <code>merge</code> solution yield an <code>n^4</code> complexity?</span>
<span class="comment-copy">@njzk2: it doesn't. the merge is <code>O(n)</code>. You might be confused  by <code>10**4 == 10000</code> Python notation.</span>
<span class="comment-copy">side note: your <code>dict</code> solution ignores keys that are not in <code>b</code>.</span>
<span class="comment-copy">@njzk2: An inner join contains only those rows (identified by their keys) that are both in <code>a</code> and <code>b</code>. It must ignore <code>a</code> keys that are not in <code>b</code>.</span>
<span class="comment-copy">I have not used pandas. I'm not opposed to using it, just haven't. I'm new to python and noticed it's a packaged module.</span>
<span class="comment-copy">Sure. Since you mentioned database and SQL like operations in the question it might be worth looking into. Your list of tuples are essentially arrays and so maybe numpy and/or pandas would be the way to go, especially if performance is a concern. You can pandas through Anaconda which a free to download.</span>
<span class="comment-copy">I installed it but getting some errors. I need to look a little deeper.</span>
<span class="comment-copy">@DenaliHardtail: pandas is great for data analysis. You could <a href="http://pandas.pydata.org/pandas-docs/stable/install.html#trying-out-pandas-no-installation-required" rel="nofollow noreferrer">try it even without installation</a></span>
<span class="comment-copy">I've posted <a href="http://stackoverflow.com/a/31888214/4279"><code>defaultdict</code>-based solution</a></span>
