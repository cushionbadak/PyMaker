<div class="post-text" itemprop="text">
<p>Given 2 large arrays of 3D points (I'll call the first "source", and the second "destination"), I needed a function that would return indices from "destination" which matched elements of "source" as its closest, with this limitation: <strong>I can only use numpy</strong>... So no scipy, pandas, numexpr, cython...</p>
<p>To do this i wrote a function <a href="https://stackoverflow.com/questions/2486093/millions-of-3d-points-how-to-find-the-10-of-them-closest-to-a-given-point">based on the "brute force" answer to this question</a>. I iterate over elements of source, find the closest element from destination and return its index. Due to performance concerns, and again because i can only use numpy, I tried multithreading to speed it up. Here are both threaded and unthreaded functions and how they compare in speed on an 8 core machine.</p>
<pre><code>import timeit
import numpy as np
from numpy.core.umath_tests import inner1d
from multiprocessing.pool import ThreadPool

def threaded(sources, destinations):
    # Define worker function
    def worker(point):
        dlt = (destinations-point) # delta between destinations and given point
        d = inner1d(dlt,dlt) # get distances
        return np.argmin(d) # return closest index

    # Multithread!
    p = ThreadPool()
    return p.map(worker, sources)


def unthreaded(sources, destinations):
    results = []
    #for p in sources:
    for i in range(len(sources)):
        dlt = (destinations-sources[i]) # difference between destinations and given point
        d = inner1d(dlt,dlt) # get distances
        results.append(np.argmin(d)) # append closest index

    return results


# Setup the data
n_destinations = 10000 # 10k random destinations
n_sources = 10000      # 10k random sources
destinations= np.random.rand(n_destinations,3) * 100
sources = np.random.rand(n_sources,3) * 100

#Compare!
print 'threaded:   %s'%timeit.Timer(lambda: threaded(sources,destinations)).repeat(1,1)[0]
print 'unthreaded: %s'%timeit.Timer(lambda: unthreaded(sources,destinations)).repeat(1,1)[0]
</code></pre>
<p>Retults:</p>
<pre><code>threaded:   0.894030461056
unthreaded: 1.97295164054
</code></pre>
<p>Multithreading seems beneficial but I was hoping for more than 2X increase given the real life dataset i deal with are much larger.</p>
<p>All recommendations to improve performance (within the limitations described above) will be greatly appreciated! </p>
</div>
<div class="post-text" itemprop="text">
<p>Ok, I've been reading Maya documentation on python and I came to these conclusions/guesses:</p>
<ul>
<li>They're probably using CPython inside (several references to <strong>that</strong> documentation and not any other).</li>
<li>They're not fond of threads (lots of non-thread safe methods)</li>
</ul>
<p>Since the above, I'd say it's better to avoid threads. Because of the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">GIL problem</a>, this is a common problem and there are several ways to do the earlier.</p>
<ul>
<li>Try to build a tool <a href="https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#C.2FC.2B-.2B-" rel="nofollow">C/C++ extension</a>. Once that is done, use threads in C/C++. <strong>Personally</strong>, I'd only try SIP to work, and then move on.</li>
<li>Use <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow"><code>multiprocessing</code></a>. Even if your custom python distribution doesn't include it, you can get to a working version since it's all pure python code. <code>multiprocessing</code> is not affected by the GIL since it spawns separate processes.</li>
<li>The above should've worked out for you. If not, try another <a href="https://wiki.python.org/moin/ParallelProcessing" rel="nofollow">parallel tool</a> (after some serious praying).</li>
</ul>
<p>On a side note, if you're using outside modules, be most mindful of trying to match maya's version. This may have been the reason because you couldn't build <code>scipy</code>. Of course, <code>scipy</code> has a huge codebase and the windows platform is not the most resilient to build stuff.</p>
</div>
<span class="comment-copy">Before trying to add horsepower by means of multithreading, I would start with better algorithms... Currently your brute force approach is <code>O(N*M)</code>, while, after preparing a KD tree of the target points, you could make it <code>O(N*log(M))</code>.</span>
<span class="comment-copy">Why are you committed to using only numpy?</span>
<span class="comment-copy">@ali_m i have to use a custom build of python called mayapy, Autodesk's implementation of python inside their 3D software (Maya). It's compiled against VC2010 64bit, so pre-built binaries such as <a href="http://www.lfd.uci.edu/~gohlke/pythonlibs/" rel="nofollow noreferrer">Christoph Gohlke's</a> and others aren't compatible. I was able to build numpy from scratch but failed to build scipy, numexpr, etc.</span>
<span class="comment-copy">@MatteoItalia I did look for pure python KD tree implementations, notably i found <a href="https://github.com/storpipfugl/pykdtree" rel="nofollow noreferrer">this one</a> and <a href="https://code.google.com/p/python-kdtree/" rel="nofollow noreferrer">this one</a>. Both were vastly slower (like 10x) than my unthreaded numpy test. So i'm afraid that without access to scipy (as stated above) KD trees are a dead end.</span>
<span class="comment-copy">Just for reference, on my puny dual core laptop <code>cKDTree</code> takes about 17ms to both construct the tree <i>and</i> query it using your example data, compared with 1.53s for <code>threaded</code> and 1.39s for <code>unthreaded</code>. I am absolutely convinced that k-D trees are worth pursuing. I'm very surprised that you saw such slow query times for <code>pykdtree</code>, which seems to be implemented in C/Cython.</span>
<span class="comment-copy">Yeah it's very annoying. Because it seems there's no way to imrpove performance by staying purely in numpy, I may end up pickeling the data out and have an external "standard" python instance running (with scipy and all its arsenal)  to crunch it down and spit out the result. Not what i want but at this time i need to move on.</span>
