<div class="post-text" itemprop="text">
<p>I have a list of numbers as described below (Elements):</p>
<pre><code>Elements = [['1','5'], ['2','5'], ['3','5'], ['4','5'], ['5', '5'], ['6', '5'], ['7', '5'], ['8', '5'], ['9', '5'], ['10', '5']]
</code></pre>
<p>I want to call a function <code>main(x1,y1)</code> using process where <code>x1=records[0]</code>, <code>y1=records[1]</code> for records in <code>Elements</code>.
I would like to call <code>main()</code> with say 10 processes to work simultaneously on first 10 records from <code>Elements</code>. Once it is finished, call next 10 records from Elements and do the same and repeat until all the records are processed by main(). I am new to python so it would be great if anyone could help me with this.</p>
<p>Here's my code-</p>
<pre><code>def main(x1,y1):
  do something
  do something

import multiprocessing as mp
output = mp.Queue()

processes = [mp.Process(target=main, args=(records[0], records[1], output)) for records in Elements]

# Run processes
for p in processes:
    p.start()

# Exit the completed processes
for p in processes:
    p.join()

# Get process results from the output queue
results = [output.get() for p in processes]

print(results)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can do something like this with <a href="https://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.pool" rel="nofollow">Pool</a>:</p>
<pre><code>from multiprocessing import Pool

PROCESS_COUNT = 10

elements = [['1','5'], ['2','5'], ['3','5'], ['4','5'], ['5', '5'], ['6', '5'], ['7', '5'], ['8', '5'], ['9', '5'], ['10', '5']]

def main(element):
    # let's say you want to have concatenations as the results
    return element[0] + element[1]

pool = Pool(PROCESS_COUNT)
results = pool.map(main, elements)
pool.close()
pool.join()
# now results is a list of concatenations: ['15', '25', '35', '45', '55', '65', '75', '85', '95', '105']
</code></pre>
</div>
<span class="comment-copy">Theoretically multiprocessing elements of a list could run faster if there is a lot of processing to do for each element, but a problem is that a Python list is not implemented for concurrent access as far as I know - and it would be heavily advertised if it did.  Therefore it would be useful to first split the list into smaller, seperate lists and process them concurrently.  The threadpool executor class makes concurrent processing easy, see <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">docs.python.org/3/library/concurrent.futures.html</a>.</span>
