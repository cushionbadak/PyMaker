<div class="post-text" itemprop="text">
<p>I'm working on a python code where I need to evaluate a 2D spline at an arbitrary set of points many times. The code looks like this:</p>
<pre class="lang-py prettyprint-override"><code>spline = scipy.interpolate.RectBivariateSpline(...)
for i in range(1000000):
    x_points, y_points = data.get_output_points(i)
    vals = spline.ev(x_points, y_points)
    """ do stuff with vals """
</code></pre>
<p>There is no overlap of the output points. I would like to parallelize this using threads or some kind of shared memory since <code>data.get_output_points</code> uses a lot of memory. Naively, I tried spawning 10 threads and giving them each 1/10 of that loop. However, this doesn't give me any speed-up over running with a single thread.</p>
<p>I profiled the code, and it is spending all of its time in <code>fitpack2.py:674(\__call__)</code>, which is the <code>_BivariateSplineBase</code> evaluation function. It seems like I'm running into some GIL issue which is preventing the threads from running independently.</p>
<p>How can I get around the GIL issue and parallelize this? Is there a way to call into the <code>fitpack</code> routines that will parallelize well, or a different spline that I could use? My input grid is uniform and oversampled, but my output points can be anywhere. I have tried using <code>RegularGridInterpolator</code> (linear interpolation) which has good enough, although not ideal, performance, but it parallelizes poorly using threads.</p>
<p>EDIT: Here is what I mean by naive thread parallelization:</p>
<pre class="lang-py prettyprint-override"><code>def worker(start, end):
    for i in range(start, end):
        x_points, y_points = data.get_output_points(i)
        vals = spline.ev(x_points, y_points)
        """ do stuff with vals """

t1 = threading.Thread(target=worker, args=(0, 500000)).start()
t2 = threading.Thread(target=worker, args=(500001, 1000000)).start()
t1.join()
t2.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>There are multiple ways to process in parallel in python avoiding the GIL:</p>
<ul>
<li><a href="http://www.stackless.com/" rel="nofollow">Stackless python</a></li>
<li><a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow">multiprocessing</a></li>
<li><a href="http://zeromq.org/" rel="nofollow">Ã˜mq</a></li>
</ul>
<p>See <a href="https://wiki.python.org/moin/ParallelProcessing" rel="nofollow">here</a> for more</p>
<p>And yes, you <strong>are</strong> hitting the GIL neckbottle.</p>
</div>
<span class="comment-copy">Could you show us <i>how</i> you parallelized that code?</span>
<span class="comment-copy">Sure, I added an example. I am just splitting up the for loop among different threads.</span>
<span class="comment-copy">Yes, you're right. I looked into this a bunch more, and the dfitpack code never disables the GIL, so it isn't possible to do what I was hoping to do with threads. I'm not sure why it holds on to the GIL when going into the fortran code, but it's probably just because nobody has spent the time to figure out what can disable the GIL and what can't. I'm going to restructure everything to use multiprocessing.</span>
