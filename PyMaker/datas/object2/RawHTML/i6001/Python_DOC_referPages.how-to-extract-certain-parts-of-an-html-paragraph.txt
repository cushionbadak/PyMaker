<div class="post-text" itemprop="text">
<p>I am new to webscraping and regular expressions and facing a problem here. One of my code gives me an output in HTML but I need to extract a certain part out of the paragraph and not the complete paragraph. I Need help with this. Below is my code.</p>
<pre><code>import mechanize
from bs4 import BeautifulSoup
import urllib2
br = mechanize.Browser()
response = br.open("http://www.consultadni.info/index.php")
br.select_form(name="form1")
br['APE_PAT']='PATRICIO'
br['APE_MAT']='GAMARRA'
br['NOMBRES']='MARCELINA'
req=br.submit().read()
soup = BeautifulSoup(req, "lxml")
for link in soup.findAll("a"):
     sub=link.get("href")
     soup1 = BeautifulSoup(sub, "lxml")
     print soup1.find_all('p')
</code></pre>
<p>Output on screen: </p>
<pre><code>[&lt;p&gt;/&lt;/p&gt;]
[&lt;p&gt;datospersonales.php?nc=PATRICIO GAMARRA MARCELINA&amp;amp;dni1=40772568&amp;amp;dni2=12405868&amp;amp;id1=12a40a58a68&amp;amp;id2=30/06/1980&amp;amp;dni3=40631880&lt;/p&gt;]
[&lt;p&gt;datospersonales.php?nc=PATRICIO GAMARRA MARCELINA&amp;amp;dni1=40772568&amp;amp;dni2=12405868&amp;amp;id1=12a40a58a68&amp;amp;id2=30/06/1980&amp;amp;dni3=40631880&lt;/p&gt;]
[&lt;p&gt;http://www.infocorpperuconsultatusdeudas.blogspot.com/2015/05/infocorp-consulta-gratis-tu-reporte-de.html?ref=dnionline&lt;/p&gt;]
</code></pre>
<p>What I need: <code>30/06/1980</code> &amp; <code>40631880</code></p>
</div>
<div class="post-text" itemprop="text">
<p>For Python 2.7 try this way:</p>
<pre><code>from urlparse import parse_qs

result = set()

for link in soup.find_all("a"):
     sub = parse_qs(link.get("href"))

     if "id2" in sub:
         result.add((sub["id2"][0], sub["dni3"][0]))

print result
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Clean way to parse URLs (Python 3):</p>
<pre><code>from urllib import parse

URL = "datospersonales.php?nc=PATRICIO GAMARRA MARCELINA&amp;dni1=40772568&amp;dni2=12405868&amp;id1=12a40a58a68&amp;id2=30/06/1980&amp;dni3=40631880"

query_parts = parse.parse_qs(parse.urlparse(URL).query)

print(query_parts["id2"][0], query_parts["dni3"][0])
</code></pre>
</div>
<span class="comment-copy">Try to parse <code>sub</code> with <a href="https://docs.python.org/3/library/urllib.parse.html" rel="nofollow noreferrer"><code>urllib.parse.parse_qs</code></a> to get a dictionary of variables and values.</span>
<span class="comment-copy">ParseResult(scheme='', netloc='', path='tmp', params='', query='', fragment='') ParseResult(scheme='', netloc='', path='tmp', params='', query='', fragment='') ParseResult(scheme='', netloc='', path='tmp', params='', query='', fragment='')</span>
<span class="comment-copy">I am new to regex, so what should be the regex for this?</span>
<span class="comment-copy">Andre this Doesn't work either. I modified my code, getting error KeyError                                  Traceback (most recent call last) &lt;ipython-input-6-0de445ee89d6&gt; in &lt;module&gt;()      14 for link in soup.find_all("a"):      15      sub = parse_qs(link.get("href")) ---&gt; 16      print sub["id2"][0], sub["dni3"][0]  KeyError: 'id2'</span>
<span class="comment-copy">Ok. I modified the code adding a check. There may be some href without query.</span>
<span class="comment-copy">Ok, let me try this one</span>
<span class="comment-copy">Yo! this works, one last quick question, so the output gives me 2 repeated values (because that's how it comes in the browser as well) How can i omit the repeat value. Example: O/p is:  30/06/1980 40631880 30/06/1980 40631880 And I need just: 30/06/1980 40631880</span>
<span class="comment-copy">This worked :) I wish I could upvote this, being a new member it says votes with less than 15 reputations are not shown! Thanks!!!</span>
<span class="comment-copy">Ah, this doesn't work for me in python 2.7.14 :( I appreciate your help. A quick question, the URL is the 2nd paragraph in the o/p. How do we just print the 2nd paragraph and not the others?</span>
<span class="comment-copy">@Sandrachuz <code>find_all()</code> should return a regular Python list whose items can be accessed in the usual way.</span>
<span class="comment-copy">Check out <a href="https://docs.python.org/2/library/urlparse.html" rel="nofollow noreferrer">docs.python.org/2/library/urlparse.html</a> for python 2</span>
