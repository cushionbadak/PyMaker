<div class="post-text" itemprop="text">
<p>I am learning about python's multiprocessing module. I want to make my code use all my CPU resources. This is the code I wrote:</p>
<pre><code>from multiprocessing import Process
import time

def work():
   for i in range(1000):
      x=5
      y=10
      z=x+y

if __name__ == '__main__':
   start1 = time.time()
   for i in range(100):
      p=Process(target=work)
      p.start()
      p.join()
   end1=time.time()
   start = time.time()
   for i in range(100):
      work()
   end=time.time()
   print(f'With Parallel {end1-start1}')
   print(f'Without Parallel {end-start}')
</code></pre>
<p>The output I get is this:</p>
<pre><code> With Parallel 0.8802454471588135
 Without Parallel 0.00039649009704589844
</code></pre>
<p>I tried experimenting with different range values in the for loops or using print statement only in work function but everytime without parallel runs faster. Is there something I am missing?</p>
<p>Thanks in advance!</p>
</div>
<div class="post-text" itemprop="text">
<p>Your benchmark method is problematic:</p>
<pre><code>for i in range(100):
    p = Process(target=work)
    p.start()
    p.join()
</code></pre>
<p>I guess you want to run 100 processes in parallel, but <code>Process.join()</code> <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.join" rel="nofollow noreferrer">blocks until process exit</a>, you effectively run in serial. Besides, run more busy processes than CPU cores count leads to high CPU contention which is a performance penalty. And as a comment pointed out, your <code>work()</code> function is too simple, compare to the overhead of <code>Process</code> creation.</p>
<p>A better version:</p>
<pre><code>import multiprocessing
import time


def work():
    for i in range(2000000):
        pow(i, 10)

n_processes = multiprocessing.cpu_count() # 8
total_runs = n_processes * 4
ps = []
n = total_runs

start1 = time.time()
while n:
    # ensure processes number limit
    ps = [p for p in ps if p.is_alive()]
    if len(ps) &lt; n_processes:
        p = multiprocessing.Process(target=work)
        p.start()
        ps.append(p)
        n = n-1
    else:
        time.sleep(0.01)
# wait for all processes to finish
while any(p.is_alive() for p in ps):
    time.sleep(0.01)
end1=time.time()

start = time.time()
for i in range(total_runs):
    work()
end=time.time()

print(f'With Parallel {end1-start1:.4f}s')
print(f'Without Parallel {end-start:.4f}s')
print(f'Acceleration factor {(end-start)/(end1-start1):.2f}')
</code></pre>
<p>result:</p>
<pre><code>With Parallel 4.2835s
Without Parallel 33.0244s
Acceleration factor 7.71
</code></pre>
</div>
<span class="comment-copy">the <code>work()</code> function is too simple to be representative. In your case you just have a case when there's an overhead caused by instantiation of <code>Process</code> objects and their functioning</span>
<span class="comment-copy">any feedback, please?</span>
