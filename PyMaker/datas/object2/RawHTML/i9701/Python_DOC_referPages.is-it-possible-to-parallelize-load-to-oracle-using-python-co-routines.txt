<div class="post-text" itemprop="text">
<p>I used <code>threading</code> module to open multiple <code>sqlloader</code> sessions and it worked fine.
Having troubles achieving same degree of parallelism using <code>asyncio</code> module (coroutines).</p>
<p>This code always loads sequentially in Python 3.5:</p>
<pre><code>import asyncio

async def load_data(filename):

        loadConf=('sqlldr SKIP=%s %s userid=%s DATA=%s control=%s LOG=%s.log BAD=%s.bad DISCARD=/dev/null'  % (...)).split(' ')

        p = Popen(loadConf, stdin=PIPE, stdout=PIPE, stderr=STDOUT, shell=False, env=os.environ)
        output, err =  p.communicate(pwd.encode())  
        status=p.wait()

async def main():
    await asyncio.wait([load_data(file1),load_data(file2)])


if __name__ == "__main__":  
  loop = asyncio.get_event_loop()
  loop.run_until_complete(main())   
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Yes it is possible, but you have to use <a href="https://docs.python.org/3/library/asyncio-subprocess.html#create-a-subprocess-high-level-api-using-process" rel="nofollow noreferrer">asyncio.create_subprocess_shell</a> instead of <code>subprocess.Popen</code> since the latter doesn't know anything about the event loop and simply blocks inside your <code>load_data</code> until complete.
<a href="https://stackoverflow.com/questions/34020599/asynchronously-receive-output-from-long-running-shell-commands-with-asyncio-pyt/34027086#34027086">Here</a> is a relevant example.</p>
</div>
<span class="comment-copy">worked like a charm, thank you</span>
