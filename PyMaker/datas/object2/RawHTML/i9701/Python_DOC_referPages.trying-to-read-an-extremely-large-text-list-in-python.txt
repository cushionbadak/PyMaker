<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20">UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)</a>
<span class="question-originals-answer-count">
                    24 answers
                </span>
</li>
</ul>
</div>
<p>I'm currently trying to reduce a large list down in size by removing irrevelent data. I'm currently using</p>
<pre><code>with open("list.txt") as f_line:
    for line in f_line:
       Doing_things()
</code></pre>
<p>It is currently working with a smaller scale file but when the larger main file is used it gives the following error. </p>
<p>UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 3656: ordinal not in range(128) </p>
<p>Is there another way to read the list into python. Also the file has over 10000 single data points for the list.
Thanks for your help.</p>
</div>
<div class="post-text" itemprop="text">
<p>The cause is probably a 'misunderstanding' about the file encoding. Your python interpreter expects a textfile encoded as ascii, but in truth it's encoded as unicode or latin1. If it contains accented characters it's certainly not an ascii-file.</p>
<p>Which version of python do you use? Python 2 treats text differently than Python 3.</p>
<p>I generally use notepad++ to check which encoding is used in a text file if it's unclear.</p>
<p>Once you know which encoding is used you can specify it as mentioned  <a href="https://docs.python.org/3/howto/unicode.html#reading-and-writing-unicode-data" rel="nofollow noreferrer">here</a> like this <code>with open('list.txt', encoding='utf-8') as f_line:</code></p>
</div>
<span class="comment-copy">The size of the file is not the problem. The problem is, that you open the file as if it contains ASCII text and it doesn't.</span>
<span class="comment-copy">I don't think the problem is with the file size. I used this method for files large as 30 GB+ without a glitch. There might be a problem with the files themselves.</span>
<span class="comment-copy">First off "large" is a relative term. 10000 isn't a significant number. From what you've ported though, it appears that it's not related to the file size or memory but rather a problem with encoding. You should convert the lines to utf-8 first.</span>
<span class="comment-copy">@ettanay: A file object is iterable.</span>
<span class="comment-copy">For the error, it might not be caused by the file size, maybe because of some strange character at that line.</span>
<span class="comment-copy">Thanks its working now :) I was using Python 3 and I think it was getting confused trying to deal with emojis in the file.</span>
