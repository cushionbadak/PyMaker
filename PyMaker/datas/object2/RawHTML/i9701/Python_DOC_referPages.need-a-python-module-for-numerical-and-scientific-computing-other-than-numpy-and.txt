<div class="post-text" itemprop="text">
<p>Simple operations, such as rounding a number, creating an increasing vector, etc., can't be done reliably in python (see the examples below). The common explanation given by the python community is the floating point precision.</p>
<pre><code>Python 2.7.11 (default, Sep 29 2016, 13:33:00) 
[GCC 5.3.1 20160406 (Red Hat 5.3.1-6)] on linux2
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; import numpy
&gt;&gt;&gt; numpy.round(2.5)
2.0
&gt;&gt;&gt; numpy.round(3.5)
4.0
&gt;&gt;&gt; numpy.arange(89,90,0.1)
array([ 89. ,  89.1,  89.2,  89.3,  89.4,  89.5,  89.6,  89.7,  89.8,  89.9])
&gt;&gt;&gt; numpy.arange(89+0.1,90,0.1)
array([ 89.1,  89.2,  89.3,  89.4,  89.5,  89.6,  89.7,  89.8,  89.9,  90. ])
&gt;&gt;&gt; numpy.arange(19,20,0.1)
array([ 19. ,  19.1,  19.2,  19.3,  19.4,  19.5,  19.6,  19.7,  19.8,  19.9])
&gt;&gt;&gt; numpy.arange(19+0.1,20,0.1)
array([ 19.1,  19.2,  19.3,  19.4,  19.5,  19.6,  19.7,  19.8,  19.9])
&gt;&gt;&gt; 
</code></pre>
<p>However, there are existing tools, like Matlab and Octave, that do not suffer from such floating point precision phenomena (see the examples below). These tools also work on the binary architectures as python and are still capable of doing the real schoolbook math.</p>
<pre><code>&gt;&gt; round(2.5)
ans =  3
&gt;&gt; round(3.5)
ans =  4
&gt;&gt; [89:0.1:90]
ans =

   89.000   89.100   89.200   89.300   89.400   89.500   89.600   89.700   89.800   89.900   90.000

&gt;&gt; [89+0.1:0.1:90]
ans =

   89.100   89.200   89.300   89.400   89.500   89.600   89.700   89.800   89.900   90.000

&gt;&gt; [19:0.1:20]
ans =

   19.000   19.100   19.200   19.300   19.400   19.500   19.600   19.700   19.800   19.900   20.000

&gt;&gt; [19+0.1:0.1:20]
ans =

   19.100   19.200   19.300   19.400   19.500   19.600   19.700   19.800   19.900   20.000

&gt;&gt;
</code></pre>
<p>I have already written my own <code>round</code> operation for python. I'm about to write my own <code>range</code> operation for python, and who knows what else in the future...</p>
<p>My question is following:
<strong>Before I write the whole new math module for python, is there maybe such a module already existing?</strong>
(and I mean a module that is capable of doing the real trustworthy schoolbook math) </p>
</div>
<div class="post-text" itemprop="text">
<p>There is nothing unreliable about numpy's behavior in the examples you show as compared to MATLAB, nor do any of the examples you show have anything to do with floating-point issues (with one exception).</p>
<p>For the rounding behavior, MATLAB is the one doing it wrong here. Numpy is following the <a href="https://en.wikipedia.org/wiki/IEEE_754-1985#Rounding_floating-point_numbers" rel="nofollow noreferrer">IEEE standard</a> for rounding.  The standard calls for rounding to the nearest even number when the decimal value is <code>.5</code>.  There is a good reason for this: MATLAB's rounding behavior is statistically biased, producing more higher values than lower values for random numbers.  </p>
<p>For the <code>arange</code> function, Numpy is following the <a href="https://en.wikipedia.org/wiki/Interval_(mathematics)#Terminology" rel="nofollow noreferrer">half-open interval</a> convention, which excludes the last value in a range, while MATLAB is following the closed interval convention, which includes the last value.  Neither is right or wrong, and both have their advantages and disadvantages, but Numpy's behavior is in line with the vast majority of programming languages.</p>
<p>If you want to use closed intervals, you can use the <code>linspace</code> function, which lets you control whether to include the last value or not (it includes the last value by default).  If you really need to use the range function, it is easy to add one value on to the end, or create your own wrapper function that does it automatically.</p>
<p>As for floating-point issues, MATLAB and numpy are exactly the same.  Both use identical <a href="https://en.wikipedia.org/wiki/IEEE_floating_point" rel="nofollow noreferrer">IEEE-standard floating-point numbers</a> (except where MATLAB violates the standard's rounding rules).  Python, however, supports true <a href="https://docs.python.org/3/library/decimal.html" rel="nofollow noreferrer">decimal numbers</a> and <a href="https://docs.python.org/3/library/fractions.html" rel="nofollow noreferrer">fractions</a>, which MATLAB doesn't, so it is at least possible to avoid these issues in Python but not in MATLAB.</p>
<p>The only exception is this operation: <code>numpy.arange(89+0.1,90,0.1)</code>.  The result you show is indeed a floating-point issue.  As I said, floating-point issues like these present in both MATLAB and numpy.  This particular example was present in numpy but not MATLAB, but there are other examples that show up in MATLAB but not numpy.  </p>
<p>For ranges, numpy does the arithmetic very literally in this case: it adds the step size to the starting value, then adds it again to that value, and so on.  This means that these issues happen in a very predictable way.  MATLAB apparently tries to be more clever, but that means it fails in more obscure and hard-to-predict ways (I can't find documentation on exactly how MATLAB does this calculation).  For both MATLAB and numpy, you really should be using <code>linspace</code> for these sorts of ranges, as it doesn't have these sorts of issues.</p>
</div>
<div class="post-text" itemprop="text">
<p>There are a bunch of libraries out there:</p>
<ul>
<li><p>SAML (Simple Algebraic Math Library)</p></li>
<li><p>pymat</p></li>
<li><p>PYML</p></li>
</ul>
</div>
<span class="comment-copy">If you want rational arithmetic then see the fractions library.</span>
<span class="comment-copy">There's also a decimal library which looks like what you want but I've never used it.</span>
<span class="comment-copy">Regarding rounding, you say "The common explanation given by the python community is the floating point precision."  That's not the explanation for numpy's rounding behavior.  As the <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.around.html" rel="nofollow noreferrer">docstring for <code>numpy.around</code></a> (equivalent to <code>numpy.round</code>) explains, "For values exactly halfway between rounded decimal values, Numpy rounds to the nearest even value."</span>
<span class="comment-copy">Given the comments and answers I've read, it seems like the user assumed a different library and even language to act the same way... But the assumption did not hold up. In addition, rather than read the documentation for numpy round and numpy arange he declares them broken... When the reality is that their behavior does not match his assumed behavior.</span>
<span class="comment-copy">@BorisL.  Your problem is you assume "different from what I am used to" is the same as "wrong".  I have seen nearly an entire class fail a homework assignment because MATLAB's rounding behavior changed their random distributions.  Numpy wouldn't have had this problem because it chose a statistically superior rounding rule.</span>
<span class="comment-copy">There are lots of rules for rounding out there, not just one. IEEE implements most of them via its selectable rounding modes. The one rule that you are looking for is the one taught to school children. The one that IEEE and numpy default to is the one preferred by scientists, engineers, and statisticians.</span>
<span class="comment-copy">@BorisL. As I explained, there is a good reason for those rules.  It is considered a better approach overall because it is statistically unbiased.  Generally people dealing with random numbers don't want their <code>round</code> function changing the distribution of your numbers.  The rounding rule, which long predates the IEEE, is used because it avoids that problem.  See, for example, the wikipedia article on the subject: <a href="https://en.wikipedia.org/wiki/Rounding#Round_half_up" rel="nofollow noreferrer">en.wikipedia.org/wiki/Rounding#Round_half_up</a></span>
<span class="comment-copy">@BorisL. You can either calculate the number of steps or you can deal with the floating-point issues.  This is going to be the case on both numpy and MATLAB.  At least for numpy <code>linspace</code> keeps the endpoints and number of steps consistent, while <code>arange</code> (as best as possible) keeps the step size consistent.  In MATLAB, <code>linspace</code> keeps the endpoint and number of steps consistent, while ranges can do one or the other based on apparently undocumented rules.</span>
<span class="comment-copy">"The standard calls for rounding to the nearest even number when the decimal value is .5." &lt;- This is a bit of a stretch. The standard specifies rounding rules that are used to determine the final bit(s) of a significand in the case of a tie in the result of a floating-point operation. But that's not the same thing as specifying the behaviour for rounding a float to an integer. For that, IEEE 754-2008 specifies five separate functions (<code>roundToIntegralTiesToEven</code>, <code>roundToIntegralTiesToAway</code>, ...) and doesn't give any indication that any of these functions is preferred over the others.</span>
<span class="comment-copy">@MarkDickinson: section 4.3.3 of the current revision of the standard says "The roundTiesToEven rounding-direction attribute shall be the default rounding-direction attribute for results in binary formats."  So yes, it does say which function is preferred.</span>
