<div class="post-text" itemprop="text">
<p>I have such a code;</p>
<pre><code>import codecs, nltk

from nltk import *
from threading import Thread
#from textblob import TextBlob

def write_tags(file_name, corpus, no):
    print "Writing to tokens" + no + ".tr ..."
    target = open(file_name, "w")
    lencorpus = len(corpus)
    for d in range(lencorpus):
        text = word_tokenize(corpus[d].replace("\n", ""))
        line = ""
        for e in range(len(text)):
            line += text[e] + " "
        line = line[:-1] + "\n"
        target.write(line.encode("utf-8"))
    target.close()
    print "tokens" + no + ".tr is written ..."


def chunkIt(seq, num):
    avg = len(seq) / float(num)
    out = []
    last = 0.0

    while last &lt; len(seq):
            out.append(seq[int(last):int(last + avg)])
            last += avg

    return out

if __name__ == "__main__":

    print "Importing corpus ..."
    f = codecs.open("../corpus/corpus2.tr", encoding="utf-8").readlines()

    print "Splitting corpus to 32 parts ..."
    all_corpus = chunkIt(f, 32)

    print "Writing tags to file ..."
    thread_list = []
    for a in range(32):
        file_name = "../corpus/tokens" + str(a) + ".tr"
        thread = Thread(target=write_tags, args=(file_name, all_corpus[a], str(a)))
        thread_list.append(thread)

    for b in range(32):
        thread_list[b].start()

    for c in range(32):
        thread_list[c].join()

    print "Merging files ..."
    target = open("../corpus/tokens.tr", "w")
    for d in range(32):
        file_name = "../corpus/tokens" + str(d) + ".tr"
        f = codecs.open(file_name, encoding="utf-8").read()
        target.write(f.encode("utf-8"))
        print "tokens" + str(d)
    target.close()
</code></pre>
<p>Basically, I want to tokenize sentences from a given text file, which involves more than 37 M sentences. Since I use nltk library for tokenizing, it takes more than 1 day for me to finish the process.</p>
<p>For this reason, I have decided to do multithreading, so basically I split the given text file into 32 pieces, and process them parallely.</p>
<p>But it seems like multithreading doesn't change the speed. </p>
<p>Is my process slow because of I have used many cores in multithreading? May decreasing the number of cores lead to better performance? </p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>threading</code> module won't take advantage of multiple processing cores, it will only share time between threads in the same process on one core.  If you want to spread your processing over many cores (which most likely <em>will</em> reduce the total time your program takes to execute), the <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing package</a>  is what you want to use. </p>
</div>
