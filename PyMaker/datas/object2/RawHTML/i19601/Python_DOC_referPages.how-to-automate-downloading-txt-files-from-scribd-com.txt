<div class="post-text" itemprop="text">
<p>This is a general question about whether it is possible, and if so how, to automate the download of a scribd.com search result document.</p>
<p>Scenario:</p>
<p>I have a Scribd account and find a document I want. I normally I then have to click the download button to start the download. </p>
<p>Any ideas for automating this? I'm using the scribd api and python to automatically extract document IDs based on automated queries, but once I get the doc_id's I have to physically go to each doc page and click the download button to get the physical txt/pdf file. I want to automate this step as well.</p>
<p>Any Ideas?</p>
</div>
<div class="post-text" itemprop="text">
<p>Looking at the <a href="http://code.google.com/p/python-scribd/wiki/User" rel="nofollow"><code>python-scribd</code> documentation</a> or the <a href="http://www.scribd.com/developers/platform/api" rel="nofollow"><code>scribd</code> API reference</a>, any object that can give you a document ID or website URL can also give you a download URL. Or, if you already have a document ID, you can just call <code>get</code> to get an object that can give you a download URL.</p>
<p>Most likely, you've got a <a href="http://code.google.com/p/python-scribd/wiki/Document" rel="nofollow"><code>Document</code></a> object, which has this method:</p>
<blockquote>
<p><code>get_download_url</code>(self, doc_type='original') </p>
<p>Returns a link that can be used to download a static version of the document. </p>
</blockquote>
<p>So, wherever you're calling <code>get_scribd_url</code>, just call <code>get_download_url</code>.</p>
<p>And then, to download the result, Python has <a href="http://docs.python.org/2/library/urllib2.html" rel="nofollow"><code>urllib2</code></a> (2.x) or <a href="http://docs.python.org/3/library/urllib.request.html" rel="nofollow"><code>urllib.request</code></a> (3.x) built into the standard library, or you can use <a href="http://pypi.python.org/pypi/requests" rel="nofollow"><code>requests</code></a> or any other third-party library instead.</p>
<p>Putting it all together as an example:</p>
<pre><code># do all the stuff to set up the api_key, get a `User` object, etc.

def is_document_i_want(document):
    return document.author == "Me"

urls = [document.get_download_url() for document in user.all()
        if is_document_i_want(document)]

for url in urls:
    path = urllib.parse.urlparse(url).path
    name = os.path.basename(path)
    u = urllib.request.urlopen(url)
    with open(name, 'w') as f:
        f.write(u.read())
    print('Wrote {} as {}'.format(url, name))
</code></pre>
<p>Presumably you're going to want to use something like <code>user.find</code> instead of <code>user.all</code>. Or, if you've already written the code that gets the document IDs and don't want to change it, you can use <code>user.get</code> with each one.</p>
<p>And if you want to post-filter the results, you probably want to use attributes beyond the basic ones (or you would have just passed them to the query), which means you need to call <code>load</code> on each document before you can access them (so add <code>document.load()</code> at the top of the <code>is_document_i_want</code> function). But really, there's nothing complicated here.</p>
</div>
<span class="comment-copy">Look into <a href="http://pypi.python.org/pypi/requests/1.1.0" rel="nofollow noreferrer">requests</a> and <a href="http://wwwsearch.sourceforge.net/mechanize/" rel="nofollow noreferrer">mechanize</a></span>
<span class="comment-copy">Meanwhile, how do you "find a document I want"? You're going to need to be able to describe that algorithmically before you can possibly automate it, unless you've got a good "guess what TWhite wants" AI library.</span>
<span class="comment-copy">If you show the code that uses the scribd API to extract document IDs, it should be trivial to change it into code that extracts download URLs. But I'm not clear on how you would have written your code in the first place without immediately knowing the answer to your question (unless you didn't know how to find the docs, or call <code>help</code> from Python), soâ€¦ maybe you're doing different than what it sounds like? In that case, you definitely need to show us the code.</span>
<span class="comment-copy">I have the code that finds the documents I want using the API. I get a list of all docs with my query parameters. I wanted to then automatically download the results,which you helped with. :)</span>
<span class="comment-copy">@TWhite: If you'd <i>shown</i> the code (ideally a stripped-down minimal version), instead of just saying you have it, it would have been helpful. I'd know you have, e.g., a <code>Document</code>, instead of having to guess where you're starting from. But I'm glad you've got the answer now.</span>
<span class="comment-copy">That was the link I was missing thank you. I couldn't find the download url of the Document obj.</span>
