<div class="post-text" itemprop="text">
<p>I have been trying to implement a neural network in python that uses back propagation and keep getting the above error. How can I go about eliminating it. The code runs for one epoch without calculating the error in the system hence it is not able to back propagate the error across the network</p>
<pre><code>import numpy as np 

 X = [0.4, 0.7]
    y = [0.1]
    class Neural_Network(object):
      def __init__(self):
        #parameters
        self.inputSize = 2
        self.outputSize = 1
        self.hiddenSize = 2

        #weights
        self.W1 = [[0.1, 0.4],
                   [0.2, -0.2]]  # (2x2) weight matrix from input to hidden layer
        self.W2 = np.array([0.2, -0.5])[np.newaxis]  # (2x1) weight matrix from hidden to output layer


      def forward(self, X):
        #forward propagation through our network
        self.z = np.dot(X, self.W1) # dot product of X (input) and first set of 3x2 weights
        self.z2 = self.sigmoid(self.z) # activation function
        self.z3 = np.dot(self.z2, self.W2.T) # dot product of hidden layer (z2) and second set of 3x1 weights
        o = self.sigmoid(self.z3) # final activation function
        return o

      def sigmoid(self, s):
        # activation function
        return 1/(1+np.exp(-s))

      def sigmoidPrime(self, s):
        #derivative of sigmoid
        return s * (1 - s)

      def backward(self, X, y, o):
        # backward propgate through the network
        self.o_error = y - o # error in output
        self.o_delta = self.o_error*self.sigmoidPrime(o) # applying derivative of sigmoid to error

        self.z2_error = self.o_delta.dot(self.W2) # z2 error: how much our hidden layer weights contributed to output error
        self.z2_delta = self.z2_error*self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error

        self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --&gt; hidden) weights
        self.W2 += self.z2.T.dot(self.o_delta) # adjusting second set (hidden --&gt; output) weights

      def train (self, X, y):
        o = self.forward(X)
        self.backward(X, y, o)

    NN = Neural_Network()
    for i in xrange(1000): # trains the NN 1,000 times
      print "Input: \n" + str(X)
      print "Actual Output: \n" + str(y)
      print "Predicted Output: \n" + str(NN.forward(X))
      print "Loss: \n" + str(np.mean(np.square(y - NN.forward(X)))) # mean sum squared loss
      print "\n"
      NN.train(X, y)
</code></pre>
<p>The error I am getting is</p>
<pre><code>File "C:/Users/Aaa/AppData/Local/Temp/abc.py", line 43, in backward
    self.W1 += X.T.dot(self.z2_delta) # adjusting first set (input --&gt; hidden) weights
AttributeError: 'list' object has no attribute 'T'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The <code>X</code> you are using is a <a href="https://docs.python.org/3/tutorial/datastructures.html" rel="nofollow noreferrer"><code>list</code></a>. You should use a <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html" rel="nofollow noreferrer"><code>numpy.array</code></a>:</p>
<pre><code>X = np.array([0.4, 0.7])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><code>X</code> is a <code>list</code>. You can see that by typing <code>type(X)</code>. And lists do not have a transpose method. You want an array, so replace <code>X = [0.4, 0.7]</code>  with:</p>
<pre><code>X = np.array([0.4, 0.7])
</code></pre>
<p>Oh and btw.: A transpose of <code>X = np.array([0.4, 0.7])</code> will be the same as <code>X</code>:</p>
<pre><code>print(np.all(X.T == X))
# Out: True
</code></pre>
<p>This is true for all <code>X</code> with one dimension.</p>
</div>
<span class="comment-copy">The answers should also be applied to your <code>self.W1</code>, which now is also a list</span>
<span class="comment-copy">After using np.array I get another error but is seems to have solved the original error.---&gt;<code>self.z2_error = self.o_delta.dot(self.W2) # z2 error: how much our hidden layer weights contributed to output error ValueError: shapes (1,) and (2,) not aligned: 1 (dim 0) != 2 (dim 0)</code></span>
<span class="comment-copy">Error line? However you should consider asking another question. Questions should be on a single, limited thing.</span>
<span class="comment-copy">After using np.array I get another error but is seems to have solved the original error.---&gt;<code>self.z2_error = self.o_delta.dot(self.W2) # z2 error: how much our hidden layer weights contributed to output error ValueError: shapes (1,) and (2,) not aligned: 1 (dim 0) != 2 (dim 0)</code></span>
<span class="comment-copy">You should open a new question, since this is another error. As Luca pointed out,  a question should be on a single limited topic. Otherwise no one would help, because you never know when a question is solved.</span>
