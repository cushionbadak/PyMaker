<div class="post-text" itemprop="text">
<p>I have a machine learning application in Python. And I'm using the <code>multiprocessing</code> module in Python to parallelize some of the work (specifically feature computation).</p>
<p>Now, <code>multiprocessing</code> works differently on Unix variants, and Windows OS.<br/>
<code>Unix (mac/linux):</code>  fork/forkserver/spawn<br/>
<code>Windows:</code> spawn<br/>
<a href="https://stackoverflow.com/questions/38236211/why-multiprocessing-process-behave-differently-on-windows-and-linux-for-global-o">Why multiprocessing.Process behave differently on windows and linux for global object and function arguments</a></p>
<p>Because of <code>spawn</code> being used on Windows, the launch of multiprocessing processes is really slow. It loads all the modules from scratch for each process on Windows.</p>
<p>Is there a way to speed up the creation of the extra processes on Windows? (using threads instead of multiple processes is not an option)</p>
</div>
<div class="post-text" itemprop="text">
<p>Instead of creating multiple new processes each time, I highly suggest using <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor" rel="nofollow noreferrer">concurrent.futures <code>ProcessPoolExecutor</code></a> and leaving the executor open in the background.</p>
<p>That way, you don't create a new process each time, but rather leave them open in the background and pass some work using the module's functions or queues and pipes.</p>
<p>Bottom line - Don't create new processes each time. Leave them open and pass work.</p>
</div>
