<div class="post-text" itemprop="text">
<p>I have a block of code which takes a long time to execute and is CPU intense. I want to run that block several times and want to use the full power of my CPU for that. Looking at <code>asyncio</code> I understood that it is mainly for asynchronous communication, but is also a general tool for asynchronous tasks.</p>
<p>In the following example the <code>time.sleep(y)</code> is a placeholder for the code I want to run. In this example every co-routine is executed one after the other and the execution takes about 8 seconds.</p>
<pre><code>import asyncio
import logging
import time


async def _do_compute_intense_stuff(x, y, logger):
    logger.info('Getting it started...')
    for i in range(x):
        time.sleep(y)
    logger.info('Almost done')
    return x * y

logging.basicConfig(format='[%(name)s, %(levelname)s]: %(message)s', level='INFO')
logger = logging.getLogger(__name__)
loop = asyncio.get_event_loop()
co_routines = [
    asyncio.ensure_future(_do_compute_intense_stuff(2, 1, logger.getChild(str(i)))) for i in range(4)]
logger.info('Made the co-routines')
responses = loop.run_until_complete(asyncio.gather(*co_routines))
logger.info('Loop is done')
print(responses)
</code></pre>
<p>When I replace <code>time.sleep(y)</code> with <code>asyncio.sleep(y)</code> it returns nearly immediately. With <code>await asyncio.sleep(y)</code> it takes about 2 seconds.</p>
<p>Is there a way to parallelize my code using this approach or should I use <code>multiprocessing</code> or <code>threading</code>? Would I need to put the <code>time.sleep(y)</code> into a Thread?</p>
</div>
<div class="post-text" itemprop="text">
<p>Executors use multithreading to accomplish this (or mulitprocessing, if you prefer).  Asyncio is used to optimize code where you wait frequently for input, output operations to run. Sometimes that can be writing to files or loading websites.</p>
<p>However, with cpu heavy operations (that don't just rely on waiting for IO), it's recommended to use something akin to threads, and, in my opinion, <code>concurrent.futures</code> provides a very nice wrapper for that and it is similar to Asyncio's wrapper.</p>
<p>The reason why Asyncio.sleep would make your code run faster is because it starts the function and then starts checking coroutines. This doesn't simulate CPU-heavy operations.</p>
<p>To change the following example from multiprocessing to multi-threading Simply change <code>ProcessPoolExecutor</code> to <code>ThreadPoolExecutor</code>.</p>
<p>Here is a <strong>multiprocessing</strong> example:</p>
<pre><code>import concurrent.futures
import time

def a(z):
    time.sleep(1)
    return z*12

if __name__ == '__main__':
    with concurrent.futures.ProcessPoolExecutor(max_workers=5) as executor:
        futures = {executor.submit(a, i) for i in range(5)}
        for future in concurrent.futures.as_completed(futures):
            data = future.result()
            print(data)
</code></pre>
<p>This is a simplified version of the example provided in the <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">documentation for executors</a>.</p>
</div>
<span class="comment-copy">You don't use asyncio for that. Asyncio is great when you have a problem that <i>waits for I/O to happen</i>. Intense computation is not such a problem. Use multiprocessing instead. Only use threading if you are using some C-extension-backed library that'll release the GIL when doing heavy computations.</span>
<span class="comment-copy">Asyncio also requires all your code to <i>cooperate</i>. Each <code>await</code> is a place that your task tells the event loop that it is willing for other tasks to run if they are not waiting. <code>time.sleep()</code> is the very opposite of cooperating. It blocks everything, so the event loop can't switch tasks.</span>
<span class="comment-copy"><code>asyncio.sleep()</code> produces a coroutine. If you don't await on it, it'll not do anything, so yes, you'd see an instant return.</span>
<span class="comment-copy">Thanks @MartijnPieters that clears up some confusion!</span>
<span class="comment-copy">Thanks so far. It seems to work somehow. The functions are executed concurrently but not in parallel (I guess). When executing my function once it takes up a whole core and 20 seconds. When executing 2 functions it takes 1 minute and none of the cores goes to 100%. Any ideas?</span>
<span class="comment-copy">The processor won't go to 100% because you're on a single core. Use multiprocessing if you wish to full-load the cpu. Please keep in mind that you might want to -pre stage your data prior to starting the process, as communication between queues can sometimes be tricky when the second process is running.</span>
<span class="comment-copy">@Benjamin Updated the answer to use multiprocessing.</span>
<span class="comment-copy">Coming from Java where threads run on a core each this [<a href="https://stackoverflow.com/a/3046201/5119485](question)">stackoverflow.com/a/3046201/5119485](question)</a> has helped me understand the difference of processes and threads in Python. My actual code however didn't want to run in a process because I used classes there which could not be pickled. Since I don't have inter process communication I ditched the nice libs and just have a wrapper starting my script with <code>Popen</code> and reading back from stdout within a <code>ThreadPoolExecutor</code>.</span>
<span class="comment-copy">Since your answer addresses the asked question I will accept it.</span>
