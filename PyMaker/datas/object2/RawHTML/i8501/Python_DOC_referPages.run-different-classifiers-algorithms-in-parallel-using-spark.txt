<div class="post-text" itemprop="text">
<p>I have a dataset and I wanted to test different classifiers in parallel using Spark with Python.
For example, if I want to test a Decision Tree and a Random Forest, how could I run them in parallel?</p>
<p>I have tried a few approaches but I keep getting:</p>
<pre><code>cPickle.PicklingError: Can't pickle &lt;type 'function'&gt;: attribute lookup __builtin__.function failed
</code></pre>
<p>I was trying to do this (which had worked well using scikit-learn's classifiers instead of Spark's:</p>
<pre><code>def apply_classifier(clf, train_dataset, test_dataset):
    model = clf.fit(train_dataset)

    predictions = model.transform(test_dataset)

    evaluator = BinaryClassificationEvaluator()
    evaluator.evaluate(predictions)

    return [(model, predictions)]

...

dt = DecisionTreeClassifier(labelCol="indexedLabel", featuresCol="indexedFeatures", maxDepth=3)

rf = RandomForestClassifier(labelCol="indexedLabel", featuresCol="indexedFeatures")

classifiers = [dt, rf]

sc.parallelize(classifiers).flatMap(lambda x: apply_classifier(x, train_dataset, test_dataset)).collect() 
</code></pre>
<p>Any suggestions on how I can manage to do this?</p>
<p>Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>@larissa-leite</p>
<p>To overcome this, I'm using <code>[multiprocessing](https://docs.python.org/3/library/multiprocessing.html)</code> like explained in that <a href="https://stackoverflow.com/a/7207336/7024760">thread</a>.</p>
<p>This is the code of the thread:</p>
<p><div class="snippet" data-babel="false" data-console="true" data-hide="false" data-lang="js">
<div class="snippet-code">
<pre class="snippet-code-html lang-html prettyprint-override"><code>from multiprocessing import Process

def func1():
  print 'func1: starting'
  for i in xrange(10000000): pass
  print 'func1: finishing'

def func2():
  print 'func2: starting'
  for i in xrange(10000000): pass
  print 'func2: finishing'

if __name__ == '__main__':
  p1 = Process(target=func1)
  p1.start()
  p2 = Process(target=func2)
  p2.start()
  p1.join()
  p2.join()</code></pre>
</div>
</div>
</p>
<p>Just explain why I'm using this: I trained several text classifier models (more than 200) using <a href="https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html" rel="nofollow noreferrer">OneVsRestClassifier</a> and I need to span out every model the text that I receive. </p>
<p>The latency here it's less than 200ms to get all predictions to me (<a href="https://www.humanbenchmark.com/tests/reactiontime" rel="nofollow noreferrer">the baseline time reaction</a> for the human being can be something between 100ms to 420ms) so this 'latency' it's not a big deal for me. </p>
</div>
<span class="comment-copy">Multi-model evaluator is under development right now</span>
<span class="comment-copy">thank you for your answer @T.GawÄ™da so there's no way around it at the moment?</span>
<span class="comment-copy">I don't think so. Even if you will paralellize submitting the jobs, it still will be queued in cluster manager. But let's wait, maybe someone will have some tested workaround - I just pointed that it's not currently supported out of the box, but will be supported in near future :)</span>
