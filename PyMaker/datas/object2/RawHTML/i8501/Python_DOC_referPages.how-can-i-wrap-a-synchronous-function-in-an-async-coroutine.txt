<div class="post-text" itemprop="text">
<p>I'm using <a href="https://github.com/aio-libs/aiohttp" rel="noreferrer">aiohttp</a> to build an API server that sends TCP requests off to a seperate server. The module that sends the TCP requests is synchronous and a black box for my purposes. So my problem is that these requests are blocking the entire API. I need a way to wrap the module requests in an asynchronous coroutine that won't block the rest of the API.</p>
<p>So, just using <code>sleep</code> as a simple example, is there any way to somehow wrap time-consuming synchronous code in a non-blocking coroutine, something like this:</p>
<pre><code>async def sleep_async(delay):
    # After calling sleep, loop should be released until sleep is done
    yield sleep(delay)
    return 'I slept asynchronously'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Eventually I found an answer in <a href="https://stackoverflow.com/a/27298880">this thread</a>. The method I was looking for is <a href="https://docs.python.org/3/library/asyncio-eventloop.html" rel="noreferrer">run_in_executor</a>. This allows a synchronous function to be run asynchronously without blocking an event loop.</p>
<p>In the <code>sleep</code> example I posted above, it might look like this:</p>
<pre><code>import asyncio
from time import sleep
from concurrent.futures import ProcessPoolExecutor

async def sleep_async(loop, delay):
    # Can set executor to None if a default has been set for loop
    await loop.run_in_executor(ProcessPoolExecutor(), sleep, delay)
    return 'I slept asynchronously'
</code></pre>
<p>Also see the following answer -&gt; <a href="https://stackoverflow.com/questions/38557768/how-do-we-call-a-normal-function-where-a-coroutine-is-expected">How do we call a normal function where a coroutine is expected?</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You can use a decorator to wrap the sync version to an async version.</p>
<pre><code>import time
from functools import wraps, partial


def wrap(func):
    @wraps(func)
    async def run(*args, loop=None, executor=None, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
        pfunc = partial(func, *args, **kwargs)
        return await loop.run_in_executor(executor, pfunc)
    return run

@wrap
def sleep_async(delay):
    time.sleep(delay)
    return 'I slept asynchronously'
</code></pre>
<p>or use the <code>aioify</code> lib</p>
<pre><code>% pip install aioify
</code></pre>
<p>then</p>
<pre><code>@aioify
def sleep_async(delay):
    pass
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Not sure if too late but you can also use a decorator to do your function in a thread. ALTHOUGH, note that it will still be non-coop blocking unlike async which is co-op blocking.</p>
<pre><code>def wrap(func):
    from concurrent.futures import ThreadPoolExecutor
    pool=ThreadPoolExecutor()
    @wraps(func)
    async def run(*args, loop=None, executor=None, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
        future=pool.submit(func, *args, **kwargs)
        return asyncio.wrap_future(future)
    return run
</code></pre>
<p>Hope that helps!</p>
</div>
<span class="comment-copy">You always block on I/O. With cooperative multitasking you can't get desired behaviour, because blocked coroutine returns control (yield) only after request is finished.</span>
<span class="comment-copy">aiohttp is good for http. For non http TCP, asyncio is enough.</span>
<span class="comment-copy"><code>ProcessPoolExecutor</code> has a high cost because it launches an entire new python interpreter. It is used when you have a CPU-intensive task that needs to use multiple processors. Consider using <code>ThreadPoolExecutor</code> instead, which uses threading.</span>
<span class="comment-copy">Thank you for the additional info. Although the original example used process pool, <code>ThreadPoolExecutor</code> is what I ended up using after a little more research. Still seems a little jenky, but so far it's all holding together.</span>
<span class="comment-copy">Just a note, instead of creating a new executor, it might be simpler to use the default executor by calling <code>loop.run_in_executor(executor=None, func, *args)</code> (see <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.AbstractEventLoop.run_in_executor" rel="nofollow noreferrer">documentation</a>).</span>
<span class="comment-copy">good advise to use <code>aioify</code> it makes now so easy to write async functions and modules :)</span>
