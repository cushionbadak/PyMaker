<div class="post-text" itemprop="text">
<p>I am using an event based system using the new Python 3.5 coroutines and await. I register events and these events are called by the system.</p>
<pre><code>@event
aysnc def handleevent(args):
    # handle the event
</code></pre>
<p>I need to initialize some classes to handle the work(time consuming). Then call instance methods, also time consuming (they actually use selenium to browse certain sites).</p>
<p>Ideally I would want something like the following code</p>
<pre><code># supposedly since this is multiprocessing this is a different driver per process
driver = None
def init():
    # do the heavy initialization here
    global driver
    driver = webdriver.Chrome()

def longworkmethod():
    ## need to return some data
    return driver.dolongwork()

class Drivers:
""" A class to handle async and multiprocessing"""
    def __init__(self, numberOfDrivers):
        self.pool = multiprocessing.Pool(processes=numberOfDrivers, initializer=init)       

    async def dowork(self, args):
        return self.pool.apply_async(longworkmethod, args=args)


### my main python class
drivers = Drivers(5)

@event
aysnc def handleevent(args):
    await drivers.dowork(args)

@event
aysnc def quit(args):
    ## do cleanup on drivers
    sys.exit(0)
</code></pre>
<p>This code doesn't work, but I have tried many different ways and none seem to be able to do what I want. </p>
<p>It doesn't have to be this exact form, but how do I go about mixing the await and coroutines with a program that needs multiprocessing?</p>
</div>
<div class="post-text" itemprop="text">
<p>While there nothing technically speaking that would limit you from mixing <code>asyncio</code> and <code>multiprocessing</code>, I would suggest avoiding doing so. It's going to add a lot of complexity as you'll end up needing an event loop per thread and passing information back and forth will be tricky. Just use one or the other. </p>
<p><code>asyncio</code> supplies functions for running tasks in another thread - such as <a href="https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.AbstractEventLoop.run_in_executor" rel="nofollow noreferrer"><code>AbstractEventLoop.run_in_executor</code></a>. Take a look at these answers</p>
<ul>
<li><a href="https://stackoverflow.com/a/33025287/66349">https://stackoverflow.com/a/33025287/66349</a> (calling selenium within a coroutine)</li>
<li><a href="https://stackoverflow.com/a/28492261/66349">https://stackoverflow.com/a/28492261/66349</a> </li>
</ul>
<p>Alternatively you could just use <code>multiprocessing</code> as selenium has a blocking (non asyncio) interface, however it sounds like some of your code is using already using <code>asyncio</code> so maybe stick with the above.</p>
</div>
<span class="comment-copy">I can't avoid the mixing because I need selenium(multiprocessing), and the event system I'm using is strictly asyncio. But I'll check those links out. See if I can make them work.</span>
<span class="comment-copy">selenium is blocking but that doesn't mean you need multiprocessing. Just use <code>run_in_executor</code> for the blocking bits and keep everything else in the main thread/event loop.</span>
<span class="comment-copy">So those links seem to help. Should I be use run_in_executor for individual expensive calls like "get", or can I do large expensive functions with multiple expensive calls? Would there be a difference?</span>
<span class="comment-copy">@leftsync It depends on the structure of your calls. Can they all be run at once or do they need to be run in sequence? How many threads can you feasibly support? Is selenium thread safe?</span>
