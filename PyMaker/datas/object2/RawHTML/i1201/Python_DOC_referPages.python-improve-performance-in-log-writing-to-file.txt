<div class="post-text" itemprop="text">
<p>I am writing a piece of code that involves generation of new parameter values over a double FOR loop and store these values to a file. The loop iteration count can go as high as 10,000 * 100,000. I have stored the variable values in a string, which gets appended on every iteration with newer values. Finally, at the end of loop I write the complete string in a txt file.</p>
<pre><code>op=open("output file path","w+")
totresult = ""
for n seconds: #this user input parameter can be upto 100,000
    result = ""
    for car in (cars running): #number of cars can be 10000
        #Code to check if given car is in range to another car
        .
        .
        #if car in range with another car 
        if distance &lt; 1000:
            result = getDetailsofOtherCar()
            totresult = totalresult + carName + result
#end of loops
op.write(totresult)
op.close()
</code></pre>
<p>My question here is, is there a better pythonic way to perform this kind of logging. As I am guessing the string gets very bulky in the later iterations and may be causing delay in execution. Is the use of string the best possible option to store the values. Or should I consider other python data structures like list, array. I came across Logging python module but would like to get an opinion before switching to it.</p>
<p>I tried looking up for similar issues but found nothing similar to my current doubt.</p>
<p>Open to any suggestions</p>
<p>Thank you</p>
<p>Edit: code added</p>
</div>
<div class="post-text" itemprop="text">
<p>You can write to the file as you go e.g.</p>
<pre><code>with open("output.txt", "w") as log:
    for i in range(10):
        for j in range(10):
            log.write(str((i,j)))
</code></pre>
<p>Update: whether or not directly streaming the records is faster than concatenating them in a memory buffer depends crucially on how big the buffer becomes, which in turn depends on the number of records and the size of each record. On my machine this seems to kick in around 350MB.</p>
<p><a href="https://i.stack.imgur.com/gczsp.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/gczsp.png"/></a></p>
</div>
<span class="comment-copy">Eventually you should show your code if you want it optimised.</span>
<span class="comment-copy">code added. hope this makes sense. rather than a code-specific optimization I am looking for a general comment on the use of string as the better option to perform such operation.</span>
<span class="comment-copy">I don't think that there is a pythonic way. The normal approach would be to write a buffer and have a thread writing this buffer to memory. (If you want to optimize the I/O) Maybe this helps <a href="https://docs.python.org/3/howto/logging-cookbook.html" rel="nofollow noreferrer">docs.python.org/3/howto/logging-cookbook.html</a></span>
<span class="comment-copy">You should profile your code and see where it's spending the majority of its time. If you don't  you may be wasting your time speeding up something that won't make a difference. It could also surprise you. Anyway, it's easy to in Python: See <a href="https://stackoverflow.com/questions/582336/how-can-you-profile-a-python-script">How can you profile a Python script?</a></span>
<span class="comment-copy">I've read it's better to avoid string concatenation and instead build a list of string components and the <code>''.join()</code> them all together once at the end. That may do nothing to speed your program up however, since we don't know if that's a bottleneck or not.</span>
<span class="comment-copy">Multiple file I/O can be very time consuming. And in my case if above approach is used it will happen millions of times, which I will avoid doing.</span>
<span class="comment-copy">I don't think that this is faster.</span>
