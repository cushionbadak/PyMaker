<div class="post-text" itemprop="text">
<h3><strong>Objective and Motivation</strong></h3>
<p><code>eval</code> and <code>query</code> are powerful, but underrated functions in the pandas API suite, and their use is far from being fully documented or understood. With the right amount of care, <code>query</code> and <code>eval</code> can greatly simplify code, improve performance, and become a powerful tool for creating dynamic workflows.</p>
<p>The aim of this canonical QnA is to give users a better understanding of these functions, discussing some of the lesser known features, how they are used, and how best to use them, with clear and easy to understand examples. The two main topics this post will address are </p>
<ol>
<li>Understanding <code>engine</code>, <code>parser</code> and <code>target</code> arguments in <code>pd.eval</code>, and how they can be used to evaluate expressions</li>
<li>Understanding the difference between <code>pd.eval</code>, <code>df.eval</code> and <code>df.query</code>, and when each function is appropriate to use for dynamic execution.</li>
</ol>
<p>This post is not a substitute for the documentation (links in the answer), so please do go through that as well! </p>
<hr/>
<h3>Question</h3>
<p>I will frame a question in such a way that opens discussion for various features supported by <code>eval</code>.</p>
<p>Given two DataFrames </p>
<pre><code>np.random.seed(0)
df1 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))
df2 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))

df1
   A  B  C  D
0  5  0  3  3
1  7  9  3  5
2  2  4  7  6
3  8  8  1  6
4  7  7  8  1

df2
   A  B  C  D
0  5  9  8  9
1  4  3  0  3
2  5  0  2  3
3  8  1  3  3
4  3  7  0  1
</code></pre>
<p>I would like to perform arithmetic on one or more columns using <code>pd.eval</code>. Specifically, I would like to port the following code:</p>
<pre><code>x = 5
df2['D'] = df1['A'] + (df1['B'] * x) 
</code></pre>
<p>...to code using <code>eval</code>. The reason for using <code>eval</code> is that I would like to automate many workflows, so creating them dynamically will be useful to me.</p>
<p>I am trying to better understand the <code>engine</code> and <code>parser</code> arguments to determine how best to solve my problem. I have gone through the <a href="https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.eval.html" rel="noreferrer">documentation</a> but the difference was not made clear to me. </p>
<ol>
<li>What arguments should be used to ensure my code is working at max performance? </li>
<li>Is there a way to assign the result of the expression back to <code>df2</code>?</li>
<li>Also, to make things more complicated, how do I pass <code>x</code> as an argument inside the string expression? </li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>This answer dives into the various features and functionality offered by <a href="https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.eval.html" rel="noreferrer"><code>pd.eval</code></a>, <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.query.html" rel="noreferrer"><code>df.query</code></a>, and <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.eval.html" rel="noreferrer"><code>df.eval</code></a>.</p>
<p><strong>Setup</strong><br/>
Examples will involve these DataFrames (unless otherwise specified).  </p>
<pre><code>np.random.seed(0)
df1 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))
df2 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))
df3 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))
df4 = pd.DataFrame(np.random.choice(10, (5, 4)), columns=list('ABCD'))
</code></pre>
<hr/>
<h1><a href="https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.eval.html" rel="noreferrer"><code>pandas.eval</code></a> - The "Missing Manual"</h1>
<blockquote>
<p><strong>Note</strong><br/>
  Of the three functions being discussed, <code>pd.eval</code> is the most important. <code>df.eval</code> and <code>df.query</code> call
  <code>pd.eval</code> under the hood. Behaviour  and usage is more or less
  consistent across the three functions, with some minor semantic
  variations which will be highlighted later. This section will
  introduce functionality that is common across all the three functions - this includes, (but not limited to) <em>allowed syntax, precedence rules</em>, and <em>keyword arguments.</em></p>
</blockquote>
<p><code>pd.eval</code> can evaluate arithmetic expressions which can consist of variables and/or literals. These expressions must be passed as strings. So, <strong>to answer the question</strong> as stated, you can do</p>
<pre><code>x = 5
pd.eval("df1.A + (df1.B * x)")  
</code></pre>
<p>Some things to note here:</p>
<ol>
<li>The entire expression is a string</li>
<li><code>df1</code>, <code>df2</code>, and <code>x</code> refer to variables in the global namespace, these are picked up by <code>eval</code> when parsing the expression</li>
<li>Specific columns are accessed using the attribute accessor index. You can also use <code>"df1['A'] + (df1['B'] * x)"</code> to the same effect.</li>
</ol>
<p>I will be addressing the specific issue of reassignment in the section explaining the <code>target=...</code> attribute below. But for now, here are more simple examples of valid operations with <code>pd.eval</code>:</p>
<pre><code>pd.eval("df1.A + df2.A")   # Valid, returns a pd.Series object
pd.eval("abs(df1) ** .5")  # Valid, returns a pd.DataFrame object
</code></pre>
<p>...and so on. Conditional expressions are also supported in the same way. The statements below are all valid expressions and will be evaluated by the engine.</p>
<pre><code>pd.eval("df1 &gt; df2")        
pd.eval("df1 &gt; 5")    
pd.eval("df1 &lt; df2 and df3 &lt; df4")      
pd.eval("df1 in [1, 2, 3]")
pd.eval("1 &lt; 2 &lt; 3")
</code></pre>
<p>A list detailing all the supported features and syntax can be found in the <a href="https://pandas.pydata.org/pandas-docs/stable/enhancingperf.html#supported-syntax" rel="noreferrer">documentation</a>. In summary,</p>
<blockquote>
<ul>
<li>Arithmetic operations except for the left shift (<code>&lt;&lt;</code>) and right shift (<code>&gt;&gt;</code>) operators, e.g., <code>df + 2 * pi / s ** 4 % 42</code> - the_golden_ratio</li>
<li>Comparison operations, including chained comparisons, e.g., <code>2 &lt; df &lt; df2</code></li>
<li>Boolean operations, e.g., <code>df &lt; df2 and df3 &lt; df4</code> or <code>not df_bool</code>
<code>list</code> and <code>tuple</code> literals, e.g., <code>[1, 2]</code> or <code>(1, 2)</code></li>
<li>Attribute access, e.g., <code>df.a</code></li>
<li>Subscript expressions, e.g., <code>df[0]</code></li>
<li>Simple variable evaluation, e.g., <code>pd.eval('df')</code> (this is not very useful)</li>
<li>Math functions: sin, cos, exp, log, expm1, log1p, sqrt, sinh, cosh, tanh, arcsin, arccos, arctan, arccosh, arcsinh, arctanh, abs and
  arctan2.</li>
</ul>
</blockquote>
<p>This section of the documentation also specifies syntax rules that are not supported, including <code>set</code>/<code>dict</code> literals, if-else statements, loops, and comprehensions, and generator expressions.</p>
<p>From the list, it is obvious you can also pass expressions involving the index, such as</p>
<pre><code>pd.eval('df1.A * (df1.index &gt; 1)')
</code></pre>
<h3>Parser Selection: The <code>parser=...</code> argument</h3>
<p><code>pd.eval</code> supports two different parser options when parsing the expression string to generate the syntax tree: <code>pandas</code> and <code>python</code>. The main difference between the two is highlighted by slightly differing precedence rules.</p>
<p>Using the default parser <code>pandas</code>, the overloaded bitwise operators <code>&amp;</code> and <code>|</code> which implement vectorized AND and OR operations with pandas objects will have the same operator precedence as <code>and</code> and `or. So, </p>
<pre><code>pd.eval("(df1 &gt; df2) &amp; (df3 &lt; df4)")
</code></pre>
<p>Will be the same as </p>
<pre><code>pd.eval("df1 &gt; df2 &amp; df3 &lt; df4")
# pd.eval("df1 &gt; df2 &amp; df3 &lt; df4", parser='pandas')
</code></pre>
<p>And also the same as</p>
<pre><code>pd.eval("df1 &gt; df2 and df3 &lt; df4")
</code></pre>
<p>Here, the parentheses are necessary. To do this conventionally, the parens would be required to override the higher precedence of bitwise operators:</p>
<pre><code>(df1 &gt; df2) &amp; (df3 &lt; df4)
</code></pre>
<p>Without that, we end up with</p>
<pre><code>df1 &gt; df2 &amp; df3 &lt; df4

ValueError: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().
</code></pre>
<p>Use <code>parser='python'</code> if you want to maintain consistency with python's actual operator precedence rules while evaluating the string.</p>
<pre><code>pd.eval("(df1 &gt; df2) &amp; (df3 &lt; df4)", parser='python')
</code></pre>
<p>The other difference between the two types of parsers are the semantics of the <code>==</code> and <code>!=</code> operators with list and tuple nodes, which have the similar semantics as <code>in</code> and <code>not in</code> respectively, when using the <code>'pandas'</code> parser. For example,</p>
<pre><code>pd.eval("df1 == [1, 2, 3]")
</code></pre>
<p>Is valid, and will run with the same semantics as </p>
<pre><code>pd.eval("df1 in [1, 2, 3]")
</code></pre>
<p>OTOH, <code>pd.eval("df1 == [1, 2, 3]", parser='python')</code> will throw a <code>NotImplementedError</code> error.</p>
<h3>Backend Selection: The <code>engine=...</code> argument</h3>
<p>There are two options - <code>numexpr</code> (the default) and <code>python</code>. The <code>numexpr</code> option uses the <a href="https://github.com/pydata/numexpr" rel="noreferrer">numexpr</a> backend which is optimized for performance. </p>
<p>With <code>'python'</code> backend, your expression is evaluated similar to just passing the expression to python's <code>eval</code> function. You have the flexibility of doing more inside expressions, such as string operations, for instance.</p>
<pre><code>df = pd.DataFrame({'A': ['abc', 'def', 'abacus']})
pd.eval('df.A.str.contains("ab")', engine='python')

0     True
1    False
2     True
Name: A, dtype: bool
</code></pre>
<p>Unfortunately, this method offers <em>no</em> performance benefits over the <code>numexpr</code> engine, and there are very few security measures to ensure that dangerous expressions are not evaluated, so <strong>USE AT YOUR OWN RISK</strong>! It is generally not recommended to change this option to <code>'python'</code> unless you know what you're doing. </p>
<h3><code>local_dict</code> and <code>global_dict</code> arguments</h3>
<p>Sometimes, it is useful to supply values for variables used inside expressions, but not currently defined in your namespace. You can pass a dictionary to <code>local_dict</code></p>
<p>For example,</p>
<pre><code>pd.eval("df1 &gt; thresh")

UndefinedVariableError: name 'thresh' is not defined
</code></pre>
<p>This fails because <code>thresh</code> is not defined. However, this works:</p>
<pre><code>pd.eval("df1 &gt; x", local_dict={'thresh': 10})
</code></pre>
<p>This is useful when you have variables to supply from a dictionary. Alternatively, with the <code>'python'</code> engine, you could simply do this:</p>
<pre><code>mydict = {'thresh': 5}
# Dictionary values with *string* keys cannot be accessed without 
# using the 'python' engine.
pd.eval('df1 &gt; mydict["thresh"]', engine='python')
</code></pre>
<p>But this is going to possibly be <em>much</em> slower than using the <code>'numexpr'</code> engine and passing a dictionary to <code>local_dict</code> or <code>global_dict</code>. Hopefully, this should make a convincing argument for the use of these parameters.</p>
<h3>The <code>target</code> (+ <code>inplace</code>) argument, and Assignment Expressions</h3>
<p>This is not often a requirement because there are usually simpler ways of doing this, but you can assign the result of <code>pd.eval</code> to an object that implements <code>__getitem__</code> such as <code>dict</code>s, and (you guessed it) DataFrames. </p>
<p>Consider the example in the question </p>
<blockquote>
<pre><code>x = 5
df2['D'] = df1['A'] + (df1['B'] * x)
</code></pre>
</blockquote>
<p>To assign a column "D" to <code>df2</code>, we do </p>
<pre><code>pd.eval('D = df1.A + (df1.B * x)', target=df2)

   A  B  C   D
0  5  9  8   5
1  4  3  0  52
2  5  0  2  22
3  8  1  3  48
4  3  7  0  42
</code></pre>
<p>This is not an in-place modification of <code>df2</code> (but it can be... read on). Consider another example:</p>
<pre><code>pd.eval('df1.A + df2.A')

0    10
1    11
2     7
3    16
4    10
dtype: int32
</code></pre>
<p>If you wanted to (for example) assign this back to a DataFrame, you could use the <code>target</code> argument as follows:</p>
<pre><code>df = pd.DataFrame(columns=list('FBGH'), index=df1.index)
df
     F    B    G    H
0  NaN  NaN  NaN  NaN
1  NaN  NaN  NaN  NaN
2  NaN  NaN  NaN  NaN
3  NaN  NaN  NaN  NaN
4  NaN  NaN  NaN  NaN

df = pd.eval('B = df1.A + df2.A', target=df)
# Similar to 
# df = df.assign(B=pd.eval('df1.A + df2.A'))

df
     F   B    G    H
0  NaN  10  NaN  NaN
1  NaN  11  NaN  NaN
2  NaN   7  NaN  NaN
3  NaN  16  NaN  NaN
4  NaN  10  NaN  NaN
</code></pre>
<p>If you wanted to perform an in-place mutation on <code>df</code>, set <code>inplace=True</code>.</p>
<pre><code>pd.eval('B = df1.A + df2.A', target=df, inplace=True)
# Similar to 
# df['B'] = pd.eval('df1.A + df2.A')

df
     F   B    G    H
0  NaN  10  NaN  NaN
1  NaN  11  NaN  NaN
2  NaN   7  NaN  NaN
3  NaN  16  NaN  NaN
4  NaN  10  NaN  NaN
</code></pre>
<p>If <code>inplace</code> is set without a target, a <code>ValueError</code> is raised.</p>
<p>While the <code>target</code> argument is fun to play around with, you will seldom need to use it.</p>
<p>If you wanted to do this with <code>df.eval</code>, you would use an expression involving an assignment:</p>
<pre><code>df = df.eval("B = @df1.A + @df2.A")
# df.eval("B = @df1.A + @df2.A", inplace=True)
df

     F   B    G    H
0  NaN  10  NaN  NaN
1  NaN  11  NaN  NaN
2  NaN   7  NaN  NaN
3  NaN  16  NaN  NaN
4  NaN  10  NaN  NaN
</code></pre>
<p><strong>Note</strong><br/>
One of <code>pd.eval</code>'s unintended uses is parsing literal strings in a manner very similar to <code>ast.literal_eval</code>:</p>
<pre><code>pd.eval("[1, 2, 3]")
array([1, 2, 3], dtype=object)
</code></pre>
<p>It can also parse nested lists with the <code>'python'</code> engine:</p>
<pre><code>pd.eval("[[1, 2, 3], [4, 5], [10]]", engine='python')
[[1, 2, 3], [4, 5], [10]]
</code></pre>
<p>And lists of strings:</p>
<pre><code>pd.eval(["[1, 2, 3]", "[4, 5]", "[10]"], engine='python')
[[1, 2, 3], [4, 5], [10]]
</code></pre>
<p>The problem, however, is for lists with length larger than 10:</p>
<pre><code>pd.eval(["[1]"] * 100, engine='python') # Works
pd.eval(["[1]"] * 101, engine='python') 

AttributeError: 'PandasExprVisitor' object has no attribute 'visit_Ellipsis'
</code></pre>
<p>More information can this error, causes, fixes, and workarounds can be found <a href="https://stackoverflow.com/questions/48008191/attributeerror-pandasexprvisitor-object-has-no-attribute-visit-ellipsis-us">here</a>.</p>
<hr/>
<h1><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.eval.htm" rel="noreferrer"><code>DataFrame.eval</code></a> - A Juxtaposition with <code>pandas.eval</code></h1>
<p>As mentioned above, <code>df.eval</code> calls <code>pd.eval</code> under the hood. The <a href="https://github.com/pandas-dev/pandas/blob/0.23.x/pandas/core/frame.py#L2861-L2962" rel="noreferrer">v0.23 source code</a> shows this:</p>
<pre><code>def eval(self, expr, inplace=False, **kwargs):

    from pandas.core.computation.eval import eval as _eval

    inplace = validate_bool_kwarg(inplace, 'inplace')
    resolvers = kwargs.pop('resolvers', None)
    kwargs['level'] = kwargs.pop('level', 0) + 1
    if resolvers is None:
        index_resolvers = self._get_index_resolvers()
        resolvers = dict(self.iteritems()), index_resolvers
    if 'target' not in kwargs:
        kwargs['target'] = self
    kwargs['resolvers'] = kwargs.get('resolvers', ()) + tuple(resolvers)
    return <b>_eval(expr, inplace=inplace, **kwargs)</b></code></pre>
<p><code>eval</code> creates arguments, does a little validation, and passes the arguments on to <code>pd.eval</code>.</p>
<p>For more, you can read on: <a href="https://stackoverflow.com/questions/38725355/when-to-use-dataframe-eval-versus-pandas-eval-or-python-eval">when to use DataFrame.eval() versus pandas.eval() or python eval()</a></p>
<h2><strong>Usage Differences</strong></h2>
<h3><strong>Expressions with DataFrames v/s Series Expressions</strong></h3>
<p>For dynamic queries associated with entire DataFrames, you should prefer <code>pd.eval</code>. For example, there is no simple way to specify the equivalent of <code>pd.eval("df1 + df2")</code> when you call <code>df1.eval</code> or <code>df2.eval</code>.</p>
<h3><strong>Specifying Column Names</strong></h3>
<p>Another other major difference is how columns are accessed. For example, to add two columns "A" and "B" in <code>df1</code>, you would call <code>pd.eval</code> with the following expression:</p>
<pre><code>pd.eval("df1.A + df1.B")
</code></pre>
<p>With df.eval, you need only supply the column names:</p>
<pre><code>df1.eval("A + B")
</code></pre>
<p>Since, within the context of <code>df1</code>, it is clear that "A" and "B" refer to column names. </p>
<p>You can also refer to the index and columns using <code>index</code> (unless the index is named, in which case you would use the name). </p>
<pre><code>df1.eval("A + index")
</code></pre>
<p>Or, more generally, for any DataFrame with an index having 1 or more levels, you can refer to the k<sup>th</sup> level of the index in an expression using the variable <strong>"ilevel_k"</strong> which stands for "<b>i</b>ndex at <strong>level k</strong>". IOW, the expression above can be written as <code>df1.eval("A + ilevel_0")</code>.</p>
<p>These rules also apply to <code>query</code>.</p>
<h3><strong>Accessing Variables in Local/Global Namespace</strong></h3>
<p>Variables supplied inside expressions must be preceeded by the "@" symbol, to avoid confusion with column names.</p>
<pre><code>A = 5
df1.eval("A &gt; @A") 
</code></pre>
<p>The same goes for <code>query</code>/</p>
<p>It goes without saying that your column names must follow the rules for valid identifier naming in python to be accessible inside <code>eval</code>. See <a href="https://docs.python.org/3/reference/lexical_analysis.html#identifiers" rel="noreferrer">here</a> for a list of rules on naming identifiers.</p>
<h3><strong>Multiline Queries and Assignment</strong></h3>
<p>A little known fact is that <code>eval</code> support multiline expressions that deal with assignment. For example, to create two new columns "E" and "F" in df1 based on some arithmetic operations on some columns, and a third column "G" based on the previously created "E" and "F", we can do</p>
<pre><code>df1.eval("""
E = A + B
F = @df2.A + @df2.B
G = E &gt;= F
""")

   A  B  C  D   E   F      G
0  5  0  3  3   5  14  False
1  7  9  3  5  16   7   True
2  2  4  7  6   6   5   True
3  8  8  1  6  16   9   True
4  7  7  8  1  14  10   True
</code></pre>
<p>...Nifty! However, note that this is not supported by <code>query</code>.</p>
<hr/>
<h1><code>eval</code> v/s <code>query</code> - Final Word</h1>
<p>It helps to think of <code>df.query</code> as a function that uses <code>pd.eval</code> as a subroutine. </p>
<p>Typically, <code>query</code> (as the name suggests) is used to evaluate conditional expressions (i.e., expressions that result in True/False values) and return the rows corresponding to the <code>True</code> result. The result of the expression is then passed to <code>loc</code> (in most cases) to return the rows that satisfy the expression. According to the documentation,</p>
<blockquote>
<p>The result of the evaluation of this expression is first passed to
  <code>DataFrame.loc</code> and if that fails because of a multidimensional key
  (e.g., a DataFrame) then the result will be passed to
  <code>DataFrame.__getitem__()</code>.</p>
<p>This method uses the top-level <code>pandas.eval()</code> function to evaluate the
  passed query.</p>
</blockquote>
<p>In terms of similarity, <code>query</code> and <code>df.eval</code> are both alike in how they access column names and variables.</p>
<p>This key difference between the two, as mentioned above is how they handle the expression result. This becomes obvious when you actually run an expression through these two functions. For example, consider</p>
<pre><code>df1.A

0    5
1    7
2    2
3    8
4    7
Name: A, dtype: int32

df2.B

0    9
1    3
2    0
3    1
4    7
Name: B, dtype: int32
</code></pre>
<p>To get all rows where "A" &gt;= "B" in <code>df1</code>, we would use <code>eval</code> like this:</p>
<pre><code>m = df1.eval("A &gt;= B")
m
0     True
1    False
2    False
3     True
4     True
dtype: bool
</code></pre>
<p><code>m</code> represents the intermediate result generated by evaluating the expression "A &gt;= B". We then use the mask to filter <code>df1</code>:</p>
<pre><code>df1[m]
# df1.loc[m]

   A  B  C  D
0  5  0  3  3
3  8  8  1  6
4  7  7  8  1
</code></pre>
<p>However, with <code>query</code>, the intermediate result "m" is directly passed to <code>loc</code>, so with <code>query</code>, you would simply need to do </p>
<pre><code>df1.query("A &gt;= B")

   A  B  C  D
0  5  0  3  3
3  8  8  1  6
4  7  7  8  1
</code></pre>
<p>Performance wise, it is <em>exactly</em> the same. </p>
<pre><code>df1_big = pd.concat([df1] * 100000, ignore_index=True)

%timeit df1_big[df1_big.eval("A &gt;= B")]
%timeit df1_big.query("A &gt;= B")

14.7 ms ± 33.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
14.7 ms ± 24.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</code></pre>
<p>But the latter is more concise, and expresses the same operation in a single step. </p>
<p>Note that you can also do weird stuff with <code>query</code> like this (to, say, return all rows indexed by df1.index) </p>
<pre><code>df1.query("index")
# Same as df1.loc[df1.index] # Pointless,... I know

   A  B  C  D
0  5  0  3  3
1  7  9  3  5
2  2  4  7  6
3  8  8  1  6
4  7  7  8  1
</code></pre>
<p>But don't. </p>
<p>Bottom line: Please use <code>query</code> when querying or filtering rows based on a conditional expression.</p>
</div>
<div class="post-text" itemprop="text">
<p>Great tutorial already, but bear in mind that before jumping wildly into the usage of <code>eval/query</code> attracted by its simpler syntax, it has severe performance issues if your dataset has less than 15,000 rows.</p>
<p>In that case, simply use <code>df.loc[mask1, mask2]</code>.</p>
<p>Refer: <a href="https://pandas.pydata.org/pandas-docs/version/0.22/enhancingperf.html#enhancingperf-eval" rel="nofollow noreferrer">https://pandas.pydata.org/pandas-docs/version/0.22/enhancingperf.html#enhancingperf-eval</a></p>
<p><a href="https://i.stack.imgur.com/z4XMS.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/z4XMS.png"/></a></p>
</div>
<span class="comment-copy">I've upvoted both question &amp; answer, because I think this is useful original material. However, it would be even <i>more</i> useful as part of searchable official docs (which you can update via a pull request).</span>
<span class="comment-copy">Can you please write one of these for <code>pandas.MultiIndex</code>?</span>
<span class="comment-copy">@tel Sorry, I had to take down and repost because of a couple of issues. Final version of MultiIndex filtering canonical is <a href="https://stackoverflow.com/questions/53927460/how-do-i-slice-or-filter-mutliindex-dataframe-levels">here</a>. :-)</span>
<span class="comment-copy">Will you go deeper into performance seeing as it is one of the questions raised in the OP?</span>
<span class="comment-copy">@user3471881 I have not gone very deep into performance because it depends on every individual's use case, but I have made remarks about what backend and parser options are best suited to maximising performance in general.</span>
<span class="comment-copy">We already know from the documentation that <code>numexpr</code> generally gives us a speed up, I was just expecting some more indepth analysis of this because the first question in OP raises it specifically and says that it couldn't find the answer in the docs. An alternative would be to change the OP question a little bit to fit the answer?</span>
<span class="comment-copy">Or maybe analyse performance for at least three scenarios: data size, query complexity and assignment? Btw - goes without saying that I'm loving this post and really appreciate your work here and in the forum in general. Otherwise I wouldn't be asking about this :D</span>
<span class="comment-copy">@user3471881 Your point is valid and I will consider the best course of action. The easy way out for me would be to just remove the question on "performance" from the OP, but in the interest of doing justice to the post, let me dig a little deeper and see if I can address these points more appropriately. Thanks for the feedback, much appreciated :-)</span>
