<div class="post-text" itemprop="text">
<p>I have a pandas dataframe that has variable number of columns like C1, C2, C3, F1, F2... F100. I need combine F1, F2 .. F100 into one column of dict/map data type as follows. How can I do it using pandas? C1, C2, C3 are fixed name columns while F1, F2, F100 are variable.</p>
<p>Input:</p>
<pre><code>C1  C2  C3  F1  F2  F100

"1" "2" "3" "1" "2" "100"
</code></pre>
<p>Output:</p>
<pre><code>C1  C2  C3  Features

"1" "2" "3" {"F1":"1", "F2":"2", "F100": "100"}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you use pandas, you can use <code>df.apply()</code> function doing so.</p>
<p>Code would be like:</p>
<pre><code>def merge(row):
    result = {}
    for idx in row.index:
        if idx.startswith('F'):
            result[idx] = row[idx]
    print(result)
    return result

df['FEATURE'] = df.apply(lambda x: merge(x), axis=1)
</code></pre>
<p>Results:</p>
<pre><code>    C1  C2  C3  F1  F2  F100    FEATURE
0   1   2   3   1   2   100     {'F1': 1, 'F100': 100, 'F2': 2}
1   11  21  31  11  21  1001    {'F1': 11, 'F100': 1001, 'F2': 21}
2   12  22  32  2   22  2002    {'F1': 2, 'F100': 2002, 'F2': 22}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h3><code>filter</code> + <code>to_dict</code></h3>
<pre><code>df['Features'] = df.filter(like='F').to_dict('records')
</code></pre>
<h3>Output: <code>df</code></h3>
<pre><code>  C1 C2 C3 C4 F1 F2 F3 F4                                      Features
0  1  2  3  4  5  6  7  8  {'F1': '5', 'F2': '6', 'F3': '7', 'F4': '8'}
1  x  y  z  w  r  e  s  t  {'F1': 'r', 'F2': 'e', 'F3': 's', 'F4': 't'}
2  a  b  c  d  d  f  g  h  {'F1': 'd', 'F2': 'f', 'F3': 'g', 'F4': 'h'}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Consider the following example.</p>
<pre><code>d = pd.DataFrame([list('12345678'), list('xyzwrest'), list('abcddfgh')], columns = 'C1, C2, C3, C4, F1, F2, F3, F4'.split(', '))

d

&gt;&gt;&gt;    C1   C2  C3  C4  F1  F2  F3  F4
     0  1   2   3   4   5   6   7   8
     1  x   y   z   w   r   e   s   t
     2  a   b   c   d   d   f   g   h
</code></pre>
<p>Let us define the <code>Features</code> column as follows:</p>
<pre><code>d['Features'] = d.apply(lambda row: {feat: val for feat, val in row.items() if feat.startswith('F')}, axis =1)

#so that when we call d the results will be
d
&gt;&gt;&gt; C1  C2  C3  C4  F1  F2  F3  F4  Features
0   1   2   3   4   5   6   7   8   {'F1': '5', 'F2': '6', 'F3': '7', 'F4': '8'}
1   x   y   z   w   r   e   s   t   {'F1': 'r', 'F2': 'e', 'F3': 's', 'F4': 't'}
2   a   b   c   d   d   f   g   h   {'F1': 'd', 'F2': 'f', 'F3': 'g', 'F4': 'h'}
</code></pre>
<p>I hope this helps.</p>
</div>
<span class="comment-copy">So, <code>pyspark</code> or <code>pandas</code>?</span>
<span class="comment-copy">It is pandas, not pyspark</span>
<span class="comment-copy">You've already asked this question in pyspark and in spark-scala. Now it's pandas. What are you trying to do?</span>
<span class="comment-copy">Just a week later, I was asked to implement three versions of my scripts...</span>
<span class="comment-copy">It works for me! Is there any performance issue with a function if I am processing big data?</span>
<span class="comment-copy">Depends on how "big" your data is. Run the code and see the performance first.  You may use <code>timeit</code> method to evaluate.</span>
<span class="comment-copy">downvoted because your solution involves writing out the <code>n</code> columns <code>n</code> times, also it's not correct because only the <i>f</i> columns should be aggregated</span>
<span class="comment-copy">for the map columns, I need the original columns to the keys.</span>
<span class="comment-copy">@ChiCHEN  I updated the answer to address your worries. Let me know if you are helped by this edit.</span>
<span class="comment-copy">@aws_apprentice I updated my answer to address your worry.</span>
