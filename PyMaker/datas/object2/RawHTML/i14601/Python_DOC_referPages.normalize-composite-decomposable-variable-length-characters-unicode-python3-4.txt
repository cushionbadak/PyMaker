<div class="post-text" itemprop="text">
<p>I stumbled upon <a href="http://mortoray.com/2013/11/27/the-string-type-is-broken/" rel="nofollow noreferrer">http://mortoray.com/2013/11/27/the-string-type-is-broken/</a></p>
<p>And to my horror...</p>
<pre><code>print(len('noe\u0308l')) # returns 5 not 4
</code></pre>
<p>However I found
<a href="https://stackoverflow.com/a/14682498/1267259">https://stackoverflow.com/a/14682498/1267259</a>, 
<a href="https://stackoverflow.com/questions/16467479/normalizing-unicode">Normalizing Unicode</a></p>
<pre><code>from unicodedata import normalize
print(len(unicodedata.normalize('NFC','noe\u0308l'))) # returns 4
</code></pre>
<p>But what do I do with the SchrÃ¶dinger's cats?</p>
<pre><code>print(len('ðŸ˜¸ðŸ˜¾')) # returns 4 not 2
</code></pre>
<p>(side question: in my text editor when I'm trying to save I get a "utf-8 codec can't encode character x in position y: surrogates not allowed" but in the command prompt I can paste and run code with those characters, I assume it is because the cats exist on a different quantum level (SMP) but how do I normalize them?)</p>
<p>Is there anything else I should do to make sure all characters are counted as "1"?</p>
</div>
<div class="post-text" itemprop="text">
<p>Your editor is producing <a href="http://en.wikipedia.org/wiki/UTF-16#U.2B10000_to_U.2B10FFFF" rel="nofollow">surrogate pairs</a>, not the actual code points, which is why you are also getting that warning. Use:</p>
<pre><code>'\U0001f638\U0001f63e'
</code></pre>
<p>to define the cats without resorting to surrogates.</p>
<p>If you do have a string with surrogates, you can recode these via UTF-16 and allowing surrogates to be encoded with the <code>'surrogatepass'</code> error handler:</p>
<pre><code>&gt;&gt;&gt; # \U0001f638 is \ud83d\ude38 when using UTF-16 surrogates
...
&gt;&gt;&gt; '\ud83d\ude38'.encode('utf16', 'surrogatepass').decode('utf16')
'ðŸ˜¸'
&gt;&gt;&gt; len(_)
1
</code></pre>
<p>From the <a href="https://docs.python.org/3/library/codecs.html#error-handlers" rel="nofollow"><em>Error Handlers</em> documentation</a>:</p>
<blockquote>
<p><code>'surrogateescape'</code><br/>
  On decoding, replace byte with individual surrogate code ranging from <code>U+DC80</code> to <code>U+DCFF</code>. This code will then be turned back into the same byte when the <code>'surrogateescape'</code> error handler is used when encoding the data. (See <a href="https://www.python.org/dev/peps/pep-0383/" rel="nofollow">PEP 383</a> for more.)</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>For consistent codepoint counting on <em>any</em> version of Python, encode to UTF-32 and divide the byte count by 4.</p>
<pre><code>print(len(unicodedata.normalize('NFC','noe\u0308l').encode('utf-32le')) / 4)
print(len('\U0001f638\U0001f63e'.encode('utf-32le')) / 4)
</code></pre>
</div>
<span class="comment-copy">Which specific version of Python 3? Unicode processing has undergone a change or two.</span>
<span class="comment-copy">I'm using python 3.4.0.</span>
<span class="comment-copy">In hindsight, that was so obvious. I'm leaving my answer up in case it's useful to a passerby later.</span>
<span class="comment-copy">Thanks, that did take care of the error message, unfortunately no more cute cats... Although <code>len('\U0001f638\U0001f63e')</code> returns 2 now. But how do I ensure that actual code points are always used or surrogate pairs are never used? Do I need to "normalize" the string somehow? Do I have to do as Mark R suggested?</span>
<span class="comment-copy">@user1267259: what is your <i>normal</i> source of data input? If they are string literals in the source, I'd use <code>\Uhhhhhhhh</code> escape sequences, as it saves a lot of headaches with editors and encoding configurations. When reading from a file or network connection, use the right codec, you should not normally end up with surrogates in your Unicode string values, only in the encoded bytes (where they belong).</span>
<span class="comment-copy">Ahh, I see. My normal source are a bunch of text files. I've striped out non-Latin characters but had a feeling composite characters could cause problems so I googled until I found mentioned article. The variable-length characters were new to me, and in my panic I assumed they too could be considered "decomposed" somehow (given the result of the length). It didn't help that I copied and pasted those cats :) But if I understand you: as long as I load/encode those files correct there shouldn't be any problems with surrogates. I only need to unicodedata.normalize (sorry if I'm being redundant).</span>
<span class="comment-copy">@user1267259: entirely correct. :-)</span>
<span class="comment-copy">But the OP is using Python 3.4. This is not a polyglot issue.</span>
<span class="comment-copy">@MartijnPieters that information wasn't added until I left my answer. If you have a better one, go for it, because at this point I'm mystified.</span>
