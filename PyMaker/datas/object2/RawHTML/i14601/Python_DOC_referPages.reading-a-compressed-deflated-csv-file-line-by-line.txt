<div class="post-text" itemprop="text">
<div class="question-status question-originals-of-duplicate">
<p>This question already has an answer here:</p>
<ul>
<li>
<a dir="ltr" href="/questions/10566558/python-read-lines-from-compressed-text-files">python: read lines from compressed text files</a>
<span class="question-originals-answer-count">
                    3 answers
                </span>
</li>
</ul>
</div>
<p>I'm using the following generator to iterate through a given csv file row by row in a memory efficient way:</p>
<pre><code>def csvreader(file):
    with open(file, 'rb') as csvfile:
        reader = csv.reader(csvfile, delimiter=',',quotechar='"')
        for row in reader:
            yield row`
</code></pre>
<p>This works perfectly and I am able to handle very large files incredibly well. A CSV file of several gigabytes seems to be no problem at all for a small virtual machine instance with limited RAM.</p>
<p>However, when files grow too large, disk space becomes a problem. CSV files generally seem to get very high compression rates, which allows me to store the files at a fraction of their uncompressed size, but before I can use the above code to handle the file, I have to decompress/inflate the file and then run it through my script.</p>
<p>My question: Is there any way to build an efficient generator that does the above (given a file, yield CSV rows as an array), but does so by inflating parts of the file, up till a newline is reached, and then running that through the csv reader, without ever having to deflate/decompress the file as a whole? </p>
<p>Thanks very much for your consideration!</p>
</div>
<div class="post-text" itemprop="text">
<p>Try using <a href="https://docs.python.org/3/library/gzip.html" rel="nofollow noreferrer">gzip</a></p>
<p>Just replace <code>with open(file, 'rb') as csvfile:</code> with <code>with gzip.open(file, 'rb') as csvfile:</code> and add <code>import gzip</code> at the top of your script.</p>
<p>See <a href="https://stackoverflow.com/questions/10566558/python-read-lines-from-compressed-text-files">this SO question for more</a></p>
</div>
<div class="post-text" itemprop="text">
<p>If you <code>from gzip import open</code>, you do not need to change your code at all!</p>
</div>
<span class="comment-copy">Ideally, I'd love to have a solution for the reverse as well. Given an array, encode it in a CSV compatible way, deflate and then append it to an existing file. Although I realise this might be harder to do, maybe there'd be some way to read the header of a compressed file and use that compression scheme to compress a given string?</span>
<span class="comment-copy">The best chance would be to open the file as a <code>GzipFile</code> ( <a href="https://docs.python.org/2/library/gzip.html" rel="nofollow noreferrer">docs.python.org/2/library/gzip.html</a> ) and test the memory consumption. Please note that compression has a large impact on file I/O.</span>
<span class="comment-copy">Cheers! I'll try this!</span>
