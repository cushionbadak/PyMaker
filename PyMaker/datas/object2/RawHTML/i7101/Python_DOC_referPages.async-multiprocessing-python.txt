<div class="post-text" itemprop="text">
<p>So I've read this nice article about asynch threads in python. Tough, the last one have some troubles with the <a href="http://www.dabeaz.com/GIL/" rel="nofollow noreferrer">GIL</a> and threads are not as effective as it may seems.</p>
<p>Luckily python incorporates Multiprocessing which are designed to be not affected by this trouble.</p>
<p>I'd like to understand how to implement a multiprocessing queue (with Pipe open for each process) in an async manner so it wouldn't hang a running <a href="http://aiohttp.readthedocs.io/en/stable/" rel="nofollow noreferrer">async webserver</a> .</p>
<p>I've read this <a href="https://stackoverflow.com/questions/32955846/in-python-is-there-an-async-equivalent-to-multiprocessing-or-concurrent-futures">topic</a> however I'm not looking for performance but rather boxing out a big calculation that hangs my webserver. Those calculations require pictures so they might have a significant i/o exchange but in my understanding this is something that is pretty well handled by async.</p>
<p>All the calcs are separate from each other so they are not meant to be mixed.</p>
<p>I'm trying to build this in front of a ws handler.</p>
<p>If you hint heresy in this please let me know as well :)</p>
</div>
<div class="post-text" itemprop="text">
<p><em>This is re-sourced from a article after someone nice on #python irc hinted me on async executors, and another answer on reddit :</em></p>
<p>(2) Using ProcessPoolExecutor
“The ProcessPoolExecutor class is an Executor subclass that uses a pool of processes to execute calls asynchronously. ProcessPoolExecutor uses the multiprocessing module, which allows it to side-step the Global Interpreter Lock but also means that only picklable objects can be executed and returned.”</p>
<pre><code>import asyncio
from concurrent.futures import ProcessPoolExecutor

def cpu_heavy(num):
    print('entering cpu_heavy', num)
    import time
    time.sleep(10)
    print('leaving cpu_heavy', num)
    return num

async def main(loop):
    print('entering main')
    executor = ProcessPoolExecutor(max_workers=3)
    data = await asyncio.gather(*(loop.run_in_executor(executor, cpu_heavy, num) 
                                  for num in range(3)))
    print('got result', data)
    print('leaving main')


loop = asyncio.get_event_loop()
loop.run_until_complete(main(loop))
</code></pre>
<p>And this from another nice guy on reddit ;)</p>
</div>
<span class="comment-copy">Is there a reason why you wouldn't be interested in python hreading module (<a href="https://docs.python.org/3/library/threading.html" rel="nofollow noreferrer">docs.python.org/3/library/threading.html</a>)?</span>
<span class="comment-copy">Yes, CPU threads have a tendency to lock the GIL which makes the hole infra slower. edit : explained here <a href="http://dabeaz.blogspot.fr/2010/02/revisiting-thread-priorities-and-new.html" rel="nofollow noreferrer">dabeaz.blogspot.fr/2010/02/…</a></span>
<span class="comment-copy">Someone nice on #python gave me hints about async executor ; After some research it seems the full answer is here <a href="https://pythonadventures.wordpress.com/tag/processpoolexecutor/" rel="nofollow noreferrer">pythonadventures.wordpress.com/tag/processpoolexecutor</a></span>
<span class="comment-copy">You can make it an answer and accept it so your thread get solved. ;)</span>
<span class="comment-copy">I also wanted to point to this question which might be better formulated and contains another "version" of the answer. <a href="https://stackoverflow.com/questions/27290656/should-i-use-two-asyncio-event-loops-in-one-program/27298880#27298880" title="should i use two asyncio event loops in one program">stackoverflow.com/questions/27290656/…</a> ; Difference being in one spawning spawning only one process at the time whereas another spawns bunch of them. So depending on yours needs you might want to use run_in_executor alone, or if you want to split out a calc, I guess you'll be using asyncio.gather as well</span>
