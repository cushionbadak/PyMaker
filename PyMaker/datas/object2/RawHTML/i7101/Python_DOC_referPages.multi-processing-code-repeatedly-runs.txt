<div class="post-text" itemprop="text">
<p>So I wish to create a process using the python multiprocessing module, I want it be part of a larger script. (I also want a lot of other things from it but right now I will settle for this)</p>
<p>I copied the most basic code from the <a href="https://docs.python.org/3.6/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing docs</a> and modified it slightly</p>
<p>However, <strong>everything</strong> outside of the <code>if __name__ == '__main__':</code> statement gets <strong>repeated</strong> every time p.join() is called.</p>
<p>This is my <strong>code</strong>:</p>
<pre><code>from multiprocessing import Process

data = 'The Data'
print(data)

# worker function definition
def f(p_num):
    print('Doing Process: {}'.format(p_num))

print('start of name == main ')

if __name__ == '__main__':
    print('Creating process')
    p = Process(target=f, args=(data,))
    print('Process made')
    p.start()
    print('process started')
    p.join()
    print('process joined')

print('script finished')
</code></pre>
<p>This is what I <strong>expected</strong>:</p>
<pre><code>The Data
start of name == main 
Creating process
Process made
process started
Doing Process: The Data
process joined
script finished

Process finished with exit code 0
</code></pre>
<p>This is the <strong>reality</strong>:</p>
<pre><code>The Data
start of name == main 
Creating process
Process made
process started
The Data                         &lt;- wrongly repeated line
start of name == main            &lt;- wrongly repeated line
script finished                  &lt;- wrongly executed early line
Doing Process: The Data
process joined
script finished

Process finished with exit code 0
</code></pre>
<p>I am not sure whether this is caused by the <code>if</code> statement or <code>p.join()</code> or something else and by extension <em>why this is happening</em>. Can some one please explain <strong>what</strong> caused this and <strong>why</strong>?</p>
<p>For clarity because some people cannot replicate my problem but I have; I am using Windows Server 2012 R2 Datacenter and I am using python 3.5.3. </p>
</div>
<div class="post-text" itemprop="text">
<p>The way <a href="https://docs.python.org/3/library/multiprocessing.html" rel="noreferrer">Multiprocessing</a> works in Python is such that each child process <em>imports</em> the parent script. In Python, when you import a script, everything not defined within a function is executed. As I understand it, <code>__name__</code> is changed on an import of the script (<a href="https://stackoverflow.com/questions/419163/what-does-if-name-main-do">Check this SO answer here for a better understanding</a>), which is different than if you ran the script on the command line directly, which would result in <code>__name__ == '__main__'</code>. This import results in <code>__name__</code> not equalling <code>'__main__'</code>, which is why the code in <code>if __name__ == '__main__':</code> is not executed for your subprocess.</p>
<p>Anything you don't want executed during subprocess calls should be moved into your <code>if __name__ == '__main__':</code> section of your code, as this will only run for the parent process, i.e. the script you run initially.</p>
<p>Hope this helps a bit. There are some more resources around Google that better explain this if you look around. I linked the official Python resource for the multiprocessing module, and I recommend you look through it.</p>
</div>
<div class="post-text" itemprop="text">
<p>Exploring the topic I run into an issue of multiple loads of modules. to make it work per above I had to:</p>
<ul>
<li>put all imports in a function (initializer())</li>
<li>return all imports as objects in the call to initializer() function</li>
<li>reference those objects in definition and calls to the remaining functions in my module</li>
</ul>
<p>the example module below runs multiple classification approaches on the same dataset in parallel:</p>
<pre><code>print("I am being run so often because: https://stackoverflow.com/questions/45591987/multi-processing-code-repeatedly-runs")

def initializer():
    from sklearn import datasets

    iris = datasets.load_iris()
    x = iris.data
    y = iris.target    

    from sklearn.preprocessing import StandardScaler as StandardScaler
    from sklearn.metrics import accuracy_score
    from sklearn.linear_model import Perceptron
    from sklearn.linear_model import LogisticRegression
    from sklearn.pipeline import Pipeline
    import multiprocessing as mp
    from multiprocessing import Manager

    results = [] # for some reason it needs to be defined before the if __name__ = __main__

    return x, y, StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline, mp, Manager, results

def perceptron(x,y,results, StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline):
    scaler = StandardScaler()
    estimator = ["Perceptron", Perceptron(n_iter=40, eta0=0.1, random_state=1)]

    pipe =  Pipeline([('Scaler', scaler),
                      ('Estimator', estimator[1])])

    pipe.fit(x,y)

    y_pred_pipe = pipe.predict(x)
    accuracy = accuracy_score(y, y_pred_pipe)
    result = [estimator[0], estimator[1], pipe, y_pred_pipe, accuracy]
    results.append(result)
    print(estimator[0], "Accuracy: ",accuracy)
    return results

def logistic(x,y,results,StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline):
    scaler = StandardScaler()
    estimator = ["LogisticRegression", LogisticRegression(C=100.0, random_state=1)]

    pipe =  Pipeline([('Scaler', scaler),
                      ('Estimator', estimator[1])])

    pipe.fit(x,y)

    y_pred_pipe = pipe.predict(x)
    accuracy = accuracy_score(y, y_pred_pipe)
    result = [estimator[0], estimator[1], pipe, y_pred_pipe, accuracy]
    #results = []
    results.append(result)
    print(estimator[0], "Accuracy: ",accuracy)
    return results

def parallel(x,y,results,StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline):
    with Manager() as manager:

        tasks = [perceptron, logistic,]
        results = manager.list() 
        procs = []
        for task in tasks:
            proc = mp.Process(name=task.__name__, target=task, args=(x,y,results,StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline))
            procs.append(proc)
            print("done with check 1")
            proc.start()
            print("done with check 2")

        for proc in procs:
            print("done with check 3")
            proc.join()
            print("done with check 4")

        results = list(results)
        print("Within WITH")
        print(results)

    print("Within def")
    print(results)
    return results 

if __name__ == '__main__':
    __spec__ = "ModuleSpec(name='builtins', loader=&lt;class '_frozen_importlib.BuiltinImporter'&gt;)"

    x, y, StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline, mp, Manager, results = initializer()

    results = parallel(x,y,results,StandardScaler, accuracy_score, Perceptron, LogisticRegression, Pipeline)

    print("Outside of def")
    print(type(results))
    print(len(results))

    print(results[1]) # must be within IF as otherwise does not work ?!?!?!?

    cpu_count = mp.cpu_count()
    print("CPUs: ", cpu_count)
</code></pre>
</div>
<span class="comment-copy">When using the multiprocessing module, a whole new python process is created, meaning the python script is essentially duplicated. The only difference is the newly created process will have a target method, and that target is what is executed. All the code outside of any function definitions is run the same way any python script behaves. That's my understanding.</span>
<span class="comment-copy">Cannot reproduce your result. The code works fine on my machine and also <a href="http://www.tutorialspoint.com/execute_python_online.php?PID=0Bw_CjBb95KQMVFJETFNzZG1rX1U" rel="nofollow noreferrer">tutorialspoint.com/…</a></span>
<span class="comment-copy">@aristotll I cannot exaplain why it works online but I have run this on two computers here and it fails everytime - but none the less, thanks for checking.</span>
<span class="comment-copy">@Peter you answer seems reasonable, do you know somewhere that explains this a tad more thoroughly? becasue I cannot find this in literature</span>
<span class="comment-copy">@aristotll: Just a guess but are you using some kind of Unix? The unix version will fork by default, rather than create a new process: <a href="https://docs.python.org/3.6/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">docs.python.org/3.6/library/…</a> I assume since the forking process has already run the script outside of the function definitions before forking, no output is going to be emitted more than once</span>
<span class="comment-copy">Fantastic answer, exactly what I was looking for, however is there another way to hide unnecessary functions and modules from the child processes (to  try and save time and space) apart from including them in the <code>if</code> statement or does loading other functions/classes/modules etc take so little time it is not worth it?</span>
<span class="comment-copy">I don't think the time saved would be substantial - it shouldn't matter.</span>
<span class="comment-copy">Okay, I am sticking to using it as explained</span>
