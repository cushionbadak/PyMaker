<div class="post-text" itemprop="text">
<p>I am trying to read a CSV file and writing the rows in it on to another csv file. My input file has duplicate rows. In output I want only single row. from my sample script you can see that I created a list called readers . This list got all the rows of input csv. Then inside the for loop I am using writer.writerow(readers[1] + ....) which is basically reading the first row following the header. But the problem is this first row is repetitive. How can I tweak my script so it is executed only once ?</p>
<pre><code>for path in glob.glob("out.csv"):
    if path == "out1.csv": continue
    with open(path) as fh:
        readers = list(csv.reader(fh))

        for row in readers:

            if row[8] == 'READ' and row[10] == '1110':

                writer.writerow(readers[1] + [] + [row[2]])
            elif row[8] == 'READ' and row[10] == '1011':
                writer.writerow(readers[1] + [] + [" "] + [" "] + [" "] + [row[2]])
            elif row[8] == 'READ' and row[10] != ('1101', '0111'):
                writer.writerow(readers[1] + [] + [" "] + [row[2]]) 
</code></pre>
<p>Sample Input</p>
<pre><code>    ID No.  Name    Value   RESULTS
      28    Jason   56789   Fail
      28    Jason   56789   Fail
      28    Jason   56789   Fail
      28    Jason   56789   Fail
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You may use the pandas package. That would be something like this:</p>
<pre><code>import pandas as pd
# Read the file (considering header by default) and save in variable:
table = pd.read_csv()
# Drop the duplicates:
clean_table = table.drop_duplicates()
# Save clean data:
clean_table.to_csv("data_without_duplicates.csv")
</code></pre>
<p>You may check the references <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html" rel="nofollow noreferrer">here</a>, and <a href="http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.DataFrame.drop_duplicates.html" rel="nofollow noreferrer">here</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset" rel="nofollow noreferrer">set</a> type to remove duplicates</p>
<p><code>readers_unique = list(set(readers))</code></p>
</div>
<div class="post-text" itemprop="text">
<p>While the answers above are basically correct, using Pandas for this seems like overkill to me. Simply use a list with the ID column values you already have seen in processing (assuming that the ID column earns its name, otherwise you have to use a combined key). Then just check if you already saw this value and "presto":</p>
<pre><code>ID_COL = 1
id_seen = []
for path in glob.glob("out.csv"):
    if path == "out1.csv": continue
    with open(path) as fh:
        for row in csv.reader(fh):
            if row[ID_COL] not in id_seen:
                id_seen.append(row[ID_COL])
                # write out whatever column you have to
                writer.writerow(readers[1] + [] + [row[2]])
</code></pre>
</div>
<span class="comment-copy">Are the rows sorted already (i.e., can we expect duplicates to appear next to one another?)? Or does the script also need to do this?</span>
<span class="comment-copy">Sorry can you please elaborate a little bit more what do you exactly mean by sorting here ? I want to make changes in my script so I can write the same rows only once. Currently it is repeating same rows.</span>
