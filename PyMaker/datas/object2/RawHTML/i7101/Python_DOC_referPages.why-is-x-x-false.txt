<div class="post-text" itemprop="text">
<p>The title is a bit misleading, because it's not exactly x and x, it's x and 0.3; however, the values <em>should</em> be the same.</p>
<p>I have:</p>
<pre><code>arr = np.arange(0, 1.1, 0.1)
</code></pre>
<p>and I receive:</p>
<pre><code>arr[arr &lt;= 0.3]
&gt; array([0., 0.1, 0.2])
</code></pre>
<p>The correct result should be:</p>
<pre><code>arr[arr &lt;= 0.3]
&gt; array([0., 0.1, 0.2, 0.3])
</code></pre>
<p>I have not yet stumbled upon this problem. I know it is related to floating point precision ... but what can I do here?</p>
</div>
<div class="post-text" itemprop="text">
<p>Don't rely on comparing floats for equality (unless you know <em>exactly</em> what floats you are dealing with).
Since you know the stepsize used to generate the array is 0.1,</p>
<pre><code>arr = np.arange(0, 1.1, 0.1)
</code></pre>
<p>you could increase the threshold value, 0.3, by half the stepsize to find a new threshold which is safely between values in <code>arr</code>:</p>
<pre><code>In [48]: stepsize = 0.1; arr[arr &lt; 0.3+(stepsize/2)]
Out[48]: array([ 0. ,  0.1,  0.2,  0.3])
</code></pre>
<hr/>
<p>By the way, the <code>1.1</code> in <code>np.arange(0, 1.1, 0.1)</code> is an application of the same idea -- given the vagaries of floating-point arithmetic, we couldn't be sure that <code>1.0</code> would be included if we wrote <code>np.arange(0, 1.0, 0.1)</code>, so the right endpoint was increased by the stepsize.</p>
<hr/>
<p>Fundamentally, the problem boils down to <a href="https://docs.python.org/3/faq/design.html#why-are-floating-point-calculations-so-inaccurate" rel="nofollow noreferrer">floating-point arithmetic being inaccurate</a>:</p>
<pre><code>In [17]: 0.1+0.2 == 0.3
Out[17]: False
</code></pre>
<p>So the fourth value in the array is a little bit greater than 0.3.</p>
<pre><code>In [40]: arr = np.arange(0,1.1, 0.1)
In [41]: arr[3]
Out[41]: 0.30000000000000004
</code></pre>
<hr/>
<p>Note that rounding may not be a viable solution. For example,
if <code>arr</code> has dtype <code>float128</code>:</p>
<pre><code>In [53]: arr = np.arange(0, 1.1, 0.1, dtype='float128')

In [56]: arr[arr.round(1) &lt;= 0.3]
Out[56]: array([ 0.0,  0.1,  0.2], dtype=float128)
</code></pre>
<p>Although making the dtype <code>float128</code> made <code>arr[3]</code> closer to the decimal 0.3,</p>
<pre><code>In [54]: arr[3]
Out[54]: 0.30000000000000001665
</code></pre>
<p>now rounding does not produce a number less than 0.3:</p>
<pre><code>In [55]: arr.round(1)[3]
Out[55]: 0.30000000000000000001
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Unutbu points out the main problem. You should avoid comparing floating point numbers, as they have a round off error.</p>
<p>However this is a problem many people come across, therefore there is a function that helps you getting around this problem; <code>np.isclose</code> in your case this would lead to:</p>
<pre><code>arr[np.logical_or(arr &lt;= 0.3, np.isclose(0.3, arr))]
&gt;&gt;&gt; array([0., 0.1, 0.2, 0.3])
</code></pre>
<p>In this case this might not be the best option, but it might be helpful to know about this function.</p>
<p>Sidenote:
In case nobody has ever explained to you, why this happens. Basically computer save everything in binary, however 0.1 is a periodic number in binary, this means that the computer can't save all the digits (as there are infinitely many). The equivalent in decimal would be:</p>
<p>1/3+1/3+1/3 = 0.33333 + 0.33333 + 0.33333 = 0.99999</p>
<p>Which is not 1</p>
</div>
<span class="comment-copy">Well... <code>arr[arr.round(1) &lt;= 0.3]</code> works...</span>
<span class="comment-copy">So should I <i>always</i> round numbers before performing any comparisons?</span>
<span class="comment-copy">Equivalence between floats is always a risky thing to test for.</span>
<span class="comment-copy">@Xiphias depends on your use case - one way is to store the above as 0-10... and use plain ints as you're aware of the precision and ints don't have floating point shennigans - but that may not be practical</span>
<span class="comment-copy"><code>np.linspace</code> is generally a much better option than <code>np.arange</code> for floating-point ranges - particularly, it gives you much better control of the endpoints - but it won't save you from all rounding error.</span>
<span class="comment-copy">Even if you didn't know the step size, you <i>might</i> still be able to do something like <code>arr[arr &lt;= 0.3 + sys.float_info.epsilon]</code> - however, I'm not at all confident that will <i>always</i> be enough to guarantee the comparison works... What are your thoughts?</span>
<span class="comment-copy">Although - the above does seem to work on your <code>float128</code> example as well...</span>
<span class="comment-copy">I'm not sure how to quantify just how far off the values in <code>np.arange(...)</code> may be from their idealized decimal counterparts. Depending on the floats, the gap between successive floats changes and could be greater than <code>sys.float_info.epsilon</code>. For example,  <code>x = 10.3; (np.nextafter(x, np.inf) - x) &gt; sys.float_info.epsilon</code>.</span>
<span class="comment-copy">Yeah... I'll do my poor brain a favour and not think about it :)</span>
<span class="comment-copy">Here's a case where add <code>sys.float_info.epsilon</code> is insufficient:  <code>x = 1.83; arr = np.arange(x,x+1.1, 0.1); arr[arr &lt;= x+0.3+sys.float_info.epsilon]</code> returns <code>array([ 1.83,  1.93,  2.03])</code>.</span>
