<div class="post-text" itemprop="text">
<p>I think what I want to do is a fairly common task but I've found no reference on the web. I have text with punctuation, and I want a list of the words. </p>
<pre><code>"Hey, you - what are you doing here!?"
</code></pre>
<p>should be</p>
<pre><code>['hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
<p>But Python's <code>str.split()</code> only works with one argument, so I have all words with the punctuation after I split with whitespace. Any ideas?</p>
</div>
<div class="post-text" itemprop="text">
<p>A case where regular expressions are justified:</p>
<pre><code>import re
DATA = "Hey, you - what are you doing here!?"
print re.findall(r"[\w']+", DATA)
# Prints ['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><a href="http://docs.python.org/library/re.html#re.split" rel="noreferrer">re.split()</a></p>
<blockquote>
<p>re.split(pattern, string[, maxsplit=0])</p>
<p>Split string by the occurrences of pattern. If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list. (Incompatibility note: in the original Python 1.5 release, maxsplit was ignored. This has been fixed in later releases.)</p>
</blockquote>
<pre><code>&gt;&gt;&gt; re.split('\W+', 'Words, words, words.')
['Words', 'words', 'words', '']
&gt;&gt;&gt; re.split('(\W+)', 'Words, words, words.')
['Words', ', ', 'words', ', ', 'words', '.', '']
&gt;&gt;&gt; re.split('\W+', 'Words, words, words.', 1)
['Words', 'words, words.']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Another quick way to do this without a regexp is to replace the characters first, as below:</p>
<pre><code>&gt;&gt;&gt; 'a;bcd,ef g'.replace(';',' ').replace(',',' ').split()
['a', 'bcd', 'ef', 'g']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>So many answers, yet I can't find any solution that does efficiently what the <em>title</em> of the questions literally asks for (splitting on multiple possible separators—instead, many answers remove anything that is not a word, which is different). So here is an answer to the question in the title, that relies on Python's standard and efficient <code>re</code> module:</p>
<pre><code>&gt;&gt;&gt; import re  # Will be splitting on: , &lt;space&gt; - ! ? :
&gt;&gt;&gt; filter(None, re.split("[, \-!?:]+", "Hey, you - what are you doing here!?"))
['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
<p>where:</p>
<ul>
<li>the <code>[…]</code> matches <em>one</em> of the separators listed inside,</li>
<li>the <code>\-</code> in the regular expression is here to prevent the special interpretation of <code>-</code> as a character range indicator (as in <code>A-Z</code>),</li>
<li>the <code>+</code> skips one <em>or more</em> delimiters (it could be omitted thanks to the <code>filter()</code>, but this would unnecessarily produce empty strings between matched separators), and</li>
<li><code>filter(None, …)</code> removes the empty strings possibly created by leading and trailing separators (since empty strings have a false boolean value).</li>
</ul>
<p>This <code>re.split()</code> precisely "splits with multiple separators", as asked for in the question title.</p>
<p>This solution is furthermore immune to the problems with non-ASCII characters in words found in some other solutions (see the first comment to <a href="https://stackoverflow.com/a/1157498/42973">ghostdog74's answer</a>).</p>
<p>The <code>re</code> module is much more efficient (in speed and concision) than doing Python loops and tests "by hand"!</p>
</div>
<div class="post-text" itemprop="text">
<p>Another way, without regex</p>
<pre><code>import string
punc = string.punctuation
thestring = "Hey, you - what are you doing here!?"
s = list(thestring)
''.join([o for o in s if not o in punc]).split()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Pro-Tip: Use <code>string.translate</code> for the fastest string operations Python has.</p>
<p>Some proof...</p>
<p>First, the slow way (sorry pprzemek):</p>
<pre><code>&gt;&gt;&gt; import timeit
&gt;&gt;&gt; S = 'Hey, you - what are you doing here!?'
&gt;&gt;&gt; def my_split(s, seps):
...     res = [s]
...     for sep in seps:
...         s, res = res, []
...         for seq in s:
...             res += seq.split(sep)
...     return res
... 
&gt;&gt;&gt; timeit.Timer('my_split(S, punctuation)', 'from __main__ import S,my_split; from string import punctuation').timeit()
54.65477919578552
</code></pre>
<p>Next, we use <code>re.findall()</code> (as given by the suggested answer). MUCH faster:</p>
<pre><code>&gt;&gt;&gt; timeit.Timer('findall(r"\w+", S)', 'from __main__ import S; from re import findall').timeit()
4.194725036621094
</code></pre>
<p>Finally, we use <code>translate</code>:</p>
<pre><code>&gt;&gt;&gt; from string import translate,maketrans,punctuation 
&gt;&gt;&gt; T = maketrans(punctuation, ' '*len(punctuation))
&gt;&gt;&gt; timeit.Timer('translate(S, T).split()', 'from __main__ import S,T,translate').timeit()
1.2835021018981934
</code></pre>
<p><strong>Explanation:</strong></p>
<p><code>string.translate</code> is implemented in C and unlike many string manipulation functions in Python, <code>string.translate</code> <strong>does not</strong> produce a new string. So it's about as fast as you can get for string substitution.</p>
<p>It's a bit awkward, though, as it needs a translation table in order to do this magic. You can make a translation table with the <code>maketrans()</code> convenience function. The objective here is to translate all unwanted characters to spaces. A one-for-one substitute. Again, no new data is produced. So this is <strong>fast</strong>!</p>
<p>Next, we use good old <code>split()</code>. <code>split()</code> by default will operate on all whitespace characters, grouping them together for the split. The result will be the list of words that you want. And this approach is almost 4x faster than <code>re.findall()</code>!</p>
</div>
<div class="post-text" itemprop="text">
<p>Kinda late answer :), but I had a similar dilemma and didn't want to use 're' module.</p>
<pre><code>def my_split(s, seps):
    res = [s]
    for sep in seps:
        s, res = res, []
        for seq in s:
            res += seq.split(sep)
    return res

print my_split('1111  2222 3333;4444,5555;6666', [' ', ';', ','])
['1111', '', '2222', '3333', '4444', '5555', '6666']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>join = lambda x: sum(x,[])  # a.k.a. flatten1([[1],[2,3],[4]]) -&gt; [1,2,3,4]
# ...alternatively...
join = lambda lists: [x for l in lists for x in l]
</code></pre>
<p>Then this becomes a three-liner:</p>
<pre><code>fragments = [text]
for token in tokens:
    fragments = join(f.split(token) for f in fragments)
</code></pre>
<hr/>
<p><strong>Explanation</strong></p>
<p>This is what in Haskell is known as the List monad. The idea behind the monad is that once "in the monad" you "stay in the monad" until something takes you out. For example in Haskell, say you map the python <code>range(n) -&gt; [1,2,...,n]</code> function over a List. If the result is a List, it will be append to the List in-place, so you'd get something like <code>map(range, [3,4,1]) -&gt; [0,1,2,0,1,2,3,0]</code>. This is known as map-append (or mappend, or maybe something like that). The idea here is that you've got this operation you're applying (splitting on a token), and whenever you do that, you join the result into the list.</p>
<p>You can abstract this into a function and have <code>tokens=string.punctuation</code> by default. </p>
<p>Advantages of this approach:</p>
<ul>
<li>This approach (unlike naive regex-based approaches) can work with arbitrary-length tokens (which regex can also do with more advanced syntax).</li>
<li>You are not restricted to mere tokens; you could have arbitrary logic in place of each token, for example one of the "tokens" could be a function which splits according to how nested parentheses are.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>First, I want to agree with others that the regex or <code>str.translate(...)</code> based solutions are most performant.  For my use case the performance of this function wasn't significant, so I wanted to add ideas that I considered with that criteria.</p>
<p>My main goal was to generalize ideas from some of the other answers into one solution that could work for strings containing more than just regex words (i.e., blacklisting the explicit subset of punctuation characters vs whitelisting word characters).</p>
<p><em>Note that, in any approach, one might also consider using <code>string.punctuation</code> in place of a manually defined list.</em></p>
<h1>Option 1 - re.sub</h1>
<p>I was surprised to see no answer so far uses <a href="https://docs.python.org/3/library/re.html#re.sub" rel="nofollow noreferrer">re.sub(...)</a>.  I find it a simple and natural approach to this problem.</p>
<pre><code>import re

my_str = "Hey, you - what are you doing here!?"

words = re.split(r'\s+', re.sub(r'[,\-!?]', ' ', my_str).strip())
</code></pre>
<p>In this solution, I nested the call to <code>re.sub(...)</code> inside <code>re.split(...)</code> — but if performance is critical, compiling the regex outside could be beneficial — for my use case, the difference wasn't significant, so I prefer simplicity and readability.</p>
<h1>Option 2 - str.replace</h1>
<p>This is a few more lines, but it has the benefit of being expandable without having to check whether you need to escape a certain character in regex.</p>
<pre><code>my_str = "Hey, you - what are you doing here!?"

replacements = (',', '-', '!', '?')
for r in replacements:
    my_str = my_str.replace(r, ' ')

words = my_str.split()
</code></pre>
<p>It would have been nice to be able to map the str.replace to the string instead, but I don't think it can be done with immutable strings, and while mapping against a list of characters would work, running every replacement against every character sounds excessive. (Edit: See next option for a functional example.)</p>
<h1>Option 3 - functools.reduce</h1>
<p>(In Python 2, <code>reduce</code> is available in global namespace without importing it from functools.)</p>
<pre><code>import functools

my_str = "Hey, you - what are you doing here!?"

replacements = (',', '-', '!', '?')
my_str = functools.reduce(lambda s, sep: s.replace(sep, ' '), replacements, my_str)
words = my_str.split()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>try this:</p>
<pre><code>import re

phrase = "Hey, you - what are you doing here!?"
matches = re.findall('\w+', phrase)
print matches
</code></pre>
<p>this will print <code>['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']</code></p>
</div>
<div class="post-text" itemprop="text">
<p>Use replace two times:</p>
<pre><code>a = '11223FROM33344INTO33222FROM3344'
a.replace('FROM', ',,,').replace('INTO', ',,,').split(',,,')
</code></pre>
<p>results in: </p>
<pre><code>['11223', '33344', '33222', '3344']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I like <strong>re</strong>, but here is my solution without it:</p>
<pre><code>from itertools import groupby
sep = ' ,-!?'
s = "Hey, you - what are you doing here!?"
print [''.join(g) for k, g in groupby(s, sep.__contains__) if not k]
</code></pre>
<p><strong>sep.__contains__</strong> is a method used by 'in' operator. Basically it is the same as</p>
<pre><code>lambda ch: ch in sep
</code></pre>
<p>but is more convenient here.</p>
<p><strong>groupby</strong> gets our string and function. It splits string in groups using that function:  whenever a value of function changes - a new group is generated. So, <strong>sep.__contains__</strong> is exactly what we need.</p>
<p><strong>groupby</strong> returns a sequence of pairs, where pair[0] is a result of our function and pair[1] is a group. Using <strong>'if not k'</strong> we filter out groups with separators (because a result of <strong>sep.__contains__</strong> is True on separators). Well, that's all - now we have a sequence of groups where each one is a word (group is actually an iterable so we use <strong>join</strong> to convert it to string).</p>
<p>This solution is quite general, because it uses a function to separate string (you can split by any condition you need). Also, it doesn't create intermediate strings/lists (you can remove <strong>join</strong> and the expression will become lazy, since each group is an iterator)</p>
</div>
<div class="post-text" itemprop="text">
<p>Instead of using a re module function re.split you can achieve the same result using the series.str.split method of pandas. </p>
<p>First, create a series with the above string and then apply the method to the series.</p>
<p><code>thestring = pd.Series("Hey, you - what are you doing here!?")
thestring.str.split(pat = ',|-')</code></p>
<p>parameter <em>pat</em> takes the delimiters and returns the split string as an array. Here the two delimiters are passed using a | (or operator).
The output is as follows:</p>
<p><code>[Hey,  you ,  what are you doing here!?]
</code> </p>
</div>
<div class="post-text" itemprop="text">
<p>I'm re-acquainting myself with Python and needed the same thing.
The findall solution may be better, but I came up with this:</p>
<pre><code>tokens = [x.strip() for x in data.split(',')]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>In Python 3, your can use the method from <a href="https://www.py4e.com/html3/09-dictionaries" rel="nofollow noreferrer">PY4E - Python for Everybody</a>.</p>
<blockquote>
<p>We can solve both these problems by using the string methods <code>lower</code>, <code>punctuation</code>, and <code>translate</code>. The <code>translate</code> is the most subtle of the methods. Here is the documentation for <code>translate</code>:</p>
</blockquote>
<p><code>your_string.translate(your_string.maketrans(fromstr, tostr, deletestr))</code></p>
<blockquote>
<p>Replace the characters in <code>fromstr</code> with the character in the same position in <code>tostr</code> and delete all characters that are in <code>deletestr</code>. The <code>fromstr</code> and <code>tostr</code> can be empty strings and the <code>deletestr</code> parameter can be omitted.</p>
</blockquote>
<p>Your can see the "punctuation":</p>
<pre><code>In [10]: import string

In [11]: string.punctuation
Out[11]: '!"#$%&amp;\'()*+,-./:;&lt;=&gt;?@[\\]^_`{|}~'  
</code></pre>
<p>For your example:</p>
<pre><code>In [12]: your_str = "Hey, you - what are you doing here!?"

In [13]: line = your_str.translate(your_str.maketrans('', '', string.punctuation))

In [14]: line = line.lower()

In [15]: words = line.split()

In [16]: print(words)
['hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
<p>For more information, you can refer:</p>
<ul>
<li><a href="https://www.py4e.com/html3/09-dictionaries" rel="nofollow noreferrer">PY4E - Python for Everybody</a></li>
<li><a href="https://docs.python.org/3.6/library/stdtypes.html#str.translate" rel="nofollow noreferrer">str.translate</a></li>
<li><a href="https://docs.python.org/3.6/library/stdtypes.html#str.maketrans" rel="nofollow noreferrer">str.maketrans</a></li>
<li><a href="https://www.tutorialspoint.com/python/string_maketrans.htm" rel="nofollow noreferrer">Python String maketrans() Method</a></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>using maketrans and translate you can do it easily and neatly</p>
<pre><code>import string
specials = ',.!?:;"()&lt;&gt;[]#$=-/'
trans = string.maketrans(specials, ' '*len(specials))
body = body.translate(trans)
words = body.strip().split()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Another way to achieve this is to use the Natural Language Tool Kit (<a href="http://nltk.org/doc/en/ch02.html" rel="nofollow noreferrer">nltk</a>).</p>
<pre><code>import nltk
data= "Hey, you - what are you doing here!?"
word_tokens = nltk.tokenize.regexp_tokenize(data, r'\w+')
print word_tokens
</code></pre>
<p>This prints: <code>['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']</code></p>
<p>The biggest drawback of this method is that you need to <a href="http://pypi.python.org/pypi/nltk/0.9.9" rel="nofollow noreferrer">install the nltk package</a>.</p>
<p>The benefits are that you can do <a href="http://nltk.googlecode.com/svn/trunk/doc/howto/index.html" rel="nofollow noreferrer">a lot of fun stuff</a> with the rest of the nltk package once you get your tokens.</p>
</div>
<div class="post-text" itemprop="text">
<p>First of all, I don't think that your intention is to actually use punctuation as delimiters in the split functions.  Your description suggests that you simply want to eliminate punctuation from the resultant strings.</p>
<p>I come across this pretty frequently, and my usual solution doesn't require re.</p>
<h2>One-liner lambda function w/ list comprehension:</h2>
<p>(requires <code>import string</code>):</p>
<pre><code>split_without_punc = lambda text : [word.strip(string.punctuation) for word in 
    text.split() if word.strip(string.punctuation) != '']

# Call function
split_without_punc("Hey, you -- what are you doing?!")
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
</code></pre>
<p><br/></p>
<h2>Function (traditional)</h2>
<p>As a traditional function, this is still only two lines with a list comprehension (in addition to <code>import string</code>):</p>
<pre><code>def split_without_punctuation2(text):

    # Split by whitespace
    words = text.split()

    # Strip punctuation from each word
    return [word.strip(ignore) for word in words if word.strip(ignore) != '']

split_without_punctuation2("Hey, you -- what are you doing?!")
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
</code></pre>
<p>It will also naturally leave contractions and hyphenated words intact. You can always use <code>text.replace("-", " ")</code> to turn hyphens into spaces before the split.</p>
<h2>General Function w/o Lambda or List Comprehension</h2>
<p>For a more general solution (where you can specify the characters to eliminate), and without a list comprehension, you get:</p>
<pre><code>def split_without(text: str, ignore: str) -&gt; list:

    # Split by whitespace
    split_string = text.split()

    # Strip any characters in the ignore string, and ignore empty strings
    words = []
    for word in split_string:
        word = word.strip(ignore)
        if word != '':
            words.append(word)

    return words

# Situation-specific call to general function
import string
final_text = split_without("Hey, you - what are you doing?!", string.punctuation)
# returns ['Hey', 'you', 'what', 'are', 'you', 'doing']
</code></pre>
<p>Of course, you can always generalize the lambda function to any specified string of characters as well.</p>
</div>
<div class="post-text" itemprop="text">
<p>First of all, always use re.compile() before performing any RegEx operation in a loop because it works faster than normal operation.</p>
<p>so for your problem first compile the pattern and then perform action on it.</p>
<pre><code>import re
DATA = "Hey, you - what are you doing here!?"
reg_tok = re.compile("[\w']+")
print reg_tok.findall(DATA)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is the answer with some explanation.</p>
<pre><code>st = "Hey, you - what are you doing here!?"

# replace all the non alpha-numeric with space and then join.
new_string = ''.join([x.replace(x, ' ') if not x.isalnum() else x for x in st])
# output of new_string
'Hey  you  what are you doing here  '

# str.split() will remove all the empty string if separator is not provided
new_list = new_string.split()

# output of new_list
['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']

# we can join it to get a complete string without any non alpha-numeric character
' '.join(new_list)
# output
'Hey you what are you doing'
</code></pre>
<p>or in one line, we can do like this:</p>
<pre><code>(''.join([x.replace(x, ' ') if not x.isalnum() else x for x in st])).split()

# output
['Hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
<p>updated answer</p>
</div>
<div class="post-text" itemprop="text">
<p>Create a function that takes as input two strings (the source string to be split and the splitlist string of delimiters) and outputs a list of split words:</p>
<pre><code>def split_string(source, splitlist):
    output = []  # output list of cleaned words
    atsplit = True
    for char in source:
        if char in splitlist:
            atsplit = True
        else:
            if atsplit:
                output.append(char)  # append new word after split
                atsplit = False
            else: 
                output[-1] = output[-1] + char  # continue copying characters until next split
    return output
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>got same problem as @ooboo and find this topic
@ghostdog74 inspired me, maybe someone finds my solution usefull</p>
<pre><code>str1='adj:sg:nom:m1.m2.m3:pos'
splitat=':.'
''.join([ s if s not in splitat else ' ' for s in str1]).split()
</code></pre>
<p>input something in space place and split using same character if you dont want to split at spaces.</p>
</div>
<div class="post-text" itemprop="text">
<p>Here is my go at a split with multiple deliminaters:</p>
<pre><code>def msplit( str, delims ):
  w = ''
  for z in str:
    if z not in delims:
        w += z
    else:
        if len(w) &gt; 0 :
            yield w
        w = ''
  if len(w) &gt; 0 :
    yield w
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I think the following is the best answer to suite your needs :</p>
<p><code>\W+</code> maybe suitable for this case, but may not be suitable for other cases.</p>
<pre><code>filter(None, re.compile('[ |,|\-|!|?]').split( "Hey, you - what are you doing here!?")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Heres my take on it....</p>
<pre><code>def split_string(source,splitlist):
    splits = frozenset(splitlist)
    l = []
    s1 = ""
    for c in source:
        if c in splits:
            if s1:
                l.append(s1)
                s1 = ""
        else:
            print s1
            s1 = s1 + c
    if s1:
        l.append(s1)
    return l

&gt;&gt;&gt;out = split_string("First Name,Last Name,Street Address,City,State,Zip Code",",")
&gt;&gt;&gt;print out
&gt;&gt;&gt;['First Name', 'Last Name', 'Street Address', 'City', 'State', 'Zip Code']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I like the <code>replace()</code> way the best. The following procedure changes all separators defined in a string <code>splitlist</code> to the first separator in <code>splitlist</code> and then splits the text on that one separator. It also accounts for if <code>splitlist</code> happens to be an empty string. It returns a list of words, with no empty strings in it.</p>
<pre><code>def split_string(text, splitlist):
    for sep in splitlist:
        text = text.replace(sep, splitlist[0])
    return filter(None, text.split(splitlist[0])) if splitlist else [text]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>def get_words(s):
    l = []
    w = ''
    for c in s.lower():
        if c in '-!?,. ':
            if w != '': 
                l.append(w)
            w = ''
        else:
            w = w + c
    if w != '': 
        l.append(w)
    return l
</code></pre>
<p>Here is the usage:</p>
<pre><code>&gt;&gt;&gt; s = "Hey, you - what are you doing here!?"
&gt;&gt;&gt; print get_words(s)
['hey', 'you', 'what', 'are', 'you', 'doing', 'here']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you want a reversible operation (preserve the delimiters), you can use this function:</p>
<pre><code>def tokenizeSentence_Reversible(sentence):
    setOfDelimiters = ['.', ' ', ',', '*', ';', '!']
    listOfTokens = [sentence]

    for delimiter in setOfDelimiters:
        newListOfTokens = []
        for ind, token in enumerate(listOfTokens):
            ll = [([delimiter, w] if ind &gt; 0 else [w]) for ind, w in enumerate(token.split(delimiter))]
            listOfTokens = [item for sublist in ll for item in sublist] # flattens.
            listOfTokens = filter(None, listOfTokens) # Removes empty tokens: ''
            newListOfTokens.extend(listOfTokens)

        listOfTokens = newListOfTokens

    return listOfTokens
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You want Python's RegEx module's <code>findall()</code> method:</p>
<p><a href="http://www.regular-expressions.info/python.html" rel="nofollow noreferrer">http://www.regular-expressions.info/python.html</a></p>
<p><a href="https://stackoverflow.com/questions/234512/splitting-strings-in-python">Example</a></p>
</div>
<span class="comment-copy"><a href="http://docs.python.org/library/re.html" rel="nofollow noreferrer">docs.python.org/library/re.html</a></span>
<span class="comment-copy">python's <code>str.split()</code> also works with no arguments at all</span>
<span class="comment-copy">Thanks.  Still interested, though - how can I implement the algorithm used in this module? And why does it not appear in the string module?</span>
<span class="comment-copy">Regular expressions can be daunting at first, but are very powerful. The regular expression '\w+' means "a word character (a-z etc.) repeated one or more times".  There's a HOWTO on Python regular expressions here: <a href="http://www.amk.ca/python/howto/regex/" rel="nofollow noreferrer">amk.ca/python/howto/regex</a></span>
<span class="comment-copy">This isn't the answer to the question. This is an answer to a different question, that happens to work for this particular situation. It's as if someone asked "how do I make a left turn" and the top-voted answer was "take the next three right turns." It works for certain intersections, but it doesn't give the needed answer. Ironically, the answer <i>is</i> in <code>re</code>, just not <code>findall</code>. The answer below giving <code>re.split()</code> is superior.</span>
<span class="comment-copy">This will not work with words that contain hyphens (<code>-</code>).</span>
<span class="comment-copy">@JesseDhillon "take all substrings consisting of a sequence of word characters" and "split on all substrings consisting of a sequence of non-word characters" are literally just different ways of expressing the same operation; I'm not sure why you'd call either answer superior.</span>
<span class="comment-copy">This solution have the advantage of being easily adapted to split on underscores too, something the findall solution does not: print re.split("\W+|_", "Testing this_thing")' yields: ['Testing', 'this', 'thing']</span>
<span class="comment-copy">Now if only I could remember the difference between <code>\w</code>, <code>\W</code>, <code>\s</code>, and <code>\S</code>. Whoever thought that the capitalization of a flag should invert its meaning needs to be shot through the head.</span>
<span class="comment-copy">A common use case of string splitting is removing empty string entries from the final result.  Is it possible to do that with this method? re.split('\W+', ' a b c ') results in ['', 'a', 'b', 'c', '']</span>
<span class="comment-copy">@ScottMorken I suggest st. like <code>[ e for e in re.split(r'\W+', ...) if e ]</code> ... or possibly first do <code>' a b c '.strip()</code></span>
<span class="comment-copy">@ArtOfWarfare It is common to use the <code>shift</code> key to do the opposite of something. <code>ctrl+z</code> undo vs. <code>ctrl+shift+z</code> for redo. So <code>shift w</code>, or <code>W</code>, would be the opposite of <code>w</code>.</span>
<span class="comment-copy">Quick and dirty but perfect for my case (my separators were a small, known set)</span>
<span class="comment-copy">Perfect for the case where you don't have access to the RE library, such as certain small microcontrollers. :-)</span>
<span class="comment-copy">I think this is more explicit than RE as well, so it's kind of noob friendly.  Sometimes don't need general solution to everything</span>
<span class="comment-copy">Looks less tedious than unpacking the regex toolbox...</span>
<span class="comment-copy">This is such a great idea compared to my brain hurting about regex...</span>
<span class="comment-copy">"I can't find any solution that does efficiently what the title of the questions literally asks" - second answer does that, posted 5 years ago: <a href="http://stackoverflow.com/a/1059601/2642204">stackoverflow.com/a/1059601/2642204</a>.</span>
<span class="comment-copy">This answer does not split at delimiters (from a set of multiple delimiters): it instead splits at anything that's not alphanumeric. That said, I agree that the intent of the original poster is probably to keep only the words, instead of removing some punctuation marks.</span>
<span class="comment-copy">EOL: I think this answer does split on a set of multiple delimeters. If you add non-alphanumerics to the string that are not specified, like underscore, they are not split, as expected.</span>
<span class="comment-copy">@GravityWell: I am not sure I understand: can you give a concrete example?</span>
<span class="comment-copy">@EOL: I just realized I was confused by your comment "This answer does not split..." I thought "this" referred to your re.split answer, but I now realize you meant gimel's answer. I think THIS answer (the answer to which I'm commenting) is the best answer :)</span>
<span class="comment-copy">This solution is actually better than the accepted one. It works with no ASCII chars, try <code>"Hey, you - what are you doing here María!?"</code>. The accepted solution will not work with the previous example.</span>
<span class="comment-copy">I think there is a small issue here ... Your code will append characters that are separated with punctuation and thus won't split them ... If I'm not wrong, your last line should be: <code>''.join([o if not o in string.punctuation else ' ' for o in s]).split()</code></span>
<span class="comment-copy">The regular expression library can be made to accept Unicode conventions for characters if necessary. Additionally, this has the same problem the accepted solution used to have: as it is now, it splits on apostrophes. You may want <code>o for o in s if (o in not string.punctuation or o == "'")</code>, but then it's getting too complicated for a one-liner if we add in cedbeu's patch also.</span>
<span class="comment-copy">There is another issue here. Even when we take into account the changes of @cedbeu, this code doesn't work if the string is something like <code>"First Name,Last Name,Street Address,City,State,Zip Code"</code> and we want to split only on a comma <code>,</code>. Desired output would be: <code>['First Name', 'Last Name', 'Street Address', 'City', 'State', 'Zip Code']</code> What we get instead:<code>['First', 'Name', 'Last', 'Name', 'Street', 'Address', 'City', 'State', 'Zip', 'Code']</code></span>
<span class="comment-copy">This solution is terribly inefficient: first the list is deconstructed into individual characters, then the <i>whole</i> set of punctuation characters is gone through for each single characters in the original string, then the characters are assembled back, and then split again. All this "movement" is very complicated, too, compared to a regular expression-based solution: even if speed does not matter in a given application, there is no need for a complicated solution. Since the <code>re</code> module is standard and gives both legibility and speed, I don't see why it should be eschewed.</span>
<span class="comment-copy">I made a test here, and if you need to use unicode, using <code>patt = re.compile(ur'\w+', re.UNICODE); patt.findall(S)</code> is faster than translate, because you must encode the string before applying transform, and decode each item in the list after the split to go back to unicode.</span>
<span class="comment-copy">You can one-liner the translate implementation and ensure that S isn't among the splitters with: <code>s.translate(''.join([(chr(i) if chr(i) not in seps else seps[0]) for i in range(256)])).split(seps[0])</code></span>
<span class="comment-copy">None taken.  You're comparing apples and oranges. ;) my solution in python 3 still works ;P and has support for multi-char separators. :) try doing that in simple manner without allocating a new string. :) but true, mine is limited to parsing command line params and not a book for example.</span>
<span class="comment-copy">fyi: I will use a function very similiar to your suggestion in an IDLE-extension.</span>
<span class="comment-copy">I like this. Just a note, the order of separators matters. Sorry if that's obvious.</span>
<span class="comment-copy">Why not use the <code>re</code> module, which is both way faster and clearer (not that regular expressions are especially clear, but because it is way shorter and direct)?</span>
<span class="comment-copy">Neat Haskell solution, but IMO this can be written more clearly without mappend in Python.</span>
<span class="comment-copy">@Goose: the point was that the 2-line function <code>map_then_append</code> can be used to make a problem a 2-liner, as well as many other problems much easier to write. Most of the other solutions use the regular expression <code>re</code> module, which isn't python. But I have been unhappy with how I make my answer seem inelegant and bloaty when it's really concise... I'm going to edit it...</span>
<span class="comment-copy">is this supposed to be working in Python as-written? my <code>fragments</code> result is just a list of the characters in the string (including the tokens).</span>
<span class="comment-copy">@RickTeachey: it works for me in both python2 and python3.</span>
<span class="comment-copy">hmmmm. Maybe the example is a bit ambiguous. I have tried the code in the answer all sorts of different ways- including having <code>fragments = ['the,string']</code>, <code>fragments = 'the,string'</code>, or <code>fragments = list('the,string')</code> and none of them are producing the right output.</span>
<span class="comment-copy">Quick (untested) suggestion: for option 1, I think the sub() might be better if it replaced the special characters with a space, otherwise "hello!!How" would get turned into "helloHow" and then not split correctly.</span>
<span class="comment-copy">For option 2, <code>reduce</code> can be used to "map" <code>str.replace</code> to the string: <code>my_str = functools.reduce(lambda s, sep: s.replace(sep, ' '), replacements, my_str)</code></span>
<span class="comment-copy">@NathanWailes Good catch - I've updated the answer with your suggestion.  It looks like this introduces the possibility of having leading or trailing whitespace after <code>re.sub</code> which causes <code>re.split</code> to include empty strings in the output list.  I added a <code>str.strip</code> to make the final output consistent with the other option.</span>
<span class="comment-copy">Hm, one another method is to use <code>str.translate</code> - it is not unicode-capable but is most likely faster than other methods and as such might be good in some cases: <code>replacements=',-!?'; import string; my_str = my_str.translate(string.maketrans(replacements, ' ' * len(replacements)))</code> Also here it is mandatory to have replacements as a string of characters, not tuple or list.</span>
<span class="comment-copy">@MarSoft Thanks! I mentioned that one at the top of the answer but decided not to add it since existing answers already discussed it well.</span>
<span class="comment-copy">It seems to me that you are using a sledgehammer to crack a nut</span>
<span class="comment-copy">Then you haven't read other answers to the question. They are much verbose.</span>
<span class="comment-copy">It&amp;#39;s not a matter of verbose but, rather the fact of importing an entire library (which I love, BTW) to perform a simple task after converting a string to a panda series. Not very &amp;quot;Occam friendly&amp;quot;.</span>
<span class="comment-copy">Clever, should work on all English grammatical constructs I can think of except an em-dash with no spaces—this, for example. (Workaroundable.)</span>
<span class="comment-copy">The translate() and maketrans() methods of strings are interesting, but this method fails to "split at delimiters" (or whitespace): for example, "There was a big cave-in" will incorrectly produce the word "cavein" instead of the expected "cave" and "in"… Thus, this does not do what the question asks for.</span>
<span class="comment-copy">@EricLebigot You are correct. Thanks for pointing out the error.</span>
<span class="comment-copy">Just like what @EricLebigot commented. The method above does not do what the question asks for very well.</span>
<span class="comment-copy">what if I have to split using word?</span>
<span class="comment-copy">I agree, the <code>\w</code> and <code>\W</code> solutions are not an answer to (the title of) the question. Note that in your answer, <code>|</code> should be removed (you're thinking of <code>expr0|expr1</code> instead of <code>[char0 char1…]</code>). Furthermore, there is no need to <code>compile()</code> the regular expression.</span>
<span class="comment-copy">Python's "RegEx" module? Python once had a "regex" module which was provided but deprecated up until 2.5 when it vanished.</span>
<span class="comment-copy">"re"? As in the one included in 2.6.2? <a href="http://docs.python.org/library/re.html" rel="nofollow noreferrer">docs.python.org/library/re.html</a> The one included in the bleeding edge 3.2a0? <a href="http://docs.python.org/dev/py3k/library/re.html" rel="nofollow noreferrer">docs.python.org/dev/py3k/library/re.html</a> Something tells me it's not deprecated and is, in fact, the definitive RegEx module for Python.</span>
