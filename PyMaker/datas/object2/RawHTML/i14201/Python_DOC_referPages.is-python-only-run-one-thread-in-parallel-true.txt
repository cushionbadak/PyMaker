<div class="post-text" itemprop="text">
<p>I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.</p>
<p>From what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?</p>
<p>Where is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.</p>
</div>
<div class="post-text" itemprop="text">
<p>Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:</p>
<ul>
<li><a href="http://www.artima.com/weblogs/viewpost.jsp?thread=214235" rel="noreferrer">http://www.artima.com/weblogs/viewpost.jsp?thread=214235</a></li>
<li><a href="http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/" rel="noreferrer">http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/</a></li>
</ul>
<p>From the last link an interesting quote:</p>
<blockquote>
<p>Let me explain what all that means. 
  Threads run inside the same virtual
  machine, and hence run on the same
  physical machine.  Processes can run
  on the same physical machine or in
  another physical machine.  If you
  architect your application around
  threads, you’ve done nothing to access
  multiple machines.  So, you can scale
  to as many cores are on the single
  machine (which will be quite a few
  over time), but to really reach web
  scales, you’ll need to solve the
  multiple machine problem anyway.</p>
</blockquote>
<p>If you want to use multi core, <a href="http://www.python.org/dev/peps/pep-0371/" rel="noreferrer">pyprocessing</a> defines an process based API to do real parallelization. The <a href="http://en.wikipedia.org/wiki/Python_Enhancement_Proposal#Development" rel="noreferrer">PEP</a> also includes some interesting benchmarks.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python's a fairly easy language to thread in, but there are caveats.  The biggest thing you need to know about is the Global Interpreter Lock.  This allows only one thread to access the interpreter.  This means two things:  1)  you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes.  EDIT:  I should also point out that you can put some of the code in C/C++ if you want to get around the GIL as well.</p>
<p>Thus, you need to re-consider why you want to use threads.  If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes.</p>
<p>If you want to improve responsiveness, you should CONSIDER using threads.  There are other alternatives though, namely <a href="http://en.wikipedia.org/wiki/Microthread" rel="noreferrer">microthreading</a>.  There are also some frameworks that you should look into:</p>
<ul>
<li><a href="http://www.stackless.com/" rel="noreferrer">stackless python</a></li>
<li><a href="http://greenlet.readthedocs.org/en/latest/" rel="noreferrer">greenlets</a></li>
<li><a href="http://www.gevent.org/" rel="noreferrer">gevent</a></li>
<li><a href="https://github.com/saucelabs/monocle" rel="noreferrer">monocle</a></li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print.</p>
<pre><code>import threading
class Foo (threading.Thread):
    def __init__(self,x):
        self.__x = x
        threading.Thread.__init__(self)
    def run (self):
          print str(self.__x)

for x in xrange(20):
    Foo(x).start()
</code></pre>
<p>As you have hinted at Python threads are implemented through time-slicing. This is how they get the "parallel" effect. </p>
<p>In my example my Foo class extends thread, I then implement the <code>run</code> method, which is where the code that you would like to run in a thread goes. To start the thread you call <code>start()</code> on the thread object, which will automatically invoke the <code>run</code> method...</p>
<p>Of course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use threads in python if the individual workers are doing I/O bound operations. If you are trying to scale across multiple cores on a machine either find a good <a href="http://www.python.org/dev/peps/pep-0371/" rel="noreferrer">IPC</a> framework for python or pick a different language.</p>
</div>
<div class="post-text" itemprop="text">
<p><strong>Note:</strong>  wherever I mention <code>thread</code> i mean specifically <strong><em>threads in python</em></strong> until explicitly stated.</p>
<p>Threads work a little differently in python if you are coming from <code>C/C++</code> background. In python, Only one thread can be in running state at a given time.This means Threads in python cannot truly leverage the power of multiple processing cores since by design it's not possible for threads to run parallelly on multiple cores.</p>
<p>As the memory management in python is not thread-safe each thread require an exclusive access to data structures in python interpreter.This exclusive access is acquired by a mechanism called <strong><em><code>GIL</code></em></strong> <em>( global interpretr lock )</em>.</p>
<p><strong><code>Why does python use GIL?</code></strong></p>
<p>In order to prevent multiple threads from accessing interpreter state simultaneously and corrupting the interpreter state.</p>
<p>The idea is whenever a thread is being executed <em>(even if it's the main thread)</em>, a GIL is acquired and after some predefined interval of time the 
GIL is released by the current thread and reacquired by some other thread( if any).</p>
<p><strong><code>Why not simply remove GIL?</code></strong></p>
<p>It is not that its impossible to remove GIL,  its just that in prcoess of doing so we end up putting mutiple locks inside interpreter in order to serialize access, which makes even a single threaded application less performant.</p>
<p>so the cost of removing GIL is paid off by reduced performance of a single threaded application, which is never desired.</p>
<p><strong><code>So when does thread switching occurs in python?</code></strong></p>
<p>Thread switch occurs when GIL is released.So when is GIL Released?
There are two scenarios to take into consideration.</p>
<p><strong><em>If a Thread is doing CPU Bound operations(Ex image processing).</em></strong></p>
<p>In Older versions of python , Thread switching used to occur after a fixed no of python instructions.It was by default set to <strong><code>100</code></strong>.It turned out that its not a very good policy to decide when switching should occur since the time spent executing a single instruction can
very wildly from millisecond to even a second.Therefore releasing GIL after every <strong><code>100</code></strong> instructions regardless of the time they take to execute is a poor policy.</p>
<p>In new versions instead of using instruction count as a metric to switch thread ,  a configurable time interval is used. 
The default switch interval is 5 milliseconds.you can get the current switch interval using <a href="https://docs.python.org/3/library/sys.html#sys.getswitchinterval" rel="nofollow noreferrer"><strong><em><code>sys.getswitchinterval()</code></em></strong></a>.
This can be altered using <a href="https://docs.python.org/3/library/sys.html#sys.setswitchinterval" rel="nofollow noreferrer"><strong><em><code>sys.setswitchinterval()</code></em></strong></a></p>
<p><strong><em>If a Thread is doing some IO Bound Operations(Ex filesystem access or<br/>
    network IO)</em></strong></p>
<p>GIL is release whenever the thread is waiting for some for IO operation to get completed.</p>
<p><strong><code>Which thread to switch to next?</code></strong></p>
<p>The interpreter doesn’t have its own scheduler.which thread becomes scheduled at the end of the interval is the operating system’s decision. .</p>
</div>
<div class="post-text" itemprop="text">
<p>One easy solution to the GIL is the <a href="http://docs.python.org/2/library/multiprocessing.html" rel="nofollow" title="Python docs link">multiprocessing</a> module. It can be used as a drop in replacement to the threading module but uses multiple Interpreter processes instead of threads. Because of this there is a little more overhead than plain threading for simple things but it gives you the advantage of real parallelization if you need it.
It also easily scales to multiple physical machines.</p>
<p>If you need truly large scale parallelization than I would look further but if you just want to scale to all the cores of one computer or a few different ones without all the work that would go into implementing a more comprehensive framework, than this is for you.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try to remember that the GIL is set to poll around every so often in order to do show the appearance of multiple tasks. This setting can be fine tuned, but I offer the suggestion that there should be work that the threads are doing or lots of context switches are going to cause problems.</p>
<p>I would go so far as to suggest multiple parents on processors and try to keep like jobs on the same core(s).</p>
</div>
<span class="comment-copy">Really a comment on the smoothspan quote: surely Python threading effectively limits you to one core, even if the machine has several? There may be benefits from multicore as the next thread can be ready to go without a context switch, but your Python threads can never make use of &gt;1 core at a time.</span>
<span class="comment-copy">Correct, python threads are practically limited to the one core, UNLESS a C module interacts nicely with the GIL, and runs it's own native thread.</span>
<span class="comment-copy">Actually, multiple cores make threads <i>less</i> efficient as there's a lot of churn with checking if each thread can access the GIL. Even wit the new GIL, performance is still worse... <a href="http://www.dabeaz.com/python/NewGIL.pdf" rel="nofollow noreferrer">dabeaz.com/python/NewGIL.pdf</a></span>
<span class="comment-copy">Please note that GIL considerations to not apply to all interpreters. As far as I am aware both IronPython and Jython function without a GIL, allowing their code to make more effective use of multi-processor hardware. As Arafangion mentioned, the CPython interpreter can also run properly multi-threaded if code that does not need access to Python data items releases the lock, then acquires it again before returning.</span>
<span class="comment-copy">What causes a context switch between the threads in Python? Is it based on timer interrupts? Blocking, or a specific yield call?</span>
<span class="comment-copy">@JS - Fixed.  That list was outdated anyway.</span>
<span class="comment-copy">It just feels wrong to me that you need multiple processes - with all the overhead that entails - to take advantage of a multi-core system. We've got some servers with 32 logical cores - so I need 32 processes to use them efficiently? Madness</span>
<span class="comment-copy">@Basic - The overhead in starting a process vs starting a thread these days is minimal.  I suppose you may start to see problems if we're talking about thousands of queries per second, but then I would question the choice of Python for such a busy service in the first place.</span>
