<div class="post-text" itemprop="text">
<p>please take a few time of you to help me. How can I use seek with wfile:</p>
<p><code>self.wfile = self.connection.makefile('wb', self.wbufsize)</code></p>
<p>My code look like this:</p>
<p><code>
self.wfile.seek(offset, 0)
self.wfile.write(r.data)
</code></p>
<p>But problem is, my ILDE show this error every time I try to run my code:
<code>self.wfile.seek(offset, 0)
io.UnsupportedOperation: seek
</code></p>
<p>I thought wfile and open are the same, but why I cannot seek like open ? Even if it is true, I still think there is a way to bypass this restrict.. </p>
<p>Note: If you at least one time hear about http.server or BaseHTTPServer you probably understood what wfile is.</p>
<p>EDIT: I edit my post to add my code, only a part of my full software, but this others part is not really needed:</p>
<pre><code>        self.send_response(200)
        self.end_headers()

        def accelerator(url=None, splitBy=3):


            def buildRange(url, numsplits):
                global globaldownloadersave
                value = int(self.pool.urlopen('HEAD', url).headers["content-length"])
                print("Fullsize: ", value)
                print("Try devide with :", value / numsplits)
                lst = []
                for i in range(numsplits):
                    if i == range(numsplits):
                        lst.append('%s-%s' % (i * value//numsplits + 1, i * value//numsplits + 1 + (value - (i * value//numsplits + 1))))
                    if i == 0:
                        lst.append('%s-%s' % (0, value//numsplits))
                    else:
                        lst.append('%s-%s' % (i * value//numsplits + 1, (i + 1) * value//numsplits))
                return lst
            def downloadChunk(idx, irange):
                global globaldownloadersave
                r = self.pool.urlopen('GET', url, headers={'Range': 'bytes=' + str(irange)})
                offset = int(re.sub("(^.*?)-(.*?)$", "\\1", irange))
                offset2 = int(re.sub("(^.*?)-(.*?)$", "\\2", irange))
                self.wfile.seek(offset, 0)
                self.wfile.write(r.data)

            #self.data = io.BytesIO(b'')
            ranges = buildRange(url, splitBy)
            tasks = []
            # create one downloading thread per chunk
            #q = queue.Queue()  big fail, so comment it
            downloaders = [
                threading.Thread(
                    target=downloadChunk, 
                    args=(idx, irange),
                )
                for idx,irange in enumerate(ranges)
                ]

            # start threads, let run in parallel, wait for all to finish
            for th in downloaders:
                th.start()

            for th in downloaders:
                th.join()

        accelerator(self.url, 4)
        self.close_connection = 1
        return
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A socket connection is a stream. Bytes once read from a stream are gone. So <code>seek</code> makes no sense. While it is possible to keep all read bytes in memory and simulate a <code>seek</code>, this is normally not preferred. Try to write your code without the need of <code>seek</code>.</p>
<p>EDIT: Didn't see it at first sight. You try to seek in a writing stream. This will be never possible, because you cannot say the receiving end "forget about all I've send, you get new data". If you really need that functionality you have to save the data locally in a normal file, and, when finished, send this file as one block to the client.</p>
</div>
<span class="comment-copy">what is <code>self.connection</code>? <code>wfile</code> is just a name that someone (you?) gave that of <code>self</code>, hence it's called <code>self.wfile</code>.</span>
<span class="comment-copy">Hi! self.connection.makefile is from SocketServer, this code will create a virtual file, it is wfile. <a href="https://docs.python.org/3/library/socket.html#socket.socket.makefile" rel="nofollow noreferrer">docs.python.org/3/library/socket.html#socket.socket.makefile</a></span>
<span class="comment-copy"><b>you</b> call that thing <code>wfile</code> in your own code.</span>
<span class="comment-copy">self.wfile is a _io.StringIO object which does have a seek method</span>
<span class="comment-copy">@Padraic Cunningham: So can I convert self.wfile to io.BytesIO or something like to have "seek" method ? Or any idea to solve this math ? Thanks!</span>
<span class="comment-copy">Okay, thank sir, I will try other way if I can figure something. I used seek method because of my threading knowledge was so bad, and I tried hundred time with threading but my result become worse and worse (threading block GIL so my code run slower)</span>
<span class="comment-copy">Thank you again, I figure something from your answer! But still I need to finish the remaining problem and I will post my solution!</span>
<span class="comment-copy">The GIL only blocks CPU-bound problems. Your problem is IO-bound, so the GIL shouldn't slow down anything.</span>
<span class="comment-copy">My threading knowledge is really bad at this time, so I think I really need your idea, so finally I think I will try to make my code run like this:  - threading will download 4 part of a random url (don't care much about this part) at the same time (using urllib.urlopen with Range header) - But if, for example thread number 2 finished download before thread number 1, thread number 2 will wait til thread number 1 finish and write (in my case is write data to self.wfile) and then thread number 2 will write, same with thread number 3 will wait thread 1, 2 and thread 4 will wait thread 1,2,3</span>
<span class="comment-copy">I tried queue library combine with threading already, but weird I got GIL problem (that mean my code download only one part of a given url one by one then write data to self.wfile one by one, not all part at the same time). Maybe I should use threading.Lock, will this bypass GIL problem ? To be honest threading.Lock look very complicated.</span>
