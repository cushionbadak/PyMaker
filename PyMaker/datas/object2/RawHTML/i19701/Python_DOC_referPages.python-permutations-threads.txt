<div class="post-text" itemprop="text">
<p>I have generated permutations with the itertools.permutations function in python. The problem is that the result is very big and I would like to go through it with multiple threads but don't really know how to accomplish that here is what I have so far:</p>
<pre><code>perms = itertools.permutations('1234', r=4)

#I would like to iterate through 'perms' with multiple threads
for perm in perms:
    print perm
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If the work you want to do with the items from the permutation generator is CPU intensive, you probably want to use processes rather than threads. CPython's Global Interpreter Lock (GIL) makes multithreading of limited value when doing CPU bound work.</p>
<p>Instead, use the <a href="http://docs.python.org/3/library/multiprocessing.html" rel="nofollow"><code>multiprocessing</code></a> module's <code>Pool</code> class, like so:</p>
<pre><code>import multiprocessing
import itertools

def do_stuff(perm):
    # whatever
    return list(reversed(perm))

if __name__ == "__main__":
    with multiprocessing.Pool() as pool: # default is optimal number of processes
        results = pool.map(do_stuff, itertools.permutations('1234', r=4))

        # do stuff with results
</code></pre>
<p>Note that if you will be iterating over <code>results</code> (rather than doing something with it as a list), you can use <code>imap</code> instead of <code>map</code> to get an iterator that you can use to work on the results as they are produced from the worker processes. If it doesn't matter what order the items are returned, you can use <code>imap_unordered</code> to (I think) save a bit of memory.</p>
<p>The <code>if __name__ is "__main__"</code> boilerplate is required on Windows, where the <code>multiprocessing</code> module has to work around the OS's limitations (no <code>fork</code>).</p>
</div>
<div class="post-text" itemprop="text">
<p>Split the <em>index</em> of the number of perms between threads then use <a href="https://stackoverflow.com/questions/12884428/generate-sample-of-1-000-000-random-permutations/13056801#13056801">this function</a> to generate the perm from its index in each thread rather than generating all the perms and splitting them between threads.</p>
</div>
<div class="post-text" itemprop="text">
<p>Assuming your processing function is f(x) you want to do</p>
<pre><code>from multiprocessing import Pool

def f(x):
    return x*x

if __name__ == '__main__':
    pool = Pool(processes=4)   # start 4 worker processes
    perms = itertools.permutations('1234', r=4)
    for r in pool.map(f, perms):
        print (r)  
</code></pre>
<p>In fact, using threads would not execute the processes in parallel, unless it is IO bound. If it is CPU bound and you have a quad core, then it's the way to go. If you don't have multicore and it is CPU bound, then I'm afraid that making it parallel will not improve your current situation.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python's <a href="http://docs.python.org/dev/library/concurrent.futures.html" rel="nofollow">futures</a> module makes it easy to split work between threads.  In this example, 4 threads will be used, but you can modify that to suit your needs.</p>
<pre><code>from concurrent import futures

def thread_process(perm):
    #do something

with futures.ThreadPoolExecutor(max_workers=4) as executor:
    for perm in perms:
        executor.submit(thread_process, perm)
</code></pre>
</div>
<span class="comment-copy">how do you want to split the data between threads? why do you want to use multiple thread ?</span>
<span class="comment-copy">I would like to split it evenly: if 'perms' contains 1'000'000 entries and I have 4 threads every thread should process 250'000 entries; If I only use one thread it takes about 10minutes to go through the entire entries therefore I would like to use more than one thread</span>
<span class="comment-copy">what is exactly your process, IO bound or CPU bound ?</span>
<span class="comment-copy">Are you using CPython or another version like jython, pypy?</span>
<span class="comment-copy">both I have to go through the entries and perform some operations on them and then write them into a file. The operations I am performing on the entries should be done by more than one thread</span>
<span class="comment-copy">the problem with using threading is that it will not do what the OP wants as because of the GIL it does not execute in parallel</span>
<span class="comment-copy">I don't see where he says what he means by "go through with multiple threads" - he could be doing anything from executing another process to making socket / file calls which block threads.  In these scenarios the GIL won't cause a problem.  I agree that it certainly depends what he wants to do.</span>
