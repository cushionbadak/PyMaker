<div class="post-text" itemprop="text">
<p>I'm working on a small program that collects certain data and processes it. Currently, the program runs constantly on my server, storing the data to the disk. Every once in a while I run another program that reads the stored data, processes it, sorts it, saves it to a new location, and clears the old data files.</p>
<p>I've never learned about threads, but it SOUNDS like this is a good place to use them? If threading works the way I think it does, I could set up a queue to hold the data, and have a separate thread that could pull data from the queue and process it as it's ready. If the queue is full, thread1 could sleep for a bit. If it's empty, thread2 could sleep for a bit</p>
<p>That would reduce disk writing, get rid of disk reading, and make the data collection run side-by-side with the data processing to save time.</p>
<p>Is any of this accurate? I'm a senior CS student and threads have never once come up (Surely that's a little odd?). I would appreciate any tips/knowledge/advice with using threads, as well as if this is the correct solution to my "problem".</p>
<p>Thanks!</p>
</div>
<div class="post-text" itemprop="text">
<p>That does sound like a situation where some form of parallelism might be useful. However, since this is Python, you might not want to actually use threads. Python, in the standard implementation, has something called the Global Interpreter Lock. Effectively, to allow the garbage collector to work, only one thread of a Python program can actually be running Python code at any time (modules written directly in C, or external operations such as disk IO or database queries, are not "running Python code" for this purpose, though you will have called them from Python).</p>
<p>Because of this, threading in Python is generally only a good idea if your Python code spends significant amounts of time waiting on responses from non-Python parts of the program, or external sources. If the data collection or processing is being done outside Python (collecting from a database or website, processing in numpy, etc.), that might be reasonable. If your code isn't in this situation often enough, your program ends up wasting more time switching between threads than it gains (because if two threads are both in Python code it still only runs one at a time)</p>
<p>If not, you should try the <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing" rel="nofollow"><code>multiprocessing</code></a> module instead. This is also a generally safer model, as the only things that can be shared between processes in multiprocessing are the things you explicitly share (while threads share all state, potentially allowing one thread to break another because you forgot to lock something).</p>
<p>Alternately, you might use <a href="https://docs.python.org/3/library/subprocess.html" rel="nofollow"><code>subprocess</code></a>. Effectively, this would be having your first program intermittently restart the second one every time it finishes a batch of data.</p>
</div>
<span class="comment-copy">You have to be careful about the timing there. Otherwise they will both just end up empty and sleeping. You could use threads but considering that it's one workflow I don't know if it would help you. Are you hitting a performance issue?</span>
<span class="comment-copy">No performance issues here. I mainly am looking at it from a learning perspective. I want to learn about using multiple threads, but also learning to use them effectively and when to just leave them out.</span>
<span class="comment-copy">Sure but keep in mind that untill the data is stored on the disk, it is in danger of being lost in case of an unexpected error or perhaps an electrical black out...</span>
<span class="comment-copy">So, without going into great detail because there are lots of resources online discussing exactly this, threads are used when you want parts of your program to run at the same time. For example, if you run a program that as a basic user interface and it loads a large file in the same thread, the UI will become unresponsive while the file loads. Run them in threads and the UI can function while the file loads. Threads add a layer of complexity that is mitigated with practice. But you have to access yourself, is any of this stuff I want to happen at the same time? In this use case probably not.</span>
<span class="comment-copy">Oh nice, I like the idea of subprocess, thanks! Also, multiprocessing sounds worth a look. The data collection part does crawl websites, I'm with you guys - multithreading doesn't sound like the best fit.  After it collects the data, it processes it and uses the results in order to collect the next batch of data, which is then processed, and the cycle keeps going. They don't have to be in perfect sync and can have overlap. I may use subprocess and execute the second program every few hours.  Thanks!</span>
