<div class="post-text" itemprop="text">
<p>I have some kind of test data and want to create a unit test for each item. My first idea was to do it like this:</p>
<pre><code>import unittest

l = [["foo", "a", "a",], ["bar", "a", "b"], ["lee", "b", "b"]]

class TestSequence(unittest.TestCase):
    def testsample(self):
        for name, a,b in l:
            print "test", name
            self.assertEqual(a,b)

if __name__ == '__main__':
    unittest.main()
</code></pre>
<p>The downside of this is that it handles all data in one test. I would like to generate one test for each item on the fly. Any suggestions?</p>
</div>
<div class="post-text" itemprop="text">
<p>i use something like this:</p>
<pre><code>import unittest

l = [["foo", "a", "a",], ["bar", "a", "b"], ["lee", "b", "b"]]

class TestSequense(unittest.TestCase):
    pass

def test_generator(a, b):
    def test(self):
        self.assertEqual(a,b)
    return test

if __name__ == '__main__':
    for t in l:
        test_name = 'test_%s' % t[0]
        test = test_generator(t[1], t[2])
        setattr(TestSequense, test_name, test)
    unittest.main()
</code></pre>
<p>The <a href="https://github.com/wolever/parameterized" rel="noreferrer"><code>parameterized</code></a> package can be used to automate this process:</p>
<pre><code>from parameterized import parameterized

class TestSequence(unittest.TestCase):
    @parameterized.expand([
        ["foo", "a", "a",],
        ["bar", "a", "b"],
        ["lee", "b", "b"],
    ])
    def test_sequence(self, name, a, b):
        self.assertEqual(a,b)
</code></pre>
<p>Which will generate the tests:</p>
<pre><code>test_sequence_0_foo (__main__.TestSequence) ... ok
test_sequence_1_bar (__main__.TestSequence) ... FAIL
test_sequence_2_lee (__main__.TestSequence) ... ok

======================================================================
FAIL: test_sequence_1_bar (__main__.TestSequence)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/site-packages/parameterized/parameterized.py", line 233, in &lt;lambda&gt;
    standalone_func = lambda *a: func(*(a + p.args), **p.kwargs)
  File "x.py", line 12, in test_sequence
    self.assertEqual(a,b)
AssertionError: 'a' != 'b'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><strong>Using unittest (since 3.4)</strong></p>
<p>Since Python 3.4, the standard library <code>unittest</code> package has the <code>subTest</code> context manager.</p>
<p>See the documentation:</p>
<ul>
<li><a href="https://docs.python.org/3/library/unittest.html#distinguishing-test-iterations-using-subtests" rel="noreferrer">26.4.7. Distinguishing test iterations using subtests</a></li>
<li><a href="https://docs.python.org/3/library/unittest.html#unittest.TestCase.subTest" rel="noreferrer">subTest</a></li>
</ul>
<p>Example:</p>
<pre><code>from unittest import TestCase

param_list = [('a', 'a'), ('a', 'b'), ('b', 'b')]

class TestDemonstrateSubtest(TestCase):
    def test_works_as_expected(self):
        for p1, p2 in param_list:
            with self.subTest():
                self.assertEqual(p1, p2)
</code></pre>
<p>You can also specify a custom message and parameter values to <code>subTest()</code>:</p>
<pre><code>with self.subTest(msg="Checking if p1 equals p2", p1=p1, p2=p2):
</code></pre>
<p><strong>Using nose</strong></p>
<p>The <a href="https://nose.readthedocs.org/en/latest/" rel="noreferrer">nose</a> testing framework <a href="https://nose.readthedocs.org/en/latest/writing_tests.html#test-generators" rel="noreferrer">supports this</a>. </p>
<p>Example (the code below is the entire contents of the file containing the test):</p>
<pre><code>param_list = [('a', 'a'), ('a', 'b'), ('b', 'b')]

def test_generator():
    for params in param_list:
        yield check_em, params[0], params[1]

def check_em(a, b):
    assert a == b
</code></pre>
<p>The output of the nosetests command:</p>
<pre><code>&gt; nosetests -v
testgen.test_generator('a', 'a') ... ok
testgen.test_generator('a', 'b') ... FAIL
testgen.test_generator('b', 'b') ... ok

======================================================================
FAIL: testgen.test_generator('a', 'b')
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/usr/lib/python2.5/site-packages/nose-0.10.1-py2.5.egg/nose/case.py", line 203, in runTest
    self.test(*self.arg)
  File "testgen.py", line 7, in check_em
    assert a == b
AssertionError

----------------------------------------------------------------------
Ran 3 tests in 0.006s

FAILED (failures=1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This can be solved elegantly using Metaclasses:</p>
<pre><code>import unittest

l = [["foo", "a", "a",], ["bar", "a", "b"], ["lee", "b", "b"]]

class TestSequenceMeta(type):
    def __new__(mcs, name, bases, dict):

        def gen_test(a, b):
            def test(self):
                self.assertEqual(a, b)
            return test

        for tname, a, b in l:
            test_name = "test_%s" % tname
            dict[test_name] = gen_test(a,b)
        return type.__new__(mcs, name, bases, dict)

class TestSequence(unittest.TestCase):
    __metaclass__ = TestSequenceMeta

if __name__ == '__main__':
    unittest.main()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>As of Python 3.4 subtests have been introduced to unittest for this purpose. See <a href="https://docs.python.org/3/library/unittest.html#distinguishing-test-iterations-using-subtests" rel="nofollow noreferrer">the documentation</a> for details. TestCase.subTest is a context manager which allows one to isolate asserts in a test so that a failure will be reported with parameter information but does not stop the test execution. Here's the example from the documentation:</p>
<pre><code>class NumbersTest(unittest.TestCase):

def test_even(self):
    """
    Test that numbers between 0 and 5 are all even.
    """
    for i in range(0, 6):
        with self.subTest(i=i):
            self.assertEqual(i % 2, 0)
</code></pre>
<p>The output of a test run would be:</p>
<pre><code>======================================================================
FAIL: test_even (__main__.NumbersTest) (i=1)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "subtests.py", line 32, in test_even
    self.assertEqual(i % 2, 0)
AssertionError: 1 != 0

======================================================================
FAIL: test_even (__main__.NumbersTest) (i=3)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "subtests.py", line 32, in test_even
    self.assertEqual(i % 2, 0)
AssertionError: 1 != 0

======================================================================
FAIL: test_even (__main__.NumbersTest) (i=5)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "subtests.py", line 32, in test_even
    self.assertEqual(i % 2, 0)
AssertionError: 1 != 0
</code></pre>
<p>This is also part of <a href="https://pypi.python.org/pypi/unittest2" rel="nofollow noreferrer">unittest2</a>, so it is available for earlier versions of Python.</p>
</div>
<div class="post-text" itemprop="text">
<p><a href="https://docs.python.org/2/library/unittest.html#load-tests-protocol">load_tests</a> is a little known mechanism introduced in 2.7 to dynamically create a TestSuite. With it, you can easily create parametrized tests.</p>
<p>For example:</p>
<pre><code>import unittest

class GeneralTestCase(unittest.TestCase):
    def __init__(self, methodName, param1=None, param2=None):
        super(GeneralTestCase, self).__init__(methodName)

        self.param1 = param1
        self.param2 = param2

    def runTest(self):
        pass  # Test that depends on param 1 and 2.


def load_tests(loader, tests, pattern):
    test_cases = unittest.TestSuite()
    for p1, p2 in [(1, 2), (3, 4)]:
        test_cases.addTest(GeneralTestCase('runTest', p1, p2))
    return test_cases
</code></pre>
<p>That code will run all the TestCases in the TestSuite returned by load_tests. No other tests are automatically run by the discovery mechanism.</p>
<p>Alternatively, you can also use inheritance as shown in this ticket: <a href="http://bugs.python.org/msg151444">http://bugs.python.org/msg151444</a></p>
</div>
<div class="post-text" itemprop="text">
<p>It can be done by using <a href="http://pytest.org" rel="noreferrer">pytest</a>. Just write the file <code>test_me.py</code> with content:
</p>
<pre><code>import pytest

@pytest.mark.parametrize('name, left, right', [['foo', 'a', 'a'],
                                               ['bar', 'a', 'b'],
                                               ['baz', 'b', 'b']])
def test_me(name, left, right):
    assert left == right, name
</code></pre>
<p>And run your test with command <code>py.test --tb=short test_me.py</code>. Then the output will be looks like:
</p>
<pre><code>=========================== test session starts ============================
platform darwin -- Python 2.7.6 -- py-1.4.23 -- pytest-2.6.1
collected 3 items

test_me.py .F.

================================= FAILURES =================================
_____________________________ test_me[bar-a-b] _____________________________
test_me.py:8: in test_me
    assert left == right, name
E   AssertionError: bar
==================== 1 failed, 2 passed in 0.01 seconds ====================
</code></pre>
<p>It simple!. Also <a href="http://pytest.org" rel="noreferrer">pytest</a> has more features like <code>fixtures</code>, <code>mark</code>, <code>assert</code>, etc ...</p>
</div>
<div class="post-text" itemprop="text">
<p>Use the <a href="https://technomilk.wordpress.com/2012/02/12/multiplying-python-unit-test-cases-with-different-sets-of-data/" rel="noreferrer">ddt</a> library. It adds simple decorators for the test methods:</p>
<pre><code>import unittest
from ddt import ddt, data
from mycode import larger_than_two

@ddt
class FooTestCase(unittest.TestCase):

    @data(3, 4, 12, 23)
    def test_larger_than_two(self, value):
        self.assertTrue(larger_than_two(value))

    @data(1, -3, 2, 0)
    def test_not_larger_than_two(self, value):
        self.assertFalse(larger_than_two(value))
</code></pre>
<p>This library can be installed with <code>pip</code>. It doesn't require <code>nose</code>, and works excellent with the standard library <code>unittest</code> module.</p>
</div>
<div class="post-text" itemprop="text">
<p>You would benefit from trying the <a href="https://launchpad.net/testscenarios" rel="noreferrer">TestScenarios</a> library.</p>
<blockquote>
<p>testscenarios provides clean dependency injection for python unittest style tests. This can be used for interface testing (testing many implementations via a single test suite) or for classic dependency injection (provide tests with dependencies externally to the test code itself, allowing easy testing in different situations).</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>There's also Hypothesis which adds fuzz or property based testing: <a href="https://pypi.python.org/pypi/hypothesis" rel="noreferrer">https://pypi.python.org/pypi/hypothesis</a></p>
<p>This is a very powerful testing method.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://github.com/taykey/nose-ittr" rel="nofollow">nose-ittr</a> plugin (<code>pip install nose-ittr</code>).</p>
<p>It's very easy to integrate with existing tests, minimal changes (if any) are required. It also supports <em>nose</em> multiprocessing plugin.</p>
<p>Not that you can also have a customize <code>setup</code> function per test.</p>
<pre><code>@ittr(number=[1, 2, 3, 4])   
def test_even(self):   
    assert_equal(self.number % 2, 0)
</code></pre>
<p>It is also possible to pass <code>nosetest</code> parameters like with their build-in plugin <code>attrib</code>, this way you can run only a specific test with specific parameter:</p>
<pre><code>nosetest -a number=2
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I came across <a href="https://pypi.python.org/pypi/ParamUnittest" rel="nofollow"><strong>ParamUnittest</strong></a> the other day when looking at the source code to <a href="https://pypi.python.org/pypi/radon" rel="nofollow">radon</a> (<a href="https://github.com/rubik/radon/blob/master/radon/tests/test_other_metrics.py" rel="nofollow">example usage on the github repo</a>). It should work with other frameworks that extend TestCase (like Nose).</p>
<p>Here is an example:</p>
<pre><code>import unittest
import paramunittest


@paramunittest.parametrized(
    ('1', '2'),
    #(4, 3),    &lt;---- uncomment to have a failing test
    ('2', '3'),
    (('4', ), {'b': '5'}),
    ((), {'a': 5, 'b': 6}),
    {'a': 5, 'b': 6},
)
class TestBar(TestCase):
    def setParameters(self, a, b):
        self.a = a
        self.b = b

    def testLess(self):
        self.assertLess(self.a, self.b)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I use metaclasses and decorators for generate tests. You can check my implementation <a href="https://github.com/erm0l0v/python_wrap_cases" rel="nofollow">python_wrap_cases</a>. This library doesn't require any test frameworks.</p>
<p>Your example:</p>
<pre><code>import unittest
from python_wrap_cases import wrap_case


@wrap_case
class TestSequence(unittest.TestCase):

    @wrap_case("foo", "a", "a")
    @wrap_case("bar", "a", "b")
    @wrap_case("lee", "b", "b")
    def testsample(self, name, a, b):
        print "test", name
        self.assertEqual(a, b)
</code></pre>
<p>Console output:</p>
<pre><code>testsample_u'bar'_u'a'_u'b' (tests.example.test_stackoverflow.TestSequence) ... test bar
FAIL
testsample_u'foo'_u'a'_u'a' (tests.example.test_stackoverflow.TestSequence) ... test foo
ok
testsample_u'lee'_u'b'_u'b' (tests.example.test_stackoverflow.TestSequence) ... test lee
ok
</code></pre>
<p>Also you may use <em>generators</em>. For example this code generate all possible combinations of tests with arguments <code>a__list</code> and <code>b__list</code></p>
<pre><code>import unittest
from python_wrap_cases import wrap_case


@wrap_case
class TestSequence(unittest.TestCase):

    @wrap_case(a__list=["a", "b"], b__list=["a", "b"])
    def testsample(self, a, b):
        self.assertEqual(a, b)
</code></pre>
<p>Console output:</p>
<pre><code>testsample_a(u'a')_b(u'a') (tests.example.test_stackoverflow.TestSequence) ... ok
testsample_a(u'a')_b(u'b') (tests.example.test_stackoverflow.TestSequence) ... FAIL
testsample_a(u'b')_b(u'a') (tests.example.test_stackoverflow.TestSequence) ... FAIL
testsample_a(u'b')_b(u'b') (tests.example.test_stackoverflow.TestSequence) ... ok
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just use metaclasses, as seen here;</p>
<pre><code>class DocTestMeta(type):
    """
    Test functions are generated in metaclass due to the way some
    test loaders work. For example, setupClass() won't get called
    unless there are other existing test methods, and will also
    prevent unit test loader logic being called before the test
    methods have been defined.
    """
    def __init__(self, name, bases, attrs):
        super(DocTestMeta, self).__init__(name, bases, attrs)

    def __new__(cls, name, bases, attrs):
        def func(self):
            """Inner test method goes here"""
            self.assertTrue(1)

        func.__name__ = 'test_sample'
        attrs[func.__name__] = func
        return super(DocTestMeta, cls).__new__(cls, name, bases, attrs)

class ExampleTestCase(TestCase):
    """Our example test case, with no methods defined"""
    __metaclass__ = DocTestMeta
</code></pre>
<p>Output:</p>
<pre><code>test_sample (ExampleTestCase) ... OK
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import unittest

def generator(test_class, a, b):
    def test(self):
        self.assertEqual(a, b)
    return test

def add_test_methods(test_class):
    #First element of list is variable "a", then variable "b", then name of test case that will be used as suffix.
    test_list = [[2,3, 'one'], [5,5, 'two'], [0,0, 'three']]
    for case in test_list:
        test = generator(test_class, case[0], case[1])
        setattr(test_class, "test_%s" % case[2], test)


class TestAuto(unittest.TestCase):
    def setUp(self):
        print 'Setup'
        pass

    def tearDown(self):
        print 'TearDown'
        pass

_add_test_methods(TestAuto)  # It's better to start with underscore so it is not detected as a test itself

if __name__ == '__main__':
    unittest.main(verbosity=1)
</code></pre>
<p>RESULT:</p>
<pre><code>&gt;&gt;&gt; 
Setup
FTearDown
Setup
TearDown
.Setup
TearDown
.
======================================================================
FAIL: test_one (__main__.TestAuto)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "D:/inchowar/Desktop/PyTrash/test_auto_3.py", line 5, in test
    self.assertEqual(a, b)
AssertionError: 2 != 3

----------------------------------------------------------------------
Ran 3 tests in 0.019s

FAILED (failures=1)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <code>TestSuite</code> and custom <code>TestCase</code> classes. </p>
<pre><code>import unittest

class CustomTest(unittest.TestCase):
    def __init__(self, name, a, b):
        super().__init__()
        self.name = name
        self.a = a
        self.b = b

    def runTest(self):
        print("test", self.name)
        self.assertEqual(self.a, self.b)

if __name__ == '__main__':
    suite = unittest.TestSuite()
    suite.addTest(CustomTest("Foo", 1337, 1337))
    suite.addTest(CustomTest("Bar", 0xDEAD, 0xC0DE))
    unittest.TextTestRunner().run(suite)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I'd been having trouble with a very particular style of parameterized tests.  All our Selenium tests can run locally, but they also should be able to be run remotely against several platforms on SauceLabs.  Basically, I wanted to take a large amount of already-written test cases and parameterize them with the fewest changes to code possible.  Furthermore, I needed to be able to pass the parameters into the setUp method, something which I haven't seen any solutions for elsewhere.</p>
<p>Here's what I've come up with:</p>
<pre><code>import inspect
import types

test_platforms = [
    {'browserName': "internet explorer", 'platform': "Windows 7", 'version': "10.0"},
    {'browserName': "internet explorer", 'platform': "Windows 7", 'version': "11.0"},
    {'browserName': "firefox", 'platform': "Linux", 'version': "43.0"},
]


def sauce_labs():
    def wrapper(cls):
        return test_on_platforms(cls)
    return wrapper


def test_on_platforms(base_class):
    for name, function in inspect.getmembers(base_class, inspect.isfunction):
        if name.startswith('test_'):
            for platform in test_platforms:
                new_name = '_'.join(list([name, ''.join(platform['browserName'].title().split()), platform['version']]))
                new_function = types.FunctionType(function.__code__, function.__globals__, new_name,
                                                  function.__defaults__, function.__closure__)
                setattr(new_function, 'platform', platform)
                setattr(base_class, new_name, new_function)
            delattr(base_class, name)

    return base_class
</code></pre>
<p>With this, all I had to do was add a simple decorator @sauce_labs() to each regular old TestCase, and now when running them, they're wrapped up and rewritten, so that all the test methods are parameterized and renamed.  LoginTests.test_login(self) runs as LoginTests.test_login_internet_explorer_10.0(self), LoginTests.test_login_internet_explorer_11.0(self), and LoginTests.test_login_firefox_43.0(self), and each one has the parameter self.platform to decide what browser/platform to run against, even in LoginTests.setUp, which is crucial for my task since that's where the connection to SauceLabs is initialized.</p>
<p>Anyway, I hope this might be of help to someone looking to do a similar "global" parameterization of their tests!</p>
</div>
<div class="post-text" itemprop="text">
<p>This solution works with <code>unittest</code> and <code>nose</code>:</p>
<pre><code>#!/usr/bin/env python
import unittest

def make_function(description, a, b):
    def ghost(self):
        self.assertEqual(a, b, description)
    print description
    ghost.__name__ = 'test_{0}'.format(description)
    return ghost


class TestsContainer(unittest.TestCase):
    pass

testsmap = {
    'foo': [1, 1],
    'bar': [1, 2],
    'baz': [5, 5]}

def generator():
    for name, params in testsmap.iteritems():
        test_func = make_function(name, params[0], params[1])
        setattr(TestsContainer, 'test_{0}'.format(name), test_func)

generator()

if __name__ == '__main__':
    unittest.main()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The metaclass-based answers still work in Python3, but instead of the <code>__metaclass__</code> attribute one has to use the <code>metaclass</code> parameter, as in:</p>
<pre><code>class ExampleTestCase(TestCase,metaclass=DocTestMeta):
    pass
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Meta-programming is fun, but can get on the way. Most solutions here make it difficult to:</p>
<ul>
<li>selectively launch a test</li>
<li>point back to the code given test's name</li>
</ul>
<p>So, my first suggestion is to follow the simple/explicit path (works with any test runner):</p>
<pre><code>import unittest

class TestSequence(unittest.TestCase):

    def _test_complex_property(self, a, b):
        self.assertEqual(a,b)

    def test_foo(self):
        self._test_complex_property("a", "a")
    def test_bar(self):
        self._test_complex_property("a", "b")
    def test_lee(self):
        self._test_complex_property("b", "b")

if __name__ == '__main__':
    unittest.main()
</code></pre>
<p>Since we shouldn't repeat ourselves, my second suggestion builds on @Javier's answer: embrace property based testing. Hypothesis library:</p>
<ul>
<li>is "more relentlessly devious about test case generation than us mere humans"</li>
<li>will provide simple count-examples</li>
<li>works with any test runner</li>
<li><p>has many more interesting features (statistics, additional test output, ...)</p>
<p>class TestSequence(unittest.TestCase):</p>
<pre><code>@given(st.text(), st.text())
def test_complex_property(self, a, b):
    self.assertEqual(a,b)
</code></pre></li>
</ul>
<p>To test your specific examples, just add:</p>
<pre><code>    @example("a", "a")
    @example("a", "b")
    @example("b", "b")
</code></pre>
<p>To run only one particular example, you can comment out the other examples (provided example will be run first). You may want to use <code>@given(st.nothing())</code>. Another option is to replace the whole block by:</p>
<pre><code>    @given(st.just("a"), st.just("b"))
</code></pre>
<p>Ok, you don't have distinct test names. But maybe you just need:</p>
<ul>
<li>a descriptive name of the property under test.</li>
<li>which input leads to failure (falsifying example).</li>
</ul>
<p><a href="http://hypothesis.works/articles/how-not-to-die-hard-with-hypothesis" rel="nofollow noreferrer">Funnier example</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Super late to the party, but I had trouble making these work for <code>setUpClass</code>.</p>
<p>Here's a version of <a href="https://stackoverflow.com/a/23508426/5932228">@Javier's answer</a> that gives <code>setUpClass</code> access to dynamically allocated attributes.</p>
<pre><code>import unittest


class GeneralTestCase(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        print ''
        print cls.p1
        print cls.p2

    def runTest1(self):
        self.assertTrue((self.p2 - self.p1) == 1)

    def runTest2(self):
        self.assertFalse((self.p2 - self.p1) == 2)


def load_tests(loader, tests, pattern):
    test_cases = unittest.TestSuite()
    for p1, p2 in [(1, 2), (3, 4)]:
        clsname = 'TestCase_{}_{}'.format(p1, p2)
        dct = {
            'p1': p1,
            'p2': p2,
        }
        cls = type(clsname, (GeneralTestCase,), dct)
        test_cases.addTest(cls('runTest1'))
        test_cases.addTest(cls('runTest2'))
    return test_cases
</code></pre>
<p>Outputs</p>
<pre><code>1
2
..
3
4
..
----------------------------------------------------------------------
Ran 4 tests in 0.000s

OK
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Besides using setattr, we can use load_tests since python 3.2. Please refer to blog post <a href="http://blog.livreuro.com/en/coding/python/how-to-generate-discoverable-unit-tests-in-python-dynamically/" rel="nofollow">blog.livreuro.com/en/coding/python/how-to-generate-discoverable-unit-tests-in-python-dynamically/</a></p>
<pre><code>class Test(unittest.TestCase):
    pass

def _test(self, file_name):
    open(file_name, 'r') as f:
        self.assertEqual('test result',f.read())

def _generate_test(file_name):
    def test(self):
        _test(self, file_name)
    return test

def _generate_tests():
    for file in files:
        file_name = os.path.splitext(os.path.basename(file))[0]
        setattr(Test, 'test_%s' % file_name, _generate_test(file))

test_cases = (Test,)

def load_tests(loader, tests, pattern):
    _generate_tests()
    suite = TestSuite()
    for test_class in test_cases:
        tests = loader.loadTestsFromTestCase(test_class)
        suite.addTests(tests)
    return suite

if __name__ == '__main__':
    _generate_tests()
    unittest.main()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Following is my solution. I find this useful when:
1. Should work for unittest.Testcase and unittest discover
2. Have a set of tests to be run for different parameter settings.
3. Very simple no dependency on other packages
        import unittest</p>
<pre><code>    class BaseClass(unittest.TestCase):
        def setUp(self):
            self.param = 2
            self.base = 2

        def test_me(self):
            self.assertGreaterEqual(5, self.param+self.base)

        def test_me_too(self):
            self.assertLessEqual(3, self.param+self.base)



     class Child_One(BaseClass):
        def setUp(self):
            BaseClass.setUp(self)
            self.param = 4


     class Child_Two(BaseClass):
        def setUp(self):
            BaseClass.setUp(self)
            self.param = 1
</code></pre>
</div>
<span class="comment-copy">possible duplicate of <a href="http://stackoverflow.com/questions/2798956/python-unittest-generate-multiple-tests-programmatically">Python unittest: Generate multiple tests programmatically?</a></span>
<span class="comment-copy">A good link that may provide an answer: <a href="http://eli.thegreenplace.net/2014/04/02/dynamically-generating-python-test-cases" rel="nofollow noreferrer">eli.thegreenplace.net/2014/04/02/…</a></span>
<span class="comment-copy">Actually, bignose, this code DOES generate a different name for each test (it actually wouldn't work otherwise). In the example given the tests executed will be named "test_foo", "test_bar", and "test_lee" respectively. Thus the benefit you mention (and it is a big one) is preserved as long as you generate sensible names.</span>
<span class="comment-copy">As the answer given by @codeape states, nose handles this. However, nose does not seem to handle Unicode; therefore for me this is a preferable solution. +1</span>
<span class="comment-copy">So note, that more proper answer is given in the <i>duplicate</i> question: <a href="http://stackoverflow.com/a/2799009/322020">stackoverflow.com/a/2799009/322020</a> - you have use to <code>.__name__ =</code> to enable <i><code>.exact_method</code></i> testing</span>
<span class="comment-copy">Why does the code modifying the class appear in the <code>if __name__ == '__main__'</code> conditional? Surely it should go outside this to run at import time (remembering that python modules are only imported once even if imported from several different places)</span>
<span class="comment-copy">I don't think this is a good solution. The code of a unittest should not depend on the way it gets called. The TestCase should be useable in nose or pytest or a different test environment.</span>
<span class="comment-copy">That's a very clean way to dynamically generate test cases.</span>
<span class="comment-copy">But be aware, 'setup()' will not know what variables are being used as arguments to yield. Actually setup() won't know what test is running, or vars set inside test_generator().  This complicates sanity checking within setup(), and it's one of the reasons that some folks prefer py.test.</span>
<span class="comment-copy">This works! but then you can not use unittest.TestCase and its assert* method families.</span>
<span class="comment-copy">Actually, you can. I had a look at the unittest docs and this was added in 3.4 (I've updated the answer with a code example).</span>
<span class="comment-copy">Upvoted for the update section. Exactly what I needed. :)</span>
<span class="comment-copy">This worked GREAT for me with Selenium. As a note, in the class TestSequence, you can define "static" methods like setUp(self), is_element_present(self, how, what), ... tearDown(self). Putting them AFTER the "<b>metaclass</b> = TestSequenceMeta" statement seems to work.</span>
<span class="comment-copy">This solution is better than the one selected as accepted IMHO.</span>
<span class="comment-copy">Can you perhaps clarify why this does not work when just overriding <code>__new__</code> from <code>TestSequence</code> class (and thus skip the metaclass altogether)?</span>
<span class="comment-copy">@petroslamb The <code>__new__</code> method in the metaclass gets called when the class itself is defined, not when the first instance is created. I would imagine this method of dynamically creating test methods is more compatible with the introspection used by <code>unittest</code> to determine how many tests are in a class (i.e. it may compile the list of tests before it ever creates an instance of that class).</span>
<span class="comment-copy">Note: in python 3, change this to: <code>class TestSequence(unittest.TestCase, metaclass=TestSequenceMeta):[...]</code></span>
<span class="comment-copy">The best solution if you use python 3.4 and higher.</span>
<span class="comment-copy">Using unittest2, this is also available for Python 2.7.</span>
<span class="comment-copy">One major difference between this approach and having separate tests is that the test state isn't reset each time. (That is, <code>setUp()</code> and <code>tearDown()</code> aren't run between the sub-tests.)</span>
<span class="comment-copy">@KevinChristopherHenry Yes, but <code>self.setUp()</code> can in theory be called manually from within the subtest. As for <code>tearDown</code>, having it called automatically at the end might suffice.</span>
<span class="comment-copy">The code above fails: TypeError: __init__() takes at most 2 arguments (4 given)</span>
<span class="comment-copy">Added null defaults to the constructor extra parameters.</span>
<span class="comment-copy">I prefer the nose-parameterize code in <a href="http://stackoverflow.com/a/32939/527489">@mojo's answer</a>, but for my clients it's just too useful to avoid an extra dependency so I'll be using this for them.</span>
<span class="comment-copy">The client is always right! :p</span>
<span class="comment-copy">bonus: ability to redefine shortDescription method for output passed in params</span>
<span class="comment-copy">I was looking for a simple, straight forward example how to parametrize test cases with py.test. Thank you very much!</span>
<span class="comment-copy">@timgeb I'm glad to help you. Check <a href="http://stackoverflow.com/questions/tagged/py.test">py.test</a> tag, for more examples. Also I suggest to use <a href="https://github.com/hamcrest/PyHamcrest" rel="nofollow noreferrer">hamcrest</a> for adding some sugar into your asserts with human readable mutchers, which can be modified, combined or created by your own way. Plus we have <a href="https://github.com/allure-framework/allure-python" rel="nofollow noreferrer">allure-python</a>, a nice looking report generation for <code>py.test</code></span>
<span class="comment-copy">Thanks. I just started moving from <code>unittest</code> to py.test. I used to have <code>TestCase</code> base classes that were able to dynamically create children with different arguments which they would store as class variables... which was a bit unwieldy.</span>
<span class="comment-copy">@timgeb Yep you are right. The most <i>killer feature</i> of <code>py.test</code> is <a href="https://pytest.org/latest/yieldfixture.html" rel="nofollow noreferrer">yield_fixtures</a>. Which can do <i>setup</i>, return some useful data into test and after test ends make <i>teardown</i>. Fixtures can also be <a href="https://pytest.org/latest/example/parametrize.html#apply-indirect-on-particular-arguments" rel="nofollow noreferrer">parametirized</a>.</span>
<span class="comment-copy">I couldn't use <code>@given()</code> macro inside the unittest class.</span>
<span class="comment-copy">Check this out: <a href="https://hypothesis.readthedocs.io/en/master/quickstart.html#running-tests" rel="nofollow noreferrer">hypothesis.readthedocs.io/en/master/…</a></span>
<span class="comment-copy">I like this approach, especially the per method level it supports.</span>
<span class="comment-copy">Minor problem with your <code>def add_test_methods</code> function. Should be <code>def _add_test_methods </code> I think</span>
<span class="comment-copy">@Raychaser...You are correct..I fixed that but did not update it here....Thanks for catching that.</span>
<span class="comment-copy">While the TestSuite works, the arguments are not passed down to <code>__init__</code> function.</span>
<span class="comment-copy">Why the down vote?</span>
<span class="comment-copy">This doesn't answer the question, which is about generating tests on the fly.</span>
