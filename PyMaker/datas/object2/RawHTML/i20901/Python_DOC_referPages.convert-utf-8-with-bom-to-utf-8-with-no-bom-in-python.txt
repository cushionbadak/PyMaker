<div class="post-text" itemprop="text">
<p>Two questions here. I have a set of files which are usually UTF-8 with BOM. I'd like to convert them (ideally in place) to UTF-8 with no BOM. It seems like <code>codecs.StreamRecoder(stream, encode, decode, Reader, Writer, errors)</code> would handle this. But I don't really see any good examples on usage. Would this be the best way to handle this?  </p>
<pre><code>source files:
Tue Jan 17$ file brh-m-157.json 
brh-m-157.json: UTF-8 Unicode (with BOM) text
</code></pre>
<p>Also, it would be ideal if we could handle different input encoding wihtout explicitly knowing (seen ASCII and UTF-16). It seems like this should all be feasible. Is there a solution that can take any known Python encoding and output as UTF-8 without BOM?</p>
<p><strong>edit 1</strong>  proposed sol'n from below (thanks!)</p>
<pre><code>fp = open('brh-m-157.json','rw')
s = fp.read()
u = s.decode('utf-8-sig')
s = u.encode('utf-8')
print fp.encoding  
fp.write(s)
</code></pre>
<p>This gives me the following error:  </p>
<pre><code>IOError: [Errno 9] Bad file descriptor
</code></pre>
<h3>Newsflash</h3>
<p>I'm being told in comments that the mistake is I open the file with mode 'rw' instead of 'r+'/'r+b', so I should eventually re-edit my question and remove the solved part.</p>
</div>
<div class="post-text" itemprop="text">
<p>Simply use the <a href="https://docs.python.org/3/library/codecs.html#module-encodings.utf_8_sig" rel="noreferrer">"utf-8-sig" codec</a>:</p>
<pre><code>fp = open("file.txt")
s = fp.read()
u = s.decode("utf-8-sig")
</code></pre>
<p>That gives you a <code>unicode</code> string without the BOM. You can then use</p>
<pre><code>s = u.encode("utf-8")
</code></pre>
<p>to get a normal UTF-8 encoded string back in <code>s</code>. If your files are big, then you should avoid reading them all into memory. The BOM is simply three bytes at the beginning of the file, so you can use this code to strip them out of the file:</p>
<pre><code>import os, sys, codecs

BUFSIZE = 4096
BOMLEN = len(codecs.BOM_UTF8)

path = sys.argv[1]
with open(path, "r+b") as fp:
    chunk = fp.read(BUFSIZE)
    if chunk.startswith(codecs.BOM_UTF8):
        i = 0
        chunk = chunk[BOMLEN:]
        while chunk:
            fp.seek(i)
            fp.write(chunk)
            i += len(chunk)
            fp.seek(BOMLEN, os.SEEK_CUR)
            chunk = fp.read(BUFSIZE)
        fp.seek(-BOMLEN, os.SEEK_CUR)
        fp.truncate()
</code></pre>
<p>It opens the file, reads a chunk, and writes it out to the file 3 bytes earlier than where it read it. The file is rewritten in-place. As easier solution is to write the shorter file to a new file like <a href="https://stackoverflow.com/a/8898682/110204">newtover's answer</a>. That would be simpler, but use twice the disk space for a short period.</p>
<p>As for guessing the encoding, then you can just loop through the encoding from most to least specific:</p>
<pre><code>def decode(s):
    for encoding in "utf-8-sig", "utf-16":
        try:
            return s.decode(encoding)
        except UnicodeDecodeError:
            continue
    return s.decode("latin-1") # will always work
</code></pre>
<p>An UTF-16 encoded file wont decode as UTF-8, so we try with UTF-8 first. If that fails, then we try with UTF-16. Finally, we use Latin-1 — this will always work since all 256 bytes are legal values in Latin-1. You may want to return <code>None</code> instead in this case since it's really a fallback and your code might want to handle this more carefully (if it can).</p>
</div>
<div class="post-text" itemprop="text">
<p>In Python 3 it's quite easy: read the file and rewrite it with <code>utf-8</code> encoding:</p>
<pre><code>s = open(bom_file, mode='r', encoding='utf-8-sig').read()
open(bom_file, mode='w', encoding='utf-8').write(s)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import codecs
import shutil
import sys

s = sys.stdin.read(3)
if s != codecs.BOM_UTF8:
    sys.stdout.write(s)

shutil.copyfileobj(sys.stdin, sys.stdout)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is my implementation to convert any kind of encoding to UTF-8 without BOM and replacing windows enlines by universal format:</p>
<pre><code>def utf8_converter(file_path, universal_endline=True):
    '''
    Convert any type of file to UTF-8 without BOM
    and using universal endline by default.

    Parameters
    ----------
    file_path : string, file path.
    universal_endline : boolean (True),
                        by default convert endlines to universal format.
    '''

    # Fix file path
    file_path = os.path.realpath(os.path.expanduser(file_path))

    # Read from file
    file_open = open(file_path)
    raw = file_open.read()
    file_open.close()

    # Decode
    raw = raw.decode(chardet.detect(raw)['encoding'])
    # Remove windows end line
    if universal_endline:
        raw = raw.replace('\r\n', '\n')
    # Encode to UTF-8
    raw = raw.encode('utf8')
    # Remove BOM
    if raw.startswith(codecs.BOM_UTF8):
        raw = raw.replace(codecs.BOM_UTF8, '', 1)

    # Write to file
    file_open = open(file_path, 'w')
    file_open.write(raw)
    file_open.close()
    return 0
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I found this question because having trouble with <code>configparser.ConfigParser().read(fp)</code> when opening files with UTF8 BOM header. </p>
<p>For those who are looking for a solution to remove the header so that ConfigPhaser could open the config file instead of reporting an error of:
<code>File contains no section headers</code>, please open the file like the following:</p>
<pre><code>        configparser.ConfigParser().read(config_file_path, encoding="utf-8-sig")
</code></pre>
<p>This could save you tons of effort by making the remove of the BOM header of the file unnecessary.</p>
<p>(I know this sounds unrelated, but hopefully this could help people struggling like me.)</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use codecs.</p>
<pre><code>import codecs
with open("test.txt",'r') as filehandle:
    content = filehandle.read()
if content[:3] == codecs.BOM_UTF8:
    content = content[3:]
print content.decode("utf-8")
</code></pre>
</div>
<span class="comment-copy">You need to open your file for reading plus update, i.e., with a <code>r+</code> mode. Add <code>b</code> too so that it will work on Windows as well without any funny line ending business. Finally, you'll want to seek back to the beginning of the file and truncate it at the end — please see my updated answer.</span>
<span class="comment-copy">hmm, i updated the question in edit #1 with sample code but getting a bad file descriptor. thx for any help. Trying to figure this out.</span>
<span class="comment-copy">Works on 2.7 too. Just import open from codecs.</span>
<span class="comment-copy">Best answer in the web on this topic. Just use utf-8-sig.</span>
<span class="comment-copy">thx for answer!</span>
<span class="comment-copy">can you explain how this code is work? $ remove_bom.py &lt; input.txt &gt; output.txt Am i right?</span>
<span class="comment-copy">@guneysus, yes, exactly</span>
<span class="comment-copy">i just added <code>header = header[3:] if header[0:3] == codecs.BOM_UTF8 else header</code></span>
<span class="comment-copy">not usable snipplet at all (filehandle? also codecs.BOM_UTF8 return a syntax error)</span>
<span class="comment-copy">Code sample works now (it was useful to me)</span>
