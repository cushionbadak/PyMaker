<div class="post-text" itemprop="text">
<p>I'm trying to implement a Python app that uses async functions to receive and emit messages using <a href="http://nats.io/" rel="nofollow">NATS</a>, using a <a href="https://github.com/nats-io/python-nats" rel="nofollow">client</a> based on Tornado. Once a message is received, a blocking function must be called, that I'm trying to implement on a separate thread, to allow the reception and publication of messages to put messages in a Tornado queue for later processing of the blocking function.</p>
<p>I'm very new to Tornado (and to python multithreading), but after reading several times the Tornado documentation and other sources, I've been able to put up a working version of the code, that looks like this:</p>
<pre><code>import tornado.gen
import tornado.ioloop
from tornado.queues import Queue
from concurrent.futures import ThreadPoolExecutor
from nats.io.client import Client as NATS

messageQueue = Queue()
nc = NATS()
@tornado.gen.coroutine
def consumer():
    def processMessage(currentMessage):
        # process the message ...

    while True:
        currentMessage = yield messageQueue.get()
        try:
            # execute the call in a separate thread to prevent blocking the queue
            EXECUTOR.submit(processMessage, currentMessage)
        finally:
            messageQueue.task_done()

@tornado.gen.coroutine
def producer():
    @tornado.gen.coroutine
    def enqueueMessage(currentMessage):
        yield messageQueue.put(currentMessage)

    yield nc.subscribe("new_event", "", enqueueMessage)

@tornado.gen.coroutine
def main():
    tornado.ioloop.IOLoop.current().spawn_callback(consumer)
    yield producer()

if __name__ == '__main__':
    main()
    tornado.ioloop.IOLoop.current().start()
</code></pre>
<p>My questions are:</p>
<p>1) Is this the correct way of using Tornado to call a blocking function?</p>
<p>2) What's the best practice for implementing a consumer/producer scheme that is always listening? I'm afraid my <code>while True:</code> statement is actually blocking the processor... </p>
<p>3) How can I inspect the Queue to make sure a burst of calls is being enqueued? I've tried using Queue().qSize(), but it always returns zero, which makes me wonder if the enqueuing is done correctly or not.</p>
</div>
<div class="post-text" itemprop="text">
<p>General rule (credits to NYKevin) is:</p>
<ul>
<li>multiprocessing for CPU- and GPU-bound computations.    </li>
<li>Event-driven stuff for non-blocking I/O (which should be preferred over blocking I/O where possible, since it scales much more effectively).</li>
<li>Threads for blocking I/O (you can also use multiprocessing, but the per-process overhead probably isn't worth it).</li>
</ul>
<p>ThreadPoolExecutor for IO, ProcessPoolExecutor for CPU. Both have internal queue, both scale to <strong>at most</strong> specified <code>max_workers</code>. More info about <a href="https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures" rel="nofollow">concurrent executors in docs</a>.</p>
<p>So answer are:</p>
<ol>
<li>Reimplementing pool is an overhead. Thread or Process depends on what you plan to do.</li>
<li><code>while True</code> is not blocking if you have e.g. some yielded async calls (even <code>yield gen.sleep(0.01)</code>), it gives back control to ioloop</li>
<li><code>qsize()</code> is the right to call, but since I have not run/debug this and I would take a different approach (existing pool), it is hard to find a problem here. </li>
</ol>
</div>
<span class="comment-copy">mind GIL limits with python's multithreading. I would use PorcessPoolExceutor if possible like <a href="http://stackoverflow.com/questions/33553940/queue-and-processpoolexecutor-in-tornado" title="queue and processpoolexecutor in tornado">stackoverflow.com/questions/33553940/â€¦</a></span>
<span class="comment-copy">that's an interesting approach... I didn't know the ProcessPoolExecutor had it's own queue. Is that also true for the ThreadPoolExecutor? I'm also interested in running one worker at a time maximum, since the events must be processed sequentially... would the GIL limits impact me in such case too?</span>
