<div class="post-text" itemprop="text">
<p>What's the most pythonic way to mesh two strings together?</p>
<p>For example:</p>
<p>Input:</p>
<pre><code>u = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
l = 'abcdefghijklmnopqrstuvwxyz'
</code></pre>
<p>Output:</p>
<pre><code>'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>For me, the most pythonic* way is the following which <em>pretty much does the same thing</em> but uses the <code>+</code> operator for concatenating the individual characters in each string:</p>
<pre><code>res = "".join(i + j for i, j in zip(u, l))
print(res)
# 'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
<p>It is also faster than using two <code>join()</code> calls:</p>
<pre><code>In [5]: l1 = 'A' * 1000000; l2 = 'a' * 1000000

In [6]: %timeit "".join("".join(item) for item in zip(l1, l2))
1 loops, best of 3: 442 ms per loop

In [7]: %timeit "".join(i + j for i, j in zip(l1, l2))
1 loops, best of 3: 360 ms per loop
</code></pre>
<p>Faster approaches exist, but they often obfuscate the code.</p>
<p><strong>Note:</strong> If the two input strings are <em>not</em> the same length then the longer one will be truncated as <strong><a href="https://docs.python.org/3/library/functions.html#zip"><code>zip</code></a></strong> stops iterating at the end of the shorter string. In this case instead of <code>zip</code> one should use <strong><a href="https://docs.python.org/3/library/itertools.html#itertools.zip_longest"><code>zip_longest</code></a></strong> (<strong><a href="https://docs.python.org/2.7/library/itertools.html#itertools.izip_longest"><code>izip_longest</code></a></strong> in Python 2) from the <a href="https://docs.python.org/3/library/itertools.html"><code>itertools</code></a> module to ensure that both strings are fully exhausted.</p>
<hr/>
<p><sub>*To take a quote from <strong><em><a href="https://www.python.org/dev/peps/pep-0020/">the Zen of Python</a></em></strong>: <strong>Readability counts</strong>. <br/>
Pythonic = <strong>readability</strong> for me; <code>i + j</code> is just visually parsed more easily, at least for my eyes.</sub></p>
</div>
<div class="post-text" itemprop="text">
<h2>Faster Alternative</h2>
<p>Another way:</p>
<pre><code>res = [''] * len(u) * 2
res[::2] = u
res[1::2] = l
print(''.join(res))
</code></pre>
<p>Output:</p>
<pre><code>'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
<h2>Speed</h2>
<p>Looks like it is faster:</p>
<pre><code>%%timeit
res = [''] * len(u) * 2
res[::2] = u
res[1::2] = l
''.join(res)

100000 loops, best of 3: 4.75 µs per loop
</code></pre>
<p>than the fastest solution so far:</p>
<pre><code>%timeit "".join(list(chain.from_iterable(zip(u, l))))

100000 loops, best of 3: 6.52 µs per loop
</code></pre>
<p>Also for the larger strings:</p>
<pre><code>l1 = 'A' * 1000000; l2 = 'a' * 1000000

%timeit "".join(list(chain.from_iterable(zip(l1, l2))))
1 loops, best of 3: 151 ms per loop


%%timeit
res = [''] * len(l1) * 2
res[::2] = l1
res[1::2] = l2
''.join(res)

10 loops, best of 3: 92 ms per loop
</code></pre>
<p>Python 3.5.1.</p>
<h2>Variation for strings with different lengths</h2>
<pre><code>u = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
l = 'abcdefghijkl'
</code></pre>
<h3>Shorter one determines length (<code>zip()</code> equivalent)</h3>
<pre><code>min_len = min(len(u), len(l))
res = [''] * min_len * 2 
res[::2] = u[:min_len]
res[1::2] = l[:min_len]
print(''.join(res))
</code></pre>
<p>Output:</p>
<pre><code>AaBbCcDdEeFfGgHhIiJjKkLl
</code></pre>
<h3>Longer one determines length (<code>itertools.zip_longest(fillvalue='')</code> equivalent)</h3>
<pre><code>min_len = min(len(u), len(l))
res = [''] * min_len * 2 
res[::2] = u[:min_len]
res[1::2] = l[:min_len]
res += u[min_len:] + l[min_len:]
print(''.join(res))
</code></pre>
<p>Output:</p>
<pre><code>AaBbCcDdEeFfGgHhIiJjKkLlMNOPQRSTUVWXYZ
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>With <code>join()</code> and <code>zip()</code>.</p>
<pre><code>&gt;&gt;&gt; ''.join(''.join(item) for item in zip(u,l))
'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>On Python 2, by <em>far</em> the faster way to do things, at ~3x the speed of list slicing for small strings and ~30x for long ones, is</p>
<pre><code>res = bytearray(len(u) * 2)
res[::2] = u
res[1::2] = l
str(res)
</code></pre>
<p>This wouldn't work on Python 3, though. You could implement something like</p>
<pre><code>res = bytearray(len(u) * 2)
res[::2] = u.encode("ascii")
res[1::2] = l.encode("ascii")
res.decode("ascii")
</code></pre>
<p>but by then you've already lost the gains over list slicing for small strings (it's still 20x the speed for long strings) and this doesn't even work for non-ASCII characters yet.</p>
<p>FWIW, if you <em>are</em> doing this on massive strings and need every cycle, <em>and</em> for some reason have to use Python strings... here's how to do it:</p>
<pre><code>res = bytearray(len(u) * 4 * 2)

u_utf32 = u.encode("utf_32_be")
res[0::8] = u_utf32[0::4]
res[1::8] = u_utf32[1::4]
res[2::8] = u_utf32[2::4]
res[3::8] = u_utf32[3::4]

l_utf32 = l.encode("utf_32_be")
res[4::8] = l_utf32[0::4]
res[5::8] = l_utf32[1::4]
res[6::8] = l_utf32[2::4]
res[7::8] = l_utf32[3::4]

res.decode("utf_32_be")
</code></pre>
<p>Special-casing the common case of smaller types will help too. FWIW, this is only 3x the speed of list slicing for long strings and a factor of 4 to 5 <em>slower</em> for small strings.</p>
<p>Either way I prefer the <code>join</code> solutions, but since timings were mentioned elsewhere I thought I might as well join in.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you want the fastest way, you can combine <a href="https://docs.python.org/2/library/itertools.html" rel="noreferrer">itertools</a> with <code>operator.add</code>:</p>
<pre><code>In [36]: from operator import add

In [37]: from itertools import  starmap, izip

In [38]: timeit "".join([i + j for i, j in uzip(l1, l2)])
1 loops, best of 3: 142 ms per loop

In [39]: timeit "".join(starmap(add, izip(l1,l2)))
1 loops, best of 3: 117 ms per loop

In [40]: timeit "".join(["".join(item) for item in zip(l1, l2)])
1 loops, best of 3: 196 ms per loop

In [41]:  "".join(starmap(add, izip(l1,l2))) ==  "".join([i + j   for i, j in izip(l1, l2)]) ==  "".join(["".join(item) for item in izip(l1, l2)])
Out[42]: True
</code></pre>
<p>But combining <code>izip</code> and <code>chain.from_iterable</code> is faster again</p>
<pre><code>In [2]: from itertools import  chain, izip

In [3]: timeit "".join(chain.from_iterable(izip(l1, l2)))
10 loops, best of 3: 98.7 ms per loop
</code></pre>
<p>There is also a substantial difference between 
<code>chain(*</code> and <code>chain.from_iterable(...</code>.</p>
<pre><code>In [5]: timeit "".join(chain(*izip(l1, l2)))
1 loops, best of 3: 212 ms per loop
</code></pre>
<p>There is no such thing as a generator with join, passing one is always going to be slower as python  will first build a list using the content because it does two passes over the data, one to figure out the size needed and one to actually do the join which would not be possible using a generator:</p>
<p><a href="https://github.com/python/cpython/blob/master/Objects/stringlib/join.h#L54" rel="noreferrer">join.h</a>:</p>
<pre><code> /* Here is the general case.  Do a pre-pass to figure out the total
  * amount of space we'll need (sz), and see whether all arguments are
  * bytes-like.
   */
</code></pre>
<p>Also if you  have different length strings and you don't want to lose data you can use <a href="https://docs.python.org/2/library/itertools.html#itertools.izip_longest" rel="noreferrer">izip_longest</a> :</p>
<pre><code>In [22]: from itertools import izip_longest    
In [23]: a,b = "hlo","elworld"

In [24]:  "".join(chain.from_iterable(izip_longest(a, b,fillvalue="")))
Out[24]: 'helloworld'
</code></pre>
<p>For python 3 it is called <code>zip_longest</code></p>
<p>But  for python2, veedrac's suggestion is  by far the fastest:</p>
<pre><code>In [18]: %%timeit
res = bytearray(len(u) * 2)
res[::2] = u
res[1::2] = l
str(res)
   ....: 
100 loops, best of 3: 2.68 ms per loop
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could also do this using <a href="https://docs.python.org/3/library/functions.html#map" rel="noreferrer"><code>map</code></a> and <a href="https://docs.python.org/3/library/operator.html#operator.add" rel="noreferrer"><code>operator.add</code></a>:</p>
<pre><code>from operator import add

u = 'AAAAA'
l = 'aaaaa'

s = "".join(map(add, u, l))
</code></pre>
<p><strong>Output</strong>:</p>
<pre><code>'AaAaAaAaAa'
</code></pre>
<p>What map does is it takes every element from the first iterable <code>u</code> and the first elements from the second iterable <code>l</code> and applies the function supplied as the first argument <code>add</code>. Then join just joins them.</p>
</div>
<div class="post-text" itemprop="text">
<p>Jim's answer is great, but here's my favorite option, if you don't mind a couple of imports:</p>
<pre><code>from functools import reduce
from operator import add

reduce(add, map(add, u, l))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>A lot of these suggestions assume the strings are of equal length. Maybe that covers all reasonable use cases, but at least to me it seems that you might want to accomodate strings of differing lengths too. Or am I the only one thinking the mesh should work a bit like this:</p>
<pre><code>u = "foobar"
l = "baz"
mesh(u,l) = "fboaozbar"
</code></pre>
<p>One way to do this would be the following:</p>
<pre><code>def mesh(a,b):
    minlen = min(len(a),len(b))
    return "".join(["".join(x+y for x,y in zip(a,b)),a[minlen:],b[minlen:]])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I like using two <code>for</code>s, the variable names can give a hint/reminder to what is going on:</p>
<pre><code>"".join(char for pair in zip(u,l) for char in pair)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Just to add another, more basic approach:</p>
<pre><code>st = ""
for char in u:
    st = "{0}{1}{2}".format( st, char, l[ u.index( char ) ] )
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Potentially faster and shorter than the current leading solution:</p>
<pre><code>from itertools import chain

u = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
l = 'abcdefghijklmnopqrstuvwxyz'

res = "".join(chain(*zip(u, l)))
</code></pre>
<p>Strategy speed-wise is to do as much at the C-level as possible.  Same zip_longest() fix for uneven strings and it would be coming out of the same module as chain() so can't ding me too many points there!</p>
<p>Other solutions I came up with along the way:</p>
<pre><code>res = "".join(u[x] + l[x] for x in range(len(u)))

res = "".join(k + l[i] for i, k in enumerate(u))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Feels a bit un-pythonic not to consider the double-list-comprehension answer here, to handle n string with O(1) effort:</p>
<pre><code>"".join(c for cs in itertools.zip_longest(*all_strings) for c in cs)
</code></pre>
<p>where <code>all_strings</code> is a list of the strings you want to interleave. In your case, <code>all_strings = [u, l]</code>. A full use example would look like this:</p>
<pre><code>import itertools
a = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
b = 'abcdefghijklmnopqrstuvwxyz'
all_strings = [a,b]
interleaved = "".join(c for cs in itertools.zip_longest(*all_strings) for c in cs)
print(interleaved)
# 'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
<p>Like many answers, fastest? Probably not, but simple and flexible. Also, without too much added complexity, this is slightly faster than the accepted answer (in general, string addition is a bit slow in python):</p>
<pre><code>In [7]: l1 = 'A' * 1000000; l2 = 'a' * 1000000;

In [8]: %timeit "".join(a + b for i, j in zip(l1, l2))
1 loops, best of 3: 227 ms per loop

In [9]: %timeit "".join(c for cs in zip(*(l1, l2)) for c in cs)
1 loops, best of 3: 198 ms per loop
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could use <a href="http://iteration-utilities.readthedocs.io/en/latest/generated/roundrobin.html" rel="nofollow noreferrer"><code>iteration_utilities.roundrobin</code></a><sup>1</sup></p>
<pre><code>u = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
l = 'abcdefghijklmnopqrstuvwxyz'

from iteration_utilities import roundrobin
''.join(roundrobin(u, l))
# returns 'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
<p>or the <a href="http://iteration-utilities.readthedocs.io/en/latest/generated/ManyIterables.html" rel="nofollow noreferrer"><code>ManyIterables</code></a> class from the same package:</p>
<pre><code>from iteration_utilities import ManyIterables
ManyIterables(u, l).roundrobin().as_string()
# returns 'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
<hr/>
<p><sup>1 This is from a third-party library I have written: <a href="https://github.com/MSeifert04/iteration_utilities" rel="nofollow noreferrer"><code>iteration_utilities</code></a>.</sup></p>
</div>
<div class="post-text" itemprop="text">
<p>I would use zip() to get a readable and easy way:</p>
<pre><code>result = ''
for cha, chb in zip(u, l):
    result += '%s%s' % (cha, chb)

print result
# 'AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz'
</code></pre>
</div>
<span class="comment-copy">Answers here have largely assumed that your two input strings will be the same length. Is that a safe assumption or do you need that to be handled?</span>
<span class="comment-copy">@SuperBiasedMan It may be helpful to see how to handle all conditions if you have a solution. It's relevant to the question, but not my case specifically.</span>
<span class="comment-copy">@drexx The top answerer commented with a solution for it anyway, so I just edited it into their post so it's comprehensive.</span>
<span class="comment-copy">Coding effort for n strings is O(n), though. Still, it's good as long as n is small.</span>
<span class="comment-copy">Your generator is probably causing more overhead than the join.</span>
<span class="comment-copy">run <code>"".join([i + j for i, j in zip(l1, l2)])</code> and it will definitely be the fastest</span>
<span class="comment-copy"><code>"".join(map("".join, zip(l1, l2)))</code> is even faster, although not necessarily more pythonic.</span>
<span class="comment-copy">Or <code>''.join(itertools.chain.from_iterable(zip(u, l)))</code></span>
<span class="comment-copy">This will truncate a list if one is shorter than the other, as <code>zip</code> stops when the shorter list has been fully iterated over.</span>
<span class="comment-copy">@SuperBiasedMan - Yep. <code>itertools.zip_longest</code> can be used if it becomes an issue.</span>
<span class="comment-copy">why <code>list</code>?? is unneeded</span>
<span class="comment-copy">not according to my tests, you lose time making the intermediary list and that defeat the purpose of using iterators. Timeit the <code>"".join(list(...))</code> give me 6.715280318699769 and timeit the <code>"".join(starmap(...))</code> give me 6.46332361384313</span>
<span class="comment-copy">then what, is machine dependent?? because no matter where I run the test I get the same exact result <code>"".join(list(starmap(add, izip(l1,l2))))</code> is slower than <code>"".join(starmap(add, izip(l1,l2)))</code>. I run the test in my machine in python 2.7.11 and in python 3.5.1 even in the virtual console of <a href="https://www.python.org/" rel="nofollow noreferrer">www.python.org</a> with python 3.4.3 and all say the same and I run it  a couple of times and always the same</span>
<span class="comment-copy">I read and I what I see is that it build a list internally all the time in its buffers variable regarless of what you pass to it, so the more reason to NO give it a list</span>
<span class="comment-copy">@Copperfield, are you talking about the list call or passing a list?</span>
<span class="comment-copy">He said most Pythonic, not most Haskellic ;)</span>
<span class="comment-copy"><a href="https://repl.it/@zed1/interleaved-strings" rel="nofollow noreferrer"><code>''.join(map(add, a, b))</code></a></span>
<span class="comment-copy">Still not as fast as the fastest answer, though: which got 50.3 ms on this same data and computer</span>
