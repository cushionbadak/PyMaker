<div class="post-text" itemprop="text">
<p>I'm trying to wrap my brain around the 'text encoding standards'. When interpreting a bunch of bytes as 'text', one has to know which 'encoding sheme' applies. Possible candidates that I know of:</p>
<ul>
<li>ASCII: Very basic encoding scheme, supports 128 characters.</li>
<li>CP-1252: Windows encoding scheme for the Latin alphabet. Also known as 'ANSI'.</li>
<li>UTF-8: A coding scheme for the Unicode table (1.114.112 characters). Represents each character with one byte if possible, more bytes if needed (max. 4 bytes).</li>
<li>UTF-16: Another coding scheme for the Unicode table (1.114.112 characters). Represents each character with min 2 bytes, max 4 bytes.</li>
<li>UTF-32: Yet another coding scheme for the Unicode table. Represents each character with 4 bytes.</li>
<li>. . .</li>
</ul>
<p>Now I would expect that Python consistently uses one encoding scheme for its built-in String type. I did the following test, and the result makes me shiver. I start to believe that Python is not consistently sticking to one encoding scheme to store its Strings internally. In other words: Python Strings seem to be 'not born equal'..</p>
<p><strong>EDIT :</strong></p>
<p>I forgot to mention that I'm using Python 3.x . Sorry :-)</p>
<p><strong>1. The test</strong></p>
<p>I have two simple text files in a folder: <code>myAnsi.txt</code> and <code>myUtf.txt</code>. As you can guess, the first is encoded in the <code>CP-1252</code> encoding scheme, also known as <code>ANSI</code>. The latter is encoded in <code>utf-8</code>. In my test, I open each file and read out its content. I assign the content to a native Python String variable. Then I close the file. After that, I create a new file and write the content of the String variable to that file. Here is the code to do all that:</p>
<pre><code>    ##############################
    #    TEST ON THE ANSI-coded  #
    #    FILE                    #
    ##############################
    import os
    file = open(os.getcwd() + '\\myAnsi.txt', 'r')
    fileText = file.read()
    file.close()

    file = open(os.getcwd() + '\\outputAnsi.txt', 'w')
    file.write(fileText)
    file.close()

    # A print statement here like:
    #    &gt;&gt; print(fileText)
    # will raise an exception.
    # But if you're typing this code in a python terminal,
    # you can just write:
    #    &gt;&gt; fileText
    # and get the content printed. In my case, it is the exact
    # content of the file.
    # PS: I use the native windows cmd.exe as my Python terminal ;-)

    ##############################
    #    TEST ON THE Utf-coded   #
    #    FILE                    #
    ##############################
    import os
    file = open(os.getcwd() + '\\myUtf.txt', 'r')
    fileText = file.read()
    file.close()

    file = open(os.getcwd() + '\\outputUtf.txt', 'w')
    file.write(fileText)
    file.close()

    # A print statement here like:
    #    &gt;&gt; print(fileText)
    # will just work fine (at least for me).

    ############# END OF TEST #############
</code></pre>
<p><strong>2. The result I would expect</strong></p>
<p>Let us suppose that Python consistently sticks to one internal coding scheme - for example <code>utf-8</code> - for all its Strings. Assigning other content to a String would lead to some sort of implicit conversion. Under these assumptions, I would expect both output files to be of the <code>utf-8</code> type:</p>
<pre><code>    outputAnsi.txt   -&gt;   utf-8 encoded
    outputUtf.txt    -&gt;   utf-8 encoded
</code></pre>
<p><strong>3. The result I get</strong></p>
<p>The result I get is this:</p>
<pre><code>    outputAnsi.txt   -&gt;   CP-1252 encoded (ANSI)
    outputUtf.txt    -&gt;   utf-8 encoded
</code></pre>
<p>From these results, I have to conclude that the String variable <code>fileText</code> somehow stores the encoding scheme it adheres to.</p>
<p>Many people tell me in their answers:</p>
<blockquote>
<p>When no encoding is passed explicitly, <code>open()</code> uses the preferred
  system encoding both for reading and for writing.</p>
</blockquote>
<p>I just cannot wrap my brain around that statement. If open() uses the 'preferred system encoding' - say <code>cp1252</code> as example - then both <code>*.txt</code> outputs should be encoded in that way, wouldn't they?</p>
<p><strong>4. Questions..</strong></p>
<p>My test raises several questions to me:</p>
<p>(1) When I open a file to read its content, how does Python know the encoding scheme of that file? I did not specify it when opening the file.</p>
<p>(2) Apparently a Python String can adhere to any encoding scheme supported by Python. So not all Python Strings are born equal. How do you find out the encoding scheme of a particular String, and how do you convert it? Or how do you make sure your freshly created Python String is of the expected type?</p>
<p>(3) When I create a file, how does Python decide in what encoding scheme the file will be created? I did not specify the encoding scheme when creating those files in my test. Nevertheless, Python made a different (!) decision in each case.</p>
<p><strong>5. Extra information (based on the comments to this question):</strong></p>
<ul>
<li>Python version: Python 3.x (installed from Anaconda)</li>
<li>Operating system: Windows 10</li>
<li>Terminal: Standard Windows command prompt <code>cmd.exe</code></li>
<li>Some questions raised about the temporary variable <code>fileText</code>. Apparently the instruction <code>print(fileText)</code> does not work for the ANSI case. An exception is thrown. But in the python terminal window, I can simply type the variable name <code>fileText</code> and get the file content printed out.</li>
<li>Encoding detection of files: Bottom right corner of Notepad++ for first check, online tool for double check: <a href="https://nlp.fi.muni.cz/projects/chared/" rel="nofollow">https://nlp.fi.muni.cz/projects/chared/</a></li>
<li>The output files <code>outputAnsi.txt</code> and <code>outputUtf.txt</code> do not exist at the start of the test. They are created at the very moment that I issue the <code>open(..)</code> command with the <code>'w'</code> option.</li>
</ul>
<p><strong>6. The actual files (for completeness):</strong></p>
<p>I got several comments encouraging me to share the actual files on which I'm doing this test. Those files were quite large, so I've trimmed them down and re-did the tests. Results are similar. Here are the files (PS: of course, my files contain source code, what else?):</p>
<p><strong>myAnsi.txt</strong></p>
<pre><code>/*
******************************************************************************
**
**  File        : LinkerScript.ld
**
**  Author      : Auto-generated by Ac6 System Workbench
**
**  Abstract    : Linker script for STM32F746NGHx Device from STM32F7 series
**
**  Target      : STMicroelectronics STM32
**
**  Distribution: The file is distributed “as is,” without any warranty
**                of any kind.
**
*****************************************************************************
** @attention
**
** &lt;h2&gt;&lt;center&gt;&amp;copy; COPYRIGHT(c) 2014 Ac6&lt;/center&gt;&lt;/h2&gt;
**
*****************************************************************************
*/

/* Entry Point */
/*ENTRY(Reset_Handler)*/
ENTRY(Default_Handler)

/* Highest address of the user mode stack */
_estack = 0x20050000;    /* end of RAM */

_Min_Heap_Size = 0;      /* required amount of heap  */
_Min_Stack_Size = 0x400; /* required amount of stack */

/* Memories definition */
MEMORY
{
  RAM (xrw)     : ORIGIN = 0x20000000, LENGTH = 320K
  ROM (rx)      : ORIGIN = 0x8000000, LENGTH = 1024K
}
</code></pre>
<p>The print statement of the <code>fileText</code> variable leads to the following exception:</p>
<pre><code>&gt;&gt;&gt; print(fileText)
    Traceback (most recent call last):
      File "&lt;stdin&gt;", line 1, in &lt;module&gt;
      File "C:\Anaconda3\lib\encodings\cp850.py", line 19, in encode
        return codecs.charmap_encode(input,self.errors,encoding_map)[0]
    UnicodeEncodeError: 'charmap' codec can't encode character '\u201c' in position 357: character maps to &lt;undefined&gt;
</code></pre>
<p>But just typing the name of the variable prints out the contents without problems:</p>
<pre><code>&gt;&gt;&gt; fileText
    ### contents of the file are printed out :-) ###
</code></pre>
<p><strong>myUtf.txt</strong></p>
<pre><code>/*--------------------------------------------------------------------------------------------------------------------*/
/*           _ _ _                                                                                                    */
/*          / -,- \                   __  _            _                                                              */
/*         //  |  \\                 / __\ | ___   ___| | __                   _            _                         */
/*         |   0--,|                / /  | |/ _ \ / __| |/ /    __ ___ _ _  __| |_ __ _ _ _| |_ ___                   */
/*         \\     //               / /___| | (_) | (__|   &lt;    / _/ _ \ ' \(_-&lt;  _/ _` | ' \  _(_-&lt;                   */
/*          \_-_-_/                \____/|_|\___/ \___|_|\_\   \__\___/_||_/__/\__\__,_|_||_\__/__/                   */
/*--------------------------------------------------------------------------------------------------------------------*/


#include "clock_constants.h"
#include "../CMSIS/stm32f7xx.h"
#include "stm32f7xx_hal_rcc.h"


/*--------------------------------------------------------------------------------------------------*/
/*          S y s t e m C o r e C l o c k       i n i t i a l        v a l u e                      */
/*--------------------------------------------------------------------------------------------------*/
/*                                                                                                  */
/* This variable is updated in three ways:                                                          */
/*      1) by calling CMSIS function SystemCoreClockUpdate()                                        */
/*      2) by calling HAL API function HAL_RCC_GetHCLKFreq()                                        */
/*      3) each time HAL_RCC_ClockConfig() is called to configure the system clock frequency        */
/*          Note: If you use this function to configure the system clock; then there                */
/*                is no need to call the 2 first functions listed above, since SystemCoreClock      */
/*                variable is updated automatically.                                                */
/*                                                                                                  */
uint32_t SystemCoreClock = 16000000;
const uint8_t AHBPrescTable[16] = {0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 6, 7, 8, 9};


/*--------------------------------------------------------------------------------------------------*/
/*          S y s t e m C o r e C l o c k       v a l u e      u p d a t e                          */
/*--------------------------------------------------------------------------------------------------*/
/*                                                                                                  */
/* @brief  Update SystemCoreClock variable according to Clock Register Values.                      */
/*         The SystemCoreClock variable contains the core clock (HCLK), it can                      */
/*         be used by the user application to setup the SysTick timer or configure                  */
/*         other parameters.                                                                        */
/*--------------------------------------------------------------------------------------------------*/
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>When no encoding is passed explicitly, <a href="https://docs.python.org/3.5/library/functions.html#open" rel="nofollow"><code>open()</code> uses the preferred system encoding</a> both for reading and for writing (not sure exactly how the preferred encoding is detected on Windows).</p>
<p>So, when you write:</p>
<pre><code>file = open(os.getcwd() + '\\myAnsi.txt', 'r')
file = open(os.getcwd() + '\\outputAnsi.txt', 'w')
file = open(os.getcwd() + '\\myUtf.txt', 'r')
file = open(os.getcwd() + '\\outputUtf.txt', 'w')
</code></pre>
<p>All four files are opened using the same encoding, both for reading and for writing.</p>
<p>You have to pass <code>encoding='cp1252'</code> or <code>encoding='utf-8'</code> if you want to be sure that files are opened using these encodings:</p>
<pre><code>file = open(os.getcwd() + '\\myAnsi.txt', 'r', encoding='cp1252')
file = open(os.getcwd() + '\\outputAnsi.txt', 'w', encoding='cp1252')
file = open(os.getcwd() + '\\myUtf.txt', 'r', encoding='utf-8')
file = open(os.getcwd() + '\\outputUtf.txt', 'w', encoding='utf-8')
</code></pre>
<p>(As a side note, I'm not a Windows expert, but I think you can write <code>'myAnsi.txt'</code> instead of <code>os.getcwd() + '\\myAnsi.txt'</code>.)</p>
<hr/>
<p>Apart from that, you have to consider that some characters are represented in the same way with different encodings. For example, the string <code>hello</code> has the same representation in ASCII, CP-1252 or UTF-8. In general, you have to use some non-ASCII characters to see some differences:</p>
<pre><code>&gt;&gt;&gt; 'hello'.encode('cp1252')
b'hello'
&gt;&gt;&gt; 'hello'.encode('utf-8')
b'hello'  # different encoding, same byte representation
</code></pre>
<p>Not only that, but some byte strings can be perfectly valid in two distinct encodings, even though they can have different meanings, so that when you try to decode a file with the wrong encoding you don't get an error, but a weird string:</p>
<pre><code>&gt;&gt;&gt; b'\xe2\x82\xac'.decode('utf-8')
'€'
&gt;&gt;&gt; b'\xe2\x82\xac'.decode('cp1252')
'â‚¬'  # same byte representation, different string
</code></pre>
<hr/>
<p>For the record, <a href="https://docs.python.org/3.5/c-api/unicode.html" rel="nofollow">Python uses UTF-8, UTF-16 or UTF-32</a> to represent strings internally. Python tries to use the "shortest" representation, even though UTF-8 and UTF-16 are used without continuation bytes, so that lookups are always O(1).</p>
<hr/>
<p>In short, you have read two files using the system encoding and written two files using the same encoding (therefore without any transformation). The content of the files you have read are compatible with both CP-1252 and UTF-8.</p>
</div>
<div class="post-text" itemprop="text">
<p>CP-1252 is basically a byte for byte codec; it can decode arbitrary bytes, including the bytes from UTF-8 encoding. So effectively, assuming you're on Windows using a Western locale, where the default encoding provided to <code>open</code> is <code>cp-1252</code>, if you never work with the string in Python, just read and write it, you may as well have just read and written in binary mode. You'd only see a problem if you tried to use the string in ways that exposed the problem.</p>
<p>For example, consider the following test file with a single UTF-8 encoded character in it:</p>
<pre><code>with open('utf8file.txt', 'w', encoding='utf-8') as f:
    f.write('é')
</code></pre>
<p>The actual bytes in that file are <code>C3 A9</code>.</p>
<p>If you read that file in <code>cp-1252</code>, it will happily do so, because every byte is a legal <code>cp-1252</code> byte:</p>
<pre><code>with open('utf8file.txt') as f:
    data = f.read()
</code></pre>
<p>But it's not the string <code>'é'</code>, it's what those two bytes happen to represent in <code>cp-1252</code>: <code>"Ã©"</code> (you can print them or check the length and you'll see that, assuming your console encoding handles non-ASCII)</p>
<p>If you're just writing it back though, without using it, you'd never see this; the output step is (default) encoding <code>"Ã©"</code> as <code>C9 A9</code>, which restores the original bytes that you expect.</p>
<p>Your problem is that most files are legal <code>cp-1252</code> text files (and it's possible Python will silently read unassigned bytes as equivalent Unicode ordinals; I know it does so for <code>latin-1</code> for unassigned bytes like <code>\x8d</code>), and when they're legal, reading as such and writing back in the same encoding is non-mutating.</p>
</div>
<div class="post-text" itemprop="text">
<p>To fully grasp the answer we need to look at the documentation a bit. </p>
<p>Let's start with the <em>open()</em> function. According to the Python 3.* documentation </p>
<blockquote>
<p>open() returns a file object, and is most commonly used with two arguments: open(filename, mode). <a href="https://docs.python.org/3/tutorial/inputoutput.html" rel="nofollow">1</a></p>
</blockquote>
<p>This means that we are dealing with a file object which could mean raw binary, buffered binary or in this case, text files <a href="https://docs.python.org/3/glossary.html#term-file-object" rel="nofollow">2</a>.  But how can this text file object know it's encoding? Well again, according to the documentation </p>
<blockquote>
<p>A file object able to read and write str objects. Often, a text file actually accesses a byte-oriented datastream and handles the text encoding automatically.<a href="https://docs.python.org/3/glossary.html#term-text-file" rel="nofollow">3</a></p>
</blockquote>
<p>So there we have it, it's handle automatically. And since both of those formats fall within the supported codecs. Python knows how to encode your files on writes given the file object. </p>
</div>
<div class="post-text" itemprop="text">
<p>What you're hoping for is unfortunately impossible.</p>
<p>Files do not contain encoding information and therefore it's impossible to read them as text without providing an encoding or assuming one.</p>
<p>When doing things like <code>text = open("myfile.txt").read()</code> there is no one in the world that can tell for sure what encoding to use to translate the byte stream contained in the file into unicode points if the file contains characters beyond ASCII. Note that's even possible that a file doesn't contain text in a single encoding (just concatenate one encoded with <code>iso-8859-1</code> to another using <code>utf-8</code> instead).</p>
<p>IIRC russian locale for example can contain any byte from <code>0x00</code> to <code>0xFF</code> an thus any file can be interpreted as containing russian locale text without decoding errors.</p>
<p>There are libraries that try to solve this problem by statistical-based guessing, but they're just guessing, not telling for sure.</p>
<p>Python 3 strings are unicode and therefore when reading a text file it applies a decoding using the "system default" unless provided a different one explicitly.</p>
<p>If the system default is not the correct one but can decode all the 8-bit bytes contained you will just get wrong content silently. When writing back the string it will use the system default again thus rewriting the same bytes in output.</p>
<p>This is what happened to you.</p>
<p>If the system default encoding however is not able to decode the file content you will get a <code>UnicodeDecodeError</code> exception. Error detection depends on the file content and the encodings used.</p>
<p>For example reading <code>Città</code> encoded in <code>iso8859-1</code> as if it were an <code>utf-8</code> content (default on my system) you get an error as the character <code>à</code> in <code>iso8859-1</code> is <code>0xe0</code> and that byte cannot be present in a valid <code>utf-8</code> file preceded by <code>t</code> (<code>0x74</code>).</p>
<p>Doing the opposite however (i.e. reading <code>Città</code> encoded in <code>utf-8</code> as if it were <code>iso8859-1</code>) will apparently "work" but will wrongly give as text <code>CittÃ </code> (i.e. an uppercase <code>A</code> with a tilde on top <code>0xc3</code> and a non-breaking space <code>0xA0</code>).</p>
</div>
<span class="comment-copy">So what data is <b>in</b> those files? No, <code>open()</code> uses a default encoding <b>always</b> to open files with. You didn't specify any codec, so the data is decoded then encoded again with the same codec for all file operations. The contents of the file won't matter if you gave it bytes that can be decoded with the default codec.</span>
<span class="comment-copy">For example, CP-1252 can decode UTF-8. It'll be <i>rubbish</i>, but you won't notice CP-1252 was used when all you do is encode the rubbish again with the same codec</span>
<span class="comment-copy">Additional notes that follow from Martijn's comments: Python strings are (for all external purposes) encoded in a single way; as an implementation detail in modern Python 3.x, they actually store in one or more of four different encodings depending on the maximum ordinal in the string (which means ASCII and latin-1 strings only use one byte per character, BMP strings use two bytes per character, and non-BMP strings use four bytes per character). But on output, they're encoded in the encoding passed (or defaulted) to <code>open</code>; if that encoding doesn't cover all characters, it errors out.</span>
<span class="comment-copy">"When I open a file to read its content, how does Python know the encoding scheme of that file?"  It doesn't.  It uses a default that may be totally wrong.</span>
<span class="comment-copy">–1 for no <a href="http://stackoverflow.com/help/mcve">mcve</a>.  Contents of the files?</span>
<span class="comment-copy">I don't understand your statement: <code>open() uses the preferred system encoding both for reading and for writing</code>. If my system default is <code>cp1252</code>, why is Python writing the first file in <code>cp1252</code> and the second in <code>utf-8</code>? In both write commands, I did not specify a particular encoding. So according to your statement, Python would default to the system preference. Nevertheless, Python takes a different decision in each case.</span>
<span class="comment-copy">@K.Mulier: if your system defaults to cp1252, then your files are being opened with cp1252. Your utf-8 file is being interpreted as a cp1252 file. As I've shown in my example, some byte strings that are valid utf-8 strings are also valid cp1252 strings</span>
<span class="comment-copy">I still don't get why the print statement in the first example of my test raises an exception, and in the second example it works just fine..</span>
<span class="comment-copy">@K.Mulier: what is the exact exception?</span>
<span class="comment-copy">I've added that to my question. My question has been growing in the past few minutes ;-)    (PS: thank you very much for your help. I really appreciate it.)</span>
<span class="comment-copy">CP-1252 is the default encoding for <i>files</i> on Windows but if you run in a terminal window, you'll get CP-437 for <code>stdout</code> and <code>stdin</code>… which is fun.</span>
<span class="comment-copy">Thank you very much for your interesting answer. There is only one thing that I don't understand. Given that <code>cp-1252</code> is indeed the default encoding system on Windows, why does my print statement <code>print(fileText)</code> crash?</span>
<span class="comment-copy">@K.Mulier: See @DietrichEpp's comment; looks like the terminal uses a different encoding by default. Thus, characters in 1252 that don't exist in 437 can't be output properly. You might try changing the terminal encoding (before launching Python) with <code>chcp</code>, e.g. <code>chcp 1252</code>, so the file system and terminal encodings match (I don't have a Windows Python install to test on right now). Assumes Python determines terminal encoding dynamically; off-hand, I don't know.</span>
<span class="comment-copy">Thank you very much. But I still don't get what happens when Python creates a non-existing file, like: <code>file = open(os.getcwd() + '\\outputAnsi.txt', 'w')</code>. The file <code>outputAnsi.txt</code> did not exist. Python creates it, without any specification for its encoding. And yet, Python makes a decision about that.</span>
<span class="comment-copy">It is because you are opening a file in a "text mode". The open() documentation in python states that   <i>In text mode (the default, or when 't' is included in the mode argument), the contents of the file are returned as str, the bytes having been first decoded using a platform-dependent encoding or using the specified encoding if given</i>  So I believe what is happening is that the <code>fileText</code> variable has encoding associated with it and when python opens a new file, it writes the to that file with that encoding in <code>fileText</code></span>
<span class="comment-copy">So the variable <code>fileText</code> itself has an 'encoding' attribute. More generally, each String in Python has an 'encoding' attribute attached to it. So I could theoretically ask every String what its encoding is. Am I correct?</span>
<span class="comment-copy">I don't understand your statement: <code>When writing back the string it [Python] will use the system default again thus rewriting the same bytes in output.</code>. If my system default is <code>cp1252</code>, why is Python writing the first file in <code>cp1252</code> and the second in <code>utf-8</code>? In both write commands, I did not specify a particular encoding. Nevertheless, Python takes a different decision in each case.</span>
<span class="comment-copy">@K.Mulier: if your default is cp1252 then it will write both files back using cp1252. You've been simply "lucky" that the utf-8 file content could be interpreted as legal cp1252 (getting however a garbled unicode text). This wrong unicode text when written back using cp1252 happened to become valid utf-8 again on output. I've quoted "lucky" because indeed that is bad luck (you got wrong data silently).</span>
