<div class="post-text" itemprop="text">
<p>I have a question about serialization and imports. </p>
<ul>
<li>should functions have their own imports? <a href="https://docs.continuum.io/anaconda-scale/howto/spark-basic#modify-std-script" rel="noreferrer">like I've seen done with PySpark</a></li>
<li>Is the following just plain wrong? Does <code>mod.py</code> need to be a conda/pip package? <code>mod.py</code> was written to a shared filesystem.</li>
</ul>
<p></p>
<pre><code>In [1]: from distributed import Executor

In [2]: e = Executor('127.0.0.1:8786')

In [3]: e
Out[3]: &lt;Executor: scheduler="127.0.0.1:8786" processes=2 cores=2&gt;

In [4]: import socket

In [5]: e.run(socket.gethostname)
Out[5]: {'172.20.12.7:53405': 'n1015', '172.20.12.8:53779': 'n1016'}

In [6]: %%file mod.py
   ...: def hostname():
   ...:     return 'the hostname'
   ...: 
Overwriting mod.py

In [7]: import mod

In [8]: mod.hostname()
Out[8]: 'the hostname'

In [9]: e.run(mod.hostname)
distributed.utils - ERROR - No module named 'mod'
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h3>Quick Answer</h3>
<p>Upload your mod.py file to all of your workers.  You can do this using whatever mechanism you used to set up dask.distributed, or you can use the <a href="http://distributed.readthedocs.io/en/latest/api.html#distributed.executor.Executor.upload_file" rel="noreferrer">upload_file</a> method</p>
<pre><code>e.upload_file('mod.py')
</code></pre>
<p>Alternatively, if your function is made in IPython, rather than being part of a module, it will be sent along without a problem.</p>
<h3>Long Answer</h3>
<p>This all has to do with how functions get serialized in Python.  Functions from modules are serialized by their module name and function name</p>
<pre><code>In [1]: from math import sin

In [2]: import pickle

In [3]: pickle.dumps(sin)
Out[3]: b'\x80\x03cmath\nsin\nq\x00.'
</code></pre>
<p>So if the client machine wants to refer to the <code>math.sin</code> function it sends along this bytestring (which you'll notice has <code>'math'</code> and <code>'sin'</code> in it buried among other bytes) to the worker machine.  The worker looks at this bytestring and says "OK great, the function I want is in such and such a module, let me go and find that in my local file system.  If the module isn't present then it'll raise an error, much like what you received above.</p>
<p>For dynamically created functions (functions that you make in IPython) it uses a completely different approach, bundling up all of the code.  This approach generally works fine.</p>
<p>Generally speaking Dask assumes that the workers and the client all have the same software environment.  Typically this is mostly handled by whoever sets up your cluster, using some other tool like Docker.  Methods like <code>upload_file</code> are there to fill in the gaps when you have files or scripts that get updated more frequently.</p>
</div>
<div class="post-text" itemprop="text">
<p>To run an imported function on your cluster that is not available on the workers' environment, you can also create a local function from the imported function. This local function will then be pickled by <code>cloudpickle</code>. In Python 2 you can achieve this with <code>new.function</code> (see the <a href="https://docs.python.org/2/library/new.html" rel="nofollow noreferrer">new module</a>). For Python 3 this could be achieved with the <a href="https://docs.python.org/3/library/types.html" rel="nofollow noreferrer">types module</a>, but I haven't tried it.</p>
<p>Your example above would then look like:</p>
<pre><code>In [3]: import mod

In [4]: import new

In [5]: def remote(func):
   ...:     return new.function(func.func_code, func.func_globals, closure=func.func_closure)
   ...:

In [6]: e.run(remote(mod.hostname))
Out[6]: {'tcp://10.0.2.15:44208': 'the hostname'}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>adding the directory of the module to PYTHONPATH worked for me</p>
</div>
<span class="comment-copy">Thanks, that was what I needed.   So the better way may be to use <code>setup.py install --develop</code>?</span>
<span class="comment-copy">How you install dask.distributed isn't relevant for this question.  If you're referring to your mod.py software then maybe, it depends on if your various dask-worker processes will all see wherever you install software to.  This might work for example on a network file system but wouldn't work if the dask-worker processes are on different file systems altogether.</span>
<span class="comment-copy">That's what I thought, thanks.</span>
