<div class="post-text" itemprop="text">
<p>I have a function which reads in a file, compares a record in that file to a record in another file and depending on a rule, appends a record from the file to one of two lists. </p>
<p>I have an empty list for adding matched results to:</p>
<pre><code>match = []
</code></pre>
<p>I have a list <code>restrictions</code> that I want to compare records in a series of files with.</p>
<p>I have a function for reading in the file I wish to see if contains any matches. If there is a match, I append the record to the <code>match</code> list.</p>
<pre><code>def link_match(file):
    links = json.load(file)
    for link in links:
        found = False
        try:
            for other_link in other_links:
                if link['data'] == other_link['data']:
                    match.append(link)
                    found = True
                else:
                    pass
        else:
            print "not found"
</code></pre>
<p>I have numerous files that I wish to compare and I thus wish to use the multiprocessing library. </p>
<p>I create a list of file names to act as function arguments:</p>
<pre><code>list_files=[]
for file in glob.glob("/path/*.json"):
    list_files.append(file)
</code></pre>
<p>I then use the <code>map</code> feature to call the function with the different input files:</p>
<pre><code>if __name__ == '__main__':
    pool = multiprocessing.Pool(processes=6)
    pool.map(link_match,list_files)
    pool.close()
    pool.join()
</code></pre>
<p>CPU use goes through the roof and by adding in a print line to the function loop I can see that matches are being found and the function is behaving correctly. </p>
<p>However, the <code>match</code> results list remains empty. What am I doing wrong?</p>
</div>
<div class="post-text" itemprop="text">
<p>When multiprocessing, each subprocess gets its own copy of any global variables in the main module defined before the <code>if __name__ == '__main__':</code> statement. This means that the <code>link_match()</code> function in each one of the processes will be accessing a <em>different</em> <code>match</code> list in your code.</p>
<p>One workaround is to use a shared list, which in turn requires a <a href="https://docs.python.org/2/library/multiprocessing.html#multiprocessing.managers.SyncManager" rel="nofollow">SyncManager</a> to synchronize access to the shared resource among the processes (which is created by calling <code>multiprocessing.Manager()</code>). This is then used to create the list to store the results (which I have named <code>matches</code> instead of <code>match</code>) in the code below.</p>
<p>I also had to use <code>functools.partial()</code> to create a single argument callable out of the revised <code>link_match</code> function which now takes two arguments, not one (which is the kind of function <code>pool.map()</code> expects).</p>
<pre><code>from functools import partial
import glob
import multiprocessing

def link_match(matches, file):  # note: added results list argument
    links = json.load(file)
    for link in links:
        try:
            for other_link in other_links:
                if link['data'] == other_link['data']:
                    matches.append(link)
                else:
                    pass
        else:
            print "not found"

if __name__ == '__main__':
    manager = multiprocessing.Manager()  # create SyncManager
    matches = manager.list()  # create a shared list here
    link_matches = partial(link_match, matches)  # create one arg callable to
                                                 # pass to pool.map()
    pool = multiprocessing.Pool(processes=6)
    list_files = glob.glob("/path/*.json")  # only used here
    pool.map(link_matches, list_files)  # apply partial to files list
    pool.close()
    pool.join()
    print(matches)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Multiprocessing creates multiple processes. The context of your "match" variable will now be in that child process, not the parent Python process that kicked the processing off.</p>
<p>Try writing the list results out to a file in your function to see what I mean.</p>
</div>
<div class="post-text" itemprop="text">
<p>To expand cthrall's answer, you need to return something from your function in order to pass the info back to your main thread, e.g.</p>
<pre><code>def link_match(file):
    [put all the code here]
    return match

[main thread]
all_matches = pool.map(link_match,list_files)
</code></pre>
<p>the list <code>match</code> will be returned from each single thread and <code>map</code> will return a list of lists in this case. You can then <a href="https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python">flatten</a> it again to get the final output.</p>
<hr/>
<p>Alternatively you can use a <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.managers" rel="nofollow noreferrer">shared list</a> but this will just add more headache in my opinion.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>multiprocessing</code> runs a new instance of Python for each process in the pool - the context is empty (if you use <code>spawn</code> as a start method) or copied (if you use <code>fork</code>), plus copies of any arguments you pass in (either way), and from there they're all separate. If you want to pass data between branches, there's a few other ways to do it.</p>
<ol>
<li>Instead of writing to an internal list, write to a file and read from it later when you're done. The largest potential problem here is that only one thing can write to a file at a time, so either you make a lot of separate files (and have to read all of them afterwards) or they all block each other.</li>
<li>Continue with <code>multiprocessing</code>, but use a <a href="https://docs.python.org/3.5/library/multiprocessing.html#multiprocessing.Queue" rel="nofollow"><code>multiprocessing.Queue</code></a> instead of a list. This is an object provided specifically for your current use-case: Using multiple processes and needing to pass data between them. Assuming that you should indeed be using <code>multiprocessing</code> (that your situation wouldn't be better for <code>threading</code>, see below), this is probably your best option.</li>
<li>Instead of <code>multiprocessing</code>, use <a href="https://docs.python.org/3/library/threading.html#module-threading" rel="nofollow"><code>threading</code></a>. Separate threads all share a single environment. The biggest problems here are that Python only lets one thread actually run Python code at a time, per process. This is called the Global Interpreter Lock (GIL). <code>threading</code> is thus useful when the threads will be waiting on external processes (other programs, user input, reading or writing files), but if most of the time is spent in Python code, it actually takes longer (because it takes a little time to switch threads, and you're not doing anything to save time). This has its own <a href="https://docs.python.org/3/library/queue.html#module-queue" rel="nofollow"><code>queue</code></a>. You should probably use that rather than a plain list, if you use <code>threading</code> - otherwise there's the potential that two threads accessing the list at the same time interfere with each other, if it switches threads at the wrong time.</li>
</ol>
<p>Oh, by the way: If you do use threading, Python 3.2 and later has an improved implementation of the GIL, which seems like it at least has a good chance of helping. A lot of stuff for threading performance is very dependent on your hardware (number of CPU cores) and the exact tasks you're doing, though - probably best to try several ways and see what works for you.</p>
</div>
<span class="comment-copy">Modify <code>link_match()</code> to return a list of matches found instead of directly modifying a single global list, and then modify your master script to combine all the returned lists into one big list.</span>
<span class="comment-copy">As always, many thanks @martineau. This is very useful. I have one final obstacle however. I am unable to <code>dump</code> the resulting list. Error message <code>TypeError: &lt;ListProxy object, typeid 'list' at 0x10d591790&gt; is not JSON serializable</code>. I then tried to print the list before dumping and I get the following <code>&lt;ListProxy object, typeid 'list' at 0x10d591790&gt;</code>. I have never come across a ListProxy object before! In order to convert it I tried <code>manager.dict()</code> in place of <code>manager.list()</code>and also converting the final list to a <code>dict</code> but no avail.</span>
<span class="comment-copy">I was able to print its contents, as indicated by the last line of my answer. Try using <code>list(matches)</code> to convert it to a regular list.</span>
<span class="comment-copy">Nit-pick: The current context isn't actually copied to each new process. Each one imports the main module so it will start out with any context set up by doing that. This is way it's important to have the <code>if __name__ == '__main__':</code> statement in the main module to define the part of the main script that <i>doesn't</i> get executed everytime it's imported. See the <b>Safe importing of main module</b> subsection of the <a href="https://docs.python.org/2/library/multiprocessing.html#windows" rel="nofollow noreferrer">Windows</a> section of the <code>multiprocessing</code> <i>Programming Guidelines</i>.</span>
<span class="comment-copy">@martineau Oops. Correcting.</span>
<span class="comment-copy">@martineau Checked - looks to me like it possibly goes either way (see <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">Contexts and Start Methods</a>) depending on OS and certain settings. Adjusted accordingly.</span>
<span class="comment-copy">It's unclear what version of Python and OS the OP is using. Regardless, it's important to write code that works on multiple OSs whenever feasible, as it usually is since that's one of Python's greatest strengths, IMO. Besides, even on other OSs, the <code>mp.set_start_method()</code> call is placed after a <code>if __name__ == '__main__':</code> statement in the examples to put in it into effect before any other processes are started.</span>
