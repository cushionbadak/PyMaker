<div class="post-text" itemprop="text">
<p>I'm writing a program to parse through some log files. If an error code is in the line, I need to print the previous 25 lines for analysis. I'd like to be able to repeat this concept with more or less lines depending on the individual error code (instead of 25 lines, 15 or 35). </p>
<pre><code>with open(file, 'r') as input:
     for line in input:
         if "error code" in line: 
             #print previous 25 lines
</code></pre>
<p>I know the equivalent command in Bash for what I need is <code>grep "error code" -B 25 Filename | wc -1</code>. I'm still new to python and programming in general, I know I'm going to need a <code>for</code> loop and I've tried using the <code>range</code> function to do this but I haven't had much luck because I don't know how to implement the range into files.` </p>
</div>
<div class="post-text" itemprop="text">
<p>This is a perfect use case for <a href="https://docs.python.org/3/library/collections.html#collections.deque" rel="nofollow noreferrer">a length limited <code>collections.deque</code></a>:</p>
<pre><code>from collections import deque

line_history = deque(maxlen=25)
with open(file) as input:
    for line in input:
        if "error code" in line: 
            print(*line_history, line, sep='')
            # Clear history so if two errors seen in close proximity, we don't
            # echo some lines twice
            line_history.clear()
        else:
            # When deque reaches 25 lines, will automatically evict oldest
            line_history.append(line)
</code></pre>
<p><strong>Complete explanation of why I chose this approach (skip if you don't really care):</strong></p>
<p>This isn't solvable in a good/safe way using <code>for</code>/<code>range</code>, because indexing only makes sense if you load the whole file into memory; the file on disk has no idea where lines begin and end, so you can't just ask for "line #357 of the file" without reading it from the beginning to find lines 1 through 356. You'd either end up repeatedly rereading the file, or slurping the whole file into an in-memory sequence (e.g. <code>list</code>/<code>tuple</code>) to have indexing make sense.</p>
<p>For a log file, you have to assume it could be quite large (I regularly deal with multi-gigabyte log files), to the point where loading it into memory would exhaust main memory, so slurping is a bad idea, and rereading the file from scratch each time you hit an error is almost as bad (it's slow, but it's reliably slow I guess?). The <code>deque</code> based approach means your peak memory usage is based on the 27 longest lines in the file, rather than the total file size.</p>
<p>A na√Øve solution with nothing but built-ins could be as simple as:</p>
<pre><code>with open(file) as input:
    lines = tuple(input)  # Slurps all lines from file
for i, line in enumerate(lines):
    if "error code" in line:
        print(*lines[max(i-25, 0):i], line, sep='')
</code></pre>
<p>but like I said, this requires enough memory to hold your entire log file in memory at once, which is a bad thing to count on. It also repeats lines when two errors occur in close proximity, because unlike <code>deque</code>, you don't get an easy way to empty your recent memory; you'd have to manually track the index of the last <code>print</code> to restrict your slice.</p>
<p>Note that even then, I didn't use <code>range</code>; <code>range</code> is a crutch a lot of people coming from C backgrounds rely on, but it's usually the wrong way to solve a problem in Python. In cases where an index is <em>needed</em> (it usually isn't), you usually need the value too, so <code>enumerate</code> based solutions are superior; most of the time, you don't need an index at all, so direct iteration (or paired iteration with <code>zip</code> or the like) is the correct solution.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try base coding with <code>for</code> loop and <code>range</code> function without any special libraries: </p>
<pre><code>N = 25
with open(file, 'r') as f:
    lines = f.read().splitlines()
    for i, line in enumerate(lines):
        if "error code" in line: 
            j = i-N if i&gt;N else 0
            for k in range(j,i):
                print(lines[k])
</code></pre>
<p>Above prints previous 25 lines or from first line if total lines are less than 25.</p>
<p>Also, it is better to avoid using <code>input</code> as a variable term since it is a keyword in Python.</p>
</div>
<span class="comment-copy">can we use <code>queue</code> here?</span>
<span class="comment-copy">@VanPeer: <code>queue.Queue</code> is intended for hand-off between threads/processes. When you length limit a <code>queue.Queue</code>, it <i>blocks</i> when the limit is hit, it doesn't silently discard the oldest value; in this case, silently discarding the oldest value is a feature we want. <code>queue.Queue</code> also adds a ton of overhead that gains you nothing here; it's actually built on a <code>collections.deque</code> under the hood, but where <code>collections.deque</code> is implemented in C and lock-free, <code>queue.Queue</code> is implemented in Python, using fairly complex synchronization code.</span>
<span class="comment-copy">Note: If you <i>want</i> to print lines twice for errors in close proximity, you'd just delete the <code>line_history.clear()</code> and <code>else:</code> lines, then dedent <code>line_history.append(line)</code> (so it's executed unconditionally). I went with clearing because I was following a design closer to the behavior of <code>fgrep -B25 'error code'</code> which this code roughly replicates.</span>
<span class="comment-copy">thanks for the explanation! I did give it a try using <code>queue</code>. We've to write separate logic to evict when it reaches full.</span>
<span class="comment-copy">While this works for small log files, it has a peak memory requirement proportional to two times the total size of the log file (the line <code>input = f.read().splitlines()</code> must, however briefly, hold the entire file in memory as a <code>str</code>, as well as a <code>list</code> containing a <code>str</code> for every line in the file). For a 1 GB log file, you'd better have 2.7-12 GB of RAM (on top of whatever your OS, the Python interpreter, and all your other programs are using, exact amount depending on whether the text is ASCII, latin-1, BMP or non-BMP) available to hold it all, or you'll be stuck in swap thrashing hell.</span>
<span class="comment-copy">That is a very good point, but I thought a beginner will be more interested in simple code than an industry-standard approach.</span>
