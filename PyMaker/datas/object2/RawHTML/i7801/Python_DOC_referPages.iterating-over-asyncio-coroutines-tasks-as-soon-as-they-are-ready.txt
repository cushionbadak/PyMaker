<div class="post-text" itemprop="text">
<p>I launch a bunch of requests using <code>aiohttp</code>. Is there a way to get the results one-by-one as soon as each request is complete?</p>
<p>Perhaps using something like <code>async for</code>? Or Python 3.6 async generators?</p>
<p>Currently I <code>await asyncio.gather(*requests)</code> and process them when all of them are completed.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>asyncio</code> has <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed" rel="nofollow noreferrer">as_completed</a> function that probably does what you need. Note, it returns regular iterator, not async. </p>
<p>Here's example of usage:</p>
<pre><code>import asyncio


async def test(i):
    await asyncio.sleep(i)
    return i


async def main():
    fs = [
        test(1),
        test(2),
        test(3),
    ]

    for f in asyncio.as_completed(fs):
        i = await f  # Await for next result.
        print(i, 'done')



loop = asyncio.new_event_loop()
asyncio.set_event_loop(loop)
try:
    loop.run_until_complete(main())
finally:
    loop.run_until_complete(loop.shutdown_asyncgens())
    loop.close()
</code></pre>
<p>Output:</p>
<pre><code>1 done
2 done
3 done
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Canonical way is pushing result into <code>asyncio.Queue</code> like in <a href="https://github.com/aosabook/500lines/tree/master/crawler/code" rel="nofollow noreferrer">crawler example</a>.
Also it's wise to run limited amount for download tasks which get new job from input queue instead of spawning a million of new tasks.</p>
</div>
<div class="post-text" itemprop="text">
<p>As I understand according to the docs, <code>requests</code> are <code>Future</code>s (or can be easily converted to Future using <a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future" rel="nofollow noreferrer" title="asyncio.ensure_future">asyncio.ensure_future</a>).</p>
<p>A <code>Future</code> object has a method <code>.add_done_callback</code>. 
So, you can add your callback for every request, and then do <code>gather</code>.</p>
<p><a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.Future.add_done_callback" rel="nofollow noreferrer" title="Future.add_done_callback">Docs for Future.add_done_callback</a></p>
</div>
<span class="comment-copy">Don't use <code>add_done_callback</code> until you are writing something very low level.</span>
