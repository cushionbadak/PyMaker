<div class="post-text" itemprop="text">
<p>Given the following example DataFrame:</p>
<pre><code>&gt;&gt;&gt; df
                 Times  Values
0  05/10/2017 01:01:03       1
1  05/10/2017 01:05:00       2
2  05/10/2017 01:06:10       3
3  05/11/2017 08:25:20       4
4  05/11/2017 08:30:14       5
5  05/11/2017 08:30:35       6
</code></pre>
<p>I want to subset this DataFrame by the 'Time' column, by matching a partial string up to the hour.  For example, I want to subset using partial strings which contain "05/10/2017 01:" and "05/11/2017 08:" which breaks up the subsets into two new data frames:</p>
<pre><code>&gt;&gt;&gt; df1
                 Times  Values
0  05/10/2017 01:01:03       1
1  05/10/2017 01:05:00       2
2  05/10/2017 01:06:10       3
</code></pre>
<p>and</p>
<pre><code>&gt;&gt;&gt; df2
0  05/11/2017 08:25:20       4
1  05/11/2017 08:30:14       5
2  05/11/2017 08:30:35       6
</code></pre>
<p>Is it possible to make this subset iterative in Pandas, for multiple dates/times that similarly have the date/hour as the common identifier?  </p>
</div>
<div class="post-text" itemprop="text">
<p>First, cast your <code>Times</code> column into a datetime format, and set it as the index:</p>
<pre><code>df['Times'] = pd.to_datetime(df['Times'])
df.set_index('Times', inplace = True)
</code></pre>
<p>Then use the groupby method, with a <code>TimeGrouper</code>:</p>
<pre><code>g = df.groupby(pd.TimeGrouper('h'))
</code></pre>
<p><code>g</code> is an iterator that yields tuple pairs of times and sub-dataframes of those times. If you just want the sub-dfs, you can do <code>zip(*g)[1]</code>.</p>
<p>A caveat: the sub-dfs are indexed by the timestamp, and <code>pd.TimeGrouper</code> only works when the times are the index. If you want to have the timestamp as a column, you could instead do:</p>
<pre><code>df['Times'] = pd.to_datetime(df['Times'])
df['time_hour'] = df['Times'].dt.floor('1h')
g = df.groupby('time_hour')
</code></pre>
<p>Alternatively, you could just call <code>.reset_index()</code> on each of the dfs from the former method, but this will probably be much slower.</p>
</div>
<div class="post-text" itemprop="text">
<p>Convert Times to a hour period, groupby and then extract each group as a DF.</p>
<pre><code>df1,df2=[g.drop('hour',1) for n,g in\
         df.assign(hour=pd.DatetimeIndex(df.Times)\
           .to_period('h')).groupby('hour')]

df1
Out[874]: 
                Times  Values
0 2017-05-10 01:01:03       1
1 2017-05-10 01:05:00       2
2 2017-05-10 01:06:10       3

df2
Out[875]: 
                Times  Values
3 2017-05-11 08:25:20       4
4 2017-05-11 08:30:14       5
5 2017-05-11 08:30:35       6
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First make sure that the <code>Times</code> column is of type DateTime.
Second, set <code>times</code> column as index.
Third, use <code>between_time</code> method.</p>
<pre><code>df['Times'] = pd.to_datetime(df['Times'])
df.set_index('Times', inplace=True)

df1 = df.between_time('1:00:00', '1:59:59')
df2 = df.between_time('8:00:00', '8:59:59')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you use the <a href="https://docs.python.org/3/library/datetime.html" rel="nofollow noreferrer">datetime</a> type you can extract things like hours and days.</p>
<pre><code>times = pd.to_datetime(df['Times'])
hours = times.apply(lambda x: x.hour)
df1 = df[hours == 1]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use the <code>str[]</code> accessor to truncate the string representation of your date (you might have to cast <code>astype(str)</code> if your columns is a datetime and then use <code>groupby.groups</code> to access the dataframes as a dictionary where the keys are your truncated date values:</p>
<pre><code>&gt;&gt;&gt; df.groupby(df.Times.astype(str).str[0:13]).groups

{'2017-05-10 01': DatetimeIndex(['2017-05-10 01:01:03', '2017-05-10 01:05:00',
                '2017-05-10 01:06:10'],
               dtype='datetime64[ns]', name='time', freq=None),
 '2017-05-11 08': DatetimeIndex(['2017-05-11 08:25:20', '2017-05-11 08:30:14',
                '2017-05-11 08:30:35'],
               dtype='datetime64[ns]', name='time', freq=None)}
</code></pre>
</div>
<span class="comment-copy">Ken, thanks for your solution.  A couple of questions: this may be obvious, but how do I index the new sub-dfs in g?  Additionally, how would you code change if i wanted to do a groupby down to the minute?  Thanks.</span>
<span class="comment-copy">The sub-dfs are also dataframes, so you can index them in the same manner with <code>.loc</code>. For doing the groupby on minute, replace <code>'h'</code> with <code>'min'</code>.</span>
<span class="comment-copy">Hi Allen, this works, thanks.  Let's assume that all minutes are the same for df1 and separately, the minutes are the same for df2 (i.e. all 01:01 and all 08:30).  How would the above code change?  I'm taking the time now to better understand how your different functions are working together.  Cheers.</span>
<span class="comment-copy">The groupby is using Year-Month-Day-Hour as the key the so the value of minutes don't matter. As long as they have the same key(Year-Month-Day-Hour), those records will be grouped into the same DF.</span>
<span class="comment-copy">That makes sense.  I may want to subset down to the minute, though.  Is it possible to change the groupby to Year-Month-Day-Hour-Minute? Thanks.</span>
<span class="comment-copy">Yes it's possible. This will give you a minute breakdown: [g.drop('minute',1) for n,g in df.assign(minute=pd.DatetimeIndex(df.Times).to_period('T')).groupby('minute')]</span>
