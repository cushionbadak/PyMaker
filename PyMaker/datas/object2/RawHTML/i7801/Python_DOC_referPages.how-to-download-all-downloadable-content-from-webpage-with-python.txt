<div class="post-text" itemprop="text">
<p>There's a website that has 13 pages of midi files that I want to download and I can't download hundreds of files by hand so I'm wondering if there's any way of getting all the downloadable files with python.</p>
<p>here's the website's url: <a href="http://midkar.com/jazz/jazz_01.html" rel="nofollow noreferrer">http://midkar.com/jazz/jazz_01.html</a>
each page in the website has a list of links and they start downloading when you click.</p>
<p>I wrote a for loop to go through all the 13 pages like this:</p>
<pre><code>for i in range(1,14):
    url = "http://midkar.com/jazz/jazz_0" + str(i) + ".html"
    print(url)
</code></pre>
<p>but this is pretty much all I've done and I would appreciate some help.</p>
</div>
<div class="post-text" itemprop="text">
<p>you should learn to use the requests module to get the pages, and the BeautifulSoup module to get the actual links by parsing the html of those pages, then take those links and download them with the requests module once again.</p>
<p>can't write the entire code for you, but here is where you should start:</p>
<p>requests: <a href="http://docs.python-requests.org/en/master/user/quickstart/" rel="nofollow noreferrer">http://docs.python-requests.org/en/master/user/quickstart/</a></p>
<p>BeautifulSoup: <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="nofollow noreferrer">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a></p>
</div>
<div class="post-text" itemprop="text">
<p>You can write a simple web crawler with Beatutifulsoup and requests. </p>
<pre><code>from bs4 import BeautifulSoup
import requests

for i in range(1,14):
    url = "http://midkar.com/jazz/jazz_0" + str(i) + ".html"
    page = requests.get(url).content
    soup = BeautifulSoup(page, 'html5lib')
    # find all links on page
    links = soup.find_all('a', href=True)
    for link in links:
        # build absolute url
        link_url = requests.compat.urljoin(url, link['href'])
        if link_url.endswith('.mid'):
            # download midi file and write it to a local file
            filename = link_url.split('/')[-1]
            with open(filename, 'wb') as midifile:
                midifile.write(requests.get(href).content)
                print(filename)
</code></pre>
</div>
<span class="comment-copy">Yes, thank you.This is actually exactly what I was looking for but maybe I didn't phrase the question correctly.</span>
<span class="comment-copy">Also you can use <a href="https://docs.python.org/2/library/urllib2.html" rel="nofollow noreferrer"><code>urllib2.request</code></a> module, it's similar to <a href="https://docs.python.org/3/library/urllib.request.html" rel="nofollow noreferrer"><code>urllib.request</code></a> in <code>Python3</code>.</span>
