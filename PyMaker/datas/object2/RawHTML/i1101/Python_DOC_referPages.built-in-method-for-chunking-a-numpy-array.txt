<div class="post-text" itemprop="text">
<p>I have a large amount of data in NetCDF4 files, and I am trying to write a script to dynamically chunk this data to hold as much in memory as possible, do calculations on it and save the results, then move on to the next chunk. </p>
<p>An example of what I am trying to do. Say I have an array like this:</p>
<pre><code>import numpy as np
arr = np.random.randint(0, 10, (100, 15, 51))  # Call these x, y, and z coordinates
</code></pre>
<p>And I only want to read ten of the x coordinates at a time, like this:</p>
<pre><code>placeholder = 0
for i in range(10, 101, 10):
    tmp_array = arr[placeholder:i, :, :]
    # Do calculations here and save results to file or database
    placeholder += 10
</code></pre>
<p>Is there some sort of built-in method for this? In this simple example it works pretty well, but as things get more complicated this seems like it could get to be a headache for me to manage all of this myself. I am aware of Dask, but it is unhelpful to me in this situation because I am not doing array operations with the data. Although Dask could be useful to me if it had methods to deal with this too.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can reduce the complexity and increase the robustness by implementing a lazy generator that encapsulates the computation you're worried about and just returns the chunk at each step. Something like this perhaps:</p>
<pre><code>def spliterate(buf, chunk):
    for start in range(0, buf.size, chunk):
        yield buf[start:start + chunk]
</code></pre>
<p>Using it is pretty straightforward:</p>
<pre><code>for tmp in spliterate(arr, 10):
    # do calculations on tmp, don't worry about bookkeeping
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The Dask documentation shows how to create chunked arrays for just the kind of computation you have in mind, for the case of hdf5 files: <a href="http://docs.dask.org/en/latest/array-creation.html#numpy-slicing" rel="nofollow noreferrer">http://docs.dask.org/en/latest/array-creation.html#numpy-slicing</a> . Your netCDF4 case may or may not work identically, but the section further down about <code>delayed</code> will do the trick, if not.</p>
<p>Having made your dask-array, you will want to use the <a href="http://docs.dask.org/en/latest/array-api.html#dask.array.core.map_blocks" rel="nofollow noreferrer">map_blocks</a> method for the "do something with each chunk" operation (this expects to get some output back), loop over the contents of the <code>.blocks</code> attribute, or use <code>.to_delayed()</code> to do arbitrary things with each piece. Exactly which is right for you depends on what you want to achieve.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.split.html?highlight=split#numpy.split" rel="nofollow noreferrer"><code>np.split</code></a>, which takes an array and either a chunk size or a list of indices at which to perform the split. Your case would be <code>np.split(arr, 10)</code>, giving you a list of 10 arrays of shape <code>(10, 15, 51)</code>.</p>
<p>Note that an exception is raised if the axis cannot be equally divided, e.g., if you asked for chunks of size 9. If you want to split into nearly-equal chunks, without raising, you can use <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.array_split.html#numpy.array_split" rel="nofollow noreferrer"><code>np.array_split</code></a> instead.</p>
</div>
<span class="comment-copy">So I like the look of this solution and it seems to work well with what I am trying to accomplish. So this generator that is returned doesn't actually read the slice into memory until it is called in the for loop, correct? I haven't actually used a generator before so I'm just trying to make sure I understand.</span>
<span class="comment-copy">@Wade. Assuming that that's how your HDF package works, that will be the case. A normal numpy array exists only in memory to begin with. The generator will not access a chunk until the loop gets to it. Previous chunks will be garbage collected. For an in-memory numpy array, the chunk would be a view that wouldn't allocate a copy of the data.</span>
<span class="comment-copy">But wouldn't this require the entire array to be held in memory in once? I am reading the big array from file, sorry if the example is unclear in that</span>
<span class="comment-copy">Ahh, that wasn't clear. Yes, this method would hold the whole thing in memory, as a list of arrays. If you want a lazy version of <code>np.split</code>, you could use something from the <code>itertools</code> module in the standard library. Something like the <code>grouper</code> method from the <a href="https://docs.python.org/3/library/itertools.html?highlight=itertools#itertools-recipes" rel="nofollow noreferrer"><code>itertools</code> recipes</a> would work.</span>
