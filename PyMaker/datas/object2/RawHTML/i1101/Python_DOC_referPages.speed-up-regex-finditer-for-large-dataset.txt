<div class="post-text" itemprop="text">
<p>I am trying to find positions of a match (N or -) in a large dataset.
The number of matches per string (3 million letters) is around 300,000. I have 110 strings to search in the same file so I made a loop using re.finditer to match and report position of each match but it is taking very long time. Each string (DNA sequence) is composed of only six characters (ATGCN-). Only 17 strings were processed in 11 hours. The question is what can I do to speed up the process?
The part of the code I am talking about is:</p>
<pre><code>for found in re.finditer(r"[-N]", DNA_sequence):
    position = found.start() + 1
    positions_list.append(position)
    positions_set = set(positions_list)
all_positions_set = all_positions_set.union(positions_set)
count += 1
print(str(count) + '\t' +record.id+'\t'+'processed')
output_file.write(record.id+'\t'+str(positions_list)+'\n')
</code></pre>
<p>I also tried to use re.compile as I googled and found that it could improve performance but nothing changed (match = re.compile('[-N]'))</p>
</div>
<div class="post-text" itemprop="text">
<p>If you have roughly 300k matches - you are re-creating increasingly larger <code>set</code>s that contain exactly the same elements as the <code>list</code> you are already adding to:</p>
<blockquote>
<pre><code>for found in re.finditer(r"[-N]", DNA_sequence):
    position = found.start() + 1
    positions_list.append(position)
    positions_set = set(positions_list) # 300k times ... why? why at all? 
</code></pre>
</blockquote>
<p>You can instead simply use the list you got anyway and put that into your <code>all_positions_set</code> after you found all of them:</p>
<pre><code>all_positions_set = all_positions_set.union(positions_list) # union takes any iterable
</code></pre>
<p>That should reduce the memory by more then 50% (sets are more expensive then lists) and also cut down on the runtime significantly.</p>
<hr/>
<p>I am unsure what is faster, but you could even skip using regex:</p>
<pre><code>t = "ATGCN-ATGCN-ATGCN-ATGCN-ATGCN-ATGCN-ATGCN-ATGCN-"

pos = []
for idx,c in enumerate(t):
    if c in "N-":
        pos.append(idx)

print(pos)  # [4, 5, 10, 11, 16, 17, 22, 23, 28, 29, 34, 35, 40, 41, 46, 47]
</code></pre>
<p>and instead use <a href="https://docs.python.org/3/library/functions.html#enumerate" rel="nofollow noreferrer">enumerate()</a> on your string to find the positions .... you would need to test if that is faster.</p>
</div>
<div class="post-text" itemprop="text">
<p>Regarding not using regex, I did actually that and now modified my script to run in less than 45 seconds using a defined function</p>
<pre><code>def find_all(a_str, sub):
start = 0
while True:
    start = a_str.find(sub, start)
    if start == -1: return
    yield start + 1
    start += len(sub)
</code></pre>
<p>So the new coding part is:</p>
<pre><code>N_list = list(find_all(DNA_sequence, 'N'))
dash_list = list(find_all(DNA_sequence, '-'))
positions_list = N_list + dash_list
all_positions_set = all_positions_set.union(positions_list)
count += 1
print(str(count) + '\t' +record.id+'\t'+'processed')
output_file.write(record.id+'\t'+str(sorted(positions_list))+'\n')
</code></pre>
</div>
<span class="comment-copy">Thanks Patrick! I agree with you with your suggestion for using list instead of set at each step.</span>
<span class="comment-copy">Regarding not using regex, I did actually that and now modified my script to run very fast using a function</span>
