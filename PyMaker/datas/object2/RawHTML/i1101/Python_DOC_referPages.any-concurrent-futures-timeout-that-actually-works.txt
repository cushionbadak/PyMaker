<div class="post-text" itemprop="text">
<p>Tried to write a process-based timeout (sync) on the cheap, like this:</p>
<pre><code>from concurrent.futures import ProcessPoolExecutor

def call_with_timeout(func, *args, timeout=3):
    with ProcessPoolExecutor(max_workers=1) as pool:
        future = pool.submit(func, *args)
        result = future.result(timeout=timeout)
</code></pre>
<p>But it seems the <code>timeout</code> argument passed to <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Future.result" rel="nofollow noreferrer">future.result</a> doesn't really work as advertised.</p>
<pre><code>&gt;&gt;&gt; t0 = time.time()
... call_with_timeout(time.sleep, 2, timeout=3)
... delta = time.time() - t0
... print('wall time:', delta)
wall time: 2.016767978668213
</code></pre>
<p>OK.</p>
<pre><code>&gt;&gt;&gt; t0 = time.time()
... call_with_timeout(time.sleep, 5, timeout=3)
... delta = time.time() - t0
... print('wall time:', delta)
# TimeoutError
</code></pre>
<p>Not OK - <strong>unblocked after 5 seconds</strong>, not 3 seconds.</p>
<p>Related questions show how to do this with thread pools, or with <a href="https://docs.python.org/3/library/signal.html#signal.alarm" rel="nofollow noreferrer">signal</a>. How to timeout a process submitted to a pool after <em>n</em> seconds, without using any _private API of multiprocessing? Hard kill is fine, no need to request a clean shutdown.</p>
</div>
<div class="post-text" itemprop="text">
<p>You might want to take a look at <a href="https://pypi.org/project/Pebble/" rel="nofollow noreferrer"><code>pebble</code></a>. </p>
<p>Its <code>ProcessPool</code> was designed to solve this exact issue: enable timeout and cancellation of running tasks without the need of shutting down the entire pool.</p>
<p>When a future times out or is cancelled, the worker gets actually terminated effectively stopping the execution of the scheduled function.</p>
<p>Timeout:</p>
<pre><code>pool = pebble.ProcessPool(max_workers=1)
future = pool.schedule(func, args=args, timeout=1)
try:
    future.result()
except TimeoutError:
    print("Timeout")
</code></pre>
<p>Example:</p>
<pre><code>def call_with_timeout(func, *args, timeout=3):
    pool = pebble.ProcessPool(max_workers=1)
    with pool:
        future = pool.schedule(func, args=args, timeout=timeout)
        return future.result()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The timeout is behaving as it should. <code>future.result(timeout=timeout)</code> stops after the given timeout. <em>Shutting down</em> the pool still waits for all pending futures to finish executing, which causes the unexpected delay.</p>
<p>You can make the shutdown happen in the background by calling <code>shutdown(wait=False)</code>, but the overall Python program won't end until all pending futures finish executing anyway:</p>
<pre><code>def call_with_timeout(func, *args, timeout=3):
    pool = ProcessPoolExecutor(max_workers=1)
    try:
        future = pool.submit(func, *args)
        result = future.result(timeout=timeout)
    finally:
        pool.shutdown(wait=False)
</code></pre>
<p>The Executor API offers no way to cancel a call that's already executing. <code>future.cancel()</code> can only cancel calls that haven't started yet. If you want abrupt abort functionality, you should probably use something other than <code>concurrent.futures.ProcessPoolExecutor</code>.</p>
</div>
<span class="comment-copy">I'm seeing the expected timeout length in preliminary tests.</span>
<span class="comment-copy">@user2357112 Interesting - <code>time.sleep</code> was just chosen as an MCVE and might have platform-dependent quirks - could you try it with a busy-looping function, or something dumb like <code>10**100000000</code>?</span>
<span class="comment-copy">...oh, I think I see. I think <i>cleaning up</i> the pool is blocking.</span>
<span class="comment-copy">I see the 5 second wall time for the second test on Ubuntu. What OS are you using?</span>
<span class="comment-copy">I was about to add examples myself. You were indeed faster :)</span>
<span class="comment-copy">Yeah, I actually had something going with pebble already.  I was kinda hoping there was some api in stdlib...  but +1 anyway</span>
<span class="comment-copy">I built <code>pebble</code> exactly because of that. The stdlib Pool implementations <code>concurrent.futures</code> and <code>multiprocessing</code> are all a bit too optimistic.</span>
<span class="comment-copy">Ah, I hadn't realised you're the pebble author.  Thanks for your work!</span>
<span class="comment-copy">Yes, but I don't want to wait for pending futures to finish executing. Just want them killed (which is why using a subprocess and not a worker thread in the first place).</span>
<span class="comment-copy">@wim: Answer expanded.</span>
<span class="comment-copy">So is the answer essentially "there is no high-level API to do it"?  Perhaps this is because <code>concurrent.futures</code>/<code>multiprocessing</code> must also work on Windows where SIGKILL is not necessarily available...</span>
