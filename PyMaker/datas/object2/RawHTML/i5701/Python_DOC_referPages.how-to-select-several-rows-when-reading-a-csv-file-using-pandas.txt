<div class="post-text" itemprop="text">
<p>I have a very large csv file with <code>millions of rows</code> and a list of the row numbers that I need.like</p>
<pre><code>rownumberList = [1,2,5,6,8,9,20,22]
</code></pre>
<p>I know there is something called <code>skiprows</code> that helps to skip several rows when <code>reading csv file</code> like that</p>
<pre><code>df = pd.read_csv('myfile.csv',skiprows = skiplist)
#skiplist would contain the total row list deducts rownumberList
</code></pre>
<p>However, since the csv file is very large, directly selecting the rows that I need could be more efficient. So I was wondering are there any methods to <code>select rows</code> when using <code>read_csv</code>? Not try to select rows using <code>dataframe</code> afterwards, since I try to minimize the time of reading file.Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>I am not sure about <code>read_csv()</code> from Pandas (<a href="https://stackoverflow.com/questions/33642951/python-using-pandas-structures-with-large-csviterate-and-chunksize">there is though a way to use an <code>iterator</code> for reading a large file in chunks</a>), but you can read the file line by line (lazy-loading, not reading the whole file in memory) with <a href="https://docs.python.org/3/library/csv.html#csv.reader" rel="nofollow noreferrer"><code>csv.reader</code></a> (or <a href="https://docs.python.org/3/library/csv.html#csv.DictReader" rel="nofollow noreferrer"><code>csv.DictReader</code></a>), leaving only the desired rows with the help of <a href="https://docs.python.org/3/library/functions.html#enumerate" rel="nofollow noreferrer"><code>enumerate()</code></a>:</p>
<pre><code>import csv

import pandas as pd


DESIRED_ROWS = {1, 17, 28}
with open("input.csv") as input_file:
    reader = csv.reader(input_file)

    desired_rows = [row for row_number, row in enumerate(reader)
                    if row_number in DESIRED_ROWS]

df = pd.DataFrame(desired_rows)
</code></pre>
<p>(assuming you would like to pick random/discontinuous rows and not a "continuous chunk" from somewhere in the middle - in that case @James's idea to have "start and "stop" would work generally better).</p>
</div>
<div class="post-text" itemprop="text">
<p>There is a parameter called  <code>nrows : int, default None</code>
<strong><em>Number of rows of file to read. Useful for reading pieces of large files</em></strong> (Docs)</p>
<pre><code>pd.read_csv(file_name,nrows=int)
</code></pre>
<p>In case you need some part in the middle. Use both <code>skiprows</code> as well as <code>nrows</code> in <code>read_csv</code>.if skiprows indicate the beginning rows and <code>nrows</code> will indicate the next number of rows after skipping eg. </p>
<p>Example: </p>
<pre><code>pd.read_csv('../input/sample_submission.csv',skiprows=5,nrows=10)
</code></pre>
<p>This will select data from the 6th row to 16 row</p>
<p><em>Edit based on comment</em>:</p>
<p>Since there is a list this one might help i.e </p>
<pre><code>li = [1,2,3,5,9]
r = [i for i in range(max(li)) if i not in li]
df = pd.read_csv('../input/sample_submission.csv',skiprows=r,nrows= max(li))
# This will skip the rows you dont want as well as limit the number of rows to maximum of the list.
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>From de <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html" rel="nofollow noreferrer">documentation</a> you can see that <code>skiprows</code> can take an integer or a list as values to remove some lines.</p>
<p>So basicaly you can tell it to remove all but those you want. For this you first need to know the number in lines in the file (best if you know beforehand) by open it and counting as following:</p>
<pre><code>with open('myfile.csv') as f:
    row_count = sum(1 for row in f)
</code></pre>
<p>Now you need to create the complementary list (here are sets but also works, don't know why). First you create the one from 1 to the number of rows and then substract the numbers of the rows you want to read.</p>
<pre><code>skiplist = set(range(1, row_count+1)) - set(rownumberList)
</code></pre>
<p>Finally you can read the csv as normal. </p>
<pre><code>df = pd.read_csv('myfile.csv',skiprows = skiplist)
</code></pre>
<p>here is the full code:</p>
<pre><code>import pandas as pd

with open('myfile.csv') as f:
    row_count = sum(1 for row in f)

rownumberList = [1,2,5,6,8,9,20,22]
skiplist = set(range(1, row_count+1)) - set(rownumberList)

df = pd.read_csv('myfile.csv', skiprows=skiplist)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You will not be able to circumvent the read time when accessing a large file.  If you have a very large CSV file, any program will need to read through it at least up to the point where you want to begin extracting rows.  Really, that is what databases are designed for.</p>
<p>However, if you want to extract rows 300,000 to 300,123 from a 10,000,000 row CSV file, you are better off reading <strong>just</strong> the data you need into Python before converting it to a data frame in Pandas.  For this you can use the <code>csv</code> module.</p>
<pre><code>import csv
import pandas

start = 300000
stop = start + 123
data = []
with open('/very/large.csv', 'r') as fp:
    reader = csv.reader(fp)
    for i, line in enumerate(reader):
        if i &gt;= start:
            data.append(line)
        if i &gt; stop:
            break

df = pd.DataFrame(data)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>import pandas as pd

df = pd.read_csv('Data.csv')

df.iloc[3:6] 
</code></pre>
<blockquote>
<p>Returns rows 3 through 5 and all columns.</p>
<p><a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html" rel="nofollow noreferrer">https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.iloc.html</a></p>
</blockquote>
</div>
<span class="comment-copy">That still reads through the entire file, as opposed to stopping when the last line of interest is read.</span>
<span class="comment-copy">@James well, our solutions both have the same worst case (stop being the last line). But, that was a good idea to stop iterating if we know we don't need to go any further. Thanks.</span>
<span class="comment-copy">Thanks, Dark. But the problem is that I have a list contains the row numbers I need like list = [1,3,50,60] rather than choose 60 rows from the beginning.</span>
<span class="comment-copy">Its a much of hard work for the function to go through the csv and keeping counter of which line number it belongs.  I would prefer you to load csv and then select the rows in dataframe</span>
<span class="comment-copy">@huier Check the edit. That might help</span>
<span class="comment-copy">Thanks a lot! I will try how your method performs. Thanks!!!</span>
<span class="comment-copy">I was wrong at first, I misunderstood the question but now it works as wanted. The process of reading the lines takes very few seconds (tested with a 2.407.609 lines file). If your file wont change number of lines, you can just put the number there instead of row_count.</span>
<span class="comment-copy">Thanks, gonna try that!!!</span>
<span class="comment-copy">Thanks! Gonna try that and see if this method saves me some time.</span>
<span class="comment-copy">Thanks, but like I said in the description, I try to select rows when read_csv(), not afterwards.</span>
