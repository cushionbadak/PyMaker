<div class="post-text" itemprop="text">
<p>I wrote a script that updates a table. Since I couldn't find a way to "batch" update, my script updates the table one row at a time. I assumed that for a set of 100,000 rows, it would take a few seconds to do the update.</p>
<p>No. Each write operation takes ~100 milliseconds. The entire write operation takes ((((100,000 * 100)/1000)/60)/60) = 2.77 hours. Why does it take so long to write?</p>
<p>Here's the code I'm using:</p>
<pre><code>import psycopg2
...
entries = get_all_entries()
conn = psycopg2.connect(params)
try:
    for entry in entries:
        cursor = conn.cursor()
        cursor.execute(UPDATE_QUERY.format(entry.field1, entry.field2))
        cursor.close()
finally:
    conn.close()
</code></pre>
<p>What am I doing wrong?</p>
</div>
<div class="post-text" itemprop="text">
<p>Have you tried:</p>
<pre><code>cursor = conn.cursor()
for entry in entries:
     cursor.execute(UPDATE_QUERY.format(entry.field1, entry.field2))

cursor.close()
</code></pre>
<p>You can profile this code with <a href="https://docs.python.org/3/library/profile.html" rel="nofollow noreferrer">https://docs.python.org/3/library/profile.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>Instead of updating table row by row from the client side you could to upload your data into server-side temporary table using <a href="http://initd.org/psycopg/docs/usage.html#using-copy-to-and-copy-from" rel="nofollow noreferrer"><code>copy_from()</code></a> method and then update the table by single SQL.</p>
<p>Here is the artificial example:</p>
<pre><code>#!/usr/bin/env python

import time, psycopg2
from random import random
from cStringIO import StringIO

CRowCount = 100000

conn = psycopg2.connect('')
conn.autocommit = False

print('Prepare playground...')
cur = conn.cursor()
cur.execute("""
    drop table if exists foo;
    create table foo(i int primary key, x float);
    insert into foo select i, 0 from generate_series(1,%s) as i;
""", (CRowCount,))
print('Done.')
cur.close();
conn.commit();

print('\nTest update row by row...')
tstart = time.time()
cur = conn.cursor()
for i in xrange(1,CRowCount+1):
    cur.execute('update foo set x = %s where i = %s', (random(), i));
conn.commit()
cur.close()
print('Done in %s s.' % (time.time() - tstart))

print('\nTest batch update...')
tstart = time.time()
cur = conn.cursor()
# Create temporary table to hold our data
cur.execute('create temp table t(i int, x float) on commit drop')
# Create and fill the buffer from which data will be uploaded
buf = StringIO()
for i in xrange(1,CRowCount+1):
    buf.write('%s\t%s\n' % (i, random()))
buf.seek(0)
# Upload data from the buffer to the temporary table
cur.copy_from(buf, 't')
# Update test table using data previously uploaded
cur.execute('update foo set x = t.x from t where foo.i = t.i')
cur.close();
conn.commit();
print('Done in %s s.' % (time.time() - tstart))
</code></pre>
<p>Output:</p>
<pre>
Prepare playground...
Done.

Test update row by row...
Done in 62.1189928055 s.

Test batch update...
Done in 3.95668387413 s.
</pre>
<p>As you can see the second way is about 20 times faster.</p>
</div>
<span class="comment-copy">You can avoid making the transaction too big (which slows queries down) by running <code>conn.commit()</code> every few (2500?) queries… assuming you’re okay with not having the usual safeties of a single transaction.</span>
<span class="comment-copy">One way to speedup it: upload your data into temporary table using <a href="http://initd.org/psycopg/docs/usage.html#using-copy-to-and-copy-from" rel="nofollow noreferrer"><code>copy_to()</code></a>, then update your table by single SQL statement using, for example <a href="https://www.postgresql.org/docs/current/static/sql-update.html" rel="nofollow noreferrer"><code>UPDATE ... FROM ...</code></a>.</span>
<span class="comment-copy">@Abelisto interesting. can you post an answer with how you would do this?</span>
<span class="comment-copy">this isnt that much faster</span>
<span class="comment-copy">thanks! can you explain a bit about why this is faster?</span>
<span class="comment-copy">@dopatraman Mostly because instead of executing 100,000 SQL statements you executes only 3.</span>
<span class="comment-copy">can you explain these lines specifically? <code>cur.execute('create temp table t(i int, x float) on commit drop') buf = StringIO() for i in xrange(1,CRowCount+1):     buf.write('%s\t%s\n' % (i, random())) buf.seek(0) cur.copy_from(buf, 't')</code></span>
<span class="comment-copy">thank you very much!</span>
