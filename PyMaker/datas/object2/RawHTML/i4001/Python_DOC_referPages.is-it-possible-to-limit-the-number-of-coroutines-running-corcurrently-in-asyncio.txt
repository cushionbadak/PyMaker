<div class="post-text" itemprop="text">
<p>I already wrote my script using asyncio but found that the number of coroutines running simultaneously is too large and it often ends up hanging around.</p>
<p>So I would like to limit the number of coroutines concurrently, and once it reaches the limit, I want to wait for any coroutine to be finished before another is executed.</p>
<p>My current code is something like the following:</p>
<pre><code>loop = asyncio.get_event_loop()
p = map(my_func, players)
result = loop.run_until_complete(asyncio.gather(*p))

async def my_func(player):
    # something done with `await`
</code></pre>
<p>The <code>players</code> is of type <code>list</code> and contains many elements (say, 12000). It needs so much computational resource to run all of them simultaneously in <code>asyncio.gather(*p)</code> so I would rather like the number of players run simultaneously to be 200. Once it reaches 199, then I wish another coroutine starts to be executed.</p>
<p>Is this possible in asyncio?</p>
</div>
<div class="post-text" itemprop="text">
<p>I can suggest using <a href="https://docs.python.org/3/library/asyncio-sync.html#asyncio.BoundedSemaphore" rel="nofollow noreferrer"><code>asyncio.BoundedSemaphore</code></a>.</p>
<pre><code>import asyncio

async def my_func(player, asyncio_semaphore):
    async with asyncio_semaphore:
        # do stuff

async def main():
    asyncio_semaphore = asyncio.BoundedSemaphore(200)
    jobs = []
    for i in range(12000):
        jobs.append(asyncio.ensure_future(my_func(players[i], asyncio_semaphore)))
    await asyncio.gather(*jobs)

if __name__ == '__main__':
    loop = asyncio.get_event_loop()
    loop.set_debug(True)
    loop.run_until_complete(main())
</code></pre>
<p>This way, only 200 concurrent tasks can acquire semaphore and use system resources while 12000 tasks are at hand.</p>
</div>
<div class="post-text" itemprop="text">
<p>You might want to consider using <a href="http://aiostream.readthedocs.io/en/latest/operators.html#aiostream.stream.map" rel="nofollow noreferrer">aiostream.stream.map</a> with the <code>task_limit</code> argument:</p>
<pre><code>from aiostream import stream, pipe

async def main():
    xs = stream.iterate(players)
    ys = stream.map(xs, my_func, task_limit=100)
    zs = stream.list(ys)
    results = await zs
</code></pre>
<p>Same approach using pipes:</p>
<pre><code>async def main():
    results = await (
        stream.iterate(players) | 
        pipe.map(my_func, task_limit=100) |
        pipe.list())
</code></pre>
<p>See the <a href="https://github.com/vxgmichel/aiostream" rel="nofollow noreferrer">aiostream project page</a> and the <a href="http://aiostream.readthedocs.io" rel="nofollow noreferrer">documentation</a> for further information.</p>
<p><sub>Disclaimer: I am the project maintainer.</sub></p>
</div>
<span class="comment-copy">Maybe the <a href="https://docs.python.org/3/library/asyncio-queue.html" rel="nofollow noreferrer">asyncio queueing</a> library could be of some use to you?</span>
<span class="comment-copy">Coroutines don't actually run simultaneously, if that's what you're thinking. They take turns.</span>
<span class="comment-copy">@castis Thanks and let me check it out...</span>
<span class="comment-copy">Note that you don't need a <code>BoundedSemaphore</code> - an ordinary <code>Semaphore(200)</code> will have the same effect. A <code>BoundedSemaphore</code> serves a different purpose - it is designed to differ from ordinary <code>Semaphore</code> by raising an exception (instead of blocking) when the semaphore is <i>released</i> more times than it was acquired. That cannot happen when it is only acquired/released using <code>with</code>.</span>
<span class="comment-copy">@user4815162342 thanks for the info! I'll check it out.</span>
