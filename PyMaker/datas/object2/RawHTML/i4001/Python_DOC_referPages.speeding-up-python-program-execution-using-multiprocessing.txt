<div class="post-text" itemprop="text">
<p>Trying to better understand multiprocessing and how it can be used for below scenario.</p>
<p>I have a folder of 100,000 images. I have a python script that takes each image, performs some operations on the image and stores the result into another directory. </p>
<p>It takes 5 seconds for each operation on the image. </p>
<p>My question is as follows - </p>
<p>When my script is executing on a single image. If I look at cpu statistics using the top command , I can see that neither my cpu or my memory are at 100% ( this is a multi core processor) </p>
<p>Moreover I am able to process more images per minute by simply starting many python scripts in different shells. </p>
<p>What is the pythonic way to perform this task in a faster way? If the number of images increase how can I scale this horizontally? </p>
<p>Any resources / comments would be helpful. </p>
</div>
<div class="post-text" itemprop="text">
<p>you can use <code>asyncio</code> library to concurrently process images. You simply define an event-loop, register tasks into the event loop, and thats all. The system decides which one to run next. When a task is I/O bound (in your case, storing the value to somewhere within the system), or awaiting a response from somewhere, the system picks another task from the event loop instead of waiting, and so on.</p>
<p><a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow noreferrer">https://docs.python.org/3/library/asyncio.html</a></p>
</div>
<div class="post-text" itemprop="text">
<p>the I/O operations of open/read/write files are the ones that causes your cpu to be idle </p>
<p>when processing image it usually a matrices multiplications and takes a lot of cpu resources and can be done in parallel based on the cpu cores (gives or takes 2*cores)</p>
<p>my suggestion is to use different threads pool based on the task, for handling file you can create as many threads as you want without much performance downgrade, but processing the image i.e making computation with the byte array can be scaled as much as cpu cores, above that you should notice performance downgrade </p>
<p>I suggest using the worker-queue pattern describe <a href="https://docs.python.org/2/library/queue.html" rel="nofollow noreferrer">here</a></p>
<p>you can also take a look at event loop implementation that might produce better results due to it's nature of non-blocking, you can find example <a href="http://www.tornadoweb.org/en/stable/guide/queues.html" rel="nofollow noreferrer">here</a></p>
<p>keep in mind to fully utilise the cpu cores you should create multiple threads of event loops, one (or two) per core, the threads are scaled automatically (most os) on the cpu cores  </p>
</div>
<div class="post-text" itemprop="text">
<p>You could make use of <code>binge</code> (<code>pip install binge</code>) - it is a general purpose multiprocessing wrapper:</p>
<pre><code>def image_worker(image_path, output_path):
    (load image, process, and save)
    return None

img_paths = ['./img1.png',
             './img2.png',
             ...
             './img100000.png']

from binge import B
result = B(worker, cores=4)(img_paths, '../otherfolder/')
</code></pre>
<p>where <code>cores</code> is how many processes will be used. The result will be the list of returned values of the image_worker, i.e. a list of Nones.</p>
<p>cf: <a href="https://github.com/ceyzeriat/binge/" rel="nofollow noreferrer">binge documentation</a></p>
</div>
<span class="comment-copy">See the example of this link: <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">docs.python.org/3/library/multiprocessing.html</a></span>
