<div class="post-text" itemprop="text">
<p>I have multiple text (<code>.txt</code>) files saved in a folder.  I'm trying to combine them all into a single dataframe.  So far I have been able to combine them, but not in the manner I'd like.</p>
<p>The text files (named <code>yob####.txt</code> where <code>####</code> is a year) have information that looks like this:</p>
<pre><code>Jennifer,F,58376
Amanda,F,35818
Jessica,F,33923
Melissa,F,31634
Sarah,F,25755
Heather,F,19975
Nicole,F,19917
Amy,F,19834
Elizabeth,F,19529
Michelle,F,19122
Kimberly,F,18499
Angela,F,17970
</code></pre>
<p>I'm trying to open each file, add the year to the end of the row, and move on.</p>
<pre><code>def main():
    files = file_paths(FILE_FOLDER) # returns a list of file paths, i.e. ["C:\Images\file.txt","C:\Images\file2.txt", ...]

    df = []
    for file in files:
        year = file.split("\\")[-1][3:7] 
        df.append(pd.read_table(file)+","+year)
    big_df = pd.concat(df, ignore_index=True, axis=1)
    big_df.to_csv("Combined.csv", header=False, index=False)
</code></pre>
<p>This almost works...except it takes each file and puts the data in a column, the next file in a second column, next file in a third, etc.</p>
<p>Current output:
<a href="https://i.stack.imgur.com/Y0pm9.jpg" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/Y0pm9.jpg"/></a></p>
<p>The expected output is the same, except when it opens the 1881 file, it adds the info to the end of <code>1880</code>. Then <code>1882</code> goes after the <code>1881</code> data, etc. etc.</p>
</div>
<div class="post-text" itemprop="text">
<ol>
<li>With <code>read_table</code>, the default separator is assumed to be whitespace (<code>sep='\t'</code>). Change <code>read_table</code> to <code>read_csv</code>, which infers your separator. Alternatively, specify <code>sep=','</code> for the same effect.</li>
<li>You're trying to add a new column <code>year</code>, but you're not doing that correctly. You can use <code>assign</code> to add it in</li>
<li>Concatenate vertically (<code>axis=0</code>, the default), not horizontally.</li>
</ol>
<p></p>
<pre><code>df_list = []
for file in files:
    year = ...
    df_list.append(pd.read_csv(file, header=None).assign(year=year))

big_df = pd.concat(df_list, ignore_index=True)
big_df.to_csv("Combined.csv", header=False, index=False)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <a href="https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.assign.html" rel="nofollow noreferrer"><code>pd.DataFrame.assign</code></a> to add a column seamlessly while you iterate.</p>
<p>Note also that it is good practice to use <a href="https://docs.python.org/3/library/os.path.html#os.path.basename" rel="nofollow noreferrer"><code>os.path.basename</code></a> instead of splitting by specific characters: this will ensure your code will work on multiple platforms.</p>
<p><em>Updated</em>: Add <code>header=None</code> and use <code>pd.read_csv</code>, as discussed on other answer.</p>
<pre><code>dfs = []
for file in files:
    year = os.path.basename(fn)[3:7]
    dfs.append(pd.read_csv(file, header=None).assign(Year=year))

df = pd.concat(dfs, ignore_index=True, axis=1)
</code></pre>
<p>A more efficient way is to use a list comprehension:</p>
<pre><code>dfs = [pd.read_csv(file, header=None).assign(Year=os.path.basename(fn)[3:7]) \
       for file in files]

df = pd.concat(dfs, ignore_index=True, axis=1)
</code></pre>
</div>
<span class="comment-copy">You are currently concatenating the DFs in columns and not in rows, try to <code>big_df = pd.concat(df, ignore_index=True, axis=0)</code>  instead</span>
<span class="comment-copy">@Ben.T - I have tried that too...As I have it originally (axis is 1), it runs in approx. 4.6 seconds.  Doing <code>axis=0</code> pushes it up to about 38.9s. and shoots the file size from 38MB to 293MB, and it has lots of "empty columns" (<a href="https://i.stack.imgur.com/tPIk6.jpg" rel="nofollow noreferrer">screenshot here</a>)</span>
<span class="comment-copy">indeed it does not look nice...The problem might be that there is no header in your txt file, then the first row is by definition your columns' names and none of them are the same year after year. Try to do <code>pd.read_table(file, header=None)</code>  and still concatenate with <code>axis=0</code></span>
<span class="comment-copy">@Ben.T - Aha!! That looks like it does the trick, reduced to 8.2 seconds and ~33MB :D</span>
<span class="comment-copy">Thanks for the second point, I knew the way I was adding the year wasn't pythonic/was kludgy.  When I try yours, I get a <code>MemoryError</code> at the line <code>big_df = pd.concat(df, ignore_index=True)</code></span>
<span class="comment-copy">@BruceWayne Looks like you have a lot of data :D... by the way, did you mean` df_list`? I've changed the variables in my code a bit.</span>
<span class="comment-copy">It's a lot of data, but not a crazy amount I wouldn't think. FYI it's the "National Database" from <a href="https://www.ssa.gov/OACT/babynames/limits.html" rel="nofollow noreferrer">Social Security Admin</a>...I'm surprised it's hitting a memory error?  (And thanks yeah, I noticed the variable name changes).</span>
<span class="comment-copy">@BruceWayne What is <code>len(df_list)</code>? Also, what is <code>sum(map(len, df_list))</code>?</span>
<span class="comment-copy">@BruceWayne AHA! Because your text files have no header. The reason that happened is because concat tries to auto align the concatted DataFrames, resulting in a huge memory blowout with NaNs. Thanks for that, I'll fix my answer to reflect that.</span>
<span class="comment-copy">Assign isn't the only problem here. The other problem is the separator and the manner in which concatenation is done (see my answer)</span>
