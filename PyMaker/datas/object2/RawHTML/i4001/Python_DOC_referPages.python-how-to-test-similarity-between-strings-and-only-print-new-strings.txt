<div class="post-text" itemprop="text">
<p>I have developed a webscraper with beautiful soup that scrapes news from a website and then sends them to a telegram bot. Every time the program runs it picks up all the news currently on the news web page, and I want it to just pick the new entries on the news and send only those. </p>
<p>How can I do this? Should I use a sorting algorithm of some sort?</p>
<p>Here is the code:</p>
<pre><code>#Lib requests

import requests
import bs4

fonte = requests.get('https://www.noticiasaominuto.com/')
soup = bs4.BeautifulSoup(fonte.text, 'lxml')
body = soup.body

for paragrafo in body.find_all('p', class_='article-thumb-text'):
      print(paragrafo.text)
      conteudo = paragrafo.text

id = requests.get('https://api.telegram.org/bot&lt;TOKEN&gt;/getUpdates')
chat_id = id.json()['result'][0]['message']['from']['id']

print(chat_id)

msg = requests.post('https://api.telegram.org/bot&lt;TOKEN&gt;/sendMessage', data = {'chat_id': chat_id ,'text' : conteudo})
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You need to keep track of articles that you have seen before, either by using a full database solution or by simply saving the information in a file. The file needs to be read before starting. The website is then scraped and compared against the existing list. Any articles not in the list are added to the list. At the end, the updated list is saved back to the file.</p>
<p>Rather that storing the whole text in the file, a <a href="https://docs.python.org/3/library/hashlib.html?highlight=hash#module-hashlib" rel="nofollow noreferrer">hash</a> of the text can be saved instead. i.e. convert the text into a unique number, in this case a hex digest is used to make it easier to save to a text file. As each hash will be unique, they can be stored in a Python set to speed up the checking:</p>
<pre><code>import hashlib
import requests
import bs4
import os

# Read in hashes of past articles
db = 'past.txt'

if os.path.exists(db):
    with open(db) as f_past:
        past_articles = set(f_past.read().splitlines())
else:
    past_articles = set()

fonte = requests.get('https://www.noticiasaominuto.com/')
soup = bs4.BeautifulSoup(fonte.text, 'lxml')

for paragrafo in soup.body.find_all('p', class_='article-thumb-text'):
    m = hashlib.md5(paragrafo.text.encode('utf-8'))

    if m.hexdigest() not in past_articles:
        print('New {} - {}'.format(m.hexdigest(), paragrafo.text))
        past_articles.add(m.hexdigest())

        # ...Update telegram here...

# Write updated hashes back to the file
with open(db, 'w') as f_past:
    f_past.write('\n'.join(past_articles))
</code></pre>
<p>The first time this is run, all articles will be displayed. The next time, no articles will be displayed until the website is updated.        </p>
</div>
<span class="comment-copy">You need to keep a DB of the articles you've already posted.</span>
