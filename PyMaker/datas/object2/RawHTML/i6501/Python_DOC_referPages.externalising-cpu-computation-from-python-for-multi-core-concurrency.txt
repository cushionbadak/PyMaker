<div class="post-text" itemprop="text">
<p>I have a PyQt5 application which runs perfectly on my development machine (Core i7 Windows 7), but has performance issues on my target platform (Linux Embedded ARM). I've been researching Python concurrency in further detail, prior to 'optimising' my current code (i.e. ensuring all UI code is in the MainThread, with all logic code in separate threads). I've learnt that the GIL largely prevents the CPython interpreter from realising true concurrency.</p>
<p>My question: would I be better off using IronPython or Cython as the interpreter, or sending all the logic to an external non-Python function which can make use of multiple cores, and leave the PyQt application to simply update the UI? If the latter, which language would be well suited to high-speed, concurrent calculation?</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>If the latter, which language would be well suited to high-speed, concurrent calculation?</p>
</blockquote>
<p>You've written a lot about your system and yet not enough about what it actually <em>does</em>; what kind of "calculations" are you doing? â€” If you're doing anything heavily computational, it's very likely <a href="https://groups.google.com/forum/m/#!topic/openblas-users/W1tviVFDx1w" rel="nofollow noreferrer">someone has worked very hard to make a hardware-optimized library to do these kinds of calculations</a>, e.g. BLAS via <a href="https://stackoverflow.com/q/9000164/1391325">scipy/numpy</a> (see <a href="https://developer.arm.com/products/software-development-tools/hpc/arm-performance-libraries" rel="nofollow noreferrer">Arm's own website</a>). You want to push as much work out of your own Python code and into their hands. The language you use to call these libraries is much less important. Python is already great for this kind of "gluing" work for such libraries. Note that even using built-in Python functions, such as using <a href="https://docs.python.org/3/library/functions.html#sum" rel="nofollow noreferrer"><code>sum(value for value in some_iter)</code></a> instead of summing in a Python <code>for</code> loop, <a href="https://wiki.python.org/moin/PythonSpeed#Take_advantage_of_interpreter_optimizations" rel="nofollow noreferrer">also pushes computation out of slow interpretation and into highly-optimized C code</a>.</p>
<p>Otherwise, without profiling your actual code, it's hard to say what would be best. After doing the above by efficiently formulating your calculations in a way that optimized libraries can best do their work (e.g. by properly vectorizing them), you can then use Python's <code>multiprocessing</code> to divide up whatever Python logic is causing a bottleneck from that which isn't (see <a href="https://stackoverflow.com/a/20939442/1391325">this answer on why <code>multiprocesing</code> is often better than <code>threading</code></a>). I'd wager this would be much more beneficial than just swapping out CPython for another implementation.</p>
<p>Only once you've delegated as much computation to external libraries as possible <em>and</em> paralllelized as well as possible using <code>multiprocessing</code> would I then start writing these computation-heavy processes in Cython, which could be considered a type of low-level optimization over the aforementioned architectural improvements.</p>
</div>
<div class="post-text" itemprop="text">
<p>echoing @errantlinguist, please be aware that parallel performance is highly application-dependent.</p>
<p>To maintain GUI responsiveness, yes, I would just use a separate "worker" thread to keep the main thread available to handle GUI events.</p>
<p>To do something "insanely parallel", like a Monte Carlo computation, where you have many many completely independent tasks which have minimal communication between them, I might try multiprocessing.</p>
<p>If I were doing something like very large matrix operations, I would do it multithreaded. Anaconda will automatically parallelize some numpy operations via MKL on intel processors (but this will not help you on ARM). I believe you could look at something like <a href="http://numba.pydata.org/numba-doc/latest/user/parallel.html" rel="nofollow noreferrer">numba</a> to help you with this, if you stay in python. If you are unhappy with performance, you may want to try implementing in C++. If you use almost all vectorized numpy operations, you should not see a big difference from using C++, but as python loops, etc. start to creep in, you will probably begin to see big differences in performance (beyond the max 4x you will gain by parallelizing your python code over 4 cores). If you switch to C++ for matrix operations, I highly recommend the <a href="http://eigen.tuxfamily.org/index.php?title=Main_Page" rel="nofollow noreferrer">Eigen</a> library. It's very fast and easy to understand at a high-level.</p>
<p>Please be aware that when you use multithreading, you are usually in a shared memory context, which eliminates a lot of the expensive io you will encounter in multiprocessing, but it also introduces some classes of bugs you are not used to encountering in serial programs (when two threads begin to access the same resources). In multiprocessing, memory is usually separate, except for explicitly defined communications between the processes. In that sense, I find that multiprocessing code is typically easier to understand and debug.</p>
<p>Also there are frameworks out there to handle complex computational graphs, with many steps, which may include both multithreading and multiprocessing (try <a href="https://dask.pydata.org/en/latest/" rel="nofollow noreferrer">dask</a>).</p>
<p>Good luck!</p>
</div>
<span class="comment-copy">Does your target platform have more than one core?</span>
<span class="comment-copy">The prototype hardware has 4 cores, which we can assume is representative of the production target platform as well.</span>
<span class="comment-copy">Sometimes on Linux it can be better to restrict a Python application to a single core to make it faster. You can try to start the application with <a href="https://linux.die.net/man/1/taskset" rel="nofollow noreferrer">linux.die.net/man/1/taskset</a> to see if this helps.</span>
<span class="comment-copy">Another solution is to use Python's <code>multiprocessing</code>.</span>
<span class="comment-copy">I've been reading about the concurrent.futures and mutliprocessing.pool options as well, which look promising.</span>
<span class="comment-copy">Very good point, thank you. This is a data acquisition and display system; it checks the status of a number of sensors, records their value (for plotting), and updates their respective GUI element accordingly. The data acquisition component is already in an external Python file, which is run on a separate thread from the MainThread. The MainThread still contains non-GUI logic, which is largely the focus of this question. I could externalise that logic as well, but my research suggests that threading.Thread() doesn't provide the concurrency one would think.</span>
<span class="comment-copy">Python's multi<i>threading</i> isn't about performance because, as you already stated, the GIL essentially cripples it; it's mainly used to maintain responsiveness in GUI components. If your Python code still has a lot of non-GUI logic, I'd try putting that in separate <i>processes</i> which then asynchronously call back to the relevant GUI components. But don't create tons of tiny processes, or at least not until you profile the changes from using a few.</span>
<span class="comment-copy">Ok great, thanks, you've validated my interpretation of threading vs. processes. I imagine then that I'll still use multithreading to ensure GUI responsiveness, but will then incorporate multiprocessing to actually execute the work in the background. Once the work has been executed, I then emit a custom signal, which causes a GUI event on the MainThread.</span>
<span class="comment-copy">Yes, just have each process implement a callback function for your relevant widget/component, which live in their own GUI thread or threads-- It's a pretty common pattern. The multi-threading-GUI-vs.-multiprocessing thing is somewhere on SO in more detail but I'm too tired and lazy to find it.</span>
<span class="comment-copy">But don't overdo the number of processes.</span>
