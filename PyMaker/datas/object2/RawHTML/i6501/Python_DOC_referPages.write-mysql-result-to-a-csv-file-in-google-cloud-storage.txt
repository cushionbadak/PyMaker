<div class="post-text" itemprop="text">
<p>I need to write a result set from MySQL ina csv format inside a bucket in Google Cloud Storage.</p>
<p>Following the instructions <a href="https://cloud.google.com/appengine/docs/standard/python/blobstore/#Python_Using_the_Blobstore_API_with_Google_Cloud_Storage" rel="nofollow noreferrer">here</a>, I created the following example code:</p>
<pre><code>import cloudstorage
from google.appengine.api import app_identity
import db # My own Mysql wrapper

dump = db.get_table_dump(schema) # Here I made a simples SQL SELECT and fetchall()
bucket_name = app_identity.get_default_gcs_bucket_name()
file_name = "/" + bucket_name + "/finalfiles/" + schema + "/" +"myfile.csv"
with cloudstorage.open(file_name, "w") as gcsFile:
    gcsFile.write(dump)
</code></pre>
<p>It did not work 'cause <code>write</code> expects a string parameter and <code>dump</code> is tuple of tuples result from <code>fetchall()</code>.</p>
<p>I can't use <a href="https://stackoverflow.com/questions/2952366/dump-csv-from-sqlalchemy">this approach</a> (or similar) since I can't write files in GAE enviroment and I also can't create a CSV string from tuple like <a href="https://stackoverflow.com/questions/40993966/python-convert-tuple-to-comma-separated-string">here</a>, due to the size o my result set (Actually, I tried it and it takes too long and it timed out before finish).</p>
<p>So, my question is, which is the best way to get a result set from MySQL and save it as CSV in a Google Cloud Storage Bucket?</p>
</div>
<div class="post-text" itemprop="text">
<p>I just went through the same problem with PHP. I ended up using the cloud sql api (<a href="https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/" rel="nofollow noreferrer">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/</a>) with the following workflow:</p>
<ol>
<li>Create an export bucket (i.e. test-exports)</li>
<li>Give the SQL Instance Read/Write permissions to the bucket created in step 1</li>
<li>Within the application, make a call to instance export (<a href="https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export" rel="nofollow noreferrer">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/instances/export</a>). This endpoint accepts the SQL to run, as well as a path to an output bucket. (created in step (1))</li>
<li>Step (3) will return back an operation with a 'name' property. You can use this 'name' and poll the operations/get endpoint (<a href="https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/operations/get" rel="nofollow noreferrer">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/operations/get</a>) until the status is returned as DONE</li>
</ol>
<p>We have a job which performs these steps nightly (as well as an import using the /import command) on 6 tables and have yet to see any issues. The only thing to keep in mind is that only one operation can run on a single database instance at a time. To combat this, you should the top item from the the operations list endpoint (<a href="https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/operations/list" rel="nofollow noreferrer">https://cloud.google.com/sql/docs/mysql/admin-api/v1beta4/operations/list</a>) to confirm the database is ready before issuing any commands.</p>
</div>
<span class="comment-copy">Can you write to in memory files?</span>
<span class="comment-copy">Sorry @JohannesReichard, but I did't understand your question. I'm kind of new in GAE. Are memory files something that I can write in?</span>
<span class="comment-copy">I never used GAE but python not only supports to write to a file on a hard drive but also to a file like object which lives in memory: docs.python.org/3/library/io.html#in-memory</span>
<span class="comment-copy">Thank for the link @JohannesReichard. I'll see if it works, but looks promising.</span>
