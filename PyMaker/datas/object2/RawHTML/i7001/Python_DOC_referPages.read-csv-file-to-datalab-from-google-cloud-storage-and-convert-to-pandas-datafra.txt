<div class="post-text" itemprop="text">
<p>I am trying to read a csv file save in gs to a dataframe for analysis</p>
<p>I have follow the following steps without success</p>
<pre><code>mybucket = storage.Bucket('bucket-name')
data_csv = mybucket.object('data.csv')
df = pd.read_csv(data_csv)
</code></pre>
<p>this doesn't work since data_csv is not a path as expected by pd.read_csv
I also tried</p>
<pre><code>%%gcs read --object $data_csv --variable data
#result: %gcs: error: unrecognized arguments: Cloud Storage Object gs://path/to/file.csv
</code></pre>
<p>How can I read my file for analysis do this? </p>
<p>Thanks</p>
</div>
<div class="post-text" itemprop="text">
<p>You just need to use the object's <code>uri</code> property to get the actual path:</p>
<pre><code>uri = data_csv.uri
%%gcs read --object $uri --variable data
</code></pre>
<p>The first part of your code doesn't work because pandas expects the data to be in the local file system, but you're using a GCS bucket, which is in Cloud.</p>
</div>
<div class="post-text" itemprop="text">
<p>%%gcs returns bytes objects. To read it use BytesIO from io (python 3)</p>
<pre><code>mybucket = storage.Bucket('bucket-name')
data_csv = mybucket.object('data.csv')

%%gcs read --object $data_csv --variable data

df = pd.read_csv(BytesIO(data_csv), sep = ';')
</code></pre>
<p>if your csv file is comma separated, no need to specify &lt; sep = ',' &gt; which is the default
read more about io library and packages here: <a href="https://docs.python.org/3/library/io.html" rel="nofollow noreferrer">Core tools for working with streams</a></p>
</div>
<span class="comment-copy">Can you provide the full code to read the &lt; data &gt; with pandas because I am still getting an error when I do : &lt; df = pd.read_csv(data) &gt; ? " OSError: Expected file path name or file-like object, got &lt;class 'bytes'&gt; type " thanks</span>
<span class="comment-copy">In DataLab, it seems there can be only one %% command per cell</span>
<span class="comment-copy">I am trying to get a filename as an input and reading from the bucket. When I do this, the data lab read only first file present in the bucket. Actually, I need to read multiple files.</span>
