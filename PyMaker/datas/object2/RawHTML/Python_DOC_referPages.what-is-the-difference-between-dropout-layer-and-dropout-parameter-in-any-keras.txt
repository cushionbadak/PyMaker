<div class="post-text" itemprop="text">
<p>What is the difference between dropout layer and dropout parameter in any keras layer ,both are works for same purpose or different.</p>
<p>like :model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))</p>
<pre><code>   model.add(Dropout(0.2))
</code></pre>
<p>Thanks in advance.</p>
</div>
<div class="post-text" itemprop="text">
<p>Yes they have the same functionality, dropout as a parameter is used before linear transformations of that layer (multiplication of weights and addition of bias). Dropout as layer can be used before an activation layer too.</p>
<p>recurrent_dropout also has same functionality but different direction(usually dropouts are between input and output, it is between timestamps)</p>
</div>
<span class="comment-copy">@NandiniMatam Welcome to SO; if the answer resolved your issue, kindly accept it - see <a href="https://stackoverflow.com/help/someone-answers">What should I do when someone answers my question?</a> ("<i>If you want to say "thank you," vote on or accept that person's answer</i>")</span>
