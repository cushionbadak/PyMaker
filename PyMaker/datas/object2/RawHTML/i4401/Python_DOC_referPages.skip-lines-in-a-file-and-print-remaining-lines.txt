<div class="post-text" itemprop="text">
<p>I want to skip the first 17 lines while reading a text file.</p>
<p>Let's say the file looks like:</p>
<pre><code>0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
good stuff
</code></pre>
<p>I just want the good stuff. What I'm doing is a lot more complicated, but this is the part I'm having trouble with.</p>
</div>
<div class="post-text" itemprop="text">
<p>Use a slice, like below:</p>
<pre><code>with open('yourfile.txt') as f:
    lines_after_17 = f.readlines()[17:]
</code></pre>
<hr/>
<p>If the file is too big to load in memory:</p>
<pre><code>with open('yourfile.txt') as f:
    for _ in range(17):
        next(f)
    for line in f:
        # do stuff
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Use <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="noreferrer"><code>itertools.islice</code></a>, starting at index 17. It will automatically skip the 17 first lines.</p>
<pre><code>import itertools
with open('file.txt') as f:
    for line in itertools.islice(f, 17, None):  # start=17, stop=None
        # process lines
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>for line in dropwhile(isBadLine, lines):
    # process as you see fit
</code></pre>
<p>Full demo:</p>
<pre><code>from itertools import *

def isBadLine(line):
    return line=='0'

with open(...) as f:
    for line in dropwhile(isBadLine, f):
        # process as you see fit
</code></pre>
<p>Advantages: This is easily extensible to cases where your prefix lines are more complicated than "0" (but not interdependent).</p>
</div>
<div class="post-text" itemprop="text">
<p>This solution helped me to skip the number of lines specified by the <code>linetostart</code> variable.
You get the index (int) and the line (string) if you want to keep track of those too.
In your case, you substitute linetostart with 18, or assign 18 to linetostart variable.</p>
<pre><code>f = open("file.txt", 'r')
for i, line in enumerate(f, linetostart):
    #Your code
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here is a method to get lines between two line numbers in a file:</p>
<pre><code>import sys

def file_line(name,start=1,end=sys.maxint):
    lc=0
    with open(s) as f:
        for line in f:
            lc+=1
            if lc&gt;=start and lc&lt;=end:
                yield line


s='/usr/share/dict/words'
l1=list(file_line(s,235880))
l2=list(file_line(s,1,10))
print l1
print l2
</code></pre>
<p>Output:</p>
<pre><code>['Zyrian\n', 'Zyryan\n', 'zythem\n', 'Zythia\n', 'zythum\n', 'Zyzomys\n', 'Zyzzogeton\n']
['A\n', 'a\n', 'aa\n', 'aal\n', 'aalii\n', 'aam\n', 'Aani\n', 'aardvark\n', 'aardwolf\n', 'Aaron\n']
</code></pre>
<p>Just call it with one parameter to get from line n -&gt; EOF</p>
</div>
<div class="post-text" itemprop="text">
<p>If it's a table. </p>
<p><code>pd.read_table("path/to/file", sep="\t", index_col=0, skiprows=17)</code></p>
</div>
<div class="post-text" itemprop="text">
<p>If you don't want to read the whole file into memory at once, you can use a few tricks:</p>
<p>With <code>next(iterator)</code> you can advance to the next line:</p>
<pre><code>with open("filename.txt") as f:
     next(f)
     next(f)
     next(f)
     for line in f:
         print(f)
</code></pre>
<p>Of course, this is slighly ugly, so itertools has a better way of doing this:</p>
<pre><code>from itertools import islice

with open("filename.txt") as f:
    # start at line 17 and never stop (None), until the end
    for line in islice(f, 17, None):
         print(f)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here are the timeit results for the top 2 answers. Note that "file.txt" is a text file containing 100,000+ lines of random string with a file size of 1MB+.</p>
<p>Using itertools:</p>
<pre><code>import itertools
from timeit import timeit

timeit("""with open("file.txt", "r") as fo:
    for line in itertools.islice(fo, 90000, None):
        line.strip()""", number=100)

&gt;&gt;&gt; 1.604976346003241
</code></pre>
<p>Using two for loops:</p>
<pre><code>from timeit import timeit

timeit("""with open("file.txt", "r") as fo:
    for i in range(90000):
        next(fo)
    for j in fo:
        j.strip()""", number=100)

&gt;&gt;&gt; 2.427317383000627
</code></pre>
<p>clearly the itertools method is more efficient when dealing with large files.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use a List-Comprehension to make it a one-liner:</p>
<pre><code>[fl.readline() for i in xrange(17)]
</code></pre>
<p>More about list comprehension in <a href="http://www.python.org/dev/peps/pep-0202/" rel="nofollow">PEP 202</a> and in the <a href="http://docs.python.org/tutorial/datastructures.html#list-comprehensions" rel="nofollow">Python documentation</a>.</p>
</div>
<span class="comment-copy"><a href="http://stackoverflow.com/questions/620367/python-how-to-jump-to-a-particular-line-in-a-huge-text-file" title="python how to jump to a particular line in a huge text file">stackoverflow.com/questions/620367/…</a>    or    <a href="http://stackoverflow.com/questions/4796764/read-file-from-line-2-or-skip-header-row" title="read file from line 2 or skip header row">stackoverflow.com/questions/4796764/…</a>    etc..?</span>
<span class="comment-copy">I use the second solutions to read ten lines at the end of a file with 8 million (8e6) lines and it takes ~22 seconds. Is this still the preferred (=fastest) way for such long files (~250 MB)?</span>
<span class="comment-copy">I would use <code>tail</code> for that.</span>
<span class="comment-copy">@wim: I guess, tail doesn't work on Windows. Furthermore I don't always want to read the last 10 lines. I want to be able to read some lines in the middle. (e.g. if I read 10 lines after ~4e6 lines in the same file it takes still half of that time, ~11 seconds)</span>
<span class="comment-copy">The thing is, you need to read the entire content before line number ~4e6 in order to know where the line separator bytes are located, otherwise you don't know how many lines you've passed.  There's no way to magically jump to a line number.  ~250 MB should be OK to read entire file to memory though, that's not particularly big data.</span>
<span class="comment-copy">@riddleculous see <a href="https://stackoverflow.com/q/3346430/2491761">stackoverflow.com/q/3346430/2491761</a> for getting last lines</span>
<span class="comment-copy">probably the best answer</span>
<span class="comment-copy">doesn't make much sense to store those lines in a list which will just get garbage collected.</span>
<span class="comment-copy">@wim: The memory overhead is trivial (and probably unavoidable nomatter which way you do it, since you will need to do O(n) processing of those lines unless you skip to an arbitrary point in the file); I just don't think it's very readable.</span>
<span class="comment-copy">I agree with @wim, if you are throwing away the result, use a loop. The whole point of a list comprehension is that you <i>meant</i> to store the list; you can just as easily fit a for loop on one line.</span>
<span class="comment-copy">or use a generator in a 0-memory deque.</span>
