<div class="post-text" itemprop="text">
<p>I'm preparing for a class lesson (I'm teaching) and I'm trying to predict any possible questions from the students and I ran into one that I can't answer:</p>
<p>If we have floats, why do we ever use ints at all? What's the point?</p>
<p>I know (or at least I think) that floats take more memory because they have more accuracy, but surely the difference is nearly negligible as far as memory usage goes for most non-embedded applications.</p>
<p>And I realize in many cases we actually don't <em>need</em> a float, but honestly, why <em>do</em> we have ints in the first place? What's the point? There's nothing an int can do that a float can't.</p>
<p>So why are they there at all?</p>
<p>Edit: You could argue they're easier to write (3 vs. 3.0) but you could just make all numbers default to float, so 3 would be treated the same as 3.0. <strong>Why make it a different type?</strong></p>
</div>
<div class="post-text" itemprop="text">
<p>Floating point numbers are approximations in many cases. Some integers (and decimals) can be exactly represented by a <code>float</code>, but most can't. See <a href="http://docs.python.org/3/tutorial/floatingpoint.html" rel="nofollow">Floating Point Arithmetic: Issues and Limitations</a>.</p>
<pre><code>&gt;&gt;&gt; a = 1000000000000000000000000000
&gt;&gt;&gt; a+1 == a
False
&gt;&gt;&gt; a = 1000000000000000000000000000.0
&gt;&gt;&gt; a+1 == a
True
</code></pre>
<p>Resulting from this approximative nature of floats, some calculations may yield unexpected results (this isn't directly pertinent to the question, but it illustrates the point quite well):</p>
<pre><code>&gt;&gt;&gt; sum(1.1 for _ in range(9))
9.899999999999999
</code></pre>
<p>For example, when you're dealing with money calculations, it's better to use integers, or (if speed is not an issue) the <a href="http://docs.python.org/2/library/decimal.html" rel="nofollow"><code>decimal</code> module</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>It's important to use data types that are the best fit for the task they are used for. A data type may not fit in different ways. For instance, a single byte is a bad fit for a population count because you cannot count more than 255 individuals. On the other hand a float is a bad fit because many possible floating point values have no meaning. For example, 1.5 is a floating point value that has no meaning as a count. So, using an appropriately sized integer type gives us the best fit. No need to perform sanity checks to weed out meaningless values.</p>
<p>Another reason to favour integers over floats is performance and efficiency. Integer arithmetic is faster. And for a given range integers consume less memory because integers don't need to represent non-integer values.</p>
<p>Another reason is to show intent. When a reader of the code sees that you used an integer, that reader can infer that the quantity is only meant to take integer values.</p>
</div>
<div class="post-text" itemprop="text">
<p>There are various historical reasons that apply to most languages:</p>
<ul>
<li><p>A philosophy of "don't use what you don't need". A lot of programs have no need for non-integer values but use integer values a lot, so an integer type reflects the problem domain.</p></li>
<li><p>Floating point arithmetic used to be far more expensive than integer. It's still somewhat more expensive, but in a lot of cases in Python you'd hardly notice the difference.</p></li>
<li><p>A 32 bit IEEE float can only represent all integers up to <code>2**24</code> then loses precision. A 16 bit float ("half precision") only represents all integers to 2048. So for 16 and 32 bit computing, when register sizes impose a serious trade-off between performance and value range, float-for-everything makes that trade-off even more serious.</p></li>
<li><p>An 8-bit integer type (or whatever byte size exists on the platform), is very useful for low-level programming because it exactly maps to any data representable in memory. Same goes for a register-sized integer type with some efficiency advantage to working in words rather than bytes. These are the (signed and unsigned) <code>char</code> and <code>int</code> types in C.</p></li>
</ul>
<p>There is an additional reason specifically for Python:</p>
<ul>
<li>The <code>int</code> type automatically promotes to <code>long</code> when a computation goes beyond its range, thereby retaining precision. <code>float</code> doesn't get bigger to remain precise. Both behaviours are useful in different circumstances.</li>
</ul>
<p>Note that Javascript doesn't provide an integer type. The only built-in numbers in Javascript are 64 bit floating-point. So for any reason why an integer type is beneficial, it's instructive to consider how Javascript gets on without it.</p>
</div>
<div class="post-text" itemprop="text">
<p>There are four reasons which I can currently think of (and I'm sure there are more):</p>
<ol>
<li>Memory. Choosing wisely data types can dramatically affect the memory requirements (large databases, for example).</li>
<li>Speed. Hardware implementation of integer arithmetic is much faster (and simpler) than floating point arithmetic.</li>
<li>Programming practices. Having data types enforces better programming practices, as the programmer must be aware of kind of data each variable stores. This also allows <strong>early errors detection</strong> (compile time vs runtime).</li>
<li>History. Memory used to be expensive (and still is on some systems for some applications).</li>
</ol>
</div>
<span class="comment-copy">"There's nothing an int can do that a float can't." What about a shifting or masking of bits?</span>
<span class="comment-copy">Uh...idk...can floats not do that?</span>
<span class="comment-copy">If by <code>float</code> you mean the raw bits representing  its value, it's merely a bit string and your could do <i>anything</i> with it (how about a General Purpose Turing Machine on float point numbers?). However if you mean what <code>IEEE754</code> and its extension specifies, obviously not.</span>
<span class="comment-copy">"Obviously" to someone who has a strong understanding of the nature of a floating point numbers, "not even remotely apparent" to everyone else.</span>
<span class="comment-copy">Sorry for using that word. However have you seen an operator for bitwist operations on float point numbers in any languages with strong or weak typing? As far as I know there's none, while typically with integers there does exist some.</span>
<span class="comment-copy">Your first argument boils down to “the mathematical value 1.1 cannot be representing as a floating-point number”. Considering that 1.1 cannot be represented as an integer, I do not see how this is an example of something “an int can do that a float can't”.</span>
<span class="comment-copy">@PascalCuoq: But you can represent 1.1 as the integer fraction "11/10" and do exact calculations with that.</span>
<span class="comment-copy">Good examples. Actually there is <code>(a + 1234567890 == a) == True</code>. :D</span>
<span class="comment-copy">I take the question as being "why not store integers in floating point objects?", but 1.1 is not an integer.</span>
<span class="comment-copy">"When you're dealing with money calculations, it's better to use integers.":  This is an annoying meme.  <code>double</code>s are plenty fine at lots of "money calculations" and the additional hardware support makes them much faster than the equivalent fixed-point calculations would be on modern machines.  The disadvantage is that you usually have to be awake when writing floating-point code if you want it to work.</span>
<span class="comment-copy">Whether integer arithmetic is faster depends on your processor and use case.  Floating-point math really is surprisingly fast these days.</span>
<span class="comment-copy">@tmyklebu I've never come across a machine where fp is faster than int arithmetic</span>
<span class="comment-copy">IIRC, on the original Pentium, floating-point multiply and divide were considerably faster than integer multiply and divide.  (Tangentially:  On modern machines, when the alternative involves horsing around with fixed-point math, you're usually better off using floating-point instead.  But I'm pretty sure you knew that already.)</span>
<span class="comment-copy">The first point is trivially true, but it misleadingly implies that ints are smaller than floats (the size depends on the exact int and float types, which for Python's built in types depends on the language version and interpreter "bitness"; in Python 3 even on the value of the integer). The second is not true on today's desktop machines, and even if it was true any difference would be swallowed by Python's general slowness (PyPy nonwithstanding).</span>
