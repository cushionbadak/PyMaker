<div class="post-text" itemprop="text">
<p>I've used Scikit-learn's GridSearchCV before to optimize the hyperparameters of my models, but just wondering if a similar tool exists to optimize hyperparameters for Tensorflow (for instance <strong>number of epochs, learning rate, sliding window size etc.</strong>)</p>
<p>And if not, how can I implement a snippet that effectively runs all different combinations?</p>
</div>
<div class="post-text" itemprop="text">
<p>Another viable (and documented) option for grid search with Tensorflow is <a href="http://ray.readthedocs.io/en/latest/tune.html" rel="nofollow noreferrer">Ray Tune</a>. It's a scalable framework for hyperparameter tuning, specifically for deep learning/reinforcement learning.</p>
<p>You can try out <a href="https://github.com/ray-project/tutorial/blob/master/tune_exercises/Tune.ipynb" rel="nofollow noreferrer">a fast tutorial here</a>.</p>
<p>It also takes care of Tensorboard logging and efficient search algorithms (ie, <a href="http://hyperopt.github.io/hyperopt" rel="nofollow noreferrer"><code>HyperOpt</code></a> integration and <a href="https://people.eecs.berkeley.edu/~kjamieson/hyperband.html" rel="nofollow noreferrer">HyperBand</a>) in about 10 lines of Python.</p>
<pre><code>import ray
from ray import tune

def train_tf_model(config, tune_reporter):  # 1 new arg for reporting results
    # ... train here ....
    # ... train here ....
    # ... train here ....
    pass

ray.init()

tune.run_experiments({
    "my_experiment": {
        "run": train_tf_model,
        "stop": { "mean_accuracy": 100 },
        "config": {
            "alpha": tune.grid_search([0.2, 0.4, 0.6]),
            "beta": tune.grid_search([1, 2]),
        }}})
</code></pre>
<p>(Disclaimer: I contribute actively to this project!)</p>
</div>
<div class="post-text" itemprop="text">
<p>Even though it does not seem to be explicitly documented (in version 1.2), the package <a href="https://www.tensorflow.org/get_started/tflearn" rel="noreferrer"><code>tf.contrib.learn</code></a> (included in TensorFlow) defines classifiers that are supposed to be compatible with scikit-learn... However, looking at <a href="https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/learn/python/learn/estimators/_sklearn.py" rel="noreferrer">the source</a>, it seems you need to explicitly set the environment variable <code>TENSORFLOW_SKLEARN</code> (e.g. to <code>"1"</code>) to actually get this compatibility. If this works, you can already use <code>GridSearchCV</code> (<a href="https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/learn/python/learn/grid_search_test.py" rel="noreferrer">see this test case</a>).</p>
<p>That said, there are a few alternatives. I don't know about any specific to TensorFlow, but <a href="https://hyperopt.github.io/hyperopt/" rel="noreferrer">hyperopt</a>, <a href="https://scikit-optimize.github.io/" rel="noreferrer">Scikit-Optimize</a> or <a href="https://automl.github.io/SMAC3/" rel="noreferrer">SMAC3</a> should all be valid options. <a href="https://github.com/Yelp/MOE" rel="noreferrer">MOE</a> and <a href="https://github.com/HIPS/Spearmint" rel="noreferrer">Spearmint</a> look like used to be good choices but now don't seem too maintained.</p>
<p>Alternatively, you can look into a service like <a href="https://sigopt.com/" rel="noreferrer">SigOpt</a> (a company by the original author of MOE).</p>
<p><em>Edit</em></p>
<p>About running all possible combinations of parameters, the core logic, if you want to implement it yourself, is not really complicated. You can just define lists with the possible values for each parameter and then run through all the combinations with <a href="https://docs.python.org/3/library/itertools.html#itertools.product" rel="noreferrer"><code>itertools.product</code></a>. Something like:</p>
<pre><code>from itertools import product

param1_values = [...]
param2_values = [...]
param3_values = [...]
for param1, param2, param3 in product(param1_values, param2_values param3_values):
    run_experiment(param1, param2, param3)
</code></pre>
<p>Note however that grid search can be prohibitively expensive to run in many cases, and even doing just a random search in the parameters space will probably be more efficient (more about that <a href="https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf" rel="noreferrer">in this publication</a>).</p>
</div>
