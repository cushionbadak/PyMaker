<div class="post-text" itemprop="text">
<p>I am currently using the below code to import 6,000 csv files (with headers) and export them into a single csv file (with a single header row).</p>
<pre><code>#import csv files from folder
path =r'data/US/market/merged_data'
allFiles = glob.glob(path + "/*.csv")
stockstats_data = pd.DataFrame()
list_ = []

for file_ in allFiles:
    df = pd.read_csv(file_,index_col=None,)
    list_.append(df)
    stockstats_data = pd.concat(list_)
    print(file_ + " has been imported.")
</code></pre>
<p>This code works fine, but it is slow. It can take up to 2 days to process. </p>
<p>I was given a single line script for Terminal command line that does the same (but with no headers). This script takes 20 seconds.</p>
<pre><code> for f in *.csv; do cat "`pwd`/$f" | tail -n +2 &gt;&gt; merged.csv; done 
</code></pre>
<p>Does anyone know how I can speed up the first Python script? To cut the time down, I have thought about not importing it into a DataFrame and just concatenating the CSVs, but I cannot figure it out. </p>
<p>Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you don't need the CSV in memory, just copying from input to output, it'll be a lot cheaper to avoid parsing at all, and copy without building up in memory:</p>
<pre><code>import shutil

#import csv files from folder
path = r'data/US/market/merged_data'
allFiles = glob.glob(path + "/*.csv")
with open('someoutputfile.csv', 'wb') as outfile:
    for i, fname in enumerate(allFiles):
        with open(fname, 'rb') as infile:
            if i != 0:
                infile.readline()  # Throw away header on all but first file
            # Block copy rest of file from input to output without parsing
            shutil.copyfileobj(infile, outfile)
            print(fname + " has been imported.")
</code></pre>
<p>That's it; <a href="https://docs.python.org/3/library/shutil.html#shutil.copyfileobj" rel="noreferrer"><code>shutil.copyfileobj</code></a> handles efficiently copying the data, dramatically reducing the Python level work to parse and reserialize.</p>
<p>This assumes all the CSV files have the same format, encoding, line endings, etc., and the header doesn't contain embedded newlines, but if that's the case, it's a lot faster than the alternatives.</p>
</div>
<div class="post-text" itemprop="text">
<p>Are you required to do this in Python? If you are open to doing this entirely in shell, all you'd need to do is first <code>cat</code> the header row from a randomly selected input .csv file into <code>merged.csv</code> before running your one-liner:</p>
<pre><code>cat a-randomly-selected-csv-file.csv | head -n1 &gt; merged.csv
for f in *.csv; do cat "`pwd`/$f" | tail -n +2 &gt;&gt; merged.csv; done 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You don't need pandas for this, just the simple <code>csv</code> module would work fine.</p>
<pre><code>import csv

df_out_filename = 'df_out.csv'
write_headers = True
with open(df_out_filename, 'wb') as fout:
    writer = csv.writer(fout)
    for filename in allFiles:
        with open(filename) as fin:
            reader = csv.reader(fin)
            headers = reader.next()
            if write_headers:
                write_headers = False  # Only write headers once.
                writer.writerow(headers)
            writer.writerows(reader)  # Write all remaining rows.
</code></pre>
</div>
<span class="comment-copy">perfect answer @ShadowRanger, thank you!</span>
<span class="comment-copy">Nice .. perfect answer</span>
<span class="comment-copy">@ShadowRanger, Could you please also share some method to split a large csv into multiple files and keeping the header in each small files?</span>
<span class="comment-copy">@vikrantrana: That's a completely different question, not really suitable to answering in the comments, and not appropriate to answering the OP's question. Assuming one of the <a href="https://stackoverflow.com/search?q=python+split+csv">many questions on this topic</a> doesn't cover it, feel free to ask your own question on that topic. It's going to need a lot more details to answer though (e.g. are you splitting up by row counts, byte counts, etc.), and the <code>csv</code> module will be necessary (because you'll need it to properly separate rows).</span>
<span class="comment-copy">Thanks. I will raise a separate question for this and share a link.. there are solutions available but I am looking for optimIzed one.. I like the one you shared above. ðŸ˜Š</span>
<span class="comment-copy">thanks for your help - I do need it in Python as part of a bigger project. Cheers.</span>
<span class="comment-copy">@mattblack, I should have figured that was the case. Hopefully Alexander's answer works for you!</span>
<span class="comment-copy">A couple issues with this: 1) You opened the input files in text mode, the output in binary, which wouldn't work at all on Py3, and it's wrong on a Windows box even on Py2 (where you'd convert <code>\r\n</code> line endings in the inputs to <code>\n</code> line endings in the output). Sadly, it's not possible to make it fully portable without a lot of effort or third party modules (because the <code>csv</code> module requires binary I/O on Py2, and text I/O with <code>newline=''</code> on Py3). 2) (Minor) If nothing else, <code>headers = reader.next()</code> could be changed to <code>headers = next(reader)</code> to make it work on 2.6-3.x, not just 2.x.</span>
