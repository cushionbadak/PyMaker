<div class="post-text" itemprop="text">
<p>I am trying to concatenate the hidden units. For example, I have <code>3</code> units, <code>h1,h2,h3</code> then I want the new layer to have <code>[h1;h1],[h1;h2],[h1;h3],[h2;h1]...</code>.</p>
<p>So, I have tried:</p>
<pre><code>class MyLayer(Layer):
    def __init__(self,W_regularizer=None,W_constraint=None, **kwargs):
        self.init = initializers.get('glorot_uniform')
        self.W_regularizer = regularizers.get(W_regularizer)
        self.W_constraint = constraints.get(W_constraint)
        super(MyLayer, self).__init__(**kwargs)

def build(self, input_shape):
    assert len(input_shape) == 3
    # Create a trainable weight variable for this layer.
    self.W = self.add_weight((input_shape[-1],input_shape[-1]),
                             initializer=self.init,
                             name='{}_W'.format(self.name),
                             regularizer=self.W_regularizer,
                             constraint=self.W_constraint,
                            trainable=True)
    super(MyLayer, self).build(input_shape)

def call(self, x,input_shape):
    conc=K.concatenate([x[:, :-1, :], x[:, 1:, :]],axis=1)# help needed here
    uit = K.dot(conc, self.W)# W has input_shape[-1],input_shape[-1]
    return uit

def compute_output_shape(self, input_shape):
    return input_shape[0], input_shape[1],input_shape[-1]
</code></pre>
<p>I am not sure what should I return for the second argument of my output shape.</p>
<pre><code>from keras.layers import Input, Lambda, LSTM
from keras.models import Model
import keras.backend as K
from keras.layers import Lambda

lstm=LSTM(64, return_sequences=True)(input)
something=MyLayer()(lstm)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You could implement the concatenation operation that you described by leveraging <a href="https://docs.python.org/3/library/itertools.html#itertools.product" rel="nofollow noreferrer">itertools.product</a> in order to compute the cartesian product of the temporal dimension's indices. The call method could be coded as follows:</p>
<pre class="lang-py prettyprint-override"><code>def call(self, x):
    prod = product(range(nb_timesteps), repeat=2)
    conc_prod = []
    for i, j in prod:
        c = K.concatenate([x[:, i, :], x[:, j, :]], axis=-1)  # Shape=(batch_size, 2*nb_features)
        c_expanded = c[:, None, :]  # Shape=(batch_size, 1, 2*nb_features)
        conc_prod.append(c_expanded)
    conc = K.concatenate(conc_prod, axis=1)  # Shape=(batch_size, nb_timesteps**2, 2*nb_features)
    uit = K.dot(conc, self.W)  # W has shape 2*input_shape[-1], input_shape[-1]
    return uit  # Shape=(batch_size, nb_timesteps**2, nb_features)
</code></pre>
<p>In the <a href="https://stackoverflow.com/questions/53095362/concatenating-hidden-units-using-keras?noredirect=1#comment93178283_53095362">example</a> that you provided, <code>nb_timesteps</code> would be 3. Note also that the shape of the weights should be <code>(2*input_shape[-1], input_shape[-1])</code> for the dot product to be valid. </p>
<p><strong>Disclaimer</strong>: I am not sure what you want to achieve.</p>
</div>
<span class="comment-copy">Could you please post reproducible code and provide an example of the expected output?</span>
<span class="comment-copy">@rvinas I have edited the question. Will that work? I am not sure how to show you the output. I have already mentioned how I want the tensors to be concatenated.</span>
<span class="comment-copy">@rvinas It will be okay even if I can get the exhaustive concatenation like <code>h1;h1,h1;h2,h1;h3,h2;h1,h2;h2,h2;h3...</code> I tried to do that using Lambda layer what has been explained here <a href="https://stackoverflow.com/questions/52941192/multiply-multiple-tensors-pairwise-keras" title="multiply multiple tensors pairwise keras">stackoverflow.com/questions/52941192/â€¦</a> But as my comment explained, I am having trouble there as well.</span>
<span class="comment-copy">What does each <code>h</code> represent? What is the output shape that you would expect? I don't understand what you want to compute, maybe providing some detailed equations would help</span>
<span class="comment-copy">@rvinas <code>h</code> is the timestep and I am trying to compute the concatenation. Since, it is okay to perform exhaustive concatenation the output shape will be <code>input_shape[0],input_shape[1]*input_shape[1],input_shape[-1]</code>. So this means that I have <code>3</code> timesteps and I am trying to concatenate the features. So after concatenation, I should have <code>?,9,2*features</code> [as I am concatenating so the number of features will be doubled]. Then I will multiply it with W which will give a resultant output of <code>?,9,features</code></span>
