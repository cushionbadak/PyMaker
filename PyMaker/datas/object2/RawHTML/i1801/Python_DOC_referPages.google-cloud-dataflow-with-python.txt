<div class="post-text" itemprop="text">
<p>Trying to implement an easier form of <a href="https://github.com/GoogleCloudPlatform/professional-services/blob/master/examples/dataflow-python-examples/dataflow_python_examples/data_ingestion.py" rel="nofollow noreferrer">this</a> example I have and error while insert data to BigQuery</p>
<p>This is the code</p>
<pre><code>from __future__ import absolute_import
import argparse
import logging
import re
import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions


class DataIngestion:
    def parse_method(self, string_input):
        values = re.split(",",re.sub('\r\n', '', re.sub(u'"', '', string_input)))
        row = dict(zip('Mensaje',values))
        return row



def run(argv=None):
    """The main function which creates the pipeline and runs it."""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--input', dest='input', required=False,
        help='Input file to read.  This can be a local file or '
             'a file in a Google Storage Bucket.',
        default='C:\XXXX\prueba.csv')

    parser.add_argument('--output', dest='output', required=False,
                        help='Output BQ table to write results to.',
                        default='PruebasIoT.TablaIoT')

    known_args, pipeline_args = parser.parse_known_args(argv)

    data_ingestion = DataIngestion()

    p = beam.Pipeline(options=PipelineOptions(pipeline_args))

    (p
     | 'Read from a File' &gt;&gt; beam.io.ReadFromText(known_args.input,
                                                  skip_header_lines=1)

     | 'String To BigQuery Row' &gt;&gt; beam.Map(lambda s:
                                            data_ingestion.parse_method(s))
     | 'Write to BigQuery' &gt;&gt; beam.io.Write(
                beam.io.BigQuerySink
                    (
                    known_args.output,
                    schema='Mensaje:STRING'
                 )
            )
     )
    p.run().wait_until_finish()


if __name__ == '__main__':
    #  logging.getLogger().setLevel(logging.INFO)
    run()
</code></pre>
<p>And this is the error:</p>
<pre><code>RuntimeError: Could not successfully insert rows to BigQuery table [XXX]. Errors: [&lt;InsertErrorsValueListEntry
 errors: [&lt;ErrorProto
 debugInfo: u''
 location: u'm'
 message: u'no such field.'
 reason: u'invalid'&gt;]
 index: 0&gt;, &lt;InsertErrorsValueListEntry
 errors: [&lt;ErrorProto
 debugInfo: u''
 location: u'm'
 message: u'no such field.'
 reason: u'invalid'&gt;]
 index: 1&gt;]
</code></pre>
<p>I'm new with python and maybe the solutions is quite simple, but how I could do it?</p>
<p>It would be possible to pass a single string in <em>String To BigQuery Row</em> instead of </p>
<pre><code>'String To BigQuery Row' &gt;&gt; beam.Map(lambda s:
                                        data_ingestion.parse_method(s))
</code></pre>
<p>This would be the easier way to start better than using csv files and have to translate the file</p>
</div>
<div class="post-text" itemprop="text">
<p>I understand you have an input CSV file with a single column, of the form:</p>
<pre><code>Message
This is a message
This is another message
I am writing to BQ
</code></pre>
<p>If my understanding was correct, you do not need to have the <code>parse_method()</code> method, because as explained in <a href="https://github.com/GoogleCloudPlatform/professional-services/blob/master/examples/dataflow-python-examples/dataflow_python_examples/data_ingestion.py" rel="nofollow noreferrer">the sample you shared</a>, this is just a helper method that maps the CSV values to dictionaries (which are accepted by <code>beam.io.BigQuerySink</code>).</p>
<p>Then, you can simply do something like:</p>
<pre><code>p = beam.Pipeline(options=PipelineOptions(pipeline_args))

(p
 | 'Read from a File' &gt;&gt; beam.io.ReadFromText(known_args.input, skip_header_lines=1)
 | 'String To BigQuery Row' &gt;&gt; beam.Map(lambda s: dict(Message = s))
 | 'Write to BigQuery' &gt;&gt; beam.io.Write(
    beam.io.BigQuerySink(known_args.output, schema='Message:STRING')))

p.run().wait_until_finish()
</code></pre>
<p>Note that the only relevant difference is that the "<em>String to BigQuery Row</em>" mapping does not need a complex method anymore, and all it does is create a Python dictionary like <code>{Message: "This is a message"}</code>, where <code>Message</code> is the name of the column in your BQ table. In this mapping, <code>s</code> is each of the String elements read in the <code>beam.io.ReadFromText</code> transform, and we apply a <a href="https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions" rel="nofollow noreferrer">lambda function</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>To solve using a CSV file with only one value per row I have to use this:</p>
<pre><code>    values = re.split(",",re.sub('\r\n', '', re.sub(u'"', '', string_input)))
    row = dict(zip(('Name',),values))
</code></pre>
<p>I dont know why I have to put the "," after the 'Name' but if I don't do it, the dict(zip(... doesnt work properly</p>
</div>
