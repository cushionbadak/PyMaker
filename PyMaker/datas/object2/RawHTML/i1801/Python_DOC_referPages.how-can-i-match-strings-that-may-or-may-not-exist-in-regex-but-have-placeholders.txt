<div class="post-text" itemprop="text">
<p>Suppose I have a big text file in the following form</p>
<pre><code>[Surname: "Gordon"]
[Name: "James"]
[Age: "13"]
[Weight: "46"]
[Height: "12"]
[Quote: "I want to be a pilot"]

[Name: "Monica"]
[Weight: "33"]
[Quote: "I am looking forward to christmas"]
</code></pre>
<p>There are in total 8 keys which will always be in the order of "Surname","Name","Age","Weight","Height","School","Siblings","Quote" which I know beforehand.  As you can see, some profiles do not have the full set of variables. The only thing you can be sure will exist is the name. </p>
<p>I want to create a pandas dataframe with each observation as a row and each column as a key. In the case of James, since he does not have the entries in "School" and "Sibling" I would like the entries of those cells to be the numpy nan object. </p>
<p>My attempt is using something like <code>(?:\[Surname: \"()\"\])</code> for every variable. But even for the single case of surname I run into problems. If surname does not exist, it returns no place holders just the empty list.</p>
<p>Update:</p>
<p>As an example, I would like the return for monica's profile to be
('','Monica','','33','','','','I am looking forward to christmas')</p>
</div>
<div class="post-text" itemprop="text">
<p>You can parse the file data, group the results, and pass to a dataframe:</p>
<pre><code>import re
import pandas as pd
def group_results(d):
   _group = [d[0]]
   for a, b in d[1:]:
     if a == 'Name' and not any(c == 'Name' for c, _ in _group):
       _group.append([a, b])
     elif a == 'Surname' and any(c == 'Name' for c, _ in _group):
       yield _group
       _group = [[a, b]]
     else:
       if a == 'Name':
         yield _group
         _group = [[a, b]]
       else:
         _group.append([a, b])
   yield _group

headers = ["Surname","Name","Age","Weight","Height","School","Siblings","Quote"]
data = list(filter(None, [i.strip('\n') for i in open('filename.txt')]))
parsed = [(lambda x:[x[0], x[-1][1:-1]])(re.findall('(?&lt;=^\[)\w+|".*?"(?=\]$)', i)) for i in data]
_grouped = list(map(dict, group_results(parsed)))
result = pd.DataFrame([[c.get(i, "") for i in headers] for c in _grouped], columns=headers)
</code></pre>
<p>Output:</p>
<pre><code>  Surname    Name                ...                 Siblings                              Quote
0  Gordon   James                ...                                        I want to be a pilot
1          Monica                ...                           I am looking forward to christmas

[2 rows x 8 columns]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Building on @WiktorStribiżew comment, you could use <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer">groupby</a> (from itertools) to group the lines into empty lines and data lines, for instance like this:</p>
<pre><code>import re
from itertools import groupby

text = '''[Surname: "Gordon"]
[Name: "James"]
[Age: "13"]
[Weight: "46"]
[Height: "12"]
[Quote: "I want to be a pilot"]

[Name: "Monica"]
[Weight: "33"]
[Quote: "I am looking forward to christmas"]

[Name: "John"]
[Height: "33"]
[Quote: "I am looking forward to christmas"]

[Surname: "Gordon"]
[Name: "James"]
[Height: "44"]
[Quote: "I am looking forward to christmas"]'''

patterns = [re.compile('(\[Surname: "(?P&lt;surname&gt;\w+?)"\])'),
            re.compile('(\[Name: "(?P&lt;name&gt;\w+?)"\])'),
            re.compile('(\[Age: "(?P&lt;age&gt;\d+?)"\])'),
            re.compile('\[Weight: "(?P&lt;weight&gt;\d+?)"\]'),
            re.compile('\[Height: "(?P&lt;height&gt;\d+?)"\]'),
            re.compile('\[Quote: "(?P&lt;quote&gt;.+?)"\]')]

records = []
for non_empty, group in groupby(text.splitlines(), key=lambda l: bool(l.strip())):
    if non_empty:
        lines = list(group)
        record = {}
        for line in lines:
            for pattern in patterns:
                match = pattern.search(line)
                if match:
                    record.update(match.groupdict())
                    break
        records.append(record)

for record in records:
    print(record)
</code></pre>
<p><strong>Output</strong></p>
<pre><code>{'weight': '46', 'quote': 'I want to be a pilot', 'age': '13', 'name': 'James', 'height': '12', 'surname': 'Gordon'}
{'weight': '33', 'quote': 'I am looking forward to christmas', 'name': 'Monica'}
{'height': '33', 'quote': 'I am looking forward to christmas', 'name': 'John'}
{'height': '44', 'surname': 'Gordon', 'quote': 'I am looking forward to christmas', 'name': 'James'}
</code></pre>
<p><strong>Note:</strong> This creates a dictionary where the keys are the field names and the values are the values of each, this format does not match your intended output, but I believe is more complete that what you requested. In any case you can easily convert from this format into the desired tuple format.</p>
<p><strong>Explanation</strong></p>
<p>The groupby function from itertools groups the input data into contiguous  groups of empty lines and <em>record</em> lines. Then you only need to process the groups that are not empty. The processing is simple for each line try to match a pattern if the pattern is matched break, assuming the lines are exclusive for each match update the <code>record</code> dictionary with the value of the field, leveraging named groups.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can rewrite your data file. The code parses your original file into classes D, then uses csv.DictWriter to write it into a normal style csv that should be readable by pandas:</p>
<p>Create demo file:</p>
<pre><code>fn = "t.txt"
with open (fn,"w") as f:
    f.write("""
[Surname: "Gordon"]
[Name: "James"]
[Age: "13"]
[Weight: "46"]
[Height: "12"]
[Quote: "I want to be a pilot"]

[Name: "Monica"]
[Weight: "33"]
[Quote: "I am looking forward to christmas"]
""")
</code></pre>
<p>Itermediate class:</p>
<pre><code>class D:
    fields = ["Surname","Name","Age","Weight","Height","Quote"]

    def __init__(self,textlines):
        t = [(k.strip(),v.strip()) for k,v in (x.strip().split(":",1) for x in textlines)]
        self.data = {k:"" for k in D.fields}
        self.data.update(t) 

    def surname(self):    return self.data["Surname"]
    def name(self):       return self.data["Name"]
    def age(self):        return self.data["Age"]
    def weight(self):     return self.data["Weight"]
    def height(self):     return self.data["Height"]
    def quote(self):      return self.data["Quote"]

    def get_data(self):
        return self.data
</code></pre>
<p>Parsing and rewriting:    </p>
<pre><code>fn = "t.txt"

# list of all collected D-Instances
data = []
with open(fn) as f:
    # each dataset contains all lines belonging to one "person"
    dataset = []
    surname = False
    for line in f.readlines():
        clean = line.strip().strip("[]")
        if clean and (clean.startswith("Surname") or clean.startswith("Name")):
            if any(e.startswith("Name") for e in dataset):
                data.append(D(dataset))
                dataset = []
                if clean:
                    dataset.append(clean)
            else:
                if clean:
                    dataset.append(clean)
        elif clean:
            dataset.append(clean)
    if dataset:
        data.append(D(dataset))

import csv
with open("other.txt", "w", newline="") as f:
    dw = csv.DictWriter(f,fieldnames=D.fields)
    dw.writeheader()
    for entry in data:
        dw.writerow(entry.get_data())
</code></pre>
<p>Check what was written:</p>
<pre><code>with open("other.txt","r") as f:
    print(f.read())
</code></pre>
<p>Output:</p>
<pre><code>Surname,Name,Age,Weight,Height,Quote
"""Gordon""","""James""","""13""","""46""","""12""","""I want to be a pilot"""
,"""Monica""",,"""33""",,"""I am looking forward to christmas"""
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Create a list of (key,value) tuples for each info block with re.findall(), and put them in separate dictionaries: </p>
<pre><code>text="""[Surname: "Gordon"]
[Name: "James"]
[Age: "13"]
[Weight: "46"]
[Height: "12"]
[Quote: "I want to be a pilot"]

[Name: "Monica"]
[Weight: "33"]
[Quote: "I am looking forward to christmas"]"""

keys=['Surname','Name','Age','Weight','Height','Quote']

rslt=[{}]

for k,v in re.findall(r"(?m)(?:^\s*\[(\w+):\s*\"\s*([^\]\"]+)\"\s*\])+",text):
    d=rslt[-1]
    if (k=="Surname" and d) or (k=="Name" and "Name" in d):
        d={}
        rslt.append(d)
    d[k]=v

for d in rslt:
    print( [d.get(k,'') for k in keys] )

Out:
['Gordon', 'James', '13', '46', '12', 'I want to be a pilot']
['', 'Monica', '', '33', '', 'I am looking forward to christmas']
</code></pre>
</div>
<span class="comment-copy">You were right there should be colons in all those places. I've made the fixes. I put in James as an after thought to show profiles with different number of variables.</span>
<span class="comment-copy">You may read line by line and collect data upon blank lines. Then, add collected data to a list.</span>
<span class="comment-copy">@WiktorStribiżew That's a good idea actually.</span>
<span class="comment-copy">Your function does exactly what I would like it to do but could you briefly explain how group_results works?</span>
<span class="comment-copy">@Qwertford <code>group_results</code> creates a listing for each user in the input. Specifically, it will add values that are looped over to the <code>queue</code>, but if a <code>Name</code> value is found and a name already exists in the group, the current grouping will be yielded and reassigned.</span>
