<div class="post-text" itemprop="text">
<p>I have a rather complex data structure, namely dictionaries in a panda dataframe. Lets say I have this dataframe.</p>
<pre><code>trials_ = [1,2,1,2]
stimul_ = [1,1,2,2]
data_ = [[{'peak_voltage': [30.5, 65], 'Spikecount': [2]}], [{'peak_voltage': [30.5, 65, 30], 'Spikecount': [3]}], [{'peak_voltage': [20.1], 'Spikecount': [1]}], 'NaN']
featve  = pd.DataFrame({'trial': trials_, 'stimulus': stimul_, 'data': data_})
featve

    data                                                stimulus    trial
0   [{'peak_voltage': [30.5, 65], 'Spikecount': [2]}]   1           1 
1   [{'peak_voltage': [30.5, 65, 30], 'Spikecount'...   1           2
2   [{'peak_voltage': [20.1], 'Spikecount': [1]}]       2           1
3   NaN                                                 2           2
</code></pre>
<p>I now want to calculate the median and 25% / 75% quartiles of each key element of my dictionaries in my 'data' column (here <em>peak_voltage</em> and <em>Spikecount</em>) for each stimulus over all trials. </p>
<p>One example for the median:
I want the median <em>peak_voltage</em> value when stimulus 1 was applied across all trials [30.5, 65, 20.1] -&gt; 30.5. The same for when stimulus two was applied [30.5, 65, 30, NaN] -&gt; 30.5. And of course the same for <em>Spikecount</em>.</p>
<p>To be honest, I've no idea where to start. If I only wanted to calculate the median regardless of the simulus, I would simply use.</p>
<pre><code>featve.data.median
</code></pre>
<p>But this is not what I want. Also, if I didn't have dictionaries but only numbers, I would have used something like</p>
<pre><code>featve.groupby('stimulus').data.apply(np.nanmedian)  
</code></pre>
<p>But what can I do in my case with dictionaries in a panda table?</p>
<p>EDIT 1</p>
<p>I have 10 stimuli with 16 trials each, resulting in 160 rows in total. The dictionaries are the output of a toolbox called <a href="https://github.com/BlueBrain/eFEL" rel="nofollow noreferrer">EFEL</a> that I use to find certain characteristics of my data traces (e.g. the timing of peaks of neuronal action potentials). I decided to organize the resulting 160 dictionaries in a panda dataframe to keep track of the data, stimuli and trials at the same time. I don't know if this is unfortunate in the first place.</p>
</div>
<div class="post-text" itemprop="text">
<p>For what you are asking I would advise restructuring your dataframe. Instead of constructing <code>featve</code> with:</p>
<pre><code>data_ = [[{'peak_voltage': [30.5, 65], 'Spikecount': [2]}], [{'peak_voltage': [30.5, 65, 30], 'Spikecount': [3]}], [{'peak_voltage': [20.1], 'Spikecount': [1]}], 'NaN']

data_ = {'peak_voltage': [30.5, 65, 30.5, 65, 30, 20.1, np.nan], 'Spikecount': [2,2,3,3,3,1, np.nan], 'trials': [1,1,2,2,2,1,2], 'stimulus': [1,1,1,1,1,2,2]}
featve = pd.DataFrame(data_)
</code></pre>
<p>The result is the following DataFrame:</p>
<pre><code>   Spikecount  peak_voltage  stimulus  trials
0         2.0          30.5         1       1
1         2.0          65.0         1       1
2         3.0          30.5         1       2
3         3.0          65.0         1       2
4         3.0          30.0         1       2
5         1.0          20.1         2       1
6         NaN           NaN         2       2
</code></pre>
<p>On this DataFrame you can group and compute your medians as you would normally.</p>
<p>e.g</p>
<pre><code>featve.groupby('stimulus').peak_voltage.meadian()
stimulus
1    30.5
2    20.1
Name: peak_voltage, dtype: float64
</code></pre>
<p><strong>Update</strong></p>
<p>I understand the concerns about not having "Nice" data. Given a strict construct that follows the format of <code>data_</code> you could use <a href="https://docs.python.org/3/library/collections.html#collections.defaultdict" rel="nofollow noreferrer"><code>defaultdict</code></a> to get a nicer dataframe.</p>
<pre><code>dict_data = defaultdict(list)

for idx in range(len(data_)):
     if isinstance(data_[idx], list):
         for sub in data_[idx]:
             repeats = len(sub['peak_voltage'])
             data_dict['peak_voltage'] += sub['peak_voltage']
             data_dict['Spikecount'] += sub['Spikecount'] * repeats
             data_dict['trial'] += [trials_[idx]] * repeats
             data_dict['stimulus'] += [stimul_[idx]] * repeats
     else:
         data_dict['peak_voltage'].append('NaN')
         data_dict['Spikecount'].append('NaN')
         data_dict['trial'] += [trials_[idx]]
         data_dict['stimulus'] += [stimul_[idx]]

pd.DataFrame(data_dict)
  Spikecount peak_voltage  stimulus  trial
0          2         30.5         1      1
1          2           65         1      1
2          3         30.5         1      2
3          3           65         1      2
4          3           30         1      2
5          1         20.1         2      1
6        NaN          NaN         2      2
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>First, I'm not sure why you're putting your dicionaries in lists, but I would recommend having a version of your data without them. Also, if most of your data is in the form of dictionaries, then I recommend putting missing data in the form of dictionaries as well. Once you do that, you can put <code>data_</code> in a dataframe. So </p>
<p><code>my_data =  pd.DataFrame([{'peak_voltage': [30.5, 65], 'Spikecount': [2]}, {'peak_voltage': [30.5, 65, 30], 'Spikecount': [3]}, {'peak_voltage': [20.1], 'Spikecount': [1]}, {}])</code>. </p>
<p>You can then have a dataframe of <code>stimulus</code> and <code>trial</code>: </p>
<p><code>stimulus_trial_df = pd.DataFrame({'trial': trials_, 'stimulus': stimul_})</code>.  </p>
<p>Next, you can slice <code>my_data</code> on properties of <code>stiumulus_trial_df</code>: </p>
<p><code>subset1 = my_data.loc[stimulus_trial_df['stimulus']==1]</code>. </p>
<p>Note that you do have to make sure that your two dataframes have consistent indices for this to work. </p>
<p>Once you have <code>subset1</code>, you can flatten columns in it: </p>
<p><code>spikecount_agg= [spikecount for row in subset1['Spikecount'] for spikecount in row]</code>. </p>
<p>Finally, you can perform whatever operation you want on the flattened column:</p>
<pre><code>import statistics
current_median = statistics.median(spikecount_agg)
</code></pre>
<p>A final note: you put in your question <code>[30.5, 65, 20.1] -&gt; 30.5</code>, but your data has two copies of <code>30.5</code> and <code>65</code>. In this particular case, this doesn't change what the median is, but you should think about whether you want to take into account multiple copies in your data. My code includes them, so if you don't want them, you'll have to adjust the code.</p>
<p>EDIT:
Regarding subsetting for different stimuli, a for-loop should suffice. If you have an object containing unique stimuli, you can loop over that; if you don't, you can generate it with <code>unique_stimuli = set(stimul_)</code>:</p>
<pre><code>for stimulus in unique_stimuli:
   subset = my_data.loc[stimulus_trial_df['stimulus']==stimulus]
   #do what you want with subset
</code></pre>
</div>
<span class="comment-copy">Is your answer is assuming that the data is in "nice" form: the multiplicities of Spikecount and peak_voltage are the same in each row, etc.?</span>
<span class="comment-copy">Your answer puts the data in a form that is in many ways cleaner than in my answer, but it's less general. If the OP is literally dealing just with the data presented, they can just copy your answer verbatim, but if they get more data, adapting your answer will be highly non-trivial (adapting my answer is likely non-trivial as well, but probably less so). You might want to give code that transforms the OP's data to your form, rather than just manually transforming it.</span>
<span class="comment-copy">Thanks for your input! I'm using a toolbox named EFEL (<a href="https://github.com/BlueBrain/eFEL" rel="nofollow noreferrer">github.com/BlueBrain/eFEL</a>) to extract specific characteristics of my data traces. The output is a dictionary as shown in my example. i do that 160 times in total (10 stimuli, 16 trials each) and store all dictionaries in a panda dataframe as shown above. That means that the dictionary structure is kind of given. So I'd need to solve the problem differently or reconstruct my dictionaries somehow.</span>
<span class="comment-copy">@Acccumulation you raise a fair concern. I updated the answer to address a more general case of loading not so nice data.</span>
<span class="comment-copy">Thanks for your thoughts! I use lists because python otherwise throws <code>ValueError: Incompatible indexer with Series</code>. I put the dictionary in the dataframe inside a for-loop. Anyway. Do I understand your solution correctly, that I would need to create subsets manually for each stimulus set? That would be tiring, as I have 10 stimuli (maybe I should have mentioned that in my post, I will edit it).</span>
<span class="comment-copy">Regarding your final note: I used arbitrary numbers for the example above. But if I have the same number twice in my data I would consider both. So it's nice that you included them already.</span>
<span class="comment-copy">@Svenno Nito : you can put a variable in the subsetting code, rather than a fixed value. I've edited my answer to clarify. You can also do a for-loop inside the for loop, looping over <code>p for p in [25,50,75]</code> and then taking the pth percentile.</span>
