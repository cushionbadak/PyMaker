<div class="post-text" itemprop="text">
<p>I'm hoping this is a quick one.</p>
<p>I am trying to get the second level domain from a given URL</p>
<p>here is my code:</p>
<pre><code>    url = url.split(".", 1)[1]
    url = url.split('//', 1)[-1]
    url = url.split("/", 0)[0]
</code></pre>
<p>the problem is with the last line, for some reason it doesn't seem to do anything.</p>
<p>if I feed it url = "<a href="http://www.nba.com/sports" rel="nofollow noreferrer">http://www.nba.com/sports</a>"</p>
<p>i get back "nba.com/sports"</p>
<p>im trying to just get "nba.com"</p>
</div>
<div class="post-text" itemprop="text">
<p>Print <code>url</code> after each result and you'll see what you need to do:</p>
<pre><code>&gt;&gt;&gt; url = "http://www.nba.com/sports"
&gt;&gt;&gt; url = url.split(".", 1)[1]
&gt;&gt;&gt; print(url)
nba.com/sports
</code></pre>
<p>After here, it's clear all we need to do is just split at the <code>/</code>. Don't overcomplicate it too much :)</p>
<pre><code>&gt;&gt;&gt; url = url.split("/")[0]
&gt;&gt;&gt; print(url)
nba.com
</code></pre>
<hr/>
<p>As @Mark mentioned in the comments, you can also use <a href="https://docs.python.org/3.0/library/urllib.parse.html" rel="nofollow noreferrer"><code>urllib.urlparse</code></a>:</p>
<pre><code>&gt;&gt;&gt; from urllib.parse import urlparse
&gt;&gt;&gt; url = "http://www.nba.com/sports"
&gt;&gt;&gt; urlparse(url)
ParseResult(scheme='http', netloc='www.nba.com', path='/sports', params='', query='', fragment='')
&gt;&gt;&gt; urlparse(url).netloc
'www.nba.com'
</code></pre>
<p>And you can then strip everything from the first <code>.</code> if necessary, but depending on what you're doing you might not need to.</p>
<p>Note, if you're using Python 2, then the module is <a href="https://docs.python.org/2/library/urlparse.html" rel="nofollow noreferrer"><code>urlparse</code></a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Correct solution: Don't reinvent the wheel, use <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlsplit" rel="nofollow noreferrer">the existing libraries</a> for as much as you can:</p>
<pre><code>from urllib.parse import urlsplit
# On Py2, from urlparse import urlsplit

url = "http://www.nba.com/sports"
domain = urlsplit(url).hostname
# split off the last two components, then join them back together to make
# the second level domain
secondlevel = '.'.join(domain.rsplit('.', 2)[-2:])
print(secondlevel)
</code></pre>
<p>which gets you <code>nba.com</code>.</p>
</div>
<span class="comment-copy">Show us what <code>url</code> looks like at the beginning and end, and what you want as a result</span>
<span class="comment-copy">sorry submitted before i was done typing. please re-check</span>
<span class="comment-copy">why not use urlparse?</span>
<span class="comment-copy">I am trying not to import libraries for small tasks I can handle myself, trying to keep this as lightweight as possible.</span>
<span class="comment-copy">Using those 3 split is not lightweight plus it makes your code more complex. Python is meant to be more readable, concise, and dry.</span>
<span class="comment-copy">sorry trying and failing to format these responses correctly.  I had to change your example a little bit to url = url.split("/")[2] but yes this works</span>
<span class="comment-copy">I did find that library when googling for this issue, my understanding is best practices would suggest not importing whole libraries if you just need one small bit of functionality out of it that can be achieved with a few lines of your own code.</span>
<span class="comment-copy">@bubba4399: You're mistaken. For one, this isn't "one small bit of functionality"; it's surprisingly hard to do URL parsing correctly in the general sense. For another, the cost of writing new code in the first place is almost always higher than whatever tiny cost you incur importing a library. Especially for parsing known formats, never reinvent the wheel; you <i>WILL</i> get it wrong (as your question proves). Use the <code>csv</code> module for CSV, use the <code>json</code> module for JSON, and use <code>urllib.parse</code> for URLs. The only time you write it yourself is in school, as a learning exercise.</span>
