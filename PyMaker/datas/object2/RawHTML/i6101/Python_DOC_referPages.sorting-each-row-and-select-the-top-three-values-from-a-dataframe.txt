<div class="post-text" itemprop="text">
<p>I have a dataframe which looks something like :</p>
<pre><code>device_id   s2  s41 s47 s14
30          0   0   0   0.003
125         0   0   0   0
32          0   0   0   0
45          0   0   0   0
</code></pre>
<p>The objective is to get the 3 highest s's from each row and if there is a match then select the maximum index. For example, for the first row, there is a match between s2, s41 and s47 so s47 will be selected along with s41. So the selection from row 1 would be s14, s47 and s41. There are more than 2 million records and more than 250 s's and hence I need an efficient way of doing this. I have tried with iterrows and then sorting each row but it is slow and takes more than an hour for all the data.</p>
<p>The end objective would be to search for the s's ( s14, s47 , s41) in a dictionary where these values are the keys and getting the appropriate values from there.</p>
<p>Can someone please help me in doing this efficiently.
Thanks </p>
</div>
<div class="post-text" itemprop="text">
<p>I would use <a href="https://docs.python.org/3/library/heapq.html#heapq.nlargest" rel="nofollow noreferrer">heapq's <code>nlargest</code></a>:</p>
<pre><code>In [11]: df
Out[11]:
   device_id  s2  s41  s47    s14
0         30   0    0    0  0.003
1        125   0    0    0  0.000
2         32   0    0    0  0.000
3         45   0    0    0  0.000

In [12]: nlargest(3, df.columns[1:], key=lambda x: int(x[1:]))
Out[12]: ['s47', 's41', 's14']

In [13]: df[["device_id"] + nlargest(3, df.columns[1:], key=lambda x: int(x[1:]))]
Out[13]:
   device_id  s47  s41    s14
0         30    0    0  0.003
1        125    0    0  0.000
2         32    0    0  0.000
3         45    0    0  0.000
</code></pre>
<p>Note: If device_id is the index it's a little easier:</p>
<pre><code>In [21]: df1
Out[21]:
           s2  s41  s47    s14
device_id
30          0    0    0  0.003
125         0    0    0  0.000
32          0    0    0  0.000
45          0    0    0  0.000

In [22]: df1[nlargest(3, df1.columns, key=lambda x: int(x[1:]))]
Out[22]:
           s47  s41    s14
device_id
30           0    0  0.003
125          0    0  0.000
32           0    0  0.000
45           0    0  0.000
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I don't know pandas, but I understand it is numpy-based, so here is a numpy solution. It uses argpartition to efficiently get the indices of the largest 4 in each row. Unfortunately, the algorithm used by numpy is not stable, so if the smallest two of those four are equal we must do a full sort, sort giving us the option of choosing a stable algorithm.</p>
<p>Code (Couldn't check with 2m rows b/c memory on my rig, but 0.5m takes 2 sec or so):</p>
<pre><code>import numpy as np

def stable_high_3(data):
    n, m = data.shape
    high_4 = np.argpartition(data, np.arange(m-4, m), axis=-1)[:, -4:]
    must_check = np.where(data[np.arange(n), high_4[:, 0]]
                          == data[np.arange(n), high_4[:, 1]])[0]
    high_4[must_check, -3:] = np.argsort(data[must_check], axis=-1,
                                         kind='mergesort')[:, -3:]
    return high_4[:, -3:]

data = np.reshape(np.arange(30)%5, (-1, 6))
print(data)
print(stable_high_3(data))

data = np.reshape(np.arange(256*2**18)%50, (-1, 256))
stable_high_3(data)
</code></pre>
<p>Prints</p>
<pre><code>[[0 1 2 3 4 0]
 [1 2 3 4 0 1]
 [2 3 4 0 1 2]
 [3 4 0 1 2 3]
 [4 0 1 2 3 4]]
[[2 3 4]
 [1 2 3]
 [5 1 2]
 [0 5 1]
 [4 0 5]]
</code></pre>
</div>
