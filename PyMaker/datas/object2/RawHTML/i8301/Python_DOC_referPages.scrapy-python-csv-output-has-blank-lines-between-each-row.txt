<div class="post-text" itemprop="text">
<p>I am getting unwanted blank lines between each row of scrapy output in the resulting csv output file.</p>
<p>I have moved from python2 to python 3, and I use Windows 10.  I am therefore in the process of adapting my scrapy projects for python3.</p>
<p>My current (and for now, sole) problem is that when I write the scrapy output to a CSV file I get a blank line between each row.  This has been highlighted on several posts here (it is to do with Windows) but I am unable to get a solution to work.</p>
<p>As it happens, I have also added some code to the piplines.py file to ensure the csv output is in a given column order and not some random order.  Hence, I can use the normal <code>scrapy crawl charleschurch</code> to run this code rather than the <code>scrapy crawl charleschurch -o charleschurch2017xxxx.csv</code></p>
<p>Does anyone know how to skip / omit this blank line in the CSV output?</p>
<p>My pipelines.py code is below (I perhaps don't need the <code>import csv</code> line but I suspect I may do for the final answer):</p>
<pre><code># -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html

import csv
from scrapy import signals
from scrapy.exporters import CsvItemExporter

class CSVPipeline(object):

  def __init__(self):
    self.files = {}

  @classmethod
  def from_crawler(cls, crawler):
    pipeline = cls()
    crawler.signals.connect(pipeline.spider_opened, signals.spider_opened)
    crawler.signals.connect(pipeline.spider_closed, signals.spider_closed)
    return pipeline

  def spider_opened(self, spider):
    file = open('%s_items.csv' % spider.name, 'w+b')
    self.files[spider] = file
    self.exporter = CsvItemExporter(file)
    self.exporter.fields_to_export = ["plotid","plotprice","plotname","name","address"]
    self.exporter.start_exporting()

  def spider_closed(self, spider):
    self.exporter.finish_exporting()
    file = self.files.pop(spider)
    file.close()

  def process_item(self, item, spider):
    self.exporter.export_item(item)
    return item
</code></pre>
<p>I added this line to the settings.py file (not sure the relevance of the 300):</p>
<pre><code>ITEM_PIPELINES = {'CharlesChurch.pipelines.CSVPipeline': 300 }
</code></pre>
<p>my scrapy code is below:</p>
<pre><code>import scrapy
from urllib.parse import urljoin

from CharlesChurch.items import CharleschurchItem

class charleschurchSpider(scrapy.Spider):
    name = "charleschurch"
    allowed_domains = ["charleschurch.com"]    
    start_urls = ["https://www.charleschurch.com/county-durham_willington/the-ridings-1111"]


    def parse(self, response):

        for sel in response.xpath('//*[@id="aspnetForm"]/div[4]'):
           item = CharleschurchItem()
           item['name'] = sel.xpath('//*[@id="XplodePage_ctl12_dsDetailsSnippet_pDetailsContainer"]/span[1]/b/text()').extract()
           item['address'] = sel.xpath('//*[@id="XplodePage_ctl12_dsDetailsSnippet_pDetailsContainer"]/div/*[@itemprop="postalCode"]/text()').extract()
           plotnames = sel.xpath('//div[@class="housetype js-filter-housetype"]/div[@class="housetype__col-2"]/div[@class="housetype__plots"]/div[not(contains(@data-status,"Sold"))]/div[@class="plot__name"]/a/text()').extract()
           plotnames = [plotname.strip() for plotname in plotnames]
           plotids = sel.xpath('//div[@class="housetype js-filter-housetype"]/div[@class="housetype__col-2"]/div[@class="housetype__plots"]/div[not(contains(@data-status,"Sold"))]/div[@class="plot__name"]/a/@href').extract()
           plotids = [plotid.strip() for plotid in plotids]
           plotprices = sel.xpath('//div[@class="housetype js-filter-housetype"]/div[@class="housetype__col-2"]/div[@class="housetype__plots"]/div[not(contains(@data-status,"Sold"))]/div[@class="plot__price"]/text()').extract()
           plotprices = [plotprice.strip() for plotprice in plotprices]
           result = zip(plotnames, plotids, plotprices)
           for plotname, plotid, plotprice in result:
               item['plotname'] = plotname
               item['plotid'] = plotid
               item['plotprice'] = plotprice
               yield item
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>i suspect not ideal but I have found a work around to this problem.  In the pipelines.py file I have added more code that essentially reads the csv file with the blank lines to a list, and so removes the blank lines and then writes that cleaned list to a new file.</p>
<p>the code I added is:</p>
<pre><code>with open('%s_items.csv' % spider.name, 'r') as f:
  reader = csv.reader(f)
  original_list = list(reader)
  cleaned_list = list(filter(None,original_list))

with open('%s_items_cleaned.csv' % spider.name, 'w', newline='') as output_file:
    wr = csv.writer(output_file, dialect='excel')
    for data in cleaned_list:
      wr.writerow(data)
</code></pre>
<p>and so the entire pipelines.py file is:</p>
<pre><code># -*- coding: utf-8 -*-

# Define your item pipelines here
#
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html

import csv
from scrapy import signals
from scrapy.exporters import CsvItemExporter

class CSVPipeline(object):

  def __init__(self):
    self.files = {}

  @classmethod
  def from_crawler(cls, crawler):
    pipeline = cls()
    crawler.signals.connect(pipeline.spider_opened, signals.spider_opened)
    crawler.signals.connect(pipeline.spider_closed, signals.spider_closed)
    return pipeline

  def spider_opened(self, spider):
    file = open('%s_items.csv' % spider.name, 'w+b')
    self.files[spider] = file
    self.exporter = CsvItemExporter(file)
    self.exporter.fields_to_export = ["plotid","plotprice","plotname","name","address"]
    self.exporter.start_exporting()

  def spider_closed(self, spider):
    self.exporter.finish_exporting()
    file = self.files.pop(spider)
    file.close()

    #given I am using Windows i need to elimate the blank lines in the csv file
    print("Starting csv blank line cleaning")
    with open('%s_items.csv' % spider.name, 'r') as f:
      reader = csv.reader(f)
      original_list = list(reader)
      cleaned_list = list(filter(None,original_list))

    with open('%s_items_cleaned.csv' % spider.name, 'w', newline='') as output_file:
        wr = csv.writer(output_file, dialect='excel')
        for data in cleaned_list:
          wr.writerow(data)

  def process_item(self, item, spider):
    self.exporter.export_item(item)
    return item


class CharleschurchPipeline(object):
    def process_item(self, item, spider):
        return item
</code></pre>
<p>not ideal but solves the problem for now.</p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>b</code> in <code>w+b</code> is most probably part of the problem as this will make the file being considered a binary file and so linebreaks are written as is. </p>
<p>So first step is to remove the <code>b</code>. And then by adding <code>U</code> you can also activate the Universal Newline support ( see: <a href="https://docs.python.org/3/glossary.html#term-universal-newlines" rel="nofollow noreferrer">https://docs.python.org/3/glossary.html#term-universal-newlines</a> )</p>
<p>So the line in question should look like: </p>
<pre><code>file = open('%s_items.csv' % spider.name, 'Uw+')
</code></pre>
</div>
<span class="comment-copy">can you try changing this line <code>file = open('%s_items.csv' % spider.name, 'w+b')</code> to this: <code>file = open('%s_items.csv' % spider.name, 'w', newline="")</code> ?</span>
<span class="comment-copy">@Jean-FrançoisFabre I get the error <code>TypeError: write() argument must be str, not bytes</code> when I tried that.</span>
<span class="comment-copy">okay then <code>file = open('%s_items.csv' % spider.name, 'wb', newline="")</code></span>
<span class="comment-copy">@Jean-FrançoisFabre gives the error <code>ValueError: binary mode doesn't take a newline argument</code></span>
<span class="comment-copy">I had not thought of that, but I get the error <code>ValueError: mode U cannot be combined with x', 'w', 'a', or '+'</code> when I try that.</span>
<span class="comment-copy">strange, it's working on my system. The next best solution is 'w+' but according to the other comments you will run into a different error message then. Sorry.</span>
<span class="comment-copy">yes, seems odd.  Do you have a Windows system?</span>
<span class="comment-copy">Had, until I fully moved to Ubuntu about 6 months ago. Looked this snippet up in my old sources.</span>
