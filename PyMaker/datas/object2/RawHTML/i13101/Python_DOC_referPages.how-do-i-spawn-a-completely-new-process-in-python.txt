<div class="post-text" itemprop="text">
<p>I want to call python functions in sub-processes without creating a copy of the current process.</p>
<p>I have a method <code>A.run()</code> which should call <code>B.run()</code> multiple times.
<code>A.run()</code> consumes a lot of memory, so I don't want to use a <code>ProcessPoolExecutor</code> because it copies the whole memory AFAIK.
I also do not want to use <code>subprocess.Popen</code> because it has several disadvantages to me:</p>
<ul>
<li>only pass strings as parameters</li>
<li>cannot take advantage of exceptions</li>
<li>I have to know the location of <code>B.py</code> exactly, instead of relying on <code>PYTHONPATH</code></li>
</ul>
<p>I also do not want to spawn threads because <code>B.run()</code> crashes easily and I don't want it to effect the parent process.</p>
<p>Is there a way I have overlooked that has the advantage of spawning separate processes, without the extra memory but with the benefits of calling a python method?</p>
<p>Edit 1:
Answers to some questions:</p>
<ul>
<li>If I understand this correctly, I don't need the context of the first python process.</li>
<li>I cannot reuse Processes because I call a C++ library which has static variables and they need to be destroyed.</li>
</ul>
</div>
<div class="post-text" itemprop="text">
<p>Most Unix Operating Systems are using Copy-On-Write when they fork new processes.</p>
<p>This implies that, if the memory is not changed by the process children, the memory is not duplicated but shared.</p>
<p>You see the processes having the same amount of memory due to the fact that they use <em>that</em> amount of virtual memory, but when it comes to the physical one, the parent process memory is actually in a unique copy shared among them all.</p>
<p>If I assume right and the children processes are not touching the parent's memory at all, then you're just wasting your time going against Unix design principles.</p>
<p><a href="https://unix.stackexchange.com/questions/58145/how-does-copy-on-write-in-fork-handle-multiple-fork">More info here.</a></p>
</div>
<span class="comment-copy">Do you want to have context of first python process to be available in new python process ?</span>
<span class="comment-copy">Looking what you are saying your only option is run B on detached threads, and handling whenever they end manually</span>
<span class="comment-copy">Could you create the <code>ProcessPoolExecutor</code> before the clostly bits of <code>A.run</code>? Maybe create it before <code>A.run</code> starts even, and pass it in as a parameter?</span>
<span class="comment-copy"><a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">docs.python.org/3/library/â€¦</a></span>
<span class="comment-copy">@hamsolo474: I'll try the spawn method which sounds exactly what I want.</span>
