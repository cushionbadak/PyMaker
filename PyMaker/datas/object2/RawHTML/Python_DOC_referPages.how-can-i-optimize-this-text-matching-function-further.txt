<div class="post-text" itemprop="text">
<p>I need to make this function run much faster (~20x faster) to meet a required benchmark. I have made quite a few improvements from my initial implementation, but am hitting a wall. </p>
<p>The basic problem is this: count case-insensitive occurrences of <code>word</code> in <code>text</code>.</p>
<p>Complicating criteria include:</p>
<ol>
<li>Must be a whole word (<code>word</code> "George" is not found in <code>text</code> "Georges")</li>
<li>Single quotes are to be considered part of words, unless there are more than one in a row</li>
<li><code>word</code> may actually be a phrase (meaning it could have spaces, punctuation, etc.)</li>
<li>Cannot use regex</li>
</ol>
<p>My basic implementation has been to loop through each character in <code>text</code>, maintaining my position in <code>word</code> and if the character matches the corresponding character of <code>word</code>, I add it to a local string, advance my position in <code>word</code> and <code>text</code>, and go again. Once I have a match candidate (i.e. my local string is equal to <code>word</code>), I check the surrounding characters to ensure the match candidate is a full word, per rules 1 and 2 above. Note this checking does not occur frequently enough to materially impact the total time the algorithm takes.</p>
<p>Most successful optimizations I have made so far:</p>
<ul>
<li>Do string lowercasing and length measuring outside the loop</li>
<li>Check that <code>word</code> is at least a substring of <code>text</code> otherwise return 0 immediately</li>
<li>Don't bother checking for full word potential until we have a full match</li>
<li>Count the number of occurrences up front (with no rules), and break out of the loop immediately if we meet that number</li>
</ul>
<p>I've profiled the code line-by-line using <a href="https://github.com/vpelletier/pprofile" rel="nofollow noreferrer">pprofile</a>, and the majority of my code's runtime is simple lines like incrementing the counter var, resetting the <code>match_candidate</code> string to "", indexing into strings, and if statements. I have not included the code for <code>validate_full_match</code> as it is not a significant time user.</p>
<p>Are there any low-hanging fruit I'm ignoring? A different approach entirely I should consider?</p>
<p>Thanks for any suggestions!</p>
<pre><code>def count_occurences_in_text(word, text):
    """Number of occurences of word (case insensitive) in text

    Note that word can actually be any length of text, from a single
    character to a complete phrase; however, partial words do not
    count. For example:
    count_occurences_in_text("george", "I am Georges") returns 0
    while
    count_occurences_in_text("i am", "I am Georges") returns 1
    """
    # We perform some measurements and manipulation at the start to
    # avoid performing them repeatedly in the loop below
    text = text.lower()
    word = word.lower()
    max_matches = text.count(word)
    if max_matches == 0:
        return 0
    word_len = len(word)
    # Counter vars
    match_count = 0
    text_cursor = 0
    word_cursor = 0
    # We will build up match_candidate and check it against word
    match_candidate = ""
    for text_char in text:
        if text_char == word[word_cursor]:
            match_candidate += text_char
            if word == match_candidate:
                if validate_full_match(text, text_cursor, word_len):
                    match_count += 1
                    if match_count == max_matches:
                        break
                    word_cursor = 0
                    match_candidate = ""
            else:
                word_cursor += 1
        else:
            match_candidate = ""
            word_cursor = 0
        text_cursor += 1
    return match_count
</code></pre>
</div>
<div class="post-text" itemprop="text">
<ol>
<li>Python strings are immutable, every time you perform a <code>match_candidate += text_char</code> you are effectively making a new string and copying all contents of previous version of match_candidate to it. Let's say your word is <code>'helloworld'</code>. When there is chance of matching with <code>'helloworl'</code> in text, you perform <code>(len(word)^2)</code> operations here. You can surely avoid that by maintaining an index. This can save a lot of operations.</li>
<li><code>max_matches = text.count(word)</code>, you can avoid this by checking if you have reached the end of the text. This function initially will cost you <code>O(len(text))</code> that you can avoid.</li>
<li><code>validate_full_match</code> what is checked in this function. You can avoid this if this by doing proper steps when comparing individual characters.</li>
</ol>
<p>Python is easy to code and has amazing inbuilt functions and constructs. But to optimize, you need to ensure that you keep a track of complexity of every line.</p>
</div>
<span class="comment-copy">In your case the GUILD is the bottleneck, try multiprocessing not that hard. I am on my phone so is hard to write, but found this link here in SOF <a href="https://stackoverflow.com/q/2846653/6202092">stackoverflow.com/q/2846653/6202092</a> is that the entire code? I would like to test it when at my station</span>
