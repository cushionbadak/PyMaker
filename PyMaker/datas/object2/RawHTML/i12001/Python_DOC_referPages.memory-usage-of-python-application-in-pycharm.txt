<div class="post-text" itemprop="text">
<p>Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs.  With python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to <code>__main__</code>.</p>
<p>What is a good way to profile how long a python program takes to run?</p>
</div>
<div class="post-text" itemprop="text">
<p>Python includes a profiler called <a href="https://docs.python.org/3/library/profile.html#module-cProfile" rel="noreferrer">cProfile</a>. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.</p>
<p>You can call it from within your code, or from the interpreter, like this:</p>
<pre><code>import cProfile
cProfile.run('foo()')
</code></pre>
<p>Even more usefully, you can invoke the cProfile when running a script:</p>
<pre><code>python -m cProfile myscript.py
</code></pre>
<p>To make it even easier, I made a little batch file called 'profile.bat':</p>
<pre><code>python -m cProfile %1
</code></pre>
<p>So all I have to do is run:</p>
<pre><code>profile euler048.py
</code></pre>
<p>And I get this:</p>
<pre class="lang-none prettyprint-override"><code>1007 function calls in 0.061 CPU seconds

Ordered by: standard name
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    1    0.000    0.000    0.061    0.061 &lt;string&gt;:1(&lt;module&gt;)
 1000    0.051    0.000    0.051    0.000 euler048.py:2(&lt;lambda&gt;)
    1    0.005    0.005    0.061    0.061 euler048.py:2(&lt;module&gt;)
    1    0.000    0.000    0.061    0.061 {execfile}
    1    0.002    0.002    0.053    0.053 {map}
    1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}
    1    0.000    0.000    0.000    0.000 {range}
    1    0.003    0.003    0.003    0.003 {sum}
</code></pre>
<p>EDIT: Updated link to a good video resource from PyCon 2013 titled 
<a href="https://web.archive.org/web/20170318204046/http://lanyrd.com/2013/pycon/scdywg/" rel="noreferrer"><strong><em>Python Profiling</em></strong></a><br/>
<a href="https://www.youtube.com/watch?v=QJwVYlDzAXs" rel="noreferrer">Also via YouTube</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>A while ago I made <a href="http://pycallgraph.slowchop.com/" rel="noreferrer"><code>pycallgraph</code></a> which generates a visualisation from your Python code. <strong>Edit:</strong> I've updated the example to work with 3.3, the latest release as of this writing.</p>
<p>After a <code>pip install pycallgraph</code> and installing <a href="http://www.graphviz.org/" rel="noreferrer">GraphViz</a> you can run it from the command line:</p>
<pre><code>pycallgraph graphviz -- ./mypythonscript.py
</code></pre>
<p>Or, you can profile particular parts of your code:</p>
<pre><code>from pycallgraph import PyCallGraph
from pycallgraph.output import GraphvizOutput

with PyCallGraph(output=GraphvizOutput()):
    code_to_profile()
</code></pre>
<p>Either of these will generate a <code>pycallgraph.png</code> file similar to the image below:</p>
<p><img alt="enter image description here" src="https://i.stack.imgur.com/aiNEA.png"/></p>
</div>
<div class="post-text" itemprop="text">
<p>It's worth pointing out that using the profiler only works (by default) on the main thread, and you won't get any information from other threads if you use them.  This can be a bit of a gotcha as it is completely unmentioned in the <a href="http://docs.python.org/library/profile.html" rel="noreferrer">profiler documentation</a>.</p>
<p>If you also want to profile threads, you'll want to look at the <a href="http://docs.python.org/library/threading.html#threading.setprofile" rel="noreferrer" title="threading.setprofile() function"><code>threading.setprofile()</code> function</a> in the docs.</p>
<p>You could also create your own <code>threading.Thread</code> subclass to do it:</p>
<pre><code>class ProfiledThread(threading.Thread):
    # Overrides threading.Thread.run()
    def run(self):
        profiler = cProfile.Profile()
        try:
            return profiler.runcall(threading.Thread.run, self)
        finally:
            profiler.dump_stats('myprofile-%d.profile' % (self.ident,))
</code></pre>
<p>and use that <code>ProfiledThread</code> class instead of the standard one.  It might give you more flexibility, but I'm not sure it's worth it, especially if you are using third-party code which wouldn't use your class.</p>
</div>
<div class="post-text" itemprop="text">
<p>The python wiki is a great page for profiling resources:
<a href="http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code">http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code</a></p>
<p>as is the python docs:
<a href="http://docs.python.org/library/profile.html">http://docs.python.org/library/profile.html</a></p>
<p>as shown by Chris Lawlor cProfile is a great tool and can easily be used to print to the screen:</p>
<pre><code>python -m cProfile -s time mine.py &lt;args&gt;
</code></pre>
<p>or to file:</p>
<pre><code>python -m cProfile -o output.file mine.py &lt;args&gt;
</code></pre>
<p>PS&gt; If you are using Ubuntu, make sure to install python-profile</p>
<pre><code>sudo apt-get install python-profiler 
</code></pre>
<p>If you output to file you can get nice visualizations using the following tools</p>
<p>PyCallGraph : a tool to create call graph images <br/>
  install:<br/></p>
<pre><code> sudo pip install pycallgraph
</code></pre>
<p>run:</p>
<pre><code> pycallgraph mine.py args
</code></pre>
<p>view:</p>
<pre><code> gimp pycallgraph.png
</code></pre>
<p><em>You can use whatever you like to view the png file, I used gimp</em><br/>
Unfortunately I often get </p>
<p>dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.257079 to fit</p>
<p>which makes my images unusably small.  So I generally create svg files:</p>
<pre><code>pycallgraph -f svg -o pycallgraph.svg mine.py &lt;args&gt;
</code></pre>
<p>PS&gt; make sure to install graphviz (which provides the dot program):</p>
<pre><code>sudo pip install graphviz
</code></pre>
<p>Alternative Graphing using gprof2dot via @maxy / @quodlibetor :</p>
<pre><code>sudo pip install gprof2dot
python -m cProfile -o profile.pstats mine.py
gprof2dot -f pstats profile.pstats | dot -Tsvg -o mine.svg
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>@Maxy's comment on <a href="https://stackoverflow.com/a/7693928/25616">this answer</a> helped me out enough that I think it deserves its own answer: I already had cProfile-generated .pstats files and I didn't want to re-run things with pycallgraph, so I used <a href="http://code.google.com/p/jrfonseca/wiki/Gprof2Dot" rel="noreferrer">gprof2dot</a>, and got pretty svgs:</p>
<pre><code>$ sudo apt-get install graphviz
$ git clone https://github.com/jrfonseca/gprof2dot
$ ln -s "$PWD"/gprof2dot/gprof2dot.py ~/bin
$ cd $PROJECT_DIR
$ gprof2dot.py -f pstats profile.pstats | dot -Tsvg -o callgraph.svg
</code></pre>
<p>and BLAM!</p>
<p>It uses dot (the same thing that pycallgraph uses) so output looks similar. I get the impression that gprof2dot loses less information though:</p>
<p><img alt="gprof2dot example output" src="https://i.stack.imgur.com/JjSvt.png"/></p>
</div>
<div class="post-text" itemprop="text">
<p>I ran into a handy tool called <a href="https://jiffyclub.github.io/snakeviz/">SnakeViz</a> when researching this topic. SnakeViz is a web-based profiling visualization tool. It is very easy to install and use. The usual way I use it is to generate a stat file with <code>%prun</code> and then do analysis in SnakeViz.</p>
<p>The main viz technique used is <strong>Sunburst chart</strong> as shown below, in which the hierarchy of function calls is arranged as layers of arcs and time info encoded in their angular widths.</p>
<p>The best thing is you can interact with the chart. For example, to zoom in one can click on an arc, and the arc and its descendants will be enlarged as a new sunburst to display more details.</p>
<p><a href="https://i.stack.imgur.com/kCmSY.png"><img alt="enter image description here" src="https://i.stack.imgur.com/kCmSY.png"/></a></p>
</div>
<div class="post-text" itemprop="text">
<p>I think that <a href="https://docs.python.org/2/library/profile.html" rel="noreferrer"><code>cProfile</code></a> is great for profiling, while <a href="https://kcachegrind.github.io/html/Home.html" rel="noreferrer"><code>kcachegrind</code></a> is great for visualizing the results. The <a href="https://pypi.python.org/pypi/pyprof2calltree" rel="noreferrer"><code>pyprof2calltree</code></a> in between handles the file conversion.</p>
<pre><code>python -m cProfile -o script.profile script.py
pyprof2calltree -i script.profile -o script.calltree
kcachegrind script.calltree
</code></pre>
<p>To install the required tools (on Ubuntu, at least):</p>
<pre><code>apt-get install kcachegrind
pip install pyprof2calltree
</code></pre>
<p>The result:</p>
<p><a href="https://i.stack.imgur.com/1TFZe.png" rel="noreferrer"><img alt="Screenshot of the result" src="https://i.stack.imgur.com/1TFZe.png"/></a></p>
</div>
<div class="post-text" itemprop="text">
<p>Also worth mentioning is the GUI cProfile dump viewer <a href="http://www.vrplumber.com/programming/runsnakerun/">RunSnakeRun</a>.  It allows you to sort and select, thereby zooming in on the relevant parts of the program.  The sizes of the rectangles in the picture is proportional to the time taken.  If you mouse over a rectangle it highlights that call in the table and everywhere on the map.  When you double-click on a rectangle it zooms in on that portion.  It will show you who calls that portion and what that portion calls.</p>
<p>The descriptive information is very helpful.  It shows you the code for that bit which can be helpful when you are dealing with built-in library calls.  It tells you what file and what line to find the code.</p>
<p>Also want to point at that the OP said 'profiling' but it appears he meant 'timing'.  Keep in mind programs will run slower when profiled.</p>
<p><img alt="enter image description here" src="https://i.stack.imgur.com/2GahD.png"/></p>
</div>
<div class="post-text" itemprop="text">
<p>A nice profiling module is the line_profiler (called using the script kernprof.py).  It can be downloaded <a href="http://packages.python.org/line_profiler/" rel="noreferrer">here</a>.</p>
<p>My understanding is that cProfile only gives information about total time spent in each function.  So individual lines of code are not timed.  This is an issue in scientific computing since often one single line can take a lot of time.  Also, as I remember, cProfile didn't catch the time I was spending in say numpy.dot.</p>
</div>
<div class="post-text" itemprop="text">
<h1>pprofile</h1>
<p><code>line_profiler</code> (already presented here) also inspired  <a href="https://github.com/vpelletier/pprofile" rel="noreferrer"><code>pprofile</code></a>, which is described as:</p>
<blockquote>
<p>Line-granularity, thread-aware deterministic and statistic pure-python
  profiler</p>
</blockquote>
<p>It provides line-granularity as <code>line_profiler</code>, is pure Python, can be used as a standalone command or a module, and can even generate callgrind-format files that can be easily analyzed with <code>[k|q]cachegrind</code>.</p>
<h1>vprof</h1>
<p>There is also <a href="https://github.com/nvdv/vprof" rel="noreferrer">vprof</a>, a Python package described as:</p>
<blockquote>
<p>[...] providing rich and interactive visualizations for various Python program characteristics such as running time and memory usage.</p>
</blockquote>
<p><a href="https://i.stack.imgur.com/uafO3.png" rel="noreferrer"><img alt="heatmap" src="https://i.stack.imgur.com/uafO3.png"/></a></p>
</div>
<div class="post-text" itemprop="text">
<p><strong>Simplest</strong> and <strong>quickest</strong> way to find where all the time is going.</p>
<pre><code>1. pip install snakeviz

2. python -m cProfile -o temp.dat &lt;PROGRAM&gt;.py

3. snakeviz temp.dat
</code></pre>
<p>Draws a pie chart in a browser. Biggest piece is the problem function. Very simple.</p>
</div>
<div class="post-text" itemprop="text">
<p>I recently created <a href="https://github.com/nschloe/tuna" rel="noreferrer">tuna</a> for visualizing Python runtime and import profiles; this may be helpful here.</p>
<p><a href="https://i.stack.imgur.com/3r6cY.gif" rel="noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/3r6cY.gif"/></a></p>
<p>Install with</p>
<pre><code>pip3 install tuna
</code></pre>
<p>Create a runtime profile</p>
<pre><code>python -mcProfile -o program.prof yourfile.py
</code></pre>
<p>or an import profile (Python 3.7+ required)</p>
<pre><code>python -X importprofile yourfile.py 2&gt; import.log
</code></pre>
<p>Then just run tuna on the file</p>
<pre><code>tuna program.prof
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Following Joe Shaw's answer about multi-threaded code not to work as expected, I figured that the <code>runcall</code> method in cProfile is merely doing <code>self.enable()</code> and <code>self.disable()</code> calls around the profiled function call, so you can simply do that yourself and have whatever code you want in-between with minimal interference with existing code.</p>
</div>
<div class="post-text" itemprop="text">
<p>There's a lot of great answers but they either use command line or some external program for profiling and/or sorting the results.</p>
<p>I really missed some way I could use in my IDE (eclipse-PyDev) without touching the command line or installing anything. So here it is.</p>
<h1>Profiling without command line</h1>
<pre><code>def count():
    from math import sqrt
    for x in range(10**5):
        sqrt(x)

if __name__ == '__main__':
    import cProfile, pstats
    cProfile.run("count()", "{}.profile".format(__file__))
    s = pstats.Stats("{}.profile".format(__file__))
    s.strip_dirs()
    s.sort_stats("time").print_stats(10)
</code></pre>
<p>See <a href="https://docs.python.org/3.4/library/profile.html">docs</a> or other answers for more info.</p>
</div>
<div class="post-text" itemprop="text">
<p>In Virtaal's <a href="https://github.com/translate/virtaal/blob/master/devsupport/profiling.py" rel="nofollow noreferrer">source</a> there's a very useful class and decorator that can make profiling (even for specific methods/functions) very easy. The output can then be viewed very comfortably in KCacheGrind.</p>
</div>
<div class="post-text" itemprop="text">
<p>cProfile is great for quick profiling but most of the time it was ending for me with the errors. Function runctx solves this problem by initializing correctly the environment and variables, hope it can be useful for someone:</p>
<pre><code>import cProfile
cProfile.runctx('foo()', None, locals())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>My way is to use yappi (<a href="https://code.google.com/p/yappi/">https://code.google.com/p/yappi/</a>). It's especially useful combined with an RPC server where (even just for debugging) you register method to start, stop and print profiling information, e.g. in this way: </p>
<pre><code>@staticmethod
def startProfiler():
    yappi.start()

@staticmethod
def stopProfiler():
    yappi.stop()

@staticmethod
def printProfiler():
    stats = yappi.get_stats(yappi.SORTTYPE_TTOT, yappi.SORTORDER_DESC, 20)
    statPrint = '\n'
    namesArr = [len(str(stat[0])) for stat in stats.func_stats]
    log.debug("namesArr %s", str(namesArr))
    maxNameLen = max(namesArr)
    log.debug("maxNameLen: %s", maxNameLen)

    for stat in stats.func_stats:
        nameAppendSpaces = [' ' for i in range(maxNameLen - len(stat[0]))]
        log.debug('nameAppendSpaces: %s', nameAppendSpaces)
        blankSpace = ''
        for space in nameAppendSpaces:
            blankSpace += space

        log.debug("adding spaces: %s", len(nameAppendSpaces))
        statPrint = statPrint + str(stat[0]) + blankSpace + " " + str(stat[1]).ljust(8) + "\t" + str(
            round(stat[2], 2)).ljust(8 - len(str(stat[2]))) + "\t" + str(round(stat[3], 2)) + "\n"

    log.log(1000, "\nname" + ''.ljust(maxNameLen - 4) + " ncall \tttot \ttsub")
    log.log(1000, statPrint)
</code></pre>
<p>Then when your program work you can start profiler at any time by calling the <code>startProfiler</code> RPC method and dump profiling information to a log file by calling <code>printProfiler</code> (or modify the rpc method to return it to the caller) and get such output:</p>
<pre><code>2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000: 
name                                                                                                                                      ncall     ttot    tsub
2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000: 
C:\Python27\lib\sched.py.run:80                                                                                                           22        0.11    0.05
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\pyAheadRpcSrv\xmlRpc.py.iterFnc:293                                                22        0.11    0.0
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\serverMain.py.makeIteration:515                                                    22        0.11    0.0
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\pyAheadRpcSrv\PicklingXMLRPC.py._dispatch:66                                       1         0.0     0.0
C:\Python27\lib\BaseHTTPServer.py.date_time_string:464                                                                                    1         0.0     0.0
c:\users\zasiec~1\appdata\local\temp\easy_install-hwcsr1\psutil-1.1.2-py2.7-win32.egg.tmp\psutil\_psmswindows.py._get_raw_meminfo:243     4         0.0     0.0
C:\Python27\lib\SimpleXMLRPCServer.py.decode_request_content:537                                                                          1         0.0     0.0
c:\users\zasiec~1\appdata\local\temp\easy_install-hwcsr1\psutil-1.1.2-py2.7-win32.egg.tmp\psutil\_psmswindows.py.get_system_cpu_times:148 4         0.0     0.0
&lt;string&gt;.__new__:8                                                                                                                        220       0.0     0.0
C:\Python27\lib\socket.py.close:276                                                                                                       4         0.0     0.0
C:\Python27\lib\threading.py.__init__:558                                                                                                 1         0.0     0.0
&lt;string&gt;.__new__:8                                                                                                                        4         0.0     0.0
C:\Python27\lib\threading.py.notify:372                                                                                                   1         0.0     0.0
C:\Python27\lib\rfc822.py.getheader:285                                                                                                   4         0.0     0.0
C:\Python27\lib\BaseHTTPServer.py.handle_one_request:301                                                                                  1         0.0     0.0
C:\Python27\lib\xmlrpclib.py.end:816                                                                                                      3         0.0     0.0
C:\Python27\lib\SimpleXMLRPCServer.py.do_POST:467                                                                                         1         0.0     0.0
C:\Python27\lib\SimpleXMLRPCServer.py.is_rpc_path_valid:460                                                                               1         0.0     0.0
C:\Python27\lib\SocketServer.py.close_request:475                                                                                         1         0.0     0.0
c:\users\zasiec~1\appdata\local\temp\easy_install-hwcsr1\psutil-1.1.2-py2.7-win32.egg.tmp\psutil\__init__.py.cpu_times:1066               4         0.0     0.0 
</code></pre>
<p>It may not be very useful for short scripts but helps to optimize server-type processes especially given the <code>printProfiler</code> method can be called multiple times over time to profile and compare e.g. different program usage scenarios. </p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>Ever want to know what the hell that python script is doing? Enter the
  Inspect Shell. Inspect Shell lets you print/alter globals and run
  functions without interrupting the running script. Now with
  auto-complete and command history (only on linux).</p>
<p>Inspect Shell is not a pdb-style debugger.</p>
</blockquote>
<p><a href="https://github.com/amoffat/Inspect-Shell" rel="nofollow">https://github.com/amoffat/Inspect-Shell</a></p>
<p>You could use that (and your wristwatch).</p>
</div>
<div class="post-text" itemprop="text">
<p>To add on to <a href="https://stackoverflow.com/a/582337/1070617">https://stackoverflow.com/a/582337/1070617</a>,</p>
<p>I wrote this module that allows you to use cProfile and view its output easily. More here: <a href="https://github.com/ymichael/cprofilev" rel="nofollow noreferrer">https://github.com/ymichael/cprofilev</a></p>
<pre><code>$ python -m cprofilev /your/python/program
# Go to http://localhost:4000 to view collected statistics.
</code></pre>
<p>Also see: <a href="http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html" rel="nofollow noreferrer">http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html</a> on how to make sense of the collected statistics.</p>
</div>
<div class="post-text" itemprop="text">
<p>A new tool to handle profiling in Python is PyVmMonitor: <a href="http://www.pyvmmonitor.com/" rel="nofollow">http://www.pyvmmonitor.com/</a></p>
<p>It has some unique features such as</p>
<ul>
<li>Attach profiler to a running (CPython) program</li>
<li>On demand profiling with Yappi integration</li>
<li>Profile on a different machine</li>
<li>Multiple processes support (multiprocessing, django...)</li>
<li>Live sampling/CPU view (with time range selection)</li>
<li>Deterministic profiling through cProfile/profile integration</li>
<li>Analyze existing PStats results</li>
<li>Open DOT files</li>
<li>Programatic API access</li>
<li>Group samples by method or line</li>
<li>PyDev integration</li>
<li>PyCharm integration</li>
</ul>
<p>Note: it's commercial, but free for open source.</p>
</div>
<div class="post-text" itemprop="text">
<p>It would depend on what you want to see out of profiling. Simple time 
metrics can be given by (bash). </p>
<pre><code>time python python_prog.py
</code></pre>
<p>Even '/usr/bin/time' can output detailed metrics by using '--verbose' flag.</p>
<p>To check time metrics given by each function and to better understand how much time is spent on functions, you can use the inbuilt cProfile in python. </p>
<p>Going into more detailed metrics like performance, time is not the only metric. You can worry about memory, threads etc.<br/>
Profiling options:<br/>
1. <strong>line_profiler</strong> is another profiler used commonly to find out timing metrics line-by-line.<br/>
2. <strong>memory_profiler</strong> is a tool to profile memory usage.<br/>
3. <strong>heapy (from project Guppy)</strong> Profile how objects in the heap are used. </p>
<p>These are some of the common ones I tend to use. But if you want to find out more, try reading this <a href="http://shop.oreilly.com/product/0636920028963.do" rel="nofollow noreferrer">book</a>
It is a pretty good book on starting out with performance in mind. You can move onto advanced topics on using Cython and JIT(Just-in-time) compiled python. </p>
</div>
<div class="post-text" itemprop="text">
<p>There's also a statistical profiler called <a href="https://pypi.python.org/pypi/statprof/" rel="nofollow noreferrer"><code>statprof</code></a>. It's a sampling profiler, so it adds minimal overhead to your code and gives line-based (not just function-based) timings. It's more suited to soft real-time applications like games, but may be have less precision than cProfile.</p>
<p>The <a href="https://pypi.python.org/pypi/statprof/" rel="nofollow noreferrer">version in pypi</a> is a bit old, so can install it with <code>pip</code> by specifying <a href="https://github.com/bos/statprof.py" rel="nofollow noreferrer">the git repository</a>:</p>
<pre><code>pip install git+git://github.com/bos/statprof.py@1a33eba91899afe17a8b752c6dfdec6f05dd0c01
</code></pre>
<p>You can run it like this:</p>
<pre><code>import statprof

with statprof.profile():
    my_questionable_function()
</code></pre>
<p>See also <a href="https://stackoverflow.com/a/10333592/320036">https://stackoverflow.com/a/10333592/320036</a></p>
</div>
<div class="post-text" itemprop="text">
<p>When i'm not root on the server, I use 
<a href="https://people.gnome.org/~johan/lsprofcalltree.py" rel="nofollow noreferrer">lsprofcalltree.py</a> and run my program like this:</p>
<pre><code>python lsprofcalltree.py -o callgrind.1 test.py
</code></pre>
<p>Then I can open the report with any callgrind-compatible software, like <a href="https://sourceforge.net/projects/qcachegrindwin/" rel="nofollow noreferrer">qcachegrind</a></p>
</div>
<span class="comment-copy">Project euler programs shouldn't need profiling.  Either you have an algorithm that works in under a minute, or you have entirely the wrong algorithm.  "Tuning" is rarely appropriate.  You generally have to take a fresh approach.</span>
<span class="comment-copy">S.Lott: Profiling is often a helpful way to determine which subroutines are slow.  Subroutines that take a long time are great candidates for algorithmic improvement.</span>
<span class="comment-copy">@stalepretzel, Dave: I wrote that comment years ago. I stand corrected, and have since answered a few of my own questions :). However, I still feel cProfile isn't that great. runsnakerun and pycallgraph are easier for me to use.</span>
<span class="comment-copy">If you want to know how long something takes, for the purpose of a competition then you shouldn't add any profiling code since that will slow it down. Just use the unix <code>time</code> command and it will tell you how long something took.</span>
<span class="comment-copy">Also it is useful to sort the results, that can be done by -s switch, example: '-s time'. You can use cumulative/name/time/file sorting options.</span>
<span class="comment-copy">Unfortunately, though, you can't sort percall for either the total or cumulative times, which is a major deficiency IMO.</span>
<span class="comment-copy">It is also worth noting that you can use the cProfile module from ipython using the magic function %prun (profile run). First import your module, and then call the main function with %prun: import euler048; %prun euler048.main()</span>
<span class="comment-copy">For visualizing cProfile dumps (created by <code>python -m cProfile -o &lt;out.profile&gt; &lt;script&gt;</code>), <a href="http://www.vrplumber.com/programming/runsnakerun/" rel="nofollow noreferrer">RunSnakeRun</a>, invoked as <code>runsnake &lt;out.profile&gt;</code> is invaluable.</span>
<span class="comment-copy">@NeilG even for python 3, <a href="https://docs.python.org/3.4/library/profile.html" rel="nofollow noreferrer"><b><code>cprofile</code> is still recommended</b></a> over <code>profile</code>.</span>
<span class="comment-copy">Are you coloring based on the amount of calls? If so, you should color based on time because the function with the most calls isn't always the one that takes the most time.</span>
<span class="comment-copy">@red You can customise colours however you like, and even independently for each measurement. For example red for calls, blue for time, green for memory usage.</span>
<span class="comment-copy">getting this error<code>Traceback (most recent call last): /pycallgraph.py", line 90, in generate     output.done()   File "/net_downloaded/pycallgraph-develop/pycallgraph/output/graphviz.py", line 94, in done     source = self.generate()   File "/net_downloaded/pycallgraph-develop/pycallgraph/output/graphviz.py", line 143, in generate     indent_join.join(self.generate_attributes()),   File "/net_downloaded/pycallgraph-develop/pycallgraph/output/graphviz.py", line 169, in generate_attributes     section, self.attrs_from_dict(attrs), ValueError: zero length field name in format</code></span>
<span class="comment-copy">I updated this to mention that you need to install GraphViz for things to work as described. On Ubuntu this is just <code>sudo apt-get install graphviz</code>.</span>
<span class="comment-copy">This requires a bit of work to install here is 3 steps to help. 1. Install via pip, 2. Install GraphViz via exe 3. Set up path variables to GraphViz directory 4. Figure out how to fix all the other errors. 5. Figure out where it saves the png file?</span>
<span class="comment-copy">I don't see any reference to runcall in the documentation either. Giving a look at cProfile.py, I'm not sure why you use the threading.Thread.run function nor self as argument. I'd have expected to see a reference to <i>another</i> thread's run method here.</span>
<span class="comment-copy">It's not in the documentation, but it is in the module.  See <a href="http://hg.python.org/cpython/file/6bf07db23445/Lib/cProfile.py#l140" rel="nofollow noreferrer">hg.python.org/cpython/file/6bf07db23445/Lib/cProfile.py#l140</a>.  That allows you to profile a specific function call, and in our case we want to profile the Thread's <code>target</code> function, which is what the <code>threading.Thread.run()</code> call executes.  But as I said in the answer, it's probably not worth it to subclass Thread, since any third-party code won't use it, and to instead use <code>threading.setprofile()</code>.</span>
<span class="comment-copy">wrapping the code with profiler.enable() and profiler.disable() seems to work quite well, too. That's basically what runcall do and it doesn't enforce any number of argument or similar things.</span>
<span class="comment-copy">I combined my own <a href="http://stackoverflow.com/questions/10748118/starting-debugger-on-errors-in-threads" title="starting debugger on errors in threads">stackoverflow.com/questions/10748118/…</a> with <a href="http://ddaa.net/blog/python/lsprof-calltree" rel="nofollow noreferrer">ddaa.net/blog/python/lsprof-calltree</a> and it kindof works ;!-)</span>
<span class="comment-copy">Joe, do you know how the profiler plays with asyncio in Python 3.4?</span>
<span class="comment-copy"><a href="http://code.google.com/p/jrfonseca/wiki/Gprof2Dot" rel="nofollow noreferrer">gprof2dot</a> can do those graphs too. I think the output is a bit nicer (<a href="http://maxy.homeip.net/misc/profile_tiny_straight_line_preview.png" rel="nofollow noreferrer">example</a>).</span>
<span class="comment-copy">graphviz is also required if you are using OSX</span>
<span class="comment-copy">On my Ubuntu 14.04 installation, <code>sudo apt-get install gprof2dot</code> results in an <code>E: Unable to locate package gprof2dot</code> error. But if I run <code>sudo pip install gprof2dot</code> it works fine. Are you sure you meant <code>apt-get</code> and not <code>pip install</code>?</span>
<span class="comment-copy">I made the edit, PS: you might want to look into python virtualenv, or conda if you are using the anaconda distribution of python.  They keep it so that you don't have to pollute you make python site packages with package that you are downloading for one single project.</span>
<span class="comment-copy">You are right <code>pip install</code> not <code>apt-get install</code>, I changed it above.</span>
<span class="comment-copy">Good approach, works really well as you can view SVG in Chrome etc and scale it up/down.  Third line has typo, should be: ln -s <code>pwd</code>/gprof2dot/gprof2dot.py $HOME/bin  (or use ln -s $PWD/gprof2dot/gprof2dot.py ~/bin in most shells - grave accent is taken as formatting in first version).</span>
<span class="comment-copy">Ah, good point. I get <code>ln</code>'s argument-order wrong almost every time.</span>
<span class="comment-copy">the trick is to remember that ln and cp have the same argument order - think of it as 'copying file1 to file2 or dir2, but making a link'</span>
<span class="comment-copy">That makes sense, I think the use of "TARGET" in the manpage throws me.</span>
<span class="comment-copy">ln -s from to ;)</span>
<span class="comment-copy">Mac Users install <code>brew install qcachegrind</code> and substitude each <code>kcachegrind</code>  with <code>qcachegrind </code> in the description for successful profiling.</span>
<span class="comment-copy">this is the best answer and works on windows like a charm. Thanks!</span>
<span class="comment-copy">Excellent tip! A quick peek at <code>cprofile.py</code>'s source code reveals that's <i>exactly</i> what <code>runcall()</code> does. Being more specific, after creating a Profile instance with <code>prof = cprofile.Profile()</code>, immediately call <code>prof.disable()</code>, and then just add <code>prof.enable()</code> and <code>prof.disable()</code> calls around the section of code you want profiled.</span>
<span class="comment-copy">This is very helpful, but it seems <b>the code that is actually between enable and disable is not profiled</b> -- only the functions it calls. Do I have this right?  I'd have to wrap that code in a function call for it to count toward any of the numbers in print_stats().</span>
<span class="comment-copy">for example, the profile prints {map} or {xxx} . how do I know the method {xxx} is called from which file? my profile prints {method 'compress' of 'zlib.Compress' objects} takes most of time, but I don't use any zlib , so I guess some call numpy function may use it . How do I know which is the exactly file and line takes much time?</span>
<span class="comment-copy">Thank you for this gem. FYI: This can be used as a standalone module with any code, Virtaal code base is not required. Just save the file to profiling.py and import the profile_func(). Use @profile_func() as a decorator to any function you need to profile and viola. :)</span>
<span class="comment-copy">Shouldn't it be named the Stupendous Yappi?</span>
<span class="comment-copy">Unfortunately the code above works only with version 0.62 which is not available on pypy. Module needs to be compiled from 0.62 sources available here: <a href="https://github.com/nirs/yappi/releases" rel="nofollow noreferrer">github.com/nirs/yappi/releases</a> or use build I made for windows in repo forked for that purpose <a href="https://github.com/Girgitt/yappi/releases" rel="nofollow noreferrer">github.com/Girgitt/yappi/releases</a></span>
