<div class="post-text" itemprop="text">
<p>I'm using selenium for web scraping  but it's too slow so I'm trying to use to instance to speed it up.</p>
<p>What I'm trying to accomplish is:</p>
<p>1) create  instance_1<br/>
2) create instance_2<br/>
3) Open a page in the first instance<br/>
do nothing<br/>
4) Open a page in the first instance<br/>
save the content of the first insctance<br/>
5) Open a new page in the first instance<br/>
save the content of the second instance    </p>
<p>The idea is to use the time that takes the first page to load to open a second one.   </p>
<pre><code>links = ('https:my_page'+ '&amp;LIC=' + code.split('_')[1] for code in data)

browser = webdriver.Firefox()
browser_2 = webdriver.Firefox()


first_link = links.next()
browser.get(first_link)
time.sleep(0.5)

for i,link in enumerate(links): 

        if i % 2:       # i starts at 0
            browser_2.get(link)
            time.sleep(0.5)
            try: 
                content = browser.page_source
                name = re.findall(re.findall('&amp;LIC=(.+)&amp;SAW',link)[0]
                with open(output_path  + name,'w') as output:
                    output.write((content_2))

                print 'error ' + str(i) 

        else:

            browser.get(link)
            time.sleep(0.5)
            try:
                content_2 = browser_2.page_source
                name = re.findall(re.findall('&amp;LIC=(.+)&amp;SAW',link)[0]
                with open(output_path  + name,'w') as output:
                    output.write((content ))

            except:
                print 'error ' + str(i) 
</code></pre>
<p>But the script is waiting to the first page to charge completely  before open  open the next one, also this approach is bounded to only to page at the same time</p>
<p>EDIT.</p>
<p>I made the following changes to the code of GIRISH RAMNANI</p>
<h3>Create the browser instances outside the function</h3>
<pre><code>driver_1 = webdriver.Firefox()
driver_2 = webdriver.Firefox()
driver_3 = webdriver.Firefox()

drivers_instance = [driver_1,driver_2,driver_3]
</code></pre>
<h3>Use the driver and the url as input for the function</h3>
<pre><code> def get_content(url,driver):    
    driver.get(url)
    tag = driver.find_element_by_tag_name("a")
    # do your work here and return the result
    return tag.get_attribute("href")
</code></pre>
<h3>create a pair of link/ browser using the zip function</h3>
<pre><code>with ThreadPoolExecutor(max_workers=2) as ex:
    zip_list = zip(links, cycle(drivers_instance)) if len(links) &gt; len(drivers_instance) else zip(cycle(links), drivers_instance)
    for par in zip_list:

       futures.append(ex.submit(get_content,par[0],par[1]))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>use of <code>concurrent.futures</code> can be done here.</p>
<pre><code>from selenium import webdriver
from concurrent.futures import ThreadPoolExecutor

URL ="https://pypi.python.org/pypi/{}"

li =["pywp/1.3","augploy/0.3.5"]

def get_content(url):    
    driver = webdriver.Firefox()
    driver.get(url)
    tag = driver.find_element_by_tag_name("a")
    # do your work here and return the result
    return tag.get_attribute("href")


li = list(map(lambda link: URL.format(link), li ))


futures = []
with ThreadPoolExecutor(max_workers=2) as ex:
    for link in li:

        futures.append(ex.submit(get_content,link))

for future in futures:
    print(future.result())
</code></pre>
<p>Keep in mind that two instances of firefox will start.</p>
<p>Note: you might want to use headless browsers such as <code>PhantomJs</code> instead of firefox.</p>
</div>
<span class="comment-copy">You may achieve better results threading with a consumer/producer queue and worker functions.</span>
<span class="comment-copy">you can use the <code>multiprocessing</code> module to create seperate <code>Process</code> for each browser</span>
<span class="comment-copy">Have you tried <i>not</i> using Selenium at all? I mean, it is slow by nature because it is emulating a full-fledged browser. If the page you are trying to scrape isn't full of AJAX, a simpler approach using just plain <code>requests</code>/<code>lxml</code> (or BS4) or perhaps <code>mechanize</code> (if you need forms) should be a lot faster by default. You can also use the aforementioned tools with <a href="http://scrapy.org/" rel="nofollow noreferrer">scrapy</a>, in case you need to scrape a LOT of pages.</span>
<span class="comment-copy">@GustavoBezerra Yes, I usually use scrapy, but in thios case I need to interact with the page in order to get the data.</span>
<span class="comment-copy">It almost work, but I've an issue, each time the function get_content is called it creates a new instance of the browser, so at each iteration I have to new windows. I guess I could close the browser but still will have the problem of the time it takes it to start. is possible to use the same two instance all the time?</span>
<span class="comment-copy">I made I few changes and now works fine, but I had to change generators for lists, do you have any suggestion to use the generators again or any other improvement</span>
<span class="comment-copy">for the issue of idle instances , you can create a list of firefox instances with a <code>contextmanager</code> which <code>on_enter</code> removes the instance from the <code>idle</code> list and adds them <code>on_exit</code>. more info on <a href="https://docs.python.org/3/library/contextlib.html" rel="nofollow noreferrer">contextmanager</a></span>
