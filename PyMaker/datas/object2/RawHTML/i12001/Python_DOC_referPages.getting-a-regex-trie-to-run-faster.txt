<div class="post-text" itemprop="text">
<p>I have a 50mb regex trie that I'm using to split phrases apart.</p>
<p>Here is the relevant code:</p>
<pre><code>import io
import re

with io.open('REGEXES.rx.txt', encoding='latin-1') as myfile:
        regex = myfile.read()


while True == True:
    Password = input("Enter a phrase to be split: ")

    Words = re.findall(regex, Password)

    print(Words)
</code></pre>
<p>Since the regex is so large, this takes forever! </p>
<p>Here is the code I'm trying now, with re.compile(TempRegex):</p>
<pre><code>import io
import re

with io.open('REGEXES.rx.txt', encoding='latin-1') as myfile:
        TempRegex = myfile.read()

regex = re.compile(TempRegex)

while True == True:
    Password = input("Enter a phrase to be split: ")

    Words = re.findall(regex, Password)

    print(Words)
</code></pre>
<p>What I'm trying to do is I'm trying to check to see if an entered phrase is a combination of names. For example, the phrase "johnsmith123" to return ['john', 'smith', '123']. The regex file was created by a tool from a word list of every first and last name from Facebook. I want to see if an entered phrase is a combination of words from that wordlist essentially ... If johns and mith are names in the list, then I would want "johnsmith123" to return ['john', 'smith', '123', 'johns', 'mith']. </p>
</div>
<div class="post-text" itemprop="text">
<p>I don't think that regex is the way to go here. It seems to me that all you are trying to do is to find a list of all of the substrings of a given string that happen to be names.</p>
<p>If the user's input is a password or passphrase, that implies a relatively short string. It's easy to break that string up into the set of possible substrings, and then test that set against another set containing the names.</p>
<p>The number of substrings in a string of length <em>n</em> is <em>n(n+1)/2</em>. Assuming that no one is going to enter more than say 40 characters you are only looking at 820 substrings, many of which could be eliminated as being too short. Here is some code to do that:</p>
<pre><code>def substrings(s, min_length=1):
    for start in range(len(s)):
        for length in range(min_length, len(s)-start+1):
            yield s[start:start+length]
</code></pre>
<p>So the problem then is loading the names into a suitable data structure. Your regex is 50MB, but considering the snippet that you showed in one of your comments, the amount of actual data is going to be a lot smaller than that due to the overhead of the regex syntax.</p>
<p>If you just used text files with one name per line you could do this:</p>
<pre><code>names = set(word.strip().lower() for word in open('names.txt'))

def substrings(s, min_length=1):
    for start in range(len(s)):
        for length in range(min_length, len(s)-start+1):
            yield s[start:start+length]

s = 'johnsmith123'
print(sorted(names.intersection(substrings(s)))
</code></pre>
<p>Might give output:</p>
<pre>
['jo', 'john', 'johns', 'mi', 'smith']
</pre>
<p>I doubt that there will be memory issues given the likely small data set, but if you find that there's not enough memory to load the full data set at once you could look at using <a href="https://docs.python.org/3/library/sqlite3.html#module-sqlite3" rel="nofollow"><code>sqlite3</code></a> with a simple table to store the names. This will be slower to query, but it will fit in memory.</p>
<p>Another way could be to use the <a href="https://docs.python.org/3/library/shelve.html#module-shelve" rel="nofollow"><code>shelve</code></a> module to create a persistent dictionary with names as keys.</p>
</div>
<div class="post-text" itemprop="text">
<p>Python's regex engine is not actually a regular expression, since it includes features such as lookbehind, capture groups, back references, and uses backtracking to match the leftmost valid branch instead of the longest.</p>
<p>If you use a true regex engine, you will almost always get better results if your regex does not require those features.</p>
<p>One of the most important qualities of a true regular expression is that it will <em>always</em> return a result in time proportional to the length of the input, without using <em>any</em> memory.</p>
<p>I've written one myself using a DFA implemented in C (but usable from python via cffi), which will have optimal asymptotic performance, but I haven't tried constant-factor improvements such as vectorization and assembly generation. I didn't make a generally usable API though since I only need to call it from within my library, but it shouldn't be too hard to figure out from the examples. (Note that search can be implemented as match with <code>.*</code> up front, then match backward, but for my purpose I would rather return a single character as an error token). <a href="https://github.com/o11c/nicate/blob/master/src/mre.h" rel="nofollow noreferrer">Link to my project</a></p>
<p>You might also consider building the DFA offline and using it for multiple runs of your program - but this is what <a href="https://github.com/westes/flex/" rel="nofollow noreferrer"><code>flex</code></a> does so there was no point in me doing that for my project, so maybe just use that if you're comfortable with C? Of course you'd almost certainly have to write a fair bit of custom C code to use my project anyway ...</p>
</div>
<div class="post-text" itemprop="text">
<p>If you compile it, the regex patterns will be compiled into a bytecodes then run by a matching engine. If you don't compile it, it will load it over and over for the same regex whenever it is called. That's why compiled one is way faster if you are using same regex for multiple different records.</p>
</div>
<span class="comment-copy">A 50 MB regex will probably always be slow. Honestly, I have no idea how to even construct something on that scale or how it would be used. Can't you do some filtering first to reduce its size? The longest one I've ever seen before is <a href="http://www.ex-parrot.com/~pdw/Mail-RFC822-Address.html" rel="nofollow noreferrer">this one</a>, and at 6kB, it's already a monster.</span>
<span class="comment-copy">A regex this large is very unusual, and almost certainly not the right solution to any problem. Could you post, say, the first 400 chars of your regex?</span>
<span class="comment-copy">from your syntax it's clear you are beginner in Python. It's ok but without proper code we can not help you. Why are you using io.open - use just open. Also - why the regex is in file ? Show it please.</span>
<span class="comment-copy">A 50mb regular expression in order to parse short phrases entered by a user? This all sounds incredibly strange. Are you really searching for a 50 million character <i>pattern</i>, or are you searching for a list of word separated by pipes?</span>
<span class="comment-copy">Really go for another approach - get a good database with names and use this one instead of monstrous regexes.</span>
<span class="comment-copy">His problem is probably the method of operation, not python's regex engine.</span>
<span class="comment-copy">If there is a way to compile the regex into a DFA offline and load it into the problem, this would be a feasible approach. (Constructing an automaton from a regex might take <code>O(2^n)</code> time, where <code>n</code> is the regex length, but evaluating a dfn will take only <code>O(n)</code> time.)</span>
<span class="comment-copy">@Bharel I'm not convinced of that actually. I don't think there's any faster way to pull out the <code>john</code> from <code>johnsmith</code> than a true RE.</span>
<span class="comment-copy">This is not true at all. Python caches the last regexes used meaning it will take the same time.</span>
<span class="comment-copy">It is true, as you don't compile it, it will be re-read each time whenever regex is called and compiled again.</span>
<span class="comment-copy">Doesn't matter. Even a compiled 50 MB regex will probably an unfeasible monstrosity.</span>
<span class="comment-copy">You guys don't get the point. The point is "it will not be loaded and compiled over and over" when it is compiled and used.</span>
<span class="comment-copy">@Gon Read the documentation for <a href="https://docs.python.org/3.5/library/re.html#re.compile" rel="nofollow noreferrer"><code>re.compile()</code></a> before stating incorrect facts. See the note. And as @Carsten says, 50 MB regex is just a bad idea.</span>
