<div class="post-text" itemprop="text">
<p>For example...</p>
<pre><code>import numpy as np
from scipy.sparse import csr_matrix

X = csr_matrix([[1,2,3], [4,5,6], [7,8,9]])
Y = csr_matrix([[1,2,3], [4,5,6], [7,8,9], [11,12,13]])

# Print matrices
X.toarray()
[[1, 2, 3],
 [4, 5, 6],
 [7, 8, 9]]

Y.toarray()
[[ 1,  2,  3],
 [ 4,  5,  6],
 [ 7,  8,  9],
 [11, 12, 13]]
</code></pre>
<p>I have a set of pairs of indices (x,y) representing a row from <code>X</code> and a row from <code>Y</code>. I'd like to take the dot product of the corresponding rows, but I can't figure out how to do this efficiently.</p>
<p>Here's what I've tried</p>
<pre><code># build arbitrary combinations of row from X and row from Y. Need to calculate dot product of each pair
x_idxs = np.array([2,2,1,0])
y_idxs = np.arange(Y.shape[0])

# current method (slow)
def get_dot_product(x_idx, y_idx):
    return np.dot(X[x_idx].toarray()[0], Y[y_idx].toarray()[0])

func_args = np.transpose(np.array([x_idxs, y_idxs]))
np.apply_along_axis(func1d=lambda x: get_dot_product(x[0], x[1]), axis=1, arr=func_args)
</code></pre>
<p>which works but is slow as <code>X</code> and <code>Y</code> get large.  Is there a more efficient way?</p>
<h1>Update</h1>
<p>Following Warren's elegant but slow solution, here's a better example for testing (along with a benchmark)</p>
<pre><code>X = csr_matrix(np.tile(np.repeat(1, 50000),(10000,1)))
Y = X
y_idxs = np.arange(Y.shape[0])
x_idxs = y_idxs

import time
start_time = time.time()
func_args = np.transpose(np.array([x_idxs, y_idxs]))
bg = np.apply_along_axis(func1d=lambda x: get_dot_product(x[0], x[1]), axis=1, arr=func_args)
print("--- %s seconds ---" % (time.time() - start_time)) # 15.48 seconds

start_time = time.time()
ww = X[x_idxs].multiply(Y[y_idxs]).sum(axis=1)
print("--- %s seconds ---" % (time.time() - start_time)) # 38.29 seconds
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>With your <code>X</code>, <code>Y</code>, <code>x_idxs</code> and <code>y_idxs</code>, you can do:</p>
<pre><code>In [160]: X[x_idxs].multiply(Y[y_idxs]).sum(axis=1)
Out[160]: 
matrix([[ 50],
        [122],
        [122],
        [ 74]])
</code></pre>
<p>That uses "fancy" indexing (i.e. indexing with an arbitrary sequence to pull out the desired set of rows), followed by pointwise multiplication and a sum along axis 1 to compute the dot products.</p>
<p>The result is in a numpy <code>matrix</code>, which you can convert to a regular numpy array and flatten as needed.  You could even use the somewhat cryptic <code>A1</code> attribute (a shortcut for the <a href="http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.getA1.html" rel="nofollow"><code>getA1</code></a> method):</p>
<pre><code>In [178]: p = X[x_idxs].multiply(Y[y_idxs]).sum(axis=1)

In [179]: p
Out[179]: 
matrix([[ 50],
        [122],
        [122],
        [ 74]])

In [180]: p.A1
Out[180]: array([ 50, 122, 122,  74])
</code></pre>
<p><em>Update, with timing...</em></p>
<p>Here's a complete script to compare the performance of my version with the original, using arrays <code>X</code> and <code>Y</code> that are actually sparse (with density approximately 0.001, i.e. about 0.1% nonzero elements).</p>
<pre><code>import numpy as np
from scipy import sparse


def get_dot_product(x_idx, y_idx):
    return np.dot(X[x_idx].toarray()[0], Y[y_idx].toarray()[0])

print("Generating random sparse integer matrix X...")
X = (100000*sparse.rand(50000, 120000, density=0.001, format='csr')).astype(np.int64)
X.eliminate_zeros()
print("X has shape %s with %s nonzero elements." % (X.shape, X.nnz))
Y = X
y_idxs = np.arange(Y.shape[0])
x_idxs = y_idxs

import time
start_time = time.time()
func_args = np.transpose(np.array([x_idxs, y_idxs]))
bg = np.apply_along_axis(func1d=lambda x: get_dot_product(x[0], x[1]), axis=1, arr=func_args)
print("--- %8.5f seconds ---" % (time.time() - start_time))

start_time = time.time()
ww = X[x_idxs].multiply(Y[y_idxs]).sum(axis=1)
print("--- %8.5f seconds ---" % (time.time() - start_time))
</code></pre>
<p>Output:</p>
<pre><code>Generating random sparse integer matrix X...
X has shape (50000, 120000) with 5999934 nonzero elements.
--- 18.29916 seconds ---
---  0.32749 seconds ---
</code></pre>
<p>For less sparse matrices, the speed difference is not so large, and for sufficiently dense matrices, the original version is faster.</p>
</div>
<span class="comment-copy">Have you tried sum(imap(operator.mul, vector1, vector2)) <a href="https://docs.python.org/2/library/itertools.html" rel="nofollow noreferrer">link</a> for Python 2.7 and sum(map(operator.mul, vector1, vector2)) <a href="https://docs.python.org/3/library/itertools.html" rel="nofollow noreferrer">link</a> for Python 3.x</span>
<span class="comment-copy">Is 10000x50000 a typical size that you are working with?  For how many rows are you typically computing these dot products?  (Your updated example uses <code>y_idxs = np.arange(Y.shape[0])</code>--in other words, <i>all</i> the rows.)</span>
<span class="comment-copy">The current matrices I'm working with have dimensions X: 50K x 120K and Y: 250K x 120K and I need to compute one dot product for each row in Y (with some random row in X).  My function takes 6 or 7 minutes to run and I suspect it can be speeded up a lot.</span>
<span class="comment-copy"><code>X</code> in your updated example is fully populated (no nonzero elements).  What is the actual typical sparseness of your arrays?  I just timed your version and mine with a 10000x50000 random array with density 0.01 (i.e. 5000000 nonzero elements), and my version was significantly faster.</span>
<span class="comment-copy">Good point.  My matrices should be very sparse.  (It's 2AM here, so I will do more research on this later.  Would be helpful if you could post your example)</span>
<span class="comment-copy">This method is significantly slower than my method for large <code>X</code> and <code>Y</code> so I can't use it.  (+1 anyways because it's pretty elegant for small matrices)</span>
<span class="comment-copy">Ah, sorry, I should have checked the timing myself.  Thanks for the detailed update in the question!</span>
<span class="comment-copy">Ben, I added an example with a timing comparsion, using matrices that are actually sparse.</span>
<span class="comment-copy">I don't understand why, but your method is much slower for my sparse matrix even though it's clearly faster using your example.</span>
