<div class="post-text" itemprop="text">
<p>I have a list of dictionaries and I use each dictionary to do some process on a graph. This processing is done within a function that returns nothing.</p>
<p>There's no I/O operations nor networking, it's merely computational; basically, each dictionary represents a path in the graph and I need to update that path's edges weight.
For the moment I'm not concerned with the graph's stored data consistency, I'm just trying to get the processing time improved.</p>
<p>I've first did it <em>serially</em>, processing each item inside a for loop:</p>
<pre><code>def processDict(dic, graph):
    # Modify graph according to the data stored in the dictionary
    # Returns nothing

def updatePheromone(listOfDicts):
    # Graph is accesible within this function's scope
    for dic in listOfDicts:
        processDict(dic, graph)
</code></pre>
<p>Then I decided to give a try and parallelize it, as the list of dicts may contain up to tens of thousands dictionaries and I can get access on a computer with quite a lot CPU's. My first try was using the <em>threading</em> module but results were much worse than the serial version.
Reading some questions here in SO and the network, I've came across several suggestions to use the multiprocessing.Pool class instead of threads due to the GIL.
Results were better than just using threads, but still the serial version outperforms it (it takes approximately half of time on a quadcore PC!). Here's what I've tried for this parallel version:</p>
<pre><code>from multiprocessing import Pool, cpu_count
from functools import partial


def updatePheromone(listOfDicts):
    # Graph is accesible within this function's scope

    pool = Pool()
    partial_Func = partial(processDict, graph=graph)
    pool.map_async(partial_Func, listOfDicts, len(listOfDicts)/cpu_count())
    pool.close()
</code></pre>
<p>I feel I'm getting something wrong in this approach. Can the poor performance be related to the fact that the function passed to map is a <em>"void"</em> kind of function? Should I be using some other library or class?</p>
<p>EDIT: I'm running this on Linux.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>I feel I'm getting something wrong in this approach. </p>
</blockquote>
<p>The likely cause is that too much data is being passed in.</p>
<p>Processes don't share memory, so any data you pass in has to be serialized on one side, transmitted over a channel (like a raw socket), and deserialized on the other.  If the time that takes is more than the time saved by the parallel processing, the result is a net loss.</p>
<p>One technique for dealing with this is to have the graph in memory as a global variable <em>before</em> you create the pool (that lets the data be shared by copy-on-write).  Then just pass in an index (a single number) to the process and let it work on its own section of the graph.</p>
</div>
<span class="comment-copy">It would be helpful if you specify what platform you are using (Linux/Windows/BSD/...): multiprocessing is implemented in different ways depending on the system, some are faster than others. You may want to look at <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer">the ways to start a process with multiprocessing</a></span>
<span class="comment-copy">Raymond Hettinger actually gives a <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi0x42Bkt_TAhVo7oMKHXB6DYIQtwIIIzAA&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DBv25Dwe84g0&amp;usg=AFQjCNFU5XoX6_4TzUX3gB7Yo7aZPSjmdQ&amp;sig2=qVDaq4m7qhP1ecYlDWQNzA" rel="nofollow noreferrer">great talk</a> about just that very thing. He's the perfect person to have answered your question.</span>
<span class="comment-copy">It may be worth mentioning that forking a copy-on-write subprocess works on unix-like systems (Linux, OSX, ...) but not Windows. I found the statement "Processes don't share memory" followed by copy-on-write because those systems do share a snapshot at the time of the fork.</span>
<span class="comment-copy">Thanks for the replies. I'll look at the pyCon video and give this a more carefult thinking.</span>
