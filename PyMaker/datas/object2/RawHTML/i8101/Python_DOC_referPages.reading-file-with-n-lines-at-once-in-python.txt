<div class="post-text" itemprop="text">
<p>I am reading xyz trajectory files a lot. These files are structured in a way, that information corresponding to a time frame is stored in N lines. </p>
<p>I would like to write an iterator similar to:</p>
<pre><code>file=open(...)
for line in file:
   analyze(line)
</code></pre>
<p>but reading N line at once:</p>
<pre><code>file=Myopen(...,N=n)
for Nlines in file:
    analyze(Nlines)
</code></pre>
<p>Since the files are huge, I do not want to read the whole into memory,
but the purpose is not to gain efficiency but to make a clean and reuseable code. Of course, one could check the index%N==0, and analyze when it is true,
but I am a bit sick of writing that few lines over, and over, and over....</p>
<p>Comments and answers are more than appreciated! </p>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer"><code>itertools</code> documentation</a> has a recipe for a generator function that does what you want:</p>
<pre><code>def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    # grouper('ABCDEFG', 3, 'x') --&gt; ABC DEF Gxx"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)
</code></pre>
<p>If you don't need to handle files that aren't an exact multiple of three lines long, you can simplify things a bit and just use <code>for nlines in zip(*[file]*5)</code> directly in your code.</p>
</div>
<div class="post-text" itemprop="text">
<p>For instance:  </p>
<pre><code>file=Myopen(...,N=n)
Nlines = []
for i in range(N):
     Nlines.append(file.readline)
analyze( ''.join(Nlines) )
</code></pre>
</div>
<span class="comment-copy">you might want to look at: <a href="http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks" title="how do you split a list into evenly sized chunks">stackoverflow.com/questions/312443/â€¦</a></span>
