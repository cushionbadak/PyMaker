<div class="post-text" itemprop="text">
<p>I am generating 100 random integers and I want to store them in a sorted array. The first approach that I tried was using a binary search to find the proper index to store each number at and then insert the number at that index. This way, after 100th random number, I will have a sorted array. Binary search has a time complexity of <code>log(N)</code> and <code>insert()</code> method has a time complexity of <code>N</code> so the final Big-O should be <code>O(Nlog(N))</code> right?</p>
<p>Below is the code for this approach:</p>
<pre><code>def binary_search(start, end, item):
    mid = (start + end)/2
    if item &gt; mlist[end]:
        return end+1
    elif item &gt; mlist[mid]:
        return binary_search(mid+1, end, item)
    elif item &lt; mlist[mid]:
        return binary_search(start, mid-1, item)
    else:
        return int(math.ceil(mid))

begin = time.time()
for i in range(100):
    rand = randint(0,100)
    index = binary_search(0,len(mlist)-1,rand)
    mlist.insert(index,rand)
elapsed = time.time()
print((elapsed-begin)*(10**4))
</code></pre>
<p>When I printed the difference between elapsed and begin time, I got <strong>4.2414</strong> microseconds.</p>
<p>My second approach was to simply add all random numbers in an array/list and then use the built in <code>sort()</code> method to sort it. The time complexity for <code>sort()</code> method is <code>Nlog(N)</code>. </p>
<pre><code>begin = time.time()
mlist=[]
for i in range(100):
    rand = randint(0,100)
    mlist.append(rand)
mlist = sorted(mlist)
elapsed = time.time()
print((elapsed-begin)*(10**4))
</code></pre>
<p>The elapsed time for this approach was <strong>1.9407</strong> microseconds. </p>
<p>I don't understand that if the time complexities for both methods are same then what makes the second approach so much faster?</p>
</div>
<div class="post-text" itemprop="text">
<p>Your binary search insertion is O(N^2); <em>each insertion</em> has to move up to O(N) elements up one step to the right, and you do this N times. However, even if it was O(NlogN), the constant cost of the sorting code is <em>far lower</em> than your Python code could match.</p>
<p>If you do want to stick to bisect insertion sorting, rather than re-invent the (admittedly simple) <code>bisect</code> wheel, do use the <a href="https://docs.python.org/3/library/bisect.html" rel="nofollow noreferrer"><code>bisect</code> module</a>. This module comes with a C-optimised implementation.</p>
<p>It even has <a href="https://docs.python.org/3/library/bisect.html#bisect.insort_left" rel="nofollow noreferrer"><code>bisect.insort*()</code> functions</a>, which note:</p>
<blockquote>
<p>Keep in mind that the O(log n) search is dominated by the slow O(n) insertion step.</p>
</blockquote>
<p>Another tip: don't use wall-clock time to measure algorithms. Use the <a href="https://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer"><code>timeit</code> module</a>, which disables the garbage collector, uses the most accurate clock available, and runs your test <em>multiple times</em> to eliminate external factors.</p>
<p>Next, don't include creating the random values, you don't want to time how fast those can be produced; produce one list, <em>up front</em>, and re-use it for all timings.</p>
<p>Next, use a proper <code>bisect()</code> function, yours is broken for any <code>len(mlist) &lt; 2</code>; there is <em>no need</em> to test for <code>mlist[end]</code> for example. The following avoids an off-by-one error and uses <code>mlist</code> as a parameter rather than a global:</p>
<pre><code>def binary_search(mlist, item, start=0, end=None):
    if end is None:
        end = len(mlist)
    if start &gt;= end:
        return start
    mid = (start + end) // 2
    if item &gt;= mlist[mid]:
        return binary_search(mlist, item, mid + 1, end)
    else:
        return binary_search(mlist, item, start, mid)
</code></pre>
<p>Use <code>binary_search(mlist, value)</code> to call it, the start and end values are filled in for you.</p>
<p>Now you can conduct a proper timed test:</p>
<pre><code>&gt;&gt;&gt; import random, timeit
&gt;&gt;&gt; def binsort(l):
...     mlist = []
...     for i in l:
...         index = binary_search(0, len(mlist), i, mlist)
...         mlist.insert(index, i)
...     return mlist
...
&gt;&gt;&gt; values = [random.randint(0, 100) for _ in range(100)]
&gt;&gt;&gt; count, time = timeit.Timer('binsort(values)', 'from __main__ import values, binsort').autorange()
&gt;&gt;&gt; format(time / count, '.15f')
'0.000146628010299'
&gt;&gt;&gt; count, time = timeit.Timer('sorted(values)', 'from __main__ import values').autorange()
&gt;&gt;&gt; format(time / count, '.15f')
'0.000008379445840'
&gt;&gt;&gt; values = [random.randint(0, 100) for _ in range(1000)]
&gt;&gt;&gt; count, time = timeit.Timer('binsort(values)', 'from __main__ import values, binsort').autorange()
&gt;&gt;&gt; format(time / count, '.15f')
'0.002460538140149'
&gt;&gt;&gt; count, time = timeit.Timer('sorted(values)', 'from __main__ import values').autorange()
&gt;&gt;&gt; format(time / count, '.15f')
'0.000144566002200'
&gt;&gt;&gt; values = [random.randint(0, 100) for _ in range(10000)]
&gt;&gt;&gt; count, time = timeit.Timer('binsort(values)', 'from __main__ import values, binsort').autorange()
&gt;&gt;&gt; print(format(time / count, '.15f'))
0.043877328099916
&gt;&gt;&gt; count, time = timeit.Timer('sorted(values)', 'from __main__ import values').autorange()
&gt;&gt;&gt; print(format(time / count, '.15f'))
0.001707894587977
&gt;&gt;&gt; values = [random.randint(0, 100) for _ in range(100000)]
&gt;&gt;&gt; count, time = timeit.Timer('binsort(values)', 'from __main__ import values, binsort').autorange()
&gt;&gt;&gt; print(format(time / count, '.15f'))
1.435402424700442
&gt;&gt;&gt; count, time = timeit.Timer('sorted(values)', 'from __main__ import values').autorange()
&gt;&gt;&gt; print(format(time / count, '.15f'))
0.017957194280170
</code></pre>
<p>As you can see, with larger input lists, the <code>binsort()</code> function is lagging further and further behind in performance.</p>
</div>
<div class="post-text" itemprop="text">
<p>First, neither version of your code is O(Nlog(N)). Your version with the binary search isn't, due to the <code>insert</code> calls. Your version with <code>sorted</code> isn't either, because you're calling <code>sorted</code> on every insertion!</p>
<p>The <code>sorted</code> calls win because <code>sorted</code> is implemented in C. Interpreted Python code has a lot of overhead that the C implementation of <code>sorted</code> gets to avoid. Also, <code>sorted</code> is smart enough to take advantage of existing order in the input, so it doesn't need to go through the full effort of an O(Nlog(N)) sort every time.</p>
</div>
<span class="comment-copy">First, time complexities aren't everything. Second, your first version is actually quadratic time due to the <code>insert</code> calls.</span>
<span class="comment-copy">@user2357112 so what is the time complexity of the first approach? How did you determine that?</span>
<span class="comment-copy">Wait, your "sorting in the end" code isn't even sorting <i>in the end</i>. It calls <code>sorted</code> on every insertion!</span>
<span class="comment-copy">@user2357112 My bad, it was a formatting mistake while copy+pasting code. I have updated it. I am sorting it after the end of the loop</span>
<span class="comment-copy">N=100 is <i>waaay</i> to small to learn <i>anything</i> about complexity. Constant factors (like slow interpreter code vs. fast C code) are a lot more important. If you want to see asymptotic cost, increase N until you exhaust your memory. Say N=2^31 or something like that should be reasonable. But also increase your value range to 64 bit integers then. It's as with cars: if you drive just 100cm, you can't tell which car is "faster". You need to race at the limit.</span>
<span class="comment-copy">I suspect for lists this small, the <code>insert</code> calls are actually only a small fraction of the time cost and most of the time is spent in <code>binary_search</code>.</span>
<span class="comment-copy">Your explanation makes sense. I didn't think that insertion was costing me so much. Thank you!</span>
<span class="comment-copy">As Martijn Pieters notes your time will eventually be dominated by the N * O(N) insertions (O(NÂ²)). I would add one other note, not really applicable here but useful in other cases: searching for an integer (or similar key) in a sorted array can be done with interpolative search, which is O(log log N). The overhead on interpolation searches is high compared to binary search, so the situations where this is better are somewhat unusual, but it's something to keep in mind.</span>
<span class="comment-copy">At N=100, asymptotic complexity is worthless and completely irrelevant, only constant factors matter.</span>
<span class="comment-copy">thank you for the detailed explanation and the tips.</span>
<span class="comment-copy">I have updated the code, I am not calling <code>sorted()</code> after every insertion, I am only calling it after the list fully populated. But your answer does make sense. I didn't realize how expensive the <code>insert</code> calls were.</span>
<span class="comment-copy">Also don't underestimate how much faster a C call like <code>sort</code> is compared to any <i>interpreter</i> code like your binary search. If you want fast Python, call C as much as possible, then identify the remaining.bottlenecks and rewrite them in C/Cython, too. The interpreter is 20x slower.</span>
