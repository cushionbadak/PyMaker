<div class="post-text" itemprop="text">
<p>Using Python 3.x, I am trying to iterate over a dictionary of datasets (<a href="http://unidata.github.io/netcdf4-python/#netCDF4.Dataset" rel="nofollow noreferrer">NetCDF4 datasets</a>). They are just files...</p>
<p>I want to examine each dataset on a separate process:</p>
<pre><code>def DoProcessWork(datasetId, dataset):
    parameter = dataset.variables["so2"]
    print(parameter[0,0,0,0])

if __name__ == '__main__':
    mp.set_start_method('spawn')
    processes = []
    for key, dataset in datasets.items():
        p = mp.Process(target=DoProcessWork, args=(key, dataset,))
        p.start()
        processes.append(p)
</code></pre>
<p>When I run my program, I get some message about 'pickable'</p>
<pre><code>File "C:\Program Files (x86)\Python36-32\lib\multiprocessing\process.py", line 105, in start
    self._popen = self._Popen(self)
  File "C:\Program Files (x86)\Python36-32\lib\multiprocessing\context.py", line 223, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File "C:\Program Files (x86)\Python36-32\lib\multiprocessing\context.py", line 322, in _Popen
    return Popen(process_obj)
  File "C:\Program Files (x86)\Python36-32\lib\multiprocessing\popen_spawn_win32.py", line 65, in __init__
    reduction.dump(process_obj, to_child)
  File "C:\Program Files (x86)\Python36-32\lib\multiprocessing\reduction.py", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
  File "netCDF4\_netCDF4.pyx", line 1992, in netCDF4._netCDF4.Dataset.__reduce__ (netCDF4\_netCDF4.c:16805)
NotImplementedError: Dataset is not picklable
</code></pre>
<p>What am I doing wrong? How can I fix this?
Could it be that opening the file is done on another process, and so I am getting an error because I am trying to pass data loaded on 1 process to another process?</p>
</div>
<div class="post-text" itemprop="text">
<p>The <code>multiprocessing</code> needs to serialize (pickle) the inputs to pass them to the new proccess which will run the <code>DoProcessWork</code>. In your case the dataset object is a problem, see the <a href="https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled" rel="nofollow noreferrer">list of what can be pickled</a>.</p>
<p>A possible workaround for you would be using multiprocessing with another function which reads the dataset and calls <code>DoProcessWork</code> on it.</p>
</div>
<span class="comment-copy">The multiprocessing module uses pickles to pass arbitrary parameters to each process.  I'm not familiar enough with netCDF4 to suggest an exact solution, but perhaps you could load the datasets in each process?  In other words, pass the filename as an argument to <code>DoProcessWork</code>, rather than the dataset itself.</span>
<span class="comment-copy">Yeah, you're right. I guess I pretty much realised that it was loading the dataset in one process and then trying to read it on another... Thanks for the help.</span>
