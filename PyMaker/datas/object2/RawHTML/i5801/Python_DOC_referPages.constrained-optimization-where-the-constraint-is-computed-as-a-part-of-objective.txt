<div class="post-text" itemprop="text">
<p>I made a function <code>f</code> that takes a long time to run. The constraints are calculated at the end of <code>f</code>'s routine. How can I return these constraints to cobyla without evaluating <code>f</code> twice?</p>
<pre><code>import numpy as np
from scipy.optimize import fmin_cobyla as mini
def f(x, returncons=True):
    if returncons: return x[1] - x[0]
    else: return (x[0] - 2)**2 + 4 * (x[1] -x[0]**2)**2

x_opt = mini(f, [1., 1.], args=(False,), cons=f)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<h3>LRU Cache</h3>
<p>This is implementing Paul Panzer's suggestion, it relies on <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow noreferrer">@lru_cache</a> which is a Python 3 feature. We cannot directly apply this decorator to the objective function, because it receives a NumPy array, which is mutable and therefore not hashable. So we need two functions: </p>
<ul>
<li><code>func_with_cons</code> computes the objective and constraint, given scalar arguments.</li>
<li><code>f</code> calls <code>func_with_cons</code> and returns either objective or constraint, based on <code>returncons</code> argument. </li>
</ul>
<p>Note that we need <code>consargs</code> parameter in the call to <code>fmin_cobyla</code>, because without it the same extra arguments <code>args</code> will be passed to the constraint function. </p>
<pre><code>from scipy.optimize import fmin_cobyla as mini
from functools import lru_cache

@lru_cache(maxsize=32)
def func_with_cons(x0, x1):
    return (x0 - 2)**2 + 4 * (x1 -x0**2)**2, x0 - x1

def f(x, returncons=True):
    value, cons = func_with_cons(x[0], x[1])
    return cons if returncons else value

func_with_cons.cache_clear()
x_opt = mini(f, (1., 1.), cons=f, args=(False,), consargs=())
print(x_opt)
print(func_with_cons.cache_info())
</code></pre>
<p>Output: </p>
<pre><code>[ 1.14491021  1.14491021]
CacheInfo(hits=41, misses=32, maxsize=32, currsize=32)
</code></pre>
<p>So, the cache works. I changed the constraint from x1-x0 to x0-x1 to show that it also works (the original constraint x1-x0 is satisfied by the global minimum of this function, so it would have no effect on the result). </p>
<p>Cache size can be much smaller: with <code>maxsize=2</code> we would have 40 hits (vs 41 with the above size). </p>
<h3>Global variable</h3>
<p>This is implementing Jakob Lovern's suggestion. The function f stores the constraint in a global variable, from which the function cons retrieves it. The use of a global has obvious drawbacks, but then again, this works in Python 2.7.  </p>
<pre><code>def f(x):
    global stored_cons
    stored_cons = x[0] - x[1]
    return (x[0] - 2)**2 + 4 * (x[1] -x[0]**2)**2

def cons(x):
    return stored_cons

x0 = [1., 1.] 
f(x0)  # called to initialize stored_cons        
x_opt = mini(f, x0, cons=cons) 
</code></pre>
<p>This returns <code>[ 1.14491021,  1.14491021]</code> since the global minimum [2, 4] is disallowed by the constraint.</p>
</div>
<span class="comment-copy">Have you considered saving the constraints calculated by <code>f</code> and then using the saved value?</span>
<span class="comment-copy">Perhaps use <code>functools.lru_cache</code>? Don't know how much overhead that adds, though.</span>
<span class="comment-copy">@JakobLovern Yes that is what I want to do. How would you do that?</span>
<span class="comment-copy">I don't think this translates to a real workflow. What if my function is imported from another program?</span>
<span class="comment-copy">I added a version with <code>lru_cache</code></span>
