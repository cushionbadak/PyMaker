<div class="post-text" itemprop="text">
<p>My use case is the following:</p>
<ul>
<li>several scripts that can be run individually</li>
<li>one 'mother' script that can run all the scripts</li>
<li>each script has global variables it uses (paths to specific locations, constants used by all scripts)</li>
<li>some of these global variables are inputted in a settings.yaml file which gets dynamically loaded with <code>yaml.load()</code></li>
<li>several people are running the system, we want to avoid environment variables or any kind of low-level path settings</li>
</ul>
<p>The use cases were satisfied with an </p>
<pre><code>import settings
</code></pre>
<p>at the beginning of each export module. </p>
<p>The settings.py script is our 'initialize' script that loads and create variables used for all the modules, e.g.:</p>
<pre><code>import os
import yaml
from utils import create_dir

input_f = open("settings.yml")
settings = yaml.load(input_f.read())
input_f.close()

TOHELLO = settings['TOHELLO']
TOBONJOUR = settings['TOBONJOUR']

#check for needed directories and create if necessary
create_dir(TOHELLO)
create_dir(TOBONJOUR)
</code></pre>
<p>The 'mother module' export_all.py uses <code>Subprocess.Popen()</code> to run all the scripts sequentially.</p>
<p>Originally all files were in the root:</p>
<pre><code>+--settings.py
+--settings.yml
+--export_foo1.py
+--export_foo2.py
+--export_foo3.py
+--export_foo4.py
+--export_bar1.py
+--export_bar2.py
+--export_bar3.py
+--export_bar4.py
+--export_all.py
</code></pre>
<p>With time, though, this became messy and we decided to restructure it:</p>
<pre><code>+--settings.py
+--settings.yml
+--Foo
+  +--export_foo1.py
+  +--export_foo2.py
+  +--export_foo3.py
+  +--export_foo4.py
+--Bar
+  +--export_bar1.py
+  +--export_bar2.py
+  +--export_bar3.py
+  +--export_bar4.py
+--export_all.py
</code></pre>
<p>And then all hell broke loose.</p>
<p>We discovered that one can only use 'import' for modules that are either <em>underneath</em> the module or specifically within sys.path.</p>
<p>The solution we've come up with involves inserting this beauty at the top of all of our scripts:</p>
<pre><code>PACKAGE_PARENT = os.path.join('..','..')
SCRIPT_DIR = os.path.dirname(os.path.realpath(os.path.join(os.getcwd(), os.path.expanduser(__file__))))
sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))
</code></pre>
<p>but it just seems like overkill to us.</p>
<p>We tried</p>
<pre><code>from settings import functionname
</code></pre>
<p>but that doesn't run the code that generates the constants from the yaml file</p>
<p>Also, we tried squeezing the <code>import</code>s in __init.py__ in each directory, but then the <code>Subprocess.Popen()</code> didn't work.</p>
<p>We're kind of missing a pythonesque way to have some global constants, and an initialiazing script that runs only once (even when the 'mother' script is running).</p>
<p>Is it us, or is python just weird and ugly here?</p>
</div>
<div class="post-text" itemprop="text">
<p>I am not sure what exactly the problem is, but here are several options you can choose from:</p>
<ol>
<li><p>The best approach is to reference your scripts as if they are submodules of a package. In this case, everything should work if you run all scripts from the directory where <code>export_all.py</code> lives. The only change is that you should run them as modules, and not as scripts:</p>
<pre><code>$ python export_all.py
</code></pre>
<p>but</p>
<pre><code>$ python -m Foo.export_foo
</code></pre></li>
<li><p>You can use <code>PYTHONPATH</code> environment variable to pass additional paths for <code>sys.path</code> to your script. The variable will be inherited by subprocesses.</p></li>
<li><p>Assuming you run your scripts in a virtual environment, you can put a <code>.pth</code> file in your site-packages directory with absolute paths of the <code>Foo</code> and <code>Bar</code> directories. The paths will be added to <code>sys.path</code> each time a script is started with <code>python</code> without <code>-S</code> switch. You can read about <code>.pth</code> files in the documentation for standard <a href="https://docs.python.org/3/library/site.html" rel="nofollow noreferrer">site</a> module.</p></li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>You need to turn your directories into modules: <a href="https://docs.python.org/2/tutorial/modules.html#packages" rel="nofollow noreferrer">https://docs.python.org/2/tutorial/modules.html#packages</a></p>
<p>to allow you use a structure like this:</p>
<pre><code>from foo import export_foo1
</code></pre>
<p>or to use:</p>
<pre><code>from ..bar import export_bar1
</code></pre>
<p>in case you are inside a subfolder</p>
<p><a href="https://docs.python.org/2/tutorial/modules.html#intra-package-references" rel="nofollow noreferrer">https://docs.python.org/2/tutorial/modules.html#intra-package-references</a></p>
</div>
<span class="comment-copy">dear newtover, thanks for your answer. I've edited my question to show that I'm interested in the 'run code of the module that I'm importing' aspect of the import keyword. Regarding 1.), this was our original setup and all worked well. but 'Foo' and 'Bar' contain 50+ scripts each, so we were trying to clean up. We might need to revert to 'everything in the root directory' but I'd rather avoid that. I didn't know about the -m switch, that's really useful for our Subprocess.Popen() command.</span>
<span class="comment-copy">Regarding 2) we'd rather avoid having to set environment variables because the use case involves many different machines using many different OS (Mac, unix, Windows) and it's a pain in non-windows environment (we want noobs to be able to install it easily)</span>
<span class="comment-copy">Regarding 3) I've read PEP 340 and as far as I understand, we would have to manually add a something.pth in the sites-directory of each machine. Our use case is 'clone from git, run' so that looks a bit fiddly to me.</span>
<span class="comment-copy">In any case, thanks for the answer!</span>
<span class="comment-copy">Hi Shailyn, thanks for the answer. What you suggest works if i'm interested in a function, but I'm interested in the fact that the pure 'import' statement actually runs all the code in the imported module.</span>
<span class="comment-copy">That is how python works:   See here a few options <a href="https://stackoverflow.com/questions/6523791/why-is-python-running-my-module-when-i-import-it-and-how-do-i-stop-it" title="why is python running my module when i import it and how do i stop it">stackoverflow.com/questions/6523791/â€¦</a></span>
<span class="comment-copy">Thanks for the link. Essentially what I'm saying is that I like the fact that the whole code of a module is run when it is imported; I was expecting there to be a way to import code which is in a directory above. It works with a directory below. At a more deeper level, I'm curious as to what are the mechanisms are typical for initialization and global constants/variables. newtover seems to imply that the best way to get the advantages of what I'm trying is to put all my scripts in the same directory. Which is what i wanted to avoid in the first place because I have too many modules.</span>
