<div class="post-text" itemprop="text">
<p>I have a list of <code>x</code>,<code>y</code> coordinates that I need to sort based on the <code>x</code> coordinate, then <code>y</code> coordinate when <code>x</code> is the same and eliminate duplicates of the same coordinates. For example, if the list is:</p>
<pre><code>[[450.0, 486.6], [500.0, 400.0], [450.0, 313.3], [350.0, 313.3], [300.0, 400.0], 
 [349.9, 486.6], [450.0, 313.3]]
</code></pre>
<p>I would need to rearrange it to:</p>
<pre><code>[[300.0, 400.0], [349.9, 486.6], [350.0, 313.3], [450.0, 313.3], [450.0, 486.6],
 [500.0, 400.0]]
</code></pre>
<p>(with one duplicate of <code>[450.0, 313.3]</code> removed)</p>
</div>
<div class="post-text" itemprop="text">
<p>That is the normal sort order for a list of lists, anyway.  De-dupe it with a dict.</p>
<pre><code>&gt;&gt;&gt; L = [[450.0, 486.6], [500.0, 400.0], [450.0, 313.3], [350.0, 313.3], [300.0, 400.0], [349.9, 486.6], [450.0, 313.3]]
&gt;&gt;&gt; sorted({tuple(x): x for x in L}.values())
[[300.0, 400.0],
 [349.9, 486.6],
 [350.0, 313.3],
 [450.0, 313.3],
 [450.0, 486.6],
 [500.0, 400.0]]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>As we are sorting anyway we can dedupe with <code>groupby</code>:</p>
<pre><code>&gt;&gt;&gt; import itertools
&gt;&gt;&gt; [k for k, g in itertools.groupby(sorted(data))]                                                                 
[[300.0, 400.0], [349.9, 486.6], [350.0, 313.3], [450.0, 313.3], [450.0, 486.6], [500.0, 400.0]]                    
</code></pre>
<p>A few timings:</p>
<pre><code>&gt;&gt;&gt; import numpy as np # just to create a large example
&gt;&gt;&gt; a = np.random.randint(0, 215, (10000, 2)).tolist()
&gt;&gt;&gt; len([k for k, g in groupby(sorted(a))])
8977 # ~ 10% duplicates
&gt;&gt;&gt; 
&gt;&gt;&gt; timeit("[k for k, g in groupby(sorted(a))]", globals=globals(), number=1000)
6.1627248489967315
&gt;&gt;&gt; timeit("sorted({tuple(x): x for x in a}.values())", globals=globals(), number=1000)
6.654527607999626
&gt;&gt;&gt; timeit("sorted(unique(a, key=tuple))", globals=globals(), number=1000)
7.198703720991034
&gt;&gt;&gt; timeit("np.unique(a, axis=0).tolist()", globals=globals(), number=1000)
8.848866895001265
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>What you want seems to be easily done with <code>numpy</code>'s <code>unique</code> function:</p>
<pre><code>import numpy as np
u = np.unique(data, axis=0) # or np.unique(data, axis=0).tolist()
</code></pre>
<p>If you are really worried that the array is not sorted by columns, then run <code>np.lexsort()</code> in addition to the above:</p>
<pre><code>u = u[np.lexsort((u[:,1], u[:,0]))]
</code></pre>
<h3>Timings (non-random sample):</h3>
<pre><code>In [1]: import numpy as np

In [2]: from toolz import unique

In [3]: data = [[450.0, 486.6], [500.0, 400.0], [450.0, 313.3],
   ...:  [350.0, 313.3], [300.0, 400.0], [349.9, 486.6], [450.0, 313.3]]
   ...:  

In [4]: L = 100000 * data

In [5]: npL = np.array(L)

In [6]: %timeit sorted(unique(L, key=tuple))
125 ms ± 1.72 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [7]: %timeit sorted({tuple(x): x for x in L}.values())
139 ms ± 3.41 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [8]: %timeit np.unique(L, axis=0)
732 ms ± 12.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [9]: %timeit np.unique(npL, axis=0)
584 ms ± 8.11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

# @user3483203 solution:

In [57]: %timeit lex(np.asarray(L))
227 ms ± 8.34 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

In [58]: %timeit lex(npL)
76.2 ms ± 410 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre>
<h3>Timings (more random sample):</h3>
<p>When sample data are more random, the results are different:</p>
<pre><code>In [29]: npL = np.random.randint(1,1000,(100000,2)) + np.random.choice(np.random.random(1000), (100000, 2))

In [30]: L = npL.tolist()

In [31]: %timeit sorted(unique(L, key=tuple))
143 ms ± 2.35 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [32]: %timeit sorted({tuple(x): x for x in L}.values())
134 ms ± 1.14 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [33]: %timeit np.unique(L, axis=0)
78.5 ms ± 1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [34]: %timeit np.unique(npL, axis=0)
54 ms ± 398 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

# @Paul Panzer's solution:

In [36]: import itertools

In [37]: %timeit [k for k, g in itertools.groupby(sorted(L))]
123 ms ± 3.42 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)

# @user3483203 solution:

In [54]: %timeit lex(np.asarray(L))
60.1 ms ± 744 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)

In [55]: %timeit lex(npL)
38.8 ms ± 728 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>We can do this quite fast using <strong><code>np.lexsort</code></strong> and some masking</p>
<pre><code>def lex(arr):                 
    tmp =  arr[np.lexsort(arr.T),:]
    tmp = tmp[np.append([True],np.any(np.diff(tmp,axis=0),1))]
    return tmp[np.lexsort((tmp[:, 1], tmp[:, 0]), axis=0)]

L = np.array(L)
lex(L)

# Output:
[[300.  400. ]
 [349.9 486.6]
 [350.  313.3]
 [450.  313.3]
 [450.  486.6]
 [500.  400. ]]
</code></pre>
<h2><strong><em>Performance</em></strong></h2>
<h3><code>Functions</code></h3>
<pre><code>def chrisz(arr):                 
    tmp =  arr[np.lexsort(arr.T),:]
    tmp = tmp[np.append([True],np.any(np.diff(tmp,axis=0),1))]
    return tmp[np.lexsort((tmp[:, 1], tmp[:, 0]), axis=0)]

def pp(data):
    return [k for k, g in itertools.groupby(sorted(data))]

def gazer(data):
    return np.unique(data, axis=0)

def wim(L):
    return sorted({tuple(x): x for x in L}.values())

def jpp(L):
    return sorted(unique(L, key=tuple))
</code></pre>
<h2><code>Setup</code></h2>
<pre><code>res = pd.DataFrame(
       index=['chrisz', 'pp', 'gazer', 'wim', 'jpp'],
       columns=[10, 50, 100, 500, 1000, 5000, 10000, 50000, 100000],
       dtype=float
)

for f in res.index: 
    for c in res.columns:
        npL = np.random.randint(1,1000,(c,2)) + np.random.choice(np.random.random(1000), (c, 2))
        L = npL.tolist()
        stmt = '{}(npL)'.format(f) if f in {'chrisz', 'gazer'} else '{}(L)'.format(f)
        setp = 'from __main__ import L, npL, {}'.format(f)
        res.at[f, c] = timeit(stmt, setp, number=50)

ax = res.div(res.min()).T.plot(loglog=True) 
ax.set_xlabel("N"); 
ax.set_ylabel("time (relative)");

plt.show()
</code></pre>
<p><a href="https://i.stack.imgur.com/1iguf.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/1iguf.png"/></a></p>
<h2><code>Validation</code></h2>
<pre><code>npL = np.random.randint(1,1000,(100000,2)) + np.random.choice(np.random.random(1000), (100000, 2))    
L = npL.tolist()    
chrisz(npL).tolist() == pp(L) == gazer(npL).tolist() == wim(L) == jpp(L)
True
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Here's one way using <code>sorted</code> and <code>toolz.unique</code>:</p>
<pre><code>from toolz import unique

res = sorted(unique(L, key=tuple))

print(res)

[[300.0, 400.0], [349.9, 486.6], [350.0, 313.3],
 [450.0, 313.3], [450.0, 486.6], [500.0, 400.0]]
</code></pre>
<p>Note <code>toolz.unique</code> is also available via the standard library as the <code>itertools</code> <code>unique_everseen</code> <a href="https://docs.python.org/3/library/itertools.html#itertools-recipes" rel="nofollow noreferrer">recipe</a>. Tuple conversion is necessary as the algorithm uses hashing via <code>set</code> to check uniqueness.</p>
<p>Performance using <code>set</code> appears slightly better than <code>dict</code> here, but as always you should test with your data.</p>
<pre><code>L = L*100000

%timeit sorted(unique(L, key=tuple))               # 223 ms
%timeit sorted({tuple(x): x for x in L}.values())  # 243 ms
</code></pre>
<p>I suspect this is because <code>unique</code> is lazy, and so you have less memory overhead since <code>sorted</code> isn't making a <em>copy</em> of the input data.</p>
</div>
<span class="comment-copy">Is a dict more efficient than a set?</span>
<span class="comment-copy">Probably.  Sets can't contain lists.</span>
<span class="comment-copy">@OlivierMelançon, which is exactly what I've done :)</span>
<span class="comment-copy">But then you'd have to convert back to lists to get your output.</span>
<span class="comment-copy">@OlivierMelançon Actually, take a look at my answer. With a more randomized input set than the one created by <code>jpp</code> (<code>L=100000*L</code>), dictionary approach is slightly faster than <code>jpp</code> solution.</span>
<span class="comment-copy">Can you comment on the memory implications? I suspect <a href="https://stackoverflow.com/questions/4154571/sorted-using-generator-expressions-rather-than-lists/4155652#4155652">based on this</a> that all but the <code>unique</code> will be making copies of the data. Of course, I may be wrong :).</span>
<span class="comment-copy"><code>unique</code> needs to keep track of what's been seen already, meaning near the end of it being exhausted there will be the input list, <code>unique</code>s seen-that set and <code>sorted</code>s input list (<code>sorted</code> has to collect the entire input before it can start sorting) simultaneaously in memory. So there is no memory advantage for <code>unique</code>.</span>
<span class="comment-copy">Why downvote?  Have you tried?</span>
<span class="comment-copy">This doesn't seem to preserve pairs. <code>np.unique</code> flattens by default.</span>
<span class="comment-copy">@PaulPanzer Thanks! Locally, I have <code>axis=0</code> but not when posting... It's late</span>
<span class="comment-copy">Would you mind adding mine to your benchmarks?</span>
<span class="comment-copy">@AGNGazer should be fixed now, it actually got faster I believe.  I validated using <code>np.all(np.unique(npL, axis=0) == lex(npL))</code></span>
<span class="comment-copy">Just added your timings. Very fast!</span>
<span class="comment-copy">Sorry, but that's just plain incorrect. Sorted will consume the entire sequence before doing any comparisons, it requires an intermediary structure in memory all the same - it's irrelevant here whether unique iterates lazy or not.</span>
<span class="comment-copy">@wim, Is that intermediary structure a <code>list</code>, or a <code>dict</code>? There's a cost attached to creating Python structures, e.g. try <code>sorted(range(10000))</code> vs <code>sorted(list(range(10000)))</code>, I know which I'd prefer.</span>
<span class="comment-copy">@wim, The memory benefit is from the fact that if you feed a list (or other in-memory iterable), <code>sorted</code> will <a href="https://stackoverflow.com/questions/4154571/sorted-using-generator-expressions-rather-than-lists/4155652#4155652">make its own list</a> prior to sorting, i.e. if you feed a list it'll copy it. This copy is what I call an intermediary structure.</span>
<span class="comment-copy">In my case, it's a <code>dict_values</code> view.  <code>unique</code> also necessarily needs to maintain some intermediary structures somehow (I assume it uses a set).  If you didn't notice it, that's because your testing was flawed: setting <code>L = L*100000</code> means the data contains virtually 100% dupes.</span>
