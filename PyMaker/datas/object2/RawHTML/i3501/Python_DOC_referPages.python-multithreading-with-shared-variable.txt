<div class="post-text" itemprop="text">
<p>I'm trying to parallelise my job, but I'm new to multithreading, so feel confused about the concrete implementation.</p>
<p>I have a socket listener, that saves data to a buffer. When buffer reaches his capacity I need to save its data to database.
On one thread I want to start socket listener, while on parallel task I want to check the buffer status.</p>
<p><code>BufferQueue</code> is just an extension of a python <code>list</code>, with method that allow to check whether the list has reached the specified size.</p>
<p><code>SocketManager</code> is streaming data provider of a <code>STREAM_URL</code> I'm listening to. It use callback function to handle messages</p>
<p>But as I use callbacks to retrieve data I'm not sure that using shared variable is a right and optimal decision for that</p>
<pre><code>buffer = BufferQueue(buffer_size=10000)

def start_listening_to_sokcet(client):
    s = SocketManager(client)
    s.start_socket(cb_new)
    s.start()

def cb_new(message):
    print("New message")
    global buffer
    for m in message:
        #save data to buffer

def is_buffer_ready(buffer):
    global buffer
    print("Buffer state")
    if buffer.ready():
         #save buffer data to db
</code></pre>
<p>I'm appreciate if you can help me with this case</p>
</div>
<div class="post-text" itemprop="text">
<p>I think all you’re looking for is the <a href="https://docs.python.org/3.6/library/queue.html" rel="nofollow noreferrer"><code>queue</code></a> module. </p>
<p>A <code>queue.Queue</code> is a self-synchronized queue designed specifically for passing objects between threads.</p>
<p>By default, calling <code>get</code> on a queue will block until an object is available, which is what you usually want to do—the point of using threads for concurrency in a network app is that your threads all look like normal synchronous code, but spend most of their time waiting on a socket, a file, a queue, or whatever when they have nothing to do. But you can check without blocking by using <code>block=False</code>, or put a <code>timeout</code> on the wait.</p>
<p>You can also specify a <code>maxsize</code> when you construct the queue. Then, by default, <code>put</code> will block until the queue isn’t too full to accept the new object. But, again, you can use <code>block</code> or <code>timeout</code> to try and fail if it’s too full.</p>
<p>All synchronization is taken care of internally inside <code>get</code> and <code>put</code>, so you don’t need a <code>Lock</code> to guarantee thread safety or a <code>Condition</code> to signal waiters.</p>
<p>A queue can even take care of shutdown for you. The producer can just <code>put</code> a special value that tells the consumer to quit when it sees it on a <code>get</code>.</p>
<p>For graceful shutdown where the producer then needs to wait until the consumer has finished, you can use the optional <code>task_done</code> method after the consumer has finished processing each queued object, and have the producer block on the <code>join</code> method. But if you don’t need this—or or have another way to wait for shutdown, e.g., joining the consumer thread—you can skip this part.</p>
</div>
<div class="post-text" itemprop="text">
<p><strong>Multithreading</strong> gives you shared state of resources (variables). Instead of using globals, just pass in the buffer as an argument to your methods, and read/write from/to it.</p>
<p>You still need to control access to the buffer resource, so both threads are not reading/writing at the same time. You can achieve that using <code>Lock</code> from the <code>threading</code> module:</p>
<pre><code>lock = threading.Lock()

def cb_new(buffer_, lock_, message):
    print("New message")
    with lock_():
        for m in message:
            #save data to buffer
            buffer.add(m)

def is_buffer_ready(buffer_, lock_):
    print("Buffer state")
    with lock_():
        if buffer_.ready():
             #save buffer data to db
</code></pre>
<p>Note that in case you are working with <strong>multiprocessing</strong> instead of threads, this solution won't work.</p>
<p>By the way, as @abarnert commented, there are better mechanisms to check if the buffer is <em>ready</em> (has data to read / has free space to write) then calling a function that checks it. Check out <a href="https://docs.python.org/2/library/select.html" rel="nofollow noreferrer"><code>select.select()</code></a> which blocks you until the buffer is actually <em>ready</em>. </p>
<hr/>
<p>When working with select, you put the calls inside a <code>while True</code> loop, and then you check if the buffer is ready for reading. You can start this function in a thread, passing a flag variable and the buffer. If you want to stop the thread, change the flag you passed to False. For the buffer object, use <code>Queue.Queue()</code> or similar datastructure.</p>
<pre><code>def read_select(flag, buff):
    flag = 1
    while flag:
        r, _, _ = select.select([buff], [], [])
        if r:
            data = s.read(BUFFSIZE)
            # process data
</code></pre>
<p><strong>P.S</strong> - select also works with sockets. You can pass a socket object instead of a buffer, and it would check if the buffer on the socket is ready for read.</p>
</div>
<span class="comment-copy">You can use that shared buffer, but you need some way to control access to it so that only one thread at a time can modify it. Eg, you could use a <a href="https://docs.python.org/3/library/threading.html#threading.Lock" rel="nofollow noreferrer"><code>Lock</code></a>.</span>
<span class="comment-copy">Without knowing where these <code>BufferQueue</code>, <code>SocketManager</code>, etc. types come from, or at least what they do, it's pretty hard to offer anything that's not really vague. But I'd be wary of any API that used an <code>is_buffer_ready</code> function that the caller had to check periodically (or, worse, in a spin-loop); usually you're going to want something you can block on instead.</span>
<span class="comment-copy">If you can give us a <a href="https://stackoverflow.com/help/mcve">Minimal, Complete, and Verifiable example</a>, we can probably suggest more concrete ideas than "you probably want a Lock here" and "usually you want some way to block there"…</span>
<span class="comment-copy">@abarnert thanks for suggestion. I edited my question</span>
<span class="comment-copy">I guess you are right. <code>select.select()</code> looks very reasonable in that case. Could you give me a hint how to start</span>
<span class="comment-copy">I've added an example of how you would use it.</span>
<span class="comment-copy">I don’t think this is a good suggestion. You can’t <code>select</code> on a queue, and you don’t need to; you just block on the <code>get</code> call. And, while you can <code>select</code> on a socket, again, you don’t need to; you can just block on the <code>recv</code> call. The main point of <code>select</code> is that you can block on multiple sockets at the same time without needing a thread per socket. It’s an alternative to multithreading for network concurrency; you don’t need to use both.</span>
<span class="comment-copy">And you definitely don’t want to use <code>select</code> on top of a callback API. You might want to use it to <i>implement</i> that callback API, but again, that’s as an alternative to threads (and there are better alternatives, like <code>asyncio</code>, or a third party lib like Twisted). And, either way, once your callback has been called, either the data is ready to read or it’s already been read, so you don’t want to call <code>select</code> on anything.</span>
