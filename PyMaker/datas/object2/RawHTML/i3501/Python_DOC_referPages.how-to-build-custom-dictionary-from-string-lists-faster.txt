<div class="post-text" itemprop="text">
<h1>Background</h1>
<p>I want to create dictionary that each word has an unique id for word embedding purpose. The dataset looks like:</p>
<pre><code>s_lists = [['I', 'want', 'to', 'go', 'to', 'the', 'park'],
           ['I', 'want', 'to', 'quit', 'the', 'team']]
</code></pre>
<p>The following function is building a dictionary</p>
<pre><code>def build_dict(input_list, start=2):
    """
    build dictionary
    start with 2，1 for unknow word，0 for zero padding

    :param input_list:
    :param start:
    :return: custom dictionary
    """

    whole_set = set()
    for current_sub_list in input_list:
         # remove duplicate elements
        current_set = set(current_sub_list)
        # add new element into whole set
        whole_set = whole_set | current_set
    return {ni: indi + start for indi, ni in enumerate(whole_set)}
</code></pre>
<p>It works and output </p>
<pre><code>{'I': 7,'go': 2,'park': 4,'quit': 8, 'team': 6,'the': 5,'to': 9,'want': 3}
</code></pre>
<h1>Question</h1>
<p>When I use it for a large dataset (around 50w strings), it will cost around <strong>30s</strong> (ENV mbpr15-i7). It is <strong>too slow</strong> and I want to search a solution to improve the performance but i have no idea at the moment.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try the following code with <a href="https://docs.python.org/3/library/itertools.html#itertools.chain" rel="nofollow noreferrer"><code>itertools.chain</code></a>. In my test case it works about x4 faster:</p>
<pre><code>from itertools import chain

start = 2
{it: n + start for n, it in enumerate(set(chain(*s_lists)))}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>You can use <code>chain</code> and <code>count</code> from itertools</p>
<pre><code>&gt;&gt;&gt; from itertools import chain,count
&gt;&gt;&gt; 
&gt;&gt;&gt; dict(zip(set(chain(*s_lists)), count(2)))
{'team': 2, 'park': 3, 'want': 4, 'I': 5, 'the': 6, 'quit': 7, 'to': 8, 'go': 9}
&gt;&gt;&gt; 
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Try something like this,</p>
<pre><code>flatern_s_lists = [item for sub_item in s_lists for item in sub_item]
result = {j:i+2 for i,j in enumerate(set(flatern_s_lists))}
</code></pre>
<p>Making a list of lists to flatter this the best option in case of the speed of execution.</p>
<p>Result:    </p>
<pre><code>{'quit': 2, 'I': 3, 'park': 4, 'to': 5, 'want': 6, 'team': 7, 'go': 8, 'the': 9}
</code></pre>
</div>
<span class="comment-copy">Question has nothing to do with <code>machine-learning</code> - kindly do not spam the tag (removed)</span>
<span class="comment-copy">Awesome! it works for nearly x200 faster when feeding 50w dataset. Thanks a lot :)</span>
<span class="comment-copy">Yeah!, much better than mine but just a little bit slower than @Kopytok 's solution. More precisely it costs 0.2474s compared to 0.1053s (50w data). It's simple enough to understand by the way :)</span>
