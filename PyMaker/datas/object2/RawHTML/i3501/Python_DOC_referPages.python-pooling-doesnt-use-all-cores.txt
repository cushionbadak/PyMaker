<div class="post-text" itemprop="text">
<p>I'm using <code>Pool</code> from <code>multiprocessing</code> package (<code>from multiprocessing.dummy import Pool</code>).
I wrote a function that reads a text file and preprocessing it for a future function. 
I have about 20,000 such text files, thus I wanted to parallelize the process- and for this I used the pool. 
I have 32 cores on my remote server that is running the code, thus I tried to open 70 process (I also tried less, the problem remains) - this is how my system monitor looks like: </p>
<p><a href="https://i.stack.imgur.com/BO5cG.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/BO5cG.png"/></a> </p>
<p>As one can see, 16 out of 32 cores don't work at all!</p>
<p>Any help would be appreciated. </p>
</div>
<div class="post-text" itemprop="text">
<p>As I said in my comment, all <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow noreferrer"><code>multiprocessing.dummy</code></a> structures are intended to simulate the multiprocessing interface using regular threads which can be quite useful for testing, debugging, profiling etc. Or, as the official docs say:</p>
<blockquote>
<p><a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow noreferrer"><code>multiprocessing.dummy</code></a> replicates the API of <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing" rel="nofollow noreferrer"><code>multiprocessing</code></a> but is no more than a wrapper around the <a href="https://docs.python.org/3/library/threading.html#module-threading" rel="nofollow noreferrer"><code>threading</code></a> module.</p>
</blockquote>
<p>While Python (CPython) <a href="https://docs.python.org/3/library/threading.html#module-threading" rel="nofollow noreferrer"><code>threading</code></a> uses real system threads, and hence it is in theory possible to have your threaded code execute on different CPUs, due to the dreaded GIL no two of those threads will ever run simultaneously. There are exceptions to that rule, tho - all tasks that are abstracting system calls and wait for an event (like I/O) can execute in parallel but the moment processing moves to the Python domain it will be locked out by GIL and will not be allowed to continue execution until the opt-code counter switches its context.</p>
<p>Long story short, if you want to utilize multiple cores through a <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing" rel="nofollow noreferrer"><code>multiprocessing</code></a> pool, do not use the adaptations and abstractions in the <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow noreferrer"><code>multiprocessing.dummy</code></a> (that reigns true for other <code>dummy</code> packages, too) and use the root <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing" rel="nofollow noreferrer"><code>multiprocessing</code></a> module itself - in your case, <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool" rel="nofollow noreferrer"><code>multiprocessing.pool.Pool</code></a>. </p>
<p>That being said, given that the <a href="https://docs.python.org/3/library/threading.html#module-threading" rel="nofollow noreferrer"><code>threading</code></a> module doesn't come with a pool interface I often find myself using <code>multiprocessing.dummy.Pool</code> (or <code>multiprocessing.pool.ThreadPool</code>) instead for I/O heavy stuff (i.e. not restricted by the GIL) when shared memory is more important than <em>shared</em> processing and the overhead that it incurs. It's quite possible that even with a switch to <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool" rel="nofollow noreferrer"><code>multiprocessing.pool.Pool</code></a> you won't notice much of a difference if you don't do heavy post-processing when you grab the files.</p>
</div>
<span class="comment-copy">All packages under <code>multiprocessing.dummy</code> are intended to simulate the behavior of multiprocessing via multithreading, GIL and all that jazz included. Use the regular <code>multiprocessing.Pool</code>.</span>
<span class="comment-copy">There's also a decent chance the storage isn't fast enough to keep up with even a few of those cores. Unless they're all in RAM already, expect this to be an I/O bound task.</span>
<span class="comment-copy">are you sure this is a python related problem and not an os related one? there is nothing in multiprocessing that would stop a process from running on a specific core by default (although you can set affinities for it) and if you really do have 70 processes running it could mean its a problem with the os scheduling</span>
<span class="comment-copy">@zwer thanks!!! you can write it as an answer and I will happily accept it...</span>
