<div class="post-text" itemprop="text">
<p>I can't find any elegant way to select unique rows from column <code>A</code> and column <code>B</code> but not jointly and not in a sequence. This is in order to keep "inclusive" intersection of unique values from these two columns.</p>
<p>My aim is to keep as many unique values as possible across columns <code>A</code> and <code>B</code>. The columns are considered jointly but I am looking for all the unique "combinations" of their values...</p>
<p>Sample dataframe</p>
<pre><code>df1 = pd.DataFrame({"A": [ "A1", "A2", "A2", "A3", "A3", ],
                    "B": [ "B1", "B1", "B2", "B3", "B1", ], },
                   index=[ 0, 1, 2, 3, 4, ])
</code></pre>
<p>Result:</p>
<pre><code>    A   B
0  A1  B1
1  A2  B1
2  A2  B2
3  A3  B3
4  A3  B1
</code></pre>
<p>This does nothing useful...</p>
<pre><code>df2 = df1.drop_duplicates( subset=[ "A", "B", ], keep="first", inplace=False, )
</code></pre>
<p>Result:</p>
<pre><code>    A   B
0  A1  B1
1  A2  B1
2  A2  B2
3  A3  B3
4  A3  B1
</code></pre>
<p>The below code leaves duplicated <code>B1</code> which can be removed later using <code>drop_duplicates</code> on column <code>B</code> but then <code>A2</code> will also be removed and it could have been kept if it was present in one row with <code>B2</code>, as it was at the <code>index=2</code> of the original dataframe.</p>
<pre><code>df3 = df1.drop_duplicates( subset=[ "A", ], keep="first", inplace=False, )
</code></pre>
<p>Result:</p>
<pre><code>    A   B
0  A1  B1
1  A2  B1
3  A3  B3
</code></pre>
<p>As mentioned above <code>A2</code> is removed, but there was an option to keep it, if it was present in one row with <code>B2</code>, as it was at the <code>index=2</code> of the original dataframe.</p>
<pre><code>df4 = df3.drop_duplicates( subset=[ "B", ], keep="first", inplace=False, )

    A   B
0  A1  B1
3  A3  B3
</code></pre>
<p><strong>Desired result:</strong></p>
<pre><code>    A   B
0  A1  B1
1  A2  B2
2  A3  B3
</code></pre>
<p>So my aim is to keep as many unique values as possible across columns <code>A</code> and <code>B</code>. The columns are considered jointly but I am looking for all the unique "combinations" of their values...</p>
</div>
<div class="post-text" itemprop="text">
<p>Try Below Code:</p>
<pre><code>df1.drop_duplicates( subset=[ "A" and "B"], keep="first", inplace=False, )
</code></pre>
<p>Output:</p>
<pre><code>    A   B
0   A1  B1
2   A2  B2
3   A3  B3
</code></pre>
</div>
<span class="comment-copy">And what happens if you add one more row to your original DataFrame ['A3', 'B4']. Should this row also appear in your output? Right now, I can't tell if you are trying to get the maximum number of rows with entirely unique values, or the minimum  number of rows that capture all unique values.</span>
<span class="comment-copy">I don't mind if row <code>['A3', 'B4']</code> happens to appear in the output as I can filter it out in the next step by removing duplicates in the <code>A</code> column.   What I am after is to get <b>all</b> the values from the <code>A</code> column but only once (so this column contains only unique values) but paired with unique values from the <code>B</code> column.</span>
<span class="comment-copy">Now if I use <code>subset=[ "A", "B"]</code> then the output contains rows unique in both.  If I drop duplicates from the <code>A</code> column first and from the <code>B</code> column afterwards many unique values will be lost.  I would need to remove the duplicates from <code>A</code> column but in a way that saves as many values in the <code>B</code> column as possible and the other way around...</span>
<span class="comment-copy">possibly something with the use of <code>networkx.algorithms.matching.max_weight_matching</code> ?</span>
<span class="comment-copy">@Alex, you need the unique value of both of the column, right? then how you think that below code is not work for it?</span>
