<div class="post-text" itemprop="text">
<p>From <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map" rel="nofollow noreferrer">https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map</a></p>
<blockquote>
<p>If a func call raises an exception, then that exception will be raised
  when its value is retrieved from the iterator.</p>
</blockquote>
<p>The following snippet only outptus the first exeption (Exeption: 1), and stops. Does this contradict the above statement? I expect the following to print out all exceptions in the loop.</p>
<pre><code>def test_func(val):
  raise Exception(val)        

with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:   
  for r in executor.map(test_func,[1,2,3,4,5]):
    try:
      print r
    except Exception as exc:
      print 'generated an exception: %s' % (exc)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map" rel="nofollow noreferrer"><code>map</code></a> method returns a generator which allows to iterate through the results once ready.</p>
<p>Unfortunately, it is not possible to resume a generator after an exception occurs. From <a href="https://www.python.org/dev/peps/pep-0255/#specification-generators-and-exception-propagation" rel="nofollow noreferrer">PEP 255</a>.</p>
<blockquote>
<p>If an unhandled exception-- including, but not limited to, StopIteration --is raised by, or passes through, a generator function, then the exception is passed on to the caller in the usual way, and subsequent attempts to resume the generator function raise StopIteration. In other words, an unhandled exception terminates a generator's useful life.</p>
</blockquote>
<p>There are other libraries such as <a href="https://pypi.org/project/Pebble/" rel="nofollow noreferrer"><code>pebble</code></a> which allow to continue the iteration after an error occurs. Check the <a href="https://pebble.readthedocs.io/en/latest/#pools" rel="nofollow noreferrer">examples</a> in the documentation.</p>
</div>
<div class="post-text" itemprop="text">
<p>As mentioned above, unfortunately executor.map's API is limited and only lets you get the first exception. Also, when iterating through the results, you will only get values up to the first exception.</p>
<p>To answer your question, if you don't wan to use a different library, you can unroll your map and manually apply each function:</p>
<pre><code>future_list = []
with concurrent.futures.ThreadPoolExecutor() as executor:
  for arg in range(10):
    future = executor.submit(test_func, arg)
    future_list.append(future)

for future in future_list:
  try:
    print(future.result())
  except Exception as e:
    print(e)
</code></pre>
<p>This allows you to handle each future individually.</p>
</div>
<div class="post-text" itemprop="text">
<p>Ehsan's solution is good, but it may be slightly more efficient to take the results as the are completed instead of waiting for sequential items in the list to finish. Here is an example from the <a href="https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example" rel="nofollow noreferrer">library docs</a>.</p>
<pre><code>import concurrent.futures
import urllib.request

URLS = ['http://www.foxnews.com/',
        'http://www.cnn.com/',
        'http://europe.wsj.com/',
        'http://www.bbc.co.uk/',
        'http://some-made-up-domain.com/']

# Retrieve a single page and report the URL and contents
def load_url(url, timeout):
    with urllib.request.urlopen(url, timeout=timeout) as conn:
        return conn.read()

# We can use a with statement to ensure threads are cleaned up promptly
with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
    # Start the load operations and mark each future with its URL
    future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
    for future in concurrent.futures.as_completed(future_to_url):
        url = future_to_url[future]
        try:
            data = future.result()
        except Exception as exc:
            print('%r generated an exception: %s' % (url, exc))
        else:
            print('%r page is %d bytes' % (url, len(data)))
</code></pre>
</div>
<span class="comment-copy">related: <a href="https://stackoverflow.com/questions/33448329/how-to-detect-exceptions-in-concurrent-futures-in-python3" title="how to detect exceptions in concurrent futures in python3">stackoverflow.com/questions/33448329/â€¦</a></span>
<span class="comment-copy">thanks. Is pebble is common framework used in python for multithreading and multiprocessing? Isn't it redundant now that python has its own native concurrent.futures module ?</span>
<span class="comment-copy"><code>pebble</code> overcomes some limitation of Python's native library such as the above example and other issues like terminating timing out tasks.</span>
<span class="comment-copy">Doesn't concurrent.futures have options to do such things now ?</span>
<span class="comment-copy">No it doesn't. That's why <code>pebble</code> was designed. Another alternative library worth to check is <a href="https://github.com/celery/billiard" rel="nofollow noreferrer"><code>billiard</code></a>.</span>
