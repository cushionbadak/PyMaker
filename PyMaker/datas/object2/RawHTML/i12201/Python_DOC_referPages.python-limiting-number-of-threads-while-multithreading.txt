<div class="post-text" itemprop="text">
<p>Code below.</p>
<pre><code>            import sys
            import urllib2
            import threading
            import time

            urls = ["http://www.google.com", "http://www.apple.com"]

            def fetch_url(url):
                html = urllib2.urlopen(url).read()
                print html

            f = open("Output.txt", "w")
            e = open("ErrorUsers.txt", "w")

            threads = [threading.Thread(target=fetch_url, args=(url,)) for url in urls]
            for thread in threads:
                try:
                    thread.daemon = True
                    thread.start()
                except urllib2.HTTPError, e:
                    e.write(url + "\n")
                except urllib2.URLError, e:
                    e.write(url + "\n")
            for thread in threads:
                thread.join()
</code></pre>
<p>Essentially I need to grab data from a large number of sites (we're talking in the tens of thousands).
I'm using the above code as a base, which works great, however, the code freezes after the creation of 750 threads of so.
I'm wondering how to limit the number of active threads, or to like close a thread once it finishes.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use a thread pool like the one implemented in multiprocessing.In the following snippet, a maximum of 100 threads will be active any time.</p>
<pre><code>from multiprocessing.pool import ThreadPool

urls = ["http://www.google.com", "http://www.apple.com"]

def fetch_url(url):
    html = urllib2.urlopen(url).read()
    print html

pool = ThreadPool(100)
pool.map(fetch_url, urls)
pool.close()
pool.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<pre><code>            from multiprocessing.pool import ThreadPool
            import urllib2


            urls = ["http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com","http://www.google.com", "http://www.apple.com"]

            def fetch_url(url):
                html = urllib2.urlopen(url).read()
                print html[1:10]
                pool.TerminateProcess()

            pool = ThreadPool(100)
            pool.map(fetch_url, urls)
            pool.close()
            pool.join()
</code></pre>
</div>
<span class="comment-copy">Take a look at <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">docs.python.org/3/library/concurrent.futures.html</a></span>
<span class="comment-copy">I'm using Python 2.7, will that still apply?</span>
<span class="comment-copy"><a href="https://pypi.python.org/pypi/futures" rel="nofollow noreferrer">pypi.python.org/pypi/futures</a></span>
<span class="comment-copy">requests + futures will make your life better.</span>
<span class="comment-copy">Hey Walid, That doesn't seem to work either. I'm running the following code, which is the same as yours but there is like 200 URLS, and it will stop executing after 100 or so threads. Added code below so you can try.</span>
<span class="comment-copy">it doesn't stop, it's just uses 100 threads at a time, then when a threads finishes, it is reused with another url. your whole list will be processed at the end.</span>
<span class="comment-copy">why you put  pool.TerminateProcess()?</span>
<span class="comment-copy">@WalidSaad I tried to see if killing a process would make it work, but even without that, it still doesn't work for long lists of links?</span>
