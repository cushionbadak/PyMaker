<div class="post-text" itemprop="text">
<p>I read in <a href="https://stackoverflow.com/questions/472000/usage-of-slots">Usage of __slots__?</a> that using <code>__slots__</code> in Python can actually save time. But, when I tried to find the time taken using <code>datetime</code>, the results were contrary.</p>
<pre><code>import datetime as t

class A():
    def __init__(self,x,y):
        self.x = x
        self.y = y

t1 = t.datetime.now()
a = A(1,2)
t2 = t.datetime.now()
print(t2-t1)
</code></pre>
<p>... gave output: <code>0:00:00.000011</code>
And using slots:</p>
<pre><code>import datetime as t

class A():
    __slots__ = 'x','y'
    def __init__(self,x,y):
        self.x = x
        self.y = y

t1 = t.datetime.now()
a = A(1,2)
t2 = t.datetime.now()
print(t2-t1)
</code></pre>
<p>... gave output: <code>0:00:00.000021</code></p>
<p>Using slots actually took longer. Why do we need to use <code>__slots__</code> then?</p>
</div>
<div class="post-text" itemprop="text">
<ol>
<li>The article you quoted says using slots provides for faster
attribute <strong>access</strong> - you tested the time of object creation, and
never accessed attributes of your object.</li>
<li>Testing a single operation is not statistically meaningful - measure the times of, say, 100000 operations.</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p><code>__slots__</code> can save time (depends on Python version), but that's not usually what you use it for. What it really saves is memory. Instead of a <code>__dict__</code> of fairly large size for every instance, you store attributes directly in the C struct backing the object, and the class itself stores a single copy of the lookup table mapping from names to struct offsets for each attribute. Even on modern Py3 x64 with key-sharing dicts, it's still 96 bytes for a key-sharing <code>__dict__</code> where the class has a single instance attribute, on top of the 56 bytes for the object structure itself.</p>
<p>By using <code>__slots__</code>, you eliminate the 16 bytes for the pointers to the <code>__dict__</code> and <code>__weakref__</code> attributes, and eliminate the <code>__dict__</code> entirely.</p>
<p>For comparison on Py 3.5:</p>
<pre><code>&gt;&gt;&gt; class Foo:
...    def __init__(self, x): self.x = x
...
&gt;&gt;&gt; sys.getsizeof(Foo(1)) + sys.getsizeof(Foo(1).__dict__)
152
&gt;&gt;&gt; class Foo:
...    __slots__ = 'x',
...    def __init__(self, x): self.x = x
...
&gt;&gt;&gt; sys.getsizeof(Foo(1))  # With __slots__, doesn't have __dict__ at all
48
</code></pre>
<p>That's a savings of over 100 bytes per-instance; on Py2 (w/o key sharing dictionaries) the savings are even greater.</p>
<p>So it's not that <code>__slots__</code> is faster in general (it's usually pretty similar), but if you're making millions of instances, saving 100+ B per instance might help you keep your code in cache, in RAM, etc., rather than running out of memory and paging out half your data to swap.</p>
<p>As the other answer notes, you never actually accessed your attributes, so you weren't benchmarking slot access at all, which is why you saw no difference at all. Using <code>ipython3</code> <code>%%timeit</code> magic, I find that loading the <code>x</code> attribute of a given instance repeatedly is about 15% faster when it's slotted (33.5 ns with <code>__slots__</code> vs. 39.2 ns without), but that's only noticeable in microbenchmarks; it rarely matters in real code (where the actual work is doing a lot more than just attribute lookup). Reducing memory usage by a factor of 2-3x is a much bigger gain when it matters.</p>
</div>
<span class="comment-copy">I'd note that manually using <code>datetime</code> in this way isn't the recommended method for timing code. There's <a href="https://docs.python.org/3/library/timeit.html" rel="nofollow noreferrer">a module meant for timing code snippets</a>. And (as mentioned in an answer) you <i>must</i> repeat short operations many times to get anything approaching a meaningful result.</span>
