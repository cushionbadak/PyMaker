<div class="post-text" itemprop="text">
<p>I have below code where i am splitting a big text file into smaller one's and i am using generators to iterate over the file and then processing it. It is highly memory efficient compared to a lists version i wrote, but it suffers badly in terms of execution speed. Below is my code and i have figured it out why it takes more time but i am not getting a way to optimize it.</p>
<pre><code>def main():
    # file_name = input("Enter the full path of file you want to split into smaller inputFiles: ")
    file_name = "/rbhanot/Downloads/newtest.txt"
    input_file = open(file_name)
    num_lines_orig = sum(1 for _ in input_file)
    input_file.seek(0)
    # parts = int(input("Enter the number of parts you want to split in: "))
    parts = 3
    output_files = ((file_name + str(i)) for i in range(1, parts + 1))
    st = 0
    p = int(num_lines_orig / parts)
    ed = p
    for i in range(parts - 1):
        file = next(output_files)
        with open(file, "w") as OF:
            for _ in range(st, ed):
                OF.writelines(input_file.readline())

            st = ed
            ed = st + p
            if num_lines_orig - ed &lt; p:
                ed = st + (num_lines_orig - ed) + p
            else:
                ed = st + p

    file = next(output_files)
    with open(file, "w") as OF:
        for _ in range(st, ed):
            OF.writelines(input_file.readline())


if __name__ == "__main__":
    main()
</code></pre>
<p>The part that most of the time is below where it loops over the range and then there are two function calls for reading and writing the files.</p>
<pre><code>    for _ in range(st, ed):
        OF.writelines(input_file.readline())
</code></pre>
<p>Here is another version of same code using lists and apparently this works much faster</p>
<pre><code>def main():
    # file_name = input("Enter the full path of file you want to split into smaller inputFiles: ")
    file_name = "/rbhanot/Downloads/newtest.txt"
    input_file = open(file_name).readlines()
    num_lines_orig = len(input_file)
    # parts = int(input("Enter the number of parts you want to split in: "))
    parts = 3
    output_files = [(file_name + str(i)) for i in range(1, parts + 1)]
    st = 0
    p = int(num_lines_orig / parts)
    ed = p
    for i in range(parts - 1):
        with open(output_files[i], "w") as OF:
            OF.writelines(input_file[st:ed])
        st = ed
        ed = st + p

    with open(output_files[-1], "w") as OF:
        OF.writelines(input_file[st:])


if __name__ == "__main__":
    main()
</code></pre>
<p>I know i can improve the execution speed by some fraction if I make this code multi threaded since most of the stuff here is IO, but i want to know if there is any other way to do the same without threading the code.</p>
<p>Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>Your biggest bottleneck is file I/O. Reading from and writing to disk is <em>slow</em>.</p>
<p>You are, however, making matters a little worse by passing in single lines to the <code>file.writelines()</code> method. The latter expects an <em>iterable of lines</em> (the implementation effectively just iterates and calls <code>file.write()</code> for each element). Since a string is an iterable too giving you the individual characters, you are, in effect, writing single characters to the file buffer. Compared to file I/O, that's not <em>that</em> slow, but it is not efficient either. Don't use <code>file.writelines()</code> to write one line, just use <code>file.write()</code>.</p>
<p>Next, you are using repeated <code>file.readline()</code> calls. Don't use a method call for each line; you could use the file object as in iterator instead, and take a range of lines from it using <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice()</code></a> to pick limit how many lines are written. If you pass the <code>islice()</code> object to <code>file.writelines()</code> then that method would do the iteration:</p>
<pre><code>with open(file, "w") as OF:
    OF.writelines(islice(input_file, p))
</code></pre>
<p>The above writes <code>p</code> number of lines to the <code>OF</code> file object. Note that we don't need to track start and end numbers <em>at all</em> here! If you need to tack on the 'remaining' lines of the file to the end, you only need to read the remainder of the input file and copy whatever is there to the last output file. You can vastly simplify the code by just looping <code>parts</code> times and creating the file name in the loop:</p>
<pre><code>from itertools import islice
from shutil import copyfileobj

parts = int(input("Enter the number of parts you want to split in: "))

file_name = "/rbhanot/Downloads/newtest.txt"
with open(file_name) as input_file:
    num_lines_orig = sum(1 for _ in input_file)
    input_file.seek(0)

    chunk_size = num_lines_orig // parts

    for i in range(parts):
        output_file = f'{file_name}{i + 1}'
        with open(output_file, "w") as OF:
            OF.writelines(islice(input_file, chunk_size))

        if i == parts - 1:   # last iteration
            # copy across any remaining lines
            copyfileobj(input_file, OF)
</code></pre>
<p>I used the <a href="https://docs.python.org/3/library/shutil.html#shutil.copyfileobj" rel="nofollow noreferrer"><code>shutil.copyfileobj()</code> function</a> to handle the remainder copying; it'll read and write file data in blocks.</p>
</div>
<span class="comment-copy">Not really in-topic, but remember to close the files after you use them, or use <code>with open() as f:</code> and the file will be closed automatically.</span>
<span class="comment-copy">If you're writing the remaining portion of <code>input_file</code> to <code>OF</code>, <code>OF.write(input_file.read())</code> should be sufficient.  Unfortunately, I don't think multithreading is going to help, since only one thread would be able to write to the file at a time.</span>
<span class="comment-copy">For a generator, your code has a conspicious lack of <code>yeild</code>.</span>
<span class="comment-copy">@ivan_pozdeev , i am not creating a generator function but instead i am using generator to iterate over the file, rather than doing something like this <code>input_file = open(file_name).readlines()</code> which will read the file into a list and hog the memory.</span>
<span class="comment-copy">@Iv√°nC. yes i do understand that, i might have missed that, thanks for noticing and letting me know.</span>
<span class="comment-copy">Thanks much, i really learned some stuff from your answer. Much appreciated.</span>
