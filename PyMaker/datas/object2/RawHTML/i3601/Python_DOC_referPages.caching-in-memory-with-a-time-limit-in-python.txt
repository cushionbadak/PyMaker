<div class="post-text" itemprop="text">
<p>I have a function that returns a list, say list_x.</p>
<pre><code>def result(val):
    ..
    return(list_x)
</code></pre>
<p>I am calling result() every minute and storing the list.</p>
<pre><code>def other_func():
    #called every minute
    new_list = result(val)
</code></pre>
<p>I would like to store the value of new_list for an hour (in some sort of in-memory cache may be?) and then update it again, basically call results() after an hour and not every minute.I read about functools.lru_cache but that will not help here I think. Any ideas?</p>
</div>
<div class="post-text" itemprop="text">
<p>Building a single-element cache with a time-to-live is pretty trivial:</p>
<pre><code>_last_result_time = None
_last_result_value = None
def result(val):
    global _last_result_time
    global _last_result_value
    now = datetime.datetime.now()
    if not _last_result_time or now - _last_result_time &gt; datetime.timedelta(hours=1):
        _last_result_value = &lt;expensive computation here&gt;
        _last_result_time = now
    return _last_result_value
</code></pre>
<p>If you want to generalize this as a decorator, it's not much harder:</p>
<pre><code>def cache(ttl=datetime.timedelta(hours=1)):
    def wrap(func):
        time, value = None, None
        @functools.wraps(func)
        def wrapped(*args, **kw):
            nonlocal time
            nonlocal value
            now = datetime.datetime.now()
            if not time or now - time &gt; ttl:
                value = func(*args, **kw)
                time = now
            return value
        return wrapped
    return wrap
</code></pre>
<p>If you want it to handle different arguments, storing a time-to-live for each one:</p>
<pre><code>def cache(ttl=datetime.timedelta(hours=1)):
    def wrap(func):
        cache = {}
        @functools.wraps(func)
        def wrapped(*args, **kw):
            now = datetime.datetime.now()
            # see lru_cache for fancier alternatives
            key = tuple(args), frozenset(kw.items()) 
            if key not in cache or now - cache[key][0] &gt; ttl:
                value = func(*args, **kw)
                cache[key] = (now, value)
            return cache[key][1]
        return wrapped
    return wrap
</code></pre>
<p>You can of course key adding features to itâ€”give it a max size and evict by time of storage or by LRU or whatever else you want, expose cache stats as attributes on the decorated function, etc. The implementation of <a href="https://github.com/python/cpython/blob/3.6/Lib/functools.py#L448" rel="nofollow noreferrer"><code>lru_cache</code></a> in the stdlib should help show you how to do most of the trickier things (since it does almost all of them).</p>
</div>
<div class="post-text" itemprop="text">
<p>A decorator usually solves this nicely</p>
<pre><code>def cache(fn=None,time_to_live=3600*24): # one DAY default (or whatever)
    if not fn: return functools.partial(cache,time_to_live=time_to_live)
    my_cache = {}
    def _inner_fn(*args,**kwargs)
        kws = sorted(kwargs.items()) # in python3.6+ you dont need sorted
        key = tuple(args)+tuple(kw) 
        if key not in my_cache or time.time() &gt; my_cache[key]['expires']:
               my_cache[key] = {"value":fn(*args,**kwargs),"expires":time.time()+ time_to_live}
        return my_cache[key]
    return __inner_fn

@cache(time_to_live=3600) # an hour
def my_sqrt(x):
    return x**0.5

@cache(time_to_live=60*30) # 30 mins
def get_new_emails():
    return my_stmp.get_email_count()
</code></pre>
<p>as an aside this is built into memcache and that may be a better solution (im not sure what problem domain you are working in)</p>
<p>you can use nested functions also </p>
<pre><code>def cache(time_to_live=3600*24): # one DAY default (or whatever)
    def _wrap(fn):
        my_cache = {}
        def _inner_fn(*args,**kwargs)
            kws = sorted(kwargs.items()) # in python3.6+ you dont need sorted
            key = tuple(args)+tuple(kw) 
            if key not in my_cache or time.time() &gt; my_cache[key]['expires']:
                 my_cache[key] = {"value":fn(*args,**kwargs),"expires":time.time()+ time_to_live}
            return my_cache[key]
         return _inner_fn
    return _wrap
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Create a function that acts as a cache, we'll call it <code>result_cacher</code>.</p>
<pre><code>import time 
lastResultCache = 0 
resultCache = None
def result_cacher():
    if time.time() - lastResultCache &gt;= 3600: #Checks if 3600 sec (1 hour) has passed since the last cache 
        lastResultCache = time.time()
        resultCache = result()
    return resultCache 
</code></pre>
<p>This function checks if an hour has passed, updates the cache if it has, and then returns the cache.</p>
<p>If you want to apply the caching for each individual input instead of for whenever the function is called, use dictionaries for <code>lastResultCache</code> and <code>resultCache</code>.</p>
<pre><code>import time 
lastResultCache = {}
resultCache = {}
def result_cacher(val):
    #.get() gets value for key from dict, but if the key is not in the dict, it returns 0
    if time.time() - lastResultCache.get(val, 0) &gt;= 3600: #Checks if 3600 sec (1 hour) has passed since the last cache 
        lastResultCache[val] = time.time()
        resultCache[val] = result(val)
    return resultCache.get(val)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://cachetools.readthedocs.io/en/latest/#cachetools.func.ttl_cache" rel="nofollow noreferrer"><code>ttl_cache</code></a> decorator in <a href="https://pypi.org/project/cachetools" rel="nofollow noreferrer"><code>cachetools==3.1.0</code></a> works a lot like <a href="https://docs.python.org/3/library/functools.html#functools.lru_cache" rel="nofollow noreferrer"><code>functools.lru_cache</code></a>, but with a <a href="https://en.wikipedia.org/wiki/Time_to_live" rel="nofollow noreferrer">time to live</a>.</p>
<pre><code>import cachetools.func

@cachetools.func.ttl_cache(maxsize=128, ttl=10 * 60)
def target(key):
    return get_expensively_computed_value(key)
</code></pre>
</div>
<span class="comment-copy">If you're on a unix based system, I would recommend using <code>cron</code> to handle this.</span>
<span class="comment-copy">What's the reason for not liking <code>lru_cache</code>?  It's oriented around the number of calls rather than time duration, but that's not a huge difference.  If nothing else, you could look at the implementation of <code>lru_cache</code> for ideas on how to write your own.</span>
<span class="comment-copy">not on unix sadly @user</span>
<span class="comment-copy">@BowlingHawk95 looking for ideas if there is already something implemented along these lines rather than writing my own stuff</span>
<span class="comment-copy">@user2715898 google "python memoization decorator" hopefully you can take one of the existing solutions and understand it ... and figure out how you might add a timelimit</span>
<span class="comment-copy">this works fine assuming you don't want to cache multiple results for different arguments to the function.  Would highly recommend 1. turning this into a decorator to wrap around a function doing the computation and 2. turning that decorator into an instance of a class with a <code>__call__</code> implementation, so that way the statefulness of the cache is hidden inside a object's member variables rather than globals.</span>
<span class="comment-copy">@BowlingHawk95 Sure, I wrote the simplest version first because that's what the OP explicitly asked for.</span>
<span class="comment-copy">right, hence why I didn't downvote; just proposing improvements :) see Joran's answer above</span>
<span class="comment-copy">oooo fancy ... nonlocal (first time ive actually seen that ...thats cool) (also this doesnt really account for function args kwargs ... but im sure you know that and can easily extend it to (ie different args = different cache value)</span>
<span class="comment-copy">@BowlingHawk95 OK, I added first a decorator, then a version that handles args and kwargs if they're all hashable, then some comments on what other features you might want and how to find most of them in the <code>lru_cache</code> source, because I'm not going to keep going until I include every feature anyone might want.</span>
<span class="comment-copy">The recursive setup with <code>partial</code> is clever, but IMO uglier than just having another layer of closure.  You're now allowing <code>cache</code> to be called in two different ways: <code>cache(time_to_live=___)(function)</code> or <code>cache(function, time_to_live=___)</code>.  Just a matter of taste, though, and I like the solution.</span>
<span class="comment-copy">you sould only really call it as <code>@cache</code> or <code>@cache(time_to_live=1000)</code> ... but yeah you have a good point ... i dislike nesting functions ... and in general i like this as a solution so I always use it when accepting kwargs for a decorator (I <b>DISLIKE</b> <code>@cache(1000)</code> and want to not allow it)</span>
<span class="comment-copy">If you want to ban <code>@cache(1000)</code>, this doesn't do so nearly as clearly as making <code>time_to_live</code> a keyword-only parameter.</span>
<span class="comment-copy">but then you need a pyhton that supports that :P (which TBH they should have... but theres no guarantee or indication from the problem statement)</span>
<span class="comment-copy">@JoranBeasley I assumed you were writing for Python 3, because before 3.6+, <code>kwargs</code> is explicitly in arbitrary order, so you either want <code>tuple(sorted(kwargs.items()))</code> or <code>frozenset(kwargs.items())</code>. And also because it's not 2008 anymore.</span>
<span class="comment-copy">21600 is way more than an hour ;P</span>
<span class="comment-copy">Oops, fixed. Thanks!</span>
