<div class="post-text" itemprop="text">
<p>I am having problems with code in the following format and assume that the error is to do with how I am trying to access the elements in each tuple.</p>
<pre><code>from numberer import numberify
from sys import argv
infile=argv[1]
from multiprocessing import Pool
pool=Pool(15)
import os

def chunker(fob):
    chunkbegin=0
    filesize=os.stat(fob.name).st_size
    while chunkbegin &lt; filesize:
        chunkend=chunkbegin+100000
        fob.seek(chunkend)
        fob.readline()
        chunkend=fob.tell()
        yield (chunkbegin,chunkend)
        chunkbegin=chunkend

def run(tup, fob):
    fob.seek(tup[0])
    length=int(tup[1])-int(tup[0])
    lines=fob.readlines(length)
    for line in lines:
        print(line)

fob=open(infile)
chunks=[x for x in chunker(fob)]
pool.map(run, (chunks, fob))
</code></pre>
<p>The exact error is:</p>
<pre><code>Process ForkPoolWorker-1:
Traceback (most recent call last):
  File "/usr/lib/python3.6/multiprocessing/process.py", line 258, in _bootstrap
    self.run()
  File "/usr/lib/python3.6/multiprocessing/process.py", line 93, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/lib/python3.6/multiprocessing/pool.py", line 108, in worker
    task = get()
  File "/usr/lib/python3.6/multiprocessing/queues.py", line 337, in get
    return _ForkingPickler.loads(res)
AttributeError: Can't get attribute 'run' on &lt;module '__main__' from 'pretonumber.py'&gt;
</code></pre>
<p>1) So when map function maps the tuples to function; I assume that these elements should be called as if they are ordinary tuples? IE with one index?</p>
<p>2) The element chunks that I am passing to the function run: is a list of tuples:
chunks=[(0,100000),(100000,200000)....] as created by the generator chunker.</p>
<p>Thank you.</p>
</div>
<div class="post-text" itemprop="text">
<p>The <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map" rel="nofollow noreferrer"><code>map</code></a> method takes an iterable of argument. Each element of the iterable is passed to one instance of <code>run</code>. Since your iterable is the tuple <code>(chunks, fob)</code>, this is going to run two tasks, calling <code>run(chunks)</code> in one task, and <code>run(fob)</code> in another.</p>
<hr/>
<p>What I think you want to do is to run one task for each <code>chunk</code> in <code>chunks</code>, calling <code>run(chunk, fob)</code>.</p>
<p>So, first, you need an iterable that yields <code>(chunk, fob)</code> once per chunk, e.g., <code>((chunk, fob) for chunk in chunks)</code>.</p>
<hr/>
<p>But this still isn't going to work, because it's going to call <code>run</code> with a single argument, the 2-tuple <code>(chunk, fob)</code>, not with two arguments. You can fix this by rewriting or wrapping <code>run</code> to take a single 2-tuple instead of two separate arguments, or you can just use <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.starmap" rel="nofollow noreferrer"><code>starmap</code></a> instead of <code>map</code>, which does that wrapping for you.</p>
<hr/>
<p>But this still isn't going to work. You're trying to pass an open file object between processes, and <code>multiprocessing</code> can't do that. </p>
<p>Since you're using the <code>fork</code> method, you can sometimes get away with inheriting the file object from the parent rather than passing it, but the details are complicated, and you really need to read the <a href="https://docs.python.org/3/library/multiprocessing.html#programming-guidelines" rel="nofollow noreferrer">Programming guidelines</a> for <code>multiprocessing</code> and understand how file descriptor inheritance works on Unix.</p>
<p>Since you want each child to have its own independent copy of the file object so they can all <code>seek</code> around in it, the easiest solution is to just pass the filename and have them <code>open</code> it themselves:</p>
<pre><code>def run(tup, path):
    with open(path) as fob:
        fob.seek(tup[0])
        length=int(tup[1])-int(tup[0])
        lines=fob.readlines(length)
        for line in lines:
            print(line)

fob = open(infile)
chunks = [x for x in chunker(fob)]
args = ((chunk, infile) for chunk in chunks)
pool.starmap(run, args)
</code></pre>
<hr/>
<p>Meanwhile, now that we're sure we're not relying on <code>fork</code> behavior, it's probably a good idea to write the code to work with any start method. This means putting the top-level code into a <code>__main__</code> block. And, while we're at it, let's make sure we close the file once we're done with it:</p>
<pre><code># imports
# function definitions
if __name__ == '__main__':
    infile = argv[1]
    pool = Pool(15)
    with open(infile) as fob:
        chunks = [x for x in chunker(fob)]
    args = ((chunk, infile) for chunk in chunks)
    pool.starmap(run, args)
</code></pre>
<hr/>
<p>You may still have other errors in your code, but I think this exhausts the <code>multiprocessing</code> ones.</p>
</div>
<span class="comment-copy">wow im just going through this. but you sir/madam are a genius and at the speed of light too...</span>
<span class="comment-copy">perfect spot on. One other query I had was about how to return results to a globally shared list contributed to be each process.. e.g. is it best to simply declare globals and then append in each run.. or can mp not handle that?</span>
<span class="comment-copy">@LewisMacLachlan The ideal solution to that, when possible, is to just have the child tasks return the results, or pass them over a queue, and have the parent build up the list. If not, if you can use something lower-level than a list of arbitrary Python objects, like an array of ints or a complex numpy array or a ctypes structure, use the shared memory and a lock. If not, you usually use a Manager object, which is inefficient, but at least it’s dead easy to write (unless you run into the uncommon but not too rare subtle synchronization issues).</span>
<span class="comment-copy">@LewisMacLachlan If you read through the multiprocessing module docs (I know it’s huge, but the way it’s organized you pretty much have to read at least the first half straight through, then search the second half for relevant reference stuff, at least the first time…), it covers all of the options and the tradeoffs between them.</span>
