<div class="post-text" itemprop="text">
<p>Is there a way to read a .csv file that is compressed via gz into a dask dataframe?</p>
<p>I've tried it directly with</p>
<pre><code>import dask.dataframe as dd
df = dd.read_csv("Data.gz" )
</code></pre>
<p>but get an unicode error (probably because it is interpreting the compressed bytes) There is a <code>"compression"</code> parameter but <code>compression = "gz"</code> won't work and I can't find any documentation so far.</p>
<p>With pandas I can read the file directly without a problem other than the result blowing up my memory ;-) but if I restrict the number of lines it works fine.</p>
<pre><code>import pandas.Dataframe as pd
df = pd.read_csv("Data.gz", ncols=100)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>It's actually a long-standing limitation of <a href="https://github.com/dask/dask/issues/2554#issuecomment-333475231" rel="nofollow noreferrer">dask</a>. Load the files with <code>dask.delayed</code> <a href="https://github.com/dask/dask/issues/2554#issuecomment-317805727" rel="nofollow noreferrer">instead</a>:</p>
<pre><code>import pandas as pd
from dask.delayed import delayed

filenames = ...
dfs = [delayed(pd.read_csv)(fn) for fn in filenames]

df = dd.from_delayed(dfs) # df is a dask dataframe
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Panda's current documentation says:</p>
<blockquote>
<p>compression : {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}, default ‘infer’</p>
</blockquote>
<p>Since 'infer' is the default, that would explain why it is working with pandas.</p>
<p>Dask's documentation on the <em>compression</em> argument:</p>
<blockquote>
<p>String like ‘gzip’ or ‘xz’. Must support efficient random access. Filenames with extensions corresponding to known compression algorithms (gz, bz2) will be compressed accordingly automatically</p>
</blockquote>
<p>That would suggest that it should also infer the compression for at least <em>gz</em>. That it doesn't (and it still does not in 0.15.3) may be a bug. However, it is working using compression='gzip'.</p>
<p>i.e.:</p>
<pre><code>import dask.dataframe as dd
df = dd.read_csv("Data.gz", compression='gzip')
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Without the file it's difficult to say. what if you set the encoding <code>like # -*- coding: latin-1 -*-</code>? or since <code>read_csv</code> is based off of Pandas, you may even <code>dd.read_csv('Data.gz', encoding='utf-8')</code>. Here's the list of Python encodings: <a href="https://docs.python.org/3/library/codecs.html#standard-encodings" rel="nofollow">https://docs.python.org/3/library/codecs.html#standard-encodings</a></p>
</div>
<span class="comment-copy">Well, the regular pandas (non-dask) reads is fine without any encoding set, so my guess would be that dask tries to read the compressed gz file directly as an ascii file and gets non-sense.</span>
<span class="comment-copy">I believe the question was about a single gz (which works) not zip file (zip was mentioned as a limitation in the linked GitHub issue). Is there still any advantage using delayed in this case?</span>
<span class="comment-copy">Sorry, I missed that. I wanted to delete my answer but I couldn't because it's the accepted answer.</span>
<span class="comment-copy">well, good idea, but still get the error:     'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte. When I decompress the file on disk and read it it almost works but for complaints about NaN types</span>
<span class="comment-copy">@Magellan88: how about adding <code>error_bad_lines=False</code></span>
