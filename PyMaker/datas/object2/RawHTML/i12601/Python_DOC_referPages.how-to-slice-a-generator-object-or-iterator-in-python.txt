<div class="post-text" itemprop="text">
<p>I would like to loop over a "slice" of an iterator. I'm not sure if this is possible as I understand that it is not possible to slice an iterator. What I would like to do is this:</p>
<pre><code>def f():
    for i in range(100):
        yield(i)
x = f()

for i in x[95:]:
    print(i)
</code></pre>
<p>This of course fails with:</p>
<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-37-15f166d16ed2&gt; in &lt;module&gt;()
  4 x = f()
  5 
----&gt; 6 for i in x[95:]:
  7     print(i)

TypeError: 'generator' object is not subscriptable
</code></pre>
<p>Is there a pythonic way to loop through a "slice" of a generator? </p>
<p>Basically the generator I'm actually concerned with reads a very large file and performs some operations on it line by line. I would like to test slices of the file to make sure that things are performing as expected, but it is very time consuming to let it run over the entire file. </p>
<p>Edit:<br/>
As mentioned I need to to this on a file. I was hoping that there was a way of specifying this explicitly with the generator for instance:</p>
<pre><code>import skbio

f = 'seqs.fna'
seqs = skbio.io.read(f, format='fasta')
</code></pre>
<p>seqs is a generator object</p>
<pre><code>for seq in itertools.islice(seqs, 30516420, 30516432):
    #do a bunch of stuff here
    pass
</code></pre>
<p>The above code does what I need, however is still very slow as the generator still loops through the all of the lines. I was hoping to only loop over the specified slice</p>
</div>
<div class="post-text" itemprop="text">
<p>In general, the <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="noreferrer">answer is <code>itertools.islice</code></a>, but you should note that <code>islice</code> doesn't, and can't, actually skip values. It just grabs and throws away <code>start</code> values before it starts <code>yield</code>-ing values. So it's usually best to avoid <code>islice</code> if possible when you need to skip a lot of values and/or the values being skipped are expensive to acquire/compute. If you can find a way to not generate the values in the first place, do so. In your (obviously contrived) example, you'd just adjust the start index for the <code>range</code> object.</p>
<p>In the specific cases of trying to run on a file object, pulling a huge number of lines (particularly reading from a slow medium) may not be ideal. Assuming you don't need specific lines, one trick you can use to avoid actually reading huge blocks of the file, while still testing some distance in to the file, is the <code>seek</code> to a guessed offset, read out to the end of the line (to discard the partial line you probably seeked to the middle of), then <code>islice</code> off however many lines you want from that point. For example:</p>
<pre><code>import itertools

with open('myhugefile') as f:
    # Assuming roughly 80 characters per line, this seeks to somewhere roughly
    # around the 100,000th line without reading in the data preceding it
    f.seek(80 * 100000)
    next(f)  # Throw away the partial line you probably landed in the middle of
    for line in itertools.islice(f, 100):  # Process 100 lines
        # Do stuff with each line
</code></pre>
<p>For the specific case of files, you might also want to look at <a href="https://docs.python.org/3/library/mmap.html" rel="noreferrer"><code>mmap</code></a> which can be used in similar ways (and is unusually useful if you're processing blocks of data rather than lines of text, possibly randomly jumping around as you go).</p>
<p><strong>Update:</strong> From your updated question, you'll need to look at your API docs and/or data format to figure out exactly how to skip around properly. It looks like <a href="http://scikit-bio.org/docs/0.4.0/generated/skbio.io.format.fasta.html#module-skbio.io.format.fasta" rel="noreferrer"><code>skbio</code> offers some features for skipping using <code>seq_num</code>, but that's still going to read if not process most of the file</a>. If the data was written out with equal sequence lengths, I'd look at the docs on <code>Alignment</code>; aligned data may be loadable without processing the preceding data at all, by e.g <a href="http://scikit-bio.org/docs/0.4.0/generated/skbio.alignment.Alignment.subalignment.html#skbio.alignment.Alignment.subalignment" rel="noreferrer">by using <code>Alignment.subalignment</code> to create new <code>Alignment</code>s that skip the rest of the data for you</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can't slice a generator object or iterator using  a normal <a href="https://stackoverflow.com/questions/509211/explain-pythons-slice-notation">slice operations</a>. 
Instead you need to use  <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice</code></a> as @jonrsharpe already mentioned in his <a href="https://stackoverflow.com/questions/34732311/loop-over-slice-in-generator#comment57211083_34732311">comment</a>.</p>
<pre><code>import iterator    

for i in iterator.islice(x, 95)
    print(i)
</code></pre>
<p>Also  note that <code>islice</code> returns an iterator and consume data on the iterator or generator. So you will need to convert you data to list or create a new generator object if you need to go back and do something or use the little known <a href="https://docs.python.org/3/library/itertools.html#itertools.tee" rel="nofollow noreferrer"><code>itertools.tee</code></a> to create a <em>copy</em> of your generator.</p>
<pre><code>from iterator import tee


first, second = tee(f())
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>islice is the pythonic way</p>
<pre><code>from itertools import islice    

g = (i for i in range(100))

for num in islice(g, 95, None):
    print num
</code></pre>
</div>
<span class="comment-copy">I don't understand your question... If your generator takes a file as an input, then to test it, pass it slices of that file, why do you want to "slice the generator"?</span>
<span class="comment-copy">Have you looked into <a href="https://docs.python.org/3/library/itertools.html#itertools.islice" rel="nofollow noreferrer"><code>itertools.islice</code></a>?</span>
<span class="comment-copy">Note that <code>islice</code>-ing the generator won't stop it from going through the lines before the ones you care about and processing them. It'd be better to provide it with an <code>islice</code> of the file. (You'll still need to read the file to look for newlines, but you'll skip whatever processing the generator does on the unwanted lines.)</span>
<span class="comment-copy">In an unstructured, unindexed file, is there any way of getting the (exactly) 100,000th line without ripping through the entire thing?</span>
<span class="comment-copy">@NickT: Nope. Modules like <a href="https://docs.python.org/3/library/linecache.html" rel="nofollow noreferrer"><code>linecache</code></a> will let you pretend like you have random access, but it's still "ripping through" the whole thing; there is no meaningful way to find where the line breaks are without reading through to find them. <code>mmap</code>-ing a file and using <code>mmap.find</code> or <code>mmap.rfind</code> repeatedly could find lines relative to the start or end of a file without storing any lines in memory, but it's still reading the file.</span>
<span class="comment-copy">@NickT: I've previously <a href="http://stackoverflow.com/a/34029605/364696">posted an answer for using <code>mmap</code> to read the last X lines of a large file without slurping the whole thing</a>; that's the closest you'll get. You need to read from one end of the file or the other, you can't leap to a given line without reading to figure out where that specific line is unless the lines are of fixed length.</span>
<span class="comment-copy">Note: <code>itertools.tee</code> is storing a copy of every output produced by the furthest advanced <code>tee</code>-ed copy, and can't discard any of those values until the least advanced iterator produces it. So a use of <code>tee</code> in which one <code>tee</code>-ed iterator is exhausted before you read the second one would usually be handled better by just <code>list</code>-ifying the original generator, then iterating it multiple times.</span>
<span class="comment-copy">@ShadowRanger Do you mean by iterating the original the copy is also consumed? Can you please elaborate?  <code>list</code>-ifying the original generator means load all the data in memory.</span>
<span class="comment-copy">I never said anything about iterating the original consuming the copy; not sure what you mean by that? Basically, if you do <code>x, y = tee(some_generator_making_numbers)</code>, then do <code>sum(x)</code>, then all the values of <code>some_generator_making_numbers</code> are stored internally in the <code>tee</code> shared data until you drain them from <code>y</code> as well; if you don't iterate all outputs of <code>tee</code> roughly in parallel, then you aren't likely to be reducing memory overhead over just <code>list</code>-ifying with <code>somelist = list(some_generator_making_numbers)</code> then iterating <code>somelist</code> as many times as you want.</span>
<span class="comment-copy">Point is, <code>tee</code> isn't actually copying the generator. It's making new generators based on a single shared cache, where the first generator to request item X causes the shared cache to pull the value from the original generator, and the last generator to request item X releases that value from the cache. But if the first <code>tee</code> generator runs to exhaustion before the second even pulls a single value, then the shared cache contains every value from the original generator (memory required is roughly equivalent to having stored all the values in a <code>list</code>).</span>
<span class="comment-copy">This is actually part of the <a href="https://docs.python.org/3/library/itertools.html#itertools.tee" rel="nofollow noreferrer"><code>tee</code> documentation</a>: "This itertool may require significant auxiliary storage (depending on how much temporary data needs to be stored). In general, if one iterator uses most or all of the data before another iterator starts, it is faster to use list() instead of tee()."</span>
