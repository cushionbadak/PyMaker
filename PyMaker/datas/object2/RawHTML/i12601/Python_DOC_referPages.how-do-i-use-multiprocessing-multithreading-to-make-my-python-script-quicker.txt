<div class="post-text" itemprop="text">
<p>I am fairly new to Python and programming in general. I have written a script to go through a long list (~7000) of URLs and check their status to find any broken links. Predictably, this takes a few hours to request each URL one by one. I have heard that multiprocessing (or multithreading?) can be used to speed things up. What is the best approach to this? How many processes/threads should I run in one go? Do I have to create batches of URLs to check concurrently?</p>
</div>
<div class="post-text" itemprop="text">
<p>The answer to the question depends on whether the process spends most of its time processing data or waiting for the network. If it is the former, then you need to use <a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow">multiprocessing</a>, and spawn about as many processes as you have physical cores on the system. Do not forget to make sure that you choose the appropriate algorithm for the task. Finally, if all else fails, coding <a href="https://docs.python.org/2/extending/" rel="nofollow">parts of the program in C</a> can be a viable solution as well.</p>
<p>If your program is slow because it spends a lot of time waiting for individual server responses, you can parallelize network access using <a href="https://docs.python.org/2/library/threading.html" rel="nofollow">threads</a> or an <a href="https://docs.python.org/3/library/asyncio.html" rel="nofollow">asynchronous IO framework</a>. In this case you can use many more threads than you have physical processor cores because most of the time your cores will be sleeping waiting for something interesting to happen. You will need to measure the results on your machine to find out the best number of threads that works for you.</p>
<p>Whatever you do, please make sure that your program is not hammering the remote servers with a large number of concurrent or repeated requests.</p>
</div>
<span class="comment-copy">This is a very broad question. Would take a small book to answer. I suggest first you read a little on multithreading in python docs and come back to us with more specific question.</span>
<span class="comment-copy">The documentation for <a href="https://docs.python.org/dev/library/multiprocessing.html" rel="nofollow noreferrer">multiprocessing</a> comes with a few helpful examples</span>
<span class="comment-copy">I was hoping that someone here could explain the basics as the documentation for most libraries is very daunting to newbies.</span>
<span class="comment-copy">@Abbie This is not how StackOverflow works. One is expected to ask a concrete question in order to get well-supported answers. Explaining the "basics" of an unspecified library is appropriate for sites dedicated to documenting those libraries, not a Q&amp;A site.</span>
<span class="comment-copy">Note: If you write your code assuming you'll use the <code>multiprocessing</code> module (and make your workers aren't taking dependencies on shared data), you can easily switch your code from processes to threads by changing <code>import multiprocessing</code> to <code>import multiprocessing.dummy as multiprocessing</code>. <code>multiprocessing.dummy</code> is the <code>multiprocessing</code> API implemented using threads instead of processes, so you can use stuff like <code>multiprocessing.Pool</code> and it will seamlessly use threads instead. Useful for comparing processes to threads.</span>
