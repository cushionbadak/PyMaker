<div class="post-text" itemprop="text">
<p>Suppose I have a class, And want to read few files from the disk in parallel, and parameterize class parameters. What is the most correct way to do it (and how)? </p>
<ul>
<li>Main thread should wait for load_data() action to be over, before anything else is happening.</li>
</ul>
<p>I thought about threading since it's only I/O actions. </p>
<p>Example of non-parallel implementation (1-Threading):</p>
<pre><code>import pandas as pd


class DataManager(object):
    def __init__(self):
        self.a = None
        self.b = None
        self.c = None
        self.d = None
        self.e = None
        self.f = None

    def load_data(self):
        self.a = pd.read_csv('a.csv')
        self.b = pd.read_csv('b.csv')
        self.c = pd.read_csv('c.csv')
        self.d = pd.read_csv('d.csv')
        self.e = pd.read_csv('e.csv')
        self.f = pd.read_csv('f.csv')

if __name__ == '__main__':
    dm = DataManager()
    dm.load_data()
    # Main thread is waiting for load_data to finish.
    print("finished loading data")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>I/O operations are not CPU bounded in most cases so using multiple processes is an overkill. Using multiple threads can be good, but <code>pb.read_csv</code> not only reads the file but parses it what can be CPU bounded. I suggest you to read files from disk with asyncio as soon as it was initially made for this purpose. Here is the code to do so:</p>
<pre><code>import asyncio
import aiofiles


async def read_file(file_name):
    async with aiofiles.open(file_name, mode='rb') as f:
        return await f.read()


def read_files_async(file_names: list) -&gt; list:
    loop = asyncio.get_event_loop()
    return loop.run_until_complete(
        asyncio.gather(*[read_file(file_name) for file_name in file_names]))


if __name__ == '__main__':
    contents = read_files_async([f'files/file_{i}.csv' for i in range(10)])
    print(contents)
</code></pre>
<p>The function <code>read_files_async</code> returns the list of file contents (byte buffers), which you can pass to <code>pd.read_csv</code>.</p>
<p>I think optimization of files reading only should be enough but you can parse files contents in parallel with multiple processes (threads and async won't increase performance of parsing process):</p>
<pre><code>import multiprocessing as mp

NUMBER_OF_CORES = 4
pool = mp.Pool(NUMBER_OF_CORES)
pool.map(pb.read_csv, contents)
</code></pre>
<p>You should set <code>NUMBER_OF_CORES</code> according to your machine spec.</p>
</div>
<div class="post-text" itemprop="text">
<p>Possible solution with Python3 <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="nofollow noreferrer">ThreadPoolExecutor</a></p>
<pre><code>    from concurrent.futures import ThreadPoolExecutor
    import queue
    import pandas as pd

    def load_data_worker(data_queue, file_name):
        data_queue.put(pd.read_csv(file_name))

    class DataManager(object):
        def __init__(self):
            self.data_queue = queue.Queue()
            self.data_arr = []

        def load_data(self):
            with ThreadPoolExecutor() as executor:
                executor.submit(load_data_woker, self.data_queue, 'a.csv')
                executor.submit(load_data_woker, self.data_queue, 'b.csv')
                # ... 
                executor.submit(load_data_woker, self.data_queue, 'f.csv')
           # dumping Queue of loaded data to array 
           self.data_arr = list(self.data_queue.queue)



    if __name__ == '__main__':
        dm = DataManager()
        dm.load_data()
        # Main thread is waiting for load_data to finish.
        print("finished loading data")
</code></pre>
</div>
<span class="comment-copy">Thanks to the <code>with</code> clause, the 'Main' thread won't proceed until <code>load_data()</code> is finished ?</span>
<span class="comment-copy">@EranMoshe Indeed, <code>with ThreadPoolExecutor() as executor</code> is blocking</span>
<span class="comment-copy">with <code>executor.submit(load_data_woker, self.a, 'a.csv')</code>, <code>self.a</code> (and all self. vars) doesn't get parameterized.</span>
<span class="comment-copy">@EranMoshe Fixed, we should use queue if we want to get processed data from workers</span>
<span class="comment-copy">And only got knows the order of the data frames in the data_arr ...</span>
