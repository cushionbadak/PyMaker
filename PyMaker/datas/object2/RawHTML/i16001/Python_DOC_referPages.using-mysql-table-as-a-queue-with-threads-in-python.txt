<div class="post-text" itemprop="text">
<p>I have a DB with a <code>queue</code> table, new entries are inserted continuously in the queue.</p>
<p>I want a Python script to execute the queue as fast as possible, and I think I need some threaded code to do so, running like a daemon.</p>
<p>But I can't figure out how to use the DB as the queue.</p>
<p>I am looking at this example:</p>
<pre><code>import MySQLdb
from Queue import Queue
from threading import Thread

def do_stuff(q):
    while True:
        print q.get()
        q.task_done()

q = Queue(maxsize=0)
num_threads = 10

for i in range(num_threads):
    worker = Thread(target=do_stuff, args=(q,))
    worker.setDaemon(True)
    worker.start()

// TODO:  Use the DB
db = MySQLdb.connect(...)
cursor = db.cursor()
q = cursor.execute("SELECT * FROM queue")

for x in range(100):
    q.put(x)
q.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>2 quick points :</p>
<ol>
<li><p>Assuming you are using cPython, The <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow"><strong>GIL</strong></a> will effectively
render threading useless, allowing only 1 thread through the
interpreter at one time. Couple of workarounds are :</p>
<ul>
<li><p>The <code>Gevent</code> library <a href="http://www.gevent.org/" rel="nofollow">[<strong>source</strong>]</a></p>
<blockquote>
<p>gevent is a coroutine-based Python networking library that uses
  greenlet to provide a high-level synchronous API on top of the libev
  event loop.</p>
</blockquote></li>
<li><p>The <code>multiprocessing</code> module, you can spawn multiple processes - this is true concurrency in python.</p></li>
<li><p>The <code>concurrent.futures</code> module - new in python 3, port available for
python 2. <a href="https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures" rel="nofollow"><strong>[source]</strong></a></p>
<blockquote>
<p>This is a new high-level library that operates only at a “job” level, which means that you no longer have to fuss with<br/>
  synchronization, or managing threads or processes. you just specify a
  thread or process pool with a certain number of “workers,” submit<br/>
  jobs, and collate the results. It’s new in Python 3.2, but a port for
  Python 2.6+ is available at <a href="http://code.google.com/p/pythonfutures" rel="nofollow">http://code.google.com/p/pythonfutures</a>.</p>
</blockquote></li>
</ul></li>
</ol>
<p>You can use the <code>SSDictCursor()</code> of MySQLdb and do a fetchone().This is a streaming cursor and you can run this in an infinite while() loop to resemble a queue:</p>
<blockquote>
<pre><code>cur = MySQLdb.cursors.SSDictCursor()

cur.execute(query)

while True:

row = cursor.fetchone()

if not row : break # (or sleep()!)

else: # other
</code></pre>
</blockquote>
<ol start="2">
<li>Having said all that, I would suggest you look at implementing tools like <code>celery</code> or <code>mongodb</code> to emulate queues and workers. Relational databases are just not cut out for that kind of a job and suffer unnecessary fragmentation. <a href="http://www.databasejournal.com/features/mysql/article.php/3927871/MySQL-Data-Fragmentation---What-When-and-How.htm" rel="nofollow">Here's</a> a great source if you want to know more about fragmentation in mysql.</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>I am not sure if its the best solution but I think of a structure of a main-thread which reads the db and fill the Queue. Make sure to avoid doublets. Maybe by using primary key of increasing numbers would be easy to check.</p>
<p>The Worker-Structure is nice, but like mentioned in comments: the GIL will avoid any boost. But you could use multiprocessing if your "do_stuff" is independent from the script himself (f.e. the tasks are pictures and the "do_stuff" is "rotate ervery picture 90°"). Afaik it doesn't suffer from GIL</p>
<p><a href="https://docs.python.org/2/library/subprocess.html" rel="nofollow">https://docs.python.org/2/library/subprocess.html</a> get you some informations about that.</p>
<p>PS: English isn't my native language.</p>
</div>
<span class="comment-copy">I can't understand what you are trying to do with the db. Anyway Python has GIL, that means that most likely you will get zero performance boost for parallelising this operation.</span>
<span class="comment-copy"><code>gevent</code> doesn't allow you to bypass the GIL, and neither does <code>concurrent.futures.ThreadPoolExecutor</code>. Only <code>multiprocessing</code> and <code>concurrent.futures.ProcessPoolExecutor</code> do that. Note that threads and <code>gevent</code> are still useful for I/O bound operations, because doing I/O releases the GIL.</span>
<span class="comment-copy">Thats correct. Its only by spawning multiple processes that will we be able to achieve true concurrency here. However, many times, what we are trying to achieve by concurrency is actually asynchronous processing ,and gevent fits in beautifully there.</span>
<span class="comment-copy">I think the <code>multiprocessing</code> module will be more relevant than <code>subprocess</code> in this case.</span>
