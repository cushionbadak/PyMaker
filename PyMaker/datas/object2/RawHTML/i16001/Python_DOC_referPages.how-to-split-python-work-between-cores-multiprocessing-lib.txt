<div class="post-text" itemprop="text">
<p>I have a sequential function that sorts through lists and performs tasks. For example... (this is not the actual code but is analagous)</p>
<pre><code>def myFunction(list):
   for item in list:
      sublist_a=item[0]
      sublist_b=item[1]
      sublist_c=item[2]
      sublist_d=item[3]
   for row in sublist_a:
      #(do tasks....)
   for row in sublist_b:
      #(do tasks....)
   for row in sublist_c:
      #(do tasks....)
   for row in sublist_d:
      #(do tasks....)
   print "COMPLETE"
</code></pre>
<p>So this is overly simplified, but essentially these lists are quire large, and the order of execution is important (ie. <code>for row in ....</code>), so I would like to split them between the available cores on my system.</p>
<p>Could someone please suggest a method for doing so?</p>
<p>Have never used the Multiprocessing library but it seems this is probably the best to use with python.</p>
</div>
<div class="post-text" itemprop="text">
<p>You are looking for a <a href="https://docs.python.org/3/library/multiprocessing.html#using-a-pool-of-workers" rel="nofollow"><code>multiprocessing.Pool</code></a></p>
<pre><code>from multiprocessing import Pool

def function_to_process_a(row):
    return row * 42 # or something similar

# replace 4 by the number of cores that you want to utilize
with Pool(processes=4) as pool:
    # The lists are processed one after another,
    # but the items are processed in parallel.
    processed_sublist_a = pool.map(function_to_process_a, sublist_a)
    processed_sublist_b = pool.map(function_to_process_b, sublist_b)
    processed_sublist_c = pool.map(function_to_process_c, sublist_c)
    processed_sublist_d = pool.map(function_to_process_d, sublist_d)
</code></pre>
<p>Edit: As sidewaiise pointed out in the comments, it is preferable to use this pattern:</p>
<pre><code>from contextlib import closing, cpu_count, Pool

with closing(Pool(processes=cpu_count())) as pool
    pass # do something
</code></pre>
</div>
<span class="comment-copy">"the order of execution is important", as in "needs to be done sequentially", as in "cannot be split between cores"?</span>
<span class="comment-copy">some of the work can be split - for example, I think you could split the work for each of the <code>for</code> loops. But the loops would need to be executed one after the other.</span>
<span class="comment-copy">@sidewaiise What are you doing to each <code>row</code>? It seems that's the only piece that can actually be parallelized, right?</span>
<span class="comment-copy">@dano Yes this is true. Each loop simply cleans the list data in different ways. how do I parallelize it though? do I need to turn each of these loops into functions that utilize the <code>multiprocessing</code> lib?</span>
<span class="comment-copy">Kay thanks, I'll implement this method and see how she runs.</span>
<span class="comment-copy">Actually Kay, Just to confirm, is sublist_a, sublist_b etc. inputs? Eg. similar to calling a <code>function_to_process_a(sublist_a)</code>?</span>
<span class="comment-copy"><code>sublist_a</code> should be iterable. <code>function_to_process_a</code> gets a single row as argument, just like the ordinary <a href="https://docs.python.org/3/library/functions.html#map" rel="nofollow noreferrer"><code>map(function, iterable)</code></a>.</span>
<span class="comment-copy">Ok great. Now I get <code>AttributeError: __exit__</code>. Any ideas why this would happen?</span>
<span class="comment-copy">had to use <code>from contextlib import closing</code>, then <code>while closing(Pool(processes=multiprocessing.cpu_count())) as pool</code>. Thanks, your answer basically answered the question.</span>
