<div class="post-text" itemprop="text">
<p>I have been working with the <code>multiprocessing</code> package to speed up some geoprocessing (GIS/<code>arcpy</code>) tasks that are redundant and need to be done the same for more than 2,000 similar geometries.</p>
<p>The splitting up works well, but my "worker" function is rather long and complicated because the task itself from start to finish is complicated. I would love to break the steps apart down more but I am having trouble passing information to/from the worker function because for some reason ANYTHING that a worker function under multiprocessing uses needs to be passed in explicitly. </p>
<p>This means I cannot define constants in the body of <code>if __name__ == '__main__'</code> and then use them in the worker function. It also means that my parameter list for the worker function is getting really long - which is super ugly since trying to use more than one parameter also requires creating a helper "star" function and then <code>itertools</code> to rezip them back up (a la the second answer on <a href="https://stackoverflow.com/questions/5442910/python-multiprocessing-pool-map-for-multiple-arguments">this question</a>). </p>
<p>I have created a trivial example below that demonstrates what I am talking about. Are there any workarounds for this - a different approach I should be using - or can someone at least explain <strong>why</strong> this is the way it is?</p>
<p>Note: I am running this on Windows Server 2008 R2 Enterprise x64. </p>
<p><strong>Edit:</strong> I seem to have not made my question clear enough. I am not that concerned with how <code>pool.map</code> only takes one argument (although it is annoying) but rather I do not understand why the scope of a function defined outside of <code>if __name__ == '__main__'</code> cannot access things defined inside that block <em>if it is used as a multiprocessing function</em> - unless you explicitly pass it as an argument, which is obnoxious. </p>
<pre><code>import os
import multiprocessing
import itertools

def loop_function(word):
    file_name = os.path.join(root_dir, word + '.txt')
    with open(file_name, "w") as text_file:
        text_file.write(word + " food")

def nonloop_function(word, root_dir): # &lt;------ PROBLEM
    file_name = os.path.join(root_dir, word + '.txt')
    with open(file_name, "w") as text_file:
        text_file.write(word + " food")

def nonloop_star(arg_package):
     return nonloop_function(*arg_package)

# Serial version
#
# if __name__ == '__main__':
# root_dir = 'C:\\hbrowning'
# word_list = ['dog', 'cat', 'llama', 'yeti', 'parakeet', 'dolphin']
# for word in word_list:
#     loop_function(word)
#
## --------------------------------------------

# Multiprocessing version
if __name__ == '__main__':
    root_dir = 'C:\\hbrowning'
    word_list = ['dog', 'cat', 'llama', 'yeti', 'parakeet', 'dolphin']
    NUM_CORES = 2
    pool = multiprocessing.Pool(NUM_CORES, maxtasksperchild=1)

    results = pool.map(nonloop_star, itertools.izip(word_list, itertools.repeat(root_dir)),
                   chunksize=1)
    pool.close()
    pool.join()
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The problem is, at least on Windows (although there are similar caveats with *nix <code>fork</code> style of multiprocessing, too) that, when you execute your script, it (to greatly simplify it) effectively ends up as as if you called two blank (shell) processes with <code>subprocess.Popen()</code> and then have them execute:</p>
<pre><code>python -c "from your_script import nonloop_star; nonloop_star(('dog', 'C:\\hbrowning'))"
python -c "from your_script import nonloop_star; nonloop_star(('cat', 'C:\\hbrowning'))"
python -c "from your_script import nonloop_star; nonloop_star(('yeti', 'C:\\hbrowning'))"
python -c "from your_script import nonloop_star; nonloop_star(('parakeet', 'C:\\hbrowning'))"
python -c "from your_script import nonloop_star; nonloop_star(('dolphin', 'C:\\hbrowning'))"
</code></pre>
<p>one by one as soon as one of those processes finishes with the previous call. That means that your <code>if __name__ == "__main__"</code> block never gets executed (because it's not the main script, it's imported as a module) so anything declared within it is not readily available to the function (as it was never evaluated).</p>
<p>For the staff outside your function you can at least cheat by accessing your <code>module</code> via <code>sys.modules["your_script"]</code> or even with <code>globals()</code>  but that works only for the evaluated staff, so anything that was placed within the <code>if __name__ == "__main__"</code> guard is not available as it didn't even had a chance. That's also a reason why you must use this guard on Windows -  without it you'd be executing your pool creation, and other code that you nested within the guard, over and over again with each spawned process.</p>
<p>If you need to share read-only data in your multiprocessing functions, just define it in the global namespace of your script, outside of that <code>__main__</code> guard, and all functions will have the access to it (as it gets re-evaluated when starting a new process) regardless if they are running as separate processes or not.</p>
<p>If you need data that changes then you need to use something that can synchronize itself over different processes - there is a slew of modules designed for that, but most of the time Python's own pickle-based, datagram communicating <code>multiprocessing.Manager</code> (and types it provides), albeit slow and not very flexible, is enough.</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p>Python Â» 3.6.1 Documentation: <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool" rel="nofollow noreferrer">multiprocessing.pool.Pool</a> </p>
<pre><code>map(func, iterable[, chunksize])
A parallel equivalent of the map() built-in function (it supports only one iterable argument though)
</code></pre>
</blockquote>
<p>There is no Restriction, only it have to be a iterable!<br/>
Try a <code>class Container</code>, for instance:</p>
<pre><code>class WP(object):
    def __init__(self, name):
        self.root_dir ='C:\\hbrowning'
        self.name = name

word_list = [WP('dog'), WP('cat'), WP('llama'), WP('yeti'), WP('parakeet'), WP('dolphin')]
results = pool.map(nonloop_star, word_list, chunksize=1)
</code></pre>
<blockquote>
<p><strong>Note</strong>: The <code>Var Types</code> inside the <code>class</code> have to be <code>pickleable</code>!<br/>
  Read about <a href="https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled" rel="nofollow noreferrer">what-can-be-pickled-and-unpickled</a></p>
</blockquote>
</div>
<span class="comment-copy">I don't understand why you need to define them in the <code>__name__</code> block rather than at module level, which would work.</span>
<span class="comment-copy">Actually, defining things in the block works fine for me as well. Why do you think you need to zip everything up?</span>
<span class="comment-copy">Because <code>pool.map</code> for Python 2.7 only takes a function and one argument (again, from the question I linked). I am confused about why things are working for you - perhaps you could post some code that worked?</span>
<span class="comment-copy">And I get <code>NameError: global name 'root_dir' not defined</code> if I run the <code>loop_function</code> with a single argument (word_list) under multiprocessing</span>
<span class="comment-copy">@DanielRoseman: Windows behaves differently, since it doesn't have <code>fork</code>. HFBrowning is probably on Windows, and you're probably not.</span>
<span class="comment-copy">This is a great answer, @zwer! I didn't explain but my reasoning for not wanting to include the data in the module level environment is that it is expensive to calculate (3 hours) and I only need it done once per script run. Then I make 2,000 reports in a parallel way, hitting off the same data. It sounds like splitting these into two scripts and using the data paths as constants in the latter would be a clearer approach. But at least I understand the program execution flow now - something I could not grasp based on the documentation.</span>
<span class="comment-copy">@HFBrowning - if it takes a long time to evaluate your data (assuming large quantities) and your processes need unrestricted access to the whole data set - I'd recommend you store it in some in-memory database (<a href="https://redis.io/" rel="nofollow noreferrer"><code>Redis</code></a> for example) then have your processes poll the data from it. If the processes can use the data in a serialized way (so no need for the whole set at once), you can create a streaming dispatcher pattern like <a href="https://stackoverflow.com/a/44502827/7553525">this</a> or <a href="https://stackoverflow.com/a/44415368/7553525">this</a> and feed your workers in a controlled manner.</span>
<span class="comment-copy">I've never heard of <code>Redis</code> before - it looks great! Thank you for the additional suggestions (:</span>
