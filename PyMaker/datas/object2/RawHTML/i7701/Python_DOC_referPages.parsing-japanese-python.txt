<div class="post-text" itemprop="text">
<p>*****EDITED WITH THE FULL CODE******</p>
<p>I am trying to parse some Japanese code using Python (Version 3.5.3) and the MeCab library on MacOS.</p>
<p>I have a txt file with the following text:</p>
<p>石の上に三年</p>
<p>I set my preferences on my textEdit to save using utf-8. So I believe the system is correctly saving it in the utf-8 format.</p>
<p>I got the following error:</p>
<pre><code>Traceback (most recent call last):   File "japanese.py", line 29, in &lt;module&gt;
    words = extractMetadataFromTXT(fileName)   File "japanese.py", line 14, in extractMetadataFromTXT
    md = extractWordsJP(data)   File "japanese.py", line 22, in extractWordsJP
    components.append(parsed.surface) UnicodeDecodeError: 'utf-8' codec can't decode byte 0xb0 in position 0: invalid start byte
</code></pre>
<p>Bellow goes my full code. Nothing missing.</p>
<pre><code>import MeCab
import nltk
from nltk import *
from nltk.corpus import knbc

mt = MeCab.Tagger("-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd")
wordsList = knbc.words()
fdist = nltk.FreqDist(w.lower() for w in wordsList)

def extractMetadataFromTXT(filePath):
    with open(filePath, 'r', encoding='utf-8') as f:
        data = f.read()
        print(data)
    md = extractWordsJP(data)
    print(md)
    return md

def extractWordsJP(wordsJP):
    components = []
    parsed = mt.parseToNode(wordsJP)
    while parsed:
        components.append(parsed.surface)
        parsed = parsed.next
    return components

if __name__ == "__main__":
    fileName = "simple_japanese.txt"
    words = extractMetadataFromTXT(fileName)
    print(words)
</code></pre>
<p>Has anyone any clue of why I am getting this error message?</p>
<p><strong>Funny fact: Sometimes it works. :O</strong></p>
<p>Thanks in advance,</p>
<p>Israel</p>
</div>
<div class="post-text" itemprop="text">
<p>The error is happening because you're feeding something that isn't valid UTF-8 into a UTF-8 decoder. This could be caused by splitting bytes rather than characters, or perhaps by incorrectly attempting to decode another encoding like JIS or EUC as if it were UTF-8. In Python it's generally sound to stick to unicode strings, and your system might switch to decoding text files if something has set the <a href="https://docs.python.org/3/library/locale.html" rel="nofollow noreferrer">locale</a> parameters. Even when you do have proper unicode strings splitting is a non-trivial issue as there are codes to modify others, such as accents. Japanese doesn't have much of that sort of thing, luckily (unless someone happens to encode po as ho+ring etc). </p>
<p>One potential issue: Mecab's webpage states (per google translate) "Unless otherwise specified, euc is used." If Mecab is word splitting under the assumption it is reading EUC, it will mangle UTF-8. </p>
</div>
<div class="post-text" itemprop="text">
<p>Solution:</p>
<p>Apparently, the problem was with MeCab, not with the python code itself. This problem was that when you install it from the scratch, using make, sometimes it doesn't install properly but it doesn't raise any error.</p>
<p>I am not sure about why, but if you wanna dig further and find out what is exactly happening, it would be great. I only know that I uninstalled and re-installed again using brew, and it worked. </p>
<p>Similar stuff happened in other Macs from the office. I am using brew in OS X, so I will post the command I used to install it properly:</p>
<pre><code>brew install mecab mecab-ipadic git curl xz
</code></pre>
<p>Also, to install it on linux, use the following command:</p>
<pre><code>sudo apt-get install mecab libmecab-dev mecab-ipadic
sudo apt-get install mecab-ipadic-utf8
sudo apt-get install python-mecab
</code></pre>
<p>Hope this helps future people trying to tag Japanese words.</p>
</div>
<div class="post-text" itemprop="text">
<p>When you open the file, specify the encoding:</p>
<pre><code>with open(file, 'r', encoding='utf-8') as f:
    data = f.read()

...
</code></pre>
<p>BTW, when opening the file, use a <a href="https://docs.python.org/3/library/contextlib.html" rel="nofollow noreferrer">context manager</a> as shown in this example. </p>
</div>
<span class="comment-copy">The error can only be caused by an encoding issue, so your TextEdit settings probably didn't work. From a shell, <code>cd</code> to the directory with your input file and type <code>file simple_japanese.txt</code>. That should say <code>UTF-8 Unicode text</code>.</span>
<span class="comment-copy">I set the configurations of textEdit to save only in utf-8 and the error persists. :(</span>
<span class="comment-copy">TypeError: an integer is required (got type str)</span>
<span class="comment-copy">That should read <code>encoding='utf-8'</code>, though it requires Python 3 and probably doesn't fix the problem.</span>
<span class="comment-copy">Thanks Yann, I was missing the encoding='utf-8' part. But, as you predicted, it didn't solve the problem. It works sometimes, but it doesn't. I need something stable instead of randomness.</span>
<span class="comment-copy">It souldn't be <code>utf-8</code>, otherwise there would have been no error in the first place (the error message in OP explicitely states that <code>utf-8</code> was already used). @israel.zinc do you know which encoding your original file uses? - Oh, and providing the full traceback would be nice ^^</span>
<span class="comment-copy">I don't think it's random, I think it's data dependent. It could even be that your input data is actually malformed.</span>
