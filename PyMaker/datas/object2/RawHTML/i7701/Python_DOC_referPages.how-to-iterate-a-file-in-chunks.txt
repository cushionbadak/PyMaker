<div class="post-text" itemprop="text">
<p>I have a file (foo.txt) that is sorted like so (column 0 is grouped):</p>
<pre><code>1  foo     bar
1  lorem   ipsum   gypsum
1  baba    loo     too
2  hello   goodbye seeya
3  kobe    magic   wilt
3  foo     sneaks  bar
3  more    stuff
3  last    line    in      file
</code></pre>
<p>How can I iterate the file in chunks of <code>line.split()[0]</code>?  I know that generators can do this but I'm not entirely sure how.  Essentially, I would like to do this:</p>
<pre><code>def first_column_grouping(file):
    yield some_list ## How?

with open("foo.txt") as file:
    for group in first_column_grouping(file): ## 3 values
        print group
</code></pre>
<p>Expected output:</p>
<pre><code>["1 foo bar", "1 lorem ipsum gypsum", "1 baba loo too"]
["2 hello goodbye seeya"]
["3 kobe magic wilt", 3 foo sneaks bar", "3 more stuff", "3 last line in file"]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>So, you actually want the functionality provided by <code>itertools.groupby</code>. This will work if your first-column is sorted:</p>
<pre><code>&gt;&gt;&gt; from itertools import groupby
&gt;&gt;&gt; from operator import itemgetter
&gt;&gt;&gt; with io.StringIO(s) as f:
...     for k, g in groupby(f, itemgetter(0)):
...         print(list(g))
...
['1  foo     bar\n', '1  lorem   ipsum   gypsum\n', '1  baba    loo     too\n']
['2  hello   goodbye seeya\n']
['3  kobe    magic   wilt\n', '3  foo     sneaks  bar\n', '3  more    stuff\n', '3  last    line    in      file']
&gt;&gt;&gt;
</code></pre>
<p>If you want to clean up that output a bit, you can map <code>str.split</code> onto your group:</p>
<pre><code>&gt;&gt;&gt; with io.StringIO(s) as f:
...     for k, g in groupby(f, itemgetter(0)):
...         print(list(map(str.strip, g)))
...
['1  foo     bar', '1  lorem   ipsum   gypsum', '1  baba    loo     too']
['2  hello   goodbye seeya']
['3  kobe    magic   wilt', '3  foo     sneaks  bar', '3  more    stuff', '3  last    line    in      file']
</code></pre>
<p>If you wanted to implement this from scratch, an inflexible and naive generator could look something like this:</p>
<pre><code>&gt;&gt;&gt; def groupby_first_column(f):
...     line = next(f)
...     k = line[0]
...     group = [line]
...     for line in f:
...         if line[0] == k:
...             group.append(line)
...         else:
...             yield group
...             group = [line]
...             k = line[0]
...     yield group
...
&gt;&gt;&gt; with io.StringIO(s) as f:
...     for group in groupby_first_column(f):
...         print(list(group))
...
['1  foo     bar\n', '1  lorem   ipsum   gypsum\n', '1  baba    loo     too\n']
['2  hello   goodbye seeya\n']
['3  kobe    magic   wilt\n', '3  foo     sneaks  bar\n', '3  more    stuff\n', '3  last    line    in      file']
&gt;&gt;&gt;
</code></pre>
<p><strong>Warning</strong> the above generator only works if each line has the first column in exactly the first position, and it is only 1 character long. This was not meant to be very useful, only to illustrate the idea. If you wanted to roll your own, you would have to be much more thorough </p>
</div>
<div class="post-text" itemprop="text">
<p>this is a variant (the <code>fake_file</code>  here is just your <code>file</code> in the <code>with</code> statement):</p>
<pre><code>from io import StringIO

fake_file = StringIO('''1  foo     bar
1  lorem   ipsum   gypsum
1  baba    loo     too
2  hello   goodbye seeya
3  kobe    magic   wilt
3  foo     sneaks  bar
3  more    stuff
3  last    line    in      file''')


def iter_cols(file):

    lne = next(file).strip()
    buffer = [lne]
    last_number = lne.split()[0]

    for line in file:
        lne = line.strip()
        number = lne.split()[0]
        if number != last_number:
            yield buffer
            buffer = [lne]
            last_number = number
        else:
            buffer.append(lne)
    yield buffer

for cols in iter_cols(fake_file):
    print(cols)
</code></pre>
<p>this iterates over the file and does not need to have the whole file in memory. therefore only the neighboring lines will be grouped.</p>
<p>(you seem to be using python2: <code>file</code> is not a good variable name then - because it's a built-in)</p>
</div>
<div class="post-text" itemprop="text">
<p>This is what <code>itertools.groupby</code> is for, though I think you'll need to read the whole file into memory to do that.</p>
<pre><code>import itertools

with open("path/to/file") as f:
    data = f.readlines()  # a list of the lines of the file

groups = itertools.groupby(data, key=lambda line: line.split()[0])
# group on the first column of each line. This produces something like:
# [ ("1", ["1 foo bar", "1 lorem ipsum gypsum", "1 baba loo too"]),
#   ("2", ["2 hello goodbye seeya"]),
#   ("3", ["3 kobe magic wilt", 3 foo sneaks bar", "3 more stuff", "3 last line in file"]) ]

# since you only want the values there, just pull them out of the tuples
result = [v for k,v in groups]
</code></pre>
<p>However I'm honestly not sure if <code>groupby</code> consumes all the data at once. If it's a lazy iterator you could pass <code>f</code> directly.</p>
<pre><code>import itertools
import operator

with open('path/to/file') as f:
    groups = itertools.groupby(f, key=lambda line: line.split()[0])
    for _, group in groups:
        result = list(group)
        # use this result however you like, but...
    # be sure not to leave this block until you've consumed all of
    # result, or you won't be able to read any more of the file.
</code></pre>
<hr/>
<p>If you can't or don't want to read the file into memory all at once, you'll have to do something special.</p>
<pre><code>def group_by_col(filename, key=None):
    if key is None:
        key = lambda s: s
    with open(filename) as f:
        cur_group = []
        grouper = []
        for line in file:
            new_grouper = key(line)
            if new_grouper != grouper:
                if cur_group:
                    yield cur_group
                cur_group = [line]
                grouper = new_grouper
            else:
                cur_group.append(line.rstrip())
        yield cur_group
</code></pre>
<p>In this case, you'll have to pass the key function to select the first space-separated column of each row: e.g. <code>lambda s: s.split()[0]</code></p>
<pre><code>for group in group_by_col('path/to/file', key=lambda s: s.split()[0]):
    print(group)
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>This is built upon the accepted answer, and will group by any specified column:</p>
<pre><code>def group_by_column(f, column):
     line = next(f)
     k = line.split()[column]
     group = [line]
     for line in f:
         if line.split()[column] == k:
             group.append(line)
         else:
             yield group
             group = [line]
             k = line.split()[column]
     yield group


if __name__ == "__main__":

    foo = "foo.txt"
    with open(foo) as foofile:
        for group in group_by_column(foofile, 0):
            print(group)
</code></pre>
</div>
<span class="comment-copy">@AdamSmith yes, definitely. I'll add that warning. Thanks.</span>
<span class="comment-copy">Thanks!  I added an argument, <code>groupby_column(f, column)</code> that allows you to specify which column you wish to group by (so if the number "175" is in column 0, it still works).  I also substituted <code>line.split()[column]</code> everywhere that <code>line[0]</code> appeared</span>
<span class="comment-copy">No, you don't have to read the whole file into memory. It <code>groupby</code> works lazily, and a file-handler is a lazy iterator, so you only need the memory overhead of each individual group.</span>
<span class="comment-copy">f.readlines() reads the entire file into memory</span>
<span class="comment-copy">@touchmyboomboom juanpa is saying that I wouldn't need to do that. That I can pass <code>f</code> directly into <code>groupby</code>. I don't have the time to test that, but I trust that it's probably true! My edit basically just re-implements <code>groupby</code>, but neglects the grouping header that's the first element of each tuple in the result. That should work regardless (though of course <code>groupby</code> is cleaner)</span>
<span class="comment-copy">Well, if the value in the first column could be anywhere, that is, row 0  and row 100 both have <code>1</code>, but the rows in between are all different, you would either have to read the whole file into memory <i>or</i> make multiple passes, I suppose</span>
<span class="comment-copy">The <a href="https://docs.python.org/3/library/itertools.html#itertools.groupby" rel="nofollow noreferrer">docs</a> have a sample implementation (not the actual implementation of course) which implies that it is in-fact lazy. Also, it warns "The returned group is itself an iterator that shares the underlying iterable with groupby(). Because the source is shared, when the groupby() object is advanced, the previous group is no longer visible. " Anyway, the library was written by Raymond Hettinger, and it was meant to provide lazy, memory efficient iterators.</span>
