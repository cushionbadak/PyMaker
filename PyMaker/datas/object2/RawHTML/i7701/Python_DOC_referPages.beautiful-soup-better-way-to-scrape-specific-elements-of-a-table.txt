<div class="post-text" itemprop="text">
<p>I am scraping some publicly available retail data from the table at this URL: <a href="https://502data.com/retailers" rel="nofollow noreferrer">https://502data.com/retailers</a> </p>
<p>My goal is to create a list in python for each column, e.g. a "Name_list" with all the entries in that column of the web table, a "County_list" and so on. </p>
<p>Here's my code for getting started with the scrape:</p>
<pre><code>r = requests.get(url_to_scrape)
soup = BeautifulSoup(r.text, 'html.parser')
all_text = soup.get_text()
</code></pre>
<p>It seems to me that my all_text variable may not be necessary. It looks like there must be a slicker way to do this than I currently realize. For example:</p>
<pre><code>all_text[7200:8000]
</code></pre>
<p>The above yields:</p>
<pre><code>u', function($scope, $filter) {\n                    $scope.retailers = [{"licensenumber":"414876","name":"MAIN STREET MARIJUANA","city":"VANCOUVER","county":"CLARK","year":2017,"month":5,"sales":41170232.357500,"tax":14971101.020000,"recentSales":1374866.000000,"recentTax":508700.000000,"monthName":"May"}, ...
</code></pre>
<p>I can see that after $scope.retailers = I have all the information I want stored in what looks like an easy to parse way. </p>
<p>I'm just not familiar with Beautiful Soup enough to know the best commands for me to loop through this table, using either the soup or all_text variable, and pull out the data in each row of the web table. </p>
<p>Looking for a specific solution to this problem as well as any general BeautifulSoup advice for a beginner. </p>
</div>
<div class="post-text" itemprop="text">
<p>Since this is not actually the HTML you want to parse, but rather JavaScript code, I would either use a JavaScript parser, like <a href="https://pypi.python.org/pypi/slimit" rel="nofollow noreferrer"><code>slimit</code></a>, or use a <em>regular expression</em>: </p>
<pre><code>import json
import re

import requests


url = "https://502data.com/retailers"
response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36'})

pattern = re.compile(r"\$scope\.retailers = (\[.*?\]);")

match = pattern.search(response.text)
data = json.loads(match.group(1))
for item in data:
    print(item["name"])
</code></pre>
<p>The parenthesis here mean a <a href="https://docs.python.org/3/howto/regex.html#grouping" rel="nofollow noreferrer">"capturing group"</a>, backslashes are used for escaping the characters.</p>
<p>Note that I'm applying the expression directly against the page source without using <code>BeautifulSoup</code> at all. We can though use it to locate this <code>script</code> element and then apply the expression on the <code>script</code> element's text.</p>
</div>
<span class="comment-copy">Great, thanks! Can you explain what is being specified by 'headers' in the response variable?</span>
<span class="comment-copy">@pavlov it is not really necessary to specify the custom user-agent header in this case, just my bad web-scraping habit :)</span>
<span class="comment-copy">Ok, but what is that? You're specifying what computer and browser you're using for the scrape?</span>
<span class="comment-copy">@pavlov it is basically for pretending to be a real browser.</span>
