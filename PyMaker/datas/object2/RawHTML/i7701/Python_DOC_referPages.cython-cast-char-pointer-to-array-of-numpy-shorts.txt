<div class="post-text" itemprop="text">
<p>I'm trying to improve on the time taken in adding two fixed length arrays. I must convert 2 strings of bytes into 2 short arrays of fixed length and then add the two arrays together, finally outputting the resultant array as a string of bytes. </p>
<p>Currently I have:</p>
<pre><code>import cython
cimport numpy as np
import numpy as np

@cython.boundscheck(False)
@cython.wraparound(False)
def cython_layer( char* c_string1, char* c_string2, int length ):
    cdef np.ndarray[ np.int16_t, ndim=1 ] np_orig = np.fromstring( c_string1[:length], np.int16, count=length//2 )
    cdef np.ndarray[ np.int16_t, ndim=1 ] np_new  = np.fromstring( c_string2[:length], np.int16, count=length//2 )
    res = np_orig + np_new
    return res.tostring() 
</code></pre>
<p>however, the simpler numpy only method yields a very similar (better) performance:</p>
<pre><code>def layer(self, orig, new, length):
    np_orig = fromstring(orig, np.int16, count=length // 2)
    np_new  = fromstring(new,  np.int16, count=length  // 2)
    res     = np_orig + np_new 
    return res.tostring()
</code></pre>
<p>Is it possible to improve on numpy speed for this simple example ? My gut says yes but I don't have enough of a handle on Cython to improve anymore. Using Ipython <code>%timeit</code> magic I've clocked the functions at:</p>
<pre><code>100000 loops, best of 3: 5.79 µs per loop    # python + numpy
100000 loops, best of 3: 8.77 µs per loop    # cython + numpy
</code></pre>
<p>e.g:</p>
<pre><code>a = np.array( range(1024), dtype=np.int16).tostring()
layer(a,a,len(a)) == cython_layer(a,a,len(a))
# True
%timeit layer(a, a, len(a) )
# 100000 loops, best of 3: 6.06 µs per loop
%timeit cython_layer(a, a, len(a))
# 100000 loops, best of 3: 9.19 µs per loop
</code></pre>
<p>edit: changes <code>layer</code> to show <code>size=len(orig)//2</code> orig and new are both byte arrays of length 2048. Converting them to shorts (<code>np.int16</code>) results in an output array of size 1024.</p>
<p>edit2: I'm an idiot.</p>
<p>edit3: example in action</p>
</div>
<div class="post-text" itemprop="text">
<p>One solution is to skip the numpy arrays and just use C pointers:</p>
<pre><code>from cpython.bytes cimport PyBytes_FromStringAndSize
from libc.stdint cimport int16_t

def layer2(char* orig, char* new, length):
    cdef:
        bytes res = PyBytes_FromStringAndSize(NULL,2*(length//2))
        char* res_as_charp = res
        int16_t* orig_as_int16p = &lt;int16_t*&gt;orig
        int16_t* new_as_int16p = &lt;int16_t*&gt;new
        int16_t* res_as_int16p = &lt;int16_t*&gt;res_as_charp       
        Py_ssize_t i


    for i in range(length//2):
        res_as_int16p[i] = orig_as_int16p[i] + new_as_int16p[i]

    return res
</code></pre>
<p>Essentially, I create an empty string for the result using the C API function <code>PyBytes_FromStringAndSize</code> and modify that. The advantages of that are that unlike your version the both the inputs and outputs are used as is and not copied. Note that the <em>only</em> situation where you're allowed to modify Python strings like this is when you've just created an new one using <code>PyBytes_FromStringAndSize(NULL,length)</code> - <a href="https://docs.python.org/3/c-api/bytes.html" rel="nofollow noreferrer">this is in the C API documentation</a>.</p>
<p>I then get a <code>char*</code> to it (doesn't copy the data, just points to existing data).</p>
<p>I then cast the <code>char*</code> for both inputs and the output to be <code>int16_t*</code> - this just changes how the memory is interpreted.</p>
<p>I then loop over the array doing the addition and using pointer indexing.</p>
<p>In terms of speed, this is about 8 times faster than the Python implementation for short strings (<code>length&lt;100</code>). This is largely due to the fixed Python overhead of function calls are creating numpy arrays I believe. For longer strings (<code>length&gt;=100000</code>) my version actually slower slightly. I suspect numpy has a better vectorized/parallelized loop for the addition.</p>
<hr/>
<h2>Extra notes</h2>
<p>Code shown is form Python 3 - for Python 2 you want <code>PyString_...</code> instead of <code>PyBytes_...</code></p>
<p>You can get a slight improvement (~10-20%) on your pure Python version by using <code>np.frombuffer</code> instead of <code>np.fromstring</code>. This avoids copying the inputs.</p>
</div>
<span class="comment-copy">So how are you calling this function?</span>
<span class="comment-copy">What's <code>chunk_size</code>? Your code as posted doesn't work... I think one issue is that your <code>char*</code> are probably autoconverted from <code>str</code> your function being called and then autoconverted to <code>str</code> (i.e. unnecessarily copied) before being passed to <code>np.fromstring</code>.</span>
<span class="comment-copy">@DavidW sorry, had <code>to_string()</code> instead of <code>tostring()</code>. I've also updated the python + numpy solution to implicitly use the length of the byte array. are you suggesting that <code>np.fromstring(char)</code> would work ? because it converts only the first 48 bytes to short.</span>
<span class="comment-copy">No - I'm just suggesting that it gets converted <code>char*</code>-&gt;<code>str</code>-&gt;<code>np.array</code> and so it ends up being copied twice. I don't know if that's easily avoidable though.</span>
<span class="comment-copy">Is there any chance you can add a full working example, including whatever benchmark you're using?</span>
<span class="comment-copy">Thanks @DavidW - that works an absolute charm. Great explanation too.  For anyone interested I saw a substantial performance increase.      <code>%timeit layer(byts,byts,len(byts))</code> <code>#100000 loops, best of 3: 5.83 µs per loop</code> <code>%timeit cython_layer(byts,byts,len(byts))</code> <code>#1000000 loops, best of 3: 438 ns per loop</code></span>
