<div class="post-text" itemprop="text">
<p>I have a set of links like:</p>
<pre><code>['http://www.nytimes.com/2016/12/31/us/politics/house-republicans-health-care-suit.html?partner=rss&amp;amp;emc=rss" rel="standout"&gt;&lt;/atom:link&gt;',
 'http://www.nytimes.com/2016/12/31/nyregion/bronx-murder-40th-precinct-police-residents.html&lt;/guid&gt;',
 'http://www.nytimes.com/2016/12/30/movies/tyrus-wong-dies-bambi-disney.html?partner=rss&amp;amp;emc=rss',
 'http://www.nytimes.com/2016/12/30/obituaries/among-deaths-in-2016-a-heavy-toll-in-pop-music.html&lt;/guid&gt;',
 'http://www.nytimes.com/video/world/100000004830728/daybreak-around-the-world.html?partner=rss&amp;amp;emc=rss']
</code></pre>
<p>I'm trying to iterate over them to remove everything that comes after <code>html</code>. So I have:</p>
<pre><code>cleanitems = []

for item in links:  
    cleanitems.append(re.sub(r'html(.*)', '', item))
</code></pre>
<p>Which returns:</p>
<pre><code>['http://www.nytimes.com/2016/12/31/us/politics/house-republicans-health-care-suit.',
 'http://www.nytimes.com/2016/12/31/nyregion/bronx-murder-40th-precinct-police-residents.',
 'http://www.nytimes.com/2016/12/30/movies/tyrus-wong-dies-bambi-disney.',
 'http://www.nytimes.com/2016/12/30/obituaries/among-deaths-in-2016-a-heavy-toll-in-pop-music.',
 'http://www.nytimes.com/video/world/100000004830728/daybreak-around-the-world.]
</code></pre>
<p>Confused as to why it's including <code>html</code> in the capture group. Thanks for any help.</p>
</div>
<div class="post-text" itemprop="text">
<p><code>html</code> is part of the matched text <em>too</em>, not just the <code>(...)</code> group. <code>re.sub()</code> replaces all of the whole matched text.</p>
<p>Include the literal <code>html</code> text in the replacement:</p>
<pre><code>cleanitems.append(re.sub(r'html(.*)', 'html', item))
</code></pre>
<p>or, alternatively, capture that part in a group instead:</p>
<pre><code>cleanitems.append(re.sub(r'(html).*', r'\1', item))
</code></pre>
<p>You may want to consider using a non-greedy match, and a <code>$</code> end-of-string anchor to prevent cutting off a URL that contains <code>html</code> in the path more than once, and including the <code>.</code> dot to make sure you are really only matching the <code>.html</code> extension:</p>
<pre><code>cleanitems.append(re.sub(r'\.html.*?$', r'.html', item))
</code></pre>
<p>However, if your goal is to remove the <em>query string</em> from a URL, consider parsing the URL using <a href="https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse" rel="nofollow noreferrer"><code>urllib.parse.urlparse()</code></a>, and re-building it without the query string or fragment identifiers:</p>
<pre><code>from urlib.parse import urlparse

cleanitems.append(urlparse(item)._replace(query='', fragment='').geturl())
</code></pre>
<p>This won't remove the eroneous HTML chunks however; if you are parsing these URLs from a HTML document, consider using a <a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/" rel="nofollow noreferrer">real HTML parser</a> rather than regex.</p>
</div>
<div class="post-text" itemprop="text">
<p>Just a complement to Martijn's answer.</p>
<p>You could also use a lookbehind assertion to only match the text following <code>html</code>:</p>
<pre><code>cleanitems.append(re.sub(r'(?&lt;=html).*', '', item))
</code></pre>
<p>or use a replacement string to keep the initial part:</p>
<pre><code>cleanitems.append(re.sub(r'(html).*', r'\1', item))
</code></pre>
<p>But as already said by Martin, you'd better use the urllib module to correctly parse URLs</p>
</div>
<span class="comment-copy">You also remove <code>html</code>. Put <code>html</code> into the replacement string to keep it.</span>
<span class="comment-copy">Interesting, I figured it only captured the parenthese'd group. Also I guess I included <code>''</code> out of habit of getting rid of bad characters. Will accept answer in 9 minutes when SO lets me. Thanks.</span>
<span class="comment-copy">good advice, thanks much</span>
