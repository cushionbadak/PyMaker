<div class="post-text" itemprop="text">
<p>I am using Ubuntu 16.04. Here is tensorflow info:</p>
<pre><code>&gt;&gt;&gt; pip show tensorflow-gpu
pip show tensorflow-gpu
Name: tensorflow-gpu
Version: 1.2.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /home/xxxx/anaconda3/envs/tensorflow/lib/python3.5/site-packages
Requires: markdown, backports.weakref, wheel, bleach, html5lib, protobuf, numpy, six, werkzeug
</code></pre>
<p>The cuda info:</p>
<pre><code>nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17
</code></pre>
<p>When I <code>import tensorflow</code> in Python from Ubuntu terminal I get no loading information as below.</p>
<pre><code>&gt;&gt;&gt; import tensorflow
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
</code></pre>
<p>If I run the python program in terminal, I get different information. </p>
<pre><code>2017-06-20 16:08:18.075709: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 16:08:18.075733: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 16:08:18.075740: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 16:08:18.075744: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 16:08:18.075750: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-06-20 16:08:18.260629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-20 16:08:18.261462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Quadro K620M
major: 5 minor: 0 memoryClockRate (GHz) 1.124
pciBusID 0000:08:00.0
Total memory: 1.96GiB
Free memory: 1.58GiB
2017-06-20 16:08:18.261514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-20 16:08:18.261524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-20 16:08:18.261550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -&gt; (device: 0, name: Quadro K620M, pci bus id: 0000:08:00.0)
2
</code></pre>
<p>How do I know if tensorflow is using cuda and cudnn or not? What other information do I need to provide?</p>
</div>
<div class="post-text" itemprop="text">
<p>You can check with <code>nvidia-smi</code> if the GPU is used by the python/tensorflow process. If there is no process using the GPU, tensorflow doesn't use cuda and cudnn.</p>
</div>
<div class="post-text" itemprop="text">
<p>Had a similar question on Windows - wanted to see the GPU being utilised and can't figure out how to install the smi utility.</p>
<p>The most convincing way I found check whether it was using the CPU was to run the tutorial:</p>
<p><a href="https://www.tensorflow.org/tutorials/layers" rel="nofollow noreferrer">https://www.tensorflow.org/tutorials/layers</a></p>
<p>Main change required is the following:</p>
<pre><code># Create the Estimator
config = tf.ConfigProto(log_device_placement=True)
config.gpu_options.allow_growth = True
run_config = tf.estimator.RunConfig().replace(
    session_config=config)

mnist_classifier = tf.estimator.Estimator(
  model_fn=cnn_model_fn, model_dir="./mnist_convnet_model2",
  config = run_config)
</code></pre>
<p>The logging shows where it's putting the operations - GPU:0 (you should see this in the console)</p>
<p>allow_growth stops CUDA falling over on my machine by allocating all the memory straight away.  It took quite a while to find how to apply this to the estimator - docs could be improved a little here for new users I feel!</p>
<p>Once I got it up and running, not only was it lightening fast in comparison to the CPU only version, but I could see GPU usage in the 70s-80s on task manager!</p>
</div>
<span class="comment-copy">What does <code>import tensorflow</code> in the terminal do? And is <a href="https://docs.python.org/3/library/sys.html#sys.implementation" rel="nofollow noreferrer"><code>sys.implementation</code></a> or <a href="https://docs.python.org/3/library/sys.html#sys.executable" rel="nofollow noreferrer"><code>sys.executable</code></a> what you are looking for?</span>
<span class="comment-copy">Ops, my bad. I run <code>import tensorflow</code> in Python from terminal. I am testing if tensorflow use cuda or cudnn or not.</span>
<span class="comment-copy">For TensorFlow 1.2, see <a href="https://github.com/tensorflow/tensorflow/issues/10827" rel="nofollow noreferrer">this issue</a>.</span>
<span class="comment-copy">@HelloGoodbye, thanks for the link.</span>
<span class="comment-copy">@AZ2016 were you able to fix this issue, I am going through the same thing.</span>
