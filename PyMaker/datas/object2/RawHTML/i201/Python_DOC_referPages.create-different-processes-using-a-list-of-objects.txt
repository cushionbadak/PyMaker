<div class="post-text" itemprop="text">
<p>I want to execute this function without having to rewrite all the code for each process.</p>
<pre><code>def executeNode(node):
    node.execution()
</code></pre>
<p>And the code that I don't feel the need to repeat n times the next one. I need to use Process not Threads.</p>
<pre><code>a0 = Process(target=executeNode, args = (node1))
a1 = Process(target=executeNode, args = (node2))
a2 = Process(target=executeNode, args = (node3))
...............................
an = Process(target=executeNode, args = (nodeN))
</code></pre>
<p>So I decided to create a list of nodes but I don't know how to execute a process for each item (node) of the list. </p>
<pre><code>sNodes = []

for i in range(0, n):
    node = node("a"+ str(i), (4001 + i))
    sNodes.append(node)
</code></pre>
<p>How can I execute a process for each item (node) of the list (sNodes).
Thank you all.</p>
</div>
<div class="post-text" itemprop="text">
<p>You can use a <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer"><code>Pool</code></a>:</p>
<pre><code>from multiprocessing import Pool

if __name__ == '__main__':
    with Pool(n) as p:
        print(p.map(executeNode, sNodes))
</code></pre>
<p>Where <code>n</code> is the number of processes you want.</p>
<p>In case you want detached processes or you dont expect a result is better to simply use another loop:</p>
<pre><code>processes = []
for node in sNodes:
    p = Process(target=executeNode, args = (node1))
    processes.append(p)
    p.Start()
</code></pre>
<p>General tip: having <strong>a lot</strong> of processes will not speed up your code but make your processor start swaping and everything will be slower. Just in case you are looking for a code speedup instead of a logical architecture.</p>
</div>
<div class="post-text" itemprop="text">
<p>Try something like this:</p>
<pre><code>from multiprocessing import Pool

process_number = 4
nodes = [...]

def execute_node(node):
    print(node)

pool = Pool(processes=process_number)
pool.starmap(execute_node, [(node,) for node in nodes])
pool.close()
</code></pre>
<p>You will find more intel here: <a href="https://docs.python.org/3/library/multiprocessing.html" rel="nofollow noreferrer">https://docs.python.org/3/library/multiprocessing.html</a></p>
</div>
<span class="comment-copy">Is it important to have exactly one process per node object, or is it acceptable to run some of the function calls in serial rather than parallel? Even multiprocessing won't speed things up if you start more processes than your CPU has cores.</span>
