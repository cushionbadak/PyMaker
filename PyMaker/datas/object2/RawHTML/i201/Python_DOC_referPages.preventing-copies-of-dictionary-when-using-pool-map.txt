<div class="post-text" itemprop="text">
<p>I have a function <code>f(x)</code> I want to evaluate over list of values <code>xrange</code> in parallel. The function does something like this:</p>
<pre><code>def f(x, wrange, dict1, dict2):

    out_list = []

    v1 = dict1[x]

    for w in wrange:
        v2 = dict2[x-w]
        out_list += [np.dot(v1, v2)]

    return out_list
</code></pre>
<p>it takes values a matrix from a dictionary <code>dict1</code>, a vector from dictionary <code>dict2</code>, then multiplies them together. Now my normal approach for doing this in parallel would be something like this:</p>
<pre><code>import functools
import multiprocessing

par_func = functools.partial(f, wrange=wrange, dict1=dict1, dict2=dict2)

p = multiprocessing.Pool(4)
ssdat = p.map(par_func, wrange)
p.close()
p.join()
</code></pre>
<p>Now when <code>dict1</code> and <code>dict2</code> are big dictionaries, this causes the code to fail with the error </p>
<pre><code>File "/anaconda3/lib/python3.6/multiprocessing/connection.py", line 393, in _send_bytes header = struct.pack("!i", n)
struct.error: 'i' format requires -2147483648 &lt;= number &lt;= 2147483647
</code></pre>
<p>and I think this is because <code>pool</code> is making copies of the <code>dict1</code> and <code>dict2</code> for every evaluation of my function. Is there an efficient way, instead, to set these dictionaries as shared memory objects? Is <code>map</code> the best function to do this?</p>
</div>
<div class="post-text" itemprop="text">
<p>If you're on a <code>fork</code>-based system (read: Not Windows), one solution to this problem is to put the <code>dict</code>s in question in globals, write a function that doesn't take them as arguments, but simply access them from its own globals, and use that. <a href="https://stackoverflow.com/q/35062087/364696"><code>functools.partial</code> is, unfortunately, unsuited to this use case</a>, but your use case makes it easy to replace with globals and a <code>def</code>-ed function:</p>
<pre><code>import multiprocessing

# Assumes wrange/dict1/dict2 defined or imported somewhere at global scope,
# prior to creating the Pool
def par_func(x):
    return f(x, wrange, dict1, dict2)

# Using with statement implicitly terminates the pool, saving close/join calls
# and guaranteeing an exception while mapping doesn't leave the pool alive indefinitely
with multiprocessing.Pool(4) as p:
    ssdat = p.map(par_func, wrange)
</code></pre>
<p>Changes to <code>dict1</code>/<code>dict2</code> won't be reflected between processes after the <code>Pool</code> is created, but you seem to be using it in a read-only fashion anyway, so that's not a problem.</p>
<p>If you're on Windows, or need to mutate the <code>dict</code>s, you can always <a href="https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager.dict" rel="nofollow noreferrer">make a <code>multiprocessing.Manager</code> and make <code>dict</code> proxies with the <code>dict</code> method of the manager</a> (these are shared <code>dict</code>s, updated on key assignment), but it's uglier and slower, so I'd discourage it if at all possible.</p>
</div>
<div class="post-text" itemprop="text">
<p>If you want to share memory between processes using multiprocessing, you'll need to explicitly share the objects with <a href="https://docs.python.org/2/library/multiprocessing.html#multiprocessing.Array" rel="nofollow noreferrer">multiprocessing.Array</a>.  That's not ideal since you're wanting to access elements from dicts and finding the correct data might be time consuming.  There are likely ways around this if it does become a problem for you.</p>
<p>As @Peque mentioned, the other option is to use <a href="https://docs.python.org/2/library/threading.html" rel="nofollow noreferrer">threading</a>.  With threading, memory is automatically shared across all processes but you can run into performance issues due to the <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow noreferrer">global interpreter lock</a> (GIL).  The GIL is Python's way to keep you thread-safe and avoid race conditions.</p>
</div>
<span class="comment-copy">You may try with <code>threading</code> instead. If your <code>np.dot()</code> is computationally expensive you may not notice the difference between mutiprocessing and multithreading as NumPy should release the GIL while calculating the matrix product.</span>
<span class="comment-copy">This is <i>almost</i> a duplicate of <a href="https://stackoverflow.com/q/35062087/364696">Python multiprocessing - Why is using functools.partial slower than default arguments?</a>, but the focus is different (this asks how, the other question asks why); I'll leave it up to others to make that decision.</span>
<span class="comment-copy">@ShadowRanger thanks, this gave some good background to my question.</span>
<span class="comment-copy">This did the trick, thanks very much!</span>
