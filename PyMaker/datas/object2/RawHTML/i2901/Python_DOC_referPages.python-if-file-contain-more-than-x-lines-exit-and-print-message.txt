<div class="post-text" itemprop="text">
<p>I'm trying to create error handler in python, python will check the file and if the file contains more than 95000 lines, it will stop and print an error message.</p>
<p>Is it an easy way to make this?</p>
<p>This is solution I found:</p>
<pre><code>def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
    return i + 1
</code></pre>
<p>And then something like, if i &gt; 95000 print 'Error'</p>
</div>
<div class="post-text" itemprop="text">
<p>try this simple approach:</p>
<pre><code>with open(&lt;your_file&gt;, 'r') as abc:
    lines = [i for i in abc.readlines() if len(i)&gt;1]
    if len(lines) &gt;95000:
        raise StopIteration("File too big!")
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Your approach was a good one:</p>
<pre><code>def get_bounded_num_lines(k, infile):
    """Returns min(K, number of lines in infile).

    Max running time is proportional to K rather than total file length,
    similar to /usr/bin/head -K.
    """
    try:
        for i in range(k + 1):
            next(infile)
    except StopIteration:
        pass
    infile.close()
    return i


if __name__ == '__main__':
    k, fspec = 95000, '/tmp/foo.txt'
    if get_bounded_num_lines(k, open(fspec)) &gt;= k:
        raise ValueError('File is too big')
</code></pre>
<p>This avoids wasting lots of time reading every single line of a multi-terabyte file before signaling an error.</p>
<p>If you don't need a completely accurate result and your files have predictable contents, then read the head of the file, the first 100 lines or so, add up their length, and compute <code>avg_line_length = total_head_length / 100</code>. Armed with that and with <code>file_length = os.path.getsize(fspec)</code>, you'd be able to <em>very</em> quickly compute <code>estimated_num_lines = int(file_length / avg_line_length)</code> and compare to that.</p>
</div>
<div class="post-text" itemprop="text">
<p>Assuming there are no blank lines in the file, you can use the <code>linecache</code> library, which provides the content of a line directly. Try this one:</p>
<pre><code>file_path="path_to_file"  
line_content=linecache.getline(file_path,95000)
if line_content:
   print "Lines goes beyond limit error"
</code></pre>
<p>More details at <a href="https://docs.python.org/3/library/linecache.html" rel="nofollow noreferrer">https://docs.python.org/3/library/linecache.html</a></p>
</div>
<span class="comment-copy">Please show us what you have done so far</span>
<span class="comment-copy">Do you really need a solution which works in both <a href="https://stackoverflow.com/questions/tagged/python-2.7">python-2.7</a> and <a href="https://stackoverflow.com/questions/tagged/python-3.x">python-3.x</a>?</span>
<span class="comment-copy">@tripleee Ideally this is what I'm looking for</span>
<span class="comment-copy">What's wrong with the code you found? Just replace the <code>pass</code> with  <code>if i &gt; 95000: raise ValueError('File is too big')</code> inside the loop.</span>
<span class="comment-copy">@tripleee as well I found - num_lines = sum(1 for line in open('myfile.txt')) , I'm looking for and appropriate way of error handler , (I'm just new to this... and maybe this is a way of using any kind of exceptions and so on to handle this issues) ...??</span>
<span class="comment-copy">This is wasteful in that it reads the entire file into memory before deciding. Reading 10 million lines when you know after 100,000 that they are too many will needlessly allocate a lot of memory for data you will never use, probably resulting in swapping and degraded overall performance on many servers.</span>
<span class="comment-copy">Nice alternative solution, though I have also upvoted the other answer.</span>
