<div class="post-text" itemprop="text">
<p>I'm trying to learn how to implement multiprocessing for computing Monte Carlo simulations. I reproduced the code from <a href="https://www.dmcdougall.co.uk/parallel-monte-carlo-using-python-and-numpy" rel="nofollow noreferrer">this simple tutorial</a> where the aim is to compute an integral. I also compare it to the <a href="http://www.wolframalpha.com/input/?i=integrate+exp(-x%5E2)+from+0+to+1" rel="nofollow noreferrer">answer from WolframAlpha</a> and compute the error. The first part of my code has no problems and is just there to define the integral function and declare some constants:</p>
<pre><code>import numpy as np
import multiprocessing as mp
import time

def integrate(iterations):
    np.random.seed()
    mc_sum = 0
    chunks = 10000
    chunk_size = int(iterations/chunks)

    for i in range(chunks):
        u = np.random.uniform(size=chunk_size)
        mc_sum += np.sum(np.exp(-u * u))

    normed = mc_sum / iterations
    return normed

wolfram_answer = 0.746824132812427
mc_iterations = 1000000000
</code></pre>
<p>But there's some <strong>very spooky stuff</strong> that happens in the next two parts (I've labelled them because it's important). First (labelled "BLOCK 1"), I do the simulation without any multiprocessing at all, just to get a benchmark. After this (labelled "BLOCK 2"), I do the same thing but with a multiprocessing step. If you're reproducing this, you may want to adjust the <code>num_procs</code> variable depending on how many cores your machines has:</p>
<pre><code>#### BLOCK 1
single_before = time.time()
single = integrate(mc_iterations)
single_after = time.time()
single_duration = np.round(single_after - single_before, 3)
error_single = (wolfram_answer - single)/wolfram_answer

print(mc_iterations, "iterations on single-thread:",
      single_duration, "seconds.")
print("Estimation error:", error_single)
print("")

#### BLOCK 2
if __name__ == "__main__":
    num_procs = 8
    multi_iterations = int(mc_iterations / num_procs)

    multi_before = time.time()
    pool = mp.Pool(processes = num_procs)

    multi_result = pool.map(integrate, [multi_iterations]*num_procs)
    multi_result = np.array(multi_result).mean()
    multi_after = time.time()

    multi_duration = np.round(multi_after - multi_before, 3)
    error_multi = (wolfram_answer - multi_result)/wolfram_answer

    print(num_procs, "threads with", multi_iterations, "iterations each:",
          multi_duration, "seconds.")
    print("Estimation error:", error_multi)
</code></pre>
<p>The output is:</p>
<pre><code>1000000000 iterations on single-thread: 37.448 seconds.
Estimation error: 1.17978774235e-05

8 threads with 125000000 iterations each: 54.697 seconds.
Estimation error: -5.88380936901e-06
</code></pre>
<p>So, the multiprocessing is slower. That's not at all unheard of; maybe the overhead from the multiprocessing is just more than the gains from the parallelization?</p>
<p>But, <strong>that is not what is happening.</strong> Watch what happens when I merely <strong>comment out the first block</strong>:</p>
<pre><code>#### BLOCK 1
##single_before = time.time()
##single = integrate(mc_iterations)
##single_after = time.time()
##single_duration = np.round(single_after - single_before, 3)
##error_single = (wolfram_answer - single)/wolfram_answer
##
##print(mc_iterations, "iterations on single-thread:",
##      single_duration, "seconds.")
##print("Estimation error:", error_single)
##print("")

#### BLOCK 2
if __name__ == "__main__":
    num_procs = 8
    multi_iterations = int(mc_iterations / num_procs)

    multi_before = time.time()
    pool = mp.Pool(processes = num_procs)

    multi_result = pool.map(integrate, [multi_iterations]*num_procs)
    multi_result = np.array(multi_result).mean()
    multi_after = time.time()

    multi_duration = np.round(multi_after - multi_before, 3)
    error_multi = (wolfram_answer - multi_result)/wolfram_answer

    print(num_procs, "threads with", multi_iterations, "iterations each:",
          multi_duration, "seconds.")
    print("Estimation error:", error_multi)
</code></pre>
<p>The output is:</p>
<pre><code>8 threads with 125000000 iterations each: 6.662 seconds.
Estimation error: 3.86063069069e-06
</code></pre>
<p>That's right -- the time to complete the multiprocessing goes down from 55 seconds to less than 7 seconds! And that's not even the weirdest part. Watch what happens when I <strong>move Block 1 to be after Block 2</strong>:</p>
<pre><code>#### BLOCK 2
if __name__ == "__main__":
    num_procs = 8
    multi_iterations = int(mc_iterations / num_procs)

    multi_before = time.time()
    pool = mp.Pool(processes = num_procs)

    multi_result = pool.map(integrate, [multi_iterations]*num_procs)
    multi_result = np.array(multi_result).mean()
    multi_after = time.time()

    multi_duration = np.round(multi_after - multi_before, 3)
    error_multi = (wolfram_answer - multi_result)/wolfram_answer

    print(num_procs, "threads with", multi_iterations, "iterations each:",
          multi_duration, "seconds.")
    print("Estimation error:", error_multi)

#### BLOCK 1
single_before = time.time()
single = integrate(mc_iterations)
single_after = time.time()
single_duration = np.round(single_after - single_before, 3)
error_single = (wolfram_answer - single)/wolfram_answer

print(mc_iterations, "iterations on single-thread:",
      single_duration, "seconds.")
print("Estimation error:", error_single)
print("")
</code></pre>
<p>The output is:</p>
<pre><code>8 threads with 125000000 iterations each: 54.938 seconds.
Estimation error: 7.42415402896e-06
1000000000 iterations on single-thread: 37.396 seconds.
Estimation error: 9.79800494235e-06
</code></pre>
<p>We're back to the slow output again, which is <strong>completely crazy!</strong> Isn't Python supposed to be interpreted? I know that statement comes with a hundred caveats, but I took for granted that the code gets executed line-by-line, so stuff that comes afterwards (outside of functions, classes, etc) can't affect the stuff from before, because it hasn't been "looked at" yet.</p>
<p>So, how can the stuff that gets executed <strong>after</strong> the multiprocessing step has concluded, <strong>retroactively</strong> slow down the multiprocessing code?</p>
<p>Finally, the fast behavior is restored <strong>merely by indenting Block 1</strong> to be inside the <code>if __name__ == "__main__"</code> block, because of course it does:</p>
<pre><code>#### BLOCK 2
if __name__ == "__main__":
    num_procs = 8
    multi_iterations = int(mc_iterations / num_procs)

    multi_before = time.time()
    pool = mp.Pool(processes = num_procs)

    multi_result = pool.map(integrate, [multi_iterations]*num_procs)
    multi_result = np.array(multi_result).mean()
    multi_after = time.time()

    multi_duration = np.round(multi_after - multi_before, 3)
    error_multi = (wolfram_answer - multi_result)/wolfram_answer

    print(num_procs, "threads with", multi_iterations, "iterations each:",
          multi_duration, "seconds.")
    print("Estimation error:", error_multi)

    #### BLOCK 1
    single_before = time.time()
    single = integrate(mc_iterations)
    single_after = time.time()
    single_duration = np.round(single_after - single_before, 3)
    error_single = (wolfram_answer - single)/wolfram_answer

    print(mc_iterations, "iterations on single-thread:",
          single_duration, "seconds.")
    print("Estimation error:", error_single)
    print("")
</code></pre>
<p>The output is:</p>
<pre><code>8 threads with 125000000 iterations each: 7.293 seconds.
Estimation error: 1.10350027622e-05
1000000000 iterations on single-thread: 31.035 seconds.
Estimation error: 2.53582945763e-05
</code></pre>
<p>And the fast behavior is also restored if you keep Block 1 inside the <code>if</code> block, but move it to above where <code>num_procs</code> is defined (not shown here because this question is already getting long).</p>
<p>So, <strong>what on Earth is causing this behavior?</strong> I'm guessing it's some kind of race-condition to do with threading and process branching, but from my level of expertise it might as well be that my Python interpreter is haunted.</p>
</div>
<div class="post-text" itemprop="text">
<p>This is because you are using Windows. On Windows, each subprocess is generated using the <a href="https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods" rel="nofollow noreferrer"><code>'spawn'</code> method</a> which essentially starts a new python interpreter and imports your module instead of forking the process. </p>
<p>This is a problem, because all the code outside <code>if __name__ == '__main__'</code> is <em>executed again</em>. This can lead to a <a href="https://stackoverflow.com/questions/2697640/multiprocessing-bomb">multiprocessing bomb</a> if you put the multiprocessing code at the top-level, because it will start spawning processes until you run out of memory.</p>
<p>This is actually <a href="https://docs.python.org/3.7/library/multiprocessing.html#the-spawn-and-forkserver-start-methods" rel="nofollow noreferrer">warned about in the docs</a></p>
<blockquote>
<p>Safe importing of main module</p>
<p>Make sure that the main module can be safely imported by a new Python
  interpreter without causing unintended side effects (such a starting a
  new process).</p>
<p>...</p>
<p>Instead one should protect the “entry point” of the program by using
  <code>if __name__ == '__main__'</code></p>
<p>...</p>
<p>This allows the newly spawned Python interpreter to safely import the
  module...</p>
</blockquote>
<p>That section used to be called "Windows" in the older docs on Python 2.</p>
</div>
<div class="post-text" itemprop="text">
<p>Adding some detail, on Windows the module is imported "from scratch" in each worker process.  That means <em>everything</em> in the module is executed by each worker.  So, in your first example, each worker process <em>first</em> executes "BLOCK 1".</p>
<p>But your output doesn't reflect that.  You should have gotten a line of output like</p>
<blockquote>
<p>1000000000 iterations on single-thread: 37.448 seconds.</p>
</blockquote>
<p>from each of your 8 worker processes.  But your output doesn't show that.  Perhaps you're using an IDE that suppresses output from spawned processes?  If you run it in a "DOS box" (<code>cmd.exe</code> window) instead, that won't suppress output, and can make what's going on clearer.</p>
</div>
<span class="comment-copy">Are you on windows?</span>
<span class="comment-copy">Yeah Windows 10</span>
<span class="comment-copy">Oh I get it -- so the <code>single</code> calculation is getting done again in each process before it does the multi one? That makes sense. So if I need to do a multi-processing Monte Carlo calculation inside a larger piece of code, where there's a whole lot of stuff being computed beforehand, how should I handle this? Should I bud the parallelized Monte Carlo function into its own little module and import it?</span>
<span class="comment-copy">@dain you can just put it inside the <code>if __name__ == "__main__"</code> block, no?</span>
<span class="comment-copy">So I just put that at the beginning and everything will work properly?</span>
<span class="comment-copy">@dain yes. It should.</span>
<span class="comment-copy">It seems kind of hacky to have to indent the entire main program just to accommodate a function that might only be used once. If I were to parcel out the multi-processing function into its own module and import it, how would I have to structure it? Is this even possible?</span>
