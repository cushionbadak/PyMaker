<div class="post-text" itemprop="text">
<p>When converting a <code>float</code> to a <code>str</code>, I can specify the number of decimal points I want to display</p>
<pre><code>'%.6f' % 0.1
&gt; '0.100000'
'%.6f' % .12345678901234567890
&gt; '0.123457'
</code></pre>
<p>But when simply calling <code>str</code> on a <code>float</code> in python 2.7, it seems to default to 12 decimal points max</p>
<pre><code>str(0.1)
&gt;'0.1'
str(.12345678901234567890)
&gt;'0.123456789012'
</code></pre>
<p>Where is this max # of decimal points defined/documented? Can I programmatically get this number?</p>
</div>
<div class="post-text" itemprop="text">
<p>The number of decimals displayed is going to vary greatly, and there won't be a way to predict how many will be displayed in pure Python.  Some libraries like <code>numpy</code> allow you to set precision of output.</p>
<p>This is simply because of the <a href="https://docs.python.org/3/tutorial/floatingpoint.html" rel="nofollow noreferrer">limitations of float representation</a>.</p>
<p>The relevant parts of the link talk about how Python chooses to display floats.</p>
<blockquote>
<p>Python only prints a decimal approximation to the true decimal value of the binary approximation stored by the machine</p>
<p>Python keeps the number of digits manageable by displaying a rounded value instead</p>
</blockquote>
<p>Now, there is the possibility of overlap here:</p>
<blockquote>
<p>Interestingly, there are many different decimal numbers that share the same nearest approximate binary fraction</p>
</blockquote>
<p>The method for choosing which decimal values to display was changed in Python 3.1 (But the last sentence implies this might be an implementation detail).</p>
<blockquote>
<p>For example, the numbers 0.1 and 0.10000000000000001 are both
  approximated by 3602879701896397 / 2 ** 55. Since all of these decimal
  values share the same approximation, any one of them could be
  displayed while still preserving the invariant eval(repr(x)) == x</p>
<p>Historically, the Python prompt and built-in repr() function would
  choose the one with 17 significant digits, 0.10000000000000001.
  Starting with Python 3.1, Python (on most systems) is now able to
  choose the shortest of these and simply display 0.1.</p>
</blockquote>
</div>
<div class="post-text" itemprop="text">
<p>I do not believe this exists in the python language spec. However, the cpython implementation does specify it. The <a href="https://hg.python.org/cpython/file/55fed3eae14b/Objects/floatobject.c#l379" rel="nofollow noreferrer"><code>float_repr()</code></a> function, which turns a float into a string, eventually calls a helper function with the <code>'r'</code> formatter, which eventually calls a utility function that hardcodes the format to what comes down to <code>format(float, '.16g')</code>. That code can be seen <a href="https://hg.python.org/cpython/file/55fed3eae14b/Python/pystrtod.c#l1057" rel="nofollow noreferrer">here</a>. Note that this is for python3.6.</p>
<pre><code>&gt;&gt;&gt; import math
&gt;&gt;&gt; str(math.pi*4)
12.5663706144
</code></pre>
<p>giving the maximum number of signification digits (both before and after the decimal) at 16. It appears that in the python2.7 implementation, this value was hardcoded to <code>.12g</code>. As for why this happened (and is somewhat lacking documentation, can be found <a href="https://stackoverflow.com/questions/25898733/why-does-strfloat-return-more-digits-in-python-3-than-python-2">here</a>.)</p>
<p>So if you are trying to get how long a number will be formatted when printed, simply get it's length with <code>.12g</code>.</p>
<pre><code>def len_when_displayed(n):
     return len(format(n, '.12g'))
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Well, if you're looking for a pure python way of accomplishing this, you could always use something like,</p>
<pre><code>len(str(.12345678901234567890).split('.')[1])
&gt;&gt;&gt;&gt; 12
</code></pre>
<p>I couldn't find it in the documentation and will add it here if I do, but this is a work around that can at least always return the length of precision if you want to know before hand. </p>
<p>As you said, it always seems to be <code>12</code> even when feeding bigger floating-points.</p>
<hr/>
<p>From what I was able to find, <strong>this number can be highly variable</strong> and in these cases, <strong>finding it empirically seems to be the most reliable way</strong> of doing it. So, what I would do is define a simple method like this,</p>
<pre><code>def max_floating_point():
    counter = 0
    current_length = 0
    str_rep = '.1'
    while(counter &lt;= current_length):
        str_rep += '1'
        current_length = len(str(float(str_rep)).split('.')[1])
        counter += 1

    return current_length
</code></pre>
<p>This will return you the maximum length representation on your current system,</p>
<pre><code>print max_floating_point()
&gt;&gt;&gt;&gt; 12
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>By looking at the output of random numbers converted, I have been unable to understand how the length of the <code>str()</code> is determined, e.g. under Python 3.6.6:</p>
<pre><code>&gt;&gt;&gt; str(.123456789123456789123456789)
'0.12345678912345678'
&gt;&gt;&gt; str(.111111111111111111111111111)
'0.1111111111111111'
</code></pre>
<p>You may opt for this code that actually simulates your real situation:</p>
<pre><code>import random
maxdec=max(map(lambda x:len(str(x)),filter(lambda x:x&gt;.1,[random.random() for i in range(99)])))-2
</code></pre>
<p>Here we are testing the length of ~90 random numbers in the (.1,1) open interval after conversion (and deducing the <code>0.</code> from the left, hence the <code>-2</code>).
Python 2.7.5 on a 64bit linux gives me 12, and Python 3.4.8 and 3.6.6 give me 17.</p>
</div>
<span class="comment-copy">It might be better to demonstrate something in <code>&lt; Python 2.7</code>, as the float represenation changes made in 3.1 were backported to 2.7</span>
<span class="comment-copy">FWIW, the "12" (which is specific to Python 2.x, Python 3.1, and earlier) comes from here: <a href="https://github.com/python/cpython/blob/d1c5e278a1a2458bc5efcdc300c17f9e39a59b6c/Include/floatobject.h#L28" rel="nofollow noreferrer">github.com/python/cpython/blob/â€¦</a>. This changed in Python 3.2.</span>
<span class="comment-copy">@MarkDickinson Thanks, now if only there was a way to check the PyFloat_STR_PRECISION value from Python itself (assuming we know we are using cpython)</span>
<span class="comment-copy">@C_Z_ Are there situations you have to deal with where just checking the version isn't good enough? The use of 12 digits has been fixed since the very beginning of Python (at least, it's there in v0.9.8 of Python, released in 1993). It didn't change until Python 3.2, where it became irrelevant because <code>str</code> no longer bases its output on a fixed number of significant digits.</span>
<span class="comment-copy">Note that there <i>was</i> a change in Python 2.0 when the <code>repr</code> of the float changed to use 17 significant digits rather than 12. The <code>str</code> precision stayed the same, though.</span>
<span class="comment-copy">Hmmm, "Python only prints a decimal approximation to the true decimal value of the binary <i>approximation</i> stored by the machine" seems amiss.  The value in the binary float I'd call exact, not a binary <i>approximation</i>.  "...to the true decimal value of the binary stored by the machine" sounds clearer.  The way the float was assigned may have incurred some rounding, yet the stored value itself is exact.</span>
<span class="comment-copy">@chux I agree, the documentation seems a bit off in that regard.</span>
<span class="comment-copy">How does <code>'.16g'</code> equate to 12 decimal places?</span>
<span class="comment-copy">@modesitt: I think you're misinterpreting the code. In Python versions &gt;= 3.2 and Python 2.7, on most machines, <code>float_repr</code> doesn't use a fixed number of significant digits at all. There's no <code>.16g</code> anywhere, and never has been (in Python 2.6 and earlier, <code>.17g</code> was used). <code>repr</code> returns the shortest string of decimal digits that's guaranteed to round back to the original float under round-ties-to-even. You're right about the .12g being hardcoded for Python <code>str</code> (not <code>repr</code>) for Python 2.x, though.</span>
<span class="comment-copy">Why go through the trouble of a loop with a counter when you could just test a single super long float in the first place? Then the function could be a logic-free wrapper for the line of code you started with.</span>
<span class="comment-copy">@AlexHurst My goal was to provide a general solution to OP's problem. I mean, what would you consider a  <i>super long float</i> ? Not to mention that I'm not sure  that the workload of my loop is <i>trouble</i> as you implied. OP could run this utility method once and store the returned value. I would actually argue that it represent a negligible computation.</span>
