<div class="post-text" itemprop="text">
<p><strong>The setup</strong></p>
<p>I have written a pretty complex piece of software in Python (on a Windows PC). My software starts basically two Python interpreter shells. The first shell starts up (I suppose) when you double click the <code>main.py</code> file. Within that shell, other threads are started in the following way:</p>
<pre><code>    # Start TCP_thread
    TCP_thread = threading.Thread(name = 'TCP_loop', target = TCP_loop, args = (TCPsock,))
    TCP_thread.start()

    # Start UDP_thread
    UDP_thread = threading.Thread(name = 'UDP_loop', target = UDP_loop, args = (UDPsock,))
    TCP_thread.start()
</code></pre>
<p>The <code>Main_thread</code> starts a <code>TCP_thread</code> and a <code>UDP_thread</code>. Although these are separate threads, they all run within one single Python shell.</p>
<p>The <code>Main_thread</code>also starts a subprocess. This is done in the following way:</p>
<pre><code>p = subprocess.Popen(['python', mySubprocessPath], shell=True)
</code></pre>
<p>From the Python documentation, I understand that this subprocess is running <em>simultaneously (!)</em> in a separate Python interpreter session/shell. The <code>Main_thread</code>in this subprocess is completely dedicated to my GUI. The GUI starts a <code>TCP_thread</code> for all its communications.</p>
<p>I know that things get a bit complicated. Therefore I have summarized the whole setup in this figure:</p>
<p><a href="https://i.stack.imgur.com/XFN5o.png"><img alt="enter image description here" src="https://i.stack.imgur.com/XFN5o.png"/></a></p>
<hr/>
<p>I have several questions concerning this setup. I will list them down here:</p>
<p><strong>Question 1</strong>  [<em>Solved</em>]</p>
<p>Is it true that a Python interpreter uses only one CPU core at a time to run all the threads? In other words, will the <code>Python interpreter session 1</code> (from the figure) run all 3 threads (<code>Main_thread</code>, <code>TCP_thread</code> and <code>UDP_thread</code>) on one CPU core?</p>
<p><em>Answer: yes, this is true. The GIL (Global Interpreter Lock) ensures that all threads run on one CPU core at a time.</em></p>
<p><strong>Question 2</strong>  [<em>Not yet solved</em>]</p>
<p>Do I have a way to track which CPU core it is?</p>
<p><strong>Question 3</strong>  [<em>Partly solved</em>]</p>
<p>For this question we forget about <em>threads</em>, but we focus on the <em>subprocess</em> mechanism in Python. Starting a new subprocess implies starting up a new Python interpreter <strong>instance</strong>. Is this correct?</p>
<p><em>Answer: Yes this is correct. At first there was some confusion about whether the following code would create a new Python interpreter instance:</em></p>
<pre><code>    p = subprocess.Popen(['python', mySubprocessPath], shell = True)
</code></pre>
<p><em>The issue has been clarified. This code indeed starts a new Python interpreter instance.</em></p>
<p>Will Python be smart enough to make that separate Python interpreter instance run on a different CPU core? Is there a way to track which one, perhaps with some sporadic print statements as well?</p>
<p><strong>Question 4</strong>   [<em>New question</em>]</p>
<p>The community discussion raised a new question. There are apparently two approaches when spawning a new process (within a new Python interpreter instance):</p>
<pre><code>    # Approach 1(a)
    p = subprocess.Popen(['python', mySubprocessPath], shell = True)

    # Approach 1(b) (J.F. Sebastian)
    p = subprocess.Popen([sys.executable, mySubprocessPath])

    # Approach 2
    p = multiprocessing.Process(target=foo, args=(q,))
</code></pre>
<p>The second approach has the obvious downside that it targets just a function - whereas I need to open up a new Python script. Anyway, are both approaches similar in what they achieve?</p>
</div>
<div class="post-text" itemprop="text">
<blockquote>
<p><strong>Q:</strong> Is it true that a Python interpreter uses only one CPU core at a time to run all the threads?</p>
</blockquote>
<p>No. GIL and CPU affinity are unrelated concepts. GIL can be released during blocking I/O operations, long CPU intensive computations inside a C extension anyway.</p>
<p>If a thread is blocked on GIL; it is probably not on any CPU core and therefore it is fair to say that pure Python multithreading code may use only one CPU core at a time on CPython implementation.</p>
<blockquote>
<p><strong>Q:</strong> In other words, will the Python interpreter session 1 (from the figure) run all 3 threads (Main_thread, TCP_thread and UDP_thread) on one CPU core? </p>
</blockquote>
<p>I don't think CPython manages CPU affinity implicitly. It is likely relies on OS scheduler to choose where to run a thread. Python threads are implemented on top of real OS threads.</p>
<blockquote>
<p><strong>Q:</strong> Or is the Python interpreter able to spread them over multiple cores?</p>
</blockquote>
<p>To find out the number of usable CPUs:</p>
<pre><code>&gt;&gt;&gt; import os
&gt;&gt;&gt; len(os.sched_getaffinity(0))
16
</code></pre>
<p>Again, whether or not threads are scheduled on different CPUs does not depend on Python interpreter.</p>
<blockquote>
<p><strong>Q:</strong> Suppose that the answer to Question 1 is 'multiple cores', do I have a way to track on which core each thread is running, perhaps with some sporadic print statements? If the answer to Question 1 is 'only one core', do I have a way to track which one it is?</p>
</blockquote>
<p>I imagine, a specific CPU may change from one time-slot to another. You could <a href="https://stackoverflow.com/q/8032372/4279">look at something like <code>/proc/&lt;pid&gt;/task/&lt;tid&gt;/status</code> on old Linux kernels</a>. On my machine, <a href="https://www.kernel.org/doc/Documentation/filesystems/proc.txt" rel="noreferrer"><code>task_cpu</code> can be read from <code>/proc/&lt;pid&gt;/stat</code> or <code>/proc/&lt;pid&gt;/task/&lt;tid&gt;/stat</code></a>:</p>
<pre><code>&gt;&gt;&gt; open("/proc/{pid}/stat".format(pid=os.getpid()), 'rb').read().split()[-14]
'4'
</code></pre>
<p>For a current portable solution, see whether <a href="https://pythonhosted.org/psutil/" rel="noreferrer"><code>psutil</code></a> exposes such info.</p>
<p>You could restrict the current process to a set of CPUs:</p>
<pre><code>os.sched_setaffinity(0, {0}) # current process on 0-th core
</code></pre>
<blockquote>
<p><strong>Q:</strong> For this question we forget about threads, but we focus on the subprocess mechanism in Python. Starting a new subprocess implies starting up a new Python interpreter session/shell. Is this correct? </p>
</blockquote>
<p>Yes. <code>subprocess</code> module creates new OS processes. If you run <code>python</code> executable then it starts a new Python interpeter. If you run a bash script then no new Python interpreter is created i.e., running <code>bash</code> executable does not start a new Python interpreter/session/etc.</p>
<blockquote>
<p><strong>Q:</strong> Supposing that it is correct, will Python be smart enough to make that separate interpreter session run on a different CPU core? Is there a way to track this, perhaps with some sporadic print statements as well?</p>
</blockquote>
<p>See above (i.e., OS decides where to run your thread and there could be OS API that exposes where the thread is run).</p>
<blockquote>
<p><code>multiprocessing.Process(target=foo, args=(q,)).start()</code></p>
</blockquote>
<p><code>multiprocessing.Process</code> also creates a new OS process (that runs a new Python interpreter).</p>
<blockquote>
<p>In reality, my subprocess is another file. So this example won't work for me.</p>
</blockquote>
<p>Python uses modules to organize the code. If your code is in <code>another_file.py</code> then <code>import another_file</code> in your main module and pass <code>another_file.foo</code> to <code>multiprocessing.Process</code>.</p>
<blockquote>
<p>Nevertheless, how would you compare it to p = subprocess.Popen(..)? Does it matter if I start the new process (or should I say 'python interpreter instance') with subprocess.Popen(..)versus multiprocessing.Process(..)?</p>
</blockquote>
<p><code>multiprocessing.Process()</code> is likely implemented on top of <code>subprocess.Popen()</code>. <code>multiprocessing</code> provides API that is similar to <code>threading</code> API and it abstracts away details of communication between python processes (how Python objects are serialized to be sent between processes).</p>
<p>If there are no CPU intensive tasks then you could run your GUI and I/O threads in a single process. If you have a series of CPU intensive tasks then to utilize multiple CPUs at once, either use multiple threads with C extensions such as <code>lxml</code>, <code>regex</code>, <code>numpy</code> (or your own one created using <a href="http://cython.org" rel="noreferrer">Cython</a>) that can release GIL during long computations or offload them into separate processes (a simple way is to use a process pool such as provided by <a href="https://docs.python.org/3/library/concurrent.futures.html" rel="noreferrer"><code>concurrent.futures</code></a>).</p>
<blockquote>
<p><strong>Q:</strong> The community discussion raised a new question. There are apparently two approaches when spawning a new process (within a new Python interpreter instance):</p>
<pre><code># Approach 1(a)
p = subprocess.Popen(['python', mySubprocessPath], shell = True)

# Approach 1(b) (J.F. Sebastian)
p = subprocess.Popen([sys.executable, mySubprocessPath])

# Approach 2
p = multiprocessing.Process(target=foo, args=(q,))
</code></pre>
</blockquote>
<p><em>"Approach 1(a)"</em> is wrong on POSIX (though it may work on Windows). For portability, use <em>"Approach 1(b)"</em> unless you know you need <code>cmd.exe</code> (pass a string in this case, to make sure that the correct command-line escaping is used).</p>
<blockquote>
<p>The second approach has the obvious downside that it targets just a function - whereas I need to open up a new Python script. Anyway, are both approaches similar in what they achieve?</p>
</blockquote>
<p><code>subprocess</code> creates new processes, <em>any</em> processes e.g., you could run a bash script. <code>multprocessing</code> is used to run Python code in another process. It is more flexible to <em>import</em> a Python module and run its function than to run it as a script. See <a href="https://stackoverflow.com/q/30076185/4279">Call python script with input with in a python script using subprocess</a>.</p>
</div>
<div class="post-text" itemprop="text">
<p>Since you are using the <code>threading</code> module which is build up on <code>thread</code>. As the documentation suggests, it uses the ''POSIX thread implementation'' <strong>pthread</strong> of your OS. </p>
<ol>
<li>The threads are managed by the OS instead of Python interpreter.  So the answer will depend on the pthread library in your system. However, CPython uses GIL to prevent multiple threads from executing Python bytecodes simutanously. So they will be sequentialized. But still they can be separated to different cores, which depends on your pthread libs.</li>
<li>Simplly use a debugger and attach it to your python.exe. For example the <a href="https://sourceware.org/gdb/onlinedocs/gdb/GDB_002fMI-Thread-Commands.html" rel="nofollow">GDB thread command</a>.</li>
<li>Similar to question 1, the new process is managed by your OS and probably running on a different core. Use debugger or any process monitor to see it. For more details, go to the <code>CreatProcess()</code> documentation <a href="https://msdn.microsoft.com/en-us/library/windows/desktop/ms682425%28v=vs.85%29.aspx?f=255&amp;MSPPError=-2147217396" rel="nofollow">page</a>.</li>
</ol>
</div>
<div class="post-text" itemprop="text">
<p>1, 2: You have three real threads, but in CPython they're limited by GIL , so, assuming they're running pure python, code you'll see CPU usage as if only one core used.</p>
<p>3: As said gdlmx it's up to OS to choose a core to run a thread on,
but if you really need control, you can set process or thread affinity using
native API via <code>ctypes</code>. Since you are on Windows, it would be like this:</p>
<pre><code># This will run your subprocess on core#0 only
p = subprocess.Popen(['python', mySubprocessPath], shell = True)
cpu_mask = 1
ctypes.windll.kernel32.SetProcessAffinityMask(p._handle, cpu_mask)
</code></pre>
<p>I use here private <code>Popen._handle</code> for simplicty. The clean way would be<code>OpenProcess(p.tid)</code> etc. </p>
<p>And yes, <code>subprocess</code> runs python like everything else in another new process. </p>
</div>
<span class="comment-copy"><a href="https://docs.python.org/2/library/multiprocessing.html" rel="nofollow noreferrer">docs.python.org/2/library/multiprocessing.html</a></span>
<span class="comment-copy">I think you should question why you care on which physical cores your threads run. The OS will usually move threads around between the available CPUs in the system depending on various factors. Is there any particular reason why you want to monitor and/or interfere with this process?</span>
<span class="comment-copy">Good question :-). Yes, I believe I do have a valid reason. I'm building a data acquisition system in Python, that reads my microcontroller data (like Analog inputs, ...)  and shows live graphs in my GUI. As long as the incoming data is limited, nobody cares about multiprocessing. But once it gets really fast, I want to be in control. Maybe I can make certain low-latency parts of my Python software run on a dedicated CPU core that I do not use for anything else, hence ensuring high responsiveness.</span>
<span class="comment-copy">@K.Mulier: As long as you have fewer runnable threads than CPUs in your system, the OS will always let all of them run concurrently. Also, if you get so fast as to have to care about allocating threads to fix cores, you are far beyond the point where you can write the program in Python.</span>
<span class="comment-copy">I think that your statement <i>'the OS will always let all of them run concurrently</i>' does not hold for Python. Python has a GIL (Global Interpreter Lock) to make sure that your software is not executed multicore. If you want to execute it on multiple CPU cores, you need to bypass this GIL. I'm only a beginner in Python, so feel free to correct me where I'm wrong. You are right that Python is not the best choice for CPU intensive tasks. The reasons that I chose Python have more to do with sharing the software with my colleagues who know Python. Anyway, that's beyond the scope of the question :-)</span>
<span class="comment-copy">In you first question/answer do you imply that in presence of blocking IO operations multiple cores could be involved by pure Python multithreaded (but not multiprocess) application?</span>
<span class="comment-copy">@Serge What are you referring to? Could you provide a direct quote.</span>
<span class="comment-copy">No. GIL and CPU affinity are unrelated concepts. GIL can be released during blocking I/O operations, long CPU intensive computations inside a C extension anyway.  If a thread is blocked on GIL; it is probably not on any CPU core and therefore it is fair to say that pure Python multithreading code may use only one CPU core at a time on CPython implementation.</span>
<span class="comment-copy">@Serge I don't see how it relates to your question. Are you asking whether different CPython processes have their own GILs? (the answer is yes). Obviously, different Python processes may run on different CPUs at the same time (even on different hosts).</span>
<span class="comment-copy">Nope, according to docs,  The lock is also released around potentially blocking I/O operations like reading or writing a file, so that other Python threads can run in the meantime. Does it mean it released and then reaquired in order to do I/O, or reading of file contend might happen in parallel to another thread, using another core.</span>
<span class="comment-copy">(3) works perfectly. Without it, a simple single-threaded busy loop gets thrown around all the cores; with that code, it is permanently on core #0. I have no idea if it's ever useful, but perhaps there are some cache-related reasons to keep a critical thread on a single core.</span>
