<div class="post-text" itemprop="text">
<p>I have a folder of 1000's of csv files on specific datasets. For each dataset, I have three types of data. The naming convention is as follows:</p>
<p>(assuming name of dataset is 'aaa')</p>
<ol>
<li><code>'aaa_values.csv'</code></li>
<li><code>'aaa_info.csv'</code></li>
<li><code>'aaaps.csv'</code></li>
</ol>
<p>Each dataset has a title of varying length e.g., 'aaa', 'ab3fz', 'gjt89', etc. Note the third type of data has no underscore separating the type - it is <code>'ps.csv'</code></p>
<p>I would like to filter this to obtain the universe of datasets. I have managed to do this with the following Python code, but it is clunky and not very 'Pythonic'.</p>
<p>Does anyone have suggestions for a more elegant way of doing this?</p>
<pre><code>import os
x = []
y = os.listdir("C:\\Anaconda3\\Python_Library\\Python_Folder\\csvData")
for i in y:
    x.append(i.split('_'))
h = []
for i in x:
    for j in i:
        h.append(j)
c = [l for l in h if l != 'values.csv']
c = list(set([p for p in c if p != 'info.csv']))
[t for t in c if t[-6:]!='ps.csv']
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>The first step to a more pythonic code is using more descriptive names than <code>x</code>, <code>y</code>, <code>i</code>, <code>j</code>, <code>c</code>, and <code>p</code>. This looks a bit better:</p>
<pre><code># paths = os.listdir("C:\\Anaconda3\\Python_Library\\Python_Folder\\csvData")
paths = ['aaa_values.csv', 'aaa_info.csv', 'aaaps.csv', 'bbbps.csv', 'ccc_info.csv']
res = set()
for path in paths:
    path_parts = path.split('_')
    last = path_parts[-1]
    if (last == 'values.csv' or last == 'info.csv'):
        res.add(path_parts[0])
    elif last[-6:] == 'ps.csv':
        res.add(last[:-6])
</code></pre>
<p>Now:</p>
<pre><code>&gt;&gt;&gt; res
{'aaa', 'bbb', 'ccc'}
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>Use a set to remove duplicates, and use <code>find()</code> to check for and locate the '_' in the filename:</p>
<pre><code>import os

path = "C:\\Anaconda3\\Python_Library\\Python_Folder\\csvData"
suffixlength = len('ps.csv')

# use a set to remove duplicates
datasets = set()

for filename in os.listdir(path):

    # find() returns the index of the '_' or -1 if it isn't found.   
    i = filename.find('_')

    # chop the filename at the index of the '_' if found else just
    # before the 'ps.csv' suffix
    datasets.add(filename[:i] if i&gt;0 else filename[:-suffixlength])
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p><strong><a href="https://docs.python.org/3/library/re.html#re.findall" rel="nofollow">Regular expressions</a></strong> and <strong><a href="https://docs.python.org/3/tutorial/datastructures.html#sets" rel="nofollow">set comprehensions</a></strong> are very Pythonic, so to extend on Mike Muller's example:</p>
<pre><code>import re
import os

# see https://regex101.com/r/sR5cQ8 for the regex explanation
dataset_re = re.compile(r'^(.*)(?:_values|_info|ps)\.csv$')

# paths = os.listdir("C:\\Anaconda3\\Python_Library\\Python_Folder\\csvData")
paths = ['aaa_values.csv', 'aaa_info.csv', 'aaaps.csv',
         'bbbps.csv', 'ccc_info.csv', 'README.txt']
dataset_universe = {match for path in paths
                          for match in dataset_re.findall(path)}

dataset_universe  # {'aaa', 'bbb', 'ccc'}
</code></pre>
<p><hr/>
Regex explanation copied from <a href="https://regex101.com/r/sR5cQ8" rel="nofollow">https://regex101.com/r/sR5cQ8</a>:</p>
<pre><code>^ assert position at start of the string
1st Capturing group (.*)
    .* matches any character (except newline)
        Quantifier: * Between zero and unlimited times, as many times as possible, giving back as needed [greedy]
(?:_values|_info|ps) Non-capturing group
    1st Alternative: _values
        _values matches the characters _values literally (case sensitive)
    2nd Alternative: _info
        _info matches the characters _info literally (case sensitive)
    3rd Alternative: ps
        ps matches the characters ps literally (case sensitive)
\. matches the character . literally
csv matches the characters csv literally (case sensitive)
$ assert position at end of the string
</code></pre>
<p></p>
</div>
<div class="post-text" itemprop="text">
<p>Here is another way of doing it using <a href="http://pandas.pydata.org/pandas-docs/stable/10min.html" rel="nofollow noreferrer"><code>pandas</code></a>:</p>
<blockquote>
<p><strong>Consider your input folder contains files like this:</strong></p>
</blockquote>
<pre><code>aaa_info.csv
aaa_values.csv
aaapd.csv
bbb_info.csv
bbb_values.csv
bbbpd.csv
ccc_info.csv
ccc_values.csv
cccpd.csv
ddd_info.csv
ddd_values.csv
dddpd.csv
</code></pre>
<blockquote>
<p><strong>CODE</strong></p>
</blockquote>
<pre><code>import os
import glob
import pandas as pd

#Get all the csv files in the folder
flist = [os.path.basename(x) for x in glob.glob(os.getcwd() + '\\*.csv')]

#Create a dataframe
df = pd.DataFrame()

#Create a column named files and assign the file list to it
df['files'] = flist

#Create another column named set and assign only the portion of the file name that we want to create set by
df['set'] = [x.rsplit('_')[0] if '_' in x else x[:-6] for x in flist]

#Group by the set names required
#if you want the output as sets
dfs = df.groupby(df['set']).apply(lambda x: set(x['files']))

#if you want them to be CSV
dfg = df.groupby(df['set']).apply(lambda x: ','.join(x['files']))

dfg.to_csv('setoffiles.csv')
</code></pre>
<blockquote>
<p><strong>Following will be the output produced</strong></p>
</blockquote>
<p><a href="https://i.stack.imgur.com/LgfyH.png" rel="nofollow noreferrer"><img alt="enter image description here" src="https://i.stack.imgur.com/LgfyH.png"/></a></p>
</div>
