<div class="post-text" itemprop="text">
<p>I work on n elements (named "pair" below) variations with repetition used as my function's argument. Obviously everything works fine as long as the "r" list is not big enough to consume all the memory. The issue is I have to make more then 16 repetitions for 6 elements eventually. I use 40 cores system in cloud for this.  </p>
<p>The code looks looks like the following:</p>
<pre><code>if __name__ == '__main__':
  pool = Pool(39)
  r = itertools.product(pairs,repeat=16)
  pool.map(f, r)
</code></pre>
<p>I believe i should use iterator instead of creating the huge list upfront and here the problem starts..</p>
<p>I tried to solve the issue with the following code:</p>
<pre><code>if __name__ == '__main__':
  pool = Pool(39)
  for r in itertools.product(pairs,repeat=14):
    pool.map(f, r)
</code></pre>
<p>The memory problem goes away but the CPUs usage is like 5% per core. Now the single core version of the code is faster then this.</p>
<p>I'd really appreciate if you could guide me a bit..</p>
<p>Thanks.</p>
</div>
<div class="post-text" itemprop="text">
<p>Your original code isn't creating a <code>list</code> upfront in your own code (<code>itertools.product</code> returns a generator), but <code>pool.map</code> is realizing the whole generator (because it assumes if you can store all outputs, you can store all inputs too).</p>
<p>Don't use <code>pool.map</code> here. If you need ordered results, using <code>pool.imap</code>, or if result order is unimportant, use <code>pool.imap_unordered</code>. Iterate the result of either call (don't wrap in <code>list</code>), and process the results as they come, and memory should not be an issue:</p>
<pre><code>if __name__ == '__main__':
    pool = Pool(39)
    for result in pool.imap(f, itertools.product(pairs, repeat=16)):
        print(result)
</code></pre>
<p>If you're using <code>pool.map</code> for side-effects, so you just need to run it to completion but the results and ordering don't matter, you could dramatically improve performance by using <code>imap_unordered</code> and using <code>collections.deque</code> to efficiently drain the "results" without actually storing anything (a <code>deque</code> with <code>maxlen</code> of <code>0</code> is the fastest, lowest memory way to force an iterator to run to completion without storing the results):</p>
<pre><code>from collections import deque

if __name__ == '__main__':
    pool = Pool(39)
    deque(pool.imap_unordered(f, itertools.product(pairs, repeat=16)), 0)
</code></pre>
<p>Lastly, I'm a little suspicious of specifying 39 <code>Pool</code> workers; <code>multiprocessing</code> is largely beneficial for CPU bound tasks; if you're using using more workers than you have CPU cores and gaining a benefit, it's possible <code>multiprocessing</code> is costing you more in IPC than it gains, and using more workers is just masking the problem by buffering more data.</p>
<p>If your work is largely I/O bound, you might try using a thread based pool, which will avoid the overhead of pickling and unpickling, as well as the cost of IPC between parent and child processes. Unlike process based pools, Python threading is subject to <a href="https://wiki.python.org/moin/GlobalInterpreterLock" rel="nofollow">GIL</a> issues, so your CPU bound work in Python (excluding GIL releasing calls for I/O, <code>ctypes</code> calls into .dll/.so files, and certain third party extensions like <code>numpy</code> that release the GIL for heavy CPU work) is limited to a single core (and in Python 2.x for CPU bound work you often waste a decent amount of that resolving GIL contention and performing context switches; Python 3 removes most of the waste). But if your work is largely I/O bound, blocking on I/O releases the GIL to allow other threads to run, so you can have many threads as long as most of them delay on I/O. It's easy to switch too (as long as you haven't designed your program to rely on separate address spaces for each worker by assuming you can write to "shared" state and not affect other workers or the parent process), just change:</p>
<pre><code>from multiprocessing import Pool
</code></pre>
<p>to:</p>
<pre><code>from multiprocessing.dummy import Pool
</code></pre>
<p>and you get the <a href="https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy" rel="nofollow"><code>multiprocessing.dummy</code></a> version of the pool, based on threads instead of processes.</p>
</div>
<div class="post-text" itemprop="text">
<p>The second code example is slower because you're submitting a single pair to a Pool of 39 works. Only one worker will be processing your request and the other 38 will do nothing! Will be slower because you'll have overhead in piping data from the main thread to the workers processes.</p>
<p>You can "buffer" some pairs, then execute the set of pairs to balance out memory usage but still get advantage of the multiprocess environment.</p>
<pre><code>import itertools
from multiprocessing import Pool

def foo(x):
    return sum(x)

cpus = 3
pool = Pool(cpus)
# 10 is buffer size multiplier - the number of pair that each process will get
buff_size = 10*cpus  
buff = []
for i, r in enumerate(itertools.product(range(20), range(10))):
    if (i % buff_size) == (buff_size-1):
        print pool.map(foo, buff)
        buff = []
    else:
        buff.append(r)

if len(buff) &gt; 0:
    print pool.map(foo, buff)
    buff = []
</code></pre>
<p>The output of the above will look like this</p>
<pre><code>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 4, 5, 6, 7, 8, 9, 10]
[3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 5, 6, 7, 8, 9, 10, 11, 12, 13]
[6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 8, 9, 10, 11, 12, 13, 14, 15, 16]
[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 14, 15, 16, 17, 18, 19, 20, 21, 22]
[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 17, 18, 19, 20, 21, 22, 23, 24, 25]
[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
</code></pre>
<p>Play with the <code>buff_size</code> multiplier to get the right balance for your system!</p>
</div>
<span class="comment-copy">Side-note: If you're using modern Python (Python 3.3 or higher), it's best to use <code>Pool</code> with the <code>with</code> statement, so the <code>Pool</code> workers are cleaned up predictably. Just change <code>pool = Pool(39)</code> to <code>with Pool(39) as pool:</code> and indent the lines below it that use the pool; when the block is exited, the workers are cleaned up immediately.</span>
<span class="comment-copy">Thank you for the clarification. I've tried both options and for both, first process shows like 150% of CPU utilization (in top )and the rest of the processes are busy only in 40% and it goes dramatically  down once the number of processes increases ( Up to 17% with 39 processes - for 40 vcpus). How to make it more efficient?</span>
<span class="comment-copy">@xis_one: One thing that could help would be passing a &gt;1 <code>chunksize</code> to <code>imap</code>/<code>imap_unordered</code> so more work is done in the workers before they have to block on IPC again. More complicated but often better option would be to make the workers generate some of their own work, e.g. if <code>pairs</code> is a global, you could <code>imap</code> out work for <code>product(pairs, repeat=10)</code>, then have each worker generate all of the last 6 possible items, e.g. <code>for workitem in map(workerarg.__add__, product(pairs, repeat=6)):</code>, thereby reducing the amount of data that must be transferred to perform a single task.</span>
<span class="comment-copy">Note: <code>map</code> in my last comment would be the plain built-in <code>map</code>, not a pool mapping. If you're on Python 2, you'd want to do <code>from future_builtins import map</code> to get Py3's generator based <code>map</code> to avoid the huge <code>list</code> issues.</span>
<span class="comment-copy">Additional note: If you push some of the work generation to the child processes, they'll be returning a collection of values rather than single values. In that case, to make it still behave like you're getting a single value at a time, you might want to look at wrapping the <code>imap*</code> call in <code>itertools.chain.from_iterable</code>, so it converts from an iterator of <code>list</code>/<code>tuple</code>s to an iterator of the underlying values.</span>
