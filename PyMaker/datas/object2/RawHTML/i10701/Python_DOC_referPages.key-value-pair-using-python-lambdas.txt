<div class="post-text" itemprop="text">
<p>I am trying to work on a simple word count problem and trying to figure if that can be done by use of map, filter and reduce exclusively.</p>
<p>Following is an example of an wordRDD(the list used for spark):</p>
<pre><code>myLst = ['cats', 'elephants', 'rats', 'rats', 'cats', 'cats']
</code></pre>
<p>All i need is to count the words and present it in a tuple format:</p>
<pre><code>counts = [('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]
</code></pre>
<p>I tried with simple map() and lambdas as:</p>
<pre><code>counts = myLst.map(lambdas x: (x, &lt;HERE IS THE PROBLEM&gt;))
</code></pre>
<p>I might be wrong with the syntax or maybe confused. 
P.S.: This isnt a duplicate questin as rest answers give suggestions using if/else or list comprehensions.</p>
<p>Thanks for the help.</p>
</div>
<div class="post-text" itemprop="text">
<p>You don't need <code>map(..)</code> at all. You can do it with just <code>reduce(..)</code></p>
<pre><code>&gt;&gt;&gt; def function(obj, x):
...     obj[x] += 1
...     return obj
...
&gt;&gt;&gt; from functools import reduce
&gt;&gt;&gt; reduce(function, myLst, defaultdict(int)).items()
dict_items([('elephants', 1), ('rats', 2), ('cats', 3)])
</code></pre>
<p>You can then iterate of the result.</p>
<hr/>
<p>However, there's a better way of doing it: Look into <a href="https://docs.python.org/3/library/collections.html#collections.Counter" rel="nofollow"><code>Counter</code></a></p>
</div>
<div class="post-text" itemprop="text">
<p>Not using a lambda but gets the job done.</p>
<pre><code>from collections import Counter
c = Counter(myLst)
result = list(c.items())
</code></pre>
<p>And the output:</p>
<pre><code>In [21]: result
Out[21]: [('cats', 3), ('rats', 2), ('elephants', 1)]
</code></pre>
</div>
<div class="post-text" itemprop="text">
<p>If you don't want the full reduce step done for you (which aggregated the counts in SuperSaiyan's answer), you can use map this way:</p>
<pre><code>    &gt;&gt;&gt; myLst = ['cats', 'elephants', 'rats', 'rats', 'cats', 'cats']
    &gt;&gt;&gt; counts = list(map(lambda s: (s,1), myLst))
    &gt;&gt;&gt; print(counts)
    [('cats', 1), ('elephants', 1), ('rats', 1), ('rats', 1), ('cats', 1), ('cats', 1)]
</code></pre>
</div>
<span class="comment-copy">How did you get <code>counts</code>? your expected result is completely irrelevant to what you want ans your input.</span>
<span class="comment-copy"><code>lambda</code> not <code>lambdas</code>.</span>
<span class="comment-copy">@Hobbes, thanks for correcting.. I am a java guy so mixed it! :P</span>
<span class="comment-copy">Just to be clear, if you are working on an rdd, you should probably be doing <code>map</code> and then <code>reduceByKey</code>. <code>map</code> is not an eager operation.</span>
<span class="comment-copy">@zengr agreed totally</span>
<span class="comment-copy">the problem is, I am working on a Spark project and we are dealing with RDD's  and not lists. Hence Counter arent of much help to us.</span>
<span class="comment-copy">@downvoter care to explain the downvote?</span>
<span class="comment-copy">I agree to this that Counter does help. But unfortunately while dealing with Spark libraries, you deal with RDD's and not with actual lists. Hence no module from collections really help to get the k,v pair.</span>
<span class="comment-copy">Why not convert them into a (k, v) tuple then, before inserting into a counter?</span>
<span class="comment-copy">Why are you calling Counter twice on the list? Why not <code>for x,y in Counter(myLst).items()</code>?</span>
<span class="comment-copy">I guess you can acheive the same (but shorter) result with <code>result = list(c.items())</code></span>
