<div class="post-text" itemprop="text">
<p>TCP flows by their own nature will grow until they fill the maximum capacity of the links used from <code>src</code> to <code>dst</code> (if all those links are empty).</p>
<p>Is there an easy way to limit that ? I want to be able to send TCP flows with a maximum X mbps rate. </p>
<p>I thought about just sending X bytes per second using the <code>socket.send()</code> function and then sleeping the rest of the time. However if the link gets congested and the rate gets reduced, once the link gets uncongested again it will need to recover what it could not send previously and the rate will increase. </p>
</div>
<div class="post-text" itemprop="text">
<p>At the TCP level, the only control you have is how many bytes you pass off to send(), and how often you call it.  Once send() has handed over some bytes to the networking stack, it's entirely up to the networking stack how fast (or slow) it wants to send them.</p>
<p>Given the above, you can roughly limit your transmission rate by monitoring how many bytes you have sent, and how much time has elapsed since you started sending, and holding off subsequent calls to send() (and/or the number of data bytes your pass to send()) to keep the average rate from going higher than your target rate.</p>
<p>If you want any finer control than that, you'll need to use UDP instead of TCP.  With UDP you have direct control of exactly when each packet gets sent.  (Whereas with TCP it's the networking stack that decides when to send each packet, what will be in the packet, when to resend a dropped packet, etc)</p>
</div>
<span class="comment-copy">The recovery will burst at a higher rate, but the average over the long term should still be the rate you send with <code>socket.send()</code>.</span>
<span class="comment-copy">Is there a way I could limit the burst? I am working with a super congested network so I will have those burst all the time.</span>
<span class="comment-copy">you can send <a href="https://docs.python.org/3/library/socket.html#socket.socket.setblocking" rel="nofollow noreferrer">non-blocking</a> (packets of at max the size of the <a href="https://de.wikipedia.org/wiki/Maximum_Transmission_Unit" rel="nofollow noreferrer">MTU</a> ) but non-blocking mode makes things a bit more difficult</span>
<span class="comment-copy">@janbrohl Non-blocking vs. blocking only affects how the application behaves if the local socket buffer fills up, it has nothing to do with the rate on the wire.</span>
<span class="comment-copy">With UDP I am doing that already. For what I have to do I need to generate both types of flows and I wanted to limit TCP in the same way I was doing with UDP.</span>
<span class="comment-copy">AFAIK limiting your calls to send() is all you can do, short of hacking the TCP stack or writing your own TCP layer.</span>
<span class="comment-copy">I suppose one thing that might help would be to call setsockopt(SO_SNDBUF, ...) to the smallest value you can get away with, so that the TCP stack will hold as few bytes as possible in its outgoing-TCP-buffer for your socket.  That way any resend "bursts" will be kept as small as possible, if only because the TCP stack won't be holding many bytes to resend.</span>
<span class="comment-copy">If I limit that buffer would I have packet loss? Or the socket.send() will block me when there is no more space in the buffer (when congestion for example)</span>
<span class="comment-copy">You'll have packet loss no matter what you do; that's the nature of networking.  What you won't have is data loss, because the TCP layer will keep the outgoing data in memory and retransmit it as many times as necessary until it finally gets through to the remote peer.  (The exception is if things get so bad that the TCP layer finally just gives up and breaks the TCP connection; at that point any pending outgoing bytes will be simply dropped)  (to answer your question:  yes, assuming it's a blocking socket, send() will block when the buffer gets full)</span>
