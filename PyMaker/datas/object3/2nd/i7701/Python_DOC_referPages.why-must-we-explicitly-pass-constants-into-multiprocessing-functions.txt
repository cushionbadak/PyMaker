Natural Text
I have been working with the  package to speed up some geoprocessing (GIS/) tasks that are redundant and need to be done the same for more than 2,000 similar geometries.The splitting up works well, but my "worker" function is rather long and complicated because the task itself from start to finish is complicated. I would love to break the steps apart down more but I am having trouble passing information to/from the worker function because for some reason ANYTHING that a worker function under multiprocessing uses needs to be passed in explicitly. This means I cannot define constants in the body of  and then use them in the worker function. It also means that my parameter list for the worker function is getting really long - which is super ugly since trying to use more than one parameter also requires creating a helper "star" function and then  to rezip them back up (a la the second answer on this question). I have created a trivial example below that demonstrates what I am talking about. Are there any workarounds for this - a different approach I should be using - or can someone at least explain why this is the way it is?Note: I am running this on Windows Server 2008 R2 Enterprise x64. Edit: I seem to have not made my question clear enough. I am not that concerned with how  only takes one argument (although it is annoying) but rather I do not understand why the scope of a function defined outside of  cannot access things defined inside that block if it is used as a multiprocessing function - unless you explicitly pass it as an argument, which is obnoxious. 
The problem is, at least on Windows (although there are similar caveats with *nix  style of multiprocessing, too) that, when you execute your script, it (to greatly simplify it) effectively ends up as as if you called two blank (shell) processes with  and then have them execute:one by one as soon as one of those processes finishes with the previous call. That means that your  block never gets executed (because it's not the main script, it's imported as a module) so anything declared within it is not readily available to the function (as it was never evaluated).For the staff outside your function you can at least cheat by accessing your  via  or even with   but that works only for the evaluated staff, so anything that was placed within the  guard is not available as it didn't even had a chance. That's also a reason why you must use this guard on Windows -  without it you'd be executing your pool creation, and other code that you nested within the guard, over and over again with each spawned process.If you need to share read-only data in your multiprocessing functions, just define it in the global namespace of your script, outside of that  guard, and all functions will have the access to it (as it gets re-evaluated when starting a new process) regardless if they are running as separate processes or not.If you need data that changes then you need to use something that can synchronize itself over different processes - there is a slew of modules designed for that, but most of the time Python's own pickle-based, datagram communicating  (and types it provides), albeit slow and not very flexible, is enough.
Python Â» 3.6.1 Documentation: multiprocessing.pool.Pool There is no Restriction, only it have to be a iterable!Try a , for instance:Note: The  inside the  have to be !  Read about what-can-be-pickled-and-unpickled


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool
https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled
