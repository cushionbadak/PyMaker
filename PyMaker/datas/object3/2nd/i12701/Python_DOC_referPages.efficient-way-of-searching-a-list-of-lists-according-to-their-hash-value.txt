Natural Text
I have a list of tuples with 3 members in each tuple as seen below:The tuples are ordered in ascending according to first element of each tuple - the hash value of each key (e.g ). I want to find a quick way of searching through these tuples using binary search of their hash values to find a specific key. Problem is the quickest way I have found is using a for loop:The function I have written above seems to be very slow at searching through a much longer list of tuples, lets say a list of 6000 different tuples. It also breaks if there are any hash collisions. I was wondering if there was a more efficient/quick way of searching the list for the correct tuple?Side note: I know using dictionaries will be a much quicker and easier way to solve my problem but I'd like to avoid using them.
You could modify    to just check the first element: replicating some collisions, it does what it should:Some timings:To get a better idea you would have to throw in collisions but to find the section that the hash may belong is pretty efficient.Just type casting a few variables and compiling with cython:Gets us almost down to 1 microsecond:
First, prehash the key, don't do it over and over. Second, you can use  with an unpacking generator expression to optimize a bit:That said, you claim you want to do a binary search, but the above is still a linear search, just optimized to avoid redundant work and to stop when the desired key is found (it checks hash first, assuming key comparison is expensive, then checks key equality only on hash match, since you complained about issues with duplicates). If the goal is binary search, and  is sorted by hash code, you'd want to use the  module. It's not trivial to do so (because  doesn't take a  argument like ), but if you could split  into two parts, one with just hash codes, and one with codes, keys and values, you could do:That gets you true binary search, but as noted, requires that the hash codes be separated from the complete s of  ahead of time, before the search. Splitting the hash codes at the time of each search wouldn't be worth it since the loop that split them off could have just found your desired value directly (it would only be worth splitting if you were performing many searches at once).As Padraic notes in his answer, at the expense of giving up the C accelerator code, you could copy and modify the pure Python implementation of  and  changing each use of  to  which would get you  code that doesn't require you to maintain a separate  of hashes. The memory savings might be worth the higher lookup costs. Don't use  to perform the slicing though, as  with a  index iterates the whole  up to that point; true slicing only reads and copies what you care about. If you want to avoid the second  operation though, you could always write your own -optimized  and combine it with  to get a similar effect without having to calculate the  index up front. Code for that might be something like:Note: You could save even more work at the expense of more memory, by having  actually be  pairs; assuming uniqueness, this would mean a single  call, not two, and no need for a scan between indices for a  match; you either found it in the binary search or you didn't. Just for example, I generated 1000 key value pairs, storing them as either  s in a  (which I sorted on the ), or a  mapping s->s. The s were all 65 bit s (long enough that the hash code wasn't a trivial self-mapping). Using the linear search code I provided up top, it took ~15 microseconds to find the value located at index 321; with binary search (having copied hashes only to a separate ) it took just over 2 microseconds. Looking it up in the equivalent  took ~55 _nano_seconds; the run time overhead even for binary search worked out to ~37x, and linear search ran ~270x higher. And that's before we get into the increased memory costs, increased code complexity, and increased overhead to maintain sorted order (assuming  is ever modified).Lastly: You say "I'd like to avoid using [s]", but give no explanation as to why. s are the correct way to solve a problem like this; assuming no self-hashing (i.e.  is an  that hashes to itself, possibly saving the cost of the hash code), the memory overhead just for the  of s (not including a separate  of hash codes) would be (roughly) twice that of a simple  mapping keys to values.  would also prevent accidentally storing duplicates, have ~ insertion cost (even with , insertion maintaining sorted order would have ~ lookup and  memory move costs), ~ lookup cost (vs. ~ with ), and beyond the big-O differences, would do all the work using C built-in functions that are heavily optimized, so the real savings would be greater.
Try using list comprehensions. I'm not sure if it's the most efficient way, but it's the pythonic way and quite effective!


Answer URL
https://docs.python.org/3/library/bisect.html
