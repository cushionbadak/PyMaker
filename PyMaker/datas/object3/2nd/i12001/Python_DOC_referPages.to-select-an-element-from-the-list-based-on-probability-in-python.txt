Natural Text
I needed to write a weighted version of random.choice (each element in the list has a different probability for being selected).  This is what I came up with:This function seems overly complex to me, and ugly.  I'm hoping everyone here can offer some suggestions on improving it or alternate ways of doing this.  Efficiency isn't as important to me as code cleanliness and readability.
Since version 1.7.0, NumPy has a  function that supports probability distributions.Note that  is a sequence in the same order of . You can also use the keyword  to change the behavior so that drawn items are not replaced.

Since Python3.6 there is a method  from  module.And people also mentioned that there is  which support weights, BUT it don't support 2d arrays, and so on. So, basically you can get whatever you like (see update) with builtin  if you have 3.6.x Python.UPDATE: As @roganjosh kindly mentioned,  cannot return values without replacement, as it mentioned in the docs:Return a  sized list of elements chosen from the population with replacement.And @ronan-paixÃ£o's brilliant answer states that  has  argument, that controls such behaviour.
Arrange the weights into acumulative distribution.Use random.random() to pick a randomfloat . Search thedistribution using bisect.bisect asshown in the example at http://docs.python.org/dev/library/bisect.html#other-examples.If you need to make more than one choice, split this into two functions, one to build the cumulative weights and another to bisect to a random point.
If you don't mind using numpy, you can use numpy.random.choice. For example:If you know how many selections you need to make in advance, you can do it without a loop like this:
Crude, but may be sufficient:Does it work?Prints:Assumes that all weights are integers.  They don't have to add up to 100, I just did that to make the test results easier to interpret. (If weights are floating point numbers, multiply them all by 10 repeatedly until all weights >= 1.)
If you have a weighted dictionary instead of a list you can write thisNote that  produces this list 
As of Python ,  could be used to return a  of elements of specified size from the given population with optional weights.population :  containing unique observations. (If empty, raises )weights : More precisely relative weights required to make selections.cum_weights : cumulative weights required to make selections.k : size() of the  to be outputted. (Default )Few Caveats:1) It makes use of weighted sampling with replacement so the drawn items would be later replaced. The values in the weights sequence in itself do not matter, but their relative ratio does.Unlike  which can only take on probabilities as weights and also which must ensure summation of individual probabilities upto 1 criteria, there are no such regulations here. As long as they belong to numeric types ( except  type) , these would still perform.2) If neither weights nor cum_weights are specified, selections are made with equal probability.  If a weights sequence is supplied, it must be the same length as the population sequence. Specifying both weights and cum_weights raises a .3) cum_weights are typically a result of  function which are really handy in such situations.  From the documentation linked: Internally, the relative weights are converted to cumulative weights  before making selections, so supplying the cumulative weights saves  work.So, either supplying  or  for our contrived case produces the same outcome and the latter seems to be more faster / efficient.
Here's is the version that is being included in the standard library for Python 3.6:Source:  https://hg.python.org/cpython/file/tip/Lib/random.py#l340
I'd require the sum of choices is 1, but this works anyway

I'm probably too late to contribute anything useful, but here's a simple, short, and very efficient snippet:No need to sort your probabilities or create a vector with your cmf, and it terminates once it finds its choice. Memory: O(1), time: O(N), with average running time ~ N/2. If you have weights, simply add one line:
A general solution:
If your list of weighted choices is relatively static, and you want frequent sampling, you can do one O(N) preprocessing step, and then do the selection in O(1), using the functions in this related answer.
It depends on how many times you want to sample the distribution. Suppose you want to sample the distribution K times. Then, the time complexity using  each time is  when  is the number of items in the distribution. In my case, I needed to sample the same distribution multiple times of the order of 10^3 where n is of the order of 10^6. I used the below code, which precomputes the cumulative distribution and samples it in . Overall time complexity is .
I looked the pointed other thread and came up with this variation in my coding style, this returns the index of choice for purpose of tallying, but it is simple to return the string ( commented return alternative):
Here is another version of weighted_choice that uses numpy. Pass in the weights vector and it will return an array of 0's containing a 1 indicating which bin was chosen. The code defaults to just making a single draw but you can pass in the number of draws to be made and the counts per bin drawn will be returned.If the weights vector does not sum to 1, it will be normalized so that it does. 
One way is to randomize on the total of all the weights and then use the values as the limit points for each var. Here is a crude implementation as a generator.
Using numpy
I needed to do something like this really fast really simple, from searching for ideas i finally built this template. The idea is receive the weighted values in a form of a json from the api, which here is simulated by the dict.Then translate it into a list in which each value repeats proportionally to it's weight, and just use random.choice to select a value from the list.I tried it running with 10, 100 and 1000 iterations. The distribution seems pretty solid.


Answer URL
https://docs.python.org/3/library/random.html#random.choices
https://docs.python.org/3/library/itertools.html#itertools.accumulate
https://docs.python.org/3/library/random.html#random.choices
