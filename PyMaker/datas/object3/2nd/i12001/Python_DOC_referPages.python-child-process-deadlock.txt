Natural Text
It seems python (python 3) queue will be stuck by large data, see the following example:The above code will cause deadlock on my machine and changing  to  will solve the problem.What is happening here?
Joining the child processes before consuming all the data off the queue can result in deadlock because the child will wait for all data to be removed from the queue before it can terminate. Meanwhile the parent will be blocked waiting for the child to terminate - which can't happen because the parent is not consuming the child's data from the queue.The solution is to join the child processes after the parent has consumed all data from the queue. That includes data that has not been enqueued yet. So just moveto the end of the file and it will work.This is not perfect because you need to make sure that all of the data from the child is removed from the queue. But fortunately it's OK in your case because there is a single  in each child. If there is more than one large "put", the parent process will not collect the second and subsequent "puts" and the deadlock condition will occur.This is explained along with an example in the multiprocessing programming guidelines in the section "Joining processes that use queues".


Answer URL
https://docs.python.org/3/library/multiprocessing.html#programming-guidelines
