Natural Text
We all know that the common way of executing a statement a certain number of times in Python is to use a  loop.The general way of doing this is,I believe nobody will argue that the code above is the common implementation, however there is another option. Using the speed of Python list creation by multiplying references.There is also the old  way.I tested the execution times of these approaches. Here is the code.I would not initiate the subject if there was a small difference, however it can be seen that the difference of speed is 100%. Why does not Python encourage such usage if the second method is much more efficient? Is there a better way?The test is done with Windows 10 and Python 3.6.Following @Tim Peters' suggestion,Which offers a much better way, and this pretty much answers my question. Why is this faster than , since both are generators. Is it because the value never changes?
Usingis the non-obvious way of getting the best of all worlds: tiny constant space requirement, and no new objects created per iteration. Under the covers, the C code for  uses a native C integer type (not a Python integer object!) to keep track of the count remaining.For that reason, the count needs to fit in the platform C  type, which is generally at most  on a 32-bit box, and here on a 64-bit box:Which is plenty big for my loops ;-)
The first method (in Python 3) creates a range object, which can iterate through the range of values. (It's like a generator object but you can iterate through it several times.) It doesn't take up much memory because it doesn't contain the entire range of values, just a current and a maximum value, where it keeps increasing by the step size (default 1) until it hits or passes the maximum.Compare the size of  to the size of : Try It Online!. The former is very memory efficient; it only takes 48 bytes regardless of the size, whereas the entire list increases linearly in terms of size.The second method, although faster, takes up that memory I was talking about in the past one. (Also, it seems that although  takes up 24 bytes and  takes 16, arrays of  of each have the same size. Interesting. Probably because they're pointers)Interestingly enough,  is smaller than  by about 10000, which kind of makes sense because in the first one, everything is the same primitive value so it can be optimized.The third one is also nice because it doesn't require another stack value (whereas calling  requires another spot on the call stack), though since it's 6 times slower, it's not worth that.The last one might be the fastest just because  is cool that way :P I think it uses some C-library optimizations, if I remember correctly.
The first two methods need to allocate memory blocks for each iteration while the third one would just make a step for each iteration.Range is a slow function, and I use it only when I have to run small code that doesn't require speed, for example, . I think you can't compare the three methods; they are totally different.According to a comment below, the first case is only valid for Python 2.7, in Python 3 it works like xrange and doesn't allocate a block for each iteration. I tested it, and he is right.
This answer provides a loop construct for convenience. For additional background about looping with  look up Tim Peters' answer above, Alex Martelli's answer here and Raymond Hettinger's answer here.


Answer URL
https://docs.python.org/3/library/stdtypes.html#typesseq-range
https://docs.python.org/3/library/stdtypes.html#typesseq-range
