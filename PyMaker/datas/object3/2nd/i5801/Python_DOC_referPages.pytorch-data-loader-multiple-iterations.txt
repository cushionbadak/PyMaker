Natural Text
i use iris-dataset to train a simple network with pytorch.the dataset itself has only 150 data points, and pytorch dataloader iterates jus t once over the whole dataset, because of the batch size of 150.My question is now, is there generally any way to tell dataloader of pytorch to repeat over the dataset if it's once done with iteration? thnaksupdategot it runnning :)just created a sub class of dataloader and implemented my own 
The simplest option is to just use a nested loop:Another option would be to use itertools.cycle, perhaps in combination with itertools.take.Of course, using a DataLoader with batch size equal to the whole dataset is a bit unusual. You don't need to call iter() on the trainloader either.
Using itertools.cycle has an important drawback, in that it does not shuffle the data after each iteration:When the iterable is exhausted, return elements from the saved copy.This can negatively affect the performance of your model in some situations. A solution to this can be to write your own cycle generator:Which you would use as:
if you use tqdm, the best solution is:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.cycle
https://docs.python.org/3/library/itertools.html#itertools.cycle
