Natural Text
I need to download many files from a single folder in a single server and so I'm looking for a way to do it quicker. After a little bit of reading it seems that either a multi-threading or asynchronous approach would work, but I can't seem to get either approach to work.The async approach I'm using is below. This works, i.e. no errors, but it only downloads one file at a time, and so doesn't improve speed. Is there away to modify it so that I do improve speed?Then I tried using the simple Pool() func in multiprocessing as below:But this fails with an error. I'll update with that error as soon as I'm back at the server.
For the async approach, you will want to build a list of files to download and call them concurrently. You are only calling simple_get once so there is only 1 instance of the download running. See this example as @Klas-d mentioned.
I'm author of . The reason you actually can't speed up download for ftp is that ftp session have limit of exactly one data connection, so you can't download multiple files via one client connection at same time, only sequential. Also, your code will not work, because you use lazy . If you want to try speed up your download, then you need multiple client sessions, but if server do not throttle download speed, than you have no speed up.


Answer URL
https://docs.python.org/3/library/asyncio-task.html#example-parallel-execution-of-tasks
https://docs.python.org/3/library/asyncio-task.html#example-parallel-execution-of-tasks
