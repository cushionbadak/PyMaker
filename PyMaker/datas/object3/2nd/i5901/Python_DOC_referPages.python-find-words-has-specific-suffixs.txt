Natural Text
I am dealing with Chinese NLP Problem.I find to find word has specific suffixs. For example, I have two list!I know I can use re package, but re just can deal with less than 100 suffixs,but I have 1000+ suffixs.I try to useBut it is too slow.The func(s,w) could split the word w to no_suffix word and suffix.For example 'oneaaa' to ['one','aaa']ï¼Œbut the func bases on some condition and more complex.So any doesn't work here.So I want to know whether a better way to deal with it.
If you just wan to see which words have "back-fixes" (the correct term is suffix, BTW), you can just use  in combination with Or pass all the suffixes to , but for that they have to be in a , not :If you also need to know which suffix matches, you can get the , or  if non match:              Or shorter using : Or without default, using :


Answer URL
https://docs.python.org/3/library/stdtypes.html#str.endswith
