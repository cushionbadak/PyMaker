Natural Text
Trying to better understand multiprocessing and how it can be used for below scenario.I have a folder of 100,000 images. I have a python script that takes each image, performs some operations on the image and stores the result into another directory. It takes 5 seconds for each operation on the image. My question is as follows - When my script is executing on a single image. If I look at cpu statistics using the top command , I can see that neither my cpu or my memory are at 100% ( this is a multi core processor) Moreover I am able to process more images per minute by simply starting many python scripts in different shells. What is the pythonic way to perform this task in a faster way? If the number of images increase how can I scale this horizontally? Any resources / comments would be helpful. 
you can use  library to concurrently process images. You simply define an event-loop, register tasks into the event loop, and thats all. The system decides which one to run next. When a task is I/O bound (in your case, storing the value to somewhere within the system), or awaiting a response from somewhere, the system picks another task from the event loop instead of waiting, and so on.https://docs.python.org/3/library/asyncio.html
the I/O operations of open/read/write files are the ones that causes your cpu to be idle when processing image it usually a matrices multiplications and takes a lot of cpu resources and can be done in parallel based on the cpu cores (gives or takes 2*cores)my suggestion is to use different threads pool based on the task, for handling file you can create as many threads as you want without much performance downgrade, but processing the image i.e making computation with the byte array can be scaled as much as cpu cores, above that you should notice performance downgrade I suggest using the worker-queue pattern describe hereyou can also take a look at event loop implementation that might produce better results due to it's nature of non-blocking, you can find example herekeep in mind to fully utilise the cpu cores you should create multiple threads of event loops, one (or two) per core, the threads are scaled automatically (most os) on the cpu cores  
You could make use of  () - it is a general purpose multiprocessing wrapper:where  is how many processes will be used. The result will be the list of returned values of the image_worker, i.e. a list of Nones.cf: binge documentation


Answer URL
https://docs.python.org/3/library/asyncio.html
https://docs.python.org/3/library/multiprocessing.html
