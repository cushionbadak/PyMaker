Natural Text
I am using scrapy to crawl a site which seems to be appending random values to the query string at the end of each URL. This is turning the crawl into a sort of an infinite loop.How do i make scrapy to neglect the query string part of the URL's?
See urllib.urlparseExample code:Example output:
There is a function  in  module (used by scrapy itself) to clean urls keeping only a list of allowed arguments.
Provide some code, so we can help you.If you are using  and 's with , provide custom function to  parameter of  constructor.See documentation for BaseSgmlLinkExtractor
You can use the  function. The result is a structured parse result, a named tuple with added functionality.Use the  method to alter the parsed result values, then use the  method to get a URL string again.To remove the query string, set the  value to :Demo:For Python 2, the same function is available under the  name.You could also use the  function; for URLs without any path parameters, the result would be the same. The two functions differ in how path parameters are handled;  only supports path parameters for the last segment of the path, while  leaves path parameters in place in the path, leaving parsing of such parameters to other code. Since path parameters are rarely used these days [later URL RFCs have dropped the feature altogether), the difference is academical.  uses  and without parameters, doesn't add anything other than extra overhead. It is better to just use  directly.
If you are using BaseSpider, before yielding a new request, remove manually random values from the query part of the URL using urlparse:
use this method to remove query string from urloutput will be:http://url.something.com/bla.html


Answer URL
https://docs.python.org/3/library/urllib.parse.html
https://docs.python.org/3/library/urllib.parse.html#urlparse-result-object
https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urllib.parse.SplitResult.geturl
https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlparse
