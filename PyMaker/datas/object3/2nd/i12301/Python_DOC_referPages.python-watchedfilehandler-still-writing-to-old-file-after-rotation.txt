Natural Text
I've been using WatchedFileHandler as my python logging file handler, so that I can rotate my logs with  (on ubuntu 14.04), which you know is what the docs say its for. My  config files looks likeEverything seemed to be working just fine. I'm using logstash to ship my logs to my elasticsearch cluster and everything is great. I added a second log file for my debug logs which gets rotated but is not watched by logstash. I noticed that when that file is rotated, python just keeps writing to  and never starts writting to the new file. If I manually tail , it switches over instantly  and starts writing to .This seems REALLY weird to me.I believe what is happening is that logstash is always tailing my non-debug logs, which some how triggers the switch over to the new file after  is called. If  is called twice without a switch over, the log.1 file gets moved and compressed to log.2.gz, which python can no longer log to and logs are lost.Clearly there are a bunch of hacky solutions to this (such as a cronjob that tails all my logs every now and then), but I feel like I must be doing something wrong.I'm using  and  instead of  for a number of reasons, but mainly because it will nicely compress my logs for me after rotation.UPDATE:I tried the horrible hack of adding a manual tail to the end of my log rotation config script.Sure enough this works most of the time, but randomly fails sometimes for no clear reason, so isn't a solution. I've also tried a number of less hacky solutions where I've modified the way  checks if the file has changed, but no luck.I'm fairly sure the root of my problem is that the logs are stored on a network drive, which is somehow confusing the file system.I'm moving my rotation to python with , but if anyone knows the proper way to handle this I'd love to know.
Use  option of logrotate. From docscopytruncateTruncate  the  original log file in place after creating a copy, instead of moving the old log file and optionally creating a new one,  It  can be used when some program can not be told to close its logfile and thus might continue writing (appending)  to  the previous log file forever.  Note that there is a very small time slice between copying the file and truncating it, so  some  logging  data  might be lost.  When this option is used, the create option will have no effect, as the old log file stays in  place.
 does a rollover when a device and/or inode change is detected in the log file just before writing to it. Perhaps the file which isn't being watched by  doesn't see a change in its device/inode? That would explain why the handler keeps on writing to it.


Answer URL
https://docs.python.org/3/library/logging.handlers.html#watchedfilehandler
