Natural Text
I have a speed/efficiency related question about Python:I need to extract multiple fields from a nested JSON File (after writing to the  files, they have ~64k lines and the current snippet does it in ~ 9 mins),where each line can contain floats and strings.Normally, I would just put all my data in  and use  to save it.. I have resorted to simply assembling the lines as strings, but this is a tad slow. So far I'm doing:Assemble each line as a string(extract the desired field from JSON)Write string to the concerned fileI have several problems with this: - it's leading to more separate  commands, which are very slow as well..(around 64k * 8 calls (for 8 files))So my question is: What is a good routine for this kind of problem? One that balances out  for most efficient writing to disk.Should i increase my ? (its currently 8192)I have checked this File I/O in Every Programming Language and this python org: IO but didn't help much except(in my understanding after going through it, file io should already be buffered in python 3.6.x) and I found that my default  is .Thanks in advance for the help!!Here's the part of My Snippet - 
From comment: why do you think that 8 writes result in 8 physical writes to your harddisk? The file object itself buffers what to write, if it decides to write to your OS, your OS might as well wait a little until it physically writes - and even then your harrdrives got buffers that might keep the files content for a while until it starts to really write. See How often does python flush to a file?You should not use exceptions as control flow, nor recurse where it is not needed. Each recursion prepares new call stacks for the function call - that takes ressources and time - and all of it has to be reverted as well.The best thing to do would be to clean up your data before feeding it into the json.load() ... the next best thing to do would be to avoid recursing ... try something along the lines of:


Answer URL
https://docs.python.org/3/library/io.html
