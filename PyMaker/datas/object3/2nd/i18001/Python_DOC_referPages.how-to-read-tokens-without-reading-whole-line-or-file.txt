Natural Text
Is there a well-hidden way to read tokens from a file or file-like object without reading entire lines?  The application I immediately have (someone else's problem, not mine) is transposing a large matrix with a few very long rows, essentially performing an  on iterators that pick out the elements of a single column.  The idea is not not have the entire file in memory during iteration.The rows are space-delimited ASCII decimal numbers.The problem would be simple with Java's Scanner class, but I don't see anything in the Python Standard Library that appears to tokenize without having the whole input in a string.For the record, I know how to write this on my own.  I'm just wondering if there's a standard tool that I missed.  Something FOSS/libre that can be EasyInstalled is good, too, but I don't see anything on PYPI either.The full problem was to take the sample input:...and produce the output (as a generator, without reading all of very long rows into memory at once:As I said, it's essentially itertools.izip(iterator1, iterator2), pointing iterator1 at the start of the file, and iterator2 just past the newline to read the second row.
To read tokens from a file one by one; you could use  module to generate tokens from a memory-mapped file:It works even if the file doesn't fit in memory.    
Here is a generator that processes a file one character at a time and yields tokens when whitespace is encountered.To be more generic, it looks like you might be able to use the  module as described at this link. Just feed the input with a generator from your file to avoid reading the whole file at once.Python equivalent of ruby's StringScanner?
You can read file in chunks with . I would not recomment however to read by 1 byte, as this will drastically affect performance. Following snippet (not much tested, use on your own risk) reads file in chunks an yields numbers. You'll have to read through file first to determine rows starting position though.


Answer URL
