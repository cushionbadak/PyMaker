Natural Text
I have a dictionary with 500 DateFrames in it. Each data frame has columns 'date' , 'num_patients'. I apply the model to all the data frames in the dictionary, but Python kernel crash due to large data in the dictionary.  So, then I've subsetted the dictionary and applied the model to each subset.  But I will need to run the code above for 10 times since I have 500 DataFrames (10 subsets). Is there a more efficient way to do this?  
One immediate improvement is to drop the sorted() and slicing step and replace it with heapq.nsmallest() which will do many fewer comparisons.  Also, the  is not necessary since dicts automatically iterate over their keys by default.Replace:With:The big for-loop in your code looks to only need  instead of  since key doesn't seem to be used.


Answer URL
https://docs.python.org/3/library/heapq.html#heapq.nsmallest
