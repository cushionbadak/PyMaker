Natural Text
I have a very large (say a few thousand) list of partitions, something like:What I want to do is apply to each of them a function (which outputs a small number of partitions), then put all the outputs in a list and remove duplicates. I am able to do this, but the problem is that my computer gets very slow if I put the above list directly into the python file (esp. when scrolling). What is making it slow? If it is memory being used to load the whole list, Is there a way to put the partitions in another file, and have the function just read the list term by term? EDIT: I am adding some code. My code is probably very inefficient because I'm quite an amateur. So what I really have is a list of lists of partitions, that I want to add to:fock, lowering1, partition are all functions in earlier code, they are pretty simple functions. The above function, say addtolist(24), takes all the partition of 21 that I have and returns the desired list of partitions of 24, which I can then append to the end of listofparts3.
A few thousand partitions uses only a modest amount of memory, so that likely isn't the source of your problem.One way to speed-up function application is to use map() for Python 3 or itertools.imap() from Python 2.The fastest way to eliminate duplicates is to feed them into a Python set() object.


Answer URL
https://docs.python.org/3/library/functions.html#map
https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset
