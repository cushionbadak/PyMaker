Natural Text
I am facing a pretty odd issue. I have multi process python code that processes some data in parallel. I split the data in to 8 and work on each split individually using a Process Class, I then do a join on each Process.I just noticed that when I process a large amount of data, one of the threads.... disappears. As in it doesn't error out or raise an exception and it just goes missing. What is even more interesting is that it seems to successfully complete the join() on the process when I know for a fact it did not finish. What do I know for sure:All Processes are starting and are processing data and reach about half way, I know this because I have logs that show all the Processes doing their work. Then Process 1 disappears from the logs towards the end of it's job, while all the other ones keep working fine and completing. Then My code moves on after thinking all the Processes are complete after the joins (I demonstrate this with a print) however I know for a fact that one of the processes did not complete, it did not error out and for some strange reason it passed the join()?The only thing I can think of is that the Process runs out of memory but I would feel it would error out or throw an exception if this happened. Actually it has happened to me before using the same code and I saw the exception in my logs and the code was able to handle and see that the Process failed. But this, no error or anything is strange. Can anyone shed some light?Using Python3.4
If I remember correctly when a process abruptly terminates it wouldn't throw an error, you need to have another  for storing the thrown exceptions and handle them elsewhere. When a process ends however, an exit code is given: https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.exitcodeA rudimentary check would be making sure all of them safely exited (probably with  as exit code, while negative indicates termination signal and  as running).
The issue was that the python was running out of memory. The only way I knew this is that I monitored the machine's memory usage while the code was running and it needed more space than was available so one of the processes was just killed with no errors or exceptions. @j4hangir's answer of how to avoid this is good, I need to check the exit code. I haven't tested this yet but I will and then update


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Process.exitcode
