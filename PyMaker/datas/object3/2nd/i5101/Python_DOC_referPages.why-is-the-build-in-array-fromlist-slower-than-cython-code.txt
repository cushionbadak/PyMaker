Natural Text
Often, when gluing Python and C-code together, one needs to convert a Python-list to a continuous memory, e.g. an . It's also not unusual, that this conversion step becomes the bottle-neck, so I find myself doing silly things with Cython because it is faster than the build-in Python solutions.For example to convert a Python-list  to an  continuous memory I'm aware of two possibilities: andThey are however both slower than the following cython-version:My timings show (Linux, Python3.6 but the results are very similar for Windows and/or Python2.7), that the cython-solution is about 6 times faster:With my limited understanding of CPython, I would say that the -solution uses this build-in function: grows dynamically and needs to reallocate, so that could explain some slow-down (yet as the measurements show, not by much!), but  preallocates the needed memory - it is basically exactly the same algorithm as the Cython-code. So the question: Why is this Python-code 6 times slower than the Cython-code? What am I missing?Here is the code for measuring timings:The numpy-solution is about factor 2 slower than the python-versions.
The biggest difference seems to be the actual int unboxing.  The CPython array implementation is using PyArg_Parse while cython is calling PyLong_AsLong - at least I think, through several layers of macros.


Answer URL
https://docs.python.org/3/c-api/long.html#c.PyLong_AsLong
