Natural Text
I am new to Python and figured I'd play around with problems on Project Euler to have something concrete to do meanwhile. I came across the idea of timing different solutions to see how they rate against each other. That simple task turned out to be too complicated for my taste however. I read that the  calls are not accurate enough on unix systems (seconds resolution is simply pathetic with modern processors). Thus I stumbled upon the  module which seems to be the first choice for profiling tasks. I have to say I really don't understand why they went with such a counter-intuitive way to go about it. I can't seem to get it to work, without needing to rewrite/restructure my code, which I find very frustrating. Take the code below and nevermind for a second that it's neither pretty nor particularly efficient:If i would like to time the line  why should I go through a bunch of loops, trying to define a setup statement etc.. I understand why one would want to have debug tool that are detached from the code being tested (a la unit testing) but shouldn't there be a simple and straightforward way to get the process time of a chunk of code without much hassle (importing/defining a setup etc)? What I am thinking here is something like the way one would do that: .. or even better with MATLAB, using the tic/toc commands:Hope this doesn't come across as a rant, I am really trying understand "the pythonian way of thinking" but honestly it doesn't come naturally here, not at all...
When timing a statement, you want to time just that statement, not the setup. The setup could be considerably slower than the statement-under-test.Note that  runs your statement thousands of times to get a reasonable average. It does this to eliminate the effects of OS scheduling and other processes (including but not limited to disk buffer flushing, cronjob execution, memory swapping, etc); only an average time would have any meaning when comparing different code alternatives.For your case, just test  directly, and just use the  function:The setup code retrieves the  function, as well as  taken from  from the main script; the function and number won't otherwise be seen.There is absolutely no point in performance testing the  statement, that's not what you are trying to time. Using  is not about seeing the result of the call, just the time it takes to run it. Since the code-under-test is run thousands of times, all you'd get is thousands of prints of (presumably) the same result.Note that usually  is used to compare performance characteristics of short python snippets; to find performance bottlenecks in more complex code, use profiling instead.If you want to time just one run, use the  function to get the most accurate timer for your platform:
Simple, the logic behind the statement and setup is that the setup is not part of the code you want to benchmark. Normally a python module is loaded once while the functions inside it are run more than one, much more.A pythonic way of use ?As you can see, the way  works is much more intuitive than you think.Edit to add:I read that the time.clock() calls are not accurate enough on unix  systems (seconds resolution is simply pathetic with modern  processors).quoting the documentation:On Unix, return the current processor time as a floating point number  expressed in seconds. The precision, and in fact the very definition  of the meaning of “processor time”, depends on that of the C function  of the same name, but in any case, this is the function to use for  benchmarking Python or timing algorithms... The resolution is  typically better than one microsecond.going on..I have to say I really don't understand why they went with such a  counter-intuitive way to go about it. I can't seem to get it to work,  without needing to rewrite/restructure my code, which I find very  frustrating.Yes, it could be but then this is one of those cases where documentation can help you, here a link to the examples for the impatiens. Here a more gentle introduction to .


Answer URL
