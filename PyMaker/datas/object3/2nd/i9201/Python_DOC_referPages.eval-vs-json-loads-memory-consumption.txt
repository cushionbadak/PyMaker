Natural Text
I have a dictionary that I am writing to a file and then loading it again. The dictionary has some sets, so I have the option of either doing an  or  with a custom ModelEncoder. I tried both and  has a much smaller memory footprint than  does. Why does  take up so much more memory?
Whether or not you should be using  is really another question.The primary reason  takes more memory is the text is first compiled into a python expression (parsed, converted to byte code) and then evaluated.Especially with large literals, python has a memory leak in the bytecode compiler.  This issue talks about pyc compilation, but you'll also hit it with code compilation in eval.json doesn't suffer from this because it's not converting your text into executable bytecode.


Answer URL
https://docs.python.org/3/library/pickle.html
