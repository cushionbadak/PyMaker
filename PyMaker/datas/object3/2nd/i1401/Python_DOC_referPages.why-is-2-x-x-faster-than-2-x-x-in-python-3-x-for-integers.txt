Natural Text
The following Python 3.x integer multiplication takes on average between 1.66s and 1.77s:if I replace  with , it takes between  and . How come?On the other hand it is the opposite in Java:  is faster in Java. Java test link: Why is 2 * (i * i) faster than 2 * i * i in Java?I ran each version of the program 10 times, here are the results.
First of all, note that we don't see the same thing in Python 2.x:So this leads us to believe that this is due to how integers changed in Python 3: specifically, Python 3 uses  (arbitrarily large integers) everywhere.For small enough integers (including the ones we're considering here), CPython actually just uses the O(MN) grade-school digit by digit multiplication algorithm (for larger integers it switches to the Karatsuba algorithm). You can see this yourself in the source.The number of digits in  is roughly twice that of  or  (since log(x2) = 2 log(x)). Note that a "digit" in this context is not a base-10 digit, but a 30-bit value (which are treated as single digits in CPython's implementation). Hence,  is a single-digit value, and  and  are single-digit values for all iterations of the loop, but  is two-digit for . Hence, for ,  only requires single-by-single-digit multiplications whereas  requires a single-by-single and a single-by-double-digit multiplication (since  has 2 30-bit digits).Here's a direct way to see this (Python 3):Again, compare this to Python 2, which doesn't use arbitrary-length integers everywhere:(One interesting note: If you look at the source, you'll see that the algorithm actually has a special case for squaring numbers (which we're doing here), but even still this is not enough to overcome the fact that  just requires processing more digits.)
Python intern representation of integers is special, it uses slots of 30 bits :So everything happens as if Python counts in base .For a human who want to calculate 2*4*4, two ways :(2*4)*4 = 8*4 =32 = 30 + 2 is immediate if you knows your add tables.2*(4*4) = 2*16 = 2*10 + 2*6 = (2*10+10) + 2 = 30 + 2 since we have to put the operation down.  Python have the same problem. If  is a number such than  , let  , with .  is stored in 2 slots, which I note .  Computations leads to (without managing carries here):in the first case  the  operation is done two times, against only one in the  first case. That  explains the difference.
If your benchmark is right (didn't check), it may come from the fact that Python  integers may be two different things : native integers when they are small (with a quick computation), and big integers when they increase in size (slower computation). The first syntax keeps the size smaller after the first operation while the second syntax may lead to two operations involving big integers.
From what I can tell, it comes down to a little bit more memory access in the version using . I printed the disassembled bytecode and it seems to prove that:Relevant part of :Relevant part of :


Answer URL
https://docs.python.org/3/library/timeit.html
