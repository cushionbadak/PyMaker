Natural Text
I got a working function for compressing multiple files into one zip file But it is very slow to run since I got lots of file. So I'm looking for a way to optimize this loop with multi-processing capability in python, like OpenMP.Thanks for any advice.
You can refer - Python Module of the Week
I doubt that multiprocessing would help here.The  module in the Python stdlib is not thread safe!!!Thus, how shall we optimize your code?ALWAYS profile before and while performing optimizations.Because I don't know your file structures. I take the python source code for example.Then, let's try the zip command shipped with Ubuntu.(info-zip).Your can specify the compression level for the zip command. -1 indicates the fastest compression speed (less compression) and -9 indicates the slowest compression speed. The default compression level is -6.You see, the performance of python's zlib module is very competitive. But there are some professional zip tools could give you more control on the compression strategy.You can call those external command with the subprocess modules in python.Besides, when you use the python code above to zip a directory, You'll lose the metadata (permission bits, last access time, last modification time ...)of the directory and its subdirectories.


Answer URL
https://docs.python.org/3/library/multiprocessing.html
