Natural Text
I have a large program (specifically, a function) that I'm attempting to parallelize using a  and the multiprocessing  method. The function that I'm working with does several operations on multidimensional arrays, so I break up each array into sections, and each section evaluates independently; however I need to stitch together one of the arrays early on, but the "stitch" happens before the "evaluate" and I need to introduce some kind of delay in the JoinableQueue. I've searched all over for a workable solution but I'm very new to multiprocessing and most of it goes over my head.This phrasing may be confusing- apologies. Here's an outline of my code (I can't put all of it because it's very long, but I can provide additional detail if needed)
I'm pretty sure that your issue is how you're creating the s and trying to share them with the child processes. If you just have them as global variables, they may be recreated in the child processes instead of inherited (the exact details depend on what OS and/or context you're using for ).A better way to go about solving this issue is to avoid using  to spawn your processes and instead explicitly create  instances for your workers yourself. This way you can pass the  instances to the processes that need them without any difficulty (it's technically possible to pass the queues to the  workers, but it's awkward).I'd try something like this:If the different stages of your worker function are more or less independent of one another (that is, the "do many more operations" step doesn't depend directly on the "do several operations" step above it, just on ), you might be able to keep the  and instead split up the different steps into separate functions, which the main process could call via several calls to  on the pool. You don't need to use your own s in this approach, just the ones built in to the Pool. This might be best especially if the number of "sections" you're splitting the work up into doesn't correspond closely with the number of processor cores on your computer. You can let the  match the number of cores, and have each one work on several sections of the data in turn.A rough sketch of this would be something like:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
