Natural Text
I'm new and studying machine learning. I stumble upon a tutorial I found online and I'd like to make the program work so I'll get a better understanding. However, I'm getting problems about loading the CSV File into the Jupyter Notebook. I get this error:and here is the code: I followed tutorials online regarding this error but none worked. Does anyone know how to fix it? 3rd attempt with r"path"I've tried also "\" and utf-8 but none worked. I'm using the latest version of AnacondaWindows 7Python 3.7
Use raw string notation for your Windows path. In python '\' have meaning in python. Try instead do string like this r"path":If it doesnt work try this way:
Either replace all backslashes  with frontslashes  or place a  before your filepath string to avoid this error. It is not a matter of your folder name being too long.As Bohun Mielecki mentioned, the  character which is typically used to denote file structure in Windows has a different function when written within a string.From Python3 Documentation: The backslash  character is used to escape characters that otherwise have a special meaning, such as newline, backslash itself, or the quote character.How this particularly affects your statement is that in the line matches the escape sequence  whereby  refers to a . Because of this, Python tries to find a 32-bit hex value. However as the  from  doesn't match the  format, you get the error:SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in   position 2-3: truncated \UXXXXXXXX escapeThe reason why your code works now is that you have placed a  in front of . This tells python not to process the backslash character  as it usually does and read the whole string as-is. I hope this helps you better understand your problem. If you need any more clarification, do let me know.Source: Python 3 Documentation
Try
I found the problem. The problem is my folder name that is really long. I changed my folder name into "project" and the data is now finally loaded! Silly!


Answer URL
https://docs.python.org/3/reference/lexical_analysis.html#string-and-bytes-literals
