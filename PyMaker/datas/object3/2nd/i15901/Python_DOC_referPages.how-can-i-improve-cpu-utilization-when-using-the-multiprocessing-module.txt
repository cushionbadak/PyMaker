Natural Text
I am working in Python 3.4, performing a naive search against partitioned data in memory, and am attempting to fork processes to take advantage of all available processing power.  I say naive, because I am certain there are other additional things that can be done to improve performance, but those potentials are out of scope for the question at hand.  The system I am testing on is a Windows 7 x64 environment.What I would like to achieve is a relatively even, simultaneous distribution across  cores (reading suggests that distributing against all cores rather than n-1 cores does not show any additional improvement due to baseline os system processes). So 75% pegged cpu Usage for a 4 core machine. What I am seeing (using windows task manager 'performance tab' and the 'process tab') is that I never achieve greater than 25% system dedicated cpu utilization and that the process view shows computation occurring one core at a time, switching every few seconds between the forked processes.I haven't instrumented the code for timing, but I am pretty sure that my subjective observations are correct in that I am not gaining the performance increase I expected (3x on an i5 3320m).I haven't tested on Linux.Based on the code presented:- How can I achieve 75% CPU utilization?
You're actually not doing anything concurrently here, because you're using , which will block until the task you pass to it is complete. So, for every item in , you're running  in some process inside of , waiting for it to complete, and then moving on to the next item. That perfectly coincides with what you're seeing in the Windows process manager. You want  instead:Or better yet, use  (along with  to enable passing multiple arguments to our worker function):


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map
https://docs.python.org/3/library/functools.html#functools.partial
