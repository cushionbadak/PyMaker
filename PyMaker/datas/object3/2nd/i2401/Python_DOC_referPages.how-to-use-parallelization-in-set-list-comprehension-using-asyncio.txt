Natural Text
I want to create a multiprocess comprehension in Python 3.7.Here's the code I have:In this code example, I want to remove non-existing URLs from a list. (Note that I'm using a set instead of a list because I also want to remove duplicates).My issue is that I still see that the execution is sequential. HTTP Requests make the execution wait.When compared to a serial execution, the execution time is the same.Am I doing something wrong?How should these await/async keywords be used with python comprehension?
 itself doesn't run different  functions concurrently. However, with the  module's , you can schedule functions to run in another process:
 does not support . If you want to go for true asynchronous execution, you will have to look at libs like aiohttp or asksYour set should be built before offloading to the tasks, so you don't even execute for duplicates, instead of streamlining the result.With  itself, you can fall back to  which will execute your requests inside a ThreadPoolExecutor, so not really asynchronous I/O:OutputAs you can see, there is a penalty from initializing the thread pool, ~2.3 seconds in this case. However, given that fact that each of the three tasks runs for ten seconds until timeout on my box (my IDE is not allowed through the proxy), an overall of twelve seconds execution time looks quite concurrent.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor
