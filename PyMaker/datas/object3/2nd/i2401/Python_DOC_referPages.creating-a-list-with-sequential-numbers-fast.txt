Natural Text
When I timed both actions to fill the list, I get 14 seconds for using for loop and 0.5 seconds for So it seems it is obvious to use the second method if I need to insert massive amount of items at once.But if I do the second thing, I have to insert the same number for all, or manually type  numbers that will repeat.Is there a way to performthis action resulting in [0,1,2,3,...,n] with good speed?The code doesn't necessarily have to be short if the speed is fast.
For full portability,  will get the best performance as Prune notes. That said, if you're purely targeting Python 3.5 or higher, you can use PEP 448's additional unpacking generalizations to speed it up a small amount, with:Note that this is a fixed savings, not per-item; all it does is bypass the lookup of  in the built-in namespace, and the generalized function call dispatch and  argument processing of the normal  constructor. So when you're talking about 100 million items, the savings are going to be lost in the noise; all this does is reduce the fixed overhead by (on my 3.6 install) 170Â±10 ns (e.g.  takes 417 ns per call, vs. 247 ns per call for ).In specific cases though, there is an even faster option:In modern Python,  objects are full fledged sequences, they're just not mutable. So you can construct them, index them, slice them, compute their length, iterate them forwards and backwards, check membership (in  for s, unlike  where membership testing is ), etc. The only non-mutability related features they lack are concatenation and repetition (with  and ), though you can simulate that with  functions like  (for concatenation), and ing a  (for repetition).If you don't need to mutate the sequence, just read from it, using the  "raw" is by far the best option; s are lazy, consuming no memory, while still producing their values extremely efficiently. That laziness can be important;  will require (on 64 bit Python) 3.45 gigabytes of memory for the  itself plus all the s it contains;  requires 48 bytes. The trivial cost of generating the values on the fly is more than worth it, given the memory savings.If you need mutability, you can still save a bit on memory. If  is an option, sacul's answer has you covered; if not, Python's array module will save you a little bit of time, and a lot of memory. Compared to:the  alternative:takes about 10% less time (microbenchmarks had  at 3.39 sec, vs.  at 3.07 sec), and consumes far less memory (under ~391 MB, vs. the ~3529 MB of the  of s). The main cost of  is limited range of values (e.g. for , four byte s can only store values in ; the maximum range for / format codes, using twice the memory, would be /).
Since you say you need speed, I think that  is the best way to go, it's even faster than creating the list of all s. Here are the timings on my machine:Note that  returns a . If you need to convert it back to a list, you lose the speed. Better to just use the array...
Try making a list of the  output:I added this to your tests and got these times:


Answer URL
https://docs.python.org/3/library/stdtypes.html#typesseq-range
https://docs.python.org/3/glossary.html#term-sequence
https://docs.python.org/3/library/itertools.html
https://docs.python.org/3/library/itertools.html#itertools.chain
https://docs.python.org/3/library/itertools.html#itertools.islice
https://docs.python.org/3/library/itertools.html#itertools.cycle
https://docs.python.org/3/library/array.html
