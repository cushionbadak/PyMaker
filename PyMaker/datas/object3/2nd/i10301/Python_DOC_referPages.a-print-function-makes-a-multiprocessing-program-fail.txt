Natural Text
In the following code, I'm trying to create a sandboxed master-worker system, in which changes to global variables in a worker don't reflect to other workers.To achieve this, a new process is created each time a task is created, and to make the execution parallel, the creation of processes itself is managed by .This program works fine, until I put the  function inside the loop.  If the function exists, some tasks remain unfinished, and what is worse, this program itself doesn't finish.Results are not always the same, but the following is the typical output:Why is this program so fragile?I use Python 3.4.5.
Try usingIf you search Stackoverflow for python multiprocessing and multithreading you will find a a fair few questions mentioning similar hanging issues. (esp. for python version 2.7 and 3.2)Mixing multithreading and multiprocessing ist still a bit of an issue and even the python docs for multiprocessing.set_start_method mention that. In your case 'spawn' and 'forkserver' should work without any issues.Another option might be to use MultiProcessingPool directly, but this may not be possible for you in a more complex use case.Btw. 'Not Finished' may still appear in your output, as you are not waiting for your sub processes to finish, but the whole code should not hang anymore and always finish cleanly.
You are not creating ThreadPoolExecutor every time , rather using the pre initialized pool for every iteration. I really not able to track which print statement is hindering you?


Answer URL
https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
