Natural Text
I would like to exec() a script with a custom  for that script, and letting it import modules without caching those modules into the builtin .I dont want to pollute the current interpreter  and , because different scripts are going to be executed simultaneously in a multithreaded  environment.So different scripts would be running simultaneously, with different paths each, importing different modules, but with possibly clashing names (thats why they need to run from different paths).I thought that giving a different globals dictionary to each exec() would be enough, but the builtin sys module instance is actually shared among then.Any ideas on how can I achieve that?Note: I dont require a full sandbox solution - my scripts are from a trusted source, I just would like to run them all concurrently.
As @Rufflewind suggested in the comments, I ended up using the multiprocessing library. Each script is actually started on its own  instance. This library spawns another python interpreter process for each object, and thus, allows me to use different paths and modules, without interfering with the main script. The progress of the child process is shared with the main process by a  object. Because I am using a logging handler to write log records to a file, I have also used  to send these log records, generated on the child process, back to the main process. These records are then retrieved using a  object.Well, it turned out to be quite simple, indeed. =) 


Answer URL
https://docs.python.org/3/library/multiprocessing.html
