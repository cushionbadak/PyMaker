Natural Text
From doc: https://docs.python.org/3/library/asyncio-stream.html#asyncio.StreamWriter.writewrite(data)coroutine drain()From what I understand, You need to call  every time  is called.If not I guess,  will block the loop threadThen why is write not a coroutine that calls it automatically? Why would one call  without having to drain? I can think of two casesYou want to  and  immediatelyYou have to buffer some data before message it is complete. First one is a special case, I think we can have a different api. Buffering should be handled inside write function and application should not care.Let me put the question differently. What is the drawback of doing this? Does the python3.8 version effectively do this?Note:  doc explicitly states the below:When there is nothing to wait for, the drain() returns immediately.Reading the answer and links again, I think the the functions work like this. Note: Check accepted answer for more accurate version.So when to use what:When the data is not continuous, Like responding to a HTTP request. We just need to send some data and don't care about when it is reached and memory is not a concern - Just use Same as above but memory is a concern, use When streaming data to a large number of clients (e.g. some live stream or a huge file). If the data is duplicated in each of the connection's buffers, it will definitely overflow RAM. In this case, write a loop that takes a chunk of data each iteration and call . In case of huge file,  is better if available.
From what I understand, (1) You need to call drain every time write is called. (2) If not I guess, write will block the loop threadNeither is correct, but the confusion is quite understandable. The way  works is as follows:A call to  just stashes the data to a buffer, leaving it to the event loop to actually write it out at a later time, and without further intervention by the program. As far as the application is concerned, the data is written in the background as fast as the other side is capable of receiving it. In other words, each  will schedule its data to be transferred using as many OS-level writes as it takes, with those writes issued when the corresponding file descriptor is actually writable. All this happens automatically, even without ever awaiting . is not a coroutine, and it absolutely never blocks the event loop.The second property sounds convenient, but it's actually a major flaw of . Writing is decoupled from accepting the data, so if you write data faster than your peer can read it, the internal buffer will keep growing and you'll have a memory leak on your hands. Awaiting  pauses the coroutine once the buffer becomes too large. You don't need to await  after every write, but you do need to await it occasionally, typically between loop iterations. For example: returns immediately if the amount of pending unwritten data is small. If the data exceeds a high threshold,  will suspend the calling coroutine until the amount of pending unwritten data drops beneath a low threshold. The pause will cause the coroutine to stop reading from , which will in turn cause the peer to slow down the rate at which it sends us data. This kind of feedback is referred to as back-pressure.As reported by an asyncio developer, Python 3.8 will support  which removes the need for the explicit . (The support was added in the meantime.)Buffering should be handled inside write function and application should not care.That is pretty much how  works now - it does handle buffering and it lets the application not care, for better or worse. Also see this answer for additional info.Addressing the edited part of the question:Reading the answer and links again, I think the the functions work like this. is still a bit smarter than that. It won't try to write only once, it will actually arrange for data to continue to be written until there is no data left to write. This will happen even if you never await  - the only thing the application must do is let the event loop run its course for long enough to write everything out.A more correct pseudo code of  and  might look like this:The actual implementation is more complicated because:it's written on top of a Twisted-style transport/protocol layer with its own sophisticated flow control, not on top of ;because  doesn't really wait until the buffer is empty, but until it reaches a low watermark;exceptions other than  raised in  are stored and re-raised in .The last point is another good reason to call , to actually notice that the peer is gone by write to it failing.


Answer URL
https://docs.python.org/3/library/asyncio-stream.html#asyncio.StreamWriter.write
https://docs.python.org/3/library/asyncio-protocol.html
https://docs.python.org/3/library/asyncio-protocol.html#asyncio.BaseProtocol.pause_writing
https://docs.python.org/3/library/asyncio-stream.html#asyncio.StreamWriter.drain
