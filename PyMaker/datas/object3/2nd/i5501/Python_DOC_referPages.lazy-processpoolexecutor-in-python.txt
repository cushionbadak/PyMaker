Natural Text
I have a large number of tasks that I want to execute and make the results available via a generator. However, using a  and  will evaluate the results greedily and store them all in memory. Is there a way to block after a certain number of results are stored in the generator?
The idea for this is to split what you want to process in chunks, I'll be using almost the same example than in the  documentation:Notice the differences between  and , let's explain this a bit:Instead of having a list of all what we want to process I split it into chunks of size 4 (it's useful to use ), the idea is that instead of mapping with the executor the whole list we will be mapping the chunks. Then just using python3 lazy  we can map that executor call lazily to each of the chunks. So, we know that  is not lazy so that chunk will be evaluated immediately when we request it, but till we don't request the other chunks the  for that chunks will not be called.As you can see I'm only requesting the first 4 elements from the whole list of results, but since I also used  it will just consume the ones from the first chunk, without calculating the rest of the iterable.So, since you wanted to return a generator, it would be as easy as return the results from the  function, you can even abstract the chunk size (probably you would need a good function to get the propper chunks, but this is out of scope):


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor
