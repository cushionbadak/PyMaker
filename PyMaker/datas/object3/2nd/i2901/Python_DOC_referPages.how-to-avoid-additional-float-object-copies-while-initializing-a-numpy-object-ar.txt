Natural Text
I naively assumed that assigning a value via ellipsis , e.g.is basically a faster version of the following naive loop:However this seems not to be the case. Here is an example for different behavior:the object  seems to be cloned. Yet when I use the naive slow version:all elements are the "same".Funnily enough, the desired behavior with ellipsis can be observed for example with a custom class:Why do get floats this "special" treatment and is there a way for fast initialization with a float values without producing copies?NB:  and  display the same behavior as : the object  is cloned/its copies are  created.Edit: As @Till Hoffmann pointed out, the desired behavior for strings and integers is only the case for small integers (-5...255) and short strings (one char), because they come from a pool and there never more than one object of this kind.It seems as if the "desired behavior" is only for types numpy cannot downcast to something, for example:Even more,  is no longer of type  but of type .
This is actually an issue with the integers rather than the floats. In particular, "small" integers are cached in python such that all of them refer back to the same memory, thus have the same , and are thus identical when compared with the  operator. The same is not true for floats. See "is" operator behaves unexpectedly with integers for a more in-depth discussion. See https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong for the official definition of "small".Regarding the particular example of  inheriting from , the numpy documentation states thatNote that assignments may result in changes if assigning higher types to lower types [...]One might argue that, in the example case provided above, no assigning of a higher type to a lower type occurs because  should be the most general type. However, inspecting the type of the array elements, it becomes clear that the type is down-cast to a  when assigning using the  assignment.As an aside: you probably won't be able to save much memory by storing a reference to the object of interest unless the individual objects are very large. E.g. storing a single precision floating point number is cheaper than storing a pointer to it (on a 64bit system). If your objects are indeed very large they are (probably) not down-castable to a primitive type so the problem is unlikely to arise in the first place.
This behavior is a numpy bug: https://github.com/numpy/numpy/issues/11701So probably one has to use a workaround until the bug is fixed. I ended up with using the naive slow version implemented/compiled with cython, here for example for one dimension and :There is also no performance disadvantage compared to :


Answer URL
https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong
