Natural Text
I'm trying to understand why using  to solve this problem yields a slower performance of the code. The question is essentially to return all combinations that add up to a certain target.I'm using the  decorator to do the memoization (docs), and this is my solution:It seems like when the  decorator is commented out, I get almost a 50% increase in the runtime speed of this algorithm. This seems a little counter intuitive as I thought the time complexity of the solution should be reduced, even with the increased overhead of function calls to retrieve results from the memoization.For the memoized solution, I believe the time complexity should be  where  is the length of the array, and  being all numbers in the range from  to . This is my analysis (need a little help verifying):I'm also missing some gaps in my knowledge on how to analyze the time complexity of the recursive solution, I could use some help in doing so!EDIT:I'm using  as a test input, here are the benchmarks:
You didn't give both arguments, and they're both important.  I can make either version much faster than the other by picking specific pairs.  If you're passing  as , then each cache lookup has to (among other things) do 9999 comparisons just to determine that the candidates are always the same - and that's huge overhead.  Try, e.g.,for a case where the cached version is much faster.  After which:"Analysis" is futile if you don't account for the expense of doing a cache lookup, and you're apparently trying cases where cache lookup is extremely expensive.  Dict lookup is expected-case , but the hidden constant factor can be arbitrarily large depending on how expensive equality-testing is (and for a key involving an -element tuple, establishing equality requires at least  comparisons).Which should suggest a major improvement:  keep  out of the argument list.  It's invariant so there's really no need to pass it.  Then the cache just needs to store fast-to-compare  pairs.EDIT: PRACTICAL CHANGESHere's another version of the code that doesn't pass in .  Forit's faster by at least a factor of 50 on my box.  There's one other material change:  don't do a recursive call when  is reduced below zero.  An enormous number of cache entries were recording empty-list results for  arguments.  This change reduced the final cache size from 449956 to 1036 in the case above - and cut the number of hits from 9444864 to 6853.
Try running the following on your resultyou should get a result of something like thisbecause your function parameters are very long so they don't match often with the cached values, I blame the target parameter here, restructuring the program might improve the hits drastically.


Answer URL
https://docs.python.org/3/library/functools.html
