Natural Text
This might be a soft question, but here it goes. I have a large data set that has a particular structure and I want to move to Python to start using  package (previously I was using MATLAB). I am no Python expert, for most purposes you can consider me a beginner. The background is the following:The structure of the data is as follows. The raw data are a 33 x 300 matrices (say I have about 500 such samples) which are time-series. Each row comes from one generating variable, and these are collected over 300 seconds. These data points are labelled with tags (corresponding to their classes/types, its actually a multi-label problem), names corresponding to who the sample was collected from, but also with attributes depending on when the data points were collected. Points collected in order are labelled ,  if collected in a single sitting; called a . Samples collected one or more days apart belong to different sessions; and I have multiple sessions.  How I analyzed the data in MATLAB was to make a class of my own, which held an array of s and then I defined methods and functions so that I can add or remove specific samples, add or remove  from the data set, add or remove , add or remove rows from the time-series across the whole data-set, consider classes of samples seperately etc. Each instance of the MATLAB class held the covariance matrix for PCA dimension reduction; other generated features like correlation matrices, etc. for the  of that instance. All together it is about 2k lines in MATLAB. The primary purpose is just to load the data once into , indeed into an instance of the class, and then chain together a list of instructions/calls to the class methods, so that I could prune and edit the data-set as I wanted. So now for the questions:What would be the most pythonic was to approach this situation? I started with a  of  approach and some parts of the code felt very un-pythonic. Here is an example of removing sample from a study or instance of the class, Surely there must be a more elegant way than the double for loop with string comparison?  here just does the dimension reduction etc. again for the 'new' data-set. Also enforcing that the  is a list seemed odd to me. But on the other hand the  doesn't differentiate between strings or lists. :/Is there a better approach? Some other data type from a utility package or something? Because  is a key and I am removing samples based on the value instead of the key, the efficiency of  seem lost to me. My MATLAB implementation was poor in the sense that implementing a deep copy was notoriously laborious; I side-stepped the issue by having a second constructor that created a new instance of the class from a reduced  instead of the disk/data-files. For example, assuming the set had samples tagged as being from , callingwould result in a struct object that I could then use as, Question here is what are Python's deep copy abilities? I am very new to OOP in Python. Would I have to override the default copy constructor bit for bit, variable for variable, attribute for attribute? Sometimes it is necessary to have two different (internally) instances because it is for comparative purposes. Finally, speed considerations: my data set is not huge. I reckon the .MAT file I save to disk at times is usually about 12-15 Mb at the end of a day. But MATLAB has had decades of honing its internals, whereas / I think are comparatively new (yes OOP in MATLAB can be considered even newer, but I didn't find it too bad). Most of my data is not sparse. Are their any tips with regards to performance in this regard? Mostly what I do is large matrix multiplications, numerical integration, differentiation etc. As stackexchange is reminding me, yes the preference is for questions that can be answered; that being said I am not looking for a/the answer. I am new to OOP in Python so I would just like to overlay of the land, people's favorite approaches to such problems, pointers to packages I don't know for this kind of stuff etc. (and oh ... I do know ; but I don't like it, it abstracts away too much of the internals for me, or rather ... makes them hard to get at in a pinch for my liking.) 
There are too many things asked in one question, I think that what makes it an off-topic. I think you could be better off by splitting the question and cutting off the subjective part. Part 3  is especially demotivating to answer.   A quick tour though:python/pandas is not MATLAB and never will be, you should not expect the session functionality from them or complain it is not there. it is by design, not flaw.moving from MATLAB is a chance to review your datamodel and the way you handle it, one path is replicating functionality you had using the classes, the other is changing the data model, forgetting about the sessions and treating your project more as a pipeline. both are valid paths.is there new data being added to your dataset or is it fixed? if there is some new data coming, you probably want to change your data pipline, perhaps consider flatten it to a SQL database, or use NoSQL database, which effectively the same as storing dicts/json's, other options below. 33 x 300 matrices (say I have about 500 such samples) which are time-series. Each row comes from one generating variable, and these are collected over 300 seconds.  So there are 33 variables, which span 300 sec and there are 500 such observations, annotated with some extra attributes? This is a list of dicts, if you want a single data structure. If that has to stay in class, as you are doing it now, you can persist a class instance. You can also write a little file manager that stores individual observation in own folder, each folder containing a csv file and a json. for some good ideas about data pipeline I think Data Science Cookiecutter is great. Hope it's not too didactic! 


Answer URL
https://docs.python.org/3/library/pickle.html#pickling-class-instances
