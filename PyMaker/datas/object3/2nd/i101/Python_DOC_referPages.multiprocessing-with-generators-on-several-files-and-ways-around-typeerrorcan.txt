Natural Text
I am attempting to process multiple files at once, wherein each file will generate chunks of data to feed to a queue of a certain size limit simultaneously.For instance, if there are 5 files, containing 1 million elements each, I would like to feed 100 elements from each of them to another generator which yields 500 elements at a time.Here is what I have been trying so far, but am running into the  error:Anyone have any idea of how to obtain the desired behavior?
For pickle error: is a generator, not a regular function, since it uses  inside.And  requires a function as task to execute. So you should replace  with  in If you want fetch records in chunks from all files one by one, try using  in :


Answer URL
https://docs.python.org/3/library/multiprocessing.html#customized-managers
https://docs.python.org/3/library/multiprocessing.html#managers
