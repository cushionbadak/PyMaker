Natural Text
I'm doing a  of a dataset (a collection of points). The  is ok, the problem is that, when I'm trying to get the  for each point, the speed is very slow:The sample is consist of . I'm wondering if it's possible to make it run parallely, so the speed would be quicker? For example, maybe I can divide the  in to smaller sets and run the  for each set at the same time? Specifically:I'm not familliar with  at all. So I'm wondering if it's applicable in my case?If this can really speed up the process, what should I do? I'm just running the script in , and have no prior expereince in this, is there any good and simple example for my case?I'm reading http://ipython.org/ipython-doc/dev/parallel/parallel_intro.html now.UPDATE:
Here is a simple example of parallelization using multiprocessing built-in module :As you can see from code above,  allows you to map a pool of worker processes executing  on a subset of your samples.The speedup will be significant if your processor have enough cores.


Answer URL
https://docs.python.org/3/library/profile.html#module-profile
