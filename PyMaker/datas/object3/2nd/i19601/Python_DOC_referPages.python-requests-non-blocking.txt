Natural Text
Possible Duplicate:Asynchronous Requests with Python requests Is the python module Requests non-blocking?  I don't see anything in the docs about blocking or non-blocking. If it is blocking, which module would you suggest?
Like ,  is blocking.But I wouldn't suggest using another library, either.The simplest answer is to run each request in a separate thread. Unless you have hundreds of them, this should be fine. (How many hundreds is too many depends on your platform. On Windows, the limit is probably how much memory you have for thread stacks; on most other platforms the cutoff comes earlier.)If you do have hundreds, you can put them in a threadpool. The  Example in the  page is almost exactly what you need; just change  the  calls to  calls. (If you're on 2.x, use , the backport of the same packages on PyPI.) The downside is that you don't actually kick off all 1000 requests at once, just the first, say, 8.If you have hundreds, and they all need to be in parallel, this sounds like a job for . Have it monkeypatch everything, then write the exact same code you'd write with threads, but spawning s instead of s., which evolved out of the old async support directly in , effectively does the  +  wrapping for you. And for the simplest cases, it's great. But for anything non-trivial, I find it easier to read explicit  code. Your mileage may vary.Of course if you need to do something really fancy, you probably want to go to , , or  (or wait a few months for  to be part of the stdlib).
It is blocking, but this reminded me of a kind of a neat little wrapper I guy I know put around gevent, which fell back to eventlet, and then threads if neither of those two were present. You can add functions to data structures that resemble either dicts or lists and as soon as the functions are added they are executed in the background and have the values returned from the functions be available in place of the functions as soon as they're done executing. It's here.


Answer URL
