Natural Text
unicode and string encoding still gives me some headache.I followed this question / answer to be able to add special characters (äÄÜ..) to a message.For the following structure I have trouble to understand why version 2 works and version 1 does not.My model:Version 1:Version 2:As you see the only difference is that I do this  import. The error thrown is the following:
After that  statement, your literals are not  objects, but  objects. That's the whole point of the statement. That isn't described too well, either in the  docs or in PEP 3112 which they refer to (which spends most of its time talking about how to write Python 2-style  objects, given that string literals are now Unicode). But that's what it does.You can test this in the interactive interpreter:So, in version 2, you're adding two  objects together, which is easy. But in version 1, you're adding a  and a . This works by automatically converting the  to a  using the default encoding, which is ASCII, which doesn't work.The easiest way to fix this is to make  be a  itself:This will, in fact, work with or without the  statement—with it,  is already ; without it, it's a  and will be decoded from ASCII, but that's fine, because it is ASCII.If you want to use non-ASCII literals (in the project_prefix), and you want your code to work with and without the  statement, you will have to manually decode:(Make sure to match the source file's coding declaration, of course.)In a comment, you ask:when using the  import statement do I still have to define the coding at the beginning of the .py file? # -- coding: utf-8 --The short answer is yes.I don't know if the documentation directly covers this anywhere, but if you think about it, there's no other way it could work.In order to interpret literals in your 8-bit source code as Unicode, the Python compiler has to decode them. The only way it knows what to decode them from is your coding declaration.Another way to look at this is that the  statement makes Python 2 work like Python 3 as far as string literals are concerned, and Python 3 needs coding declarations.If you want to test this for yourself, copy the following as UTF and paste it into a text file. (Note that you have to use an editor that doesn't understand coding declarations to do this—something like emacs may convert your UTF-8 text to Latin-1 on saving!).When you run this, it will print out , not .While Python 3 defaults to UTF-8 if you don't specify a coding, Python 2.5-2.7 defaults to ASCII, even with . So, you still need the coding declaration. (It's always safe to add, even in 3.x, and it also makes many programmers' text editors happy, so it maybe a habit worth keeping until we get far enough into the future that nobody remembers Latin-1 and Shift-JIS and cp1250 and so on.)


Answer URL
