Natural Text
The Python future statement  provides a nice way to ease the transition to new language features. Is it is possible to implement a similar feature for Python libraries: ?It's straightforward to set a module wide constants on an import statement. What isn't obvious to me is how you could ensure these constants don't propagate to code executed in imported modules -- they should also require a future import to enable the new feature.This came up recently in a discussion of possible indexing changes in NumPy. I don't expect it will actually be used in NumPy, but I can see it being useful for other projects.As a concrete example, suppose that we do want to change how indexing works in some future version of NumPy. This would be a backwards incompatible change, so we decide we to use a future statement to ease the transition. A script using this new feature looks something like this:If this isn't possible, what's the closest we can get for enabling local options? For example, is to possible to write something like:Using something like a context manager would be fine, but the problem is that we don't want to propagate options to nested scopes:
The  in Python is both a module and also not. The Python  is actually not imported from anywhere - it is a construct used by the Python bytecode compiler, deliberately chosen so that no new syntax needs to be created. There is also a  in the library directory; it can be imported as such: ; and then you can for example access the  to find out which Python version makes the feature optionally available and in which version the feature is on by default.It is possible to make a  module that knows what is being imported. Here is an example of  that can intercept feature imports on per module basis:On load time the module is replaced with a  instance. Whenever  is imported from , the  property method will be called, and it will print out the name of the module that imported the feature:Now, you could have a bookkeeping of the modules that have imported this feature. Doing ;  would trigger the same machinery, but you could also ensure that the  import be at the beginning of the file - its global variables at that point shouldn't contain anything else except values returned from this fake module; otherwise the value is being accessed for inspection only.However the real question is: how could you use this - to find out from which module the function is being called is quite expensive, and would limit the usefulness of this feature.Thus a possibly more fruitful approach could be to use import hooks to do source translation on abstract syntax trees on modules that do , possibly changing all  into .
The way Python itself does this is pretty simple:In the importer, when you try to import from a  file, the code first scans the module for future statements. Note that the only things allowed before a future statement are strings, comments, blank lines, and other future statements, which means it doesn't need to fully parse the code to do this. That's important, because future statements can change the way the code is parsed (in fact, that's the whole point of having them…); strings, comments, and blank lines can be handled by the lexer step, and future statements can be parsed with a very simple special-purpose parser.Then, if any future statements are found, Python sets a corresponding flag bit, then re-seeks to the top of the file and calls  with those flags. For example, for , it does , which changes  from  to .In this "real compile" step, the future statements are treated as normal imports, and you will end up with a  value in the variable  in the module's globals.Now, you can't quite do the same thing, because you're not going to reimplement or wrap the compiler. But what you can do is use your future-like statements to signal an AST transform step. Something like this:Of course you have to write that  function to return 0 for a blank line, comment, or string, a flag for a recognized future import (which you can look up dynamically if you want), or  for anything else. And you have to write the AST transformers for each flag. But they can be pretty simple—e.g., you can transform  nodes into different  nodes, or even into  nodes that call different functions based on the form of the index.To hook this into the import system, see PEP 302. Note that this gets simpler in Python 3.3, and simpler again in Python 3.4, so if you can require one of those versions, instead read the import system docs for your minimum version.For a great example of import hooks and AST transformers being used in real life, see MacroPy. (Note that it's using the old 2.3-style import hook mechanism; again, your own code can be simpler if you can use 3.3+ or 3.4+. And of course your code isn't generating the transforms dynamically, which is the most complicated part of MacroPy…)
No, you can't.  The real  import is special in that its effects are local to the individual file where it occurs.  But ordinary imports are global: once one module does ,  is executed and is available globally; other modules that later do  just retrieve the already-imported module.  This means that if  changes something in numpy, everything that does  will see the change.As an aside, I don't think this is what that mailing list message is suggesting.  I read it as suggesting an effect that is global, equivalent to setting a flag like .  This would mean that you should only set that flag at the top level of your application if you know that all parts of your application will work with that.
No, there is no reasonable way to do this.  Let's go through the requirements.First, you need to figure out which modules have your custom future statement enabled.  Standard imports aren't up to this, but you could require them to e.g. call some enabling function and pass  as a parameter.  This is somewhat ugly:This falls apart in the face of , but meh.Next, you need to figure out whether your caller is running in one of these modules.  You'd start by pulling out the stack via  (which won't work under all Python implementations, misses C extension modules, etc.) and then goof around with  and the like.Frankly, this is just a Bad Idea.
If the "feature" that you want to control can be boiled down to changing a name, then this is easy to do, likevsThe feature you suggested is not, of course, but I would argue that this is the only Pythonic way of having different behavior in different scopes (and I do think you mean scope, not module, e.g., what if someone does an import inside a function definition), since scoping names is controlled and well supported by the interpreter itself. 


Answer URL
https://docs.python.org/3/reference/import.html#import-hooks
https://docs.python.org/3/reference/import.html
https://docs.python.org/3/reference/simple_stmts.html#future-statements
https://docs.python.org/3/reference/lexical_analysis.html
https://docs.python.org/3/library/functions.html#compile
https://docs.python.org/3/library/ast.html#ast.NodeTransformer
https://docs.python.org/3/reference/import.html
https://docs.python.org/3/library/importlib.html#importlib.reload
https://docs.python.org/3/library/inspect.html#inspect.stack
https://docs.python.org/3/library/inspect.html#inspect.getmodule
https://docs.python.org/3/reference/import.html
https://docs.python.org/3/reference/import.html#fnlo
