Natural Text
I am using  in order to download a huge (~400k) amount of keyframe images. Keyframes names are stored in text file (let's say keyframes_list.txt).I have modified the example provided in the documentation and it seems to work flawlessly with one exception: as it is clear the example passes every link to a  object which are all passed to an iterable ( to be precise). This iterable is passed as argument to  function to check when a  is completed. This of course requires a huge amount of text loaded at once in memory. My python process for this task takes up 1GB of RAM. The full code is shown below:So, my question is how could I provide both an iterable and also keep memory footprint low. I have considered using  but I am not sure it's cooperating with  smoothly. Is there an easy way to control the amount of s submitted to ?
If we look at the source for , the first thing it does is evaluate any iterable you pass as the first argument, on line 221, with . So as long as you're reading and queuing the entire file at once,  is going to load all those Future instances into memory when you call it.To get around it, you need to chunk the input, and only call as_completed with a subset of the Futures, on each iteration. You can use the snippet from this answer; chunks of ~1k should keep your thread pool saturated while not consuming excessive memory. Your final code, starting with the with-block for the ThreadPoolExecutor, should look something like this:


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example
