Natural Text
Since my scaper is running so slow (one page at a time) so I'm trying to use thread to make it work faster. I have a function scrape(website) that take in a website to scrape, so easily I can create each thread and call start() on each of them.Now I want to implement a num_threads variable that is the number of threads that I want to run at the same time. What is the best way to handle those multiple threads?For ex: supposed num_threads = 5 , my goal is to start 5 threads then grab the first 5 website in the list and scrape them, then if thread #3 finishes, it will grab the 6th website from the list to scrape immidiately, not wait until other threads end.Any recommendation for how to handle it? Thank you
It depends.If your code is spending most of its time waiting for network operations (likely, in a web scraping application), threading is appropriate.  The best way to implement a thread pool is to use  in 3.4.  Failing that, you can create a  object and write each thread as an infinite loop that consumes work objects from the queue and processes them.If your code is spending most of its time processing data after you've downloaded it, threading is useless due to the GIL.   provides support for process concurrency, but again only works in 3.4+.  For older Pythons, use .  It provides a  type which simplifies the process of creating a process pool.You should profile your code (using ) to determine which of those two scenarios you are experiencing.
If you're using Python 3, have a look at Example pulled from the docs ThreadPoolExecutor Example:If you're using Python 2, there is a backport available:ThreadPoolExecutor Example:


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example
