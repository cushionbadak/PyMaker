Natural Text
I'm trying to do some load testing of an openstack swift object store and want to see transfer and fail rates of large files. How can I generate a big file of 0s and stream it somewhere as its generated?In bash I would do something like Example of reading a file from disk 
The  method requires either  or a file object.In your existing code, for some reason, you're passing  instead of , meaning you're reading the whole file into memory and then passing the bytes. If that's acceptable with file data, surely it's acceptable with in-memory data, so you can just build a big  and pass that.If you don't want to build the whole buffer in advance, what you need to do is create a file object that generates bytes on demand whenever the consumer calls one of the  functions.In Python 3, the way to do that is to create a class that implements either  or . As you can see from the docs, to do this, you only need to supply a couple of methods, and the rest get automatically generated for you.Raw I/O is simpler. The main method you need to write is . You will be passed a  (or other mutable -like object), and expected to fill in as much of it as possible. So, your class could look like this:(Obviously if you can write that  function to generate the data directly in  instead of copying it over, it will be more efficient.)The  method is probably actually going to call some other file method, like , , readlinesiterRawIOBasereadinto`.What if you can't control exactly how many bytes you generate; you can only create a line at a time, and that could be anywhere from 1 byte to 300, even if you were only asked for 40? Then you want to use an internal buffer. You can still do that with , but it's probably better to implement  instead, and define the  and  methods.


Answer URL
https://docs.python.org/3/library/io.html#class-hierarchy
https://docs.python.org/3/library/io.html#io.RawIOBase.readinto
https://docs.python.org/3/library/io.html#io.BufferedIOBase.read
https://docs.python.org/3/library/io.html#io.BufferedIOBase.read
