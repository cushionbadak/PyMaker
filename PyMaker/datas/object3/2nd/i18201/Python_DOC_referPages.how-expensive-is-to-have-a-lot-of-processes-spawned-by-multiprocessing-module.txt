Natural Text
I have an application where I have 2 sub-processes ( and ) that are constantly running ( most of the time they idle). But also I need to spawn another  number of sub-processes (lets call it ) based on condition of  process. So  are very lightweight and don't do a lot of computation, but the work whey do takes a long time ( up to an hour ). The machine itself would have no more then 4 CPU cores. I'm planning to run the app on . So the question: is it OK to have a lot ( I expect from 1 to 20 ) lightweight processes like this that would come and go, and most of the time would idle? My first thought was to create one sub-process ( ) and than use threads inside. But I've heard people where having difficulties mixing  and  module together. is it true? By the way, my app is in Python 2.7 and to spawn sub-processes I use  module.
Based on your description, I would suggest that you should just go ahead and create multiple processes for your ~20 jobs.  The  API makes this very easy, and your most precious resource is your own time.  The complexity of concurrent programming can get out of hand very quickly so you need all the help you can get.DetailsIf your worker processes are I/O bound, then there is (arguably) no CPU impact to having many processes.  My Windows currently lists 145 processes running, though we would consider the machine to be idle.  Just make sure that either your code calls  periodically, where  is a "reasonable" pause time for polling, or you are using a library that does it for you, such as multiprocessing's connection object with its  method.If your worker processes are CPU bound, then I'm afraid you are better off setting up a process pool with a size equal to your free CPUs, and then push jobs onto a queue and let the processes in the pool take jobs off the queue.   supports this paradigm pretty well.It gets tricky when the workers could be both CPU bound and I/O bound at different times.  In this case I would suggest that you keep one process reserved (dedicated) for CPU work, and let it take jobs off a queue, and then let many other (I/O) processes create the jobs and push them onto the work queue. If the work is coming in faster than your one CPU core can handle, you either add a second dedicated core, or you set a maxsize on the queue and let your I/O workers monitor queue size to know whether new work can be added.  If you have a great many workers that are I/O bound, then you have to start looking at event-based frameworks such as asyncio, Twisted, gevent, eventlet, greenlet and so on.  This is because there is a reserve memory cost for each OS thread or process spawned, and once you get into thousands of instances that reserve space begins to add up; the event-based systems on the other hand do not spawn multiple threads, they just loop over the I/O device interface and accumulate data based on events. You can support a really huge number of concurrent connections with event-based networking.On Windows, there is an excellent article of the measured limits of multiple threads and processes here.  A quick scan of the document tells me a limit of ~10k was found for maximum number of processes.  I have seen this mentioned elsewhere as The 10k problem but I don't have a reference available to me right now.If you have a great many workers that are CPU bound, then you have to work with distributed computing, pushing jobs to various separate machines.   supports this too via the  API, but I have no personal experience with this. ZeroMQ appears to be popular right now for handling distributed messaging.


Answer URL
https://docs.python.org/3/library/asyncio.html
