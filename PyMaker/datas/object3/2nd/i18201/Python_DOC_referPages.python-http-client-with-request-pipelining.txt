Natural Text
The problem: I need to send many HTTP requests to a server. I can only use one connection (non-negotiable server limit). The server's response time plus the network latency is too high – I'm falling behind.The requests typically don't change server state and don't depend on the previous request's response. So my idea is to simply send them on top of each other, enqueue the response objects, and depend on the Content-Length: of the incoming responses to feed incoming replies to the next-waiting response object. In other words: Pipeline the requests to the server.This is of course not entirely safe (any reply without Content-Length: means trouble), but I don't care -- in that case I can always retry any queued requests. (The safe way would be to wait for the header before sending the next bit. That'd might help me enough. No way to test beforehand.)So, ideally I want the following client code (which uses client delays to mimic network latency) to run in three seconds.Now for the $64000 question: Is there a Python library which already does this, or do I need to roll my own? My code uses gevent; I could use Twisted if necessary, but Twisted's standard connection pool does not support pipelined requests. I also could write a wrapper for some C library if necessary, but I'd prefer native code.
Dugong is an HTTP/1.1-only client which claims to support real HTTP/1.1 pipelining. The tutorial includes several examples on how to use it, including one using threads and another using asyncio.Be sure to verify that the server you're communicating with actually supports HTTP/1.1 pipelining—some servers claim to support HTTP/1.1 but don't implement pipelining.
I think txrequests could get you most of what you are looking for, using the background_callback to en-queue processing of responses on a separate thread. Each request would still be it's own thread but using a session means by default it would reuse the same connection.https://github.com/tardyp/txrequests#working-in-the-background
It is not an answer to your library question but could you not use something as selenium and their selenium.webdriver.support.ui import WebDriverWaitto wait for your requests to be processed for some time, then taking your next step, be it storing the response for later use or sending next request if you did not have any relevant answer?The use of this interface would also allow use of a proxy for bypassing (reasonably, depending on your application and needs) the server limit (either 3 or 5 is help much speed), if you don't need authentication for this connection.  
It seems you are running python2.For python3 >= 3.5 you could use async/await loopSee asyncioAlso, there is a library built on top for better, easier usecalled Trio, available on pip.Another thing I can think of is multiple threads with locks.I will think on how to better explain this or could it even work.


Answer URL
https://docs.python.org/3/library/asyncio.html
