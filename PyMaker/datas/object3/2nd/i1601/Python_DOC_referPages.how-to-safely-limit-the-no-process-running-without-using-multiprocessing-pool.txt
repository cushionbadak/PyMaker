Natural Text
I have a list containing process objects, and i want only 100 of them to be active and running at any time, and after they are done they should exit from memory, and the next 100 process should start, and so on.., I've writen a demo code in python3, and i want to know if there are any problems or limitation with it.
It might be most sensible to use  which produces a pool of worker processes based on the max number of cores available on your system, and then basically feeds tasks in as the cores become available.Hardcoding number of process' might actually slow your execution and more importantly, there is a threat of process' entering  state. In python, multiple process' are spawned according to POSIX standard(using ). During this , everything from the parent except threads are copied into the child process. Be careful of shared memory space and inheriting config from parent to child. More on this if you are interested - How can I inherit parent logger when using Python's multiprocessing? Especially for paramikoHardcoding something like  is likely to suffer a catastrophic death on any machine by grinding disk and grokking RAM.Number of process's should always be determined by Python and it depends on:Hardware capability to run process' simultaneously.OS deciding to give resources to process'If you still want to hardcode number of process, using semaphore restricted number of process is safe:Hope this helps.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool
https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor
