Natural Text
I have written a script to fetch scan results from Qualys to be run each week for the purpose of metrics gathering. The first part of this script involves fetching a list of references for each of the scans that were run in the past week for further processing. The problem is that, while this will work perfectly sometimes, other times the script will hang on the  line. This is manageable when running the script manually as it can just be re-run until it works. However, I am looking to run this as a scheduled task each week without any manual interaction.Is there a foolproof way that I can detect if a hang has occurred and resend the PyCurl request until it works?I have tried setting the  and  options but these don't seem to be effective. Also, as no exception is thrown, simply putting it in a try-except block also won't fly.The function in question is below:
I fixed the issue myself by launching a separate process using  to launch the API call in a separate process, killing and restarting if it goes on for longer than 5 seconds. It's not very pretty but is cross-platform. For those looking for a solution that is more elegant but only works on *nix look into the signal library, specifically SIGALRM.Code below:


Answer URL
https://docs.python.org/3/library/signal.html
