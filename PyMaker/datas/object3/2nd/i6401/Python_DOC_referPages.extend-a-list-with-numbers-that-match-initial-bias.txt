Natural Text
I have a list that essentially goes as such:It currently contains 395 elements, and I'm trying to extend it such that I keep the same percentage of 1's, 2's, 3's, 4's and 5's. Min = 1, Max = 5, and I initially did the following to try and extend the list past 10000 elements:What this gave was a list with the initial bias present for the first 395 iterations, but then after that the rest of the list looked like:A lot more 3, 4, & 5 present, and it completely messes up any statistical analysis I can perform. How do I extend the list as above, while also preserving the weights and biases present (with respect to frequency of occurrence) for the list values?
You can use . This randomly samples from the original list. If you feed it the original list, you don't need to use weights:
You have two options:or This chooses randomly from   times, which should obviously keep your weights the same.Which you should use depends on two things, whether  is large and whether  is large. Using :Giving us the output:So if numTimes is quite large, Numpy is the clear winner, but if the size of  is quite large it seems that vanilla python is the way to go.


Answer URL
https://docs.python.org/3/library/random.html#random.choices
