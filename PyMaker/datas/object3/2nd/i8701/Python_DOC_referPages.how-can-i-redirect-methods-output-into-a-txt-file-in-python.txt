Natural Text
How do I redirect stdout to an arbitrary file in Python?When a long-running Python script (e.g, web application) is started from within the ssh session and backgounded, and the ssh session is closed, the application will raise IOError and fail the moment it tries to write to stdout. I needed to find a way to make the application and modules output to a file rather than stdout to prevent failure due to IOError. Currently, I employ nohup to redirect output to a file, and that gets the job done, but I was wondering if there was a way to do it without using nohup, out of curiosity.I have already tried , but this does not seem to prevent some external modules from still outputting to terminal (or maybe the  line did not fire at all). I know it should work from simpler scripts I've tested on, but I also didn't have time yet to test on a web application yet.
If you want to do the redirection within the Python script, set  to an file object does the trick:A far more common method is to use shell redirection when executing (same on Windows and Linux):
There is  function in Python 3.4:It is similar to:that can be used on earlier Python versions. The latter version is not reusable. It can be made one if desired.It doesn't redirect the stdout at the file descriptors level e.g.: and  are not redirected to the  file. To redirect at the file descriptor level,  could be used:The same example works now if  is used instead of :The output that previously was printed on stdout now goes to  as long as  context manager is active.Note:  does not flush C stdio buffers on Python 3 where I/O is implemented directly on / system calls. To flush all open C stdio output streams, you could call  explicitly if some C extension uses stdio-based I/O:You could use  parameter to redirect other streams, not only  e.g., to merge  and :Example:Note:  mixes buffered I/O ( usually) and unbuffered I/O (operations on file descriptors directly). Beware, there could be buffering issues.To answer, your edit: you could use  to daemonize your script and use  module (as @erikb85 suggested) instead of  statements and  merely redirecting stdout for your long-running Python script that you run using  now. 
you can try this too much better
The other answers didn't cover the case where you want forked processes to share your new stdout.To do that:
Quoted from PEP 343 -- The "with" Statement (added import statement): Redirect stdout temporarily:Used as follows:This isn't thread-safe, of course, but neither is doing this same dance manually.  In single-threaded programs (for example in scripts) it is a popular way of doing things.

You need a terminal multiplexer like either tmux or GNU screenI'm surprised that a small comment by Ryan Amos' to the original question is the only mention of a solution far preferable to all the others on offer, no matter how clever the python trickery may be and how many upvotes they've received. Further to Ryan's comment, tmux is a nice alternative to GNU screen.But the principle is the same: if you ever find yourself wanting to leave a terminal job running while you log-out, head to the cafe for a sandwich, pop to the bathroom, go home (etc) and then later, reconnect to your terminal session from anywhere or any computer as though you'd never been away, terminal multiplexers are the answer. Think of them as VNC or remote desktop for terminal sessions. Anything else is a workaround. As a bonus, when the boss and/or partner comes in and you inadvertently ctrl-w / cmd-w your terminal window instead of your browser window with its dodgy content, you won't have lost the last 18 hours-worth of processing!
Based on this answer: https://stackoverflow.com/a/5916874/1060344, here is another way I figured out which I use in one of my projects. For whatever you replace  or  with, you have to make sure that the replacement complies with  interface, especially if this is something you are doing because stderr/stdout are used in some other library that is not under your control. That library may be using other methods of file object.Check out this way where I still let everything go do stderr/stdout (or any file for that matter) and also send the message to a log file using Python's logging facility (but you can really do anything with this):
Programs written in other languages (e.g. C) have to do special magic (called double-forking) expressly to detach from the terminal (and to prevent zombie processes). So, I think the best solution is to emulate them.A plus of re-executing your program is, you can choose redirections on the command-line, e.g. See this post for more info: What is the reason for performing a double fork when creating a daemon?
@marcog The second option is only good if script get excuted in a go .Or script should get executed completely only then the output goes into that file And infinite loops should`nt be present(optimally). Best solution if it is a simple script.
Here is a variation of Yuda Prawira answer:implement  and all the file attributeswrite it as a contextmanagercapture  also.


Answer URL
https://docs.python.org/3/howto/logging-cookbook.html
