Natural Text
I just wrote a task queue in Python whose job is to limit the number of tasks that are run at one time. This is a little different than  because instead of limiting how many items can be in the queue, it limits how many can be taken out at one time. It still uses an unbounded  to do its job, but it relies on a  to limit the number of threads:The Python interpreter runs forever unless I explicitly stop the task queue. This is a lot more tricky than I thought it would be. If you look at the  method, you'll see that I set a  flag,  the semaphore and  a no-op callback on the queue. The last two parts are necessary because the code could be blocking on the  or on the . I basically have to force these to go through so that the loop has a chance to break out.This code works. This class is useful when running a service that is trying to run thousands of tasks in parallel. In order to keep the machine running smoothly and to prevent the OS from screaming about too many active threads, this code will limit the number of threads living at any one time.I have written a similar chunk of code in C# before. What made that code particular cut 'n' dry was that .NET has something called a  that just about every threading class uses. Any time there is a blocking operation, that operation takes an optional token. If the parent task is ever canceled, any child tasks blocking with that token will be immediately canceled, as well. This seems like a much cleaner way to exit than to "fake it" by releasing semaphores or putting values in a queue.I was wondering if there was an equivalent way of doing this in Python? I definitely want to be using threads instead of something like asynchronous events. I am wondering if there is a way to achieve the same thing using two s where one is has a max size and the other doesn't - but I'm still not sure how to handle cancellation.
You seem to be creating a new thread for each task from the queue. This is wasteful in itself, and also leads you to the problem of how to limit the number of threads.Instead, a common approach is to create a fixed number of worker threads and let them freely pull tasks from the queue. To cancel the queue, you can clear it and let the workers stay alive in anticipation of future work.
I think your code can be simplified by using poisoning and :Untested.I removed the comments, for brevity.Also, in this version  is truly private.BTW: The whole point of the  module is to free you from the dreaded locking and event stuff.
I took Janne Karila's advice and created a thread pool. This eliminated the need for a semaphore. The problem is if you ever expect the queue to go away, you have to stop the worker threads from running (just a variation of what I did before). The new code is fairly similar:If you look carefully, I had to do some accounting to kill off the workers. I basically wait on an  for as many times as there are workers. I  the underlying queue to prevent workers from being cancelled any other way. I also wait after pumping each bogus value into the queue, so only one worker can cancel out at a time.I've ran some tests on this and it appears to be working. It would still be nice to eliminate the need for bogus values.


Answer URL
