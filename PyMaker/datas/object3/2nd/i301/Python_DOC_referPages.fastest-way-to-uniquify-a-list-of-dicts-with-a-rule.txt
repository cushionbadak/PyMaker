Natural Text
I have a list of dicts:I need to sort these uniquely: should be uniqueWhichever dict's  is larger should take precedenceWhich should produce:I came up with this:However I am effectively iterating the list twice, and setting the dictionary values multiple times. This feels like it could be improved, but I have no idea how I can do so.Is there any faster way to accomplish this with the constraints given?
Assuming your list is already sorted by , you could simply just keep track of the maximum  element in one pass, and replace the maximum if found:If your list is not guaranteed to be sorted by , you can apply sorting with  as the sorting  beforehand:Using  above is the same as using:
Assuming  is already sorted by  you can use . In case it is not,  can still be used with  in order to achieve an O(nlogn) solution
This is the step by step approach. It iterates your list once and builds a new one:Output:
Question asked for "fastest" way - I timed the current approches with given data - seems RoadRunners works fastest on this dataset, mine comes second and DeepSpace's solution third. Testcode:Source: https://stackoverflow.com/a/54957067/7505395Source: https://stackoverflow.com/a/54957090/7505395Source: https://stackoverflow.com/a/54957156/7505395Edit (random 10k data - sorted and unsorted) to see if it is data dependent:Randomized data: 10000 datapoints with Source: https://stackoverflow.com/a/54957067/7505395Source: https://stackoverflow.com/a/54957090/7505395Source: https://stackoverflow.com/a/54957156/7505395Source: https://stackoverflow.com/a/54957363/7505395Results with sorting inside p1/p2: Results on presorted data:
To do this is in a single loop on an unsorted table, I created a lookup table to store information about the current result array. The lookup table stores 'T' as a key with the 'V' value and the index of the item in the result list. When looping through the data you can check the 'T' value against the lookup table key. If the key doesn't exist, add it. If it does compare its value against the rows 'V' value. You can use the stored index to replace the previous row if the current row 'V' is greater.Result:To answer the question of what is the fastest way to uniquify the list please see the benchmarks below. It is highly dependent on the data that is provided. The length of the list, whether or not it is sorted and the amount of unique keys all play a part.From my benchmarks I found Patrick Artners to be the fastest on a sorted list. While my own is the fastest on an unsorted list once it's lookup table is fully populated.Benchmark ComparisonsEach script has been run 100 times for each  value, the fastest (min) runtime has been plotted. Benchmark scripts can be found at: https://github.com/sarcoma/python-script-benchmark-tools/blob/master/examples/filter_out_lowest_duplicates.py


Answer URL
https://docs.python.org/3/library/operator.html#operator.itemgetter
https://docs.python.org/3/library/timeit.html
