Natural Text
I have a dictionary. Example,Problem is that if there is something like  in the text, then it is not expanded at all. Below is the code, I am using to replace the dictionary keys:Problem is due to space missing in between  and . How do I resolve this?After, updated code as suggested is as follows: Working for the above example, but in long text, this code is making undesired replacements.Example,lwhyear olduckwhyeahhnt lookingiaandteam effortato representhinking of whyear oldwhyear oldugh lwhyear olduckwhyeahhahandal seato This is part of the result that I am getting on my actual data. Need help. 
Your mistake comes from the way you split your text. The default case for  in python splits on white space, which means that "wtf?" is not split.As you can see in the documentation str.split() can receive a list of separating characters to be used.You could solve this specific problem by using:But most probably, you want many more characters to be used as separation points.
There is a better solution if you look visaversa, for each key, replace it in the whole text with the value of that key:also, note that:DO NOT use  as a variable name, this name is a built-in in python and you will override its functionality.The sample input and output:
Instead of checking to see the text is part of the dictionary, iterate through the dictionary and check if the key is in the text. This is not recommended though as it contains nested loops.Instead, you might want to just replace every occurrence of every key autistically using the replace method. Replace will automatically find and replace the word. No need to iterate the text yourself.
As already noted,  splits only at white spaces, if you wish to extract words and numbers from string, you might use  module for that task following way:As you can seen it discards spaces, dots, commas, colons and so on, while keeping sequences consisting of: letters, digits (and underscores ).
You can solve your problem by using text tokenizer. NLTK library provide many of them such as the WordPunctTokenizer, you can use it as follow: this will output:As you can notice It can tokenize very complex sentences.


Answer URL
https://docs.python.org/3/library/stdtypes.html#str.split
