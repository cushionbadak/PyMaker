Natural Text
I am trying to open a multiple web session and save the data into CSV, Have written my code using for loop & requests.get options, But it's taking so long to access 90 number of Web location. Can anyone let me know how the whole process run in parallel for loc_var:The code is working fine, only the issue is running one by one for loc_var, and took so long time.Want to access all the for loop loc_var URL in parallel and write operation of CSVBelow is the Code:
There are multiple approaches that you can take to make concurrent HTTP requests. Two that I've used are (1) multiple threads with  or (2) send the requests asynchronously using . To use a thread pool to send your requests in parallel, you would first generate a list of URLs that you want to fetch in parallel (in your case generate a list of  and ), and then you would request all of the URLs concurrently as follows:Using asyncio/aiohttp is generally faster than the threaded approach above, but the learning curve is more complicated. Here is a simple example (Python 3.7+):But unless you are going to be making a huge number of requests, the threaded approach will likely be sufficient (and way easier to implement).


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor
