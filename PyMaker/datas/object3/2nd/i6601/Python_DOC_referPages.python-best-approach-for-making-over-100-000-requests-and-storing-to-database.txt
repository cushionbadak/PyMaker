Natural Text
There is data that I'm scraping from many different requests.Up until now, I've used multithreading and the requests library to retrieve the necessary and then loading them into an sqlite database. with approximately the following approach:This approach is very slow (will take days to make all of the requests on my machine). After doing a little research I have seen that there are alternatives to multithreading for this kind of problem, such as asynchronous requests. Unfortunately, I don't know anything about this approach and whether or not it's appropriate, far less how to implement it.Any advice on how to complete this task efficiently would be greatly appreciated.
Since your program is I/O bound, look at event loops. True multi-threading is broken in Python because of the global interpreter lock (GIL).Look at asyncio (available since Python 3.4) and/or Twisted.


Answer URL
https://docs.python.org/3/library/asyncio.html
