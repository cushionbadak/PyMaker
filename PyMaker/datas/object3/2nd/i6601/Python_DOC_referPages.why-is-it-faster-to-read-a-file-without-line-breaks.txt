Natural Text
In Python 3.6, it takes longer to read a file if there are line breaks.  If I have two files, one with line breaks and one without lines breaks (but otherwise they have the same text) then the file with line breaks will take around 100-200% the time to read. I have provided a specific example.Step #1: Create the filesStep #2: Read the file with one single line and time performanceIPythonOutputStep #3: Read the file with many lines and time performanceIPythonOutputThis is just one example.  I have tested this for many different situations, and they do the same thing: Different file sizes from 1MB to 2GB Using file.readlines() instead of file.read()Using a space instead of tab ('\t') in the single line file (i.e. 'Hello World! ') My conclusion is that files with new lines characters ('\n') take longer to read than files without them.  However, I would expect all characters to be treated the same.  This can have important consequences for performance when reading a lot of files.  Does anyone know why this happens?I am using Python 3.6.1, Anaconda 4.3.24, and Windows 10.  
When you open a file in Python in text mode (the default), it uses what it calls "universal newlines" (introduced with PEP 278, but somewhat changed later with the release of Python 3). What universal newlines means is that regardless of what kind of newline characters are used in the file, you'll see only  in Python. So a file containing  would appear the same as a file containing  or  (since ,  and  are all line ending conventions used on some operating systems at some time).The logic that provides that support is probably what causes your performance differences. Even if the  characters in the file are not being transformed, the code needs to examine them more carefully than it does non-newline characters.I suspect the performance difference you see will disappear if you opened your files in binary mode where no such newline support is provided. You can also pass a  parameter to  in Python 3, which can have various meanings depending on exactly what value you give. I have no idea what impact any specific value would have on performance, but it might be worth testing if the performance difference you're seeing actually matters to your program. I'd try passing  and  (or whatever your platform's conventional line ending is).
However, I would expect all characters to be treated the same.Well, they're not. Line breaks are special.Line breaks aren't always represented as . The reasons are a long story dating back to the early days of physical teleprinters, which I won't go into here, but where that story has ended up is that Windows uses , Unix uses , and classic Mac OS used to use .If you open a file in text mode, the line breaks used by the file will be translated to  when you read them, and  will be translated to your OS's line break convention when you write. In most programming languages, this is handled on the fly by OS-level code and pretty cheap, but Python does things differently.Python has a feature called universal newlines, where it tries to handle all line break conventions, no matter what OS you're on. Even if a file contains a mix of , , and  line breaks, Python will recognize all of them and translate them to . Universal newlines is on by default in Python 3 unless you configure a specific line ending convention with the  argument to .In universal newlines mode, the file implementation has to read the file in binary mode, check the contents for  characters, andconstruct a new string object with line endings translatedif it finds  or  line endings. If it only finds  endings, or if it finds no line endings at all, it doesn't need to perform the translation pass or construct a new string object.Constructing a new string and translating line endings takes time. Reading the file with the tabs, Python doesn't have to perform the translation.
On Windows, opening in text-mode converts  characters to  when you write, and the reverse when you read. So, I did some experimentation. I am on MacOS, right now, so my "native" line-ending is , so I cooked up a similar test to yours, except use non-native, Windows line-endings:And the results:Very similar to yours, and note, the performance difference disappears when I open in binary mode. OK, what if instead, I use *nix line-endings?And the results using these new file:Aha! The performance difference disappears! So yes, I think using non-native line-endings impacts performance, which makes sense given the behavior of text-mode.


Answer URL
https://docs.python.org/3/glossary.html#term-universal-newlines
https://docs.python.org/3/glossary.html#term-universal-newlines
