Natural Text
I have a csv file with many millions of rows. I want to start iterating from the 10,000,000 row. At the moment I have the code:This works, however take several seconds to run before the rows of interest appear. Presumably all the unrequired rows are loaded into python unnecessarily, slowing it down. Is there a way of starting the iteration process on a certain row - i.e. without the start of the data read in.
You could use islice:It still iterates over all the rows but does it a lot more efficiently. You could also use the consume recipe which calls functions that consume iterators at C speed, calling it on the file object before you pass it to the csv.reader, so you also avoid needlessly processing those lines with the reader:As Shadowranger commented, if a file could conatin embedded newlines then you would have to consume the reader and pass  but if that is not the case then use do consume the file object as the performance difference will be considerable especially if you have a lot of columns.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.islice
https://docs.python.org/3/library/itertools.html#recipes
