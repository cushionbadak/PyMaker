Natural Text
So in the itertools recipe section, they have a snipped of code that looks like:I was wondering whether a similar idea might bridge some of the performance gap between  and . For instance, with the following code:vsSo if I'm reading the output from dis correctly, the question comes down to "is  faster than ?"Edit: to those saying it doesn't matter, I'm not using this as an optimization. I'm trying to understand the language better by picking this element apart.
We're talking a couple dozen nanoseconds at most, so usually it doesn't matter. And, even when it does, things are more complicated than they first appear.Pre-binding  as  will speed things up over calling , but not as much as just using (the more obvious and idiomatic)  instead.So, why is this different than ?In the case of , you're explicitly creating and calling a bound method, and there's no way around that. So, creating the bound method once, instead of each time… is still usually not worth it, but in those rare cases when you need to save the nanoseconds, it's a win.In the case of , you're not explicitly creating a bound method, you're just evaluating an operator. In CPython, if  is an instance of a Python class, that will implicitly create a bound method—but if it's an instance of a builtin class, it will just directly look up the method in the C slot and call that. So, while you save time by creating the bound method once instead of over and over, it's still not as much as the time you waste calling the C function through a bound method instead of calling it directly.Of course in a different Python implementation—or just with a different type that wasn't a builtin—things might be different.If this actually matters (which it usually won't), you should of course test it with the platform, Python implementation, and type that you care about. But, purely as an example, I'll test it with 64-bit python.org CPython 3.7 on my MacBook Pro with :As expected,  gets back some of our wasted time, but not all of it.But with a pure-Python type:…  is slightly slower than  (because it's basically just a wrapper around calling exactly that), and creating the bound method makes it even faster.So, we got completely opposite results with two different types that represent the same value.And again, the biggest difference in any of these cases is still only 35ns.As a side note, pre-binding the method helps a little more with locals than globals. (Local variable lookup is significantly faster than attribute lookup; global variable lookup is only a tiny bit faster than an attribute lookup.) That's harder to demonstrate in a one-liner, but you should test that yourself if that's your actual intended use.And remember, all of that is just with CPython. When I run the exact same code in PyPy 3.5.3/5.10.1, I get 6.39/6.29/6.31ns for  and 1.52/1.51/1.50ns for .Notice that almost all of the details turned out exactly the other way around:  is faster than  for , pre-binding it actually slows things down rather than speeding them up, and the non-builtin  is 4x faster rather than 3x slower. Why? I can make some guesses, but whenever I try to dive into PyPy's JIT for reliable answers I come out three days later having learned nothing more than that Armin Rigo is an 18th-level wizard.(Also notice that just switching Python interpreters made an order of magnitude more difference than any micro-optimization we could do within the language.)
 does seem to be faster.  At a guess,  is more efficent than  because it knows how many arguments it has.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
