Natural Text
I have a function, which given an argument calculates a corresponding value and returns it. Returned value of the function, depends only on its parameters, so I'd like to cache (memoize) the value somehow. Furthermore, I also want to be able to invalidate a cached value.It seems to be a common need, so I am trying to avoid reinventing the wheel.What I'm looking for is an advanced highly-configurable high-performance library (tool, framework, etc.) and would like the changes to be as lean as possible. Some good points are:efficiently handling concurrent requestsbeing able to use different cache backends (e.g. RAM or DB)retaining responsiveness on large scale dataWhat are some good libraries to use, and how are they compared?
This question doesn't make much sense to me.  When you start talking about "high performance" and "concurrent requests" , you're not really talking about using a Python library within an application -- it sounds more like using (or building) some sort of dedicated, external specialized service or daemon. Personally,  I use a mixture of memoization and 'lazy loaded' or 'deferred' properties to define cache gets (and computes).  By 'lazy loaded', I mean that instead of always pulling (or computing) cached data, I create a proxy object that has all the information to call the get/create function from the cache on first access.   when it comes to database backed material, i've also found it useful to group cache misses and consolidate cache gets - this allows me to load in parallel when possible ( instead of multiple serial requests ).   takes care of my cache administration (get, set, invalidate), which is configured to store in memcached or dbm ( it allows for several backends ).  i use two  lightweight objects (12lines?) to handle the deferred gets.  
You can use , a simple in-memory cache.An example of cached function:Clear the whole cache:Clear cache for a particular value (dirty, dirty hack, because there is no direct access to cache dict):


Answer URL
