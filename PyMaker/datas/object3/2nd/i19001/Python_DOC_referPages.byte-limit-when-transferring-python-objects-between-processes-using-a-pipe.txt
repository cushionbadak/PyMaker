Natural Text
I have a custom simulator (for biology) running on a 64-bit Linux (kernelversion 2.6.28.4) machine using a 64-bit Python 3.3.0 CPython interpreter.Because the simulator depends on many independent experiments for valid results,I built in parallel processing for running experiments.  Communication betweenthe threads primarily occurs under a producer-consumer pattern with manageds(doc).The rundown of the architecture is as follows:a master processes that handles spawning and managing es and the various sN worker processes that do simulations1 result consumer process that consumes the results of a simulation and sorts and analyzes the resultsThe master process and the worker processes communicate via an input .Similarly, the worker processes place their results in an output  whichthe result consumer process consumes items from.  The final ResultConsumerobject is passed via a (doc)back to the master process.Everything works fine until it tries to pass the ResultConsumer object back tothe master process via the :I understand the first two traces (unhandled exits in the  library),and the third is my line of code for sending the ResultConsumer object down the to the master process.  The last two traces are where it getsinteresting.  A  pickles any object that is sent to it and passes theresulting bytes to the other end (matching connection) where it is unpickledupon running .   is attempting tosend the bytes of the pickled object.   isattempting to pack a struct with an integer (network/big-endian) of length n,where n is the length of the buffer passed in as a parameter (the library handles conversions between Python values and C structs represented asPython strings, see the doc).This error only occurs when attempting a lot of experiments, e.g. 10 experimentswill not cause it, but 1000 will consitently (all other parameters being constant).  My besthypothesis so far as to why  is thrown is that the number of bytestrying to be pushed down the pipe exceeds 2^32-1 (2147483647), or ~2 GB.So my question is two-fold:I'm getting stuck with my investigations as  essentially justimports from  and I have no idea where that is.The byte limit seems arbitrary given that the underlying architecture is all64-bit.  So, why can't I pass anything larger than that?  Additionally, if Ican't change this, are there any good (read: easy) workarounds to this issue?Note: I don't think that using a  in place of a  will solve the issue,as I suspect that 's use a similar pickling intermediate step.  EDIT: This note is entirely incorrect as pointed out in abarnert's answer.
I'm getting stuck with my investigations as struct.py essentially just imports from _struct and I have no idea where that is.In CPython,  is a C extension module built from  in the  directory in the source tree. You can find the code online here.Whenever  does an , that's almost always a C extension module, usually built from . And if you can't find a  at all, it's probably a C extension module, built from .It's also often worth looking at the equivalent PyPy source, even if you're not using PyPy. They reimplement almost all extension modules in pure Python—and for the remainder (including this case), the underlying "extension language" is RPython, not C.However, in this case, you don't need to know anything about how  is working beyond what's in the docs.The byte limit seems arbitrary given that the underlying architecture is all 64-bit.Look at the code it's calling:If you look at the documentation, the  format character explicitly means "4-byte C integer", not "whatever  is". For that, you'd have to use . Or you might want to explicitly use a long long, with .You can monkeypatch  to use . Or . Or encode the length in some way other than . This will, of course, break compatibility with non-patched , which could be a problem if you're trying to do distributed processing across multiple computers or something. But it should be pretty simple:Of course there's no guarantee that this change is sufficient; you'll want to read through the rest of the surrounding code and test the hell out of it.Note: I suspect that using a  in place of a  will not solve the issue, as I suspect that 's use a similar pickling intermediate step.Well, the problem has nothing to do with pickling.  isn't using  to send the length, it's using . You can verify that  wouldn't have this problem:  will return .(In earlier versions,  also had problems with huge objects—e.g., a  of 2G elements—which could have caused problems at a scale about 8x as high as the one you're currently hitting. But that's been fixed by 3.3.)Meanwhile… wouldn't it be faster to just try it and see, instead of digging through the source to try to figure out whether it would work?Also, are you sure you really want to pass around a 2GB data structure by implicit pickling?If I were doing something that slow and memory-hungry, I'd prefer to make that explicit—e.g., pickle to a tempfile and send the path or fd. (If you're using  or  or something, use its binary file format instead of , but same idea.)Or, even better, share the data. Yes, mutable shared state is bad… but sharing immutable objects is fine. Whatever you've got 2GB of, can you put it in a , or put it in a  array or struct (of arrays or structs of …) that you can share via , or  it out of a  that you  on both sides, or…? There's a bit of extra code to define and pick apart the structures, but when the benefits are likely to be this big, it's worth trying.Finally, when you think you've found a bug/obvious missing feature/unreasonable limitation in Python, it's worth looking at the bug tracker. It looks like issue 17560: problem using multiprocessing with really big objects? is exactly your problem, and has lots of information, including suggested workarounds.


Answer URL
