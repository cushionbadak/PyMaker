Natural Text
Requirement :Python objects with 2-3 levels of nesting containing basic datypes like integers,strings, lists, and dicts.( no dates etc), needs to be stored as json in redis against a key.What are the best methods available for compressing json as a string for low memory footprint.The target objects are not very large, having 1000 small elements on average, or about 15000 characters when converted to JSON.eg.1/ Are there any other better ways to compress json to save memory in redis ( also ensuring light weight decoding afterwards ).2/ How good a candidate would be msgpack [http://msgpack.org/] ?3/ Shall I consider options like pickle as well ?
We just use  as a compressor.In our usecase we store the result as files, as you can imagine.  To use just in-memory strings, you can use a  object as a replacement for the file as well.
Based on @Alfe's answer above here is a version that keeps the contents in memory (for network I/O tasks). I also made a few changes to support Python 3.To test the compression try:
If you want it to be fast, try lz4. If you want it to compress better, go for lzma.Are there any other better ways to compress json to save memory in  redis(also ensuring light weight decoding afterwards)?How good a candidate would be msgpack [http://msgpack.org/]?Msgpack is relatively fast and has a smaller memory footprint. But ujson is generally faster for me. You should compare them on your data, measure the compression and decompression rates and the compression ratio.Shall I consider options like pickle as well?Consider both pickle(cPickle in partucular) and marshal. They are fast. But remember that they are not secure or scalable and you pay for the speed with the added responsibility.
One easy "post process" way is to build a "short key name" map and run the generated json through that before storage, and again (reversed) before de-serializing to an object. For example:Just go through the json and replace key->value on the way to the database, and value->key on the way to the application.You can also gzip for extra goodness (won't be a string after that though).
Another possibility would be to use MongoDB's storage format, BSON.You can find two python implementations in the implementation page on that site.edit: why not just save the dictionary, and convert to json on retrieval?


Answer URL
https://docs.python.org/3/library/lzma.html
