Natural Text
I am trying to use multiprocessing for the first time. So I thought I would make a very simple test example which factors 100 different numbers.This gives me the error:I see that Python Process Pool non-daemonic? discusses this problem but I don't understand why it is relevant to my simple toy example.  What am I doing wrong?
The problem appears to be that  uses its own . Unfortunately, while PyPI is down, I can't find the source to the module—but I did find various forks on GitHub, like this one, and they all have  code.So, your apparently simple example isn't all that simple—because it's importing and running non-simple code.By default, all  processes are daemonic, so you can't create more child processes from inside another . Usually, attempting to do so is a mistake. If you really do want to multiprocess the factors even though some of them are going to multiprocess their own work (quite possibly adding more contention overhead without adding any parallelism), then you just have to subclass  and override that—as explained in the related question that you linked.But the simplest thing is to just not use  here, if  is already using your cores efficiently. (If you need quasi-concurrency, getting answers as they come in instead of getting them in sequence, I suppose you could do that with a thread pool, but I don't think there's any advantage to that here—you're not using  or explicit  anywhere.)Alternatively, if it's not using all of your cores most of the time, only doing so for the "tricky remainders" at the end of factoring some numbers, while you've got 7 cores sitting idle for 60% of the time… then you probably want to prevent  from using  at all. I don't know if the module has a public API for doing that. If so, of course, just use it. If not… well, you may have to subclass or monkeypatch some of its code, or, at worst, monkeypatching its import of , and that may not be worth doing.The ideal solution would probably be to refactor  to push the "tricky remainder" jobs onto the same pool you're already using. But that's probably by far the most work, and not that much more benefit.As a side note, this isn't your problem, but you should have a  guard around your top-level code, like this:Otherwise, when run with the  or  startmethods—and notice that  is the only one available on Windows—each pool process is going to try to create another pool of children. So, if you run your code on Windows, you would get this same assertion—as a way for  to protect you from accidentally forkbombing your system.This is explained under safe importing of main module in the "programming guidelines" section of the  docs.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods
