Natural Text
I was just checking the size of some datatypes in Python 3 and I observed this.The output was  as expected.I tried making a list of 1000 locations of  and I expected the size to be  or more. But the result I got was different.The output was . Nearly the half of the size I expected. What is the reason for this.? Why memory allocated is less.? 
Note: No of bytes may vary depending on the environment
There is just a single  object referenced a thousand times.  So the situation is this:And not this:This is more visible when repeating a mutable object, like this:There is just a single, shared  object referenced three times, so changes to the set at  also affect  and .Python data structures such as ,  and  are reference-based.  In your case, most of the 8064 bytes you observed come from the object references (8 bytes per list element).


Answer URL
https://docs.python.org/3/library/sys.html#sys.getsizeof
