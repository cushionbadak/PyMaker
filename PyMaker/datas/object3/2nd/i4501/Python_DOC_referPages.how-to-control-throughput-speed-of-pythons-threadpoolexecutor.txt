Natural Text
I am starting asynchronous tasks using python's  ThreadPoolExecutor.Following this approach, I monitor the progress of the async calls using the  progress bar.My code looks like this:The console output looks like this:I know I can set up a URL queue and control its size, as described here.However, I don't know how to control throughput speed itself. Lets say I want not more than 6 URLs/sec. Can this be archived by something else than throwing in time.sleep(n) to  in the above example?How to effectively control throughput speed of  in python's ?
To answer shortly, there is no such way. Once you have declared your pool, you cannot change the number of workers without first closing the pool and recreating it. There is also no way to make the pool feed tasks slower than the maximum speed to workers.You have a couple of (not so optimal) choices. One is to add sleep based on global variable to the worker.  Then you can use task completed callbacks to measure actual speed and adjust the variable accordingly.  But if sleeping is out of question, this does not work. The better, albeit more onerous, way is to write the task manager yourself. In this version you do not use pool but write a class that manages worker processes. You spawn "enough" workers, and the workers listen to a queue for tasks. You will feed this queue from your manager in your desired speed. You will set your queue to have a very low maximum size, and if your manager detects the queue is full, it spawns another worker. But there is no built-in functionality to do what you want, which means some work is needed or you need to redesign your program so that you will not feed all of your tasks to the pool in one go but do some throttling there. 


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor
