Natural Text
I have an event oriented server which already uses select.epoll().Now a new requirement should be solved: URLs should get fetched (async).Up to now I always used the requests library, and I always used it synchronous, never asynchronous.How can I use the requests library (or a different urllib) combined with linux epoll?The requests library docs has a note about this, but there only async-frameworks are mentioned (not select.epoll()): http://docs.python-requests.org/en/master/user/advanced/#blocking-or-non-blockingI am not married with select.epoll(). It worked up to now. I can use a different solution, if feasible. Background: The bigger question is "Should I use select.epoll() or one of the many async frameworks which python has?". But questions at StackOverflow must not be too broad. That's why this question focuses on "Retrieve several URLs via select.epoll()". If you have hints to the bigger question, please leave a comment.If you are curious, this question is needed for a small project which I develop in my spare time: https://github.com/guettli/ipo (IPO is an open source asynchronous job queue which is based on PostgreSQL.)
How can I use the requests library (or a different urllib) combined with linux epoll?Unfortunately you can’t unless such a library has been built with this integration in mind. epoll, as well as select/poll/kqueue and others are I/O multiplexing system calls and the overall program architecture needs to be built around it. Simply put, a typical program structure boils down to the followingone needs to have a bunch of file descriptors (sockets in non-blocking mode  in your case)a system call (man epoll_wait in case of epoll) blocks until a specified event occurs on one or multiple descriptorsinformation of the descriptors available for I/O is returnedAfter that this is the outer code’s job to handle these descriptors i.e. figure out how much data has become available, call some callbacks etc. If the library uses regular blocking sockets the only way to parallelize it is to use threads/processesHere’s a good article on the subject, the examples use C and that’s good as it’s easier to understand what’s actually happening under the hoodAsync frameworks & requests libraryLets check out what’s suggested hereIf you are concerned about the use of blocking IO, there are lots of  projects out there that combine Requests with one of Python's  asynchronicity frameworks. Some excellent examples are  requests-threads, grequests, and requests-futures).requests-threads - uses threadsgrequests - integration with gevent (it’s a different story, see below)requests-futures - in fact also threads/processesneither of them has anything to do with true asynchronicity Should I use select.epoll() or one of the many async frameworks which python hasPlease note, epoll is linux-specific beast and it won’t work i.e. on OS X that has a different mechanism called kqueue. As you appear to be writing a general-purpose job queue it doesn’t seem to be a good solution. Now back to python. You’ve got the following options:threads/processes/concurrent.futures - unlikely is it something you’re aiming at as your app is a typical C10K serverepoll/kqueue - you’ll have to do everything yourself. In case of fetching an HTTP urls you’ll need to deal with not only http/ssl but also with asynchronous DNS resolution. Also consider using asyncore[] that provides some basic infrastructuretwisted/tornado - callback-based frameworks that already do all the low-level stuff for yougevent - this is something you might like if you’re going to reuse existing blocking libraries (urllib, requests etc) and use both python 2.x and python 3.x. But this solution is a hack by design. For an app of your size it might be ok, but I wouldn’t use it for anything bigger that should be rock-solid and run in prodasyncioThis module provides infrastructure for writing single-threaded  concurrent code using coroutines, multiplexing I/O access over sockets  and other resources, running network clients and servers, and other  related primitivesIt has everything you might need.There’s also a bunch of libraries working with popular RDBMs and httphttps://github.com/aio-libsBut it lacks support of python 2.x. There are ports of asyncio to python 2.x but not sure how stable they areFinallySo if I could sacrifice python 2.x I’d personally go with asyncio & related librariesIf you really really need python 2.x use one of the approaches above depending on the stability required and assumed peak load
when doing high performance development,we always choose weapons based on our situation.So it still too broad to answer.But your bigger question is a easier one.only the IO-bound program is suit for Async.what is the purpose of epoll and asynchronous?Avoiding the CPU waiting for IO and doing nothing.CPU waiting for IO blocks,IO blocks because NO DATA TO READ or NO space to write.Buffer is introduced to reduce the system call.When you call read on a stream,you actually read from the buffer.(concepts,not very accurate)Select or epoll are nonblocking busy polling(epoll implement by interruption underlying).it just essentially something like belowit's silly,so there is select and epoll.Everytime you read from buffer,there are data waiting for you,it's high speed IO,then epoll/select is your best choice.And when the buffer is always empty,it's a slow stream,IO-bound,async is very suit for this situation.I don't know async very well,for me it's just soft interruption internally and a lot of callback.
The main point above is correct, you cannot technically do this with a blocking call meant for multiplexed I/O such as , , and the BSD/iOS, Windows variants. These calls allow a timeout specification, so you can come close by repeated polling on short intervals, then passing work to an asynch handler off of the main thread. In that case, the reading is done on the main thread, multiple reads can signal that they're ready, and the main thread is primarily devoted to that task.If the scale of your problem is small to medium then nothing is going to beat an  or even . If your problem (number of read channels) is on the small side. So I'd encourage you to think about that - get as much work off the main thread which can be devoted to the requests. If you are looking for an async solution, one of your best options is the  library, both for ease of use and performance. To get an idea, run the following client-server pair. Note that the use of tornado is irrelevant here and only on the server side whereas your concern is the client.Try this - the performance difference is night and day.A solution for you is represented by the client.py class below; it uses  to issue  requests asynchronously.server.pyclient.pyThis is a true async solution, or as close as one can get in CPython/python. No pollers used. 


Answer URL
https://docs.python.org/3/library/asyncore.html
