Natural Text
When, where and how does Python implicitly apply encodings to strings or does implicit transcodings (conversions)?And what those "default" (i.e. implied) encodings are?For example, what are the encodings:of string literals?of byte strings when type-converted to and from Unicode?when byte- and Unicode strings are written to/from a file or a terminal?
There are multiple parts of Python's functionality involved here: reading the source code and parsing the string literals, transcoding, and printing. Each has its own conventions.Short answer:For the purpose of code parsing:(Py2) -- not applicable, raw bytes from the file are taken(Py2)/(Py3) -- "source encoding", defaults are (Py2) and (Py3)(Py3) -- none, non-ascii characters are prohibited in the literalFor the purpose of transcoding:both(Py2) --  ( almost always)there are implicit conversions which often result in a /both(Py3) -- none, must specify encoding explicitly when convertingFor the purpose of I/O:(Py2) --  if set, otherwise (Py2) -- not applicable, raw bytes are written(Py3) -- , always set and defaults to (Py3) -- none, ing produces its  insteadFirst of all, some terminology clarification so that you understand the rest correctly. Decoding is translation from bytes to characters (Unicode or otherwise), and encoding (as a process) is the reverse. See The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) â€“ Joel on Software to get the distinction.Now...Reading the source and parsing string literalsAt the start of a source file, you can specify the file's "source encoding" (its exact effect is decribed later). If not specified, the default is  for Python 2 and  for Python 3. A UTF-8 BOM has the same effect as a  encoding declaration.Python 2Python 2 reads the source as raw bytes. It only uses the "source encoding" to parse a Unicode literal when it sees one. (It's more complicated than that under the hood but this is the net effect.)So, regular strings will contain the exact bytes that are in the file. And Unicode strings will contain the result of decoding the file's bytes with the "source encoding".If the decoding fails, you will get a . Same if there is a non-ascii character in the file when there's no encoding specified. Finally, if  future is used, any regular string literals (in that file only) are treated as Unicode literals when parsing, with all what that means.Python 3Python 3 decodes the entire source file with the "source encoding" into a sequence of Unicode characters. Any parsing is done after that. (In particular, this makes it possible to have Unicode in identifiers.) Since all string literals are now Unicode, no additional transcoding is needed. In byte literals, non-ascii characters are prohibited (such bytes must be specified with escape sequences), evading the issue altogether.TranscodingAs per the clarification at the start: -- bytes => can only be d (directly, that is; details follow) -- characters => can only be dPython 2In both cases, if the encoding is not specified,  is used. It is  (unless you uncomment a code chunk in , or do some other hacks which are a recipe for disaster). So, for the purpose of transcoding,  is the "string's default encoding".Now, here's a caveat:a  and  -- with the default encoding -- is done implicitly when converting :in string formatting (a third of / questions on SO are about this)when trying to  a  or  a  (the 2nd third of the SO questions)Python 3There's no "default encoding" at all: implicit conversion between  and  is now prohibited.(As the number of SO questions from confused users testify, it proved to be more trouble than it's worth.) can only be d and  -- d, and the  argument is mandatory.converting  (incl. implicitly) produces its  instead (which is only useful for printing), evading the encoding issue entirelyconverting  is prohibitedPrintingThis matter is unrelated to a variable's value but related to what you would see on the screen when it's ed -- and whether you will get a  when ing.Python 2A  is d with  if set; otherwise, it's implicitly converted to  as per the above. (The final third of the  SO questions fall into here.)For standard streams, the stream's encoding is guessed at startup from various environment-specific sources, and can be overridden with the  envvar.'s bytes are sent to the OS stream as-is. What specific characters you will see on the screen depends on your terminal's encoding (if it's something like UTF-8, you may see nothing at all if you print a byte sequence that is invalid UTF-8).Python 3The changes are:Now s opened with text vs binary  natively accept  or , correspondingly, and outright refuse to process the wrong type. Text-mode files always have an  set,  being the default. for text streams still implicitly converts everything to , which in the case of  prints its  as per the above, evading the encoding issue altogether
Implicit encoding as internal format to store strings/arrays: you should not care about the encoding. In fact Python decodes characters in Python internal way.  It is mostly transparent. Just image that it is a Unicode text, or a sequence of bytes, in abstract way.The internal coding on Python 3.x varies according the "larger" character. It could be UTF-8/ASCII (for ASCII strings), UTF-16 or UTF-32. When you are using strings, it is like you have a Unicode String (so abstract, not a real encoding). If you do not program in C or you use some special functions (memory view), you will never be able to see the internal encoding.Bytes are just a view of actual memory. Python interprets is as . But again, often you should just think about what the sequence it is, not on internal encoding.Python2 has bytes and string as unsigned char, and unicode as UCS-2 (so code points above 65535 will be coded with 2 characters (UCS2) in Python2, and just one character (UTF-32) in Python3)


Answer URL
https://docs.python.org/3/library/functions.html?highlight=open#open
