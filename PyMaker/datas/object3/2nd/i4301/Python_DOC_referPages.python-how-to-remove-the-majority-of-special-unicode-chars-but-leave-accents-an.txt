Natural Text
I am scraping text from a webpage in Python.The text contains all kinds of special unicode chars such as hearts, smilies and other wild stuff.By using  I am able to convert everything to ASCII but that means all accented chars and mutated vowels such as 'ä' or 'ß' are gone as well.How can leave the "normal" chars such as 'ä' or 'é' intact but can remove all the other stuff?(I must admit I am quite a newbie in Python and I never really got behind all the magic behind character encoding).
It's not entirely clear from your question where you draw the line between the “good” and the “bad” characters, but you probably don't know that yet, either.Unicode contains a lot of different kinds of characters, and you might not be aware of the diversity.Unicode assigns a category to each character, such as “Letter, lowercase” or “Punctuation, final quote” or “Symbol, other”.Python's std-lib module  gives you convenient access to this information:From your examples it seems like you think letters are good, while symbols are bad.But you'll have to sort out the rest too.You probably want to keep blanks (“separators”) and punctuation as well.And you might need the marks too, as they include the combining characters.
Few steps:You should normalize unicode, with . Not really on the question, but you must have a common ground, let's have the same character to have the same encoding.Then you should check every character to see if you allow it or not:You should adapt according your next processing methods: See Python Unicode HOWTO and the linked page Unicode character categories.
Well, I finally used this:Thanks to anybody who answered


Answer URL
https://docs.python.org/3/howto/unicode.html
