Natural Text
CPython 3.6.4:now:I thought  just remembers part of parameters and then forwards them to the original function when called with the rest of the parameters (so it's nothing more than a shortcut), but it seems it makes some optimization. In my case the whole  function gets optimized by 15% compared to the , which is pretty nice.It would be great to know what the optimization is, so I could use it in a more efficient way. Docs are silent regarding any optimization. Not surprisingly, "roughly equivalent to" implementation (given in docs), does not optimize at all:
The following arguments actually apply only to CPython, for other Python implementations it could be completely different. You actually said your question is about CPython but nevertheless I think it's important to realize that these in-depth questions almost always depend on implementation details that might be different for different implementations and might even be different between different CPython versions (for example CPython 2.7 could be completely different, but so could be CPython 3.5)!TimingsFirst of all, I can't reproduce differences of 15% or even 20%. On my computer the difference is around ~10%. It's even less when you change the  so it doesn't have to look up  from the global scope (as already pointed out in the comments you can pass the  function as default argument to the function so the lookup happens in the local scope).I actually benchmarked these:Possible explanationsIt's very hard to find the exact reason for the difference. However there are a few possible options, assuming you have a CPython version with compiled  module (all desktop versions of CPython that I use have it). As you already found out the Python version of  will be significantly slower. is implemented in C and can call the function directly - without intermediate Python layer1. The  on the other hand needs to do a Python level call to the "captured" function.  actually knows how the arguments fit together. So it can create the arguments that are passed to the function more efficiently (it just concatenats the stored argument tuple to the passed in argument tuple) instead of building a completely new argument tuple.In more recent Python versions several internals were changed in an effort to optimize function calls (the so called FASTCALL optimization). Victor Stinner has a list of related pull requests on his blog in case you want to find out more about it. That probably will affect both the  and the  but again because  is a C function it knows which one to call directly without having to infer it like  does.However it's very important to realize that creating the  has some overhead. The break-even point is for ~10 list elements, if the list is shorter, then the  will be faster.Footnotes1 If you call a function from Python it uses the OP-code  which is actually a wrapper (that's what I meant with Python layer) around the  (or FASTCAL) functions. But it also includes creating the argument tuple/dictionary. If you call a function from a C function you can avoid this thin wrapper by directly calling the  functions.In case you're interested about the OP-Codes, you can assemble the function:As you can see the  op code is actually in there.As an aside: The  is responsible for the performance difference between the  and the  without default. That's because loading a name actually starts by checking the local scope (the function scope), in the case of  the add function is in the local scope and it can stop then. If you don't have it in the local scope it will check each surrounding scope until it finds the name and it only stops when it reaches the global scope. And that lookup is done every time the  is called!


Answer URL
https://docs.python.org/3/library/dis.html
