Natural Text
I am trying to request a bunch of URLs concurrently however the URLs are built from a list. Currently I am looping over the list and (I think) adding them to the queue as it happens. It is definitely 10x faster than requests.get, however I am not sure I am doing it correctly and so it can be optimized. I profiled it and noticing it is still locking 90% of the time after the concurrent requests are done i.e start -> 10+ concurrent requests -> lock for 5 seconds or so -> doneAdditionally, this code results in a  message at the end. Any idea why? Pretty sure this is using a context manager properly. I have searched and not found this exact question
Looks like what you have works, but as you thought you're not doing everything quite correctly:you create a client which you never use, and don't close correctly (causing the ) warningyou're creating a client for each request which is much less efficient than reusing a client.you're not running most of your code in a running event loop.the signal handler as you have it is not necessary, if you have long running asyncio tasks you might want to use Here's my simplified take on your code:If you want to then process the html, you can either do it inside the fetch coroutine or operate on all the results from .


Answer URL
https://docs.python.org/3/library/asyncio-eventloop.html
https://docs.python.org/3/library/asyncio-task.html#asyncio.gather
