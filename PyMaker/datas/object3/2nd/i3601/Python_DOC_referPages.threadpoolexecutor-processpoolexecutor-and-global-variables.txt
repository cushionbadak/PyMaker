Natural Text
I am new to parallelization in general and concurrent.futures in particular. I want to benchmark my script and compare the differences between using threads and processes, but I found that I couldn't even get that running because when using  I cannot use my global variables. The following code will output as I expect, but when you change  for , it will output .I don't understand why this is the case. In my real program, init is used to set the global variables to CLI arguments, and there are a lot of them. Hence, passing them as arguments does not seem recommended. So how do I pass those global variables to each process/thread correctly?I know that I can change things around, which will work, but I don't understand why. E.g. the following works for both Executors, but it also means that the globals initialisation has to happen for every instance. So my main question is, what is actually happening. Why does this code work with threads and not with processes? And, how do I correctly pass set globals to each process/thread without having to re-initialise them for every instance?(Side note: because I have read that concurrent.futures might behave differently on Windows, I have to note that I am running Python 3.6 on Windows 10 64 bit.)
I'm not sure of the limitations of this approach, but you can pass (serializable?) objects between your main process/thread.  This would also help you get rid of the reliance on global vars:Works with both executor types.Edit: Even though it sounds like it won't be a problem for your use case, I'll point out that with , the  dict you get inside  will be a frozen copy, so mutations to it will not be visible across processes nor will they be visible once you return to the  block.  , on the other hand, will share the dict object between threads.
Let's image a process is a box while a thread is a worker inside a box. A worker can only access the resources in the box and cannot touch the other resources in other boxes.So when you use threads, you are creating multiple workers for your current box(main process). But when you use process, you are creating another box. In this case, the global variables initialised in this box is completely different from ones in another box. That's why it doesn't work as you expect.The solution given by jedwards is good enough for most situations. You can expilictly package the resources in current box(serialize variables) and deliver it to another box(transport to another process) so that the workers in that box have access to the resources.
A process represents activity that is run in a separate process in the OS meaning of the term while threads all run in your main process. Every process has its own unique namespace. Your main process sets the value to  by calling  inside your condition for its own namespace. In your new process, this does not happen ( is  here) hence  remains None and  is never actually called unless you do so explicitly in the function your process executes.While sharing state between processes is generally not recommended, there are ways to do so, like outlined in @jedwards answer.You might also want to check Sharing State Between Processes from the docs.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
