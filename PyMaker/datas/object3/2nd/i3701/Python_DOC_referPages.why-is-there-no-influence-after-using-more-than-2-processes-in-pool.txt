Natural Text
By using the map function in the  library I see no difference in execution time when using more than 2 processes. I'm running the program using 4 cores. The actual code is pretty straight forward and calculates the first 4000 fibonacci numbers 4 times (= the amount of cores). It distributes the work evenly between N cores (e.g. when using a Pool with 2 processes, each process will calculate the first 4000 fibonacci numbers twice). This whole process is done for N = 1 up to the amount of cores. The output, with in every row the amount of cores and the corresponding execution time in seconds, is: 3,1471,721,8961.899Does anyone know why there is no decrease in execution time given more than 2 cores?  The actual code is:
Provided you are using a fairly modern CPU (e.g. any Intel Core processor),  won't give you the number of physical cores your machine has, but the number of hyper-threads. In a nutshell, hyper-threading allows a single physical core to have  (most commonly, two) pipelines, which fools your OS into thinking you've got  times the number of cores you really have. This is helpful, when you are doing some stuff that might starve a core with data (most notably, IO or RAM lookups caused by cache-misses), but your workload is purely arithmetic and it is not likely to starve your CPU, resulting in little to no gains from hyper-threading. And the little gains you might get will be overshadowed by multiprocessing overhead, which is quite significant.P.S.I usually post this sort of things as comments, but I've exceeded the comment size limitation. By the way, if you've chosen the Fibonacci series for something more that just an example, you might want to consider a faster algorithm: Fast Fibonacci computation


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map
