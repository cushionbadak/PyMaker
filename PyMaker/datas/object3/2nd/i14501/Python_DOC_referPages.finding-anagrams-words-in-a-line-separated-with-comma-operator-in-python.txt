Natural Text
Able to get the anagrams in a line but wanted to know if there is any better approach to solve the above problem in less complexity. Please help me in calculating complexity for the above approach.
The big efficiency problem here is the  that you do on each one.Let's go through the parts. Say we have N elements, K unique elements, and the average word is length M.Sort each element of the list and put the result in another list. That's  time per element, or  total.Make a set out of that new list, which is .For each word in the set, for each word in the list, count how many times the list-word appears in the list. This is the biggie. Counting how many times something appears in a list takes  time, and you do it  times, so that's .For each word in the set, iterate the list finding all matching values if the . That's  time.You could fix that  part just by lifting the counting out of the list comprehension. Let's assume you did that, without explaining exactly how (it's pretty easy). Now your time is . Assuming , that's .To fix this, you want to create a mapping from sorted words to original words, so you can look up the original words in constant time.For example:Now, our first two steps are , but our third step is  instead of , because we're just doing one constant-time set lookup per set word, instead of one linear list traversal per set word.So our total time is .(If the order of the anagrams in each set matters, or if there can be actual duplicated words, you can map each sorted word to a list rather than a set of original words. That doesn't really affect the performance here, because the only thing we ever do with that list/set is append/add and iterate; I just used a set because it seemed like conceptually the order is irrelevant and there shouldn't be any duplicates.)But we can do even better than that. It probably won't matter, given that , but… Why do we need to sort the words? Because if two words are the same, their sorted letters are the same. But if two words are the same, their set of letters is also the same, as long as there aren't any duplicate letters—which there aren't in your example. (Even if there were, you could handle that by using a "multiset", like , but immutable and hashable… although then comparisons aren't quite constant time anymore, they depend on the average number of duplicate letters… let's ignore that complexity, since it's not relevant to your example, but we could work it out if needed.)And now, our total time is just  instead of .Again, that last improvement is probably not worth doing (especially if you need the multiset solution, because the time we'd spend figuring out how to express the complexity of , and building and explaining , is probably more than the time we'd save running the program:), given .


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
