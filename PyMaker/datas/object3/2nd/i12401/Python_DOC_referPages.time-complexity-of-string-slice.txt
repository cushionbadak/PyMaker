Natural Text
What's the time complexity of slicing a Python string? Given that Python strings are immutable, I can imagine slicing them being either  or  depending upon how slicing is implemented.I need to write a function that iterates over all suffixes of a (potentially big) string. I could avoid slicing the string by representing a suffix as a tuple of the entire string plus an index to start reading characters from, but that's ugly. If instead I naively write my function like this:... will its time complexity be  or , where  is ?
Short answer:  slices, in general, copy. That means that your function that does a slice for each of your string's  suffixes is doing  work. That said, you can avoid copies if you can work with -like objects using s to get zero-copy views of the original bytes data. See How you can do zero copy slicing below for how to make it work.Long answer: (C)Python  do not slice by referencing a view of a subset of the data. There are exactly three modes of operation for  slicing:Complete slice, e.g. : Returns a reference to the exact same  (not just shared data, the same actual object,  since  is immutable so there is no risk to doing so)The zero length slice and (implementation dependent) cached length 1 slices; the empty string is a singleton (), and low ordinal strings of length one are cached singletons as well (on CPython 3.5.0, it looks like all characters representable in latin-1, that is Unicode ordinals in , are cached)All other slices: The sliced  is copied at creation time, and thereafter unrelated to the original The reason why #3 is the general rule is to avoid issues with large  being kept in memory by a view of a small portion of it. If you had a 1GB file, read it in and sliced it like so (yes, it's wasteful when you can seek, this is for illustration):then you'd have 1 GB of data being held in memory to support a view that shows the final 1 KB, a serious waste. Since slices are usually smallish, it's almost always faster to copy on slice instead of create views. It also means  can be simpler; it needs to know its size, but it need not track an offset into the data as well.How you can do zero copy slicingThere are ways to perform view based slicing in Python, and in Python 2, it will work on  (because  is bytes-like in Python 2, supporting the buffer protocol). With Py2  and Py3  (as well as many other data types like , ,  arrays, s, etc.), you can create a  that is a zero copy view of the original object, and can be sliced without copying data. So if you can use (or encode) to Py2 /Py3 , and your function can work with arbitrary -like objects, then you could do:The slices of s do make new view objects (they're just ultra-lightweight with fixed size unrelated to the amount of data they view), just not any data, so  can store a copy if needed and it won't be changed when we slice it down later. Should you need a proper copy as Py2 /Py3 , you can call  to get the raw  obj, or (in Py3 only it appears), decode it directly to a  that copies from the buffer, e.g. .
It all depends on how big your slices are. I threw together the following two benchmarks. The first slices the entire string and the second only a little bit. Curve fitting with this tool givesThe first looks quite linear for slices of strings up to 4MB. I guess this really measures the time taken to construct a second string. The second is pretty constant, although it's so fast it's probably not that stable.


Answer URL
https://docs.python.org/3/library/stdtypes.html#memoryview
https://docs.python.org/3/c-api/buffer.html#bufferobjects
https://docs.python.org/3/library/stdtypes.html#memoryview
