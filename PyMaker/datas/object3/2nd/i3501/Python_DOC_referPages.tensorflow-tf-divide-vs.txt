Natural Text
In tensorflow tutorials, I see both codes like  and , what is the difference between using the math function , , etc and the operators  and , etc, in precision or other aspects? 
There's no difference in precision between  and . The former translates to  which gets mapped to  by means of following line in math_ops.py The only difference is that node name in the underlying Graph is  instead of . You can generally compare things by looking at the underlying Graph representation like thisYou could also see this directly by inspecting the  method. There's an extra level of indirection because it's a closure, but you can get the underlying function as followsAnd you'll see output below which means that they call same underlying functionYou can see from  that following Python special methods are potentially overloaded by appropriate TensorFlow versionsThose methods are described in Python reference 3.3.7: emulating numeric types. Note that Python data model does not provide a way to overload assignment operator  so assignment always uses native Python implementation.
Yaroslav nicely explained that there is no real difference. I will just add when using  is beneficial.tf.add has one important parameter which is . It allows you to name the operation in a graph which will be visible in tensorboard. So my rule of thumb, if it will be beneficial to name an operation in tensorboard, I use  equivalent, otherwise I go for brevity and use overloaded version.
Now, the value of  printed will be  and simple  printed will be .


Answer URL
https://docs.python.org/3/reference/datamodel.html#emulating-numeric-types
