Natural Text
I have written code to find out common files between two given folders (paths) accounting for all levels of sub folders if present.Please suggest if there is a more efficient method. It's taking too long if folders with many levels of subfolders are given.and calling this function with paths, like shown below:I understand that if I store a list of all files for any given path the speed of execution can be reduced. but I guess that will run out of memory. Please guide me in approaching to this more efficiently. 
You can use generator expression to transform the output of  into two sets and use set intersection to efficiently identify the common paths.To reduce code duplication in the code above, you can use another list comprehension:And if you're looking for just the common file names rather than common path names, you can make the generator expression output just the file names instead:This is more efficient because it takes advantage of Python's set intersection operation, which has an average time complexity of , whereas your code with 2 nested loops always takes .


Answer URL
https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions
