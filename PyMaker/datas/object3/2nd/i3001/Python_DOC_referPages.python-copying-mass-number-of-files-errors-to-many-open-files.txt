Natural Text
I'm trying to copy a large number of files from one directory to another. However, in trying to speed up the process by using Threading I get an error where it complains about too many open files. Currently the test batch of files is around 700+ and below is the code. How do I fix this? In my example, I'm copying files from one location on the network to another location on the same network and files range from 1mb to 100mb.
You almost certainly don't want one to spawn a thread per file. To the extent that threading gives you a benefit (and you're not just saturating your disk I/O bandwidth anyhow), you should probably just use a thread pool (e.g. concurrent.futures.ThreadPoolExecutor) with a fixed number of threads. This will limit the number of files open at once. In fact this case is given as an example in the Python docs: https://docs.python.org/dev/library/concurrent.futures.html#concurrent.futures.Executor.shutdownAdapting this to your use:
I performed some timing of thread pools (both 4 thread pool and 8 thread pool) vs straight  vs OS copy of the files (ie, not in Python). The target device was one of:a local spinning hard drive;a fast external SSD with thunderbolt 3 interface;a SMB network mountpoint with an SSD on the mount device and 1000 base T interface.The source device was a very fast Mac internal SSD capable of 8K video editing, so much faster than any of the target devices. First create 100 random data files between 1 MB and 100MB:Now the timing code:The results were:And compare with raw unix copy times:As I suspected, the times (at least for MY tests) are all roughly the same since the limiting speed is the underlying I/O bandwidth. There was some advantage with thread pools for a network device with a tradeoff of a substantial disadvantage on a mechanical drive.  These results are only for copying from one homogenous location of files to another homogenous location with no processing of the individual files. If the steps involves some CPU intensive functions on a per file basis or the destination for the individual files involved different I/O paths (ie, one file to the SSD and based on some condition the next file to the network etc), that might favor using a concurrent approach. 


Answer URL
https://docs.python.org/3/library/shutil.html
