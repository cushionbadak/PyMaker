Natural Text
My program needs to spawn multiple instances of a class, each processing data that is coming from a streaming data source.For example:Once the instances are running they don't need to interact with each other, they just have to get the data as it comes in. (and print error messages, etc)I am totally at a loss how to make this work with multiprocessing, since I first have to create a new instance of the class DoStuff, and then have it run.This is definitely not the way to do it:We could try defining a function to spawn classes, but that seems ugly:Plus, I don't want to have 3 different copies of the API interface class running, I want that data to be shared between all the processes... and as far as I can tell, multiprocessing creates copies of everything for each new process.Ideas?Edit:I think I may have got it... is there anything wrong with this?
I came to the conclusion that it would be necessary to use multiprocessing.Queues to solve this. The data source (the streaming API) needs to pass copies of the data to all the different processes, so they can consume it.There's another way to solve this using the multiprocessing.Manager to create a shared dict, but I didn't explore it further, as it looks fairly inefficient and cannot propagate changes to inner values (e.g if you have a dict of lists, changes to the inner lists will not propagate).


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool
