Natural Text
I am fairly new to python, kindly excuse me for insufficient information if any. As a part of the curriculum , I got introduced to python for quants/finance, I am studying multiprocessing and trying to understand this better. I tried modifying the problem given and now I am stuck mentally with the problem.Problem:I have a function which gives me ticks, in ohlc format.every minute. I wish to do the following calculation concurrently and preferably append/insert in the samelistFind the Moving Average of the last 5 close dataFind the Median of the last 5 open dataSave the tick data to a database.so expected data is likely to beAssuming that the data is going to a db, its fairly easy to write a simple dbinsert routine to the database, I don't see that as a great challenge, I can spawn a to execute a insert statement for every minute.How do I sync 3 different functions/process( a function to insert into db, a function to calculate the average, a function to calculate the median), while holding in memory 5 ticks to calculate the 5 period, simple average Moving Average and push them back to the dict/list.The following assumption, challenges me in writing the multiprocessing routine. can someone guide me.  I don't want to use pandas dataframe.====REVISION/UPDATE===The reason, why I don't want any solution on pandas/numpy is that, my objective is to understand the basics, and not the nuances of a new library. Please don't mistake my need for understanding to be arrogance or not wanting to be open to suggestions.The advantage of having would help me understand the possibility of scaling processes based on no of functions /algo components.. But how should I make sure p1&p2 are in sync while p3 should execute post p1&p2
Here is an example of how to use multiprocessing:also see : https://stackoverflow.com/a/24101655/2026508note that this will not speed up anything unless there are a lot of slices.so for the speed up part:from what i understand multiprocessing works by message passing via pickles, so the  when called should have access to all three things, the two arrays, and the db_save function. There are of course other ways to go about it, but hopefully this shows one way to go about it.
Question: how should I make sure p1&p2 are in sync while p3 should execute post p1&p2If you sync all Processes, computing one Task (p1,p2,p3) couldn't be faster as the slowes Process are be.In the meantime the other Processes running idle.It's called "Producer - Consumer Problem".Solution using  all Data serialize, no synchronize required.You want multiple Consumer Processes and one Consumer Process gather all Results.You don't want to use , but .This Example let all Processes run independent.Only the Process  waits until notified.  This Example uses a unlimited Task Buffer .The Size could be minimized if List Entrys for done Tasks are reused.If you have some very fast algos combine some to one .Tested with Python: 3.4.2


Answer URL
https://docs.python.org/3/library/threading.html#condition-objects
