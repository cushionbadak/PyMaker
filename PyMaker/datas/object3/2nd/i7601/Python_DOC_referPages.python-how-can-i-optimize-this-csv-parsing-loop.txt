Natural Text
I wrote this loop to parse a 1 million row .csv file. It works, but can only process about 7k lines/minute. Is there a reasonable way I can get this running faster?The loop is currently transforming block of data into a row, and stripping out the extra characters, and writing each row to a new .csv file.Sample data: http://www.sharecsv.com/s/674dc42035c29eb4f250b5c2365c8dc6/OceanParseTest.csv
Don't reinvent the wheel to read csv file.You can use pandas.Or use csv standard library also.To read a big csv file, if these methods above don't work. You can split your file into small files, create a process to read each file.Your data sample.I think your format file isn't a csv file. Then suppose that you have one section like this:Clean this section with :format.sh:To get :If you are 1M of lines I suppose that you have around 15 000 sections.I get that with :Check:Give well 15 000 sections, 960000 lines, and 34MB..... 


Answer URL
https://docs.python.org/3/library/csv.html
