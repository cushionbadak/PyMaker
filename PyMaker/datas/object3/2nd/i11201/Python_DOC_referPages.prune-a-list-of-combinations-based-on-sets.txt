Natural Text
While this question is formulated using the Python programming language, I believe it is more of a programming logic problem. I have a list of all possible combinations, i.e.: n choose kI can prepare such a list usingIf 'n' is 100, and `k' is 5, then the length of 'bits_list' will be 75287520.Now, I want to prune this list, such that numbers appear in groups, or they don't. Let's use the following sets as an example:Set 1: [0, 1, 2] Set 2: [57, 58] Set 3: [10, 15, 20, 25] Set 4: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]Here each set needs to appear in any member of the bits_list together, or not at all. So far, I only have been able to think of a brute-force if-else method of solving this problem, but the number of if-else conditions will be very large this way. Here's what I have:Now, this only covered Set 1. I would like to do this for many sets. If the length of the set is longer than the value of k, we can ignore the set (for example, k = 5 and Set 4).  Note, that the ultimate aim is to have 'k' iterate over a range, say [5:25] and work on the appended list. The size of the list grows exponentially here and computationally speaking, very expensive!With 'k' as 10, the python interpreter interrupts the process before completion on any average laptop with 16 GB RAM. I need to find a solution that fits in the memory of a relatively modern server (not a cluster or a server farm). Any help is greatly appreciated! P.S.: Intuitively, think of this problem as generating all the possible cases for people boarding a public bus or train system. Usually, you board an entire group or you don't board anyone.UPDATE:For the given sets above, if k = 5, then a valid member of bits_list would be [0, 1, 2, 57, 58], i.e.: a combination of Set1 and Set2. If k = 10, then we could have built Set1 + Set2 + Set3 + NoSetElement as a possible member. @DonkeyKong's solution made me realize I haven't mentioned this explicitly in my question. I have a lot of sets; I intend to use enough sets to prune the full list of combinations such that the bits_list eventually fits into memory. @9000's suggestion is perfectly valid here, that during each iteration, I can save the combinations as actual bits. 
This still gets crushed by a memory error (which I don't see how you're getting away from if you insist on a list) at a certain point (around n=90, k=5), but it is much faster than your current implementation. For  and , my rudimentary benchmarking had my solution at 2.6 seconds and yours around 52 seconds. The idea is to construct the disjoint and subset parts of your filter separately. The disjoint part is trivial, and the subset part is calculated by taking the  of all disjoint combinations of length  and the individual elements of your set. 
If you actually represented your bits as bits, that is, 0/1 values in a binary representation of an integer n bits long with exactly k bits set, the amount of RAM you'd need to store the data would be drastically smaller. Also, you'd be able to use bit operations to look check if all  bits in a  are actually set (), or all unset ().The brute-force will probably take shorter that the time you'd spend thinking about a more clever algorithm, so it's totally OK for a one-off filtering.If you must execute this often and quickly, and your  is in small hundreds or less, I'd rather use cython to describe the brute-force algorithm efficiently than look at algorithmic improvements. Modern CPUs can efficiently operate on 64-bit numbers; you won't benefit much from not comparing a part of the number.OTOH if your  is really large, and the number of sets to compare to is also large, you could partition your bits for efficient comparison.Let's suppose you can efficiently compare a chunk of 64 bits, and your bit lists contain e.g. 100 chunks each. Then you can do the same thing you'd do with strings: compare chunk by chunk, and if one of the chunks fails to match, do not compare the rest.
A faster implementation would be to replace the if and all() statements in:with python's set operations  and  operations. I can keep going using generators and with generators you won't run out of memory but you will be waiting and hastening the heat death of the universe.  Not because of python's runtime or other implementation details but because there are some problems that are just not feasible even in computer time if you pick a large N and K values.
Based on the ideas from @Mitch's answer, I created a solution with a slightly different thinking than originally presented in the question. Instead of creating the list () of all combinations and then pruning those combinations that do not match the sets listed, I built  from the sets. Here, instead of finding n choose k, and then looping for all k, and finding combinations which match the sets, I started from the sets, and even included the individual members as sets by themselves and therefore removing the need for the 2 components - the disjoint and the subset parts - discussed in @Mitch's answer. 


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.product
