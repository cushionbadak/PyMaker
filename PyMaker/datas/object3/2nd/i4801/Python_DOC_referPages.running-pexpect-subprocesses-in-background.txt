Natural Text
I have the below code that I am runningNow, the command in pexpect creates subprocess by taking the one of the input from a loop, now everytime it spins up a subprocess I try to capture the logs via the child.read, in this case it waits for that subprocess to complete before going to the loop again, how do I make it to keep running it in the background(I get the logs of command input/output that I enter dynamically, but not of the process that runs thereafter unless I use the read or interact? I used this How do I make a command to run in background using pexpect.spawn? but it uses interact which again waits for that subprocess to complete .. since the loop will be iterated alomst more than 100 times I cannot wait on one to complete before moving to other, as the command in pexpect is an AWS lambda call, all I need to make sure is the command is triggered but I am not able to capture the process output of that call without waiting for it to complete.... Please let me know your suggestions
If you don't actually want to interact with lots of processes in parallel, but instead want to interact with each process briefly, then just ignore it while it runs and move onto interacting with the next one…A few things:Notice from the code comments that I'm assuming the child isn't writing anything to us (and waiting for us to read it) after the initial interaction. If that's not true, things are a bit more complicated.If you want to not only do this, but also spin up 8 children at a time, or even all of them at once, you can (as shown in my other answer) use an executor or just a mess of threads for the initial  calls, and have those tasks/threads return the child object to be ed on later. For example, with the  version, each future's  will be a pexpect child process. However, you definitely need to read the  docs on threads in that case—with some versions of linux, passing child-process objects between threads can break the objects.Finally, since you will now be seeing things much more out-of-order than the original version, you might want to change your  statements to show which child you're printing for (which also probably means changing  from a list of children to a list of  tuples or the like).
If you want to run a process in the background, but at the same time interact with it, the simplest solution is to just kick off a thread to interact with the process.*In your case, it sounds like you're running hundreds of processes, so you want to run some of them in parallel, but maybe not all of them at once? If so, you should use a thread pool or executor. For example, using  from the stdlib (or  the  backport if your Python is too old):If you need to return a value (or raise an exception) from the threaded code, you'll probably want a loop over  instead of just plain . But here, you just seem to be ing stuff out and then forgetting it.If the  really do come straight out of an iterable like this, it's usually simpler to use .All of this (and other options, too) is explained pretty nicely in the module docs.Also see the  FAQ and common problems. I don't think there are any issues that will affect you here in current versions (we're always spawning the child and interacting with it entirely in a single thread-pooled task), but I vaguely remember there used to be an additional problem in the past (something to do with signals?).* I think  would be a better solution, except that as far as I know none of the attempts to fork or reimplement  in a nonblocking way are complete enough to actually use…


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
