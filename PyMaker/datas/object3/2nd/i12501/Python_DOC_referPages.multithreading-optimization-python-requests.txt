Natural Text
I am trying to optimize this code, as of right now it runs 340 Requests in 10 mins.  I have trying to get 1800 requests in 30 mins.  Since I can run a request every second, according to amazon api.  Can I use multithreading with this code to increase the number of runs??  However, I was reading in the full data to the main function, should I split it now, how can I figure out how many each thread should take?
If you are using python 3.2 you can use  library to make it easy to launch tasks in multiple threads. e.g. here I am simulating running 10 url parsing job in parallel, each one of which takes 1 sec, if run synchronously it would have taken 10 seconds but with thread pool of 10 should take about 1 secondsOutput:


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example
