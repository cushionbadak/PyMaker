Natural Text
I can't use normal tools and technics to measure the performance of a coroutine because the time it takes at  should not be taken in consideration (or it should just consider the overhead of reading from the awaitable but not the IO latency).So how do measure the time a coroutine takes ? How do I compare 2 implementations and find the more efficent ? What tools do I use ?
This answer originally contained two different solutions: the first one was based on monkey-patching and the second one does not work for python 3.7 and onward. This new version hopefully presents a better, more robust approach.First off, standard timing tools such as time can be used to determine the CPU time of a program, which is usually what we're interested in when testing the performance of an asynchronous application. Those measurements can also be performed in python using the time.process_time() function: See below the similar output produced by both methods:In an asyncio application, it might happen that some synchronous part of the program ends up performing a blocking call, effectively preventing the event loop from running other tasks. So we might want to record separately the time the event loop spends waiting from the time taken by other IO tasks. This can be achieved by subclassing the default selector to perform some timing operation and using a custom event loop policy to set everything up. This code snippet provides such a policy along with a context manager for printing different time metrics.Note the difference between those two runs:Also notice that the asyncio debug mode can detect those blocking operations:
If you only want to measure performance of "your" code, you could used approach similar to unit testing - just monkey-patch (even patch + Mock) the nearest IO coroutine with Future of expected result. The main drawback is that e.g. http client is fairly simple, but let's say momoko (pg client)... it could be hard to do without knowing its internals, it won't include library overhead. The pro are just like in ordinary testing:it's easy to implement, it measures something ;), mostly one's implementation without overhead of third party libraries,performance tests are isolated, easy to re-run,it's to run with many payloads


Answer URL
https://docs.python.org/3/library/time.html#time.process_time
https://docs.python.org/3/library/selectors.html#selectors.DefaultSelector
https://docs.python.org/3/library/asyncio-policy.html#asyncio-policies
https://docs.python.org/3/library/asyncio-dev.html#asyncio-debug-mode
