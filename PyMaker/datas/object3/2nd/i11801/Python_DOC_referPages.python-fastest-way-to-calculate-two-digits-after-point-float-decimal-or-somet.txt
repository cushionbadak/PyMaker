Natural Text
As i found out, decimal is is more precise at the cost of processing power.And i found out thatalso counts the numbers before the point. In my case i need it only to calculate two numbers after the point no matter how big the number is. Because sometimes i got numbers like 12345.15 and sometimes numbers like 2.53. And what if the numbers are 5 or 298.1?Im a bit confused with all these differences between float, decimal, rounding and truncate.My main question is:How can i calculate with a Number like 254.12 or 15.35 with fewest resource costs? Maybe it is even possible to fake these numbers? The rounding doesn't matter but calculating with floats and 8 digits after the point and then truncating them seems like a waste of resources to me. Please correct me if im wrong.I also know how to do Benchmarks withBut im sure there are enough things i dont know about. Since im quite new to programming i would be very happy if someone can give me a few hints with a piece of code to work and learn with. Thank you for taking your time to read this! :)
First, please be aware that floating point operations are not necessarily as expensive as you might fear. This will depend on the CPU you are using, but for example, a single floating point operation in a mainly integer program will cost about as much as an integer operation, due to pipelining. It's like going to a bathroom at a night club. There's always a line for the girls bathroom - integer ops - but never a line for the guys - floating point ops.On the other hand, low-power CPUs may not even include floating point support at all, making any float operation hideously expensive! So before you get all judgy about whether you should use float or integer operations, do some profiling. You mention using  and comparing start with end times. You should have a look at the  module shipped with python.Worse than bad performance, though, is the fact that floats don't always represent the number you want. Regardless of decimal point, if a number is large enough, or if you do the wrong operation to it, you can end up with a float that "approximates" your result without storing it exactly.If you know that your application requires two digits beyond the decimal, I'd suggest that you write a class to implement that behavior using integer numbers. Python's integers automatically convert to big numbers when they get large, and the precision is exact. So there's a performance penalty (bignum ops are slower than integer or float ops on top-end hardware). But you can guarantee whatever behavior you want.If your application is financial, please be aware that you are going to have to spend some time dealing with rounding issues. Everybody saw Superman 3, and now they think you're stealing their .00001 cents...
In Python, all floats are all the same size, regardless of precision, because they are all represented in a single 'double' type. This means that either way you will be 'wasting' memory (24 bytes is a tiny amount, really). Using  shows this:This is also shown in the fact that if an int is too big (ints have no max value) it can't be converted into a float - you get an :Using  is even less efficient, even when the precision is set up right. This is because class instances take up lots of space on their own, regardless of their content:
The  setting actually affects the total number of digits, not only the ones after the decimal point. Regarding that, the documentation saysThe significance of a new Decimal is determined solely by the number  of digits input. Context precision and rounding only come into play  during arithmetic operations.and alsoThe quantize() method rounds a number to a fixed exponent. This method  is useful for monetary applications that often round results to a  fixed number of placesSo these are a few things you can look for if you need to work with a fixed number of digits after the point.Regarding performance, it seems to me that you are prematurely optimizing. You generally don't need to worry about the fastest way to do a calculation that will take less than a microsecond (unless, of course, you need to do something on the order of millions of such calculations per second). On a quick benchmark, a sum of two numbers takes 48 nanoseconds for s and 82 nanoseconds for s. The impact of that difference should be very little for most applications.


Answer URL
https://docs.python.org/3/library/decimal.html
