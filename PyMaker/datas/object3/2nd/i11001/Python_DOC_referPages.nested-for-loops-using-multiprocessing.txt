Natural Text
I have a quick question regarding multiprocessing in python. I am conducting a rather large grid search over three parameters and the computation is taking ~14 hours to complete. I would like to shrink this run time down by using multiprocessing. A very simplified example of my code is here:Now, I have absolutely zero experience in multiprocessing so my first attempt at this was changing the for loops into a function and then calling the multiprocessing function like this:This failed however at the pool.map call. I understand this function only takes a single iterable argument but I don't know how to fix the problem. I am also skeptical that the data_grid variable is going to be filled correctly. The result I want from this function is two files saved, one as an array of values whose indexes correspond to a, b, and c values and the last a list of lists containing the a, b, c values and the resulting value (example in the code above)Thanks for any help!-Will
This doesn't solve your multiprocessing problem but it might make your process faster.Your pattern of using nested loops to construct n-d coordinates and then operating on them can be vectorized using ```numpy.meshgrid````.  Without knowing your actual calcs this approach can't be tested.There is also the option of using  to create the actual points then use a single loop to iterate over the points - you lose the spatial info with this approach unless you can figure out how to reshape the result.  I found this in SO answer https://stackoverflow.com/a/18253506/2823755You can create a function and apply it to Reshaping this example is straightforward:Test to make sure they both the sameFor more complicated maths, just iterate over points:
As per user wwii's suggestions, I have rewrote the example above by using numpy's meshgrid  and getting rid of the nested for loops for just a single loop. Here is an example of the working code. This actually, after further investigation caused the run time to increase rather significantly. The difference between the for loops and this method was 20 seconds when subjected to a large range for a, b, and c. I have no idea why, but I do know this construction of the problem should make multiprocessing easier since there is only a single for loop to deal with. 


Answer URL
https://docs.python.org/3/library/collections.html#collections.namedtuple
