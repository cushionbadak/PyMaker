Natural Text
Motivation:For the sake of abstractness, I have a method treating a list of objects. Here I show a simplified version for illustration purpose (using Python2.7 here):However, for some cases, the input could be , then in the function call I have to recompute 1000 times of f(obj). We could possibly avoid it because all these are exactly the same object.My Solution:I can always cache the calculation result, asAnd this does exactly the job I want and it can indeed speedup the recomputation overhead.My Question:This solution is not enough neat to me because I have to manually do so in every function, will there be a better solution for avoiding a general "same-object-recomputation" for non-random functions? A global cache_map with keys from function id and all arguments seems not work because the object ids are only unique during their lifetime.In general I understand that this may not make too much sense in Python because these objects are mutable. May I ask if there is some existing scheme in functional programming languages like Scala dealing with this problem for immutable objects? Thanks!
You're describing memoization.This can be done by creating your own helper/decorator function or using functools.lru_cache from the standard library (Python 3.2+)
Something like this perhaps?You can then just do (among other uses) 


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
