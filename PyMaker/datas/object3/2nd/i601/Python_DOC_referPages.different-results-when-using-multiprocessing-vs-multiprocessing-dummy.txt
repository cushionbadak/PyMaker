Natural Text
I have a long running task that can be parallelized. I debugged code with use of . It works well and I get results I expect. But when I change it to  , it runs  function impossibly fast and actual output is not even touchedThe job is to fill pandas DataFrame with data up to some row count threshold. Each of longer processes in while cycle adds about 2500 rows at one run. Data acquisition is independent on other processes. The idea is, that processes pass DataFrame through Queue between each other and use lock to block access to it from other processes while they work with Dataframe. Once their work is done, they put it back and release lock.Once DataFrame is filled to required size, process can end and other processes are no longer required to finish(but Im not sure, if they are terminated once they finish without join() or just what happens with them - therefore .is_alive() check could replace .join())For this example  is set only to 10k but actual size will be much higherThe problem is, that when I change from  to  whole operation is finished in 0.7 seconds and returned X size is 0Maybe there is another way how to do it but Im not yet aware of it.Also I need it to run in separate file not test_mp.pyand run it form another file with  I get following output:with  Its:
Adding  in runfile made the code execute and get "some" results. But with more testing it appears to be using only one core(or I have something wrong in code)test_mp.pywith  I get following output:with  Its:Solved does not stress processor, but when its switched for function like the results from both  and  are as expected - both returns same length, but multiprocessing N-times faster


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming
