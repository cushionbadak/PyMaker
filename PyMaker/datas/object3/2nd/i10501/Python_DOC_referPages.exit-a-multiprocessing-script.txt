Natural Text
I am trying to exit a multiprocessing script when an error is thrown by the target function, but instead of quitting, the parent process just hangs.This is the test script I use to replicate the problem:This works perfectly, I can see the parent script spawning two child processes in  but when I want to force the parent script to exit if an error is thrown in the  target function the parent process just hangs and doesn't even spawn any child process. I have to  to kill it.I have tried every way to exit the function (e.g. , , ...) to no avail.
Firstly, your code has a major issue: you're trying to join the processes before flushing the content of the queues, if any, which can result in a deadlock. See the section titled 'Joining processes that use queues' here: https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programmingSecondly, the call to  will block until it receives some data, which never happensif an exception is raised from the  function and that no data has been pushed into the queue before then. So make it non-blocking and make it check for any data in a loop until it finally receives something or that something's wrong.Here's a quick'n'dirty fix to give you the idea:The function  will throw an exception but both processes will still join and the program will exit nicely.
You should use  to manage your processes for you. And then use  to iterate over the results in the order they are completed. As soon as you get the first exception, you can stop the pool and its child processes (this is automatically done when you exit the  block). egThis method is not suitable for long-timed, low-workload tasks, as it will only run as many of the tasks in parallel as the number of child processes it is managing (but this is something you can set). It's also not great if you need to run different functions.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming
