Natural Text
I'm trying to download over 30,000 files from a FTP server, and after some googling using asynchronous IO seemed a good idea. However, the code below failed to download any files and returns a Timeout Error. I'd really appreciate any help! Thanks!Error message if I remove the  part:  Traceback (most recent call last):  File "test.py", line 111, in       x.download_queue(urls)  File "test.py", line 99, in download_queue      loop.run_until_complete(asyncio.gather(*tasks))  File "/home/yz/miniconda3/lib/python3.6/asyncio/base_events.py", line 467, in run_until_complete      return future.result()  File "test.py", line 73, in unzip      data = await self.download_file(session, queue_url)  File "test.py", line 65, in download_file      return {"error": remotefile.status, "data": ""}  File "/home/yz/miniconda3/lib/python3.6/site- packages/async_timeout/init.py", line 46, in exit      raise asyncio.TimeoutError from None  concurrent.futures._base.TimeoutError  
Here you start process of downloading concurrently for all of your urls. It means that you start to count timeout for all of them also. Once it's a big number such as 30,000 it can't be physically done within 10 seconds due to networks/ram/cpu capacity.To avoid this situation you should guarantee limit of coroutines started simultaneously. Usually synchronization primitives like asyncio.Semaphore can be used to achieve this.It'll look like this:
As an alternative to @MikhailGerasimov's semaphore approach, you might consider using the aiostream.stream.map operator:Here's an equivalent implementation using pipes:You can test it with the following coroutines:See more aiostream examples in this demonstration and the documentation.Disclaimer: I am the project maintainer.


Answer URL
https://docs.python.org/3/library/asyncio-sync.html#asyncio.Semaphore
