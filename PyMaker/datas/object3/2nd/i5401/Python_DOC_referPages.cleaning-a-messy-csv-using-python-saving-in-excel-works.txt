Natural Text
I'm quite new to using python, and im trying to read loads (100s) of CSV files into one dataframe.  However, the csv files are quite messy, using multiple delimeters and such. I tried searching this site but all the things i found do not work. I have tried readlines and pd.read with many options, but all i get is errors or empty dataframes. When i open the CSV in excel it looks fine, and when i save it as an UTF-8 csv, all works fine. However, doing this for each excel file is so much work, even when using a macro. Is there any way to replicate this process using python code,in2csv for example? Below i have provided a part of the csv file i need to work with, and part of the csv that comes out of excel(that works). To me it looks like the main difference is the whitespace and comma delimiter, but changing this in pd.read does not help. many thanks in advance!Messy csv: Good CSV:
Seems that the first (title) line is unsalvageable because it contains spaces & unquoted fields. Could be fixed by a specific regex. I'll skip it instead.The rest of the lines is not csv, but contains quoted tokens separated by spaces, a breeze for :output:the file now opens properly in excel (note that various versions of excel require comma or semicolon separator by default)
Here is a more intuitive way to process large csv files for beginners. This allows you to process groups of rows, or chunks, at a time. You may want to check here, http://pandas.pydata.org/Pandas is a high performance data analysis library for big data.
You could just read the csv files as strings and then use regular expressions to handle splits. Typically the field delimiters are commas, semicolons or tabs, while a line ends with \n, so reading could look like this:Now data is a list of lists containing your data that should be easy to convert to a dataframe or anything else really. I included \n in the split , because in my test the line endings were still part of the lines. This is just an example, no doubt you will want to make a function from this and adapt it to your use case.
So this turned out to be mainly an encoding issue. I used a .exe called cpconverter to change the encoding from unicode (1200) to utf-8. Now pd.read works when i pass sep='\t'. It would be even better if i can change this encoding using a python script (or use the original encoding), but for now it works. Thanks for all the effort and help!Edit: passing encoding = 'utf-16' to pd.read_csv fixes everything now. Don't knwo how i missed it, but the original encoding is utf-16 apparently.


Answer URL
https://docs.python.org/3/library/functions.html#open
