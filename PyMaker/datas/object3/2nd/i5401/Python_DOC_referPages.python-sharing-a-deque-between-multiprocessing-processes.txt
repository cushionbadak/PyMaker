Natural Text
I've been looking at the following questions for the pas hour without any luck:Python sharing a dictionary between parallel processesmultiprocessing: sharing a large read-only object between processes?multiprocessing in python - sharing large object (e.g. pandas dataframe) between multiple processesI've written a very basic test file to illustrate what I'm trying to do:Currently this outputs the following :How can I access the mem value's from the main code or the process that runs "print_values"?
Unfortunately  doesn't support  but it does work with , , ,  and .  A  is fairly close so I've used it in the example below..You have to be a little careful using manager objects.  You can use them a lot like the objects they reference but you can't do something like...  to truncate the values because you're changing the referenced object.As for coding style, I might move the  objects outside the class or move the  function inside it but for an example, this works.  If you move things around, just note that you can't use  directly in the  method.  You need to pass it in when you start the process or the  that python does in the background will create a new instance and it won't be shared.Hopefully this works for your situation, if not, we can try to adapt it a bit.
So by combining the code provided by @bivouac0 and the comment @Marijn Pieters posted, I came up with the following solution:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue
