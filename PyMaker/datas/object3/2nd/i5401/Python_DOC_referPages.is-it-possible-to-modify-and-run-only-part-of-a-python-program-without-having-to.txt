Natural Text
I have written a Python code to train Brill Tagger from NLTK library on some 8000 English sentences and tag some 2000 sentences. The Brill Tagger takes many, many hours to train and finally when it finished training, the last statement of the program had some tiny syntax error and the code, therefore, did not return the output.Is it possible to retain the tagger in the trained state while correcting the error and getting the program running without having to wait several hours for the tagger to be trained on the very same data?
Yes! You have a few options. One quick and dirty thing that I employ frequently is dropping to a console. Add this to the end of your script (right after the training finishes):This works exactly like just the REPL you get from running , except all of the variables (including your trained model) are available:A more permanent solution would be to serialize your model and save it to a file right after training finishes. To do this you can use pickle:


Answer URL
https://docs.python.org/3/library/pickle.html
