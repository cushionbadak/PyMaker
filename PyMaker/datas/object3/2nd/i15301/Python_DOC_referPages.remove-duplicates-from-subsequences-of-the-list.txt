Natural Text
For part of log parser I need to filter occurrences of baud rate in the log.  First I get all occurrences using , then I'm trying to remove duplicates in subsequences in its result. Results are like , the list can contain several hundreds of values. So the first baud rate was , then , then again .I need to see how the baud rate changed, so I can't use , as it will lose information of baud rate switching points.  So, once again input: Desired output: What I have made already:  it works, but it doesn't seem pythonic enough to me. Please advise: is there some more efficient way possible, or do I even not need to invent the wheel again?
Use :Explanation: If no  function is given, then the elements are just grouped by identity, i.e. groups of consecutive equal elements are collapsed. The result is an iterator of key-elements and the groups (in this case, just repetitions of the key element). We need just the keys.Update: Using IPython's  magic command and a list of 100,000 random baud rates,  seems to be about as fast as the "compare to previous element loop" solutions, and a good deal shorter.

Iterate list  by normal method or by enumerate.Check last element of list  is equal to current element of list .If not equal then append current element of list  to list 'n`.Used try and expect because first time list  is empty code :Output:
I had to do the same thing, except I needed to save the position of each element. I am a physicist, so this code is probably crap, but it works. One can remove the aesthetic things like "print" and "press any key to continue..." as those were for debugging. Probably will adapt one of the answers on this thread.Final output. Position in array, then the value of that element.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.groupby
