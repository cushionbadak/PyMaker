Natural Text
I am doing a calculation on permutations of things from a generator created by itertools. I have a piece of code in this form (this is a dummy example):Except in the real code, there are several hundred thousand permutationsinstead of  I am opening files and getting results of  where  is a classifier trained in scikit-learnin place of  I'm storing a value from that predictionI think the  is trivial though.This takes too long. What should I do to make it faster? Such as:1) writing better code (maybe I should initialize  with the proper length instead of using  but how much will that help? and what's the best way to do that when I don't know the length before iterating through ?)2) initializing a pandas dataframe instead of a list and using ?3) using cython in pandas? Total newbie to this.4) parallelizing? I think I probably need to do this, but again, total newbie, and I don't know whether it's better to do it within a list or a pandas dataframe. I understand I would need to iterate over the generator and initialize some kind of container before parallelizing.Which combination of these options would be best and how can I put it together?
The  operation in pandas and  loop are slow. This code avoids using it.You can do this for each file and dataframe that you have then use pd.concat to quickly generate results thereafter. You can also add the enumeration of the permutations afterward if you want.


Answer URL
https://docs.python.org/3/library/multiprocessing.html
