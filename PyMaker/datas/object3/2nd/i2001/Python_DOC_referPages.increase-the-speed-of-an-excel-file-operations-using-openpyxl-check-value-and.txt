Natural Text
I have a medium size excel file, with about 25000 rows.In the excel file I check if a specific column value is in a list, and if is in the list I delete the row.I'm using openpyxl.The code:The code works, but is very slow(take hours) to finish. I know that is a read-only and write-only modes, but in my case, I use both, first checking and second deleting.
I see you are using a list of rows which you need to delete. Instead, you can create "sequences" of rows to delete, thus changing a delete list like [2,3,4,5,6,7,8,45,46,47,48] to one like [[2, 7],[45, 4]]i.e. Delete 7 rows starting at row 2, then delete 4 rows starting at row 45Deleting in bulk is faster than 1 by 1. I deleted 6k rows in around 10 secondsThe following code will convert a list to a list of lists/sequences:Then run another loop to delete
Personally, I would do two things:first transform the list into a set so the lookup of the item takes less timethen I would avoid removing the rows in place, as it takes a lot of time to reorganise the data structures representing the sheet.I would create a new blank worksheet and add to it only the rows which must be kept.Then save the new worksheet, overwriting the original if you wish.If it still takes too long, consider using a CSV format so you can treat the input data as text and output it the same way, re-importing the data later from the spreadsheet program (e.g. Ms-Excel)Have a look at the official docs and at this tutorial to find out how to use the CSV libraryFurther note: as spotted by @Charlie Clark, the calculation ofmay take some time as well and there is no need to repeat it.To do that, the easiest solution is to work backwards from the last row down to the first, so that the deleted rows do not affect the position of the ones before them.


Answer URL
https://docs.python.org/3/library/csv.html
