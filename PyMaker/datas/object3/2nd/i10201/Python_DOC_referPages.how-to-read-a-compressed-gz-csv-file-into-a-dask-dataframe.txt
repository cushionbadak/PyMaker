Natural Text
Is there a way to read a .csv file that is compressed via gz into a dask dataframe?I've tried it directly withbut get an unicode error (probably because it is interpreting the compressed bytes) There is a  parameter but  won't work and I can't find any documentation so far.With pandas I can read the file directly without a problem other than the result blowing up my memory ;-) but if I restrict the number of lines it works fine.
It's actually a long-standing limitation of dask. Load the files with  instead:
Panda's current documentation says:compression : {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}, default ‘infer’Since 'infer' is the default, that would explain why it is working with pandas.Dask's documentation on the compression argument:String like ‘gzip’ or ‘xz’. Must support efficient random access. Filenames with extensions corresponding to known compression algorithms (gz, bz2) will be compressed accordingly automaticallyThat would suggest that it should also infer the compression for at least gz. That it doesn't (and it still does not in 0.15.3) may be a bug. However, it is working using compression='gzip'.i.e.:
Without the file it's difficult to say. what if you set the encoding ? or since  is based off of Pandas, you may even . Here's the list of Python encodings: https://docs.python.org/3/library/codecs.html#standard-encodings


Answer URL
https://docs.python.org/3/library/codecs.html#standard-encodings
