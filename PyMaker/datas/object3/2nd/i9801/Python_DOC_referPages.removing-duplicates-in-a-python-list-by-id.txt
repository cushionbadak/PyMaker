Natural Text
I build large lists of high-level objects while parsing a tree. However, after this step, I have to remove duplicates from the list and I found this new step very slow in Python 2 (it was acceptable but still a little slow in Python 3). However I know that distinct objects actually have a distinct id. For this reason, I managed to get a much faster code by following these steps:append all objects to a list while parsing;sort the list with  option;iterate over the sorted list and remove an element if the previous one has the same id.Thus I have a working code which now runs smoothly, but I wonder whether I can achieve this task more directly in Python.Example. Let's build two identical objects having the same value but a different id (for instance I will take a  in order to rely on the standard library):Now, if I try to achieve what I want to do by using the pythonical , I get the wrong result as  keeps only one of both values (which are identical but have a different id).My question now is: what is the most pythonical, reliable, short and fast way for removing duplicates by id rather than duplicates by value? Order of the list doesn't matter if it has to be changed.
You should override the  method so that it depends on the objects  rather than its values. But note that your objects must be hashable as well, so you should define a proper  method too.Demo:
Be, careful because discrimating by  may fail with some basic types where python optimizes storage when possible:yieldsAnyway, if you want to handle standard objects (even non-hashable ones) you can store them in a dictionary with they  as key.Example with fractions:result:


Answer URL
https://docs.python.org/3/reference/datamodel.html#object.__eq__
https://docs.python.org/3/reference/datamodel.html#object.__hash__
