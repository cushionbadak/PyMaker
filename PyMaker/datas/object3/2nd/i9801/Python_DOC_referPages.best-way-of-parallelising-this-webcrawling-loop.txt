Natural Text
I am making a webcrawler, and I have some "sleep" functions that make the crawl quite long.For now I am doing : The  function is opening several webpages, waiting a few second for complete html download before moving on. The execution time is then very long : there is 25 * 10 * 2 = 500 loops, with no less than a minute by loop.I would like to use my 4 physical Cores (8 threads) to enjoy parallelism.I read about tornado, multiprocessing, joblib... and can't really make my mind on an easy solution to adapt to my code.Any insight welcome :-)
tl;dr Investing in any choice without fully understanding the bottlenecks you are facing will not help you.At the end of the day, there are only two fundamental approaches to scaling out a task like this:MultiprocessingYou launch a number of Python processes, and distribute tasks to each of them. This is the approach you think will help you right now. Some sample code for how this works, though you could use any appropriate wrapper:If this is all you wanted, you can stop reading now. Asynchronous ExecutionHere, you are content with a single thread or process, but you don't want it to be sitting idle waiting for stuff like network reads or disk seeks to come back - you want it to go on and do other, more important things while it's waiting.True native asynchronous I/O support is provided in Python 3 and does not exist in Python 2.7 outside of the Twisted networking library. So What's the Difference?My main point here it to emphasise that choosing from a list of technologies isn't as hard as figuring out where the real bottleneck is.In the examples above, there isn't any difference. Both follow a simple pattern:Have a lot of workersAllow these workers to pick something from a queue of tasks right awayWhen one is free, set them to work on the next one right away.Thus, you gain no conceptual difference altogether if you follow these examples verbatim, even though they use entirely different technologies and claim to use entirely different techniques. Any technology you pick will be for naught if you write it in this pattern - even though you'll get some speedup, you will be sorely disappointed if you expected a massive performance boost.Why is this pattern bad? Because it doesn't solve your problem.Your problem is simple: you have wait. While your process is waiting for something to come back, it can't do anything else! It can't call more pages for you. It can't process an incoming task. All it can do is wait.  Having more processes that ultimately wait is not the true solution. An army of troops that has to march to Waterloo will not be faster if you split it into regiments - each regiment eventually has to sleep, though they may sleep at different times and for different lengths, and what will happen is that all of them will arrive at almost roughly the same time. What you need is an army that never sleeps.So What Should You Do?Abstract all I/O bound tasks into something non-blocking. This is your true bottleneck. If you're waiting for a network response, don't let the poor process just sit there - give it something to do. Your task is made somewhat difficult in that by default reading from a socket is blocking. It's the way operating systems are. Thankfully, you don't need to get Python 3 to solve it (though that is always the preferred solution) - the asyncore library (though Twisted is comparably superior in every way) already exists in Python 2.7 to make network reads and writes truly in the background. There is one and only one case where true multiprocessing needs to be used in Python, and that's if you are doing CPU-bound or CPU-intensive work. From your description, it doesn't sound like that's the case.In short, you should edit your  function to avoid the incipient wait. Make that wait in the background, if needed, using a suitable abstraction from Twisted or asyncore. But don't make it consume your process completely. 
If you're using python3, I would check out the asycio module. I believe you can just decorate  with . You will likely have to adjust what  does to properly work with the event loop as well.


Answer URL
https://docs.python.org/3/library/asyncio-task.html
