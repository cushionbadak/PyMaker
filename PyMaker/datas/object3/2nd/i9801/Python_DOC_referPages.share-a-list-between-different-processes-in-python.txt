Natural Text
I have the following problem. I have written a function that takes a list as input and creates a dictionary for each element in the list. I then want to append this dictionary to a new list, so I get a list of dictionaries. I am trying to spawn multiple processes for this. My problem here is that I want the different processes to access the list of dictionaries as it is updated by other processes, for example to print something once the has reached a certain length. My example would be like this:Right now my problem is that each process creates its own . Is there a way to share the list between processes, such that all dictionaries are appended to the same list? Or is the only way to define the  outside of the function?
One way is to use a manager object and create your shared list object from it:Remember, unlike threads, processes do not share memory space. (When spawned, each process gets its own copy of the memory footprint of the spawning process, and then runs with it.) So they can only communicate via some form of IPC (interprocess communication). In Python, one such method is  and the data structures it exposes, e.g.  or . These are used in code as easily as their built-in equivalents, but under the hood utilize some form of IPC (sockets probably).


Answer URL
https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues
