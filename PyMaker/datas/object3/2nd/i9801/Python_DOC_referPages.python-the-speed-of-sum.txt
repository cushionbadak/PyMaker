Natural Text
I know the fastest way to sum a list of number is use the built in function . Using a  loop could be a slower way to do the sum than using . However when I try it, it is not true. Can someone explain this result?the time I get:
Let me show you how to do this more systematically.  First, you should use the  module for benchmarking.  It's a little awkward to use correctly but it is significantly more accurate.  Second, make absolutely certain you are not doing any work other than the work you care about benchmarking within the test.  In particular, you should not print out anything in the functions under test, because printing things is expensive.  Third, you should test each candidate function over a range of lengths and then graph the result.  Fourth, you don't need to go up to a million numbers to get useful results.We run this test program, and then we plot the output.  You didn't say whether you were using Python 2 or 3, so I wrote the above to work with either, and I tested it both ways.  [EDIT: And since another answer mentioned it, I've now tested PyPy as well.] Don't worry about the details of what I'm doing to make plots -  is well worth learning, but it, and the R language it's embedded in, can be pretty darn cryptic.Which pretty clearly demonstrates that using  is indeed slower than the  loop, but  is much faster than either.  It also clearly demonstrates that CPython 3.5 is slower at this than 2.7, which is sad but expected.  PyPy is not only a solid 5x faster than either of them, but all three algorithms perform equally well! That's what happens when you throw a genuine optimizing compiler at this sort of code.  (PyPy is faster than CPython's  intrinsic because it can figure out that all the elements of the array are numeric and slice out a bunch of per-element overhead.  The  method of a NumPy array would probably be as fast or faster than PyPy.)It's often good to plot data like this on a log-log scale - this is also why I picked the lengths I did:See how they've all got roughly the same slope now?  That means the asymptotic complexity of all three techniques is the same, O(n), just different constant factors.  Asymptotic complexity is important because it lets you predict how long bigger inputs will take.  In this case, we could just extend the three lines out to a million on the x-axis if we wanted to know how long they would take for your original test case.  With a different big-O we'd see curves, and we'd need to extrapolate them differently.We can also see that sum() has a bend in its curve, which was completely invisible on the linear plot; that means there  might be some special casing of short lists in the implementation.  And it's also clearer that  has very nearly the same performance as the hand-written  loop in 2 but not 3;  is no longer a built-in function in 3, but it's still implemented in compiled code, so I don't have an explanation for this.And we can see that PyPy is dramatically slower at the beginning, in an unpredictable way: that's because the cost of just-in-time compilation of the functions being benchmarked has been ascribed to the early calls.  I could add a "warm-up" step to the benchmark and make that go away, but it's a good thing to know about.On the other hand, the fact that CPython 3 is significantly slower than CPython 2 is much harder to see on the log-log plot.
I get dramatically different timings for . You might want to use  as a better way to time small bits of code. Here is an example:Python3 prints:Python2 prints:PyPy:
After reading your question the first thing that came to my mind:Using a for loop could be a slower way to do the sum than using reduceIs this based on some documentation or data or just an assumption? I read around a little, and it looks like it is just an assumption.Based on python document on functional programmingFunctional design may seem like an odd constraint to work under. Why should you avoid objects and side effects? There are theoretical and practical advantages to the functional style:Formal provability.Modularity.Composability.Ease of debugging and testing.Speed doesn't seem to be an advantage. If anything, I think because of the overhead of calling a function it will be slow (your empirical data supports this).Also,  is faster as it is implemented in 


Answer URL
https://docs.python.org/3/howto/functional.html
