Natural Text
Is there a way to measure time with high-precision in Python --- more precise than one second?  I doubt that there is a cross-platform way of doing that; I'm interesting in high precision time on Unix, particularly Solaris running on a Sun SPARC machine.timeit seems to be capable of high-precision time measurement, but rather than measure how long a code snippet takes, I'd like to directly access the time values. 
The standard  function provides sub-second precision, though that precision varies by platform. For Linux and Mac precision is  1 microsecond or 0.001 milliseconds. Python on Windows uses  16 milliseconds precision due to clock implementation problems due to process interrupts. The  module can provide higher resolution if you're measuring execution time.Python 3.7 introduces new functions to the  module that provide higher resolution:
Python tries hard to use the most precise time function for your platform to implement : ( from http://svn.python.org/view/python/trunk/Modules/timemodule.c?revision=81756&view=markup )
David's post was attempting to show what the clock resolution is on Windows. I was confused by his output, so I wrote some code that shows that  on my Windows 8 x64 laptop has a resolution of 1 msec:Which outputs:And a way to do a 1000 sample average of the delta:Which output on two consecutive runs:So  on my Windows 8 x64 has a resolution of 1 msec.A similar run on  returns a resolution of 0.4 microseconds: Returns:Which is ~An interesting thing about  is that it returns the time since the method was first called, so if you wanted microsecond resolution wall time you could do something like this:(which would probably drift after a while, but you could correct this occasionally, for example  would correct it every hour)
You can also use time.clock() It counts the time used by the process on Unix and time since the first call to it on Windows. It's more precise than time.time().It's the usually used function to measure performance.Just call EDITED: Ups, I miss the question as you want to know exactly the time, not the time spent... 
If Python 3 is an option, you have two choices: which always use the most accurate clock on your platform. It does include time spent outside of the process. which returns the CPU time. It does NOT include time spent outside of the process.The difference between the two can be shown with:Which outputs:
 has 13 decimal points on Windows but only two on Linux. has 17 decimals on Linux and 16 on Windows but the actual precision is different.I don't agree with the documentation that  should be used for benchmarking on Unix/Linux. It is not precise enough, so what timer to use depends on operating system.On Linux, the time resolution is high in :On Windows, however the time function seems to use the last called number:Even if I write the calls on different lines in Windows it still returns the same value so the real precision is lower.So in serious measurements a platform check () has to be done in order to determine whether to use  or .(Tested on Windows 7 and Ubuntu 9.10 with python 2.6 and 3.1)
Python 3.7 introduces 6 new time functions with nanosecond resolution, for example instead of  you can use :These 6 functions are described in PEP 564:These functions are similar to the version without the _ns suffix, but  return a number of nanoseconds as a Python int.
The comment left by tiho on Mar 27 '14 at 17:21 deserves to be its own answer:In order to avoid platform-specific code, use timeit.default_timer()
I observed that the resolution of time.time() is different between Windows 10 Professional and Education versions.On a Windows 10 Professional machine, the resolution is 1 ms. On a Windows 10 Education machine, the resolution is 16 ms.Fortunately, there's a tool that increases Python's time resolution in Windows:https://vvvv.org/contribution/windows-system-timer-toolWith this tool, I was able to achieve 1 ms resolution regardless of Windows version. You will need to be keep it running while executing your Python codes.
For those stuck on windows (version >= server 2012 or win 8)and python 2.7,GetSystemTimePreciseAsFileTime function
The original question specifically asked for Unix but multiple answers have touched on Windows, and as a result there is misleading information on windows.  The default timer resolution on windows is 15.6ms you can verify here.Using a slightly modified script from cod3monk3y I can show that windows timer resolution is ~15milliseconds by default.  I'm using a tool available here to modify the resolution.Script:These results were gathered on windows 10 pro 64-bit running python 3.7 64-bit.  



Answer URL
https://docs.python.org/3/library/time.html#time.process_time
