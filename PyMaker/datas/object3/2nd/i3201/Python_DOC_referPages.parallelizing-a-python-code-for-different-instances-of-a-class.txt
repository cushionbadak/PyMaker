Natural Text
My question is related to parallelizing a python code and I want to know how we can run a function for different instances of a class to decrease the runtime. What I have: I have multiple instances of a class A (stored in a list called instances). This class has a function add. Now, we have multiple independent tasks, one for each instance of class A where the input to all these tasks is one thing (number n in my example). Each instance needs to apply function add to n and return a number. We want to store the returned numbers of all instances in a list (list results in my example). What I want: As you can see, in this example, the tasks can be parallelized as there is no need for one to wait for the other one to gets done. How can we parallelize the simple code below? Since nothing is shared between the different instances, I guess we can even use multithreading, right? Or the only way is to use multiprocessing?Output: [20, 21, 22, 23, 24]
The pattern that your toy code seems to follow would suggest to map a wrapper function to the list using a thread pool / process pool. The number of instances and the basic arithmetic operation that you want to apply for each instance however suggests that the overhead for parallelizing this would outweigh any potential benefit.Whether it makes sense to do this, depends on the number of instances and the time it takes to run each of those member functions. So make sure to do at least some basic profiling of your code before you try to parallelize this. Find out whether the tasks you attempt to parallelize is CPU-bound or IO-bound.Here's an example that should demonstrate the basic pattern:Obviously you need to fill the blanks to adapt this to your real code.For further reading:https://docs.python.org/3/library/multiprocessing.htmlhttps://docs.python.org/2/library/multiprocessing.html#module-multiprocessing.dummyHow to use threading in Python?https://wiki.python.org/moin/GlobalInterpreterLockWhat is a global interpreter lock (GIL)?What do the terms "CPU bound" and "I/O bound" mean?Also maybe have a look at futures:https://pymotw.com/3/concurrent.futures/index.html#module-concurrent.futureshttps://docs.python.org/3/library/concurrent.futures.htmlIf you really want to have this parallel, also consider to port your calculations to a GPU (you might need to move away from Python then).


Answer URL
https://docs.python.org/3/library/multiprocessing.html
https://docs.python.org/3/library/concurrent.futures.html
