Natural Text
let say we have a list of strings which is so big that if I save it as a normal text file(every element in a separate line) it'll be 1GB in size;currently I use this code to save the list:as soon as we reach to this part of code: , I can see a huge bump in memory usage and also considerable time(~1min) to save the results;any tip or suggestion for better handling this list(less memory-usage) and save it on hard-disk more quickly?
The join in:is creating a very large string in the memory before writing it down. It will be much more memory efficient if you use a for loop:another question is, why do you have so many strings in the memory in the first place?
I would do it by iterating.
To save disk-space you could do:(also use the  operator instead).Combine this with a  operator in order to save memory:And to do it really quick you could potentially do (saves memory, disk-space and time):Note however that this big list of yours would only be accessible to external programs if they understand pythons pickle structure on the data.But assuming you want to re-use the BigList in your own application, pickle is the way to go.Noticed some comment about you reading a big textfile in order to write to another file..In that case the above an approach that would work for you.If you want to save memory or time over two files. Consider the following instead:


Answer URL
https://docs.python.org/3/library/codecs.html#codecs.open
