Natural Text
We have CentOS 7 servers in a Hadoop cluster.  Python and pip should have been installed on all of the server the same way because it was done with Ansible.  But for some reason, there are some servers where Python cannot use the modules that were installed.  For instance pandas was install, but when in python3.6, I get a 'No module named pandas' error.If I try installing pandas again, I get messages that the reuirements are already satisfied.It appears that the python 3.6 sys.path is using a different location for site-packages.It may all stem from pip being installed in an unusual location.Pip and the modules seem to be located in the same place, correctly on servers that DO work as follows:So my question is, how do I get this fixed and how do I keep this from happening in the first place?  I don't seem to find a way to configure Pip and I don't find any way to specify the installation location for modules.I tried to be thorough with the information provided, but I'm sure I missed something.Thanks,AnthonyWell, the Pip documentation for the config pointed me to the --target option for pip install.  That allowed me to specify the location where I thought the packages should go - /usr/local/lib/python3.6/site-packages (as noted in the sys.path).  That allowed the import to find the pandas package, but fail on the import of some basic system modules, builtin and binascii.  It seems like python itself is kinda hosed.Ugh...
You need to be very careful using pip when having multiple Python distributions. Instead of using python3.6 -m pip` to install  pandas:(prepend  if you really need to). In this way you are invoking pip through Python itself, and so you are guaranteed to get the pip that belongs with the Python you want.
You can try to set the location for pip in As per PIP Docs:Configuration Config filepip allows you to set all command line option defaults in a standard  ini style config file.The names and locations of the configuration files vary slightly  across platforms. You may have per-user, per-virtualenv or site-wide  (shared amongst all users) configuration:Per-user:environment variable.      On macOS the configuration file is $HOME/Library/Application Support/pip/pip.conf.      On Windows the configuration file is %APPDATA%\pip\pip.ini.There are also a legacy per-user configuration file which is also  respected, these are located at:You can set a custom path location for this config file using the  environment variable PIP_CONFIG_FILE.Inside a virtualenv:Site-wide:environment variable XDG_CONFIG_DIRS (if it exists), for example  /etc/xdg/pip/pip.conf.      On macOS the file is: /Library/Application Support/pip/pip.conf      On Windows XP the file is: C:\Documents and Settings\All Users\Application Data\pip\pip.ini      On Windows 7 and later the file is hidden, but writeable at C:\ProgramData\pip\pip.ini      Site-wide configuration is not supported on Windows VistaIf multiple configuration files are found by pip then they are  combined in the following order:Each file read overrides any values read from previous files, so if  the global timeout is specified in both the site-wide file and the  per-user file then the latter value is the one that will be used.
Short answer, but I would recommend using Python Virtual Environments. Makes managing Python versions and pip packages very easy.https://docs.python.org/3/tutorial/venv.htmlThis way you can have many different virtualized Python environments and activate them for whatever script, Ansible playbook, etc you are running. Another great feature is you can create a requirements file to share with others, so if they want to run your code they can simply install from the requirements file which guarantees they have the right version of Python and associated packages installed.


Answer URL
https://docs.python.org/3/tutorial/venv.html
