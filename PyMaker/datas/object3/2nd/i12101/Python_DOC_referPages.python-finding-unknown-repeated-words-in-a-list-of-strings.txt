Natural Text
I have a list of strings, which are subjects from different email conversations. I would like to see if there are words or word combinations which are being used frequently.An example list would be:The function would have to detect that "Company Name" as combination is used more than once, and that "Proposal" is being used more than once. These words won't be known in advance though, so I guess it would have to start trying all possible combinations.The actual list is of course a lot longer than this example, so manually trying all combinations doesn't seem like the best way to go. What would be the best way to go about this?UPDATEI've used Tim Pietzcker's answer to start developing a function for this, but I get stuck on applying the Counter correctly. It keeps returning the length of the list as count for all phrases.The phrases function, including punctuation filter and a check if this phrase has already been checked, and a max length per phrase of 3 words:And then the loop through the list of subjects:"all_phrases" returns a list with tuples where each count value is 167, which is the length of the subject list I'm using. Not sure what I'm missing here...
You also want to find phrases that are composed of more than single words. No problem. This should even scale quite well.The function  splits the input string on whitespace and returns all possible substrings of any length:Now you can count how many times each of these phrases are found in all your subjects:Result:Note that you might want to use other criteria than simply splitting on whitespace, maybe ignore punctuation and case etc.
I would suggest that you use space as a separator, otherwise there are too many possibilities if you don't specify how an allowed 'phrase' should look like.To count word occurrences you can use  from the  module:Output:
Similar to pp_'s answer. Using Split.  Output:


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
