Natural Text
Suppose that there are six kinds of problems to be handled when reading a book,I illustrate the details as follow:Assume I have 3 problems,the above program might endless loop on first one and never touch the second.Take an example that I am reading a book,'Problem A' is defined as encounter a 'new word', handle it is to look up dictionary.When looking up, I might come acorss another new word, another and another.In this case, I will never end up reading one sentence of a book.   As a solution,I introduce a container to collect problems, value-weighted them then determine to execute which one.    I tried alternatively to seek inspiration and improve efficiency.Again, the value_weighted process consume huge efforts and time. How to solve such a problem in a proper algorithms?  
'Problem A' is defined as encounter a 'new word', handle it is to look up dictionary.  When looking up, I might come across another new word, another and another.  In this case, I will never end up reading one sentence of a book.Looks like it will eventually end up reading the sentence, since the number of new words is limited by dictionary size. In general it sounds OK to me, unless there are some other restrictions not explicitly mentioned, like finish sentence reading in a limited time.How to solve such a problem in a proper algorithms?Well, if there is no a "limited time" restriction, your original algorithm is almost perfect. To make it even better in therms of overall performance, we might handle all problems  first, then move to  and so on. It will increase the data locality and overall performance of our algorithm.But if there is a "limited time" restriction, we can end up reading full sentence in that time (without full understanding) or end up reading part of the sentence (fully understanding that part) or something in between (like suggested by @Lauro Bravar).From the example above it is not quite clear how we do the , but the proper name for this kind of problems is Priority Queueing. There are variety of algorithms and implementations, please have a look at Wikipedia page for the details: https://en.wikipedia.org/wiki/Priority_queue
You can do several things to approach such a problem.One of them is to set a value of "max-iterations" or "max-effort" in a Machine Learning style that you can invest into reading a book. Therefore you will execute (handle) only up to a number of actions, until the limit has been reached. This solution will look like:The actions you do should be the ones that report more benefit/less effort according to some metric that you need to define.When you perform a certain action (handle) you substract the cost/effort of that action from  and you continue with your flow.
You have already the algorithm (with the help of Andriy for the priority queue), but you lack the design. When I see your multple s that check the type of the problem, I think to polymorphism.Why not try OOP? You have two objects to define: a problem and a priority queue. Fortunately, the priority queue is defined in the  module. Let's focus on the problem:in its core definition, it is handled and may be compared to other problems (it is more or less urgent). Note that, guided by the OOP principles, I do not talk of the structure or implementation of a problem,but only of the functions of a problem:But you said that when a problem is handled, it may add new problems to the queue. So let's add a precision to the definition of :In Python,  is a special method named , for "lower than". (You have other special comparison methods, but  will be sufficient here.)Here's a basic implementation example:Wait! Why "lower than" and a ? That's because the module  is a min-heap: it returns the smallest element first. Thus, we define the big weights as smaller than the little weights.Now, we can build a begin queue with fake data for the example:And run the main loop:I guess you will be able to subclass the  class to represent the various problems you might want to handle.


Answer URL
https://docs.python.org/3/reference/datamodel.html#special-method-names
