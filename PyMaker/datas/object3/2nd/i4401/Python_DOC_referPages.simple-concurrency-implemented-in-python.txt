Natural Text
Purpose of the question: learn more about ways to implement concurrency in Python / experimenting.Context: I want to count all of the words in all of the files that match a particular pattern. The idea is that I can invoke the function  and all of the words (i.e., strings separated by one or more whitespace characters) will be counted.In the implementation I am looking for ways to implement  using concurrency. So far I managed to use  and . Do you see alternative approaches to do the same task?I did not use  as I noticed the performance improvement was not that impressive due to the limitation of the Python GIL.For simulating large quantity of files, I downloaded some books from Project Gutenberg (http://gutenberg.org/) and used the following command to create several duplicates of the same file.
 doesn't make function calls concurrent magically, in asyncio you need to explicitly give up execution to allow other coroutines run concurrently by using  on awaitables. That said, your current  is still executed sequentially.You may want to introduce aiofiles to defer the blocking file I/O into threads, allowing concurrent file I/O in different coroutines. Even with that, the piece of CPU-bound code that calculates the number of words still run sequentially in the same main thread. To parallelize that, you still need multiple processes and multiple CPUs (or multiple computers, check Celery).Besides, there is an issue in your asyncio code -  again make the function calls run sequentially. You'll need  to start them concurrently, and  to join the results.


Answer URL
https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.AbstractEventLoop.create_task
https://docs.python.org/3/library/asyncio-task.html#asyncio.wait
