Natural Text
Preamble:Python setuptools are used for the package distribution. I have a Python package (let us call it ), that has several  packages to it. Everything works just find (installation and build of the package, as well as extras, if were requested), as all  were python packages themselves and pip correctly resolved everything. A simple  worked like a charm.Setup: Now, for one of the extras (let us call it ) I need to call a binary of a non-python library . Module  itself (source code) was added to the  codebase and was included in the distribution . Sadly for me, to be utilized,  needs to be compiled first into a binary on the target machine (C++ implementation; I assume such compilation shall happen on the build stage of  installation). There is a  in the  library optimized for different platform compilation, so all that is needed, is to run  in the respective directory of  library in the  when the build process is running. Question #1: how to run a terminal command (i.e.,  in my case) during the build process of the package, using setuptools/distutils? Question #2: how to ensure, that such terminal command is executed only if the corresponding  is specified during the installation process? Example:If someone runs , no such additional compilation of library  shall happen.If someone runs , module  needs to be compiled, so the corresponding binary would be created and available on the target machine.
This question came back to haunt me long after I commented on it two years ago! I had almost the same problem myself recently, and I found the documentation VERY scarce, as I think most of you must have experienced. So I tried to research a bit of the source code of setuptools and distutils to see if I could find a more or less standard approach to both the questions you asked.The first question you askedQuestion #1: how to run a terminal command (i.e.,  in my case) during the build process of the package, using setuptools/distutils?has many approaches and all of them involve setting a  when calling . The parameter  of  must be a mapping between command names that will execute depending on the build or install needs of the distribution, and classes that inherit from  base class (as a side note, the  class is derived from '  class so you can derive directly from  implementation).The  allows you to define any command name, like what ayoon did and then execute it specifically when calling  from the command line. The problem with this, is that it is not the standard command that will be executed when trying to install a package through  or by calling . The standard way to approach this is to check what commands will  try to execute in a normal install and then overload that particular .From looking into  and ,  will run the commands it found in the command line, which lets assume is just a plain . In the case of , this will trigger a series of tests that will see whether to resort to a simple call to the  command class, and if this does not occur, it will attempt to run . In turn, this command does many things but crucially decides on whether to call the ,  and/or the  commands. The  simply runs  if necessary which also runs ,  and/or . This means that regardless of whether you use  or , if it is necessary to build from source, the commands , , and/or  will be runned, so these are the ones that we will want to overload with the  of , the question becomes which of the three. is used to "build" pure python packages, so we can safely ignore it. is used to build declared Extension modules that are passed through the  parameter of the call to the  function. If we wish to overload this class, the main method that builds each extension is  (or here for distutils) is used to build declared libraries that are passed through the  parameter of the call to the  function. In this case, the main method that we should overload with our derived class is the  method (here for ).I'll share an example package that builds a toy c static library through a Makefile by using   command. The approach can be adapted to using the  command, but you'll have to checkout the source code of .setup.pytest_pack/__init__.pytest_pack_opt/__init__.pytest_pack_opt/src/Makefiletest_pack_opt/src/test.ctest_pack_opt/src/testlib.ctest_pack_opt/src/testlib.hIn this example, the c library that I want to build using the custom Makefile just has one function which prints  to stdout. The  script is a simple interface between python and this library's single function. The idea is that I tell  that I want to build a c extension named , which only has a single source file: the  interface script, and I also tell the extension that it must link against the static library . The main thing is that I overload the  cmdclass using . The inheritance from  is only necessary if you want to be able to call  to dispatch to parent class methods. The  method takes an  instance as its second argument, in order to work nice with other  instances that require the default behavior of , I check if this extension has the name of the special one and if it doesn't I call the 's  method.For the special library, I call the Makefile simply with . The rest of the command passed to the shell is just to move the static library to a certain default location in which the library should be found to be able to link it to the rest of the compiled extension (which is also just compiled using the 's  method).As you can imagine there are just sooo many ways in which you could organize this code differently, it does not make sense to list them all. I hope this example serves to illustrate how to call the Makefile, and which  and  derived class you should overload to call  in a standard installation.Now, onto question 2.Question #2: how to ensure, that such terminal command is executed only if the corresponding extra1 is specified during the installation process?This was possible with the deprecated  parameter of . The standard way is to try to install the package depending on the requirements that are met.  lists the mandatory requirements, the  lists the optional requirements. For example from the  documentationyou could force the installation of the optional required packages by calling , but if for some reason the requirements for the  named extra were satisfied before hand,  would end up with the same  functionality. This means that the way in which "Project-A" is installed is not customized for each extra specified at the command line, "Project-A" will always try to install in the same way and may end up with reduced functionality because of unavailable optional requirements.From what I understood, this means that in order to get your module X to be compiled and installed only if [extra1] is specified, you should ship module X as a separate package and depend on it through an . Lets imagine module X will be shipped in , your setup for  should look likeWell, I'm sorry that my answer ended up being so long but I hope it helps. Don't hesitate in pointing out any conceptual or naming error, as I mostly tried to deduce this from the  source code.
Unfortunately, the docs are extremely scarce around the interaction between setup.py and pip, but you should be able to do something like this:This gives you a hook into running arbitrary code with commands, and also supports a variety of custom option parsing (not demonstrated here).Put this in a  file and try this:Note that this command is executed after the main install sequence, so depending on exactly what you're trying to do, it may not work. See the verbose pip install output:


Answer URL
https://docs.python.org/3/distutils/apiref.html#module-distutils.cmd
