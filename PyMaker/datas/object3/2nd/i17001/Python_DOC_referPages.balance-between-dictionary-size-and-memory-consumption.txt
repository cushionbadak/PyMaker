Natural Text
I'm using a  decorator to cache repeated calls. I'm seeing about a 4x execution speedup due to memoization on some moderate-sized test cases.With larger test cases, the memoized dictionary mapping inputs to outputs takes up a considerable amount of memory, to the point where I'm getting  errors (I'm using Jython).I can save some memory by using  rather than , assuming that  is fewer bytes than . As pointed out by @gnibbler, this will cause problems if there are hash collisions.The other memory savings I can introduce is limiting the size of the dictionary to a fixed number of items. Such a SizedDict recipe already exists, but I'd like to truncate elements that are accessed the least often.Here's what I have written:Is there a better data way to implement this with less memory or time overhead?  is quite expensive: 
Use @functools.lru_cache(maxsize=128, typed=False)Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments.Or pylru as described in the answer memoization library for python 2.7


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
