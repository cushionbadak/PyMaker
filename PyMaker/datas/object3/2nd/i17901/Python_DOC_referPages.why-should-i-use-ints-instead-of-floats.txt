Natural Text
I'm preparing for a class lesson (I'm teaching) and I'm trying to predict any possible questions from the students and I ran into one that I can't answer:If we have floats, why do we ever use ints at all? What's the point?I know (or at least I think) that floats take more memory because they have more accuracy, but surely the difference is nearly negligible as far as memory usage goes for most non-embedded applications.And I realize in many cases we actually don't need a float, but honestly, why do we have ints in the first place? What's the point? There's nothing an int can do that a float can't.So why are they there at all?Edit: You could argue they're easier to write (3 vs. 3.0) but you could just make all numbers default to float, so 3 would be treated the same as 3.0. Why make it a different type?
Floating point numbers are approximations in many cases. Some integers (and decimals) can be exactly represented by a , but most can't. See Floating Point Arithmetic: Issues and Limitations.Resulting from this approximative nature of floats, some calculations may yield unexpected results (this isn't directly pertinent to the question, but it illustrates the point quite well):For example, when you're dealing with money calculations, it's better to use integers, or (if speed is not an issue) the  module.
It's important to use data types that are the best fit for the task they are used for. A data type may not fit in different ways. For instance, a single byte is a bad fit for a population count because you cannot count more than 255 individuals. On the other hand a float is a bad fit because many possible floating point values have no meaning. For example, 1.5 is a floating point value that has no meaning as a count. So, using an appropriately sized integer type gives us the best fit. No need to perform sanity checks to weed out meaningless values.Another reason to favour integers over floats is performance and efficiency. Integer arithmetic is faster. And for a given range integers consume less memory because integers don't need to represent non-integer values.Another reason is to show intent. When a reader of the code sees that you used an integer, that reader can infer that the quantity is only meant to take integer values.
There are various historical reasons that apply to most languages:A philosophy of "don't use what you don't need". A lot of programs have no need for non-integer values but use integer values a lot, so an integer type reflects the problem domain.Floating point arithmetic used to be far more expensive than integer. It's still somewhat more expensive, but in a lot of cases in Python you'd hardly notice the difference.A 32 bit IEEE float can only represent all integers up to  then loses precision. A 16 bit float ("half precision") only represents all integers to 2048. So for 16 and 32 bit computing, when register sizes impose a serious trade-off between performance and value range, float-for-everything makes that trade-off even more serious.An 8-bit integer type (or whatever byte size exists on the platform), is very useful for low-level programming because it exactly maps to any data representable in memory. Same goes for a register-sized integer type with some efficiency advantage to working in words rather than bytes. These are the (signed and unsigned)  and  types in C.There is an additional reason specifically for Python:The  type automatically promotes to  when a computation goes beyond its range, thereby retaining precision.  doesn't get bigger to remain precise. Both behaviours are useful in different circumstances.Note that Javascript doesn't provide an integer type. The only built-in numbers in Javascript are 64 bit floating-point. So for any reason why an integer type is beneficial, it's instructive to consider how Javascript gets on without it.
There are four reasons which I can currently think of (and I'm sure there are more):Memory. Choosing wisely data types can dramatically affect the memory requirements (large databases, for example).Speed. Hardware implementation of integer arithmetic is much faster (and simpler) than floating point arithmetic.Programming practices. Having data types enforces better programming practices, as the programmer must be aware of kind of data each variable stores. This also allows early errors detection (compile time vs runtime).History. Memory used to be expensive (and still is on some systems for some applications).


Answer URL
