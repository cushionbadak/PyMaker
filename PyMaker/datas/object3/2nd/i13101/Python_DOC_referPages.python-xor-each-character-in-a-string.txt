Natural Text
I'm trying to validate a checksum on a string which in this case is calculated by performing an XOR on each of the individual characters.Given my test string:I figured it would be as simple as:I know the result should be , however my code gives .I'm not sure what encoding the text is suppose to be in, although I've tried encoding/decoding in  and , both with the same result. I implemented this same algorithm in C by simply doing an XOR over the char array with perfect results, so what am I missing?EditSo it was a little while ago that I implemented (what I thought) was the same thing in C. I knew it was in an Objective-C project but I thought I had just done it this way. Totally wrong, first there was a step where I converted the checksum string value at the end to hex like so (I'm filling some things in here so that I'm only pasting what is relevant):Then I did the following to compute the checksum:Then I would just compare like so:
So as @metatoaster, @XD573, and some others in the comments have helped figure out, the issue was the difference between the result, which was base 10, and my desired solution (in base 16).The result for the code,  is correct - in base 10, however my correct value I was trying to achieve,  is given in base 16. Simply converting the solution from base 16 to base 10, for example like so:I get , the computed result.
I created the C version as shown here:And When I compiled and ran it:Which leads me to believe that the assumptions you have from your equivalent C code are incorrect.


Answer URL
https://docs.python.org/3/library/functools.html#functools.reduce
