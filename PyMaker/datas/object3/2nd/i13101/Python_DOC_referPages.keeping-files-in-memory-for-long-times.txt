Natural Text
I am working with a relatively large file (approximately 2GB). Its content is continously needed during a while loop that runs for at least 1-2 days.Having enough RAM, I load the whole file in memory before the loop, using: I am wondering whether in doing so I will face memory management issues, if the program is to run for long times. Will the file with its full content stay intact in memory for however long it may be needed? If not, what alternatives do I have?Of course initially I did try to do things properly, by only reading the parts I need for every iteration of the loop, using islice from itertools, and setting the iterator back to 0 using seek(0) to prepare for the subsequent run of the loop. But it runs very slowly since the file is large and the while loop is long.More clarification, after comments:When I wasn't loading it in memory, I was basically doing: And it was really slow compared to when I loaded all in memory as follows:
The datatype which you are keeping in the memory is a list, not a file object, so Python will be especially careful not to garbage-collect it as you are using that list later.It doesn't matter if you are not using it in close sequence. Python analyzes the code before compiling it, and he knows that you will be using this list later.Anyway, if you are using seek() and tell() on the file object, I don't see why it would be slow.Unless your lines are big as elephants.Seek moves the read/write pointer to the block of memory where you wish (inside a file). When you afterward do f.readline(), it jumps directly there.Shouldn't be slow. If you use that you will avoid the possibility that some other program crashes because Python reserved a lot of memory.Further more, Python lists, aren't exactly indefinite. I think that it can hold some more over 10**7 items on 32-bit PC.So it does matter how many lines you have as well.Example for fast random line reading directly from HD/SSD/Flash:Of course, speed can never match direct access from RAM. Just to be clear. But this is fast as thunder compare to your solution with islice(). While you can actually use islice() to do the same thing with same speed, but you will have to seek even then and code will become a bit confusing.
To explain as per my comment, you may create a function to return an in-memory bytes buffer, and cache the function to have more controls over merely a variable.For example (if you are on python3.2+, 3.3+ with "typed" option):Usage:To read the buffers, you just need to  or whatever you want with it.You can also clear the cache:You can read more hereIf you are on python2.x, look out for some existing library for caching in memory, such as memcached or redis. You can of course also implement your own caching.Hope this helps.


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
