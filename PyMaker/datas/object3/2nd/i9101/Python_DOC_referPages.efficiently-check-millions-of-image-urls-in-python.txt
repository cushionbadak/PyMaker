Natural Text
I have a tsv file with over 3 million item rows. There each Item has an id, group, and a url and the group column is sorted. i.e I load it into a python script and need to check for status 200 OK of the url of all items of a group before loading those items into a database. I thought of using processes and doing URL checks on each one, (I don't have much experience with this so not sure if its even a good idea)My logic atm: Fill array a1 with items with gr1 -> pass each item in a1 to a new process -> that process checks for 200 -> puts it into array a2 if ok -> When all items in a1 are checked push a2 to DB (along with other stuff) -> repeatThis takes likes 30 min for 100,000 items. The bottleneck is the URL check. Without checking URL the script is lightning fast in comparison. So far:Other considerations: Split the original Tsv into like 30 seperate tsv files and run the batch script 30 times in parallel. Would this make a difference?
As you do not need the actual images using a HEAD request should improve the speed. If the response is neither 200 nor 404 HEAD may not be allowed (405) and you simply try again using a GET request.You currently wait for the current group to finish before starting any new tasks. Generally it would be preferable to always keep the same number of running requests roughly the same. Also you probably want to drastically increase the Pool of workers - As the tasks are mostly I/O-Bound I'd however suggest you do something along the lines of 3 (i.e. asynchronous I/O).If you are open to using Python 3 you can make use of the excellent support for asynchronous I/O (https://docs.python.org/3/library/asyncio.html) by using https://pypi.python.org/pypi/aiohttp:
It was already mentioned that you should try to use  instead of . That will avoid having to download the images. Moreover, you seem to be spawning a separate process per request, which is also inefficient. I don't think that using asyncio is really required here, performance-wise. The solution using a plain thread pool (not even a process pool) is a tad simpler to grasp, IMHO :) Plus, it's available in Python 2.7.As you can see, I process each row of the CSV input individually, and do the grouping on the results (using ), not on the input. Mostly a matter of taste, I guess. You might want to play around with  and possibly increase it.


Answer URL
https://docs.python.org/3/library/asyncio.html
