Natural Text
I'm looking for a way to optimize an algorithm that I have already developed. As the title of my question says, I am dealing with comma delimited strings that will sometimes contain any number of embedded commas. This is all being done in the context of big data so speed is important. What I have here does everything I need it to, however, I have to believe there would be a faster way of doing it. If you have any suggestions I would love to hear them. Thank you in advance.code:
If you really want to do this yourself instead of using a library, first some tips:don't use  on csv data. (also bad for performance)for performance: don't use regEx.The regular way to scan the data would be like this (pseudo code, assuming single line csv):For even better performance you could open the file in binary mode and handle the newlines yourself while scanning. This way you don't need to scan for a line, copy it in a buffer (for example with getline() or a similar function) and then scan that buffer again to extract the fields.


Answer URL
https://docs.python.org/3/library/io.html#io.StringIO
https://docs.python.org/3/library/csv.html#csv.reader
