Natural Text
Stern's Diatomic Sequence can be read about in more details over here; however, for my purpose I will define it now.Definition of Stern's Diatomic SequenceLet  be a number to generate the  function out of. Denoted .If  is 0 then the returned value is 0.If  is 1 then the returned value is 1.If  is even then the returned value is .If  is odd then the returned value is .Currently, my Python code brute forces through most of the generation, other than the dividing by two part since it will always yield no change.However, my code must be able to handle digits in the magnitude of 1000s millions of bits, and recursively running through the function thousands millions of times does not seem very efficient or practical.Is there any way I could algorithmically improve my code such that massive numbers can be passed through without having to recursively call the function so many times?
lru_cache works wonders in your case. make sure  is a power of 2. may need to fiddle a bit with that size for your application.  will help with that.also use  instead of  for integer division.and yes, this is just meomization as proposed by Filip Malczak.you might gain an additional tiny speedup using bit-operations in the while loop:UPDATE:here is a simple way of doing meomzation 'by hand':UPDATEafter reading a short article by dijkstra himself a minor update.the article states, that  if the fist and last bit of  are the same as those of  and the bits in between are inverted. the idea is to get  as small as possible.that is what the bitmask  is for (first and last bits are ; those in the middle ; ing  with that gives  as described above).i was only able to do small benchmarks; i'm interested if this is any help at all for the magitude of your input... this will reduce the memory for the cache and hopefully bring some speedup.i had to increase the recursion limit:benchmarking gave strange results; using the code below and making sure that i always started a fresh interperter (having an empty ) i sometimes got significantly better runtimes; on other occasions the new code was slower...benchmarking code:and these are three random results i got:that is where i stopped...
With memoization for a million bits, the recursion stack would be extremely large. We can first try to look at a sufficiently large number which we can work by hand,  in this case:fusc(71) = fusc(35) + fusc(36)fusc(35) = fusc(17) + fusc(18)    fusc(36) = fusc(18)  fusc(71) = 1 * fusc(17) + 2 * fusc(18)  fusc(17) = fusc(8) + fusc(9)    fusc(18) = fusc(9)fusc(71) = 1 * fusc(8) + 3 * fusc(9)fusc(8) = fusc(4)    fusc(9) = fusc(4) + fusc(5)fusc(71) = 4 * fusc(4) + 3 * fusc(5)fusc(4) = fusc(2)    fusc(3) = fusc(1) + fusc(2)fusc(71) = 7 * fusc(2) + 3 * fusc(3)fusc(2) = fusc(1)    fusc(3) = fusc(1) + fusc(2)fusc(71) = 11 * fusc(1) + 3 * fusc(2)fusc(2) = fusc(1)fusc(71) = 14 * fusc(1) = 14We realize that we can avoid recursion completely in this case as we can always express  in the form  while reducing the value of m to 0. From the example above, you may find the following pattern:if m is odd: =   if m is even: = Therefore, you may use a simple loop function to solve the problem in O(lg(n)) time


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
