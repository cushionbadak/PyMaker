Natural Text
I have a python script that reads many executables written and compiled in C program. There is no issue with these executables. However, When I have to run these executable in for loop, i tried to parallize the loop. In my code example 1 runs fine but example 2 doesnot run.The full code is presented below:Here, if i run example 1 it runs flawlessly. But when i try to run example 2, it gives following error:Further note:To create the executables prog1,prog2,and prog3 I wrote C codes.Which looks like this:prog2 looks exactly same. And prog3 looks like this:Now, there are 21 iterations inside the for loop.In the first iteration it suppose it runs executables prog1,prog2....,prog7and finally produce ouptput1.fits.In the second interation it again run seven executables in order and produces output2.fits.And finally it creates 21 fits files.What I can do is make four functions:func1 for loop 0 to 5fucn2 for loop 5 to 10func3 for loop 11 to 15func4 for loop 16 to 21Then I want to run these four functions in parallel process.My Question is : How can I run example 2 without any error? 
not really sure what else I could add ...
Python has a Pool of processes built exactly for this purpose.Given the fact you need to run X times the same sequence of commands and supposing the sequence of commands can be run in parallel. This means the Nth run can be run together with the Nth+1 without any implication.On Pyhton3 you can use the ProcessExecutor.Whenever you want to run something concurrently you need to understand the execution boundaries first. If two lines of execution are interdependent, you either set up a communication between the two (using for example a pipe) or avoid running them concurrently.In your case, the commands are interdependent so it becomes problematic to run them concurrently. But if the whole sequence is not interdependent then you can run those in parallel.
Have a look at what group functions of Celery's canvas do. They allow you to call functions at the same time, with different set of arguments. Say you want to process a total of 1000 elements in your for loop. Doing the same sequentially is highly unoptimized. A simple solution will be to call the same function with two sets of arguments. Even this simple hack will bring down your processing time down by half. That is what Canvas and Celery are about.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor
