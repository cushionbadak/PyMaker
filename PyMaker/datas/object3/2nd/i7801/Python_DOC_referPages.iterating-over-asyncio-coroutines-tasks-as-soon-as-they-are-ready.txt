Natural Text
I launch a bunch of requests using . Is there a way to get the results one-by-one as soon as each request is complete?Perhaps using something like ? Or Python 3.6 async generators?Currently I  and process them when all of them are completed.
 has as_completed function that probably does what you need. Note, it returns regular iterator, not async. Here's example of usage:Output:
Canonical way is pushing result into  like in crawler example.Also it's wise to run limited amount for download tasks which get new job from input queue instead of spawning a million of new tasks.
As I understand according to the docs,  are s (or can be easily converted to Future using asyncio.ensure_future).A  object has a method . So, you can add your callback for every request, and then do .Docs for Future.add_done_callback


Answer URL
https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed
https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future
https://docs.python.org/3/library/asyncio-task.html#asyncio.Future.add_done_callback
