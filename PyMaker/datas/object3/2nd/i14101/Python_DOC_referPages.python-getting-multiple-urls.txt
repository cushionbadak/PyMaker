Natural Text
I'm coding an API endpoint, which you can think is really an aggregator of other APIs. You send it certain parameters and what it does is translate those parameters to the underlying API's parameters and makes the calls. Now ideally I wouldn't want to make these calls in a serial manner.What is the best way to do this?EDIT: As I suspected, threads or processes isn't the way to go when the thing you're trying to do is getting URLs. This is because most of the time is spent waiting for the network to reply, so what you really want is a change to manage changing between tasks which are waiting into tasks which are actually doing the requests. Because of this, I think that the answers which exist to a similar question are actually bad answers.
After some research, as far as I can tell single-threaded asynchronous code is a much better answer than threads for the specific case of getting several URLs, and especially so for the case of many many URLs:There's Twisted, the framework:http://twistedmatrix.com/documents/14.0.1/web/howto/client.htmlAnd gevent, the library:http://sdiehl.github.io/gevent-tutorial/Simple example from http://mauveweb.co.uk/posts/2014/07/gevent-asynchronous-io-made-easy.html, doing 100 calls using a Pool of 20:


Answer URL
https://docs.python.org/3/library/asyncio.html
