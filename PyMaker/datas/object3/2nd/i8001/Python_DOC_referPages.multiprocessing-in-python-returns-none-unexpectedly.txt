Natural Text
I'm attempting to start multiprocessing in python 3.6 (the Anaconda distribution). I've heavily tested my internal function (numerical integration), so I'm confident that it works. What is currently giving me trouble is passing the proper ranges because I get some "none" returns.Some of my debugging process can be see in the code I included here. At the moment, I just want to see the arguments that are being passed to my sint() function. When I print the result, I get the resultWhy are these "None"s arising? At present, their presence is causing overflows/NaNs that aren't present in the non-parallelized version of the code. Is there a way to not get the "None"s to show up? I tried checking for the presence of "None" in tupl, lower, and upper, but Python seems to not want to identify these (wouldn't print the message "None detected" that I wrote in).Any help would be very appreciated! Let me know if more information is needed.
One issue is that multiprocessing launches a separate process for everything you've wrote, it creates a separate Python instance entirely, so your code is actually running everything you've put in global scope multiple times.  Running your code will return multiple times for me.  You need to move your other code into either a separate function or just call it inside of .  Fixing this still results in nones however, which appears to be due to the fact you don't actually return anything in your mapping function,  in .  Normally your results would be  objects (and sum cannot sum over none objects either) but there's another problem here.  Your processes don't actually close. This is probably because you call exit, there isn't a return or anything, not even . You don't call exit to end a mapping function, please look at multiprocessing to see the examples there.  Just use a normal function as your mapper, no need to use a system call.Even though this is not what you want, this is a simple example to show actual functioning multiprocessing code with your example:EDIT: I didn't realize most of what you posted was not required, I encourage you to make minimal verifiable examples when you post questions, I've minified and changed what I origional posted to do actual integration, I also encourage you to use proper naming conventions when you ask questions and write your own code,  and  are not exceptable descriptive names. What i've done here is shown you how integration can be carried out properly in parrallel using the same scipy integration utility you provided.  You can replace  with the code for your own function and it should work the sameIf your function is complicated enough and the integration is large enough the overhead of multiprocessing should be low enough for it to be faster, note that printing out with in threads causes slowdown you don't want, so out side of debugging I would encourage you not to print.EDIT:  Since they want to do infinite integration I'll also post my thoughts and addendum to the code on that here, instead of leaving it burred in the comments.  Technically even with infinite integration range, you aren't actually integrating infinitely, the specific numerical methods of approximating integrating infinitely are beyond the scope of this question, however since  is a uses Gaussian Quadrature to carry out its integration (hence the name ''), it fixes this, and can take  as a bound. Unfortunately I don't know how to guarantee contiguous performance with this bound, it may take longer to do that bound than all of the rest of the integrations, or it may take much less time, which means dividing the work into equal chunks becomes harder.  however you would only need to change the last bound on the integration ranges to also include infinity in the range.That change looks like this: After doing this, your last bound should be bounded by infinity, so your total integration range will actually be 0 -> inf, even if  isn't infinity


Answer URL
https://docs.python.org/3/library/multiprocessing.html
