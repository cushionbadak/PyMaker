Natural Text
I have 2 list of lists x(1 million elements) and y(0.1 million elements) and want to get z=x-y.each list consist of sub lists of 4 elements each, of which the first element of each sublist is sorted. The first element are strictly increasing and no duplicates are present.Now I did this using list comprehension and it roughly takes 6.5 hrs to run it. I wanted to know what is the most time efficient way to do this, keeping in mind that my end result should also be a list of lists.Secondly, since all my first elements are sorted I thought doing a binary search would be a better idea.Idea of binary search - for ex consider I have 2 lists of size x=30 and y=10I am looping over elements of y and comparing the first element of each sub list to that of the elemnts in x using binary search, when I find a match that sublist is deleted from the x list.So the expected output list should contain 20 elements.But the code I have written gives me 23(it does not delete the last three matches) and I dont know whats wrong with it.Heres the code:
Bisection can work, but another easy solution is to use a :Note that the s have to be turned into something immutable.Now simply generate the result:This might look very similar to your initial solution, but the lookups here are much faster.@StefanPochmann has a good point that you might want to base your lookup on something more specific than the whole vector, such as just the first element. The question wasn't very clear about that (only stating those are sorted).
If I understand you correctly, use bisect.bisect_left to find the the matches and delete:If you look at the source you can see the code used for bisect_left:You can adapt that into your own code:If you have dupes then you will need to use remove. Checking the first elements for an exact match is  but if you were using remove I don't see how that could work, just because the first elements matched does not mean  was in  so  would fail. So if you are only matching first elements then you can you can change your logic and just iterate over  putting all first elements from each sublist in a set and using a generator expression to update x.
If you can use the first elements for filtering:Python 3 versions:If judging by the first element alone is not enough:On my weak laptop, with a test of your size, the first solution takes about 0.4 seconds and the second solution takes about 1 second. Not that surprising, since  lookups average O(1)).Here's a third version, and this one might be the most interesting because it doesn't just let Python do the job and because it's closer to what you intended but even better:This walks over , and "in parallel" walks over . Similar to the merge step of merge-sort. With  we point into , and we increase it as needed. Thus we have overall linear time, as we only walk over  from start to end and also over  from start up to end. My laptop takes about 0.6 seconds for this, which is faster than my second solution! (It's not fair to compare it to my first solution, since that one only looks at the first elements).


Answer URL
https://docs.python.org/3/library/bisect.html
