Natural Text
I've a python script which works just as it should, but I need to write the execution time. I've googled that I should use  but I can't seem to get it to work.My Python script looks like this:What I need is the time it takes to execute the query and write it to the file . The purpose is to test an update statement for my database with different indexes and tuning mechanisms.
You can use  or  before and after the block you want to time.This method is not as exact as  (it does not average several runs) but it is straightforward.  (in Windows and Linux) and  (in Linux) are not precise enough for fast functions (you get total = 0). In this case or if you want to average the time elapsed by several runs, you have to manually call the function multiple times (As I think you already do in you example code and timeit does automatically when you set its number argument)In Windows, as Corey stated in the comment,  has much higher precision (microsecond instead of second) and is preferred over .
If you are profiling your code and can use IPython, it has the magic function . operates on cells.
Quite apart from the timing, this code you show is simply incorrect: you execute 100 connections (completely ignoring all but the last one), and then when you do the first execute call you pass it a local variable  which you only initialize after the execute call.First, make your code correct, without worrying about timing yet: i.e. a function that makes or receives a connection and performs 100 or 500 or whatever number of updates on that connection, then closes the connection. Once you have your code working correctly is the correct point at which to think about using  on it!Specifically, if the function you want to time is a parameter-less one called  you can use timeit.timeit (2.6 or later -- it's more complicated in 2.5 and before):You'd better specify the number of runs because the default, a million, may be high for your use case (leading to spending a lot of time in this code;-).
Focus on one specific thing. Disk I/O is slow, so I'd take that out of the test if all you are going to tweak is the database query.And if you need to time your database execution, look for database tools instead, like asking for the query plan, and note that performance varies not only with the exact query and what indexes you have, but also with the data load (how much data you have stored).That said, you can simply put your code in a function and run that function with :This would disable the garbage collection, repeatedly call the  function, and time the total duration of those calls using , which is the most accurate available clock for your specific platform.You should move setup code out of the repeated function; for example, you should connect to the database first, then time only the queries. Use the  argument to either import or create those dependencies, and pass them into your function:would grab the globals ,  and  from your script and pass those to the function each repetition. 
I see the question has already been answered, but still want to add my 2 cents for the same.I have also faced similar scenario in which I have to test the execution times for several approaches and hence written a small script, which calls timeit on all functions written in it.The script is also available as github gist here.Hope it will help you and others.


Answer URL
https://docs.python.org/3/library/time.html#time.time
https://docs.python.org/3/library/time.html#time.clock
https://docs.python.org/3/library/timeit.html
