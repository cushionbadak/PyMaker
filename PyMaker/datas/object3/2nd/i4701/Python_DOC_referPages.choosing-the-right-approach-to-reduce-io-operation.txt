Natural Text
When it comes to IO read/write files from disks, it is almost blocking operations by default. I have been working on a project that uses such operations (read/write from disks) and uses the default  blocking IO here. This has been a great pick until I found out that I am dealing with really big datasets!!I have been trying to improve the execution time of my project. After doing a benchmark, I found out that IO operations are the bottleneck. Thus, I should now think of something else other than  default blocking IO. After reading for few days, I found out that I have three approaches to choose from that could reduce IO time:Non-blocking approachMulti-threading approachMulti-processing approachI would like to know which one of these approaches will be suitable to reduce the IO time, knowing that my IO operations are always performed on a disk (local disk). Plenty of libraries I came across such as twisted, asyncio, aiofiles, multiprocessing, and multithreading. Because I have never worked with IO asynchronous or events-driven networking before, I am not sure what to choose from the three approaches above!! Suggestions and thoughts from you guys are valuable to me. Thank you in advance EDIT:Special thanks to  who brought the following points:Does your program need all its data loaded before it can begin? Yes, but sometimes the program needs only to load a portion of the data from a file.Can it start writing some data to disk before all of the work is complete?Yes, this is in fact what I am looking for.Does the "work" function ever release the GIL?I don't get this question but my program makes use of multiprocessors via the library mpi4py. However, IO operations are always done by a single processor.
If all of the information needed to start writing output is located in one node of your MPI hierarchy, and you want that node to still be able to contribute to other computation, and your other computation calls C functions that release the GIL, you could spin up a thread on each node to carry out the I/O operation within the worker node. This avoids the overhead of transmitting data to a dedicated writer at the cost of increasing the unpredictability of the per-node workload.If you need to aggregate the results of more than one worker before you can start writing, you would create a dedicated writer node in your MPI hierarchy, and funnel all data to it specifically, and make it the responsibility of that node to figure out when it is ready to write data out. This could be done with one thread to receive messages and one thread to do the actual writing as well. This may not be doable with plain MPI if the writer is not also the master, in which case you might need to mix in another flavor of IPC like .


Answer URL
https://docs.python.org/3/library/asyncio.html
