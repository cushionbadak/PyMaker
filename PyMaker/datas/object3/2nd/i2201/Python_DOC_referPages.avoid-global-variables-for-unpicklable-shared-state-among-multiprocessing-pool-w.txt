Natural Text
I frequently find myself writing programs in Python that construct a large (megabytes) read-only data structure and then use that data structure to analyze a very large (hundreds of megabytes in total) list of small records.  Each of the records can be analyzed in parallel, so a natural pattern is to set up the read-only data structure and assign it to a global variable, then create a  (which implicitly copies the data structure into each worker process, via ) and then use  to crunch the records in parallel.  The skeleton of this pattern tends to look like this:I'm not happy with this because of the global variable and the implicit coupling between  and .  Ideally, I would like to writebut this does not work, because the Classifier object usually contains objects which cannot be pickled (because they are defined by extension modules whose authors didn't care about that); I have also read that it would be really slow if it did work, because the Classifier object would get copied into the worker processes on every invocation of the bound method.Is there a better alternative?  I only care about 3.x.
This was surprisingly tricky. The key here is to preserve read-access to variables that are available at fork-time without serialization. Most solutions to sharing memory in multiprocessing end up serializing. I tried using a  to pass in a classifier without serialization, but that didn't work because both dill and pickle will try to follow and serialize the referent. However, a module-ref works.This organization gets us close:A few changes to note here:we add an  method for some DI goodness; orchestrate figures out how to construct/initialize a classifier, and hands it to , decoupling the two only needs to assume that the  parameter has a  method; it doesn't care if it's an instance or a moduleFor this Proof of Concept, we provide a Classifier that is obviously not serializable:Unfortunately, there's still a global in here, but it's now nicely encapsulated inside a module as a private variable, and the module exports a tight interface composed of the  and  functions.This design unlocks some possibilities: can import and init different classifier modules, based on what it sees in one could also pass an instance of some  class to , as long as this instance is serializable and has a classify method of the same signature
If you want to use forking, I don't see a way around using a global. But I also don't see a reason why you would have to feel bad about using a global in this case, you're not manipulating a global list with multi-threading or so.It's possible to cope with the ugliness in your example, though. You want to pass  directly, but the  object contains objects which cannot be pickled. I suggest we subclass  and define  and  to enable pickling. Since you're using forking anyway, all state it has to pickle, is information how to get a reference to a forked global instance. Then we'll just update the pickled object's  with the  of the forked instance (which hasn't gone through the reduction of pickling) and your instance is complete again.To achieve this without additional boilerplate, the subclassed  instance has to generate a name for itself and register this as a global variable. This first reference, will be a weak reference, so the instance can be garbage collected when the user expects it. The second reference is created by the user when he assigns . This one, doesn't have to be global.The generated name in the example below is generated with help of standard-lib's  module. An uuid is converted to a string and edited into a valid identifier (it wouldn't have to be, but it's convenient for debugging in interactive mode).The sweet thing here is, the boilerplate is totally gone. You don't have to mess manually with declaring and deleting globals since the instance manages everything itself in background:
The  module provides functions for allocating ctypes objects from shared memory which can be inherited by child processes, i.e., parent and children can access the shared memory.You could use1.  to allocate a ctypes array from the shared memory.2.  to allocate a ctypes object from the shared memory.Dr Mianzhi Wang has written a very detailed document on this. You could share multiple  objects.You may find the solution here useful to you.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool
