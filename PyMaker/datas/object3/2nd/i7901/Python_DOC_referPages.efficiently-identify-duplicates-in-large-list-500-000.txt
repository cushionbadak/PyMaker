Natural Text
I have a large list of DOI's and I need the most efficient way to identify the DOI's which are repeated (ie. print out the index and the DOI for values which are repeated.) The array of DOI's could consist of 500,000 + DOI's. My current approach is this (inspired by this answer):Is there a more processing efficient way of doing this?Sample DOI List:
Try storing them in a  instead. You can append the duplicates to a single list, which might speed things up:At this point,  contains all the distinct doi values, while  contains all the 2nd, 3rd, etc. indexes of duplicate values. You can look them up in  to determine which index corresponds to which value.To get some more performance out of this, you can cache the methods:
Here's a full solution that returns the same data set as your example, just more than twice faster (at the expense of some memory):The stored index is the first occurrence of the found duplicate as in your example. If you want to store all the duplicate indexes you can add  after the  line, but then the data might look weird (the structure would be )Instead just flip the stored parameters in  modifications -  instead of  and  instead of , then  after it will give you a nice result in the form of: .


Answer URL
https://docs.python.org/3/library/stdtypes.html#set
