Natural Text
I want to transfer data (multiple images of size > 3 MB) from server to client. Since I want to test the packet loss with no re-transmission, I don't want to use stream (TCP). I went through this example. My approach is that, the server reads chunk of data using f.read(1024)and send to the client using transport.sendto(data + seq_num). Reading and sending will continue in a loop until end of file. The client will  receive through datagram_received(self, data, addr):.Since I send sequence number (seq_num) along the data, I can control the lost segment and the order. My problem is on receiving and writing the data on the client side. How do I store data sent from server at different time on the client side with some condition with  datagram_received (self, data, addr) function?Is there a feature that used to receive data from sock into the buf buffer?  e.g for stream (TCP) data = await loop.sock_recv(tcp_sock, buf). I appreciate your help.
Is there a feature that used to receive data from sock into the buf buffer? e.g for stream (TCP) data = await loop.sock_recv(tcp_sock, buf).As pointed out in the comment, datagrams can't provide a true streaming interface because UDP does not guarantee delivery order. If I understand the question correctly, you would like an awaitable interface to the event of the delivery of the next UDP packet, as the interface provided by default is purely callback-based.Fortunately it is quite easy to convert a callback-based interface to an awaitable one - asyncio typically uses Future for that purpose, where the coroutine awaits the future, and the callback invokes set_result() to pass some data to the awaiting coroutine - see on_con_lost in the sample UDP client from the docs.A good stream-like API always supports some form of buffering, which can be provided by a limited-capacity queue:The limited-size queue allows processing of data to temporarily be slower than the rate at which data arrives, while preventing a memory leak in case the situation continues. After the queue is filled up, the packets are dropped. (With a TCP/IP-backed stream we would slow down reading to provide backpressure - well explained in this article, but with UDP there is no choice but to drop.)


Answer URL
https://docs.python.org/3/library/asyncio-protocol.html#udp-echo-server
https://docs.python.org/3/library/asyncio-protocol.html#udp-echo-client
