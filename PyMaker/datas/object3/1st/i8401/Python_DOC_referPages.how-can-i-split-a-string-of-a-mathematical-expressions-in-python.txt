Natural Text
I made a program which convert infix to postfix in python. The problem is when I introduce the arguments.If i introduce something like this: (this will be a string)it will split it with .split() and the program will work correctly.But I want the user to be able to introduce something like this:As you can see I want that the blank spaces can be trivial but the program continue splitting the string by parentheses, integers (not digits) and operands.I try to solve it with a for but I don't know how to catch the whole number (73 , 34 ,72)  instead one digit by digit (7, 3 , 3 , 4 , 7 , 2)To sum up, what I want is split a string like ((81 * 6) /42+ (3-1))  into:
Tree with astYou could use ast to get a tree of the expression :It outputs :As @user2357112 wrote in the comments : ast.parse interprets Python syntax, not mathematical expressions. (1+2)(3+4) would be parsed as a function call and list comprehensions would be accepted even though they probably shouldn't be considered a valid mathematical expression.List with a regexIf you want a flat structure, a regex could work :It looks for either :multiple digitsor any character which isn't a digit or a spaceOnce you have a list of elements, you could check if the syntax is correct, for example with a stack to check if parentheses are matching, or if every element is a known one.
You need to implement a very simple tokenizer for your input. You have the following types of tokens:()+-*/\d+You can find them in your input string separated by all sorts of white space.So a first step is to process the string from start to finish, and extract these tokens, and then do your parsing on the tokens, rather than on the string itself.A nifty way to do this is to use the following regular expression: '\s*([()+*/-]|\d+)'. You can then:This will print ['(', '3', '+', '(', '2', '*', '5', ')', ')']You could also use re.findall or re.finditer, but then you'd be skipping non-matches, which are syntax errors in this case.
It actual would be pretty trivial to hand-roll a simple expression tokenizer. And I'd think you'd learn more that way as well. So for the sake of education and learning, Here is a trivial expression tokenizer implementation which can be extended. It works based upon the "maximal-much" rule. This means it acts "greedy", trying to consume as many characters as it can to construct each token.Without further ado, here is the tokenizer:Here is a demo the usage:Which produces the output:
Quick regex answer:re.findall(r"\d+|[()+\-*\/]", str_in)Demonstration:For the nested parentheses part, you can use a stack to keep track of the level.
If you don't want to use re module, you can try this:Output:
This does not provide quite the result you want but might be of interest to others who view this question. It makes use of the pyparsing library.Output:
Using grako:grako transpiles to python. For this example, the return value looks like this:Normally you'd use the generated semantics class as a template for further processing.
To provide a more verbose regex approach that you could easily extend:Which will give you the result:


Answer URL
https://docs.python.org/3/library/ast.html
