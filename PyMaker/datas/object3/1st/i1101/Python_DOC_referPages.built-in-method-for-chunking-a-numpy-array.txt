Natural Text
I have a large amount of data in NetCDF4 files, and I am trying to write a script to dynamically chunk this data to hold as much in memory as possible, do calculations on it and save the results, then move on to the next chunk. An example of what I am trying to do. Say I have an array like this:And I only want to read ten of the x coordinates at a time, like this:Is there some sort of built-in method for this? In this simple example it works pretty well, but as things get more complicated this seems like it could get to be a headache for me to manage all of this myself. I am aware of Dask, but it is unhelpful to me in this situation because I am not doing array operations with the data. Although Dask could be useful to me if it had methods to deal with this too.
You can reduce the complexity and increase the robustness by implementing a lazy generator that encapsulates the computation you're worried about and just returns the chunk at each step. Something like this perhaps:Using it is pretty straightforward:
The Dask documentation shows how to create chunked arrays for just the kind of computation you have in mind, for the case of hdf5 files: http://docs.dask.org/en/latest/array-creation.html#numpy-slicing . Your netCDF4 case may or may not work identically, but the section further down about delayed will do the trick, if not.Having made your dask-array, you will want to use the map_blocks method for the "do something with each chunk" operation (this expects to get some output back), loop over the contents of the .blocks attribute, or use .to_delayed() to do arbitrary things with each piece. Exactly which is right for you depends on what you want to achieve.
You can use np.split, which takes an array and either a chunk size or a list of indices at which to perform the split. Your case would be np.split(arr, 10), giving you a list of 10 arrays of shape (10, 15, 51).Note that an exception is raised if the axis cannot be equally divided, e.g., if you asked for chunks of size 9. If you want to split into nearly-equal chunks, without raising, you can use np.array_split instead.


Answer URL
https://docs.python.org/3/library/itertools.html?highlight=itertools#itertools-recipes
