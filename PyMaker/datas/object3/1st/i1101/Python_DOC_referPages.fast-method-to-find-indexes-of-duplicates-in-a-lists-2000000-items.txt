Natural Text
I have a list where each item is a combination of two event ids:(This is just a snippet of the much larger list of pairs)['10000381 10007121', '10000381 10008989', '10005169 10008989',  '10008989 10023817', '10005169 10043265', '10008989 10043265',  '10023817 10043265', '10047097 10047137', '10047097 10047265',  '10047137 10047265', '10000381 10056453', '10047265 10056453',  '10000381 10060557', '10007121 10060557', '10056453 10060557',  '10000381 10066013', '10007121 10066013', '10008989 10066013',  '10026233 10066013', '10056453 10066013', '10056453 10070153',  '10060557 10070153', '10066013 10070153', '10000381 10083798',  '10047265 10083798', '10056453 10083798', '10066013 10083798',  '10000381 10099969', '10056453 10099969', '10066013 10099969',  '10070153 10099969', '10083798 10099969', '10056453 10167029',  '10066013 10167029', '10083798 10167029', '10099969 10167029',  '10182073 10182085', '10182073 10182177', '10182085 10182177',  '10000381 10187233', '10056453 10187233', '10060557 10187233',  '10066013 10187233', '10083798 10187233', '10099969 10187233',  '10167029 10187233', '10007121 10200685', '10099969 10200685',  '10066013 10218005', '10223905 10224013']I need to find every single instance of each pair of ids and indexing it into a new list. Right now I have a few lines of code that does this for me. However, my list is more than 2,000,000 lines long and will get much bigger as I process more data. At this moment, the estimated time of completion is about 2 days. I really just need a much faster method for this. I'm working in Jupyter Notebooks (on a Mac Laptop)I have also tried:What I want is something like this:'10000381 10007121': [0]'10000381 10008989': [1]'10005169 10008989': [2, 384775, 864173, 1297105, 1321798, 1555094, 1611064, 2078015]'10008989 10023817': [3, 1321800]'10005169 10043265': [4, 29113, 864195, 1297106, 1611081][5, 864196, 2078017]'10008989 10043265': [6, 29114, 384777, 864198, 1611085, 1840733, 2078019]'10023817 10043265': [7, 86626, 384780, 504434, 792690, 864215, 1297108, 1321801, 1489784, 1524527, 1555096, 1595763, 1611098, 1840734, 1841280, 1929457, 1943701, 1983362, 2093820, 2139917, 2168437]etc.etc.etc.Where each number in the brackets is an index of that pair in the idlist.Essentially, I want it to look at a pair of id values ( i.e. '10000381 10007121'), and runs through the list and finds each instance of that pair and documents each index in the list that this pair occurs. I need something that does this for every single item in the list. In a shorter amount of time.
You can use a collections.OrderedDict in order to reduce the time complexity to O(n). Since it remembers the order of insertion the values resemble the various ids in order of their occurrence:Then list(groups.values()) contains your final result.
Instead of a list, use a dict, which makes looking up for existence O(1):
If you have a lot of data, i would suggest you using Pypy3 instead of the CPython interpreter and you'll get x5-x7 faster code execution.Here is an implementation of a time based benchmark using CPython and Pypy3 with 1000 iterations:Code:CPython:Pypy3:Pypy3 with 2000000 iterations:


Answer URL
https://docs.python.org/3/library/collections.html#collections.OrderedDict
