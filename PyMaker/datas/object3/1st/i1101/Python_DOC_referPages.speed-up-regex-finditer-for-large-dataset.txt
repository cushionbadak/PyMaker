Natural Text
I am trying to find positions of a match (N or -) in a large dataset.The number of matches per string (3 million letters) is around 300,000. I have 110 strings to search in the same file so I made a loop using re.finditer to match and report position of each match but it is taking very long time. Each string (DNA sequence) is composed of only six characters (ATGCN-). Only 17 strings were processed in 11 hours. The question is what can I do to speed up the process?The part of the code I am talking about is:I also tried to use re.compile as I googled and found that it could improve performance but nothing changed (match = re.compile('[-N]'))
If you have roughly 300k matches - you are re-creating increasingly larger sets that contain exactly the same elements as the list you are already adding to:You can instead simply use the list you got anyway and put that into your all_positions_set after you found all of them:That should reduce the memory by more then 50% (sets are more expensive then lists) and also cut down on the runtime significantly.I am unsure what is faster, but you could even skip using regex:and instead use enumerate() on your string to find the positions .... you would need to test if that is faster.
Regarding not using regex, I did actually that and now modified my script to run in less than 45 seconds using a defined functionSo the new coding part is:


Answer URL
https://docs.python.org/3/library/functions.html#enumerate
