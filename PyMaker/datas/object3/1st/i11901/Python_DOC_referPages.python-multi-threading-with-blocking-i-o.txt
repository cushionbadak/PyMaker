Natural Text
My application uses multiple I/O blocking (network) requests that take a while to complete. I tried using multi threading but it doesn't appear to bring any speedup, I'm guessing it's something to do with Python's GIL.The thing is all of the requests can be done concurrently and have no dependencies on each other. How do I solve this performance issue?My codeThe output is The urls in urllist.txt point to a server I'm running locally that take  5 seconds to respond. As you can see they all "start" at the same time, but they are blocking. 
I cannot reproduce your problem (when testing against a handful of internet servers, each one repeated a few times, all requests are serviced in about the same time, no steadily increasing delays), but your new output points to a completely different issue: I suspect the "local server" you're using may not be multithreaded (or otherwise able to service multiple requests at once).Your own output indicates the threads are launching in parallel, but requests are being serviced serially; if it was GIL handoff causing problems, I'd expect to see all of them delayed a bit (one thread would get some work done, then another would do some more, etc.), not each one running to completion before the next starts. This smacks of a problem on the server side, where the server is handling requests to completion before it services additional connections.Taking a stab at psychic debugging, did you by any chance implement the five second request time by adding a sleep in the server code, possibly after accept returns, but before launching a thread to service it? Or just not use threading on the server at all?
Python threads are slow! Python has a GIL (Global Interpreter Lock) which uses a mutex to serialize access to internals. You might want to have a look at Jython which doesn't have a GIL and can fully exploit multiprocessor systems.


Answer URL
https://docs.python.org/3/whatsnew/3.2.html#multi-threading
