Natural Text
I am using Celery with RabbitMQ to process data from API requests. The process goes as follows:Request -> API -> RabbitMQ -> Celery Worker -> ReturnIdeally I would spawn more celery workers but I am restricted by memory constraints. Currently, the bottleneck in my process is fetching and downloading the data from the URLs passed into the worker. Roughy, the process looks like this:This is unacceptable as the worker is locked up for a while while fetching the URL. I am looking at improving this through threading, but I am unsure what the best practices are:Is there a way to make the celery worker download the incoming data asynchronously while processing the data at the same time in a different thread?Should I have separate workers fetching and processing, with some form of message passing, possibly via RabbitMQ?
Using the eventlet library, you can patch the standard libraries for making them asynchronous.First import the async urllib2:So you will get the url body with:See more eventlet examples here.
I would create two tasks, one for downloading the data and the other for processing it once it is downloaded. This way you could scale the two tasks independently. See: Routing, Chains.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Pipe
