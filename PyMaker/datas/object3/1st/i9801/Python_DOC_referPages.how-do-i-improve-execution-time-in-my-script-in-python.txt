Natural Text
I'm trying to remove values from files containing 3 dimensional arrays corresponding with the dimensions corresponding to [time][long][lat].I have separate files for each years worth of data.  I have a list of observed data points T_obs for a duration of time start_time_index to end_time_index that I want to compare to the mean value over that time period in the file data.The data sets contained in the files are sufficiently large that my code is running very slowly and I want to optimize my execution time. The code I have currently is below. Are there any ways I could significantly save time?
Are you going to do this kind of work many times (with different values), or just once?If the former, you can try to put your files data in a database (such as MySQL, which is simple to setup) and create indexes on the start and end time. This would make your reads mighty faster, as you would not need to do a full table scan (which is pretty much what you are doing by reading the whole file).If you are doing it just once, then I just suggest you wait it out. There is no trivial way to make I/O (which is your bottleneck) less expensive and it seems like to make your checks / compare the data, you actually need to go through the whole dataset.


Answer URL
https://docs.python.org/3/library/os.path.html#os.path.join
