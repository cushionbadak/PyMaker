Natural Text
We have a python program that reads around 120,000 XML files, parses them(using ElementTree), extracts tag values(fromstring().findall()) etc. This is taking a loooong time. We thought of parallelizing the program using threads. But top shows the CPU consumption of this single process to be around 100%. So, my question is will threading really help. My intuition is that threading helps only when there is spare CPU left.My system config is -PS: I am totally new to Python. So there may be some language specific tricks that can help improve speed. I'll be glad to provide more info if that is the problem. 
Definitely because the most likely bottleneck here is actually I/O not CPU. So what you are doing here is processing each file sequentially, so each time you wait for the file to be read from disk you have a bottleneck which blocks everything from happening. If you used multiple threads you can have multiple files being processed simultaneously and while one is waiting for I/O the rest can be processed. This is a good explanation as to why I/O blocking can cause high CPU utilization http://www.chileoffshore.com/en/interesting-articles/126-linux-wait-io-problemJust because it's 100% it doesn't mean it's actually doing computation work during that time.
Three things right off the bat about Python and concurrency, and Python and XML processing:Python's multithreading capabilities are limited to working around IO-bound operations. For more explanation, look up "Global Interpreter Lock" or "GIL". Instead, to split up and concurrently work on CPU-bound work when you have multiple CPUs, use the multiprocessing moduleWhen processing large XML files needs to be faster, you don't want to use ElementTree which is implemented in pure Python. CPython ships with an implementation of the same API written in C under the name cElementTree. It will execute much faster.While cElementTree is fast, the world standard lxml library which also implements the elementtree API is faster still. It is relatively straightforwards to install, depending upon your operating system.Take a look at https://docs.python.org/2/library/multiprocessing.html#using-a-pool-of-workers for a straightforward way of spreading the work out across a pool of worker processes.
It's unlikely that multithreading will help in this situation assuming you are using the standard CPython implementation because it has a global interpreter lock and threads in Python cannot run simultaneously. Thus you can't utilize more than a single CPU core.XML parsing is actually quite expensive and the built-in parsers are not the fastest ones available. Lxml is known to be faster, but there are even faster options if you are willing to write your own bindings to a C or C++ library.You might want to look here or come up with your own benchmark.You'll want to profile your code, but be careful when using Python profiling tools as they can often get confused by extension modules which it is likely if you are parsing XML that you are using an extension module.Also depending on the structure of your XML, parsing an XML file is not typically conducive to parallelism. You will probably have a lot of shared state. If you are processing the XML and performing some operations on each of the elements that is much more likely to be parallelizable work as you can do each operation independently. I would spend my effort there depending on what your profiling shows.


Answer URL
https://docs.python.org/3/library/profile.html
