Natural Text
I've got a large amount of data (a couple gigs) I need to write to a zip file in Python.  I can't load it all into memory at once to pass to the .writestr method of ZipFile, and I really don't want to feed it all out to disk using temporary files and then read it back.Is there a way to feed a generator or a file-like object to the ZipFile library?  Or is there some reason this capability doesn't seem to be supported?By zip file, I mean zip file.  As supported in the Python zipfile package.
The only solution is to rewrite the method it uses for zipping files to read from a buffer.  It would be trivial to add this to the standard libraries; I'm kind of amazed it hasn't been done yet.  I gather there's a lot of agreement the entire interface needs to be overhauled, and that seems to be blocking any incremental improvements.
I took Chris B.'s answer and created a complete solution. Here it is in case anyone else is interested:
gzip.GzipFile writes the data in gzipped chunks , which you can set the size of your chunks according to the numbers of lines read from the files.an example: 
The essential compression is done by zlib.compressobj.  ZipFile (under Python 2.5 on MacOSX appears to be compiled).  The Python 2.3 version is as follows.You can see that it builds the compressed file in 8k chunks.  Taking out the source file information is complex because a lot of source file attributes (like uncompressed size) is recorded in the zip file header.  
Some (many? most?) compression algorithms are based on looking at redundancies across the entire  file.Some compression libraries will choose between several compression algorithms based on which works best on the file.I believe the ZipFile module does this, so it wants to see the entire file, not just pieces at a time.Hence, it won't work with generators or files to big to load in memory. That would explain the limitation of the Zipfile library.
Changed in Python 3.5 (from official docs): Added support for writing to unseekable streams.This means that now for zipfile.ZipFile we can use streams which do not store the entire file in memory. Such streams do not support movement over the entire data volume.So this is simple generator:path is a string path of the large file or directory or pathlike object. stream is the unseekable stream instance of the class like this (designed according to official docs):You can try this code online: https://repl.it/@IvanErgunov/zipfilegeneratorThere is also another way to create a generator without ZipInfo and manually reading and dividing your large file. You can pass the queue.Queue() object to your UnseekableStream() object and write to this queue in another thread. Then in current thread you can simply read chunks from this queue in iterable way. See docsP.S.Python Zipstream by allanlei is outdated and unreliable way. It was an attempt to add support for unseekable streams before it was done officially.
The gzip library will take a file-like object for compression.You still need to provide a nominal filename for inclusion in the zip file, but you can pass your data-source to the fileobj.(This answer differs from that of Damnsweet, in that the focus should be on the data-source being incrementally read, not the compressed file being incrementally written.)And I see now the original questioner won't accept Gzip :-(
Now with python 2.7 you can add data to the zipfile insted of the file :http://docs.python.org/2/library/zipfile#zipfile.ZipFile.writestr
This is 2017. If you are still looking to do this elegantly, use Python Zipstream by allanlei. So far, it is probably the only well written library to accomplish that.
In case anyone stumbles upon this question, which is still relevant in 2017 for Python 2.7, here's a working solution for a true streaming zip file, with no requirement for the output to be seekable as in the other cases. The secret is to set bit 3 of the general purpose bit flag (see https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT section 4.3.9.1).Note that this implementation will always create a ZIP64-style file, allowing the streaming to work for arbitrarily large files. It includes an ugly hack to force the zip64 end of central directory record, so be aware it will cause all zipfiles written by your process to become ZIP64-style.


Answer URL
https://docs.python.org/3/library/zipfile.html#zipfile-objects
https://docs.python.org/3/library/io.html?highlight=io#io.IOBase.seekable
https://docs.python.org/3/library/io.html?highlight=io
https://docs.python.org/3/library/queue.html#queue-objects
