Natural Text
I cannot get this to work!  I have a text file from a save game file parser with a bunch of UTF-8 Chinese names in it in byte form, like this in the source.txt:\xe6\x89\x8e\xe5\x8a\xa0\xe6\x8b\x89But, no matter how I import it into Python (3 or 2), I get this string, at best:\\xe6\\x89\\x8e\\xe5\\x8a\\xa0\\xe6\\x8b\\x89I have tried, like other threads have suggested, to re-encode the string as UTF-8 and then decode it with unicode escape, like so:But then it messes up the original encoding, and gives this as the string:'æ\x89\x8eå\x8a\xa0æ\x8b\x89' (printing this string results in: æå æ )Now, if I manually copy and paste b + the original string in the filename and encode this, I get the correct encoding.  For example:Results in:  '扎加拉'But, I can't do this programmatically.  I can't even get rid of the double slashes.  To be clear, source.txt contains single backslashes.  I have tried importing it in many ways, but this is the most common: Okay, so I clicked the answer below (I think), but here is what works:I can't use it on the whole file because of other encoding issues, but extracting each name as a string (stringVariable) and then doing that works!  Thank you!To be more clear, the original file is not just these messed up utf encodings.  It only uses them for certain fields.  For example, here is the beginning of the file:All of the information before the 'm_hero': field is not utf-8.  So using ShadowRanger's solution works if the file is only made up of these fake utf-encodings, but it doesn't work when I have already parsed m_hero as a string and try to convert that.  Karin's solution does work for that.
I'm assuming you're using Python 3. In Python 2, strings are bytes by default, so it would just work for you. But in Python 3, strings are unicode and interpretted as unicode, which is what makes this problem harder if you have a byte string being read as unicode.This solution was inspired by mgilson's answer. We can literally evaluate your unicode string as a byte string by using literal_eval:
The problem is that the unicode_escape codec is implicitly decoding the result of the escape fixes by assuming the bytes are latin-1, not utf-8. You can fix this by:Which (assuming the file contains the literal backslashes and codes, not the bytes they represent) leaves you with '\u624e\u52a0\u62c9' (Which should be correct, I'm just on a system without font support for those characters, so that's just the safe repr based on Unicode escapes). You could skip a step in Py2 by using the string-escape codec for the first stage decode (which I believe would allow you to omit the .encode('latin-1') step), but this solution should be portable, and the cost shouldn't be terrible.
You can do some silly things like evaluating the string:note use ast.literal_eval if you don't want attackers to gain access to your system :-PUsing this in your case would probably look something like:I think that the real issue here is likely that you have a file that contains strings representing bytes (rather than having a file that just stores the bytes themselves).  So, fixing whatever code generated that file in the first place is probably a better bet.  However, barring that, this is the next best thing that I could come up with ...
Solution in Python3 with only string manipulations and encoding conversions without evil eval :)If you like an one-liner, then we can put it simply as:
at the end of day, what you get back is a string right? i would use string.replace method to convert double slash to single slash and add b prefix to make it work. 
So there are several different ways to interpret having the data "in byte form." Let's assume you really do:The b prefix indicates those are bytes. Without getting into the whole mess that is bytes vs codepoints/characters and the long differencesbetween Python 2 and 3, the b-prefixed string indicates those are intended to be bytes (e.g. raw UTF-8 bytes).Then just decode it, which converts UTF-8 encoding (which you alreadyhave in the bytes, into true Unicode characters. In Python 2.7, e.g.:yields:One of your examples did an encode followed by a decode, which can only lead to sorrow and pain. If your variable holds true UTF-8 bytes, you only need the decode.Update Based on discussion, it appears the data isn't really in UTF-8 bytes, but a string-serialized version of same. There are a lot of ways to get from string serial to bytes. Here's mine:Then:as before yields:This byteize() isn't as general as the literal_eval()-based accepted answer, but %timeit benchmarking shows it to be about 33% faster on short strings. It could be further accelerated by swapping out range for xrange under Python 2. The literal_eval approach wins handily on long strings, however, given its lower-level nature.


Answer URL
https://docs.python.org/3/library/ast.html#ast.literal_eval
https://docs.python.org/3/library/codecs.html#python-specific-encodings
