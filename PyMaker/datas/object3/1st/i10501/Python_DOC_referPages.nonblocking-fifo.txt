Natural Text
How can I make a fifo between two python processes, that allow dropping of lines if the reader is not able to handle the input?If the reader tries to read or readline faster then the writer writes, it should block.If the reader cannot work as fast as the writer writes, the writer should not block. Lines should not be buffered (except one line at a time) and only the last line written should be received by the reader on its next readline attempt.Is this possible with a named fifo, or is there any other simple way for achiving this?
The following code uses a named FIFO to allow communication between two scripts.If the reader tries to read faster than the writer, it blocks.If the reader cannot keep up with the writer, the writer does not block.Operations are buffer oriented. Line oriented operations are not currently implemented.This code should be considered a proof-of-concept. The delays and buffer sizes are arbitrary.CodeThe server checks if the client has opened the FIFO. If the client has opened the FIFO, the server writes a line. Otherwise, the server continues running. I have implemented a non-blocking read because the blocking read causes a problem: If the server restarts, most of the time the client stays blocked and never recovers. With a non-blocking client, a server restart is more easily tolerated.OutputNotesOn startup, if the server detects that the FIFO already exists, it removes it. This is the easiest way to notify clients that the server has restarted. This notification is usually ignored by the blocking version of the client.
Well, that's not actually a FIFO (queue) as far as I am aware - it's a single variable. I suppose it might be implementable if you set up a queue or pipe with a maximum size of 1, but it seems that it would work better to use a Lock on a single object in one of the processes, which the other process references via a proxy object. The reader would set it to None whenever it reads, and the writer would overwrite the contents every time it writes.You can get those to the other processes by passing the proxy of the object, and a proxy of the lock, as an argument to all relevant processes. To get it slightly more conveniently, you can use a Manager, which provides a single object with proxy that you can pass in, which contains and provides proxies for whatever other objects (including locks) you want to put in it. This answer provides a useful example of proper use of a Manager to pass objects into a new process.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Lock
https://docs.python.org/3/library/multiprocessing.html#proxy-objects
https://docs.python.org/3/library/multiprocessing.html#managers
https://docs.python.org/3/library/multiprocessing.html#managers
