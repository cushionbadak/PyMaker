Natural Text
I have a python list where elements can repeat.I want to get the first n unique elements from the list.So, in this case, if i want the first 5 unique elements, they would be:I have come up with a solution using generators:In use:I have doubts on this being the most optimal solution. Is there an alternative strategy that i can implement to write it in a more pythonic and efficient way?
I would use a set to remember what was seen and return from the generator when you have seen enough:Output:According to PEP-479 you should return from generators, not raise StopIteration - thanks to @khelwood & @iBug for that piece of comment - one never learns out. With 3.6 you get a deprecated warning, with 3.7 it gives RuntimeErrors: Transition Plan if still using raise StopIterationYour solution using elif element not in itr[:index] and count<upper: uses O(k) lookups - with k being the length of the slice - using a set reduces this to O(1) lookups but uses  more memory because the set has to be kept as well. It is a speed vs. memory tradeoff - what is better is application/data dependend.Consider [1,2,3,4,4,4,4,5] vs [1]*1000+[2]*1000+[3]*1000+[4]*1000+[5]*1000+[6]:For 6 uniques (in longer list):you would have lookups of O(1)+O(2)+...+O(5001)mine would have 5001*O(1) lookup + memory for set( {1,2,3,4,5,6})
You can adapt the popular itertools unique_everseen recipe:Alternatively, as suggested by @Chris_Rands, you can use itertools.islice to extract a fixed number of values from a non-limited generator:Note the unique_everseen recipe is available in 3rd party libraries via more_itertools.unique_everseen or toolz.unique, so you could use:
If your objects are hashable (ints are hashable) you can write utility function using fromkeys method of collections.OrderedDict class (or starting from Python3.7 a plain dict, since they became officially ordered) likeand then implementation of iterate can be simplified toor if you want always a list as an outputImprovementsAs @Chris_Rands mentioned this solution walks through entire collection and we can improve this by writing nub utility in a form of generator like others already did:
You can use OrderedDict or, since Python 3.7, an ordinary dict, since they are implemented to preserve the insertion order. Note that this won't work with sets.
Here is a Pythonic approach using itertools.takewhile():
There are really amazing answers for this question, which are fast, compact and brilliant! The reason I am putting here this code is that I believe there are plenty of cases when you don't care about 1 microsecond time loose nor you want additional libraries in your code for one-time solving a simple task.
Assuming the elements are ordered as shown, this is an opportunity to have fun with the groupby function in itertools:Updated to use islice instead of enumerate per @juanpa.arrivillaga.  You don't even need a set to keep track of duplicates.
Using set with sorted+ key 
GivenCodeA simple list comprehension (similar to @cdlane's answer).Alternatively, in Python 3.6+:
Why not use something like this? 
Example list:Function returns all or count of unique items needed from list1st argument - list to work with, 2nd argument (optional) - count of unique items (by default - None - it means that all unique elements will be returned)Here is example how it works. List name is "a", and we need to get 2 unique elements: Output:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
https://docs.python.org/3/library/itertools.html#itertools.islice
https://docs.python.org/3/glossary.html#term-hashable
https://docs.python.org/3/library/stdtypes.html#dict.fromkeys
https://docs.python.org/3/library/collections.html#collections.OrderedDict
https://docs.python.org/3/whatsnew/3.7.html
https://docs.python.org/3/glossary.html#term-generator
