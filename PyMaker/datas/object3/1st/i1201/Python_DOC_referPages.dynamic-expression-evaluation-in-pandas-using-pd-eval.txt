Natural Text
Objective and Motivationeval and query are powerful, but underrated functions in the pandas API suite, and their use is far from being fully documented or understood. With the right amount of care, query and eval can greatly simplify code, improve performance, and become a powerful tool for creating dynamic workflows.The aim of this canonical QnA is to give users a better understanding of these functions, discussing some of the lesser known features, how they are used, and how best to use them, with clear and easy to understand examples. The two main topics this post will address are Understanding engine, parser and target arguments in pd.eval, and how they can be used to evaluate expressionsUnderstanding the difference between pd.eval, df.eval and df.query, and when each function is appropriate to use for dynamic execution.This post is not a substitute for the documentation (links in the answer), so please do go through that as well! QuestionI will frame a question in such a way that opens discussion for various features supported by eval.Given two DataFrames I would like to perform arithmetic on one or more columns using pd.eval. Specifically, I would like to port the following code:...to code using eval. The reason for using eval is that I would like to automate many workflows, so creating them dynamically will be useful to me.I am trying to better understand the engine and parser arguments to determine how best to solve my problem. I have gone through the documentation but the difference was not made clear to me. What arguments should be used to ensure my code is working at max performance? Is there a way to assign the result of the expression back to df2?Also, to make things more complicated, how do I pass x as an argument inside the string expression? 
This answer dives into the various features and functionality offered by pd.eval, df.query, and df.eval.SetupExamples will involve these DataFrames (unless otherwise specified).  pandas.eval - The "Missing Manual"Note  Of the three functions being discussed, pd.eval is the most important. df.eval and df.query call  pd.eval under the hood. Behaviour  and usage is more or less  consistent across the three functions, with some minor semantic  variations which will be highlighted later. This section will  introduce functionality that is common across all the three functions - this includes, (but not limited to) allowed syntax, precedence rules, and keyword arguments.pd.eval can evaluate arithmetic expressions which can consist of variables and/or literals. These expressions must be passed as strings. So, to answer the question as stated, you can doSome things to note here:The entire expression is a stringdf1, df2, and x refer to variables in the global namespace, these are picked up by eval when parsing the expressionSpecific columns are accessed using the attribute accessor index. You can also use "df1['A'] + (df1['B'] * x)" to the same effect.I will be addressing the specific issue of reassignment in the section explaining the target=... attribute below. But for now, here are more simple examples of valid operations with pd.eval:...and so on. Conditional expressions are also supported in the same way. The statements below are all valid expressions and will be evaluated by the engine.A list detailing all the supported features and syntax can be found in the documentation. In summary,Arithmetic operations except for the left shift (<<) and right shift (>>) operators, e.g., df + 2 * pi / s ** 4 % 42 - the_golden_ratioComparison operations, including chained comparisons, e.g., 2 < df < df2Boolean operations, e.g., df < df2 and df3 < df4 or not df_boollist and tuple literals, e.g., [1, 2] or (1, 2)Attribute access, e.g., df.aSubscript expressions, e.g., df[0]Simple variable evaluation, e.g., pd.eval('df') (this is not very useful)Math functions: sin, cos, exp, log, expm1, log1p, sqrt, sinh, cosh, tanh, arcsin, arccos, arctan, arccosh, arcsinh, arctanh, abs and  arctan2.This section of the documentation also specifies syntax rules that are not supported, including set/dict literals, if-else statements, loops, and comprehensions, and generator expressions.From the list, it is obvious you can also pass expressions involving the index, such asParser Selection: The parser=... argumentpd.eval supports two different parser options when parsing the expression string to generate the syntax tree: pandas and python. The main difference between the two is highlighted by slightly differing precedence rules.Using the default parser pandas, the overloaded bitwise operators & and | which implement vectorized AND and OR operations with pandas objects will have the same operator precedence as and and `or. So, Will be the same as And also the same asHere, the parentheses are necessary. To do this conventionally, the parens would be required to override the higher precedence of bitwise operators:Without that, we end up withUse parser='python' if you want to maintain consistency with python's actual operator precedence rules while evaluating the string.The other difference between the two types of parsers are the semantics of the == and != operators with list and tuple nodes, which have the similar semantics as in and not in respectively, when using the 'pandas' parser. For example,Is valid, and will run with the same semantics as OTOH, pd.eval("df1 == [1, 2, 3]", parser='python') will throw a NotImplementedError error.Backend Selection: The engine=... argumentThere are two options - numexpr (the default) and python. The numexpr option uses the numexpr backend which is optimized for performance. With 'python' backend, your expression is evaluated similar to just passing the expression to python's eval function. You have the flexibility of doing more inside expressions, such as string operations, for instance.Unfortunately, this method offers no performance benefits over the numexpr engine, and there are very few security measures to ensure that dangerous expressions are not evaluated, so USE AT YOUR OWN RISK! It is generally not recommended to change this option to 'python' unless you know what you're doing. local_dict and global_dict argumentsSometimes, it is useful to supply values for variables used inside expressions, but not currently defined in your namespace. You can pass a dictionary to local_dictFor example,This fails because thresh is not defined. However, this works:This is useful when you have variables to supply from a dictionary. Alternatively, with the 'python' engine, you could simply do this:But this is going to possibly be much slower than using the 'numexpr' engine and passing a dictionary to local_dict or global_dict. Hopefully, this should make a convincing argument for the use of these parameters.The target (+ inplace) argument, and Assignment ExpressionsThis is not often a requirement because there are usually simpler ways of doing this, but you can assign the result of pd.eval to an object that implements __getitem__ such as dicts, and (you guessed it) DataFrames. Consider the example in the question To assign a column "D" to df2, we do This is not an in-place modification of df2 (but it can be... read on). Consider another example:If you wanted to (for example) assign this back to a DataFrame, you could use the target argument as follows:If you wanted to perform an in-place mutation on df, set inplace=True.If inplace is set without a target, a ValueError is raised.While the target argument is fun to play around with, you will seldom need to use it.If you wanted to do this with df.eval, you would use an expression involving an assignment:NoteOne of pd.eval's unintended uses is parsing literal strings in a manner very similar to ast.literal_eval:It can also parse nested lists with the 'python' engine:And lists of strings:The problem, however, is for lists with length larger than 10:More information can this error, causes, fixes, and workarounds can be found here.DataFrame.eval - A Juxtaposition with pandas.evalAs mentioned above, df.eval calls pd.eval under the hood. The v0.23 source code shows this:eval creates arguments, does a little validation, and passes the arguments on to pd.eval.For more, you can read on: when to use DataFrame.eval() versus pandas.eval() or python eval()Usage DifferencesExpressions with DataFrames v/s Series ExpressionsFor dynamic queries associated with entire DataFrames, you should prefer pd.eval. For example, there is no simple way to specify the equivalent of pd.eval("df1 + df2") when you call df1.eval or df2.eval.Specifying Column NamesAnother other major difference is how columns are accessed. For example, to add two columns "A" and "B" in df1, you would call pd.eval with the following expression:With df.eval, you need only supply the column names:Since, within the context of df1, it is clear that "A" and "B" refer to column names. You can also refer to the index and columns using index (unless the index is named, in which case you would use the name). Or, more generally, for any DataFrame with an index having 1 or more levels, you can refer to the kth level of the index in an expression using the variable "ilevel_k" which stands for "index at level k". IOW, the expression above can be written as df1.eval("A + ilevel_0").These rules also apply to query.Accessing Variables in Local/Global NamespaceVariables supplied inside expressions must be preceeded by the "@" symbol, to avoid confusion with column names.The same goes for query/It goes without saying that your column names must follow the rules for valid identifier naming in python to be accessible inside eval. See here for a list of rules on naming identifiers.Multiline Queries and AssignmentA little known fact is that eval support multiline expressions that deal with assignment. For example, to create two new columns "E" and "F" in df1 based on some arithmetic operations on some columns, and a third column "G" based on the previously created "E" and "F", we can do...Nifty! However, note that this is not supported by query.eval v/s query - Final WordIt helps to think of df.query as a function that uses pd.eval as a subroutine. Typically, query (as the name suggests) is used to evaluate conditional expressions (i.e., expressions that result in True/False values) and return the rows corresponding to the True result. The result of the expression is then passed to loc (in most cases) to return the rows that satisfy the expression. According to the documentation,The result of the evaluation of this expression is first passed to  DataFrame.loc and if that fails because of a multidimensional key  (e.g., a DataFrame) then the result will be passed to  DataFrame.__getitem__().This method uses the top-level pandas.eval() function to evaluate the  passed query.In terms of similarity, query and df.eval are both alike in how they access column names and variables.This key difference between the two, as mentioned above is how they handle the expression result. This becomes obvious when you actually run an expression through these two functions. For example, considerTo get all rows where "A" >= "B" in df1, we would use eval like this:m represents the intermediate result generated by evaluating the expression "A >= B". We then use the mask to filter df1:However, with query, the intermediate result "m" is directly passed to loc, so with query, you would simply need to do Performance wise, it is exactly the same. But the latter is more concise, and expresses the same operation in a single step. Note that you can also do weird stuff with query like this (to, say, return all rows indexed by df1.index) But don't. Bottom line: Please use query when querying or filtering rows based on a conditional expression.
Great tutorial already, but bear in mind that before jumping wildly into the usage of eval/query attracted by its simpler syntax, it has severe performance issues if your dataset has less than 15,000 rows.In that case, simply use df.loc[mask1, mask2].Refer: https://pandas.pydata.org/pandas-docs/version/0.22/enhancingperf.html#enhancingperf-eval


Answer URL
https://docs.python.org/3/reference/lexical_analysis.html#identifiers
