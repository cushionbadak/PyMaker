Natural Text
I am using python 2.7 on Windows machine. I have an array of urls accompanied by data and headers, so POST method is required. In simple execution it works well:My question is if HostArray length is very large, then it is taking much time in loop.So, how to check each url of HostArray in a multithread. If response code of each url is 200, then I am doing different operation. I have arrays to store 200 and 400 responses.So, how to do this in multithread in python
If you want to do each one in a separate thread you could do something like:I'd also suggest using requests: http://docs.python-requests.org/en/latest/ as well as a thread pool:Threading pool similar to the multiprocessing Pool? Thread pool usage:
scrapy uses twisted library to call multiple urls in parallel without the overhead of opening a new thread per request, it also manage internal queue to accumulate and even prioritize them as a bonus you can also restrict number of parallel requests by settings maximum concurrent requests, you can either launch a scrapy spider as an external process or from your code, just set spider start_urls = HostArray
Your case (basically processing a list into another list) looks like an ideal candidate for concurrent.futures (see for example this answer) or you may go all the way to Executor.map. And of course use ThreadPoolExecutor to limit the number of concurrently running threads to something reasonable.


Answer URL
