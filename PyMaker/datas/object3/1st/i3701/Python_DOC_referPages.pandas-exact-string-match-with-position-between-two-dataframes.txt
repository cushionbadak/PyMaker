Natural Text
Let's say I have the two dataframes below. In reality, both dataframes will be around a million rows each, so I would like to find the most efficient way to compare:each df2["BaseCall"] with each df1["seq"] return a dataframe that contains a list of positions on each df1["gene"] where any df2["BaseCall"] was found   The overall goal is to count the number of times each feature_id is found in a gene, and capture the position information for use downstream. The output should look something like: This ngram function seems to work great when I use just one test basecall on one seq, but I'm having trouble figuring out the most efficient way to use the apply method with one argument coming from two different dataframes. Or perhaps there is an even better way to find matching strings/positions between two dataframes?  
Account for possible multiple occurrences of same BaseCall in a given seq, using re.finditer() and some Pandas hacking:Multiple BaseCall matches are represented as list items in Position, but our desired output puts each match on a separate row.  We can use apply(pd.Series) to explode a column of lists into multiple columns, and then stack() to swing the columns into rows:We can groupby FeatureID and gene to get occurrence totals:Notes: Per OP output, combinations with no matches are excluded.Also, assuming here that BaseCall is just one column, and that there are not both Basecall and BaseCall separate columns.


Answer URL
https://docs.python.org/3/library/re.html#re.finditer
