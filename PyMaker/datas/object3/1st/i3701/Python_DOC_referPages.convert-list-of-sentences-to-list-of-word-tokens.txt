Natural Text
I wonder whether there is a shortcut to make a simple list out of list of lists in Python.I can do that in a for loop, but maybe there is some cool "one-liner"? I tried it with reduce, but I get an error.CodeError message
Given a list of lists l,flat_list = [item for sublist in l for item in sublist]which means:is faster than the shortcuts posted so far. (l is the list to flatten.)Here is the corresponding function:As evidence, you can use the timeit module in the standard library:Explanation: the shortcuts based on + (including the implied use in sum) are, of necessity, O(L**2) when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of I items each: the first I items are copied back and forth L-1 times, the second I items L-2 times, and so on; total number of copies is I times the sum of x for x from 1 to L excluded, i.e., I * (L**2)/2.The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.
You can use itertools.chain():or, on Python >=2.6, use itertools.chain.from_iterable() which doesn't require unpacking the list:This approach is arguably more readable than [item for sublist in l for item in sublist] and appears to be faster too:
Note from the author: This is inefficient. But fun, because monoids are awesome. It's not appropriate for production Python code.This just sums the elements of iterable passed in the first argument, treating second argument as the initial value of the sum (if not given, 0 is used instead and this case will give you an error).Because you are summing nested lists, you actually get [1,3]+[2,4] as a result of sum([[1,3],[2,4]],[]), which is equal to [1,3,2,4].Note that only works on lists of lists. For lists of lists of lists, you'll need another solution.
I tested most suggested solutions with perfplot (a pet project of mine, essentially a wrapper around timeit), and foundto be the fastest solution. (operator.iadd is equally fast.)Code to reproduce the plot:
The extend() method in your example modifies x instead of returning a useful value (which reduce() expects).A faster way to do the reduce version would be
Here is a general approach that applies to numbers, strings, nested lists and mixed containers.CodeNote: in Python 3, yield from flatten(x) can replace for sub_x in flatten(x): yield sub_xDemoReferenceThis solution is modified from a recipe in Beazley, D. and B. Jones.  Recipe 4.14, Python Cookbook 3rd Ed., O'Reilly Media Inc. Sebastopol, CA: 2013.Found an earlier SO post, possibly the original demonstration.
I take my statement back. sum is not the winner. Although it is faster when the list is small. But the performance degrades significantly with larger lists. The sum version is still running for more than a minute and it hasn't done processing yet!For medium lists:Using small lists and timeit: number=1000000
If you want to flatten a data-structure where you don't know how deep it's nested you could use iteration_utilities.deepflatten1It's a generator so you need to cast the result to a list or explicitly iterate over it.To flatten only one level and if each of the items is itself iterable you can also use iteration_utilities.flatten which itself is just a thin wrapper around itertools.chain.from_iterable:Just to add some timings (based on Nico Schlömer answer that didn't include the function presented in this answer):It's a log-log plot to accommodate for the huge range of values spanned. For qualitative reasoning: Lower is better.The results show that if the iterable contains only a few inner iterables then sum will be fastest, however for long iterables only the itertools.chain.from_iterable, iteration_utilities.deepflatten or the nested comprehension have reasonable performance with itertools.chain.from_iterable being the fastest (as already noticed by Nico Schlömer).1 Disclaimer: I'm the author of that library
Why do you use extend?This should work fine.
There seems to be a confusion with operator.add! When you add two lists together, the correct term for that is concat, not add. operator.concat is what you need to use.If you're thinking functional, it is as easy as this::You see reduce respects the sequence type, so when you supply a tuple, you get back a tuple. let's try with a list::Aha, you get back a list.How about performance::from_iterable is pretty fast! But it's no comparison to reduce with concat.
The reason your function didn't work: the extend extends array in-place and doesn't return it. You can still return x from lambda, using some trick:Note: extend is more efficient than + on lists.
Consider installing the more_itertools package.It ships with an implementation for flatten (source, from the itertools recipes):As of version 2.4, you can flatten more complicated, nested iterables with more_itertools.collapse (source, contributed by  abarnet).

An bad feature of Anil's function above is that it requires the user to always manually specify the second argument to be an empty list []. This should instead be a default. Due to the way Python objects work, these should be set inside the function, not in the arguments.Here's a working function:Testing:
Following seem simplest to me:
matplotlib.cbook.flatten() will work for nested lists even if they nest more deeply than the example.Result:This is 18x faster than underscore._.flatten:
The accepted answer did not work for me when dealing with text-based lists of variable lengths. Here is an alternate approach that did work for me.Accepted answer that did not work:New proposed solution that did work for me:
One can also use NumPy's flat:Edit 11/02/2016: Only works when sublists have identical dimensions.
You can use numpy :flat_list = list(np.concatenate(list_of_list))
Simple code for underscore.py package fanIt solves all flatten problems (none list item or complex nesting)You can install underscore.py with pip

Recursive version
If you are willing to give up a tiny amount of speed for a cleaner look, then you could use numpy.concatenate().tolist() or numpy.concatenate().ravel().tolist():You can find out more here in the docs numpy.concatenate and numpy.ravel
Fastest solution I have found (for large list anyway):Done! You can of course turn it back into a list by executing list(l)
This Code also works fine as it just extend the list all the way. Although it is much similar but only have one for loop. So It have less complexity than adding 2 for loops.
Another unusual approach that works for hetero- and homogeneous lists of integers:
I recently came across a situation where I had a mix of strings and numeric data in sublists such aswhere methods like flat_list = [item for sublist in test for item in sublist] have not worked. So, I came up with the following solution for 1+ level of sublistsAnd the result
This may not be the most efficient way but I thought to put a one-liner (actually a two-liner). Both versions will work on arbitrary hierarchy nested lists, and exploits language features (Python3.5) and recursion.The output isThis works in a depth first manner. The recursion goes down until it finds a non-list element, then extends the local variable flist and then rolls back it to the parent. Whenever flist is returned, it is extended to the parent's flist in the list comprehension. Therefore, at the root, a flat list is returned.The above one creates several local lists and returns them which are used to extend the parent's list. I think the way around for this may be creating a gloabl flist, like below.The output is againAlthough I am not sure at this time about the efficiency.
Note: Below applies to Python 3.3+ because it uses yield_from.  six is also a third-party package, though it is stable.  Alternately, you could use sys.version.In the case of obj = [[1, 2,], [3, 4], [5, 6]], all of the solutions here are good, including list comprehension and itertools.chain.from_iterable.However, consider this slightly more complex case:There are several problems here:One element, 6, is just a scalar; it's not iterable, so the above routes will fail here.One element, 'abc', is technically iterable (all strs are).  However, reading between the lines a bit, you don't want to treat it as such--you want to treat it as a single element.The final element, [8, [9, 10]] is itself a nested iterable.  Basic list comprehension and chain.from_iterable only extract "1 level down."You can remedy this as follows:Here, you check that the sub-element (1) is iterable with Iterable, an ABC from itertools, but also want to ensure that (2) the element is not "string-like."
A simple recursive method using reduce from functools and the add operator on lists:The function flatten takes in lst as parameter. It loops all the elements of lst until reaching integers (can also change int to float, str, etc. for other data types), which are added to the return value of the outermost recursion.Recursion, unlike methods like for loops and monads, is that it is a general solution not limited by the list depth. For example, a list with depth of 5 can be flattened the same way as l:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
https://docs.python.org/3/whatsnew/3.3.html
https://docs.python.org/3/library/functions.html#sum
