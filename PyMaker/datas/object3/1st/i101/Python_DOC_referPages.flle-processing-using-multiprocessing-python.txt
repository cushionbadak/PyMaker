Natural Text
I am beginner to Python and trying to add few lines of code to convert json to csv and back to json. Have thousands of files (size 300 MB) to be converted and processed. With current program (using 1 CPU), i am not able to use 16 CPUs of server and need suggestions to fine tune the program for multiprocessing. Below is my code with python 3.7 version.Appreciate suggestions on multiprocessing logic
If you have a single big file that you want to process more effectively I suggest the following:Split file into chunksCreate a process to process each chunk (if necessary) merge the processed chunks back into a single fileSomething like this:
Since you have many files, the simplest multiprocessing example from the documentation should work for you. https://docs.python.org/3.4/library/multiprocessing.html?highlight=processYou could also try replacing listdir with os.scandir(), which doesn't have to return all directory entries before starting.


Answer URL
https://docs.python.org/3/library/os.html#os.scandir
https://docs.python.org/3/library/concurrent.futures.html
