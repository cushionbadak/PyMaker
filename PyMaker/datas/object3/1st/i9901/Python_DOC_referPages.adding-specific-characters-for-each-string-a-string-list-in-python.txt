Natural Text
I have written a script, which basically splits all strings in a sentence into parts;for instance;While some string may be split as above, some of them may be split as following;or some sentences may not be split at all.It is totally decided by a function which splits the strings into parts.What I want to do is the following:What I did is;I have a corpus which has 37251512 sentences. I have written the following script;This script loops over each sentence, and each word in a sentence, and splits it into parts with io.read_binary_model_file function.But it is so expensive for me, it is very slow.Could you suggest me a way which will make the process very fast?Thanks,
Jean-Fran√ßois Fabre covered the  string optimization really well. The other elephant is the use of readlines() for 37,251512 sentences. Just use for a in f, see here for detailed explanation. Depending on how many duplicates there are you in your data and the performance of the model.viterbi_segment function, it might be beneficial to use a set of words instead of doing it all over for repeated words.It seems that you are using python 2.#, in that case use xrange instead of range.replace('\n', '').split() is slow since it has to loop over the whole line when you just want to remove the last line break (there can't be more than one in your case). You could use rstrip('\n')`There is some reduncancy in your code, e.g. each line needs to end with / but you have it in 3 places.All those changes might be tiny but they will add up and your code becomes easier to read as well
What probably slows down a lot is the composition of line_str using multiple string concatenations, which are not recommended if you want performance (well it is okay for things like filename = base+".txt" but not for intensive processing.Create line as a list instead and use str.join to create the final string just to write it to disk. Appending to a list is much faster.And as Maximilian just suggested, you could turn your conditions to elif since they are exclusive to each other (x2). Also added some more micro-optimizations that enhance readability as well.My proposal of how your inner loop should look like:Alternatives:write each string to the output file everytimewrite data to a io.StringIO object and retrieve it to write in the output file.
How about inner loop like this:An then, since you can keep the input in memory at the same time, I would also try to keep the output in memory, and write it out in one go, maybe like this:


Answer URL
https://docs.python.org/3/tutorial/datastructures.html#sets
