Natural Text
I'm using this library, Tomorrow, that in turn uses the ThreadPoolExecutor from the standard library, in order to allow for Async function calls.Calling the decorator @tomorrow.threads(1) spins up a ThreadPoolExecutor with 1 worker.QuestionWhy is it faster to execute a function using 1 thread worker over just calling it as is (e.g. normally)?Why is it slower to execute the same code with 10 thread workers in place of just 1, or even None?Demo codeimports excludedNote: The data folder contains 18 files, each 700 lines of random text.Output0 workers: 0.0120 seconds 1 worker: 0.0009 seconds 10 workers: 0.0535 seconds What I've testedI've ran the code more than a couple dusin times, with different programs running in the background (ran a bunch yesterday, and a couple today). The numbers change, ofc, but the order is always the same. (I.e. 1 is fastest, then 0 then 10).I've also tried changing the order of execution (e.g. moving the do calls around) in order to eliminate caching as a factor, but still the same.Turns out that executing in the order 10, 1, None results in a different order (1 is fastest, then 10, then 0) compared to every other permutation. The result shows that whatever do call is executed last, is considerably slower than it would have been had it been executed first or in the middle instead. Results (After receiving solution from @Dunes)0 workers: 0.0122 seconds 1 worker: 0.0214 seconds 10 workers: 0.0296 seconds 
When you call one of your async functions it returns a "futures" object (instance of tomorrow.Tomorrow in this case). This allows you to submit all your jobs without having to wait for them to finish. However, never actually wait for the jobs to finish. So all do(openAsync1) does is time how long it takes to setup all the jobs (should be very fast). For a more accurate test you need to do something like:Using additional threads in python generally slows things down. This is because of the global interpreter lock which means only 1 thread can ever be active, regardless of the number of cores the CPU has.However, things are complicated by the fact that your job is IO bound. More worker threads might speed things up. This is because a single thread might spend more time waiting for the hard drive to respond than is lost between context switching between the various threads in the multi-threaded variant.Side note, even though neither openAsync1 and openAsync10 wait for jobs to complete, do(openAsync10) is probably slower because it requires more synchronisation between threads when submitting a new job.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor
