Natural Text
I have two or more huge lists(each containing 20 to 25 GB data).I want to perform minus and join operations.For example I want to find out the items present in list1 but not in list2 for following lists.the result should be:join operations:
For list subtraction you could try using a dictionary containing lists to group the values from the source list, and to provide fast lookup operations. An assumption is that the items in your lists are hashable and can therefore be used as dictionary keys.This could be reasonably memory efficient because object references should be used within the data structure, so duplication of the data in the original list should be minimised. However, if the original list contains many small objects, then you'll still end up with large memory consumption in the overhead of constructing the data structure. Depends on your data.I suggest using a defaultdict of lists because it is easy to group the values from the original list, but you can also use a standard dictionary. So, convert the list from which you want to subtract to a defaultdict of lists. Each item from the original list is a key in this dictionary, and the corresponding value is a list containing the same key, one entry per entry in the original list.Then iterate over the second list, removing entries from the dictionary's values if they are present. This bit should be faster than operating directly on lists as an in operation on a dictionary is on average O(1), whereas an in operation on a list is O(N).AlternativesUsing a defaultdict of int as a counter:Using a collections.Counter:Execution timesUsing the timeit module:Note that each function returns a generator, which minimises the amount of work done upfront, and allows the calling code to iterate over the values or convert to a list as required. Each function could return a fully realised list if preferred. The tests below consume all items from the generator in one go.Python 2Python 3The code is the same as for Python 2, however, itervalues() and iteritems() are changed to values() and items().ResultIf you are using Python 2, use a defaultdict of ints. For Python 3 use a Counter.Your mileage will vary, depending on the actual data used. This test data is much smaller than 20GB, and long lists of small objects may behave differently from shorter lists with larger objects.This test also ignores differences in memory usage for each the methods because I don't know of an easy way to measure it, and my test data might be unrepresentative. The defaultdict of lists will probably consume more though.
in python the multisets is offer in the form of a counter as you have multiples instances of the same hashable and therefore inmutable object you should considere using this.Here the minus and join listboth return a iterator over the result, to the same effect in python 2 use itertools.ifilter or a generator expresionnow compare this version vs @mhawke version (using the same script of mhawke)in python3 in python2in both cases this version is better, other than that I get the same result in defaultdict vs Counter, so use defaultdict(int) in python2 or Counter in python3
Here is some fun pythonic version for the minus case:


Answer URL
https://docs.python.org/3/library/collections.html#collections.defaultdict
https://docs.python.org/3/library/collections.html#collections.Counter
https://docs.python.org/3/library/timeit.html
https://docs.python.org/3/library/collections.html#collections.Counter
