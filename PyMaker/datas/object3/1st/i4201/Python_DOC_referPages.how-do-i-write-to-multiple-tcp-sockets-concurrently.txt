Natural Text
I'm parsing data from a binary format and want to stream the resulting JSON strings to a listening server. These streams are independent I would like to have each stream run concurrently to speed up ingest of my data into the server.I've tried using the multithreading library: but depending on the file I'm parsing I may get out-of-memory errors. I'm guessing it has to do with using the pool, but I don't know enough to understand what's happening behind the scenes.I don't think I actually need to use multiprocessing but I don't know if it's possible to open multiple TCP sockets and write to them concurrently? I want to "fire-and-forget" the TCP writes. Is this possible?
Your question is a bit light on details to give a definitive answer (how large are the JSON packets? Is the task I/O bound or CPU bound? Does all your data come from one binary file?) but here are some options that might lead you in the right directionSimple: Write the JSON to stdout and use netcat to stream it to the server. Depending on how your data is structured, you could start up multiple instances to increase parallelism.Non Blocking: If your task is I/O bound then I would keep it all in a single thread. Using non-blocking sockets you could have multiple sockets open at once and write data to them, but as your packets are large you would likely need to feed the data to the socket in chunks - this may quickly get messy.Event Framework: use an event framework to handle the non blocking sockets for you (eg Twisted Python, or asyncio-stream in Python 3). The idea here is you have an event loop which runs a given coroutine until it performs some action that blocks (writing to a socket say), then it switches to another coroutine until that blocks. You basically end up implementing this functionality if you want to use non-blocking sockets yourself. Threads: If your task is CPU bound (by decoding the binary data say) then it may be optimal to run multiple processes to process the data in parallel. Threads won't work for this as the CPython GIL doesn't allow separate threads to run at the same time. Use the multiprocessing module, or just start multiple instances of your processWhat ever method you choose, you should probably look at how you can process your data in chunks instead of loading it all into memory at once.I would suggest that asyncio would be a good place to start if you're using Python 3. By keeping it all in the same thread, you can easily pass around data, and you'll get much of the functionality you need out of the box.


Answer URL
https://docs.python.org/3/library/asyncio-stream.html
