Natural Text
I have used multi threading execute independent code ( that did not have any common code between them ), but this time, I have to use a common function that would be called in each of the thread. So, I am a little confused if it would work. For example, Would the above code be a problem, perhaps because of the race condition? Or python automatically takes care of this? The common_function(input_data) returns a list based on the input provided and this list is then displayed. For a small dataset it work, but I my question is if the input_list becomes huge, would it lead to a problem in the code?
If common_function is a function without any side effects, this is save. In other words, if common_function only works on the input_list and uses nothing else (no shared data, no service), you can call the function in parallel. The size of the input data does not matter as long as it is not shared with any other thread.
If you are using the threading package then you can use semaphore to lock a variable before writing to it. Like the Example here:So all you write between  acquire and release is save for threading
As @lutz had written, there is no danger of race conditions in case there are no shared data between two instances of the common_function. This is what is meant by referential transparency and generally all programming languages aim that such functions should be thread safe. Sometimes, you will need to write and use functions which change some global state. In such cases the modern adage is to use event driven programming - which means to not communicate directly between threads but communicate via some thread safe queueing system. In python I am a huge fan of the queue module for that matter. Another good queue module is the multiprocessing.queue for which a good example is here. I am also pasting the code here.Finally in case you are not confident about some function (probably it is a big function and you dont understand the nuts and bolts), I would recommend that you use the fuzzying method. Here you define a simple functionand then drop this function at random places inside your code. That should amplify any race conditions that there are in the code. This is of-course not a guaranteed method and so if your function is in a production application that gets called millions of times the better strategy will be to break the function to smaller more digestible parts. Watch Raymond Hettinger deliver a lecture about concurrent code in his famous talk on python threading. You can get the code that he is talking about here.


Answer URL
https://docs.python.org/3/library/queue.html
