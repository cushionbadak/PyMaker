Natural Text
I have a file with several thousand records and a list of regular expressions. Iâ€™d like to take each record in the file in turn and evaluate it against my list of regular expressions to a point where a match if found.I created a single threaded script and it does the job but is very slow. To make it multithreaded I made the following adjustments:Created the run_target() function that is be passed to the Thread constructorCreated 5 worker threadsAdded the target function to the check_file() function.Question: run_target() takes 2 arguments that I pass to it with each iteration of the while loop in the check_file() function. Do I need to somehow pass the arguments to the constructor when I create worker threads or shall I leave it as default? Or, should I pass keyword arguments with default values?Also, is there a better or smarter way to tackle this. Thanks in advance. 
Re your first question - yes, as per the threading library documentation the function arguments need to be passed in Thread constructor. So instead of worker = Thread(target = run_target(), args = ()) you need something like worker = Thread(target = run_target, args = (key, expr)). Note no braces after run_target.The code you have posted does not seem to do what you are intending, anyway. IMO, to achieve your goals, the better strategy is to have a function that takes a regex as an argument, and do the entire processing of the file in that function. And then spawn several threads with Thread(target = process_file, args = (expr,)) (note the comma after expr).Note, that there is a known hurdle with threads in the most popular python distro, that make them useless on multicore CPUs - see more in this SO answer. If that is the case on your system, then using multiprocessing is a good alternative - the high level API is quite similar.Happy coding :)


Answer URL
https://docs.python.org/3/library/threading.html
https://docs.python.org/3/library/multiprocessing.html
