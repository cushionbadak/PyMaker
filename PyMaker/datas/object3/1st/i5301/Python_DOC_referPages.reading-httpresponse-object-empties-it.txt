Natural Text
I read a webpage using urllib.request.urlopen:Then, I want both to save it as a file and use the variable for future processing in the code. If I try, for example, the following:file is successfully saved but my_response becomes empty after that.Vice versa, if I call .read() first, I can get the content but saved file will be empty:i.e. I can only access my_content once. I remember this behavior is typical for some other types of python objects (all iterators?) but not sure what is the correct term for it.What would be recommended solution in my case, if I want both to write content to the file and keep it in a variable? (so far I use workaround with writing to the file and then reading it)
This is normal behaviour for any buffer (In this example it is a buffered reader), the opposite would be to read from a stream (stream readers). You can easily circumvent it by first writing it into your variable and do your operations on that variable:The buffer gets emptied if you consume the data that is in it to make space for more data. In this case shutils.copyfileobj also calls .read() on the object and thus only the first one gets what's in the buffer. Also: The documentation of urllibb.request recommends to open the url just like any other resource:this way the resource gets directly freed again after everything was read from the buffer and you are consuming less memory as soon as the with ...: scope ends.Together that would make:


Answer URL
https://docs.python.org/3/library/urllib.request.html#examples
