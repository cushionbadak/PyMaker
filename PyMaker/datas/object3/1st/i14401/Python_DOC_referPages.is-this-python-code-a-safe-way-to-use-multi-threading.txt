Natural Text
An application I use for graphics has an embedded Python interpreter  -  It works exactly the same as any other Python interpreter except there are a few special objects.Basically I am trying to use Python to download a bunch of images and make other Network and disk I/O. If I do this without multithreading, my application will freeze (i.e. videos quit playing) until the downloads are finished.  To get around this I am trying to use multi-threading. However, I can not touch any of the main process.I have written this code. The only parts unique to the program are commented. me.store / me.fetch is basically a way of getting a global variable. op('files') refers to a global table.These are two things, "in the main process" that can only be touched in a thread safe way. I am not sure if my code does this.I would apprecaite any input as to why or (why not) this code is thread-safe and how I can get around access the global variables in a thread safe way.One thing I am worried about is how the counter is fetched multiple times by many threads.  Since it is only updated after the file is written, could this cause a race-condition where the different threads access the counter with the same value (and then don't store the incremented value correctly). Or, what happens to the counter if the disk write fails.
Your code doesn't appear to be safe at all. Key points:Appending to results is unsafe -- two threads might try to append to the list at the same time.Accessing and setting counter is unsafe -- a thread my fetch counter before another thread has set the new counter value.Passing a queue of urls is redundant -- just pass a new url to each job.Another way (concurrent.futures)Since you are using python 3, why not make use of the concurrent.futures module, which makes your task much easier to manage. Below I've written out your code in a way which does not require explicit synchronisation -- all the work is handled by the futures module.If multiple threads modify count then you should use a lock when modifying count.eg.The only problem with this if one job fails for some reason then you will get a missing file number. Any raised exception will also interrupt the executor doing the mapping, by re-raising the exception there --so you can then do something if needed.You could avoid using a counter by using the tempfile module to find somewhere to temporarily store a file before moving the file somewhere permanent.
Remember to look at multiprocessing and threading if you are new to python multi-threading stuff.Your code seems ok, though the code style is not very easy to read. You need to run it to see if it works as your expectation.with will make sure your lock is released. The acquire() method will be called when the block is entered, and release() will be called when the block is exited.If you add more threads, make sure they are not using the same address from queue and no race condition (seems it is done by Queue.get(), but you need to run it to verify). Remember, each threads share the same process so almost everything is shared. You don't want two threads are handling the same address
The Lock doesn't do anything at all.  You only have one thread that ever calls download_job - that's the one you assigned to my_thread.  The other one, the main thread, calls offToOn and is finished as soon as it reaches the end of that function.  So there is no second thread that ever tries to acquire the lock, and hence no second thread ever gets blocked.  The table you mention is, apparently, in a file that you explicitly open and close.  If the operating system protects this file against simultaneous access from different programs, you can get away with this; otherwise it is definitely unsafe because you haven't accomplished any thread synchronization.Proper synchronization between threads requires that different threads have access to the SAME lock; i.e., one lock is accessed by multiple threads.  Also note that "thread" is not a synonym for "process."  Python supports both.  If you're really supposed to avoid accessing the main process, you have to use the multiprocessing module to launch and manage a second process.And this code will never exit, since there is always a thread running in an infinite loop (in threader).Accessing a resource in a thread-safe manner requires something like this:The lock is created once, outside the function that uses it.  Every access to the resource in the whole application, from whatever thread, must acquire the same lock, either by calling use_resource or some equivalent.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
https://docs.python.org/3/library/tempfile.html
https://docs.python.org/3/library/multiprocessing.html
https://docs.python.org/3/library/threading.html
