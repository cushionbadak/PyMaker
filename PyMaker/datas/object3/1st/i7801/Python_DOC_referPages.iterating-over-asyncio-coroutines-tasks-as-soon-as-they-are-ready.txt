Natural Text
I launch a bunch of requests using aiohttp. Is there a way to get the results one-by-one as soon as each request is complete?Perhaps using something like async for? Or Python 3.6 async generators?Currently I await asyncio.gather(*requests) and process them when all of them are completed.
asyncio has as_completed function that probably does what you need. Note, it returns regular iterator, not async. Here's example of usage:Output:
Canonical way is pushing result into asyncio.Queue like in crawler example.Also it's wise to run limited amount for download tasks which get new job from input queue instead of spawning a million of new tasks.
As I understand according to the docs, requests are Futures (or can be easily converted to Future using asyncio.ensure_future).A Future object has a method .add_done_callback. So, you can add your callback for every request, and then do gather.Docs for Future.add_done_callback


Answer URL
https://docs.python.org/3/library/asyncio-task.html#asyncio.as_completed
https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future
https://docs.python.org/3/library/asyncio-task.html#asyncio.Future.add_done_callback
