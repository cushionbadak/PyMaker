Natural Text
I need a way to store 1 billion (or more) fairly large numbers such that it is possible to check relatively quickly whether an element is present in this set of 1 billion numbers or not, but once my Python set grows in size to more than about 10 million entries it makes my program to laggy to run properly.I've tried breaking up this set into smaller sets, but constantly saving/loading different sets (with cPickle) is far too slow when dealing with sets of any appreciable size.I've also looked into databases, but it seems that membership testing in most databases is much slower than in a native Python set. Also, I don't really need the extra baggage that databases provide, i.e. I'm just building a very large set- I don't need multiple data fields for each entry or any other fancy features.Any ideas on the best way to store a massive collection of numbers with as fast as possible membership testing? OR Are there any databases out there (preferably ones easy to implement in Python) that would be well suited for this task? OR Is there a significantly faster way to store/retrieve Python objects from storage than cPickle?
I would recommend sqlite3 for anyone with a similar problem. It is very fast even with a massive collection of items.
Try to store your data into a json file: check out the Json Documentation


Answer URL
https://docs.python.org/3/library/json.html
