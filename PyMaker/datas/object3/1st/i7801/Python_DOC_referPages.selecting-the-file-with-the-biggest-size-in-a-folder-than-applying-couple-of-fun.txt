Natural Text
I am interested in finding the files with the biggest size in terms of kbs in a folder and then apply a function. After that, I want to apply a different function to remaining files in the same folder. If I knew which files I was going to use, names and sizes of the files, I would use the following code:How I could apply it to many folders that consist of many files
This finds the biggest file in a given directory:
In Python 3.5 and higher, you can do this:Now bigfile is a DirEntry object. Then bigfile.name is the filename, and bigfile.path is the full path.Then you can do Or, if you want to skip directories:
Just list your files with os.listdir, check for files using os.path.isfile and use os.stat for a more reliable size readout, store them in a list and sort that list:Now your file_list will contain a list of tuples (file_size, file_path) ordered from smallest to the biggest size in the target directory.You can then use file_list[-1][1] to get the biggest file, and you can loop through all of the others (file_list[:-1]) to execute something else on them, e.g.:EDIT - It seems that after you execute your functions you want to save them all in one file, so:This will concentrate all of the files in combined.dat in the same directory, in order of the smallest to the biggest file. You can use for files in reversed(file_list): if you want to store from the biggest to the smallest file.


Answer URL
https://docs.python.org/3/library/os.html#os.DirEntry
