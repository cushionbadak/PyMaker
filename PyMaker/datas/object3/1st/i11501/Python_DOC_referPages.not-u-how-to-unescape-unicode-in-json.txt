Natural Text
I'm trying to scrape from a non-English website using Scrapy. The scraped results as JSON look something like this:This is the code I'm using:How would I output unescaped Unicode characters onto the JSON?
Edit (2016-10-19):With Scrapy 1.2+, you can use the FEED_EXPORT_ENCODING set to the character encoding you need for the output JSON file, e.g FEED_EXPORT_ENCODING = 'utf-8' (the default value being None, which means \uXXXX escaping)Note: I'm adapting what I wrote on GitHub for a similar issue I linked to in the question's comments.Note that there's an open issue on Scrapy to make the output encoding a parameter: https://github.com/scrapy/scrapy/issues/1965Scrapy's default JSON exporter uses (the default) ensure_ascii=True argument, so it outputs Unicode characters as \uXXXX sequences before writing to file. (This is what is used when doing -o somefile.json)Setting ensure_ascii=False in the exporter will output Unicode strings, which will end up as UTF-8 encoded on file. See custom exporter code at the bottom here.To illustrate, let's read your input JSON string back into some data to work on:The input with \uXXXX sequences is valid JSON for Python (as it should), and loads() produces a valid Python dict.Now let's serialize to JSON again:And now with ensure_ascii=FalseLet's print to see the difference:If you want to write JSON items as UTF-8, you can do it like this:1.. define a custom item exporter, e.g. in an exporters.py file in your project2.. replace the default JSON item exporter in your settings.py
Use the codecs module for text -> text decoding (In Python 2 it's not strictly necessary, but in Python 3 str doesn't have a decode method, because the methods are for str -> bytes and back, not str -> str). Using the unicode_escape codec for decoding will get you the correct data back:So to fix the names you're getting, you'd do:If the problem is in JSON you're producing, you'd want to just make sure the json module isn't forcing strings to be ASCII with character encodings; it does so by default because not all JSON parsers can handle true Unicode characters (they often assume data is sent as ASCII bytes with escapes). So wherever you call json.dump/json.dumps (or create a json.JSONEncoder), make sure to explicitly pass ensure_ascii=False.


Answer URL
https://docs.python.org/3/library/codecs.html#text-encodings
https://docs.python.org/3/library/codecs.html#text-encodings
