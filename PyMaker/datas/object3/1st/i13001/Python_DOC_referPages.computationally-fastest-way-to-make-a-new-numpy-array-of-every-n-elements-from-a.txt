Natural Text
This question already has an answer here:subsampling every nth entry in a numpy array                    1 answer                Suppose a 1-dimensional numpy array. I want to make a new array that contains every n elements. What is the computationally fastest way to do this? Example: Edit: bolded important part of the question. 
The absolute fastest way to do this is to write an extension module in pure C and use the buffer protocol to access the data directly.  If you use Cython or another such tool to write the C for you, you may see small amounts of performance lost in automatic reference counting.  Since you still have to do manual reference counting in handwritten C, the difference is likely to be negligible to nonexistent.This will have marginally less overhead than the slicing syntax NumPy provides out of the box.  However, assuming you use NumPy correctly, the overall performance gain is likely to be small and constant, so it's not clear to me that this is worth the extra effort in any reasonable situation.
Computational cost is O(n), you are "making" a loop with length(a)/stepUPDATE:Computational cost is O(1), there is no numpy.array object re-arrangement, just one constant ... in access-method...  is set / changed. Once deployed, the access-speed is the same as with a value stored there before an update.


Answer URL
https://docs.python.org/3/c-api/buffer.html
