Natural Text
The last line, "tokens", returns characters instead of words. Why is this and how do I get it to return words instead? Especially considering doing it based on a list of sentences. 
Because sent_tokenize returns a list of string sentences and itertools.chain chains iterables to a single iterable returning items one at a time from each until they're exhausted. In effect you've recombined the sentences to a single string and iterate over it in the list comprehension.To create a single list of words from a list of sentences you can for example split and flatten:This does not handle punctuation, but your original attempt wouldn't either. Your original would work also with split:Note that you can use a generator expression instead of a list comprehension as arguments to unpack. Even better, use chain.from_iterable:For punctuation handling use nltk.tokenize.word_tokenize instead of str.split. It'll return words and punctuation as separate items, and splits for example I's to I and 's (which of course is a good thing since they're in fact separate words, just contracted).
Firstly, if the file is in 'utf8' and you're using Python2, it'll be better if you use the encoding='utf8' parameter in io.open():If it's Python3, simply do:Do take a look at http://nedbatchelder.com/text/unipain.htmlAs for the tokenization, if we assume that each line contains some sort of paragraph that might be made up of one or more sentences, we would like to first initial a list to store the whole document:Then we iterate through the lines and split the line up into sentences:Then we split the sentences up into the tokens:Since we want to update our document list to store the tokenized sentences, we use:Not recommended!!! (but still possible in one line):
May be you should to use word_tokenize instead of sent_tokenize?http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.chain
