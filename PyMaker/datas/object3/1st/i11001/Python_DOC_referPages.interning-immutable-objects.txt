Natural Text
I have a program with an object of the formwhere a,b are immutable and the space of possible parameters a,b is very small. These objects are created and go out of scope constantly during the execution of the program, so unsurprisingly a lot of time is spent recomputing self.cache for the same values a,b. Since the very_expensive_computation is very expensive, it seems it would be better to just avoid garbage collecting these items and have the constructor return references to the already existing objects if possible, kinda like string interning.The obvious way to do this to me seems to be to add a dictionary to the class and override __new__ and __init__ so that they check the dictionary and return already existing instances if possible, but at the same time this feels kinda unsatisfactory since it would have to be done to each class separately and since detecting whether you are an actual new object in __init__ would probably be pretty hacky.Any other suggestions?
I'd memoize the very_expensive_computation storing the results in an LRU cache to guarantee an upper bound on the amount of memory used:Where the RecentlyUsedContainer could be this one: https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/collections_.py#L12You could also simplify the code with a decorator:See: https://github.com/shazow/unstdlib.py/blob/master/unstdlib/standard/functools_.py#L59I prefer to keep the memoized versions of functions separate from the "real" versions so callers can explicitly see that they could be getting a cached result, and it can make testing easier. This is largely personal preference, though.Edit: as pointed out in the comments, Python 3 ships with functools.lru_cache.
You can also accomplish this with class and instance variables:


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
