Natural Text
Why is sys.getsizeof() larger for a Python str of length 1 than for a string of length 2?  (For length > 2, the relationship seems to increase monotonically as expected.)Example:It seems it has to do with str.__sizeof__, but I don't know C well enough at all to dig into what's going on in this case.
When you import pandas, it does a whole ton of NumPy stuff, including calling UNICODE_setitem on all the single-ASCII-letter strings, and presumably somewhere else doing something similar on the single-ASCII-digit strings.That NumPy function calls the deprecated C API PyUnicode_AsUnicode.When you call that in CPython 3.3+, that caches the wchar_t * representation on the string's internal struct, in its wstr member, as the two wchar_t values w'a' and '\0', which takes 8 bytes on a 32-bit-wchar_t build of Python. And str.__size__ takes that into account.So, all of the single-character interned strings for ASCII letters and digits—but nothing else—end up 8 bytes larger.First, we know that it's apparently something that happens on import pandas (per Brad Solomon's answer.) It may happen on np.set_printoptions(precision=4, threshold=625, edgeitems=10) (miradulo posted, but then deleted, a comment to that effect on ShadowRanger's answer), but definitely not on import numpy.Second, we know that it happens to 'a', but what about other single-character strings?To verify the former, and to test the latter, I ran this code:On multiple CPython installations (but all 64-bit CPython 3.4 or later on Linux or macOS), I got the same results:So, import numpy changes nothing, and so does set_printoptions (presumably why miradulo deleted the comment…), but import pandas does.And it apparently affects ASCII digits and letters, but nothing else.Also, if you change all of the prints to print(sizes.values()), so the strings never get encoded for output, you get the same results, which implies that either it's not about caching the UTF-8, or it is but that's always happening even if we don't force it.The obvious possibility is that whatever Pandas is calling is using one of the legacy PyUnicode API to generate single-character strings for all of the ASCII digits and letters. So these strings end up not in compact-ASCII format, but in legacy-ready format, right? (For details on what that means, see the comments in the source.)Nope. Using the code from my superhackyinternals, we can see that it's still in compact-ascii format:We can see that Pandas changes the size from 50 to 58, but the fields are still:… in other words, it's 1BYTE_KIND, length 1, mortal-interned, ASCII, compact, and ready.But, if you look at ps.wstr, before Pandas it's a null pointer, while after Pandas it's a pointer to the wchar_t string w"a\0". And str.__sizeof__ takes that wstr size into account.So, the question is, how do you end up with an ascii-compact string that has a wstr value?Simple: you call PyUnicode_AsUnicode on it (or one of the other deprecated functions or macros that accesses the 3.2-style native wchar_t * internal storage. That native internal storage doesn't actually exist in 3.3+. So, for backward compatibility, those calls are handled by creating that storage on the fly, sticking it on the wstr member, and calling the appropriate PyUnicode_AsUCS[24] function to decode to that storage. (Unless you're dealing with a compact string whose kind happens to match the wchar_t width, in which case wstr is just a pointer to the native storage after all.)You'd expect str.__sizeof__ to ideally include that extra storage, and from the source, you can see that it does.Let's verify that:Tada, our 50 goes to 58.So, how do you work out where this gets called?There are actually a ton of calls to PyUnicode_AsUnicode, and the PyUnicode_AS_UNICODE macro, and other functions that call them, throughout Pandas and Numpy. So I ran Python in lldb and attached a breakpoint to PyUnicode_AsUnicode, with a script that skips if the calling stack frame is the same as last time.The first few calls involve datetime formats. Then there's one with a single letter. And the stack frame is:… and above multiarray it's pure Python all the way up to the import pandas. So, if you want to know exactly where Pandas is calling this function, you'd need to debug in pdb, which I haven't done yet. But I think we've got enough info now.
Python 3.3+'s str is quite a complicated structure, and can end up storing the underlying data in up to three different ways, depending on which APIs have been used with the string and the code points represented by the string. The most common alternate representation case is a cached UTF-8 representation, but that only applies to non-ASCII strings so it doesn't apply here.In this case, I suspect the single character string (which, as an implementation detail, is a singleton) was used in a way that triggered the creation of the legacy wchar_t* representation (extensions using the legacy Py_UNICODE APIs can cause this), and your Python build uses a four byte wchar_t, leading to the string being eight bytes bigger than it otherwise would be (four for the a itself, four more for the NUL terminator). The fact that it's a singleton means that even though you may never have triggered such a legacy API call, any extension which retrieved a reference to the singleton would affect the observed size for everyone by using it with the legacy API.Personally, I don't reproduce at all on my Linux 3.6.5 install (the sizes increase smoothly), indicating no wchar_t representation was created, and on my Windows 3.6.3 install, 'a' is only 54 bytes, not 58 (which matched Windows' native two byte wchar_t). In both cases I'm running with ipython; it's possible different ipython dependencies with different versions are responsible for your (and my) inconsistent observations.To be clear, this extra cost is fairly immaterial; since the single character string is a singleton, the incremental cost of use is really just 4-8 bytes (depending on pointer width). You're not going to break the bank on memory if a handful of strings ended up used with the legacy APIs.
This appears to be related to a single Pandas import in an IPython startup file.I can reproduce the behavior in a plain Python session also:


Answer URL
https://docs.python.org/3/c-api/unicode.html#c.PyUnicode_AsUnicode
https://docs.python.org/3/c-api/unicode.html#deprecated-py-unicode-apis
https://docs.python.org/3/c-api/unicode.html#c.PyUnicode_AsUnicode
https://docs.python.org/3/c-api/unicode.html#deprecated-py-unicode-apis
