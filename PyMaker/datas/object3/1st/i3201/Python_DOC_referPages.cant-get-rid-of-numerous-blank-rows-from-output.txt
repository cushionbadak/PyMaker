Natural Text
I've written a script in python in combination with selenium to get some information from a webpage. To reach the content it is necessary to click on the + sign next to each name within the larger table. When clicking on those + sign is done, all the table connected to each name shows up. My script can do it very efficiently. However, the next step is to parse those tabular data. This is where I'm stuck with messy content. The data of each table are getting parsed but lots of blank rows come along out of nowhere. How can I kick out those blank rows and keep on parsing only those tabular data?link to that siteThis is my script:This is how the output looks like (before and after each tabular content):
You can skip handling empty text nodes with some kind of filtering and save much time just by using correct selectors:
If you're just asking how to now print out the all-empty results, you can just write a loop that filters them. Assuming each line is a single data valueâ€¦The simplest thing is to use the implicit loop with the implicit bool filter inside any:any(data) is true for a sequence data if data is not empty, and at least one of the elements of data is truthy. Empty strings are falsey, non-empty strings are truthy. So, this does exactly what you want: it skips over [] and ['', ''], but not things like ['Achanta', 'Apr 16 2018 11:24AM'].But if you have a hard time understanding it, it may be better to be more explicit:
Assuming data contains your table, you can use any to filter outempty rows here any returns True if at least one of row's element is not empty 


Answer URL
https://docs.python.org/3/library/functions.html#any
