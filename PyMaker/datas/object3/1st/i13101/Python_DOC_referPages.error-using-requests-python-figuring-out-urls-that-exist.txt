Natural Text
I am trying to find out if a set of urls exist or if they will give back an error without having to go through all of them. I am using python 3.5.0. The basic URl is http://www5.registraduria.gov.co/CuentasClarasPublicoCon2014/Consultas/Candidato/Reporte/2 and it changes by adding a simple number at the end (from 0 to at most 10000). I tried the following:This works for small number of urls, like from 0 to 100 but I want to make sure I have them all. I was hoping to save the goodid object in a .txt file I could access later but it seems to be having an error I can't figure out, at random urls, after some time. This is the error:It seems like the main problem is that it returns a buffering error, but it does so at different urls, it has happened at /197 in a different run at 273 and the last one at 692. How can solve this error? What does it mean? Unrelated but if anyone have any suggestions on doing this faster I welcome them, I'm fairly new to python, and not a programming expert in general.EDIT: I understand now that connection reset by peer means the server closed the connection, but I still don't understand why, specially I don't understand why it is happening at random URLs
Two recommendations:Use time.sleep between requests: https://docs.python.org/3.0/library/time.html#time.sleepUse try/except on errors: https://docs.python.org/3/tutorial/errors.html#handling-exceptions


Answer URL
https://docs.python.org/3/tutorial/errors.html#handling-exceptions
