Natural Text
I want to call python functions in sub-processes without creating a copy of the current process.I have a method A.run() which should call B.run() multiple times.A.run() consumes a lot of memory, so I don't want to use a ProcessPoolExecutor because it copies the whole memory AFAIK.I also do not want to use subprocess.Popen because it has several disadvantages to me:only pass strings as parameterscannot take advantage of exceptionsI have to know the location of B.py exactly, instead of relying on PYTHONPATHI also do not want to spawn threads because B.run() crashes easily and I don't want it to effect the parent process.Is there a way I have overlooked that has the advantage of spawning separate processes, without the extra memory but with the benefits of calling a python method?Edit 1:Answers to some questions:If I understand this correctly, I don't need the context of the first python process.I cannot reuse Processes because I call a C++ library which has static variables and they need to be destroyed.
Most Unix Operating Systems are using Copy-On-Write when they fork new processes.This implies that, if the memory is not changed by the process children, the memory is not duplicated but shared.You see the processes having the same amount of memory due to the fact that they use that amount of virtual memory, but when it comes to the physical one, the parent process memory is actually in a unique copy shared among them all.If I assume right and the children processes are not touching the parent's memory at all, then you're just wasting your time going against Unix design principles.More info here.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
