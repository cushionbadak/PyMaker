Natural Text
Parsing some HTML content I got the following string:The common advice on handling it appears to be to decode using unicode_escape. However, this results in the following:The escaped characters get correctly decoded, but cyrillic letters for some reason get mangled. Other than using regexes to extract everything that looks like a unicode string, decoding only them using unicode_escape and then putting everything into a new string, which other methods exist to decode strings with unicode code points in Python?
unicode_escape treats the input as Latin-1 encoded; any bytes that do not represent a Python string literal escape sequence are decoded mapping bytes directly to Unicode codepoints. You gave it UTF-8 bytes, so the cyrillic characters are represented with 2 bytes each where decoded to two Latin-1 characters each, one of which is U+00D0 √ê, the other unprintable:This kind of mis-decoding is called a Mojibake, and can be repaired by re-encoding to Latin-1, then decoding from the correct codec (UTF-8 in your case):Note that this will fail if the \uhhhh escape sequences encode codepoints outside of the Latin-1 range (U+0000-U+00FF).The Python 3 equivalent of the above uses codecs.encode():
The regex really is the easiest solution (Python 3):This works fine with any 4-nibble Unicode escape, and can be pretty easily extended to other escapes.For Python 2, make all strings u'' strings, and use unichr.


Answer URL
https://docs.python.org/3/library/codecs.html#codecs.encode
