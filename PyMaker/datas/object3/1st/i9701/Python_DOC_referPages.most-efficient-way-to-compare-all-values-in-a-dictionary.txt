Natural Text
I have a dictionary I created by reading in a whole lot of image files. It looks like this:I am trying to process these images to see how similar each of them are to each other. The thing is, with 1000s of files worth of data this is taking forever. I'm sure I have 20 different places I could optimize but I am trying to work through it one piece at a time to see how I can better optimize it.My original method tested file1 against all of the rest of the files. Then I tested file2 against all of the files. But I still tested it against file1. So, by the time I get to file1000 in the above example I shouldn't even need to test anything at that point since it has already been tested 999 times. This is what I tried:This doesn't work, as I am getting the wrong output now. The compare function is just this:I just didn't want to put that huge equation into the if statement.Does anyone have a good method for comparing each of the data segments of the files dictionary without overlapping the comparisons?Edit:After trying ShadowRanger's answer I have realized that I may not have fully understood what I needed. My original answers dictionary looked like this:And for now I am storing my results in a file like this:I thought that by using combinations and only testing individual files once I would save a lot of time retesting files and not have to waste time getting rid of duplicate answers. But as far as I can tell, the combinations have actually reduced my ability to find matches and I'm not sure why.
You can avoid redundant comparisons with itertools.combinations to get order-insensitive unique pairs. Just import itertools and replace your doubly nested loop:with a single loop that gets the combinations:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.combinations
