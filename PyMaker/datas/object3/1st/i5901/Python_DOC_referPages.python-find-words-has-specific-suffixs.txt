Natural Text
I am dealing with Chinese NLP Problem.I find to find word has specific suffixs. For example, I have two list!suffixs = ['aaa','bbb','cc'.....]words_list = ['oneaaa','twobbb','three','four']I know I can use re package, but re just can deal with less than 100 suffixs,but I have 1000+ suffixs.I try to useBut it is too slow.The func(s,w) could split the word w to no_suffix word and suffix.For example 'oneaaa' to ['one','aaa']ï¼Œbut the func bases on some condition and more complex.So any doesn't work here.So I want to know whether a better way to deal with it.
If you just wan to see which words have "back-fixes" (the correct term is suffix, BTW), you can just use str.endswith in combination with anyOr pass all the suffixes to endswith, but for that they have to be in a tuple, not list:If you also need to know which suffix matches, you can get the next, or None if non match:              Or shorter using filter: b = next(filter(w.endswith, back_fixs), None)Or without default, using try/except:


Answer URL
https://docs.python.org/3/library/stdtypes.html#str.endswith
