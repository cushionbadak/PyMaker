Natural Text
I have a csv file, which I want to read with Python. When I use the following code snippet, I get an error.orororWhen I open the file in TextWrangler or in Excel, I don't see any strange characters in it, even when I select Display Invisibles in TextWrangler. Some other strange observation: it's always line 1380 where it goes wrong, even when I delete lines 1370-1390 from the file. This makes me wonder if there is even a wrong character in that line.Is there a way to read the file and to simply skip non-decodeable characters?EDITThis is a hex dump around the problematic area. Position 58658 is position E522 in hexadecimal. The 89 in the second field in the second line seems to be the culprit.EDIT 2It turns out that using encoding windows-1250, I can read the file. The question remains: is it possible to read the file assuming UTF-8, and skipping byte sequences that cannot be read?
None of your first two snippets could possibly raise a UnicodeDecodeError - only the third one (which is quite braindead FWIW - infinite loop indeed), when it hits the print(self.md) statement. The problem is not with reading the file but with your stdout not handling the encoding. Also I don't think you really understand what Unicode is - there's no such thing as a "non-unicode character". I strongly suggest you read this article about unicode and encodings.


Answer URL
https://docs.python.org/3/library/functions.html#open
