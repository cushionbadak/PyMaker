Natural Text
I'm trying to create a program that will fill out a form on this site: Insurance surveyI'm using python 2.7 and mechanize after numerous attempts with 3.4 and realizing mechanize doesn't work with 3.4. I'm a novice but have learned a LOT in trying to do this (python is awesome). This is my error : mechanize._form.ItemNotFoundError: insufficient items with name '$150,000'The problem is, only after I fill out the form fields location and coverageType then do the options for coverageAmount show up :( . I've been messing around with this and watching numerous videos online and all my research has led me to conclude that mechanize won't do this. I've also read that this is an ajax call, and mechanize won't work for this. Things seem to be pointing towards selenium webdriver... Does anybody have any input?
AJAX calls are performed by javascript, and mechanize has no way to run javascript. Mechanize only looks at form fields on a static HTML page and allows you to fill & submit those. This is why your research is pointing you towards things like Selenium or Ghost, which run on top of a real browser that can execute javascript.There is a simpler way to do this though! If you use the developer tools on your browser (e.g. the Network tab in Firefox or Chrome) and fill out the form you can see the request your browser is making behind the scenes, even with AJAX:This tells you:The browser made a POST requestTo this URL: https://interactive.web.insurance.ca.gov/survey/survey?type=homeownerSurvey&event=HOMEOWNERSWith the following form params:location=ALAMEDA+ALAMEDAcoverageType=HOMEOWNERScoverageAmount=150000homeAge=NewYou can use this information to make the same POST request in Python:This is python3. The requests library provides an even nicer API for making HTTP requests.Edit: In response to your three questions:is it possible for the dictionary that you've created to have more than 1 location and cycle through them using a for loop?Yes, just add a loop around the code and pass a different value for location each time. I would put this code into a function to make the code cleaner, like this:https://gist.github.com/lost-theory/08786e3a27c8d8ce3839the results are in a lot of jibberish, so I'd have to find a way to sift through it huh. Like pick out which is whichYes, the jibberish is HTML that you will need to parse to collect the data you're looking for. Look at HTMLParser in the python standard library, or install a library like lxml or BeautifulSoup, which have a little nicer API. You can also just try parsing the text by hand using str.split.If you want to convert the table's rows into python lists you'll need to find all the rows, which look like this:You want to loop over all the <tr> (row) elements, grabbing all the <td> (column) elements inside each row, then clean up the text in each column (removing those &nbsp; spaces, etc.).There are lots of questions on StackOverflow and tutorials on the internet on how to parse or scrape HTML in python, like this or this.could you explain why we had to do the data.encode lineSure! In the documentation for urlopen, it says:data must be a bytes object specifying additional data to be sent to the server, or None if no such data is needed.The urlencode function returns a unicode string, and if we try to pass that into urlopen, we get this error:So we use data.encode('utf8') to convert the unicode string to bytes. You typically need to use bytes for input & output like reading from or writing to files on disk, sending or receiving data over the network like HTTP requests, etc. This presentation has a good explanation of bytes vs. unicode strings in python and why you need to decode/encode when doing I/O.
There are no AJAX calls being made by that page. It is simple Javascript code that is executed from an onchange event for the "Type of Coverage:" select box.If you look at the source for the page you will see that all the values are stored in the Javascript function coverageTypeOnChange(). From that you can work out what to post for all cases. Provided that these values do not change you will be able to automate scraping of the site without running Javascript code.If, however, the values change over time (e.g. as premiums usually do), then you might be better off looking at Selenium or alternative headless browsers.
This problem gave me a big headache once. Regarding the following line:This implies that you are selecting 'ALAMEDA BERKELEY' from a list.  If so, then try adding a comma after the item:Otherwise use:I often try elaborate workarounds for mechanize problems, only to come back to my original code and make a slight modification... very powerful, very unforgiving


Answer URL
https://docs.python.org/3/library/html.parser.html
https://docs.python.org/3/library/urllib.request.html#urllib.request.urlopen
