Natural Text
I believe I am about to ask a definite newbie question, but here goes:I written a python script that does snmp queries. The snmp query function uses a global list as its output.The get_snmp querier's are launched using the following code:This setup works fine, all of the get_snmp process write their output out to a shared list output_list, and then the csv_write function is called and that list is dumped to disk.The main issue with this program is on a large run the memory usage can become quite high as the list is being built.  I would like to write the results to the text file in the background to keep memory usage down, and I'm not sure how to do it.  I went with the global list to eliminate file locking issues.
I think that your main problem with increasing memory usage is that you don't remove contents from that list when writing them to file. Maybe you should do del output_list[:] after writing it to file.
Have each of the workers write their output to a Queue, then have another worker (or the main thread) read from the Queue and write to a file. That way you don't have to store everything in memory.Don't write directly to the file from the workers; otherwise you can have issues with multiple processes trying to write to the same file at the same time, which will just give you a headache until you fix it anyway.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue
