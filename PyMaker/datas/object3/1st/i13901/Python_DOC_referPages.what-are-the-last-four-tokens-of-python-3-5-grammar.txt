Natural Text
https://docs.python.org/3.5/library/token.htmlWhat are last four tokens about in the token definition of Python 3.5 grammar?
token.OPIs a generalization of the operator tokens. This is also mentioned in the tokenize module:To simplify token stream handling, all Operators and Delimiters tokens are returned using the generic token.OP token type. The exact type can be determined by checking the exact_type property on the named tuple returned from tokenize.tokenize().token.ERRORTOKENIs used to mark errors within the tokenize-process of the parser. This is mostly used to generate syntax errors that abort the parsing process.It’s also mentioned in the tokenize documentation:Note that unclosed single-quoted strings do not cause an error to be raised. They are tokenized as ERRORTOKEN, followed by the tokenization of their contents.token.N_TOKENSIs simply the number of tokens that are defined. It’s used in the parser for iterating over the list of tokens.token.NT_OFFSETIs used in token.h like this:It basically separates terminal and non-terminal tokens.


Answer URL
https://docs.python.org/3/library/tokenize.html
https://docs.python.org/3/library/tokenize.html#tokenize.TokenError
https://docs.python.org/3/library/tokenize.html
