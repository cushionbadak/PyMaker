Natural Text
A while ago, I made a Python script which looked similar to this:Which, of course, worked pretty slowly on a 100mb file. However, I changed the program to do thisAnd the file copied much faster. My question is, why does the second method work faster even though the program copies the same number of lines (albeit collects them and prints them one by one)?
I may have found a reason why write is slower than writelines. In looking through the CPython source (3.4.3) I found the code for the write function (took out irrelevent parts).Modules/_io/fileio.cIf you notice, this function actually returns a value, the size of the string that has been written, which is another function call.I tested this out to see if it actually had a return value, and it did.The following is the code for the writelines function implementation in CPython (took out irrelevent parts).Modules/_io/iobase.cIf you notice, there is no return value! It simply has Py_RETURN_NONE instead of another function call to calculate the size of the written value.So, I went ahead and tested that there really wasn't a return value.The extra time that write takes seems to be due to the extra function call taken in the implementation to produce the return value. By using writelines, you skip that step and the fileio is the only bottleneck.Edit: write documentation
I do not agree with the other answer here.It is simply a coincidence. It highly depends on your environment:What OS?What HDD/CPU?What HDD file system format?How busy is your CPU/HDD?What Python version?Both pieces of code do the absolute same thing with tiny differences in performance.For me personally .writelines() takes longer to execute then your first example using .write(). Tested with 110MB text file. I will not post my machine specs on purpose.Test .write(): ------copying took 0.934000015259 seconds (dashes for readability)Test .writelines(): copying took 0.936999797821 secondsAlso tested with small and as large as 1.5GB files with the same results. (writelines always beeing slightly slower, up to 0.5sec difference for 1.5GB file).
That's because of that in first part you have to call the method write for all the lines in each iteration which makes your program take much time to run. But in second code although your waste more memory but it performs better because you have called the writelines() method each 100000 line.Let see this is source,this is the source of writelines function :As you can see it joins all the list items and calls the write function  one time.Note that joining the data here takes time but its less than the time for calling the write function for each line.But since you use python 3.4 in ,it writes the lines one at a time rather than joining them so it would be much faster than write in this case :cStringIO.writelines() now accepts any iterable argument and writes  the lines one at a time rather than joining them and writing once.  Made a parallel change to StringIO.writelines().  Saves memory and  makes suitable for use with generator expressions. 


Answer URL
https://docs.python.org/3/library/io.html#io.TextIOBase.write
