Natural Text
I have a dataset df of trader transactions.I have 2 levels of for loops as follows:I would like to parallelise the calculations for each asset in Assets, and I also want to parallelise the calculations for each trader for every asset. After ALL these calculations are done, I want to do additional analysis based on the list of smartTrader.This is my first attempt at parallel processing, so please be patient with me, and I appreciate your help.
If you use pathos, which provides a fork of multiprocessing, you can easily nest parallel maps. pathos is built for easily testing combinations of nested parallel maps -- which are direct translations of nested for loops.It provides a selection of maps that are blocking, non-blocking, iterative, asynchronous, serial, parallel, and distributed.Here this example uses a processing pool and a thread pool, where the thread map call is blocking, while the processing map call is asynchronous (note the get at the end of the last line).Get pathos here: https://github.com/uqfoundationor with:$ pip install git+https://github.com/uqfoundation/pathos.git@master
Nested parallelism can be done elegantly with Ray, a system that allows you to easily parallelize and distribute your Python code.Assume you want to parallelize the following nested programBellow is the Ray code parallelizing the above code:Use the @ray.remote decorator for each function that we want to execute concurrently in its own process. A remote function returns a future (i.e., an identifier to the result) rather than the result itself. When invoking a remote function f() the remote modifier, i.e., f.remote() Use the ids_to_vals() helper function to convert a nested list of ids to values. Note the program structure is identical. You only need to add remote and then convert the futures (ids) returned by the remote functions to values using the ids_to_vals() helper function.There are a number of advantages of using Ray over the multiprocessing module. In particular, the same code will run on a single machine as well as on a cluster of machines. For more advantages of Ray see this related post.
Instead of using for, use map:From then on, you can try different parallel map implementations s.a. multiprocessing's, or stackless'
Probably threading, from standard python library, is most convenient approach:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#introduction
