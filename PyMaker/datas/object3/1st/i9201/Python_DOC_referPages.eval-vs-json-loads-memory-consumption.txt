Natural Text
I have a dictionary that I am writing to a file and then loading it again. The dictionary has some sets, so I have the option of either doing an eval() or json.dumps() with a custom ModelEncoder. I tried both and json has a much smaller memory footprint than eval does. Why does eval take up so much more memory?
Whether or not you should be using eval is really another question.The primary reason eval takes more memory is the text is first compiled into a python expression (parsed, converted to byte code) and then evaluated.Especially with large literals, python has a memory leak in the bytecode compiler.  This issue talks about pyc compilation, but you'll also hit it with code compilation in eval.json doesn't suffer from this because it's not converting your text into executable bytecode.


Answer URL
https://docs.python.org/3/library/pickle.html
