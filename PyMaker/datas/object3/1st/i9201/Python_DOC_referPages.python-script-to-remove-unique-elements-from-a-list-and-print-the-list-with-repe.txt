Natural Text
I have written a script to remove all unique elements from a list and print the list with only repeated elements:Below are some examples how the output list for an input list should beThe script above works exactly as expected when tested with few smaller lists. However I want some ideas on how to optimize the script (both time and space complexities considered) for input lists with bigger lengths ( 50000 <=len(list) <= 50M )
your script has a number of issues:the classical if x in dict1.keys() => if x in dict1 to be sure to use the dictionary check instead of linearno list comprehension: append in a loop, not as performant.O(n^2) complexity because of the double loopMy approach:You could count your elements using collections.Counter, then filter out a new list using a list comprehension using a filter on the number of ocurrences:result:I may be wrong but, the complexity of this approach is (roughly) O(n*log(n)) (linear scan of the list plus the hashing of the keys in the dictionary and the lookup in the list comprehension). So, it's good performance-wise.


Answer URL
https://docs.python.org/3/library/stdtypes.html#dict-views
