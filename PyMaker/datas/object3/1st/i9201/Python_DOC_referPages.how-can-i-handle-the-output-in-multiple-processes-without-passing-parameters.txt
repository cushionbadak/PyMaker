Natural Text
How do I share a queue to a number of processes,the code of these processes in multiple files, and I don't want to pass the queue as parameter.I try to solve the problem, but failed.I have three filesmain.pyp_1.pyp_2.pyThen I run main.py, but without any output.
The docs about exchanging data between processes explain that you hand over the queue to the process as an argument. Your code worked on my Mac (I would call that "by chance" as it's using undocumented feature which might be just a side effect of one python version), but not on Windows.An important fact is that processes started with multiprocessing don't have a shared memory space (unlike threads, which do share their memory). The mechanisms to share objects are pipes, queues and objects created via shared memory or server processes.That said: there are a few things which I would improve in your code:the split into three modules does not make sense to me, especially p_1.py and p_2.pyit's not clear why you did a class queue_run when a normal function similar to test would do the trick as wellHere's your example, condensed into one file. I left the class so you can see easily what I changed:P.S. you may want to call test producer and queue_run consumer, that's how they are called in programming jargonUpdate:if I pass the queue as a parameter to all sub modules to solve the above problem, I need to modify all the files, this is a complex projectAs you're working on Windows (as you noted in a comment) there's an important fact to know: If you create a new process, it will be spawned: a new python interpreter is started, your python modules are loaded new, and thus all global variables (like your queue) are initiated afresh with a new instance. That means there is no way to share a global variable with processes.If you want to stay with multiprocessing, the only way is to pass them to the submodules. I cannot imagine that you have more than 50 submodules, so an hour of work with a good editor should do the trick.The alternative though is to use threading: the downside is that you can only use one cpu core, the upside is that all your threads share the same memory space. The only thing you need to care about is to use thread safe data structures, such as a queue.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
