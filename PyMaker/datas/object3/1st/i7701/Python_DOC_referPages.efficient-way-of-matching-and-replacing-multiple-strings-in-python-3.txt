Natural Text
I have multiple (>30) compiled regex'sI then have a function which takes a text and replaces some of its words using every one of the regex's above and the re.sub method as followsQuestion: Is there a more efficient way to make these replacements?The regex's cannot be generalized or simplified from their current form.I feel like reassigning the value of text each time for every regex is quite slow, given that the function only replaces a word or two from the entirety of text for each reassignment. Also, given that I have to do this for multiple documents, that slows things down even more.Thanks in advance!
Reassigning a value takes constant time in Python. Unlike in languages like C, variables are more of a "name tag". So, changing what the name tag points to takes very little time.If they are constant strings, I would collect them into a tuple:And then in your function, just iterate over the list:But if your regexes are actually named regex_1, regex_2, etc., they probably should be directly defined in a list of some sort.Also note, if you are doing replacements like 'cat' -> 'dog', the str.replace() method might be easier (text = text.replace('cat', 'dog')), and it will probably be faster.If your strings are very long, and re-making it from scratch with the regexes might take very long. An implementation of @Oliver Charlesworth's method that was mentioned in the comments could be:But this breaks down if you have overlapping text that you need to substitute.
we can pass a function to re.sub repl argumentsimplify to 3 regex for easier understandingassuming regex_1, regex_2, and regex_3 will be 111,222 and 333 respectively. Then, regex_replace will be the list holding string that will be use for replace follow the order of regex_1, regex_2 and regex_3.regex_1 will be replace will 'one'regex_2 replace with 'two' and so onNot sure how much this will improve the runtime though, give it a try


Answer URL
https://docs.python.org/3/library/re.html#re.sub
