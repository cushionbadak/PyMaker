Natural Text
So I have a python script that is running continuously that can be sent messages. It takes the content of the messages and runs a search on a few APIs and then replies with the results from that search. Currently I am using async/await, which is working so far, but what happens is that if it receives a message while it is already working on one, it will wait until it is done with the message it is currently searching for before starting the one it received. I would like to have it set up so that it can be processing multiple messages at a time, as most of the wait is waiting on the APIs to respond. Is multiprocessing what I should be using here, and if so is there a way for me to have the multiprocessing function just be idling until a message gets added, and then send that message off to the multiprocessing function. It seems like I should be using a queue, but most of the Documentation says that the queues close once there is no more to work on. One thing that is necessary is that if I have a specific amount of processes working (eg 4 processes) and i have >4 messages, it stores the extra messages, and adds them to the next process that is freed up.Something like this:(really bad psuedocode)Thanks
You should rather try to find what is "blocking" exactly. The point of asyncio is exactly what you want, avoid blocking pending tasks while you wait for another. Multiprocessing or multithreading does not seem to be the way to go here. Proper use of asyncio will be an order of magnitude better than any multiprocessing for this kind of use-case. If anything hangs, either you're misusing asyncio (calling a blocking function for instance) or you're limited by the QoS of your message queue (which is probably configurable).


Answer URL
https://docs.python.org/3/library/asyncio-queue.html
