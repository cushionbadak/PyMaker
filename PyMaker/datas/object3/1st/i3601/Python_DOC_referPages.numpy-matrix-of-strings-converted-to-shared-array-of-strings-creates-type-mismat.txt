Natural Text
I am experimenting with multiprocessing in Python, however, I am having trouble with creating some shared memory. Take the following example that illustrates my problem:In reference to the following (slightly different as he uses a matrix full of floats, but same principle), I want to convert a numpy matrix of strings into a shared memory space for processes to use. I have the following:However, the np_wrapper only has the first character of each string:Things I have tried to rectify the problem:I tried changing the dtype of the frombuffer function from <U1 to <U6, which is the dtype of the input_array. However, it throws the following exception:ValueError: buffer size must be a multiple of element sizeI tried using a dtype of int64 with the frombuffer function because my shared_memory array is of type c_wchar_p (i.e. string pointers) and I am on a 64-bit Windows 10 system. However, it throws the following exception:ValueError: cannot reshape array of size 4 into shape (4,2)I am extremely confused why my typing is wrong here. Does anyone have any insight on how to fix this problem?
It may help to understand what this array of strings contains:Because it is a transpose, the shape and strides differ from the input array, but the strings are in the original order.My guess is that Array should be defined with nbytes rather than size.
PrefaceBefore I detail my solution, I want to preface my answer with some helpful information. The function memoryview() in python proved to be extremely useful in getting the full picture. For example, run the following after specify the dtype of input_array as dtype='S6' (b/c less bytes to examine):Then following results are yielded:We can see by the following output that each entry in the input_array has a length of 6 bytes and is laid out in a contiguous block of memory. This tells us that our Numpy array is not just 8 pointers to strings out in memory.Turning back to when the dtype was not specified, @hpaulj additionally provided even more helpful insight. With having read the dtype documentation, our array has type <U6, which translates to as follows:SolutionTLDR; Here is the solution:Solution Explanation:The first incorrect aspect of the initial code was the typing information for the initial shared_memory array. Our Numpy array is not an array of pointers, but rather 8 strings compacted contiguously next to each other (with some padding dictated by the longest element). Therefore, using the type c_wchar_p (i.e. a string pointer) was not correct. I chose c_char over c_wchar because c_char is guaranteed to be one byte, where as c_wchar is not (see documentation for further details).Next, one needs to specify the entire size of the shared memory. Because I chose c_char as my type, I will be specifying the number of bytes. The length is given by the following: There are 8 elements (input_array.size) with each element contain 24 bytes (input_array.itemsize). Therefore, there are 8 * 24 = 192 bytes total in our shared memory.Finally, when using the frombuffer function in Numpy, be sure to specify the correct dtype because this is how Numpy will be dividing up and interpreting the arbitrary bytes coming in. Just simply use the same dtype of the input_array to complete the translation. And finally, once the copyto has commenced, the shared_memory will have been successfully configured!


Answer URL
https://docs.python.org/3/library/ctypes.html#fundamental-data-types
https://docs.python.org/3/library/ctypes.html#fundamental-data-types
