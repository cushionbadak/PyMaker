Natural Text
I'm pretty new to asyncio and I'm not able to figure this out by myself at this time and would greatly appreciate any help.The use case is as follows:There is a web service that I need to fetch data from that throttles and blacklists when too many requests are sent to it.I need to make a large number of requests to this web service for dataThe web service sends data in a paged fashion i.e. when there is too much data for a given request, subsequent requests need to be made to get more pages.Whether more pages need to be fetched can be figured out by examining the response from a particular request.Once data is received on the client-side it needs to written to diskSo, in my mind, the setup could be as follows: - An initial list of requests that need to be made is prepared - A Semaphore controls how many requests are made per unit time to control throttling. - All the initial requests are added to a loop. - When a response is received a separate coroutine (or maybe a thread?) is dispatched to persist the data. I don't want persistence to be blocking the fetching of more data. - When a response is received it is examined to see if more pages need to be requested to get the full data. If more pages are needed then another task is added to the loop to fetch the next page.I've written some code for a minimal example that should provide the framework for what I'm trying to achieve:This seems to set up the semaphore properly and run the workers but it leaves several questions unanswered:First and foremost, how do I dynamically add more workers (to fetch subsequent pages) to the loop?How can I handle the persistence so that it doesn't block data fetching?Assuming multiple pages need to end up in the same file, how can I safely collect all of the data from these requests, merge it, and then persist without blocking other data fetching requests?Thank you in advance for any help!
First and foremost, how do I dynamically add more workers (to fetch subsequent pages) to the loop?You can enqueue new coroutines to the event loop with asyncio.ensure_future.How can I handle the persistence so that it doesn't block data fetching?If you're talking about writing to a database, there are libraries for that. If you're talking about writing to a file, then that's tricky-- local file IO is almost always blocking, so you'd have to delegate work to a separate thread. Luckily, asyncio provides a helper for that: loop.run_in_executor.Assuming multiple pages need to end up in the same file, how can I safely collect all of the data from these requests, merge it, and then persist without blocking other data fetching requests?This starts getting outside the bounds of what's a good question for SO. You should read up on different concurrency patterns for this.


Answer URL
https://docs.python.org/3/library/asyncio-task.html#asyncio.ensure_future
https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.AbstractEventLoop.run_in_executor
