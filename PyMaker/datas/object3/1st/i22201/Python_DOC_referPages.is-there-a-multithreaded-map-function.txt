Natural Text
I have a function that is side-effect free. I would like to run it for every element in an array and return an array with all of the results.Does Python have something to generate all of the values?
Try the Pool.map function from multiprocessing:http://docs.python.org/library/multiprocessing.html#using-a-pool-of-workersIt's not multithreaded per-se, but that's actually good since multithreading is severely crippled in Python by the GIL.
You can use the multiprocessing python package (http://docs.python.org/library/multiprocessing.html). The cloud python package, available from PiCloud (http://www.picloud.com), offers a multi-processing map() function as well, which can offload your map to the cloud.
Python now has the concurrent.futures module, which is the simplest way of getting map to work with either multiple threads or multiple processes. https://docs.python.org/3/library/concurrent.futures.html
Below is my map_parallel function. It works just like map, except it can run each element in parallel in a separate thread (but see note below). This answer builds upon another SO answer.NOTE: One thing to be careful of is Exceptions. Like normal map, the above function raises an exception if one of it's sub-thread raises an exception, and will stop iteration. However, due to the parallel nature, there's no guarantee that the earliest element will raise the first exception.
Maybe try the Unladen Swallow Python 3 implementation?  That might be a major project, and not guaranteed to be stable, but if you're inclined it could work.  Then list or set comprehensions seem like the proper functional structure to use.
Try concurrent.futures.ThreadPoolExecutor.map in Python Standard Library (New in version 3.2).Similar to map(func, *iterables) except:the iterables are collected immediately rather than lazily;func is executed asynchronously and several calls to func may be made concurrently.A simple example (modified from ThreadPoolExecutor Example):
I would think there would be no reason to have such a function.  All Python threads have to execute on the same CPU.  Assuming your map function has no I/O component, you would not see any speedup in processing (and would probably see a slowdown due to context switching).Other posters have mentioned multiprocessing - that is probably a better idea.
This functionality is not built in. However, someone has already implemented it.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor.map
https://docs.python.org/3/library/functions.html#map
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor-example
