Natural Text
I have an application that needs to make a set 30-40 API calls, each of which kick off query "jobs" that will need polled for status, and then retrieved from the API.  Each job will take an unknown amount of time -anywhere from immediate to 3-4 minutes.  This seems like a great place to apply a multithreading model wherein I "dispatch" these jobs and then wait for all of them to be completed before processing the results.  I am confused by all the options available for this in Python, and it's unclear to me whether I should use concurrent.futures or asyncio or greenlets. How do I evaluate the options and make a choice that results in readable, Pythonic code?  Which of these libraries is the most prevalent and reusable(in other words, which one is a good investment for my time)? Which is best suited for my task?  Any advice or guidance on how to translate my problem into Python 3.6+ would be appreciated.
I'm not really sure what you are asking. However, multiprocessing is really easy with Python and if you simply need to trigger jobs, then the following might help:You can find out more about multiprocessing via the documentation: https://docs.python.org/3/library/multiprocessing.html


Answer URL
https://docs.python.org/3/library/multiprocessing.html
