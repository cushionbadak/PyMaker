Natural Text
I am reading a csv in chunk and passing the chunk to a pool of 4 processes.With this code my understanding is it should show me 4 process continuously running. But in the screenshot of htop below, It is always 2 running. One is htop command it self. It means that only 1 python process in running at the time.From the memory usage, It is 12 gb which i think will only be possible when the 4 chunks are loaded in memory provided 1 chunk is 2gb almostHow can i use for processors at once.
The problem is that you misuderstood how map works.From the doc:map(func, iterable[, chunksize])  This method chops the iterable into a number of chunks which it submits  to the process pool as separate tasks. The (approximate) size of these  chunks can be specified by setting chunksize to a positive integer.As iterable you provide a list with only one element: the tuple (df, ...).But you'd need to provide a iterable with many elements. To make this work, you'd need toprepare the list first and only then send it to the processes (hint:you can just write Pool() and let python find out the number of coresitself)But now you have the problem that you need to hold the full csv data inmemory which might be ok, but is usually not. To come around this problemyou could switch to using a queue: You wouldbuild up an empty queuestart the processes and tell them to get items from the queue (which is still empty at start)feed the queue with your main process (and maybe check that the queue is not getting too long so memory consumption doesn't go into the roof)put a STOP element to the queue so the processes quit themselvesThere's a good example in the official doc (look at the last example on the page) which explains you would approach that.One last word: Are you sure your operation is CPU bound? Do you do a lot ofprocessing in wrapper_process (and possibly also transformer)? Because if you just split the CSV in separatefiles without much processing your program is IO bound and not CPU boundand then the multiprocessing wouldn't make any sense.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.map
https://docs.python.org/3/library/multiprocessing.html#examples
