Natural Text
I'm designing an algorithm to do the following: Given array A[1... n], for every i < j, find all inversion pairs such that A[i] > A[j]. I'm using merge sort and copying array A to array B and then comparing the two arrays, but I'm having a difficult time seeing how I can use this to find the number of inversions. Any hints or help would be greatly appreciated.
The only advice I could give to this (which looks suspiciously like a homework question ;)   ) is to first do it manually with a small set of numbers (e.g. 5), and then write down the steps you took to solve the problem.This should allow you to figure out a generic solution you can use to write the code.
So here is O(n log n) solution in java. This is almost normal merge sort, the whole magic is hidden in merge function.Note that while sorting algorithm remove inversions.While merging algorithm counts number of removed inversions (sorted out one might say).The only moment when inversions are removed is when algorithm takes element from the right side of an array and merge it to the main array.The number of inversions removed by this operation is the number of elements left from the the left array to be merged. :)Hope it's explanatory enough.
I've found it in O(n * log n) time by the following method.Merge sort array A and create a copy (array B)Take A[1] and find its position in sorted array B via a binary search. The number of inversions for this element will be one less than the index number of its position in B since every lower number that appears after the first element of A will be an inversion. 2a. accumulate the number of inversions to counter variable num_inversions.2b. remove A[1] from array A and also from its corresponding position in array Brerun from step 2 until there are no more elements in A.Here’s an example run of this algorithm. Original array A = (6, 9, 1, 14, 8, 12, 3, 2)1: Merge sort and copy to array BB = (1, 2, 3, 6, 8, 9, 12, 14)2: Take A[1] and binary search to find it in array BA[1] = 6B = (1, 2, 3, 6, 8, 9, 12, 14)6 is in the 4th position of array B, thus there are 3 inversions. We know this because 6 was in the first position in array A, thus any lower value element that subsequently appears in array A would have an index of j > i (since i in this case is 1).2.b: Remove A[1] from array A and also from its corresponding position in array B (bold elements are removed).A = (6, 9, 1, 14, 8, 12, 3, 2) = (9, 1, 14, 8, 12, 3, 2)B = (1, 2, 3, 6, 8, 9, 12, 14) = (1, 2, 3, 8, 9, 12, 14)3: Rerun from step 2 on the new A and B arrays.A[1] = 9B =  (1, 2, 3, 8, 9, 12, 14)9 is now in the 5th position of array B, thus there are 4 inversions. We know this because 9 was in the first position in array A, thus any lower value element that subsequently appears would have an index of j > i (since i in this case is again 1).Remove A[1] from array A and also from its corresponding position in array B (bold elements are removed)A = (9, 1, 14, 8, 12, 3, 2) = (1, 14, 8, 12, 3, 2)B = (1, 2, 3, 8, 9, 12, 14) = (1, 2, 3, 8, 12, 14)Continuing in this vein will give us the total number of inversions for array A once the loop is complete.Step 1 (merge sort) would take O(n * log n) to execute. Step 2 would execute n times and at each execution would perform a binary search that takes O(log n) to run for a total of O(n * log n). Total running time would thus be O(n * log n) + O(n * log n) = O(n * log n).Thanks for your help. Writing out the sample arrays on a piece of paper really helped to visualize the problem.
In Python
I wonder why nobody mentioned binary-indexed trees yet. You can use one to maintain prefix sums on the values of your permutation elements. Then you can just proceed from right to left and count for every element the number of elements smaller than it to the right:The complexity is O(n log n), and the constant factor is very low.
I had a question similar to this for homework actually. I was restricted that it must have O(nlogn) efficiency.I used the idea you proposed of using Mergesort, since it is already of the correct efficiency. I just inserted some code into the merging function that was basically:Whenever a number from the array on the right is being added to the output array, I add to the total number of inversions, the amount of numbers remaining in the left array.This makes a lot of sense to me now that I've thought about it enough. Your counting how many times there is a greater number coming before any numbers.hth.
The number of inversions can be found by analyzing the merge process in merge sort : When copying a element from the second array to the merge array (the 9 in this exemple), it keeps its place relatively to other elements. When copying a element from the first array to the merge array (the 5 here) it is inverted with all the elements staying in the second array (2 inversions with the 3 and the 4). So a little modification of merge sort can solve the problem in O(n ln n).For exemple, just  uncomment the two # lines in the mergesort python code below to have the count.    EDIT 1The same task can be achieved with a stable version of quick sort, known to be slightly faster :Choosing pivot as the last element, inversions are well counted, and execution time  40% better than merge one above. EDIT 2 For performance in python, a numpy  & numba version :First the numpy part, which use argsort O (n ln n) : And the numba part for the efficient BIT approach :
Note that the answer by Geoffrey Irving is wrong. The number of inversions in an array is half the total distance elements must be moved in order to sort the array. Therefore, it can be computed by sorting the array, maintaining the resulting permutation p[i], and then computing the sum of abs(p[i]-i)/2. This takes O(n log n) time, which is optimal.An alternative method is given at http://mathworld.wolfram.com/PermutationInversion.html. This method is equivalent to the sum of max(0, p[i]-i), which is equal to the sum of abs(p[i]-i])/2 since the total distance elements move left is equal to the total distance elements move to the right.Take the sequence { 3, 2, 1 } as an example. There are three inversions: (3, 2), (3, 1), (2, 1), so the inversion number is 3. However, according to the quoted method the answer would have been 2.
The primary purpose of this answer is to compare the speeds of the various Python versions found here, but I also have a few contributions of my own. (FWIW, I just discovered this question while performing a duplicate search). The relative execution speeds of algorithms implemented in CPython may be different to what one would expect from a simple analysis of the algorithms, and from experience with other languages. That's because Python provides many powerful functions and methods implemented in C that can operate on lists and other collections at close to the speed one would get in a fully-compiled language, so those operations run much faster than equivalent algorithms implemented "manually" with Python code. Code that takes advantage of these tools can often outperform theoretically superior algorithms that try to do everything with Python operations on individual items of the collection. Of course the actual quantity of data being processed has an impact on this too. But for moderate amounts of data, code that uses an O(n²) algorithm running at C speed can easily beat an O(n log n) algorithm that does the bulk of its work with individual Python operations.Many of the posted answers to this inversion counting question use an algorithm based on mergesort. Theoretically, this is a good approach, unless the array size is very small. But Python's built-in TimSort (a hybrid stable sorting algorithm, derived from merge sort and insertion sort) runs at C speed, and a mergesort coded by hand in Python cannot hope to compete with it for speed.One of the more intriguing solutions here, in the answer posted by Niklas B, uses the built-in sort to determine the ranking of array items, and a Binary Indexed Tree (aka Fenwick tree) to store the cumulative sums required to calculate the inversion count. In the process of trying to understand this data structure and Niklas's algorithm I wrote a few variations of my own (posted below). But I also discovered that for moderate list sizes it's actually faster to use Python's built-in sum function than the lovely Fenwick tree.Eventually, when the list size gets around 500, the O(n²) aspect of calling sum inside that for loop rears its ugly head, and the performance starts to plummet.Mergesort isn't the only O(nlogn) sort, and several others may be utilized to perform inversion counting. prasadvk's answer uses a binary tree sort, however his code appears to be in C++ or one of its derivatives. So I've added a Python version. I originally used a class to implement the tree nodes, but discovered that a dict is noticeably faster. I eventually used list, which is even faster, although it does make the code a little less readable. One bonus of treesort is that it's a lot easier to implement iteratively than mergesort is. Python doesn't optimize recursion and it has a recursion depth limit (although that can be increased if you really need it). And of course Python function calls are relatively slow, so when you're trying to optimize for speed it's good to avoid function calls, when practical.Another O(nlogn) sort is the venerable radix sort. It's big advantage is that it doesn't compare keys to each other. It's disadvantage is that it works best on contiguous sequences of integers, ideally a permutation of integers in range(b**m) where b is usually 2. I added a few versions based on radix sort after attempting to read Counting Inversions, Offline Orthogonal Range Counting, and Related Problems which is linked in calculating the number of “inversions” in a permutation.To use radix sort effectively to count inversions in a general sequence seq of length n we can create a permutation of range(n) that has the same number of inversions as seq. We can do that in (at worst) O(nlogn) time via TimSort. The trick is to permute the indices of seq by sorting seq. It's easier to explain this with a small example.outputBy sorting the (value, index) pairs of seq we have permuted the indices of seq with the same number of swaps that are required to put seq into its original order from its sorted order. We can create that permutation by sorting range(n) with a suitable key function:outputWe can avoid that lambda by using seq's .__getitem__ method:This is only slightly faster, but we're looking for all the speed enhancements we can get. ;)The code below performs timeit tests on all of the existing Python algorithms on this page, plus a few of my own: a couple of brute-force O(n²) versions, a few variations on Niklas B's algorithm, and of course one based on mergesort  (which I wrote without referring to the existing answers). It also has my list-based treesort code roughly derived from prasadvk's code, and various functions based on radix sort, some using a similar strategy to the mergesort approaches, and some using sum or a Fenwick tree.This program measures the execution time of each function on a series of random lists of integers; it can also verify that each function gives the same results as the others, and that it doesn't modify the input list.Each timeit call gives a vector containing 3 results, which I sort. The main value to look at here is the minimum one, the other values merely give an indication of how reliable that minimum value is, as discussed in the Note in the timeit module docs.Unfortunately, the output from this program is too large to include in this answer, so I'm posting it in its own (community wiki) answer.The output is from 3 runs on my ancient 32 bit single core 2GHz machine running Python 3.6.0 on an old Debian-derivative distro. YMMV. During the tests I shut down my Web browser and disconnected from my router to minimize the impact of other tasks on the CPU.The first run tests all the functions with list sizes from 5 to 320, with loop sizes from 4096 to 64 (as the list size doubles, the loop size is halved). The random pool used to construct each list is half the size of the list itself, so we are likely to get lots of duplicates. Some of the inversion counting algorithms are more sensitive to duplicates than others.The second run uses larger lists: 640 to 10240, and a fixed loop size of 8. To save time it eliminates several of the slowest functions from the tests. My brute-force O(n²) functions are just way too slow at these sizes, and as mentioned earlier, my code that uses sum, which does so well on small to moderate lists, just can't keep up on big lists.The final run covers list sizes from 20480 to 655360, and a fixed loop size of 4, with the 8 fastest functions. For list sizes under 40,000 or so Tim Babych's code is the clear winner. Well done Tim! Niklas B's code is a good all-round performer too, although it gets beaten on the smaller lists. The bisection-based code of "python" also does rather well, although it appears to be a little slower with huge lists with lots of duplicates, probably due to that linear while loop it uses to step over dupes.However, for the very large list sizes, the bisection-based algorithms can't compete with the true O(nlogn) algorithms.Please see here for the output
Check this out: http://www.cs.jhu.edu/~xfliu/600.363_F03/hw_solution/solution1.pdfI hope that it will give you the right answer.2-3 Inversion part (d)It's running time is O(nlogn)
Here is one possible solution with variation of binary tree. It adds a field called rightSubTreeSize to each tree node. Keep on inserting number into binary tree in the order they appear in the array. If number goes lhs of node the inversion count for that element would be (1 + rightSubTreeSize). Since all those elements are greater than current element and they would have appeared earlier in the array. If element goes to rhs of a node, just increase its rightSubTreeSize. Following is the code. 

Since this is an old question, I'll provide my answer in C.
Here is c++ solution
Here is a C code for count inversionsAn explanation was given in detail here: http://www.geeksforgeeks.org/counting-inversions/
O(n log n) time, O(n) space solution in java. A mergesort, with a tweak to preserve the number of inversions performed during the merge step. (for a well explained mergesort take a look at http://www.vogella.com/tutorials/JavaAlgorithmsMergesort/article.html )Since mergesort can be made in place, the space complexity may be improved to O(1).When using this sort, the inversions happen only in the merge step and only when we have to put an element of the second part before elements from the first half, e.g. 0 5 10 15merged with 1 6 22we have 3 + 2 + 0 = 5 inversions: 1 with {5, 10, 15}  6 with {10, 15}   22 with {}After we have made the 5 inversions, our new merged list is 0, 1, 5, 6, 10, 15, 22There is a demo task on Codility called ArrayInversionCount, where you can test your solution.
Here is O(n*log(n)) perl implementation:
My answer in Python:1- Sort the Array first and make a copy of it. In my program, B represents the sorted array.2- Iterate over the original array (unsorted), and find the index of that element on the sorted list. Also note down the index of the element.3- Make sure the element doesn't have any duplicates, if it has then you need to change the value of your index by -1. The while condition in my program is exactly doing that. 4- Keep counting the inversion that will your index value, and remove the element once you have calculated its inversion. 
Well I have a different solution but I am afraid that would work only for distinct array elements.To explain my code we keep on adding elements from the end of Array.For any incoming array element we find the index of first element in vector v which is greater than our incoming element and assign that value to inversion count of the index of incoming element.After that we insert that element into vector v at it's correct position such that vector v remain in sorted order.  
Another Python solution, short one. Makes use of builtin bisect module, which provides functions to insert element into its place in sorted array and to find index of element in sorted array.The idea is to store elements left of n-th in such array, which would allow us to easily find the number of them greater than n-th.
The easy O(n^2) answer is to use nested for-loops and increment a counter for every inversionNow I suppose you want a more efficient solution, I'll think about it.
One possible solution in C++ satisfying the O(N*log(N)) time complexity requirement would be as follows.It differs from a regular merge sort only by the counter.
Here's my O(n log n) solution in Ruby:And some test cases:
Best optimized way will be to solve it through merge sort where will merging itself we can check how many inversions are required by comparing left and right array. Whenever element at left array is greater than element at right array, it will be inversion.  Merge sort Approach :-Here is the code . Code is exact same as merge sort except code snippet under mergeToParent method where i am counting the inversion under  else condition of (left[leftunPicked] < right[rightunPicked])Another approach where we can compare the input array with sorted array:-This implementation of Diablo answer. Though this should not be preferred approach as removing the n elements from an array or list is log(n^2).
Maximum number of inversions possible for a list of size n could be generalized by an expression:So for an array of size 6 maximum possible inversions will equal 15.To achieve a complexity of n logn we could piggy back the inversion algorithm on merge sort.Here are the generalized steps:Split the array into twoCall the mergeSort routine. If the element in the left subarray is greater than the element in right sub array make inversionCount += leftSubArray.lengthThat's it!This is a simple example, I made using Javascript:
Implementation of counting inversions in an array with merge sort in Swift:Note that the number of swaps is incremented by (which is the relative length of the left side of the array minus the index of the current element in the left side) ... because that is the number of elements which the element in the right side of the array had to skip over (# of inversions) to become sorted.
This answer contains the results of the timeit tests produced by the code in my main answer. Please see that answer for details!
Use mergesort, in merge step incremeant counter if the number copied to output is from right array. 
I recently had to do this in R:
C code easy to understand:


Answer URL
https://docs.python.org/3/library/timeit.html
https://docs.python.org/3/library/timeit.html#timeit.Timer.repeat
