Natural Text
I'm looking for a more efficient and Pythonic way of using itertools' roundrobin recipe on the groups formed by itertools.groupby().Specifically, I have a list of URLs (not sorted), and want to re-order them so that the ordering of their result places the maximum "distance" (or diversification, maybe) between each unique netloc (host), as defined by the attribute from urllib.parse.  Reproducible example below.I'm currently using itertools.groupby() plus its roundrobin recipe, but because of the nature of groupby(),The returned group is itself an iterator that shares the underlying iterable with groupby(). Because the source is shared, when the groupby() object is advanced, the previous group is no longer visible. So, if that data is needed later, it should be stored as a list....this seems to necessitate forming an intermediate list out of each group.Sample data:Current solution (take 1 from each group, or skip the group if it is empty, until all groups raise StopIteration):The expected output for the sample is as follows:What is a more efficient way of going about this?
Not a huge improvement, but you could use itertools.zip_longest to achieve the same effect with a little tweak:The benefit is you don't have to define the roundrobin recipe.  The time saving is negligible however (timed for n=10000):I feel like there's another solution that could use collections.Counter or use sort(key=...) on the sorted(list), but I haven't cracked that case yet, feels like the time complexity might be more severe than your implementation since it might rely on more python code than compiled modules.  This is an interesting problem though, will probably revisit this later.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
