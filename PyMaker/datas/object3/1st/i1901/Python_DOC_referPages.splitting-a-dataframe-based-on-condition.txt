Natural Text
I am trying to split my dataframe into two based of medical_plan_id. If it is empty, into df1. If not empty into df2.The code below works, but if there are no empty fields, my code raises TypeError("invalid type comparison").How to handle such situation?My df_with_medicalplanid looks like below:
Use ==, not is, to test equalityLikewise, use != instead of is not for inequality.is has a special meaning in Python. It returns True if two variables point to the same object, while == checks if the objects referred to by the variables are equal. See also Is there a difference between == and is in Python?.Don't repeat mask calculationsThe Boolean masks you are creating are the most expensive part of your logic. It's also logic you want to avoid repeating manually as your first and second masks are inverses of each other. You can therefore use the bitwise inverse ~ ("tilde"), also accessible via operator.invert, to negate an existing mask.Empty strings are different to null valuesEquality versus empty strings can be tested via == '', but equality versus null values requires a specialized method: pd.Series.isnull. This is because null values are represented in NumPy arrays, which are used by Pandas, by np.nan, and np.nan != np.nan by design.If you want to replace empty strings with null values, you can do so:Conceptually, it makes sense for missing values to be null (np.nan) rather than empty strings. But the opposite of the above process, i.e. converting null values to empty strings, is also possible:If the difference matters, you need to know your data and apply the appropriate logic.Semi-final solutionAssuming you do indeed have null values, calculate a single Boolean mask and its inverse:Final solution: avoid extra variablesCreating additional variables is something, as a programmer, you should look to avoid. In this case, there's no need to create two new variables, you can use GroupBy with dict to give a dictionary of dataframes with False (== 0) and True (== 1) keys corresponding to your masks:Then dfs[0] represents df2 and dfs[1] represents df1 (see also this related answer). A variant of the above, you can forego dictionary construction and use Pandas GroupBy methods:ExamplePutting all the above in action:
Another variant is to unpack df.groupby, which returns an iterator with tuples (first item being the element of groupby and the second being the dataframe).Like this for instance:_ is in Python used to mark variables that are not interested to keep. I have separated the code to two lines for readability.Full exampleReturns:


Answer URL
https://docs.python.org/3/library/operator.html#operator.inv
