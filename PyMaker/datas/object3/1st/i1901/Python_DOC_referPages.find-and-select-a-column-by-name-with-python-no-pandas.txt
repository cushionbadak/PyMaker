Natural Text
I'm looking for a standard Python (no pandas, no numpy) solution to the following.I have some large csv files. Let's say:First, not all the files have the same headers and the columns are not necessarily in the same order. For example, the "Status" header may be "Status" or "Case_status" or "CASE", and the value of "Status" for an individual record may be "COMPLETE", "COMPLETE-WITHDRAWN", "INCOMPLETE", etc. What I'd like to do is filter the data by selecting only the data with a "Status" value of "COMPLETE" and THEN find (list) the top 10 States according to how many "COMPLETE" statuses each State has.I'm able to do this when I know the column numbers, and I found some help for filtering rows with lambda, but I'm having trouble finding a simple Python solution to filter columns by name.Simple solution for a .csv file when the names and order of columns are known:So the output looks like:But this will not help, since I have to first filter the columns by name and then select based on Status. Slightly more complete solution with attempt at filtering:But this isn't helpful for filtering columns by name, and I get a KeyError when I attempt to useThoughts? Thank you!
You can just use csv.DictReader to read in column names too. It'll read each row as a dict, keys would be column names, and values will be row values, so assuming that the column name is Status, your filter using column name would look like:For dealing with the multiple column names, if you know that your column name could include case or status etc, you can write a regex to find the column name.Disclaimer: This code isn't tested. I just wrote it in this editor.


Answer URL
https://docs.python.org/3/library/csv.html#csv.DictReader
https://docs.python.org/3/library/
