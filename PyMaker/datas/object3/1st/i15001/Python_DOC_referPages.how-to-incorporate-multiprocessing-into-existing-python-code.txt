Natural Text
I am having a serious problem wrapping my head around using multiprocessing in my existing python code. Below is my program gauss.py which essentially fits a Gaussian to data. What is the correct way to incorporate multiprocessing and run this script multiple times using different input files? Should I create a separate .py script that calls this script as a function? Or, do I include a main section underneath all of the existing code?Also, I am currently manually entering in the data input file in the command line when executing the script. I'm guessing that will need to be changed to some sort of queue format?
You could parallelize the processing inside loglike1.But it is better to run your script with MPI. For example, "mpirun -np 4" will run your script 4 times. Multinest realises it is in MPI mode and dispatches the likelihood calls. pymultines loads the multinest MPI library automatically if you have mpi4py installed.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor
