Natural Text
I am coding a small utility, on my Mac OsX Yosemite, that globs my file system using glob2 and testing my code with py.test.My system locale is en_gb, because this is what I usually speak, however, I also have quite a few files and folders with French and Japanese names.Now whenever I get a "French" string through glob2, like "/tmp/test/réc", the encoding of the e acute is \xcc\x81c. However I declared the encoding of my python file as utf-8 which gives me e acute as \xc3\xa9c. So obviously then my tests go funny because they do not match the e acutes.How do I find the encoding my system has used to encode my e acutes? Is there any alternative but using a chardet-like library?ThanksAddendumthe test that fails is: scope_test.pyThe definition of the Scope instance is: scope.py
They are both UTF-8, just two ways of representing the character.So when OSX writes the file/directory, it's writing "e" + "combining acute accent", while you're expecting it to be a literal "é".To fix this you need to compare the normalized unicode strings instead of the byte strings (or even the decoded unicode strings). The unicodedata.normalize function in python's standard library can do this:


Answer URL
https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize
