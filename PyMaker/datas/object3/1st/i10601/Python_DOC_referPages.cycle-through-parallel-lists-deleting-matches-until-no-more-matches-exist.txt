Natural Text
I have 3 parallel lists representing a 3-tuple (date, description, amount), and 3 new lists that I need to merge without creating duplicate entries. Yes, the lists have overlapping entries, however these duplicate entries are not grouped together (instead of all of the duplicates being 0 through x and all of the new entries being x through the end).The problem I'm having is iterating the correct number of times to ensure all of the duplicates are caught. Instead, my code moves on with duplicates remaining.I don't know if it's a coincidence, but I'm currently getting exactly one half of the new items deleted and the other half remain. In reality, there should be far less than that remaining. That makes me think the for x in dates: is not iterating the correct number of times.
I suggest a different approach:  Instead of trying to remove items from a list (or worse, several parallel lists), run through the input and yield only the data that passes your test --- in this case, data you haven't seen before.  This is much easier with a single stream of input.Your lists of data are crying out to be made into objects, since each piece (like the date) is meaningless without the other two... at least for your current purpose.  Below, I start by combining each triplet into an instance of Record, a collections.namedtuple.  They're great for this kind of use-once-and-throw-away work.In the program below, build_records creates Record objects from your three input lists.  dedup_records merges multiple streams of Record objects, using unique to filter out the duplicates.  Keeping each function small (most of the main function is test data) makes each step easy to test.This reduces the 16 input Records to 11:Note that the yield from ... syntax requires Python 3.3 or greater.


Answer URL
https://docs.python.org/3/library/collections.html#collections.namedtuple
https://docs.python.org/3/library/__main__.html
https://docs.python.org/3/tutorial/modules.html#executing-modules-as-scripts
