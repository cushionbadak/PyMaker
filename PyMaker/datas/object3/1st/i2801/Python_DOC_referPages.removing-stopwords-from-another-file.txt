Natural Text
I am new to Python.Over here, I am trying to scan through a file helpme.txt, and remove stop words that are in the stopwords1.txt file. I am tasked to use only 1 parameter. I have came up with the following but I kept getting the error: ValueError: list.remove(x): x not in list.Any kind souls please help me out.  
There are so many things that you can improve in your code...Open the file correctly and use it as an iterator:For each line in the file, break that line into words. Check if the words is not in stopwords, and combine the survivors into another line. Add the line to the list of the processed line. Beware that if you have any words followed by punctuation, then they will not be processed. Use NLTK to handle punctuation.The latter five lines could be written as a one-liner, but you don't have to go that far. Do not forget to return the list of clean lines!
in your code 'word' returns a list. your are trying to remove  an item not there in 'new'. so it is throwing error. replace your for loop with this
Try printing the stop variable in the remove_stop function it should look something like this [['stop word 1\n', 'stop word 2\n'....]]. (readlines doesn't remove the carriage return) As such your for loop will only have one element being the list of stop words not the stop words them selves (same for new).This can be solved as such, remove the new and stop variables and replace them as such.stop = stopwordsnew = open("helpme.txt","r").read().split('\n')Also you will need to change thestop to open("stopwords1.txt", "r").read().split('\n') to remove any carriage return, or you can remove them after reading the file using readlines.Finally you will need to have a nested loop because you want to remove stop words from each line as such your loop will be something like this.
Nice effort. When you're stuck like this, it's a great time to exercise basic debugging and design principles.Scale down complexity: approach your code in small chunks and make sure each component is working before increasing complexity. Removing stop words and reading input lists are totally different tasks and can be broken down and debugged in discrete chunks. In terms of input, are the files being read as you planned? Instead of lists of words, you're getting a list of strings nested in a list with the file contents inside of it, which seems unintended. printing your new list reveals [["stack overflow is awesome, don't you think?\n"]]. Removing the .append and doing a direct assignment on new will ensure you're only dealing with a 1d list of strings.At this point, strings need breaking down into words. This can be a complex pattern matching task depending on what you define as a word. For now, I recommend keeping it simple and using split() to break on whitespace, but know that you may have dangling commas, periods and quotation marks that will impact your output.After settling your input routine, matters should be much clearer inside your remove_stop function, which was previously broken because it was crashing while attempting to remove strings from a list that didn't contain anything other than lists. An approach to this function I prefer is using a list comprehension for terse but readable syntax and a set for fast, almost instantaneous lookups. remove, for contrast, is a slow approach that looks through every element of the input list one at a time to find the item to remove on every iteration.Putting it all together, here's one approach:Given sample texts:helpme.txt:and stopwords1.txt:Here's the output:
This should work:  I know it is complicated and not very helpful for you at the moment, however you can use the tips about debugging and design that other people here suggested to get to a similar answer yourself and use the code above as a reference.


Answer URL
https://docs.python.org/3/tutorial/datastructures.html#sets
