Natural Text
Having imported math and decimal in 3. I'm OK with the first output but then slightly flummoxed by the really confused by... Why isn't the output precision set to 2 for future Decimal Out[] lines after the prec=2?  I thought Decimal() casts the input whether float string or int as a decimal with the precision set?
As the docs say about the Decimal() constructor:The context precision does not affect how many digits are stored. That is determined exclusively by the number of digits in value. For example, Decimal('3.00000') records all five zeros even if the context precision is only three.One way to shed the excess precision is to apply the unary + operator to the result:Another is to use a context object's .create_decimal() method:As create_decimal's docs say:Unlike the Decimal constructor, the context precision, rounding method, flags, and traps are applied to the conversion.
From the documentation:The significance of a new Decimal is determined solely by the number of digits input. Context precision and rounding only come into play during arithmetic operations.Since you're not doing any arithmetic on Decimal(str(sqrt(2))), it's not using the precision you set. You can fix this by adding a trivial arithmetic operation.
Regarding part 2 str(v) output of a float v shows the shortest representation for which v == float(str(v)) is true.Python docs say:Many users are not aware of the approximation because of the way values are displayed. Python only prints a decimal approximation to the true decimal value of the binary approximation stored by the machine. On most machines, if Python were to print the true decimal value of the binary approximation stored for 0.1, it would have to displayThat is more digits than most people find useful, so Python keeps the number of digits manageable by displaying a rounded value insteadJust remember, even though the printed result looks like the exact value of 1/10, the actual stored value is the nearest representable binary fraction.Regarding part 3, Python docs say:The context precision does not affect how many digits are stored. That is determined exclusively by the number of digits in value. For example, Decimal('3.00000') records all five zeros even if the context precision is only three


Answer URL
https://docs.python.org/3/library/decimal.html
https://docs.python.org/3/tutorial/floatingpoint.html
