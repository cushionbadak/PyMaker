Natural Text
Say, I have a source file encoded in utf8, when python interpreter loads that source file, will it convert file content to unicode in memory and then try to evaluate source code in unicode?If I have a string with non ASCII char in it, likeastring = '中文'and the file is encoded in gbk.Running that file with python 2, I found that string actually is still in raw gbk bytes. So I dboubt, python 2 interpret does not convert source code to unicode. Beacause if so, the string content will be in unicode(I heard it is actually UTF16)Is that right? And if so, how about python 3 interpreter? Does it convert source code to unicode format?Acutally, I know how to define unicode and raw string in both Python2 and 3. I'm just curious about one detail when the interpreter loads source code.  Will it convert the WHOLE raw source code (encoded bytes) to unicode at very beginning and then try to interpret unicode format source code piece by piece? Or instead, it just loads raw source piece by piece, and only decodes what it think should. For example,  when it hits the statement u'中文'  , OK, decode to unicode. While it hits statment  b'中文', OK, no need to decode.  Which way the interpreter will go?
If your source file is encoded with GBK, put this line at the top of the file (first or second line):This is required for both Python 2 and 3.If you omit this encoding declaration, the interpreter will assume ASCII in the case of Python 2, and UTF-8 for Python 3.The encoding declaration controls how the interpreter reads the bytes of the source file. This is mainly relevant for string literals (like in your example), but theoretically also applies to comments and even identifiers (it's probably not a good idea to use non-ASCII in identifiers, though).As for the question whether you get byte strings or unicode strings: this depends on the syntax, not on the choice and declaration of encoding.As pointed out in Ignacio's answer, if you want to have unicode strings in Python 2, you need to use the u'...' notation.In Python 3, the u prefix is optional.So, with a correct encoding declaration in the file header, it is sufficient to write astring = '中文' to get a correct unicode string in Python 3.UpdateBy comment, the OP asks about the interpretation of b'中文'.In Python 3, this isn't allowed (byte strings can only contain ASCII characters), but you can test this yourself in Python 2.x:This will produce:The first line reflects the actual bytes contained in the source file (if you saved it with GBK, of course).So there seems to be no decoding happening for b'中文'.However, I don't know how the interpreter internally represents the source code with respect to encoding (that seems to be your question).This is implementation-dependent anyway, so the answer might even be different for cPython, Jython, IronPython etc.
So I dboubt, python 2 interpret does not convert source code to unicode.It never does. If you want to use Unicode rather than bytes then you need to use a unicode instead.
Python source is only plain ASCII, meaning that the actual encoding does not matter except for litteral strings, be them unicode strings or byte strings. Identifiers can use non ascii characters (IMHO it would be a very bad practice), but their meaning is normally internal to the Python interpreter, so the way it reads them is not really importantByte strings are always left unchanged. That means that normal strings in Python 2 and byte litteral strings in Python 3 are never converted.Unicode strings are always converted:if the special string coding: charset_name exists in a comment on first or second line, the original byte string is converted as it would be with decode(charset_name)if not encoding is specified, Python 2 will assume ASCII and Python 3 will assume utf8


Answer URL
https://docs.python.org/3/howto/unicode.html#unicode-literals-in-python-source-code
