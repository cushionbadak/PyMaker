Natural Text
It all began last night when I was making a script that required 8 or so packages including pygame.mixer which on my computer importing this takes a few seconds.  This meant that before the script even started I had to wait 10 or so seconds for all the imports to load.  Because I want the script to obviously be as fast as possible could I start running the script while getting the imports with something like this:So my question is:Is this considered bad practice and will it cause problems?If so are there alternatives I could use? Or is it OK to do this?
If you are using CPython, this might not yield as much improvement as you'd expect.CPython has a Global Interpreter Lock ("GIL") that ensures that only one thread at a time can be executing Python bytecode.So whenever the import thread is executing Python code, the other thread is not running. The GIL is released by a thread when it is e.g. waiting on I/O. So there will be some time savings because of that.There is a difference of opinion as to whether tkinter is truly thread-safe. It is still considered wise to run the tkinter main loop in the original thread, and to not invoke tkinter calls from other threads, because that can lead to crashes.The GIL also can cause problems for GUI programs. If you are using a second thread for a long-running calculation, the user interface might become less responsive. There are at least two possible solutions. The first one is to split the long-running calculation up into small pieces which are each executed by a after method. The second is to run the calculation in a different process.Follow-up questions from the comments:is there anything else to speed up execution time?The first thing you must to do is measure; what exactly causes the problem. Then you can look into the problem areas and try to improve them.For example module load times. Run your app under a profiler to see how long the module loads take and why.If pygame.mixer takes too long to load, you could use your platform's native mixer. UNIX-like operating systems generally have a /dev/mixer device, while ms-windows has different API's for it. Using those definitely won't take 10 seconds. There is a cost associated with this: you will loose portability between operating systems.What are the alternativesUsing multiple cores is a usual tactic to try and speed things up. Currently on CPython the only general way get code to run in parallel on multiple cores is with multiprocessing or concurrent.futures.However it depends on the nature of your problem if this tactic can work.If your problem involves doing the same calculations over a huge set of data, that is relatively easy to parallelize. In that case you can expect a maximal speedup roughly equivalent to the numbers of cores you use.It could be that your problem consists of multiple steps, each of which depends on the result of a previous step. Such problems are serial in nature and are much harder to execute in parallel.Other ways to possible speed things up could be to use another Python implementation like Pypy. Or you could use cython together with type hints to convert performance-critical parts to compiled C code.


Answer URL
https://docs.python.org/3/whatsnew/3.3.html#a-finer-grained-import-lock
