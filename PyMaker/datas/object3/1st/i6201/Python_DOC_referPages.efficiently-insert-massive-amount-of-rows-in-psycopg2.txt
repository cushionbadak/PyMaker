Natural Text
I need to efficiently insert about 500k (give or take 100k) rows of data into my PostgreSQL database. After a generous amount of google-ing, I've gotten to this solution, averaging about 150 (wall-clock) seconds.Is there a faster way?
Based on the answers given here, COPY is the fastest method. COPY reads from a file or file-like object. Since memory I/O is many orders of magnitude faster than disk I/O, it is faster to write the data to a StringIO file-like object than to write to an actual file.The psycopg docs show an example of calling copy_from with a  StringIO as input.Therefore, you could use something like:
I don't know whether .execute_batch can accept generator, but can u try something like:def db_insert_spectrum(curs, visual_data, recording_id):    sql = """        INSERT INTO spectrums (row, col, value, recording_id)        VALUES %s    """    data_gen =  ((rIdx, cIdx, value, recording_id) for rIdx, cData in enumerate(visual_data)                                                    for cIdx, value in enumerate(cData))    psycopg2.extras.execute_batch(curs, sql, data_gen, page_size=1000)It might be faster.


Answer URL
https://docs.python.org/3/library/io.html#io.StringIO
