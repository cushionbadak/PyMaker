Natural Text
Let me prefice this by saying: I am by no means a Windows programmer. Please help me by correcting any misunderstanding I may have.My understanding is that Windows has both (legacy) single-byte string interfaces and modernized Unicode interfaces.My goal is to closely examine the cp1252 as implemented in the Windows kernel. I'll start with Windows XP, but I plan to check as many versions as I can.I'm going to make the output of such a program similar in format to: https://encoding.spec.whatwg.org/index-windows-1252.txtMy question is primarily: what Windows API functions would I use to accomplish the above task? I think it's mbstowcs_s.Secondarily: Must I write C in order to examine the relevant interfaces? If so what compiler would I use? I think Visual Studio Express 2010 is a good match, but I can't find any (legitimate) place to download it.For those that must know the X to my Y, there are two competing standards and implementations of cp1252. They differ only slightly but they do differ, and it's significant to me.The WHATWG specifies, and all browsers implement this standard:https://encoding.spec.whatwg.org/index-windows-1252.txtMicrosoft specifies, and python implements this standard:http://unicode.org/Public/MAPPINGS/VENDORS/MICSFT/WINDOWS/CP1252.TXTThe difference is in the five non-printable characters. In the windows spec they're entirely undefined, so these bytes cannot be round-tripped through cp1252. In the WHATWG spec (and all browsers), these bytes map to non-printing characters of the same value, as in latin1, meaning that those bytes can round-trip successfully through cp1252.I strongly suspect that Microsoft's implementation actually matches the WHATWG spec and browsers' implementations, rather than the spec they've published. This is what I'm trying to prove/disprove above.
Using @abernert's help, I came up with this. In conclusion, Microsoft's spec doesn't match their implementation, as I suspected:Output: (tested on Windows XP, Vista, 7, 8.1)Compare this with the spec that Microsoft registered with unicode.org:It's clear to me that the slots labeled UNDEFINED (bytes 81 8D 8F 90 and 9D) are not undefined, not errors, but decode to unprintable characters of equal ordinal, as they do in the WHATWG spec, below:
To answer your X question instead of your Y question:You can't really ask how "Windows" handles what it calls "ANSI strings", because there are multiple different levels that handle them independently. It's a pretty good bet that they all do so in ways that are compatible… but your whole point is to avoid that pretty good bet and examine the truth directly.I think you can safely assume that MultiByteToWideChar will give you the same results as calling SpamA vs. SpamW functions in the Win32 API. (If you can't even assume that, I think you'd really need to test every single function pair in the API to make sure they all have the same results…) You can pass CP_1252 directly, but I think passing CP_OEMCP on a system configured for 1252 is a better test of what you're asking. Or just do both.It's plausible that MSVCRT (which handles providing an 8-bit-string-based standard C interface and large chunks of POSIX to portable programs, including CPython) has its own conversions. To verify that, call mbstowcs or one of its relatives.I'm pretty sure the Win32 system layer handles ANSI strings the same way as the user layer, but you may want to search for an undocumented ZwMultiByteToWideChar or similar. And I think the kernel just doesn't handle ANSI strings anywhere—e.g., IIRC, when you write a filesystem driver, the only pathname interfaces are wide… but you may want to download the DDK and make sure I'm right about that.I think the Explorer GUI shell relies on the Win32 layer to handle everything, and doesn't touch ANSI strings anywhere. The cmd.exe command-line shell only deals in Unicode (except when running DOS programs on Win9x)—but it's also a terminal, and as a terminal, it does actually deal with both ANSI and Unicode strings and map them. In particular, you can send either ANSI or Unicode console output and read either ANSI or Unicode console input. That's probably done via MultiByteToWideChar and friends, but I couldn't promise that. I think MSVCRT's stdin/out and wstdin/out and its DOS-conio-style getch/etc. and getwch/etc. functions just access these respective console APIs instead of translating in MSVCRT, but if you don't trust that, you can go around it and either get the native console streams or just call the Console I/O functions directly.So, how do you write a test program for these things, without finding multiple out-of-support versions of Microsoft C++ compiler and an SDK for each OS? (And, even if you did, how could you be sure that later versions of the WinXP SDK weren't hiding problems from you that existed in XP itself?)The answer is to just LoadLibrary and GetProcAddress the functions out of their respective DLLs at runtime. Which you can do from a program you just compile for one version of Windows.Or, even more simply, just use Python, and use its ctypes module to access the functions out of the DLLs. Just make sure you explicitly create and pass LPSTR and LPWSTR buffers instead of passing str/bytes/unicode objects anywhere.So ultimately, I think all you need is a 20-line Python script that uses ctypes to call MultiByteToWideChar out of KERNEL32.DLL or mbstowcs out of MSVCRT32.DLL or both.
Your question doesn't really make any sense. You want to examine "the encoding" used by each version of Windows from 95 through 10.But none of those versions of Windows have "an encoding". Every single one of them is configurable in the same way: it has a default system encoding, which is pre-configured by Microsoft, and a current user encoding, which is set by Microsoft or the system OEM but which the user can change. So, your test won't depend on Windows 95 vs. Windows 7, it'll depend on US Windows 95 from Microsoft with default settings vs. ES Windows 95 from Microsoft with default settings vs. US Windows 95 from HP with default settings vs. US Windows 95 from Microsoft with each of the 238 possible choices in the Control Panel etc.Also, to generate the kind of file you're trying to generate, you don't need to touch any Win32 APIs. All you need to do is call any function that uses the configured system locale's character set to decode single-byte/multi-byte text to UTF-16/Unicode text. For example, from C, you can call one of the  mbcstowcs family from the MSVCRT; from Python, you can call the decode method on a str (Python 2)/bytes (Python 3) object with sys.getdefaultencoding(); etc.If you really want to use the system interfaces to test the same information, you can… but then you'll run into limitations of most of those interfaces. For example, you can CreateFileA to create a new file with an 8-bit name, then try to CreateFileW to open the same file with the corresponding 16-bit name and verify that it works… but then you can't test any of the illegal-for-filenames characters.Finally, Microsoft has provided free C compilers for most if not all of those platforms, but some of them are long out of service, so I don't know if you can (at least legally) get them or not. But you can always use MinGW to set up a gcc-based toolchain. I don't know if the current versions still work on Win95, but if not, the old versions should still be available.


Answer URL
https://docs.python.org/3/library/ctypes.html
