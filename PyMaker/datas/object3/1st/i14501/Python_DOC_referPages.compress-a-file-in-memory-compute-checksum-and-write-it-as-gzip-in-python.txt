Natural Text
I want to compress files and compute the checksum of the compressed file using python. My first naive attempt was to use 2 functions:However, it leads to the compressed file being written and then re-read. With many files (> 10 000), each several MB when compressed, in a NFS mounted drive, it is slow.How can I compress the file in a buffer and then compute the checksum from this buffer before writing the output file?The file are not that big so I can afford to store everything in memory. However, a nice incremental version could be nice too.The last requirement is that it should work with multiprocessing (in order to compress several files in parallel).I have tried to use zlib.compress but the returned string miss the header of a gzip file.Edit: following @abarnert sggestion, I used python3 gzip.compress:This produce a correct gzip file but the output is different at each run (the md5 is different):The gzip program doesn't have this problem:I guess it's because the gzip module use the current time by default when creating a file (the gzip program use the modification of the input file I guess). There is no way to change that with gzip.compress.I was thinking to create a gzip.GzipFile in read/write mode, controlling the mtime but there is no such mode for gzip.GzipFile.Inspired by @zwol suggestion I wrote the following function which correctly sets the filename and the OS (Unix) in the header:The output is the same at different run. Moreover the output of file is the same than gzip:However, md5 is different:gzip -l is also different:I guess it's because the gzip program and the python gzip module (which is based on the C library zlib) have a slightly different algorithm.
Wrap a gzip.GzipFile object around an io.BytesIO object.  (In Python 2, use cStringIO.StringIO instead.)  After you close the GzipFile, you can retrieve the compressed data from the BytesIO object (using getvalue), hash it, and write it out to a real file.Incidentally, you really shouldn't be using MD5 at all anymore.
I have tried to use zlib.compress but the returned string miss the header of a gzip file.Of course. That's the whole difference between the zlib module and the gzip module; zlib just deals with zlib-deflate compression without gzip headers, gzip deals with zlib-deflate data with gzip headers.So, just call gzip.compress instead, and the code you wrote but didn't show us should just work.As a side note:You almost certainly want to open the file in 'rb' mode here. You don't want to convert '\r\n' into '\n' (if on Windows), or decode the binary data as sys.getdefaultencoding() text (if on Python 3), so open it in binary mode.Another side note:Don't use line-based APIs on binary files. Instead of this:â€¦ do this:Or, if the files are too large to read into memory all at once:And one last point:With many files (> 10 000), each several MB when compressed, in a NFS mounted drive, it is slow.Does your system not have a tmp directory mounted on a faster drive?In most cases, you don't need a real file. Either there's a string-based API (zlib.compress, gzip.compress, json.dumps, etc.), or the file-based API only requires a file-like object, like a BytesIO.But when you do need a real temporary file, with a real file descriptor and everything, you almost always want to create it in the temporary directory.* In Python, you do this with the tempfile module. For example:If you need an actual filename, rather than a file object, you can use f_in.name.* The one exception is when you only want the temporary file to eventually rename it to a permanent location. In that case, of course, you usually want the temporary file to be in the same directory as the permanent location. But you can do that with tempfile just as easily. Just remember to pass delete=False.


Answer URL
https://docs.python.org/3/library/gzip.html#gzip.GzipFile
https://docs.python.org/3/library/io.html#io.BytesIO
https://docs.python.org/3/library/zlib.html
https://docs.python.org/3/library/gzip.html
https://docs.python.org/3/library/gzip.html#gzip.compress
https://docs.python.org/3/library/tempfile.html
https://docs.python.org/3/library/zlib.html#zlib.compress
