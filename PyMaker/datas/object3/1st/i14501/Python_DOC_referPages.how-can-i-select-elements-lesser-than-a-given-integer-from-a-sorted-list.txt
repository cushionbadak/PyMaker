Natural Text
I have array of primes e.g. between integers 0 to 1000I get inputWhat is the most efficient way to slice array to new array where last element of array will be less than n?
You can make use of the fact that primes is already sorted, with bisect, like thisbisect does binary search on the input list and returns the index of the element which is lesser than n.
You have a list, not an array. If you actually need to slice the list and build a new list, that's going to take linear time, no matter how you do it. The answer by thefourtheye is probably the best you're going to do:If you have NumPy, it knows how to create views that look like slices, but actually reference rather than copying the data. In fact, if primes were an ndarray, you could use exactly the same code as thefourtheye's answer and it would be O(log N).If you only need to iterate the "array" once rather than use it as a list, you can use a lazy iterator:Now the up-front time cost is 0; but there's a comparison attached to each value at the time you consume it. Of course it's more space-efficient than anything else.Realistically, "most efficient" here is unlikely to matter, and if it does matter you'll need to measure it, and if you're not using NumPy or running your code under PyPy you almost certainly want to do one of those before any micro-optimizations…
You didn't explain why you're asking for "the most efficient way", or what you mean by that (time? space? something else?), and I highly doubt this really is a performance bottleneck worth optimizing anywhere, but if it is:You've only got 168 elements. And you're not going to have lots of similar lists, so space is unlikely to be relevant. Meanwhile, for a linear algorithm over N=168 to matter, you must be calling it zillions of times—but there are only 1000 possible values. So, just pre-create a table:Now, to get the primes up to n:That's constant time. Of course the setup takes O(N^2) time, but that's nothing, since it only happens once vs. saving O(N) work zillions of times. And it takes O(N^2) space, but really that's just a constant 15K-ish pointers, which you can almost certainly afford.
If you don't need the full prime list again, truncating the primes may be the fastest approach:But as always with performance, measure it if you care.


Answer URL
https://docs.python.org/3/library/bisect.html#bisect.bisect
