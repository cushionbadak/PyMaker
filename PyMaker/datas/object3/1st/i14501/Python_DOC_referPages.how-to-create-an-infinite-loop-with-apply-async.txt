Natural Text
I havea pool of processes with apply_async in which the different processes take different times to provide output. Once one process is finished I do some calculations with their output. After I want to launch another process. In this way I want to create an infinite loop which launches processes, reads the output of the recently finished process, does some calculations and relaunches another process.So far I have been able to do what I want except that the main process gets stuck in the get() function. This because I don't know which process terminated and hence which entry of results I should do get().Some attempt code:And the output is:     [0 0]    [1 1]    [2 2]    [3 3]    [4 4]    [5 5]    [6 6]    [7 7]    [0 0]    [1 1]Instead of the odd numbers first and then the even ones (since these ones have a sleep).Any suggestions?Thank you very much for your fast reply abarnert. In reality I want to keep an infinite loop after the processes are completed (I need their results to be able to enter the loop). Q1 - If I create a pool with 30 works can I submit more than 30 processes? Will the computer wait for one to finish to put another to work? Q2 - In your code there is a callback function. However, the code that the I need to run when one worker finishes has to be in the main process since I have to update variables which will be sent to the new processes that I create.Q3 - The code that the main process does takes, let say 10% of the time that the processes need to realize their tasks. So is it a good approach to have the main process to realize some calculations and then launch new processes? Q4 - Right now if I Ctrl+C the code only terminates when all the processes are over. What can I do to be able to terminate the code as soon as I do Ctrl+C? And finally, after my comment do you think futures is still the way to go?Some pseudo-code for what I need:
The problem is that you're waiting for the results in the order the jobs were issued, rather than the order they finished. So, if job 1 finishes before job 0, it doesn't matter; you're still waiting on job 0.Fundamentally, the problem is that apply_async returns AsyncResult objects, which are not composable futures, but you want to use them as if they were. You can't do that. There's no way to wait on a bunch of AsyncResults in parallel until one of them finishes. If you want that, use concurrent.futures insteadâ€”or, for Python 2.7, the backport on PyPI, futures; then you can call wait on any sequence of futures, or iterate over as_completed.You can simulate this on top of AsyncResult by using callbacks instead of wait, but that's making your life harder than it needs to be, because you have to turn the flow of control inside-out. Something like:


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
