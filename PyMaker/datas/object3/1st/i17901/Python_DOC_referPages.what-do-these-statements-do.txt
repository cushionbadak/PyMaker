Natural Text
I am pondering over Request/Response methods of Scrapy.Can somebody explain me what the below statements (the request part) actually do?:thanks
When you say "I am pondering over Request/Response methods of Scrapy", I think you're a little confused. Request and Response are classes, not methods.And, while these classes of course do have methods, you don't ask about any of them, you just ask about one of the data attributes, meta.Or, if you meant methods in the HTTP sense, well, a Request defaults to GET, but you can specify a different one with the method= argument; what else is there to know?As the documentation for Request says:A Request object represents an HTTP request, which is usually generated in the Spider and executed by the Downloader, and thus generating a Response.In other words, you usually don't want to create one yourself. You give the Spider a list of URLs to start with, and it makes a Request for each URL on the list, and for each additional URL that it discovers while scraping.You may sometimes need to look at the Request that goes with a Response. And you may occasionally need to customize the creation of Requests inside a complex Spider. But you will rarely need to craft them manually.Meanwhile, you seem to have confused yourself with your naming. You've got a variable named start_urls, but it's not a list of URLs, it's a single URL. Which, if you actually used it as a start_urls in the normal way, would be treated as a list of single characters. But fortunately, you're not doing that; you're passing start_urls as the url argument to a Request object—and, since it happens to be just a single URL, your two confusions cancel out and you create a valid Request object.You could then feed this Request object to a Downloader manually to get back a Response object. But there's no good reason to do that. If you want to download files manually instead of spidering them, just use the stdlib module urllib2/urllib.request, or a third-party library specifically designed for making manual downloading easy, like requests, not a spidering library.Meanwhile, depth= request.meta['depth'] will just return a KeyError. As the meta docs explain, it's just a dictionary, which is empty for new Requests (unless you pass a meta= argument to the constructor, which you didn't), and:… is usually populated by different Scrapy components (extensions, middlewares, etc). So the data contained in this dict depends on the extensions you have enabled.Since you haven't actually done anything with the Request after creation, it doesn't matter what extensions you have enabled; it's going to be empty.


Answer URL
