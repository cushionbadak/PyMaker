Natural Text
I want to print some floating point numbers so that they're always written in decimal form (e.g. 12345000000000000000000.0 or 0.000000000000012345, not in scientific notation, yet I'd want to keep the 15.7 decimal digits of precision and no more.It is well-known that the repr of a float is written in scientific notation if the exponent is greater than 15, or less than -4:If str is used, the resulting string again is in scientific notation:It has been suggested that I can use format with f flag and sufficient precision to get rid of the scientific notation:It works for that number, though it has some extra trailing zeroes. But then the same format fails for .1, which gives decimal digits beyond the actual machine precision of float:And if my number is 4.5678e-20, using .20f would still lose relative precision:Thus these approaches do not match my requirements.This leads to the question: what is the easiest and also well-performing way to print arbitrary floating point number in decimal format, having the same digits as in repr(n) (or str(n) on Python 3), but always using the decimal format, not the scientific notation.That is, a function or operation that for example converts the float value 0.00000005 to string '0.00000005'; 0.1 to '0.1'; 420000000000000000.0 to '420000000000000000.0' or 420000000000000000 and formats the float value -4.5678e-5 as '-0.000045678'.After the bounty period: It seems that there are at least 2 viable approaches, as Karin demonstrated that using string manipulation one can achieve significant speed boost compared to my initial algorithm on Python 2.Thus,If performance is important and Python 2 compatibility is required; or if the decimal module cannot be used for some reason, then Karin's approach using string manipulation is the way to do it.On Python 3, my somewhat shorter code will also be faster.Since I am primarily developing on Python 3, I will accept my own answer, and shall award Karin the bounty.
Unfortunately it seems that not even the new-style formatting with float.__format__ supports this. The default formatting of floats is the same as with repr; and with f flag there are 6 fractional digits by default:However there is a hack to get the desired result - not the fastest one, but relatively simple:first the float is converted to a string using str() or repr()then a new Decimal instance is created from that string.Decimal.__format__ supports f flag which gives the desired result, and, unlike floats it prints the actual precision instead of default precision.Thus we can make a simple utility function float_to_str:Care must be taken to not use the global decimal context, so a new context is constructed for this function. This is the fastest way; another way would be to use decimal.local_context but it would be slower, creating a new thread-local context and a context manager for each conversion.This function now returns the string with all possible digits from mantissa, rounded to the shortest equivalent representation:The last result is rounded at the last digitAs @Karin noted, float_to_str(420000000000000000.0) does not strictly match the format expected; it returns 420000000000000000 without trailing .0.
If you are satisfied with the precision in scientific notation, then could we just take a simple string manipulation approach? Maybe it's not terribly clever, but it seems to work (passes all of the use cases you've presented), and I think it's fairly understandable:Performance:I was worried this approach may be too slow, so I ran timeit and compared with the OP's solution of decimal contexts. It appears the string manipulation is actually quite a bit faster. Edit: It appears to only be much faster in Python 2. In Python 3, the results were similar, but with the decimal approach slightly faster.Result:Python 2: using ctx.create_decimal(): 2.43655490875Python 2: using string manipulation: 0.305557966232Python 3: using ctx.create_decimal(): 0.19519368198234588Python 3: using string manipulation: 0.2661344590014778Here is the timing code:
If you are ready to lose your precision arbitrary by calling str() on the float number, then it's the way to go:It doesn't include global variables and allows you to choose the precision yourself. Decimal precision 100 is chosen as an upper bound for str(float) length. The actual supremum is much lower. The or '0' part is for the situation with small numbers and zero precision.Note that it still has its consequences:Otherwise, if the precision is important, format is just fine:It doesn't miss the precision being lost while calling str(f).The orAnyway, maximum decimal places are limited, since the float type itself has its limits and cannot express really long floats:Also, whole numbers are being formatted as-is.
As of NumPy 1.14.0, you can just use numpy.format_float_positional. For example, running against the inputs from your question:numpy.format_float_positional uses the Dragon4 algorithm to produce the shortest decimal representation in positional format that round-trips back to the original float input. There's also numpy.format_float_scientific for scientific notation, and both functions offer optional arguments to customize things like rounding and trimming of zeros.
Interesting question, to add a little bit more of content to the question, here's a litte test comparing @Antti Haapala and @Harold solutions outputs:Neither of them gives "consistent" results for all cases.With Anti's you'll see strings like '-000' or '000'With Harolds's you'll see strings like ''I'd prefer consistency even if I'm sacrificing a little bit of speed. Depends which tradeoffs you want to assume for your use-case.
I think rstrip can get the job done.Let me know if that works for you.


Answer URL
https://docs.python.org/3/library/decimal.html#decimal.Decimal
https://docs.python.org/3/whatsnew/3.3.html#decimal
