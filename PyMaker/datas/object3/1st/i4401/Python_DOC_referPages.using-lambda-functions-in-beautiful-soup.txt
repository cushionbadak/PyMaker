Natural Text
Trying to match links that contain certain texts. I'm doingBut that throws a TypeError: argument of type 'NoneType' is not iterable.The correct way of doing it is apparantlyWhy is the additional x and necessary here?
There's a simple reason: One of the <a> tags in your HTML has no href property.Here's a minimal example that reproduces the exception:Now if we add a href property, the exception disappears:What's happening is that BeautifulSoup is trying to access the <a> tag's href property, and that returns None when the property doesn't exist:This is why it's necessary to allow None values in your lambda. Since None is a falsy value, the code x and ... prevents the right side of the and statement from being executed when x is None, as you can see here:This is called short-circuiting.That said, x and ... checks the truthiness of x, and None is not the only value that's considered falsy. So it would be more correct to compare x to None like so:
The additional x avoids the problem that you had, i.e TypeError: argument of type 'NoneType'. Try calling the lambda function with None as the argument:The first x in x and ".org" in x tests whether x is "truthy". If it is the rest of the expression is evaluated. If it is not "truthy", e.g. it is None, then the second part of the and expression is short circuited and not executed. This avoids attempting to perform the in operation, thereby avoiding the problem.
The problem is that an <a ...> tag may have no href=... part and in this case you get a None (that cannot be used with the in operator).


Answer URL
https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not
