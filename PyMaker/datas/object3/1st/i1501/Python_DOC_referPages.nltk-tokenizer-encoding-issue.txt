Natural Text
After tokenizing, my sentence contains many weird characters. How can I remove them?This is my code:The print(line) prints a line of a txt. And print(sentences) prints the tokenized sentences in the line.But sometimes the sentences contains weird characters after nltk's processing.Like above example, where is the \xa0 and \xa0T from?
Output:Reference: unicodedata.normalize()


Answer URL
https://docs.python.org/3/library/unicodedata.html#unicodedata.normalize
