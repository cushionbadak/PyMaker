Natural Text
I have a csv file containing thousands of tweets. Lets say the data is as follows:as you can see, the data contains tweet_id and the hashtags in each tweet. What I want to do is to go to all the rows, and at last give me something like value count:Considering that the csv file contains 1 million rows (1 million tweets), what is the best way to do this?
Using np.unique Even the problem look different , but still is related unnesting problem 
One alternative with np.hstack and convert to pd.Series then use value_counts.
Counter + chainPandas methods aren't designed for series of lists. No vectorised approach exists. One way is to use collections.Counter from the standard library:Setup
Sounds like you want something like collections.Counter, which you might use like this...which gives you,Edit:  I think jpp's answer will be quite a bit faster.  If time really is a constraint, I would avoid reading the data into a DataFrame in the first place.  I don't know what the raw csv file looks like, but reading it as a text file by lines, ignoring the first token, and feeding the rest into a Counter may end up being quite a bit faster.  
So all the answers above were helpful, but didn't actually work! The problem with my data is: 1)the value of 'hashtags' filed for some tweets are nan or []. 2)The value of 'hashtags' field in the dataframe is one string! the answers above assumed that the values of the hashtags are lists of hashtag, e.g. ['trump', 'clinton'], while it actually is only an str: '[trump, clinton]'. So I added some lines to @jpp 's answer:


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
https://docs.python.org/3/library/itertools.html#itertools.chain.from_iterable
https://docs.python.org/3/library/collections.html#collections.Counter
