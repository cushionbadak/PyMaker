Natural Text
I am processing a 500MB file. the processing time increased when used re.search.Please find the below cases i have tested. In all the cases i am reading file line by line and using only one if condition.Case1:This has taken 16 seconds to read the entire file.Case2:This has taken 25 seconds to read the file.Case3:This has taken only 8 seconds to read the file.Can any one of you please let know the diference between the three cases. and Case3 is processing very fast but i am unable to do case-insensitive match. how to do a case-insensitive match in Case3 ?  
Case insensitive search for case 3 first:By lowercasing line, you make that a lowercase search.As for why case 2 is so much slower: using a pre-compiled regular expression is going to be faster, as you then avoid the cache lookup for the regular expression pattern for each and every line you read from the file. Under the hood, re.search() will also call re.compile() if no cached copy already exists and that extra function call and cache check is going to cost you.That is doubly painful on Python 3.3, which switched to a new caching model using the functools.lru_cache decorator, one that is actually slower than the previous implementation. See Why are uncompiled, repeatedly used regexes so much slower in Python 3?A simple text search with in is faster for exact text matches. Regular expressions are great for complex matching, you are simply looking for an exact match, albeit case insensitive.


Answer URL
