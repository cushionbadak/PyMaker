Natural Text
In our current c-project, we use python scripts for support and testing purposes such as unit testing, integration testing, benchmarking and communication.Current folder structure (most files not shown):Some python files are intented to be executed as script files ($ python script1.py) and some are intended to be included as modules in other python files.What we would like to achive is a structure that enables us to have parameter and utility functions that can be used by:Test codeOther utility codesSmaller python application used for monitoring of our system. I.e. custom benchmarking toolsIt should also be possible to have several workingcopies checked outUp until this date, all scripts have following lines at top:With about 20+ script files this has become hard to maintain. Is there any better way to achive this?
You should convert your folders into Python modules by adding an empty __init__.py file into it. Also, you can add the Python shebang, so they are executable without explicitly calling the Python command from shell (Should I put #! (shebang) in Python scripts, and what form should it take?). Once your folders are modules, you have to add only the main source path and you will be able to import the children modules in an easier manner.Furthermore, you should use a virtual environment (virtualenv) that can handle the paths for you (http://docs.python-guide.org/en/latest/dev/virtualenvs/) (and maybe virtualenvwrapper that allows you extra functionality)I wanted to add a couple of additional strategies you could use here:One of the cool things about python is that everything is an object so you could import and pass your script modules as a variable to a function that run's them, initialising the appropriate path. Also, the function could "discover" the scripts by looking into the folder and walking through it.Again, all this can be easily handled from pre-post activate virtualenvwrapper hooks.


Answer URL
https://docs.python.org/3/library/os.html#os.walk
