Natural Text
This question already has an answer here:How do you remove duplicates from a list whilst preserving order?                    24 answers                so I have this list: a = [-11, 13, 13, 10, -11, 10, 9, -3, 6, -9, -6, -6, 13, 8, -11, -5, 6, -8, -12, 5, -9, -1, -5, 2, -2, 13, 14, -9, 7, -4]and by using a set I need to remove the duplicates and also keep them in the same orderI used this code:it does remove the duplicates when I use it but the problem is it returns them in numerical order like this:how can I return it in the same order as the original list while removing duplicates using sets?EDIT:so I've used this code because it worked:but can someone explain to me what it does? because I need to make another once but it returns the list without negative numbers, and I can't do that unless I understand what that code does
This function already exists in the itertools recipes, as unique_everseen. You can copy and paste it from there, or read it to see how it works, or install the third-party package more-itertools and use it from there.Here's a simplified version of the code:The version in the recipes allows for a key function, which you don't need, and it has two optimizations. But first understand the simple version:seen is a set of all values seen so far. For each value, we check whether it's in seen. If so, we skip it. Otherwise, we add it to the set and yield it. So, we yield each element only the first time it's seen.The first optimization in the recipe version is simple: looking up the seen.add method isn't quite free, so we do it once instead of N times, by doing seen_add = seen.add. This makes a sizable difference when benchmarking trivial cases, like a list of small integers; it may not make much difference in real use cases with values that are more expensive to hash.The second optimization is to use ifilterfalse instead of an if to skip over the elements that have already been seen. Basically this means that if you have N elements and M unique elements, you only do M iterations in Python and N in the optimized C code inside ifilterfalse, instead of doing N in Python. Since iterating in C is much faster, this is worth it unless almost all of your elements are unique.To make it work with a key function, all you have to do is keep a set of key(element) values seen so far, instead of element values seen so far. This makes the ifilterfalse optimization a little harder to do and much less effective, so it isn't done.If you're only dealing with sequences, not arbitrary iterables, and you can count on Python 2.7+, there's another way to do this which is almost as efficient, and even simpler:
Abuse of list comprehension:


Answer URL
