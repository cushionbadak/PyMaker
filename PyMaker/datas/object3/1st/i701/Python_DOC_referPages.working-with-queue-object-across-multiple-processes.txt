Natural Text
I'm trying to reduce the processing time of reading a database with roughly 100,000 entries, but I need them to be formatted a specific way, in an attempt to do this, I tried to use python's multiprocessing.map function which works perfectly except that I can't seem to get any form of queue reference to work across them.I've been using information from Filling a queue and managing multiprocessing in python to guide me for using queues across multiple processes, and Using a global variable with a thread to guide me for using global variables across threads.  I've gotten the software to work, but when I check the list/queue/dict/map length after running the process, it always returns zeroI've written a simple example to show what I mean:You have to run the script as a file, the map's initialize function does not work from the interpreter.Theoretically, when I pass the queue object reference from the main thread to the worker threads using the pool function, and then initialize that thread's global variables using with the given function, then when I insert elements into the queue from the map function later, that object reference should still be pointing to the original queue object reference (long story short, everything should end up in the same queue, because they all point to the same location in memory).So, I expect:of course, the 1, 2, 3's are in arbitrary order, but what you'll see on the output is ''.How come when I pass object references to the pool function, nothing happens?
Here's an example of how to share something between processes by extending the multiprocessing.managers.BaseManager class to support deques. Note that the output shown isn't the same what you show as expected in your question, but it is correct. (because calling pool.map(map_fn, range(3)) only results in three calls being made to map_fn).There's a section in the documentation about creating Customized managers.Output:
You cant use global variable for multiprocesing.Pass to the function multiprocessing queue.Also you are propably experiencing that the code is allright, but as the pool create separate processes, even the errors are separeted and therefore you dont see the code not only isnt working, but that it throws error.The reason why your output is '', is because nothing was appended to your q/global_q. And if it was appended, then only some variable, that may be called global_q, but its totally different one than your global_q in your main threadTry to print('Hello world') inside the function you want to multiprocess and you will see by yourself, that nothing is actually printed at all. That processes is simply outside of your main thread and the only way to access that process is by multiprocessing Queues. You access the Queue by queue.put('something') and something = queue.get() Try to understand this code and you will do well:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#customized-managers
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager
