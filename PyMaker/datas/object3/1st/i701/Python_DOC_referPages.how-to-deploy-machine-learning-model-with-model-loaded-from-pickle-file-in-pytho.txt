Natural Text
I have created an NLP model and saved the vectorizer and model in pickle file. I am using these pickle file for predicting the new data. Loading pickle takes around 10 minutes. I want to keep the pickle file loaded in memory and run the prediction when I get the input.I have a file prediction.pyI am running the python file with input string as an argument.IN this pickle file is loaded every time I am running  the script. Is there anyway to make a program such that the pickle file is already loaded in memory and we run the prediction file and get the result? 
It depends on your use case. The easiest would be a jupyter notebook so you can play arount. If you are in a bigger project, maybe you are more interested in using some kind of API REST like flask.
You would have to change your code structure a little bit.1. daemon.pyThis part is responsible for loading models into memory once and should run all the time getting input from 'front' partThis is only a sketch as I don't know your exact use case. Basically, there is an infinite loop taking files (or paths to files like here) and outputting predictions.2. front.pyUsing subprocess module you can send path files from the 'front' script to Daemon waiting for paths and returning answers. You have to attach input and output streams of Daemon to pass the file path and get predictions from that process. subprocess.run or Popen is probably all you need to perform this operation, go through documentation and example use cases (e.g. here, here and so on).EDIT: @Koalapa answer is another option, as we've said it highly depends on what exactly you wanna do, what is the user load etc.


Answer URL
https://docs.python.org/3/library/subprocess.html#subprocess.run
https://docs.python.org/3/library/subprocess.html#subprocess.run
