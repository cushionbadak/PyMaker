Natural Text
I am trying out the TensorFlow tutorial and don't understand where does next_batch in this line come from? I looked at And didn't see next_batch there either.Now when trying out next_batch in my own code, I am getting So I would like to understand where does next_batch come from? 
next_batch is a method of the DataSet class (see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py for more information on what's in the class).When you load the mnist data and assign it to the variable mnist with:look at the class of mnist.train. You can see it by typing:You'll see the following:Because mnist.train is an instance of class DataSet, you can use the class's function next_batch. For more information on classes, check out the documentation.
After looking through the tensorflow repository, it seems to originate here:https://github.com/tensorflow/tensorflow/blob/9230423668770036179a72414482d45ddde40a3b/tensorflow/contrib/training/python/training/sequence_queueing_state_saver.py#L905However if you're looking to implement it in your own code (for your own dataset), it would likely be much simpler to write it yourself in a dataset object, as I did. As I understand it, it's a method to shuffle the entire dataset, and return $mini_batch_size number of samples from the shuffled dataset. Here's some pseudocode:shuffle data.x and data.y while retaining relationreturn [data.x[:mb_n], data.y[:mb_n]]
You can just use the help function:and get the document of function next_batch


Answer URL
https://docs.python.org/3/tutorial/classes.html
