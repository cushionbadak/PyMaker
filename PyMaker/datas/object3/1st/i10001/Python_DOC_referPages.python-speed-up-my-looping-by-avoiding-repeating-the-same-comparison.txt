Natural Text
I am working on an algorithm that checks similarity between English words.Having defined a function called 'similarity', I go though the whole list of words to check for similar words, if the similarity between two words is very high (=1) the algorithm will change one of the two words to the other one.Here is the logic:assume that there is a very high similarity between word1 and word4.Result:normally, I just need to loop it, the steps taken will be like:take word1 out, comparing to word1, word2, word3, word4take word2 out, comparing to word1, word2, word3, word4take word3 out, comparing to word1, word2, word3, word4take word4 out, comparing to word1, word2, word3, word4However, there are some useless and repeated actions. For example, I don't have to compare word1 and word2 more than once. The problem is that I have to go through 1 million words and it might take many days to run. Any advice?Here is the code I am using at the moment:
Assume all your word list are not repetitive (means you already put them into set)IMHO, you can apply set theory math in similarity. If A similar to B, while X also similar to B, it means A also similar to X.So you have a set of words["car", "bus", "cat", "dog", "pen", "duck", "motorcycle"] As in similarity attribute of "motor vehicle, if "car" similar to "bus",  and "car" similar to "motorcycle". Thus "bus" also similar to "motorcycle". So you can see, you don't need to compare all similar word that have been found. So after the "car" similarity compare is done, it already taken away ["car", "bus", "motorcycle"]. "bus", "motorcycle" don't need to use for comparison again.you only remains ["cat", "dog", "pen", "duck"] ,etc. What you need to do next is keeping an index where this similar located. Perhaps a second pass to check the distance score. (update)IMPORTANT NOTE : In natural language, same verb and noun can have multiple meaning, e.g. chicken may means coward. E.g. you may miss combined words, proverb,etc. E.g. chicken out has nothing to do with chicken going out; In vitro is a verb that you can't split them up. Above method are pretty aggressive. But you need to start from somewhere, then incrementally add more features to perfect them.
Just use a nested loop where the second index starts from the value of the first:Of course, this optimization (that divides your computations by 2) only works because your similarity measure is symmetrical (a similar to b == b similar to a). Also, this does not change the computational complexity, it's still O(n^2) (more exactly: O(n(n-1)/2) ).An alternative, but more complicated, way to compute similarity measures that is more computationally efficient is to use binomial expansion (I will add more here later).Also you should avoid while loops, most often they can be replaced by for loops. This is more reliable (no infinite loop) ang more optimizable by the interpreter. 
Currently you check every word in the list against every other word in the list. Which is exactly n2.You can cut back on this by checking every word to every word after it. Which is 1 + 2 + ... + (n-1) + n = n(n-1)/2. This would deduplicate your checks. Though your checks would need to be symmetric.It may still take a long time to run because it's now only about half the size.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.combinations
