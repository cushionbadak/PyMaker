Natural Text
This question already has an answer here:python: read lines from compressed text files                    3 answers                I'm using the following generator to iterate through a given csv file row by row in a memory efficient way:This works perfectly and I am able to handle very large files incredibly well. A CSV file of several gigabytes seems to be no problem at all for a small virtual machine instance with limited RAM.However, when files grow too large, disk space becomes a problem. CSV files generally seem to get very high compression rates, which allows me to store the files at a fraction of their uncompressed size, but before I can use the above code to handle the file, I have to decompress/inflate the file and then run it through my script.My question: Is there any way to build an efficient generator that does the above (given a file, yield CSV rows as an array), but does so by inflating parts of the file, up till a newline is reached, and then running that through the csv reader, without ever having to deflate/decompress the file as a whole? Thanks very much for your consideration!
Try using gzipJust replace with open(file, 'rb') as csvfile: with with gzip.open(file, 'rb') as csvfile: and add import gzip at the top of your script.See this SO question for more
If you from gzip import open, you do not need to change your code at all!


Answer URL
https://docs.python.org/3/library/gzip.html
