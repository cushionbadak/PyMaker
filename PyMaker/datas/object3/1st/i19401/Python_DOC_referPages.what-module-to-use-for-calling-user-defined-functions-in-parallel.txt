Natural Text
I've written an irc bot that runs some commands when told so, the commands are predefined python functions that will be called on the server where the bot is running.I have to call those functions without knowing exactly what they'll do(more I/O or something computationally expensive, nothing harmful since I review them when I accept them), but I need to get their return value in order to give a reply back to the irc channel.What module do you recommend for running several of these callbacks in parallel and why?The threading or multiprocessing modules, something else?I heard about twisted, but I don't know how it will fit in my current implementation since I know nothing about it and the bot is fully functional from the point of view of the protocol.Also requiring the commands to do things asynchronously is not an option since I want the bot to be easily extensible.
First, the tl;dr:Use concurrent.futures if you're using 3.2+, or the futures module on PyPI that backports the same thing if you're using 2.x.You can write your code with a ThreadPoolExecutor and switch it to a ProcessPoolExecutor as a one-liner change. And the API is so minimal and simple that there's nothing to get confused by.Also requiring the commands to do things asynchronously is not an option since I want the bot to be easily extensible.I don't see how that follows. There's nothing about async code that makes it less extensible. Of course you have to know how to write async code in order to extend it, but thousands of novice JS programmers are doing a nearly-passable job of that every day, and Python makes it a whole lot easier (see monocle, inlineCallbacks in twisted, tulip, etc.). Also, the fact that you explicitly refer to these things as "callbacks" in your description implies that you're already thinking in those terms…If you're convinced this actually is a requirement, then twisted is not acceptable. But gevent (and eventlet, etc.) may be—you can just write code that looks completely synchronous, and it runs asynchronously.Next:What module do you recommend for running several of these callbacks in parallel and why?Do you really need to run them in parallel (you can take advantage of multiple cores to run multiple CPU-bound jobs at the same time), concurrently (a long-running job won't block other jobs), or neither (as long as the jobs get done, it doesn't matter whether they're parallelized, interleaved, or serialized)?If you need parallelism, you need multiprocessing. There's really no way around that; the GIL will prevent you from using multiple cores in a single process.If you only need concurrency, you can use either threading or multiprocessing. Processes may mean more overhead and/or more portability issues between Windows and Unix (and even sometimes between Unixes), and it sometimes forces you to think about how to pass data around—or, if you must, share it. On the other hand, by not forcing you to think about passing or sharing data, threads make it easier to accidentally create races and other bugs. (See isedev's great answer for more on the tradeoffs.)If you need neither, you can use gevent (or something similar), threading, or multiprocessing. You can create and switch between 10000 green threads as easily as you can create a few hundreds threads or processes, and with much less overhead. However, a single long-running CPU-bound command can stall your entire system.Whichever one you use, you most likely want to use a pool of greenlets, threads, or processes pulling commands off a queue (rather than spinning off a new one for each command, or building something more complex).While multiprocessing has such a thing built in, threading does not. (Actually, there is a threading-based threadpool—but it's in multiprocessing, not threading. And it's not part of the public API.)There's a lot of amazingly cool stuff in multiprocessing, and if you need it, definitely use it. (There are also some third-party libraries with even cooler stuff in them, which can make complex use cases a whole lot easier, or do things that multiprocessing just can't do.) But if not, futures is a lot simpler, and the ability to test the same system with threads and processes with a one-liner change (or even trivially doing it at runtime) is very nice.
There is no definitive answer to your question: it really depends what the functions do, how often they are called and what level of parallelism you need.The threading and multiprocessing modules work in radically different ways.threading implements native threads within the Python interpreter: fairly inexpensive to create but limited in parallelism due to Python's Global Interpreter Lock (GIL). Threads share the same address space, so may interfere with each other (e.g. if a thread causes the interpreter to crash, all threads, including your app, die), but inter-thread communication is cheap and fast as a result.multiprocessing implements parallelism using distinct processes: the setup is far more expensive than threads (required creation of a new process), but each process runs its own copy of the interpreter (hence no GIL related locking issues) and run in different address spaces (isolating your main app). The child processes communicate with the parent over IPC channels and required Python objects to be pickled/unpickled - so again, more expensive than threads.You need to figure out what trade-off is best suited to your purpose.


Answer URL
