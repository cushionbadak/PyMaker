Natural Text
I have asked this question about a month ago. However, no one gave an answer or even comment.I am repeating the question so that someone would help this time.I have a large Unicode Monolingual corpus consists over 100 million words in a txt file of size 1.7GB. Now I need to find the word frequency of each word in that corpus so that I can find 20 most frequent words and 20 Least frequent words in the corpus. Such as,(the example is given in Swedish instead of Bengali for easy understanding) Corpus: jag har ett stort hus ocks책 jag har ett stort f채lt jag.Word Frequency:jag 3har 2ett 2stort 2hus 1f채lt  1Desicion:most frequent:jag 3har 2Least frequent:hus 1f채lt  1BUT, when I have tried to use a mysql database to store new words from corpus and increase its freqeuncy each time by one. so that finally I can get the words with their frequency. however, it took 2 days to complete even 10% of the corpus. I have tried another way by keeping a txt file to keep a record about the frequency of each word. However it fails due to the system doesn't work for unicode words. Please suggest me a easy and fast way to count to this ( Can be in PHP or PYTHON).
In python, the simplest way is to use collections.Counter to create a counter object. I timed it out using a (very limited) 200,000 word corpusThat being said, >100 million words is just going to be a very very large task, and I would expect to run into memory and time issues. I would expect that you would have better luck operating on partial chunks of your data at a time.You may also look into multiprocessing


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
