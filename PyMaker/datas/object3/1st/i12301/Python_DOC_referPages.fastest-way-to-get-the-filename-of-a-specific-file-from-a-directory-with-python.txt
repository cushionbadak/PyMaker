Natural Text
What is the fastest way of getting the filename of a specific file in a directory with python (without having to load the entire list of files first)?I have directories with thousands of files in, and need to access specific files in these directories. Specifically, I need the file that is e.g. the 1000th in the file list. I want to do this without reading in all files and then selecting the one I want. Is there a way of specifying the index of the file (e.g. the 1000th one listed in the directory) and making python (or OS) return the name of only that particular file?I need to do this again and again for different files in different directories, and therefore do not want to load all files in each directory as it will take too long.Thanks in advance.
You can't reach the thousandth file without iterating through the first 999, though you don't need to iterate the whole directory if you have Python 3.5 which adds os.scandir (or you install the scandir third party package for older Python).Combine with islice, and you'll easily skip the first 999 entries:Note that directory ordering of files is not necessarily meaningfully ordered by timestamp, name, etc., so odds are, the 1000th entry is not predictable. You probably want to find some way of identifying the correct file by name, rather than scanning for it by arbitrary listing order.If you do need the Xth entry in some order other than natural iteration order, you'll need to iterate the whole thing to sort it, but os.scandir could still save you some work; it's generally faster than os.listdir and depending on OS may give you some of the stat information "for free", avoiding per-file stat-ing; for example as you mentioned in your comments, you want to order by timestamp, and it's possible you want to skip directories and only count files:You can reduce the peak memory cost a bit by replacing sorted with heapq.nsmallest; it's a little slower if the number to retrieve is a significant fraction of the total inputs, but it caps memory usage (and can be faster if the directory contains millions of files, and you only want #1000):You can't avoiding some processing here, but it can potentially reduce memory overhead and per-file stating overhead a lot vs. non-scandir based solutions.Per your comments, it seems like you really want the 1000th file alphabetically, not by modification time or directory order (the ls command sorts alphabetically automatically, you only see true directory order running /bin/ls -U). You also seem to only care about files ending in .fits, and want only files, not directories. In that case, the complete solution is just:
You can do it in this way by using subprocess if you have Python 3. It works only for linux.


Answer URL
https://docs.python.org/3/library/os.html#os.scandir
https://docs.python.org/3/library/heapq.html#heapq.nsmallest
