Natural Text
I have written a spider that takes urls from a list, loads the according pages using requests in separate threads using concurrent.futures.ThreadPoolExecutor and when a page is loaded some info is extracted from it, put into an item (a dictionary) and that item is put into a Queue() called collected_items.After running a spider method that creates jobs for ThreadPoolExecutor in separate threads (simplified):I am waiting for the items collected by worker threads:However sometimes the while loop breaks before all the items have been collected.spider._executor._threads is a set of worker threads which in while loop take work items from spider._executor._work_queue and run associated callables.Condition not spider._executor._work_queue.empty() or not collected_items.empty() is not reliable, because the work item queue in executor maybe empty as well as the collected items queue, but at the time of checking this condition an executor worker thread could have taken the last work item from spider._executor._work_queue and right now is doing some work that will add a collected item to collected_items queue (which at the moment is empty too). Or the work item queue has not received yet the first work item.I don't see a way to reliably determine whether I have still to wait for new items to appear in collected_items or move on.UPDATE:I would solve this if after finishing a work item the worker thread would call work_queue.task_done(). Unfortunately it's not the case.I've added a comment to a related bug: http://bugs.python.org/issue14119#msg207512
Write your worker code like this:And use queue.unfinished_tasks as the condition.


Answer URL
