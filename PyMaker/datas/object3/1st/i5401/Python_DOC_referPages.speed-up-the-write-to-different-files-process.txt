Natural Text
I am reading from a huge file (232MB) line by line.First, i recognize each line according to a Regular Expression.Then for each line, I am writing to different city.txt files under the 'report' directory according to a cityname in each line. However, this process takes a while. I am wondering if there is anyway of speeding up the process?Example of input file: (each column split by a \t)2015-02-03  19:20   Sane Diebgo Music   692.08  CashActually i have tested the code with writing to different files and not writing to different file(simply process the large file and come up with 2 dicts) the time difference is huge. 80% of the time is spent writing to different files
The dictionary lookups and updates could be improved by using defaultdict:


Answer URL
https://docs.python.org/3/library/profile.html
