Natural Text
I've been looking at the following questions for the pas hour without any luck:Python sharing a dictionary between parallel processesmultiprocessing: sharing a large read-only object between processes?multiprocessing in python - sharing large object (e.g. pandas dataframe) between multiple processesI've written a very basic test file to illustrate what I'm trying to do:Currently this outputs the following :How can I access the mem value's from the main code or the process that runs "print_values"?
Unfortunately multiprocessing.Manager() doesn't support deque but it does work with list, dict, Queue, Value and Array.  A list is fairly close so I've used it in the example below..You have to be a little careful using manager objects.  You can use them a lot like the objects they reference but you can't do something like... mem = mem[-4:] to truncate the values because you're changing the referenced object.As for coding style, I might move the Manager objects outside the class or move the print_values function inside it but for an example, this works.  If you move things around, just note that you can't use self.mem directly in the run method.  You need to pass it in when you start the process or the fork that python does in the background will create a new instance and it won't be shared.Hopefully this works for your situation, if not, we can try to adapt it a bit.
So by combining the code provided by @bivouac0 and the comment @Marijn Pieters posted, I came up with the following solution:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Queue
