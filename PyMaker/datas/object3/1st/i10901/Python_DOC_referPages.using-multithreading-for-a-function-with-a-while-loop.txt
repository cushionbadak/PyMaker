Natural Text
I have a pretty basic function that iters through a directory, reading files and collecting data, however it does this way too slow and only uses about a quarter of each core (quad-core i5 CPU) for processing power. How can I run the function 4 times simultaneously. Because it's going through a rather large directory, could I have the parameter use random.shuffle()? Here's the code I have now:Because the function doesn't take any parameters, what can I do?
I didn't use map(), it is said map takes only one iterable argument, theoretically, you either modify your fuction() to function(one_arg) or try to use an empty list or tuple or other iterable structure but I didn't test it. I suggest you put all files into queue(can be shared by processes), and share the queue to multiple processes(in your case it is 4).  Use try-except to quit when finish reading a file. Creates 4 processes to consume the files queue and quit until all files are processed.Queue is easy for you to tell whether there's more files need to be read or not based on Queue.Empty and TimeoutError
This method pool.map(function) will create 4 threads, not actually 4 processes. All this "multiprocessing" will happen in the same process with 4 threads.What I suggest is to use the multiprocessing.Process according the documentation here (Python 2) or here (Python 3).


Answer URL
https://docs.python.org/3/library/multiprocessing.html#the-process-class
