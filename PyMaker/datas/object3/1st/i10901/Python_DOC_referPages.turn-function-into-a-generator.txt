Natural Text
With the following method I'm able to list all files from my Google Drive Account:For a better runtime I would like to return a generator from this method. I'm pretty new to Python so I don't know how to do this.The execute method from the files services always returns 100 items and if it returns a page_token too there are more items to fetch. It would be great if I could iterate over the generator to get the already fetched items and in the mean time the next items are fetched from the service. I hope you understand what I mean...Is this possible? How do I have to rewrite this method to get the described functionality?
You can rewrite your function to act as a generator by simply yielding single file paths.Untested:If you do not further parallelize use chapelo's answer instead. Yielding the list of all available files will allow the coroutine to continue and thus, begin to fetch the next list of files concurrently.Preloading the next bunch with futuresNow, you are still not loading the next bunch of files concurrently.For this, as mentioned in the code above, you could execute a future to already gather the next list of files concurrently.When your yielded item is consumed (and your function continues to execute) you look into your future to see whether the result is already there. If not, you have to wait (as before) until the result arrives.As I don't have your code available I can not say whether this code works (or is even syntactically correct), but you can use it as a starting point:Producer/Consumer parallelization with QueuesAnother option, as also mentioned in the comments, is to use a Queue. You can modify your function to return a queue which is filled by a thread spawned by your function. This should faster than only preloading the next list, but also yields a higher implementation overhead.I, personally, would recommend to go with the future path -- if the performance is adequate.
If you yield each file at a time, you are blocking the generator. But if you yield the whole list that the generator has prepared, while you process the list of files, the generator will have another list ready for you:Instead of Michael's suggestionTry to yield the whole list at once, and process the whole list of files when you receive it:Consider this simple example:
You're going to have to change the flow of your script. Instead of returning all the files at once, you're going to need to yield individual files. This will allow you to handle the fetching of results in the background as well. Edit: The fetching of subsequent results would be transparent to the calling function, it would simply appear to take a bit longer. Essentially, once the current list of files have all been yielded to the calling function, you would get the next list, and start yielding from that list, repeat until there are no more files to list from Google Drive.I highly suggest reading What does the "yield" keyword do in Python? to understand the concept behind generators & the yield statement. 


Answer URL
https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures
