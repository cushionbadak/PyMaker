Natural Text
I am currently attempting to create a color plot of a given data series of images, using python. After using a software called Powderday, I have in storage (in the file entitled "merger.070.new.rtout.image" which I have called in line 18 of my code) a series of approximately 35 images that each contain flux information at a specific wavelength of a certain galaxy merger. I want to loop through each of those images and create a final image that is essentially each of those images added up, so that instead of several single-wavelength images I have a series of wavelengths in one image.To do this I want to loop through each image, save the wavelength map in a final image, and keep adding subsequent images to this final one. The only issue is that I am getting an AxesImage each time I find the single-wavelength images, which as far as I know does not have a function to just merge with another image. I have found so far online that the best solution to this is to create a numpy array from the image, but I also couldn't find if the get_image function from matplotlib.image would accept an AxesImage parameter in order to turn it into such an array. My code is below. The important lines are at: 42 - 45 where I am trying to initialize finalImg so that I can "iterate" it within the loop; 47 - 61 where I am iterating through each image.Also as a side note: the B_Johnson and B_thruput files that I am reading in contain information about which wavelengths I have in my .image file, as well as the corresponding throughputs. This is because I want to multiply the flux that I find at each wavelength by its throughput in order to correctly simulate an actual real-world filter.Hope this information provides a good background for the issue! I am still very new to python. What is the best way to add up all these images?line 18 below:line 42 below:lines 47 - 61 in the loop:
First, you cannot load a Matplotlib AxesImage into a NumPy array. I am not in your field, but based on the Hyperion documentation for ModelOutput.get_image() I believe get_image() returns image data as a NumPy array in the following line from your code: Look at type(image) to verify this. You should see numpy.ndarray if I am correct.If this is the case, then finalImg = mpimg.imread(cax) is superfluous...you already have your images loaded as a NumPy array in the image variable.Now if you want your data loaded as separate channels in a single ndarray object then you are done at get_image(). Printing image.ndim should show 3 (you have a three dimensional image array) with img.shape of (y_axis_length, x_axis_length, number_of_channels).Based on how you phrased your question though I think you want to combine these channels into a single intensity value for each pixel by taking the sum of the intensities in each channel. This operation would yield a two-dimensional grayscale image of shape (y_axis_length, x_axis_length). To see what I mean, please consider the following example I have drawn up for you:


Answer URL
https://docs.python.org/3/tutorial/classes.html
