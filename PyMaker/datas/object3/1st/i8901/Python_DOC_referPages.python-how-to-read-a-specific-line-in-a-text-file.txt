Natural Text
I have a huge text file (12GB). The lines are tab delimited and the first column contains an ID. For each ID I want to do something. Therefore, my plan is to go start with the first line, go through the first column line by line until the next ID is reached.The code works, but the problem is that linecache seems to reload the txt-file every time. The code would run several years if I don't increase the performance.I appreciate your help if you have a good idea how to solve the issue or know an alternative approach!Thanks,Philipp
I think numpy.loadtxt() is the way to go. Also it would be nice to pass usecols argument to specify which columns you actually need from the file. Numpy package is solid library written with high performance in mind. After calling loadtxt() you will get ndarray back.
You can use itertools:In outer loop id can actually be obtain from the first line with an id non-matching previous value.
You should open the file just once, and iterate over the lines.You get the idea, just use plain python.Only one line is read in each iteration. The extra 1 argument in the split will split only to the first tab, encreasing performance. You will not get better performance with any specialized library. Only a plain C language implementation could beat this approach.If you get the AttributeError: '_io.TextIOWrapper' object has, it is probably because you are using Python 3.X (see question io-textiowrapper-object). Try this version instead:


Answer URL
https://docs.python.org/3/library/linecache.html
