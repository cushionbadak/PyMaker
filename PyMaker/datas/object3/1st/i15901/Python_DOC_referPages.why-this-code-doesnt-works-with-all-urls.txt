Natural Text
I'm very new to python, was playing with some code. I'm actually trying to parse a html webpage and extract some information from the parsed document:I'm getting this error in file.write() line, and I searched on the internet still have no clue on how to fix that. The Error:My code works perfectly for some sites like www.google.com or www.flipkart.com and gives the error for some URLS like www.facebook.com and www.youtube.com. I think one possilbe reason it doesn't works for www.facebook.com and youtube.com because they are developed in PHP or some other language and not an HTML web pages is that correct?
The problem is that you're trying to write to a text file with the cp1252 encoding, but your data include characters that don't exist in cp1252.In Python, the open function takes a optional encoding argument for text files. As the docs say, if you don't specify anything:The default encoding is platform dependent (whatever locale.getpreferredencoding() returns)On Windows, the "preferred encoding" returned by that function is going to be whatever you've set as your default for the system. On a US version of Windows, if you haven't changed the settings, the pre-configured default is "code page 1252", which is Microsoft's variation on IBM's variation on Latin-1. That can only handle 256 different characters (almost, but not quite, identical to the first 256 characters in Unicode). If you have any other characters, you're going to get an error.The reason this works on some pages but not others is that some pages don't have anything but normal English characters that fit into every character set.If you really want to save a UTF-8 text file, you have to do that explicitly:If you want to save a cp1252 text file—or, rather, whatever your system's default encoding happens to be, which may be UTF-8 if someone runs your script on a Mac or Shift-JIS-based cp932 on a Japanese Windows box—by skipping or replacing or escaping the characters that don't fit into cp1252, you can do that too:Or, of course, if you want cp1252 no matter what the system is set to, say so:If you want to save the raw bytes without worrying about what they are, open the file in binary mode and don't decode the bytes in the first place:Of course if you then open that file in a cp1252 (or Shift-JIS, etc.) text editor, it's going to look like mojibake… but that's not your program's fault anymore. :)However, you've got another problem here. You're assuming that every web page is UTF-8. That's not true. Pre-HTML5 web pages are, in fact, in Latin-1 by default—but they can specify a different encoding in the headers (or in a meta tag, or, for XHTML, in the top-level XML tag). In particular, try this with the Facebook page:That how you know that it's, in this case, UTF-8.For HTML5, it's… a lot more complicated. Ideally you'll want to use a library that does this for you. (Since you're already using BeautifulSoup, for many common cases its "Unicode, dammit" will work well enough—and it also works pretty well for pre-HTML5—but a standards-correct implementation is even better.)


Answer URL
https://docs.python.org/3/library/functions.html#open
