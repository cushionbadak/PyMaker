Natural Text
I am looking for a simple example of python multiprocessing.I am trying to figure out workable example of python multiprocessing. I have found an example on breaking large numbers into primes. That worked because there was little input (one large number per core) and lot of computing (breaking the numbers into primes). However, my interest is different - I have lot of input data on which I perform simple calculations. I wonder if there is a simple way to modify the below code so that multicores really beats single core. I am running python 3.6 on Win10 machine with 4 physical cores and 16 GB RAM. Here comes my sample code.I would be very grateful if anyone could advice me how to modify the code so that multiple core run beats single core run. I have also noticed that increasing variable bnds_no to 1,000 leads to BrokenPipeError. One would expect that increasing amount of input would lead to longer computational time rather than an error... What is wrong here?
The BrokenPipeError is not due to larger input but it is due to race condition which occurres due to the use of queue.empty() and queue.get() in separate steps.You don't see it with smaller inputs for most the times is because the queue items get processed pretty fast and race condition does not occur but with larger datasets the chances of race condition increases.Even with smaller inputs try running your script multiple times, maybe 10 15 times and you will see BrokenPipeError occurring. One solution to this is to pass a sentinel value to the queue which you can use to test if all the data in the queue has been processed.Try modifying your code to something like this
This doesn't directly answer your question but if you were using RxPy for reactive Python programming you could check out their small example on multiprocessing: https://github.com/ReactiveX/RxPY/tree/release/v1.6.x#concurrencySeems a bit easier to manage concurrency with ReactiveX/RxPy than trying to do it manually.
OK, so I removed queue related parts from the code to see if get rid of the BrokenPipeError (above I updated the original code indicating what should be commented out). Unfortunately it did not help.I tested the code on my personal PC with Linux (Ubuntu 18.10, python 3.6.7). Quite surprisingly the code behaves differently on the two systems. On Linux the version without queue runs without problems; the version with queue runs forever. On Windows there is no difference - I always end up with BrokenPipeError.PS: In some other post (No multiprocessing print outputs (Spyder)) I found that there might be some problem with multiprocessing when using Spyder editor. I experienced exactly the same problem on Windows machine. So, not all examples in official documentation work as expected...
This doesn't answer your question—I'm only posting it to illustrate what I was said in comments about when multiprocessing might be able to speed processing up.In the code below which is based on yours, I've added a REPEAT constant that makes the npv_zcb() do its computations over again that many times to simulate it using the CPU more. Changing this constant's value generally slows-down or speeds-up the single core processing much more than it does the multiprocessing part — in-fact it hardly affects the latter at all.  


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming
