Natural Text
In Bash, it is possible to execute a command in the background by appending &. How can I do it in Python?
I use multiprocessing.dummy.Pool. I create a singleton thread pool at the module level, and then use pool.apply_async(requests.get, [params]) to launch the task.This command gives me a future, which I can add to a list with other futures indefinitely until I'd like to collect all or  some of the results.multiprocessing.dummy.Pool is, against all logic and reason, a THREAD pool and not a process pool.Example (works in both Python 2 and 3, as long as requests is installed):The requests will be executed concurrently, so running all ten of these requests should take no longer than the longest one. This strategy will only use one CPU core, but that shouldn't be an issue because almost all of the time will be spent waiting for I/O.
Here's a hacky way to do it:
According to the doc, you should move to another library : Blocking Or Non-Blocking?With the default Transport Adapter in place, Requests does not provide  any kind of non-blocking IO. The Response.content property will block  until the entire response has been downloaded. If you require more  granularity, the streaming features of the library (see Streaming  Requests) allow you to retrieve smaller quantities of the response at  a time. However, these calls will still block.If you are concerned about the use of blocking IO, there are lots of  projects out there that combine Requests with one of Pythonâ€™s  asynchronicity frameworks.Two excellent examples are  grequests and  requests-futures.
If you can write the code to be executed separately in a separate python program, here is a possible solution based on subprocessing.Otherwise you may find useful this question and related answer: the trick is to use the threading library to start a separate thread that will execute the separated task.A caveat with both approach could be the number of items (that's to say the number of threads) you have to manage. If the items in parent are too many, you may consider halting every batch of items till at least some threads have finished, but I think this kind of management is non-trivial.For more sophisticated approach you can use an actor based approach, I have not used this library myself but I think it could help in that case.
Elegant solution from Andrew Gorcester. In addition, without using futures, it is possible to use the callback and error_callback attributes (see doc) in order to perform asynchronous processing:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async
