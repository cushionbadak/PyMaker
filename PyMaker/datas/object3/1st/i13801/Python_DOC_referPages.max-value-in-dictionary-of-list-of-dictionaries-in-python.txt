Natural Text
Consider a dictionary of lists of dictionaries, such as the following:What would be the most efficient way (from the perspective of time complexity) to find the entry with the maximum value for a key from the inner dictionary, grouped by key from the main dictionary? In case of a tie, another key from the innermost dictionary determines the winner.With the above dictionary, finding the max for key 'bits', using key 'date' to break ties (favoring the most recent) the result should be the dictionaryI currently have an implementation using two nested for loops. I'm considering to sort the list by the field bits to get to the entry with the largest value.The current implementation is like below : But its taking lots of time for large data sets. Please suggest the optimum solution
Let's make a framework to answer this empirically. It's always best to test how fast algorithms are actually running, rather than just guessing.First a way to generate test data:Here's two possible solutions. The first uses the pandas module to convert your list of dictionaries into a more structured data type. The second is a straightforward implementation using pure Python, and a sort key based on a tuple of your keys in order of importance.A method to run the test:We get the same results with either method:Which is faster? Depends entirely on the size of your inner-most dictionary list. For a sufficiently large inner list, it will be worth it to pay the upfront cost of converting to DataFrame, in order to benefit from the more optimized sorting algorithms available in pandas. For a short inner list, it's better to just used sorted.With 10000 records the pandas method is faster:With 100 records the sorted method is much faster:Note that the size of the outer dictionary is completely irrelevant since each entry is processed completely independently. So the total time is just the sum of the time needed for each entry in the outer dictionary.
Here is the idea:Is this helpful ?Let me know if you don't like this solution, i will remove it.
After I worked on it a bit, I don't think you can get around the nested loops or multiple iteration. If you have to account for ties you will need to iterate over the inner dictionaries, worst case you will have to iterate over all of those items to break a tie - So the complexity stays the same.Try to take advantage of the builtins max and map, operator.itemgetter, functools.partial, functools.reduce (all part of the standard library).  They may speed things up even though the time-complexity is the same.We need to write a key function that can be used with max.While the following may be instructional, it breaks ties based on the bits key.  It uses a key function that returns the sorted bits values from each inner dictionary of each item of the data. Make sure to see the edit at the bottom.  I'm also using a handy function that lets you string multiple functions together.  I had this in my toolbox, it doesn't have an attribution so I don't know if I wrote it or found it someplace - I probably found it.We need the value for each (k,v) item in data.We need a somethng to get the bits value of an inner dictionaryWe need to iterate over each inner dictionary and extract the bitsWe need a reverse sortCompose a key function that will return the stuff you are interested in.Not sure why I like the functional style but you could also write the key function like this (which, I imagine, many people will find way more readable).editSeems I misread or didn't see that the tiebreaker is the date field.this makes it a bit easier.


Answer URL
https://docs.python.org/3/library/functions.html#max
https://docs.python.org/3/library/functions.html#map
https://docs.python.org/3/library/operator.html#operator.itemgetter
https://docs.python.org/3/library/operator.html#operator.itemgetter
https://docs.python.org/3/library/functools.html#functools.reduce
