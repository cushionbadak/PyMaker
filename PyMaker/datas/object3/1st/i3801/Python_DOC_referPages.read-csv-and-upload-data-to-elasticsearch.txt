Natural Text
I am iterating the rows one by one of a csv file and I want to insert it into es. I'm new to both python and elastic search.How to convert one csv row and insert it into es one by one But I'm getting this error:Traceback (most recent call last):File "/home/PycharmProjects/CsvReaderForSyncEs/csvReader.py", line 25, in  csv_reader(f_obj)File "/home/PycharmProjects/CsvReaderForSyncEs/csvReader.py", line 17, in csv_readeres.index(index='product', doc_type='prod', id=i, body=json.dump([row for row in reader], file_obj))File "/usr/lib/python2.7/json/init.py", line 190, in dump fp.write(chunk)IOError: File not open for writing
Try bulk API.for more information about bulk APIhttps://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html
The problem is that you are passing file_obj as a parameter for json.dump but the file is only opened for reading. Check the mode parameter for the open function in this link.Also check the first parameter for the json.dump function, [row for row in reader] gets all the rows in the csv file, but probably you just want to pass one row, so the parameter should be row.And json.dump writes to a file, probably you should use the json.dumps function, check here
can you try this.Change reader to DictReader and json.dumps(row).DictReader make input data is python dict. And for in is loop each row in reader, you just try push row is enough


Answer URL
https://docs.python.org/3/library/functions.html#open
https://docs.python.org/3/library/json.html#json.dumps
https://docs.python.org/3/library/csv.html#csv.DictReader
