Natural Text
Can someone explain why version 1 and 2 execute at the same speed? I expected versions 2, 3, and 4 to take about the same amount of time. Results: 
Your memoize function isn't actually replacing fib with memo_fib, it's just returning a new function. That new function still recursively calls the original, un-memoized fib. So, basically, you're only memoizing the very top level.Within fib, the recursive call to fib is just using the module-global name. (Functions are basically no different from any other kind of value, and function names no different from any other kind of name, so if you define a function at the module global level, that's what it does. If you, e.g., disassemble the bytecode with dis.dis(fib), you will see a LOAD_GLOBAL on the name fib.)So, the easy fix is:Or just use memoize as a decorator, to make this harder to get wrong. In other words, your examples 3 and 4.Or, even more simply, use the built-in lru_cache decorator. (Notice the second example in its documentation.)If you want to be really sneaky: Define fib within a function body. It will end up referencing fib as a closure cell from the defining scope, rather than a global (LOAD_DEREF instead of LOAD_GLOBAL in disassembly). You can then reach into that scope and replace its fib, which means that your recursive function is now memoized "secretly" (the actual global fib isn't memoized, but the function it recursively calls is) and "safely" (nobody else has a reference to the closure cell except through fib itself).
In version 2, you've stored the memoized version with a different name, so you wind up calling fib just as many times as in the first version. Your call stack looks like this:etc.So you aren't actually receiving any benefit from the memoization in this case.


Answer URL
