Natural Text
Python raises an exception if a dictionary changes its size during iteration using iteritems().I am hit by this problem since my program is multithreaded and there are cases that I need to iterate over the dict while another thread is adding keys into the dict.Fortunately, I don't need the iteration to be very precise on every element in the dict. Therefore I am thinking to use items() instead of iteritems() to do the iteration. I think items() makes a static snapshot of the dict and I would work around the problem. My question is: does items() raises an exception if the dict size is changing at the same time with items() execution?thanks
As the excellent comments noted:This is not thread safe.You should really use a lock when doing such things.It is possible to see this in the CPython source code, dictobject.c:If you look at the functionwhich is used for items, you can see that (after some clever pre-allocation for the results), it basically iterates over the array mp->ma_table (using a mask to see where there are entries).Now if you look at the functionwhich is used when the table needs to be resized, then you can see that ma_table's elements can be moved into a completely different buffer, and then it can be freed using PYMem_Free.So, you have a very real risk of accessing garbage memory, if things are done concurrently without synchronization.
The items() method in CPython's implementation of Python 2 is guaranteed to succeed.Since the items() method is implemented purley in C without releasing the GIL beforehand or during its execution, no other thread may acquire it and the underlying data structure remains unchanged while this method is executed.


Answer URL
https://docs.python.org/3/c-api/init.html#thread-state-and-the-global-interpreter-lock
