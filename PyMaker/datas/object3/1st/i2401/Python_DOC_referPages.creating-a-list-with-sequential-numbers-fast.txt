Natural Text
When I timed both actions to fill the list, I get 14 seconds for using for loop and 0.5 seconds for mylist2 = [0] * 100000000So it seems it is obvious to use the second method if I need to insert massive amount of items at once.But if I do the second thing, I have to insert the same number for all, or manually type  numbers that will repeat.Is there a way to performthis action resulting in [0,1,2,3,...,n] with good speed?The code doesn't necessarily have to be short if the speed is fast.
For full portability, list(range(N)) will get the best performance as Prune notes. That said, if you're purely targeting Python 3.5 or higher, you can use PEP 448's additional unpacking generalizations to speed it up a small amount, with:Note that this is a fixed savings, not per-item; all it does is bypass the lookup of list in the built-in namespace, and the generalized function call dispatch and __init__ argument processing of the normal list constructor. So when you're talking about 100 million items, the savings are going to be lost in the noise; all this does is reduce the fixed overhead by (on my 3.6 install) 170Â±10 ns (e.g. list(range(0)) takes 417 ns per call, vs. 247 ns per call for [*range(0)]).In specific cases though, there is an even faster option:In modern Python, range objects are full fledged sequences, they're just not mutable. So you can construct them, index them, slice them, compute their length, iterate them forwards and backwards, check membership (in O(1) for ints, unlike list where membership testing is O(n)), etc. The only non-mutability related features they lack are concatenation and repetition (with + and *), though you can simulate that with itertools functions like chain (for concatenation), and isliceing a cycle (for repetition).If you don't need to mutate the sequence, just read from it, using the range "raw" is by far the best option; ranges are lazy, consuming no memory, while still producing their values extremely efficiently. That laziness can be important; list(range(100000000)) will require (on 64 bit Python) 3.45 gigabytes of memory for the list itself plus all the ints it contains; range(100000000) requires 48 bytes. The trivial cost of generating the values on the fly is more than worth it, given the memory savings.If you need mutability, you can still save a bit on memory. If numpy is an option, sacul's answer has you covered; if not, Python's array module will save you a little bit of time, and a lot of memory. Compared to:the array alternative:takes about 10% less time (microbenchmarks had list at 3.39 sec, vs. array.array at 3.07 sec), and consumes far less memory (under ~391 MB, vs. the ~3529 MB of the list of ints). The main cost of array is limited range of values (e.g. for 'I', four byte unsigned ints can only store values in range(2**32); the maximum range for q/Q format codes, using twice the memory, would be range(-2**63, 2**63)/range(2**64)).
Since you say you need speed, I think that np.arange is the best way to go, it's even faster than creating the list of all 0s. Here are the timings on my machine:Note that np.arange() returns a np.array. If you need to convert it back to a list, you lose the speed. Better to just use the array...
Try making a list of the range output:I added this to your tests and got these times:


Answer URL
https://docs.python.org/3/library/stdtypes.html#typesseq-range
https://docs.python.org/3/glossary.html#term-sequence
https://docs.python.org/3/library/itertools.html
https://docs.python.org/3/library/itertools.html#itertools.chain
https://docs.python.org/3/library/itertools.html#itertools.islice
https://docs.python.org/3/library/itertools.html#itertools.cycle
https://docs.python.org/3/library/array.html
