Natural Text
I need help with one of my projects. I'm cleaning a large set of data to bulk insert into microsoft SQL. The data is like 10million lines. But I created a script just to extract the first 1000 for cleaning assuming the rest are the same. I noticed there was a lot of UTF-8 characters, so I converted it to the nearest real character. But after I extracted it to view the first 100000 lines, I noticed there is way more UTF-8 conversions that needs to be done and i'm converting them manually which is pretty exhaustive. I was wondering if there was an easier way to do this rather than manually entering everything in. Here is my code:As you can see in my code i'm manually replacing to the real character value.Here's an example line in my text file that I realized needs to be converted.B%E1%BA%A3o %C4%90%E1%BA%A1i
You could use unidecode with urllib.parse.unquote :unidecode will convert the non ascii characters to their ascii equivalent. 
You can use urllib.parse.unquote. It assumes UTF-8 by default, but in case there are also urls from other codecs among there, you can use some autodetection:and B%E1%BA%A3o %C4%90%E1%BA%A1i was the last emperor of Vietnam:If you want to convert these to the ASCII equivalents, you can use the unidecode:
Thank you everyone, I ended up getting it to work. I had to install the unidecode module which took me forever to figure out cause I was running into pip and cmd prompt errors. After the package installed I added this line and it worked.I really appreciate the help!
As far as my understanding goes, this is URL encoded i.e encoding the characters so that you can pass as parameter to server.Use unquote_plus() from urllib:Output:


Answer URL
https://docs.python.org/3/library/urllib.parse.html
https://docs.python.org/3/library/urllib.parse.html#urllib.parse.unquote
