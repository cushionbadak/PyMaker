Natural Text
I ran into a pickle (literally) in parallelizing the following Python code and could really need some help.First of all the input is a CSV file consisting of a list of website links that I need to scrape with the function scrape_function(). The original code is as follows and runs perfectlyI then tried to parallelize this code using joblib as follows:However, this would result in a weird error:Any idea what I did wrong here? If I try to put the append in a separate function like below then the error would go away, but the execution would then freeze and hang indefinitely:The input list has 10000s of pages so parallel processing would be a huge benefit.
If you really need it in separate processes, the easiest way is to just create a process pool and let it deal with distributing the links to your function, e.g.:NOTE: I'm assuming your links.csv actually holds the link in its first column based on how you're pre-processing the links in your code.However, as I've stated in my comment, this doesn't have to be necessarily faster than plain threading so I'd first try it using threads. Fortunately, the multiprocessing module includes a threading interfrace dummy so you just need to replace from multiprocessing import Pool with from multiprocessing.dummy import Pool and see in what regime your code works faster.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool
https://docs.python.org/3/library/multiprocessing.html
https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.dummy
https://docs.python.org/3/library/multiprocessing.html
