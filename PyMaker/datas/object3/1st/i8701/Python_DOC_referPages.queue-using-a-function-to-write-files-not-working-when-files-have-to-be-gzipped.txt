Natural Text
I switched from using open to gzip.open in some python code using multiprocessing, and files that weren't empty in the former version of the code now end up being empty. Is this a known issue? I'm unable to find information about similar problems on the internet.My code is inspired by this solution except I use imap_unordered to set the workers to work instead of apply_async in a loop.I'll try to make a minimum working example and add it to this post if necessary, but in case the problem is well known, I already give a verbal description of the situation:I have a working python program in which computations are happening in a multiprocessing.Pool of workers using the pool's imap_unordered method.These computations have to write data to some common files. This is achieved using communications through a multiprocessing.Manager.Queue. The worker functions take this queue as argument and send information to it using the queue's put method.A "writer" function takes the queue as argument and a bunch of file paths, uses the paths to open files in w mode. Based on information received through the queue's get method, things are written to one of the files.The "writer" function and its list of arguments are passed to the pool's apply_async method.All this seems to work correctly, and I obtain files with things written inside.Now I want to write this in a compressed form using gzip. I simply used gzip.open instead of open, and opened the files in wb mode. Apart from this and the fact that I added a ".gz" suffix to my file paths, everything is the same.The program runs with no error messages, but I end up with empty file.Is the gzip module not usable with multiprocessing ?Edit: Code exampleRunning the above code results in empty /tmp/out1.txt.gz and /tmp/out2.txt.gz.I have to say that I'm having trouble getting the non-gzip version to work as well: In both cases, the print("I'm a writer. I have to write:\n%s to %s" % (what, where)) seems to be executed only once:But at least, when the non-gzip version says it is writing something to a file, there is something in the file.
I tried some modifications based on examples found in the documentation of the multiprocessing module. It seems that I somehow can force the gzipped files to get written by using the get method of the thing returned by apply_async:I have no idea why this works, and what is actually the thing that apply_async returns. The documentation doesn't say more that this "returns a result object". More explanations are welcome.Note that the above code is still bugged. It solves the initial problem of gzipped files being empty but not the problem of the writer apparently doing some write job only once.Edit: Further testsIt turns out that getting the result of pool.apply_async and running get on it is actually not the only way to get the gzipped files written.Changing what to what.encode() also forces the writing:I'm still clueless about what is happening...


Answer URL
https://docs.python.org/3/library/multiprocessing.html#using-a-pool-of-workers
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.AsyncResult
