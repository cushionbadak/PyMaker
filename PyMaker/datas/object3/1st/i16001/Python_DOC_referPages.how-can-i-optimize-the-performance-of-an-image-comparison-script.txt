Natural Text
I wrote a script that compares a huge set of images (more than 4500 files) against each other using a root mean square comparison. At first it resizes each image to 800x600 and takes a histogram. After that it builds an array of combinations and distributes them evenly to four threads which calculate the root mean square of every combination. Images with a RMS below 500 will be moved into folders to be manually sorted out later.This works but the comparison runs for hours after completing the resizes within 15 to 20 minutes. At first I assumed that it was a locking queue from which the workers got their combinations so I replaced it with pre-defined array chunks. This did not reduce the execution time. I also ran it without moving the files to exclude a possible hard drive issue.Profiling this using cProfile provides the following output.The full profiler output can be found here.Considering the fourth line I'm guessing that the threads are somehow locking. But why and why exactly 51 times regardless of the amount of images?I am running this on Windows 7 64 bit.Thanks in advance.
One major issue is that you're using threads to do work that is at least partially CPU-bound. Because of the Global Interpreter Lock, only one CPython thread can ever run at a time, which means you can't take advantage of multiple CPU cores. This will make multi-threaded performance for CPU-bound tasks at best no different from single-core execution, and probably even worse, because of the extra overhead added by threading. This is noted in the threading documentation:CPython implementation detail: In CPython, due to the Global  Interpreter Lock, only one thread can execute Python code at once  (even though certain performance-oriented libraries might overcome  this limitation). If you want your application to make better use of  the computational resources of multi-core machines, you are advised to  use multiprocessing. However, threading is still an appropriate model  if you want to run multiple I/O-bound tasks simultaneously.To get around the limitations of the GIL, you should do as the docs say, and use the multiprocessing library instead of the threading library:As you can see, multiprocessing for the most part is a drop-in replacement for threading, so the changes shouldn't be too difficult to make. The only complication would be if any of the arguments you're passing between processes aren't picklable, though I think all of them are in your case. There is also an increased cost of IPC to send Python data structures between processes, but I suspect the benefit of truly parallel computations will outweigh that additional overhead.All that said, you may be still somewhat I/O bound here, because of reliance on reads/writes to disk. Parallelizing won't  make your disk I/O faster, so there's not much that can be done there.
With 4500 images to compare, I would suggest multiprocessing on a file-level, not (necessarily) multithreading within the image. As @dano has pointed out, the GIL will get in the way for that. My strategy would be:one worker process per core (or configured number);one orchestration process, which forks off the above; does some IPC to coordinate jobs to workers.Looking (briefly) at your code looks like it would benefit from a lazy language; I don't see that makes any attempt to short-circuit comparisons. For example, if you do the RMS comparison for each segment of an image, you can stop comparing once you end comparing chunks once you determine they are sufficiently different. You might then also care to change the way you iterate through the chunks, and the size/shape of the chunks.Apart from that, I would consider looking at cheaper mechanisms that avoid doing some many square roots; possibly using something that creates an 'approximate' square-root, perhaps using a look-up table.If I'm not mistaken, you could also create an intermediate form (the histogram) that you should keep temporarily. No need to save the 800x600 image.Also, it would be useful to know what you mean be 'equal' with regard to this exercise.


Answer URL
https://docs.python.org/3/library/multiprocessing.html
