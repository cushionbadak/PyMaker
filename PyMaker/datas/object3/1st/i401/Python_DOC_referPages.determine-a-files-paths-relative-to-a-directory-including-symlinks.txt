Natural Text
I have a directory with thousands of descendants (at least 1,000, probably no more than 20,000). Given a file path (which is guaranteed to exist), I want to know where that file can be found inside that directory -- including via symlinks.For example, given:The directory path is /base.The real file path is /elsewhere/myfile./base is a symlink to /realbase/realbase/foo is a symlink to /elsewhere./realbase/bar/baz is a symlink to /elsewhere/myfile.I want to find the paths /base/foo/myfile and /base/bar/baz.I could do this by recursively checking every symlink in /base, but this would be very slow. I'm hoping that there's a more graceful solution.MotivationThis is for a Sublime Text plugin. When the user saves a file, we want to detect whether it is in the Sublime configuration directory. In particular, we want to do so even if the file is symlinked from inside the config directory and the user is editing the file at its physical path (e.g. inside their Dropbox directory). There may be other applications as well.Sublime runs on Linux, Windows, and the Mac OS, and so ideally should the solution.
This, like many things, is more complex than it might appear on the surface.Each entity in the file system points at an inode, which describes the content of the file. Entities are the things you see - files, directories, sockets, block devices, character devices, etc...The content of a single "file" can be accessed via one or more paths - each of these paths is called a "hard link". Hard links can only point at files on the same filesystem, they cannot cross the boundary of a filesystem.It is also possible for a path to address a "symbolic link", which can point at another path - that path doesn't have to exist, it can be another symbolic link, it can be on another filesystem, or it can point back at the original path producing an infinite loop.It is impossible to locate all links (symbolic or hard) that point at a particular entity without scanning the entire tree.Before we get into this... some comments:See the end for some benchmarks. I'm not convinced that this is a significant issue, though admittedly this filesystem is on a 6-disk ZFS array, on an i7, so using a lower spec system will take longer...Given that this is impossible without calling stat() on every file at some point, you're going to struggle coming up with a better solution that isn't significantly more complex (such as maintaining an index database, with all the issues that introduces)As mentioned, we must scan (index) the whole tree. I know it's not what you want to do, but it's impossible without doing this...To do this, you need to collect inodes, not filenames, and review them after the fact... there may be some optimisation here, but I've tried to keep it simple to prioritise understanding.The following function will produce this structure for us:I've produced an example tree that looks like this:The output of this function is:If we are interested in ./c/3, then you can see that just looking at symlinks (and ignoring hard links) would cause us to miss ./a/1...By subsequently searching for the path we are interested in, we can find all other references within this tree:The full source for this demo is below. Note that I've used relative paths to keep things simple, but it would be sensible to update this to use absolute paths. Additionally, any symlink that points outside the tree will not currently have a corresponding link... that's an exercise for the reader.It might also be an idea to collect the data while you're filling the tree (if that's something that would work with your process)... you can use inotify to deal with this nicely - there's even a python module.I've run this on my system out of curiosity. It's a 6x disk ZFS RAID-Z2 pool on an i7-7700K with plenty of data to play with. Admittedly this will run somewhat slower on lower-spec systems...Some benchmarks to consider:A dataset of ~3.1k files and links in ~850 directories.This runs in less than 3.5 seconds, ~80ms on subsequent runsA dataset of ~30k files and links in ~2.2k directories.This runs in less than 30 seconds, ~300ms on subsequent runsA dataset of ~73.5k files and links in ~8k directories.This runs in approx 60 seconds, ~800ms on subsequent runsUsing simple maths, that's about 1140 stat() calls per second with an empty cache, or ~90k stat() calls per second once the cache has been filled - I don't think that stat() is as slow as you think it is!
Symlinks do not admit of shortcuts. You have to know about all relevant FS entries that might point at the file of interest. That corresponds either to creating an empty directory and then listening for all file creation events under it, or to scanning all files currently under it. Run the following.You wind up with a mapping from all symlinked filespecs to a set of aliases by which that filespec may be accessed.A symlink target may be a file or directory, so to properly use the mapping on a given filespec you must repeatedly truncate it, asking if parent directory or an ancestor directory appears in the mapping.Dangling symlinks are not handled specially, they are simply allowed to dangle.You might choose to serialize the mapping, probably in sorted order. If you repeatedly re-scan a large directory, there is an opportunity to remember directory mod times across runs, and avoid re-scanning files in that directory. Unfortunately, you would still have to recurse down into its descendant directories in case any of them had recent changes.Your subtrees may exhibit enough structure to let you avoid recursing more than K levels deep, or avoid descending into a directory whose name matches some regex.If most FS changes are produced by a handful of programs, such as package managers or a build system, then getting those programs to log their actions could yield a performance win. That is, if you do a full scan each midnight, and then you run make in only two out of a thousand directories, you could choose to re-scan just that pair of subtrees.
My first instinct is to have the OS or some service inform you when the file-system tree has changed instead of you looking for the changes.  Essentially don't  reinvent the wheel.Maybe:fswatchfschangeinotifyWindows specific: 5 tools to monitor folder changes


Answer URL
https://docs.python.org/3/library/os.html#os.scandir
