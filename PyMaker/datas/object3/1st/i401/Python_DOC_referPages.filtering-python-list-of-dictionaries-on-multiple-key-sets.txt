Natural Text
Say I have the dictionary:And I have a list called keys:I want to filter myDict based on each value in keys, which would result inAs you can observe in the list dictionary in my_dict list, the duplicate dict values are removed or filtered out from the list and only the first entry for that dict instance is taken in the filtered output. i need to remove the duplicates if the values of both those keys are same.Is there an easy way to do this with dictionary/list comprehension in Python? is there another faster way to achieve this?
You can use itertools.groupby by using a key of (x["first"].lower, x["last"].lower()) to group by and then only takte the 0th element of the grouped values:Output:Caveat:Groupby only works for consecutive keys - if you had a third {'first': 'James', 'middle': 'Smith', 'last': 'JOUle'} at the end of your list he would get it's own entry:Make an iterator that returns consecutive keys and groups from the iterable(from the doku, link above) You would need to sort your list first to group then consecutively if you wanted them all in the same group.
First of all, call it my_list instead of my_dict.Then, you could achieve your goal with this comprehension: By grouping the elements by first and last name, the duplicates will be excluded. Later you just have to cast it to a list again if you need it that way.And by using OrderedDict you can preserve the original order.I also used .lower() to find case insensitive duplicates.
The solution below does not demand any import statements and is capable of being case insensitive. It also considers only the fields supplied in the keys list and ignores all other fields while matching ( the solution provided by Mstaino takes all fields into account while matching, regardless of what may be in your keys list ).If you want to eliminate only consecutive repetitions ( like in the solution provided by Patrick Artner ) you must declare filtered_dict in the following way:
One solution would be to use a pandas dataframe like below. This would allow for dropping rows of duplicates very much like a CSV file. This does not take into account the case sensitivity though, if you need case insensitive duplicate dropping, that would be a different method. But this works pretty well. 
First, clarify that you want to filter case non sensitive.A python solution to filter upper-lower:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.groupby
