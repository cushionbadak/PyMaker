Natural Text
I want to use Python to copy a local file up to several remote hosts in parallel. I'm trying to do that with asyncio and Paramiko, since I'm already using these libraries for other purposes in my program.I'm using BaseEventLoop.run_in_executor() and the default ThreadPoolExecutor, which is effectively a new interface to the old threading library, along with Paramiko's SFTP feature to do the copying.Here's a simplified example of how.The problem I'm seeing is that the file gets copied up serially to the hosts instead of in parallel. So if the copy takes 5 seconds for a single host, it takes 10 seconds for two hosts, and so on.I've tried various other approaches, including ditching SFTP and piping the file to dd on each of the remote hosts via exec_command(), but the copies always happen serially.I'm probably misunderstanding some basic idea here. What's keeping the different threads from copying the file in parallel?From my testing, it appears that the holdup happens on the remote write, not on reading the local file. But why would that be, since we are attempting network I/O against independent remote hosts?
There is nothing wrong with your usage of asyncio.To prove it, let's try a simplified version of your script - no paramiko, just pure Python.With two threads, this will print:This concurrency scales up to 5 threads:If we add one more thread, we hit the thread pool limit:Everything goes as expected, and overall time grows by 1 second for every 5 items. Magic number 5 is documented in ThreadPoolExecutor docs:Changed in version 3.5: If max_workers is None or not given, it will default to the number of processors on the machine, multiplied by 5, assuming that ThreadPoolExecutor is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for ProcessPoolExecutor.How can a third-party library block my ThreadPoolExecutor?Library uses some kind of global lock. It means that library does not support multi-threading. Try using ProcessPoolExecutor, but with caution: library may contain other anti-patterns, such as using the same hardcoded temporary file name.Function executes for a long time and doesn't release GIL. It may indicate a bug in C extension code, but the most popular reason to holding the GIL is doing some CPU-intensive computations. Again, you can try ProcessPoolExecutor, as it isn't affected by GIL.None of these is expected to happen with a library like paramiko.How can a third-party library block my ProcessPoolExecutor?It usually can't. Your tasks are executed in separate processes. If you see that two tasks in ProcessPoolExecutor take twice as much time, suspect resource bottleneck (such as consuming 100% of the network bandwidth).
I'm not sure this is the best way to approach it, but it works for mebased on comment, added a datestamp and captured the output from multiprocessing and got this:


Answer URL
https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor
https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor
https://docs.python.org/3/library/asyncio-eventloop.html#asyncio.BaseEventLoop.run_in_executor
