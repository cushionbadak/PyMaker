Natural Text
I have 500 text files in one directory.I have to find 500 most frequent words in all of the text files combined.How can I achieve that?PS: I have searched a lot but could not find a solution.
Use collections.Counter:Of course, it will read every file found in that directory. If that's not the intended behavior, use glob.glob or glob.iglob with the required pattern instead of os.listdir (see Reut's comment to my answer).
This is the most straightforward way I could think of using a dictionary for the count, with the key as the word ad the value for the count:Using collections.Counter (as Padraic suggested):
You could create a counter for each new word, and an array of words. Add each New word to the array. Compare each word In the text file(s) to the words in the array using "index of", increment the counter for the word. Or you could create one array, populate with every NEW word from the text files, use second element of the array as a counter. 
We can use Counter method from collections module.Read only text files from target directory by globIterate all files from step 1 by for loop.Open file in read mode by with statement and read() method of file object.Split content of file by split() method of string and use Counter to create countable dictionary. Add add two counters together. https://docs.python.org/2/library/collections.htmlGet most common word from the Counter by most_common(3) method.code:output:-


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
https://docs.python.org/3/library/glob.html
