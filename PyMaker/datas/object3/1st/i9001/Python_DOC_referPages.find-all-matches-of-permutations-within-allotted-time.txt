Natural Text
I'm writing a program that takes 9 characters, creates all possible permutations, and grabs a dictionary files for each character and then creates a set of all possible words. What I need to do is compare all permutations to words and return matches. The problematic function is this one: This code should return: If I get this code to work properly, it takes 10 - 15 minutes to complete. On the other hand, every attempt at making this execute within allotted time, it can only be done with 5 or less characters or returns the wrong result. So my question is how to optimize this code to return the right result, within 30 seconds time. Edithttp://www.mso.anu.edu.au/~ralph/OPTED/v003 this is the website I'm scraping the dictionary files from. 
It wastes RAM and time storing all the permutations in a list before you test if they're valid. Instead, test the permutations as you generate them, and save the valid ones into a set to eliminate duplicates. Duplicates are possible because of the way itertools.permutations works:Elements are treated as unique based on their position, not on their  value. So if the input elements are unique, there will be no repeat  values in each permutation.Your input word "SMOKEJACK" contains 2 Ks, so every permutation containing K gets generated twice.Anyway, here's some code that uses the SOWPODS Scrabble word list for English.outputThis code runs in around 2.5 seconds on my rather ancient 32 bit 2GHz machine running Python 3.6.0 on Linux. It's slightly faster on Python 2 (since Python2 strings are ASCII, not Unicode).
Instead of generating all the permutations of your letters, you should use a Prefix Tree, or Trie, to keep track of all the prefixes to valid words. We are using d["."] = None here to signify where a prefix actually becomes a valid word. Creating the tree can take a few seconds, but you only have to do this once.Now, we can go through our letters in a recursive function, checking for each letter whether it contributes to a valid prefix in the current stage of the recursion: (That rest = letters[:i] + letters[i+1:] part is not very efficient, but as we will see it does not matter much.)Minimal example:Or with your 9 letters and the words from sowpods.txt:You have to pipe the result through a set as you have duplicate letters. This yields 153 words, after a total of 623 recursive calls to find_words (measured with a counter variable). Compare that to 216,555 words in the sowpods.txt file and a total of 986,409 permutations of all the 1-9 letter combinations that could make up a valid word. Thus, once the trie is initially generated, res = set(find_words(...)) takes only a few milli seconds.You could also change the find_words function to use a mutable dictionary of letter counts instead of a string or list of letters. This way, no duplicates are generated and the function is called fewer times, but the overall running time does not change much.Then call it like this: find_words(trie, collections.Counter("SMOKEJACK"))


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.permutations
