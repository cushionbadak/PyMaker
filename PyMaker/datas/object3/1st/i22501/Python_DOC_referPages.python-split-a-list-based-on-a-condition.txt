Natural Text
What's the best way, both aesthetically and from a performance perspective, to split a list of items into multiple lists based on a conditional? The equivalent of:is there a more elegant way to do this?Update: here's the actual use case, to better explain what I'm trying to do:
is there a more elegant way to do this?That code is perfectly readable, and extremely clear!Again, this is fine!There might be slight performance improvements using sets, but it's a trivial difference, and I find the list comprehension far easier to read, and you don't have to worry about the order being messed up, duplicates being removed as so on.In fact, I may go another step "backward", and just use a simple for loop:The a list-comprehension or using set() is fine until you need to add some other check or another bit of logic - say you want to remove all 0-byte jpeg's, you just add something like..

Here's the lazy iterator approach:It evaluates the condition once per item and returns two generators, first yielding values from the sequence where the condition is true, the other where it's false.Because it's lazy you can use it on any iterator, even an infinite one:Usually though the non-lazy list returning approach is better:Edit: For your more specific usecase of splitting items into different lists by some key, heres a generic function that does that:Usage:
Problem with all proposed solutions is that it will scan and apply the filtering function twice. I'd make a simple small function like this:That way you are not processing anything twice and also are not repeating code.
My take on it. I propose a lazy, single-pass, partition function,which preserves relative order in the output subsequences.1. RequirementsI assume that the requirements are:maintain elements' relative order (hence, no sets anddictionaries)evaluate condition only once for every element (hence not using(i)filter or groupby)allow for lazy consumption of either sequence (if we can afford toprecompute them, then the naïve implementation is likely to beacceptable too)2. split libraryMy partition function (introduced below) and other similar functionshave made it into a small library:python-splitIt's installable normally via PyPI:To split a list base on condition, use partition function:3. partition function explainedInternally we need to build two subsequences at once, so consumingonly one output sequence will force the other one to be computedtoo. And we need to keep state between user requests (store processedbut not yet requested elements). To keep state, I use two double-endedqueues (deques):SplitSeq class takes care of the housekeeping:Magic happens in its .getNext() method. It is almost like .next()of the iterators, but allows to specify which kind of element we wantthis time. Behind the scene it doesn't discard the rejected elements,but instead puts them in one of the two queues:The end user is supposed to use partition function. It takes acondition function and a sequence (just like map or filter), andreturns two generators. The first generator builds a subsequence ofelements for which the condition holds, the second one builds thecomplementary subsequence. Iterators and generators allow for lazysplitting of even long or infinite sequences.I chose the test function to be the first argument to facilitatepartial application in the future (similar to how map and filterhave the test function as the first argument).
First go (pre-OP-edit): Use sets:That's good for both readability (IMHO) and performance.Second go (post-OP-edit):Create your list of good extensions as a set:and that will increase performance.  Otherwise, what you have looks fine to me.
I basically like Anders' approach as it is very general.  Here's a version that puts the categorizer first (to match filter syntax) and uses a defaultdict (assumed imported).
itertools.groupby almost does what you want, except it requires the items to be sorted to ensure that you get a single contiguous range, so you need to sort by your key first (otherwise you'll get multiple interleaved groups for each type).  eg.gives:Similar to the other solutions, the key func can be defined to divide into any number of groups you want.
Personally, I like the version you cited, assuming you already have a list of goodvals hanging around.  If not, something like:Of course, that's really very similar to using a list comprehension like you originally did, but with a function instead of a lookup:In general, I find the aesthetics of list comprehensions to be very pleasing.  Of course, if you don't actually need to preserve ordering and don't need duplicates, using the intersection and difference methods on sets would work well too.
If you want to make it in FP style:Not the most readable solution, but at least iterates through mylist only once.
Check this
I think a generalization of splitting a an iterable based on N conditions is handyFor instance: If the element may satisfy multiple conditions, remove the break. 
Sometimes, it looks like list comprehension is not the best thing to use !I made a little test based on the answer people gave to this topic, tested on a random generated list. Here is the generation of the list (there's probably a better way to do, but it's not the point) :And here we goUsing the cmpthese function, the best result is the dbr answer :
Yet another solution to this problem. I needed a solution that is as fast as possible. That means only one iteration over the list and preferably O(1) for adding data to one of the resulting lists. This is very similar to the solution provided by sastanin, except much shorter:Then, you can use the function in the following way:If you're not fine with the resulting deque object, you can easily convert it to list, set, whatever you like (for example list(lower)). The conversion is much faster, that construction of the lists directly.This methods keeps order of the items, as well as any duplicates.
For perfomance, try itertools.The itertools module standardizes a core set of fast, memory efficient tools that are useful by themselves or in combination. Together, they form an “iterator algebra” making it possible to construct specialized tools succinctly and efficiently in pure Python.See itertools.ifilter or imap.itertools.ifilter(predicate, iterable)Make an iterator that filters elements from iterable returning only those for which the predicate is True
Sometimes you won't need that other half of the list.For example:
Inspired by @gnibbler's great (but terse!) answer, we can apply that approach to map to multiple partitions:Then splitter can then be used as follows:This works for more than two partitions with a more complicated mapping (and on iterators, too):Or using a dictionary to map:
This is the fastest way.It uses if else, (like dbr's answer) but creates a set first. A set reduces the number of operations from O(m * n) to O(log m) + O(n), resulting in a 45%+ boost in speed.A little shorter:Benchmark results:The full benchmark code for Python 3.7 (modified from FunkySayu):
If you insist on clever, you could take Winden's solution and just a bit spurious cleverness:
If your concern is not to use two lines of code for an operation whose semantics only need once you just wrap some of the approaches above (even your own) in a single function:It is not a lazy-eval approach and it does iterate twice through the list, but it allows you to partition the list in one line of code.
Already quite a few solutions here, but yet another way of doing that would be -Iterates over the list only once, and looks a bit more pythonic and hence readable to me. 
I'd take a 2-pass approach, separating evaluation of the predicate from filtering the list:What's nice about this, performance-wise (in addition to evaluating pred only once on each member of iterable), is that it moves a lot of logic out of the interpreter and into highly-optimized iteration and mapping code. This can speed up iteration over long iterables, as described in this answer.Expressivity-wise, it takes advantage of expressive idioms like comprehensions and mapping.
solutiontest
If you don't mind using an external library there two I know that nativly implement this operation:iteration_utilities.partition:more_itertools.partition
Not sure if this is a good approach but it can be done in this way as well
For example, splitting list by even and oddOr in general:Advantages:Shortest posible wayPredicate applies only once for each elementDisadvantagesRequires knowledge of functional programing paradigm
If the list is made of groups and intermittent separators, you can use:Usage:

My favorite recipe for this is: Simple, fast, and readable; the way Python was meant to be.By making goodvals into a set (which uses a hash table) instead of atuple, we get super fast lookups. Each item in mylist is checked onlyonce. this helps make it faster._ = is a Pythonic way to declare that we are discarding the result of the list comprehension on purpose. It's not a bug.(Based on dansalmo's comment to this answer, because it seems to deserve to be its own answer.)EDIT: Converting goodvals into a set turbocharges performance by 55% on my benchmark. Using a tuple is O(n * m), while converting it into a set is O(log n + m). Besides, goodvals, (i.e. n), is only five items long. mylist, (i.e. m), can have hundreds of items. Furthermore, creating a set is probably highly optimized under the hood in C language code.Here is the benchmark code that I used. It is based on code taken from this answer and modified to work with Python v3.7.0 running on Windows 7. 


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
