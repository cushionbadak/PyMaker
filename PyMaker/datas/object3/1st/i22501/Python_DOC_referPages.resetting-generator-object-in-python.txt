Natural Text
I have generator object returned by multiple yield. Preparation to call this generator is rather time-consuming operation. That is why I want to reuse generator several times.Of course, I'm taking in mind copying content into simple list. 
Another option is to use the itertools.tee() function to create a second version of your generator:This could be beneficial from memory usage point of view if the original iteration might not process all the items.
Generators can't be rewound. You have the following options:Run the generator function again, restarting the generation:Store the generator results in a data structure on memory or disk which you can iterate over again:The downside of option 1 is that it computes the values again. If that's CPU-intensive you end up calculating twice. On the other hand, the downside of 2 is the storage. The entire list of values will be stored on memory. If there are too many values, that can be unpractical.So you have the classic memory vs. processing tradeoff. I can't imagine a way of rewinding the generator without either storing the values or calculating them again.

Probably the most simple solution is to wrap the expensive part in an object and pass that to the generator:This way, you can cache the expensive calculations.If you can keep all results in RAM at the same time, then use list() to materialize the results of the generator in a plain list and work with that.
I want to offer a different solution to an old problemThe benefit of this when compared to something like list(iterator) is that this is O(1) space complexity and list(iterator) is O(n). The disadvantage is that, if you only have access to the iterator, but not the function that produced the iterator, then you cannot use this method. For example, it might seem reasonable to do the following, but it will not work.
If GrzegorzOledzki's answer won't suffice, you could probably use send() to accomplish your goal. See PEP-0342 for more details on enhanced generators and yield expressions.UPDATE: Also see itertools.tee(). It involves some of that memory vs. processing tradeoff mentioned above, but it might save some memory over just storing the generator results in a list; it depends on how you're using the generator.
From official documentation of tee:In general, if one iterator uses most or all of the data before  another iterator starts, it is faster to use list() instead of tee().So it's best to use list(iterable) instead in your case.
If your generator is pure in a sense that its output only depends on passed arguments and the step number, and you want the resulting generator to be restartable, here's a sort snippet that might be handy:outputs:
You can define a function that returns your generatorNow you can just do as many times as you like:
There is no option to reset iterators. Iterator usually pops out when it iterate through next() function. Only way is to take a backup before iterate on the iterator object. Check below.Creating iterator object with items 0 to 9Iterating through next() function which will pop outConverting the iterator object to listso item 0 is already popped out. Also all the items are popped as we converted the iterator to list.So you need to convert the iterator to lists for backup before start iterating.List could be converted to iterator with iter(<list-object>)
You can now use more_itertools.seekable (a third-party tool) which enables resetting iterators.Install via > pip install more_itertoolsNote: memory consumption grows while advancing the iterator, so be wary of large iterables.  
I'm not sure what you meant by expensive preparation, but I guess you actually haveIf that's the case, why not reuse data?
Ok, you say you want to call a generator multiple times, but initialization is expensive... What about something like this?Alternatively, you could just make your own class that follows the iterator protocol and defines some sort of 'reset' function.https://docs.python.org/2/library/stdtypes.html#iterator-typeshttp://anandology.com/python-practice-book/iterators.html
Using a wrapper function to handle StopIterationYou could write a simple wrapper function to your generator-generating function that tracks when the generator is exhausted. It will do so using the StopIteration exception a generator throws when it reaches end of iteration.As you can spot above, when our wrapper function catches a StopIteration exception, it simply re-initializes the generator object (using another instance of the function call).And then, assuming you define your generator-supplying function somewhere as below, you could use the Python function decorator syntax to wrap it implicitly:
It can be done by code object. Here is the example.12341234


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.tee
