Natural Text
(This question is related to this one and this one, but those are pre-walking the generator, which is exactly what I want to avoid)I would like to split a generator in chunks. The requirements are:do not pad the chunks: if the number of remaining elements is less than the chunk size, the last chunk must be smaller.do not walk the generator beforehand: computing the elements is expensive, and it must only be done by the consuming function, not by the chunkerwhich means, of course: do not accumulate in memory (no lists)I have tried the following code:And this somehow works:Buuuut ... it never stops (I have to press ^C) because of the while True. I would like to stop that loop whenever the generator has been consumed, but I do not know how to detect that situation. I have tried raising an Exception:But then the exception is only raised in the context of the consumer, which is not what I want (I want to keep the consumer code clean)How can I detect that the generator is exhausted in the chunks function, without walking it?
One way would be to peek at the first element, if any, and then create and return the actual generator.Just use this in your chunk generator and catch the StopIteration exception like you did with your custom exception.Update: Here's another version, using itertools.islice to replace most of the head function, and a for loop. This simple for loop in fact does exactly the same thing as that unwieldy while-try-next-except-break construct in the original code, so the result is much more readable.And we can get even shorter than that, using itertools.chain to replace the inner generator:
Another way to create groups/chunks and not prewalk the generator is using itertools.groupby on a key function that uses an itertools.count object. Since the count object is independent of the iterable, the chunks can be easily generated without any knowledge of what the iterable holds.Every iteration of groupby calls the next method of the count object and generates a group/chunk key (followed by items in the chunk) by doing an integer division of the current count value by the size of the chunk.Each group/chunk g yielded by the generator function is an iterator. However, since groupby uses a shared iterator for all groups, the group iterators cannot be stored in a list or any container, each group iterator should be consumed before the next.
Fastest possible solution I could come up with, thanks to (in CPython) using purely C-level builtins. By doing so, no Python byte code is needed to produce each chunk (unless the underlying generator is implemented in Python) which has a huge performance benefit. It does walk each chunk before returning it, but it doesn't do any pre-walking beyond the chunk it's about to return:Since that's a bit dense, the spread out version for illustration:Wrapping a call to chunker in enumerate would let you number the chunks if it's needed.
How about using itertools.islice:Which gives:

Started to realize the usefulness of this scenario when crafting a solution to DB insertion of 500k+ rows at higher speed.A generator processes the data from source and "yield"s it line by line; and then another generator groups the output in chunks and "yield "s it chunk by chunk.  The second generator is only aware of the chunk size and nothing more.Below is a sample to highlight the concept:Tested in Python 2.7.12:
I had this same issue, but found a simpler solution than those mentioned here:
You've said you don't wish to store things in memory, so does this mean that you can't build an intermediate list for the current chunk?Why not traverse the generator and insert a sentinel value between chunks? The consumer (or a suitable wrapper) could ignore the sentinel:
EDIT other solution with a generator of generatorsYou should not do a while True in your iterator, but simply iterate through it and update the chunk number at each iteration :If you want a generator of generators, you can have :with a being an iterable.Tests : on python 2.7 and 3.4:gives :And on 2.7 :gives same result.But BEWARE : list(chunk(range(7)) blocks on 2.7 and 3.4
Inspired by Moses Koledoye's answer, I tried to make a solution that uses itertools.groupby but doesn't require a divide at each step.The following function can be used as a key to groupby, and it simply returns a boolean, which flips after a pre-defined number of calls.Which can be used like this:Output:I've made a fiddle demonstrating this code. 


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.groupby
https://docs.python.org/3/library/itertools.html#itertools.count
https://docs.python.org/3/library/itertools.html#itertools.groupby
