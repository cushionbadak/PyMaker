Natural Text
This question already has an answer here:How might I remove duplicate lines from a file?                    11 answers                I'm trying to have my function go through sorted text on Insults.txt and determine if there are duplicates and return false if there are, but I cannot seem to get it working. I am only trying to detect duplicates, not remove them! Does anybody know what I am doing wrong?
Try this, I am not sure why you are having numInsults
Mine's a lazier approach, as its execution will stop as soon as it finds a duplicate.
I'm not sure why you are limiting the numInsults either, if you want to check the whole file, if the number of lines is greater than 1K. Alternative (run through file line by line):This function will take all the lines in Insults.txt into a list. 'Check' is a set, which will only keep unique items in the 'lines' list. If the lines list is equal to the check list, there are no duplicates, and return False. If the check list is smaller than the lines list, you know there were duplicates, and will return True. Alternatively, you can use bash (don't know your OS). Just to point out there are faster/simpler ways to do this, unless your python script will utilize the unique list of insults from the file in other ways: sort Insults.txt | uniq -cThis is similar to what you can do with Counter from collections in Python, which will give you a count of all the lines in the file. 
What is happeningInitially, i is 0.  Is a one-element list that contains 0 equal to a one-element list that contains 1?  Clearly not.  So execution goes to the else clause, and the function returns True.It doesn't even care about the length or the contents of the file, as long as it exists and is readable.A working solutionTake a cue from the itertools recipe for pairwise(iterable), which produces pairs (line1, line2), (line2, line3), (line3, line4), etc.Also, use the any() function to simplify the inner loop.
If you need to return if there are any dupes we can take your function and  simplify a little bit:Basically we do two things: take all lines in txt and make them a list, check that the number of items in that list are the same as the number of items in a collection of unique elements of that listIf they're not the same, there must be dupes!


Answer URL
https://docs.python.org/3/library/itertools.html#itertools-recipes
https://docs.python.org/3/library/functions.html#any
