Natural Text
I scraped several e-commerce websites (more than 5) and the data is stored in a large json file as a list of dictionaries, like this:The list is composed of more than 11k dictionaries. Given that all the data is standardized, how can I search through it for best results?Is it better to use Regex or to index the json file with something like Whoosh?For example, when somebody is looking for galaxy s7 case I want to return the relevant data. Thanks!
Small nitpick:  Those are JSON "objects", not "dictionaries".  They'll turn into dictionaries when you do json.loads(...).As for your question - try it!  You can cut down the list to, say, 10,000 items, then test each implementation, regex, list comprehension, Whoosh, haystack, etc., and see how fast they are, with the timeit module.As what you're trying to do is a search over a large amount of products, I'd suggest looking into a search engine.  Some good ones I've used are solr and xapian, though if you're already familiar with Whoosh, it certainly sounds like the best option you proposed.


Answer URL
https://docs.python.org/3/library/timeit.html
