Natural Text
In this example, I show two different methods for creating a list of strings using Cython. One uses an array of char pointers (and the strcpy C function) and the other by simply appending elements to a list.I then pass each of these lists into the set function and see that performance is drastically different.Question - What can I do to create the list using character pointers to have equal performance?A simple function to create lists in CythonHere, c_list is just an array of 3-length characters. Cython will return this object as a Python list. py_list is just a normal Python list. We are filling both lists with just a single sequence of bytes, 'AB'.Create the listsPrint out some of the contentsShow both lists are equalTime operations - this is insane to me! 3x differenceUnicode and pure pythonInterestingly, the performance difference vanishes if I decode each value to unicode, though it is slower than the original set(py_list). If I create a unicode list in pure Python then I am back to the original performance.Even simpler exampleTimingseditPossible solutionI found the function PyUnicode_InternFromString in the unicode Python C API and am getting performance on par with regular python lists. This 'interns' the string - not sure what that means
Your c_list is a list of 100000 distinct bytestrings with the same contents. Cython has to convert each char[3] to a bytestring separately, and it doesn't bother to do any object deduplication.Your py_list is a list of the same bytestring object 100000 times. Every py_list.append(b'AB') appends the same object to py_list; without the trip through a C array, Cython never needs to copy the bytestring.set(c_list) is slower than set(py_list) because set(c_list) has to actually perform string comparison, while set(py_list) gets to skip that with an object identity check.


Answer URL
https://docs.python.org/3/c-api/unicode.html#c.PyUnicode_InternFromString
