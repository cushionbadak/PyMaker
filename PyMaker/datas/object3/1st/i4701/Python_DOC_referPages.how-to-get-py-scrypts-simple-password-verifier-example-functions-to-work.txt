Natural Text
I am using the example script provide by py-scrypt to build a simple password verifier. Below is my test script.Test Script:Issues:I often get an error messages, e.g.:where the last lines varies to e.g.:oror no error message but return FalseWhen I comment return scrypt.encrypt(os.urandom(datalength), password, maxtime=maxtime) to remove the random secret message generator and uncomment return scrypt.encrypt(a_secret_message, password, maxtime=maxtime) to use a non-random secret message, the function verify2_password works.Question: How do I get the random secret message element to work?   What is causing it's failure?
Explanation for UnicodeDecodeError ExceptionReason 1I think I understand why Scrypt is issuing a UnicodeDecodeError. Quoting Python's UnicodeDecodeError :The UnicodeDecodeError normally happens when decoding an str string  from a certain coding. Since codings map only a limited number of str  strings to unicode characters, an illegal sequence of str characters  will cause the coding-specific decode() to fail.Also in Python's Unicode HOWTO section Python’s Unicode Support --> The String Type, it writesIn addition, one can create a string using the decode() method of  bytes. This method takes an encoding argument, such as UTF-8, and  optionally an errors argumentThe errors argument specifies the response when the input string can’t  be converted according to the encoding’s rules. Legal values for this  argument are 'strict' (raise a UnicodeDecodeError exception),  'replace' (use U+FFFD, REPLACEMENT CHARACTER), 'ignore' (just leave  the character out of the Unicode result), or 'backslashreplace'  (inserts a \xNN escape sequence).In short, whenever Python's .decode() method fails to map str strings to unicode characters, and when it uses the strict argument, the .decode() method will return a UnicodeDecodeError exception. I tried to find the .decode() method in the .decrypt() method of py-scrypt/scrypt/scrypt.py. Initially, I could not locate it. For Python3, the .decrypt() method  return statement was:return str(out_bytes, encoding)However, further checking Python's explanation on the str class, I found the explanation saying that:if object is a bytes (or bytearray) object, then str(bytes, encoding,  errors) is equivalent to bytes.decode(encoding, errors).This meant that without defining the error argument in str(bytes, encoding), this str class defaulted to returning bytes.decode(encoding, errors='strict') and returned the UnicodeDecodeError exception whenever it failed to map str strings to unicode characters.Reason 2In the "simple password verifier" example, the input argument of Scrypt.encrypt() was defined as os.urandom(datalength) which returned a <class 'bytes'>.  When this <class 'bytes'> was encrypted, and subsequently decrypted by Scrypt.decrypt(), the returned decrypted value must also be a <class 'bytes'> . According to the doc_string of the .decrypt() method, for Python3 this method will return a str instance if encoded with encoding. If encoding=None, it will return a bytes instance. As Script.decrypt() defaults to encoding='utf-8' in function verify2_password(), Script.decrypt() attempts to return a <class str> resulted in the UnicodeDecodeError. Solution to the "simple password verifier" example script given in py-scrypt:The verify_password() function should contain the argument encoding=None .scrypt.decrypt() should contain the argument encoding=encoding .Revised Example Script:


Answer URL
https://docs.python.org/3/library/stdtypes.html?highlight=str#str
