Natural Text
The task is to average the image pixels on the values of the neighbours in a 3X3 window.The image is a standard image of 2.5 MB.In order to avoid the edge cases, i give them a value of -1 and filter them out.When running the program it terminates after 624 seconds. Why is it so slow?The program looks very minimalistic but i am sure i miss something.Here is the profiler data. It looks like the standard operations i want to do take much time. Is it possible to do it faster?The line function_base.py:436(average) is intersting. It looks like it takes most of the time.
I would try to replace the generic_filter method with a more general and maybe better suited solution. What you are basically trying to do is a convolution with a kernel of size 3x3x1 and values 1/9:[UPDATE]To respect the original image size you could use the mode 'same' instead of 'valid' for fftconvolve. This will automatically zero pad your image. However to get better results at the boundaries of the image pad the image with one of the modes promoted by numpy's pad functionand use the fftconvolve mode 'valid' on the alternately padded image.[/UPDATE]I am not sure if it will run a lot faster but it should at least compensate the method call overhead.On a test image with 4876x2278 pixels the code needs ~40 seconds (Hard drive is an SSD)Best regards


Answer URL
https://docs.python.org/3/library/profile.html
