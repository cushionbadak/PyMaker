Natural Text
I am saving RandomForestClassifier model from sklearn library with code belowIt takes a lot of space on my hard drive. There are only 50 trees in the model, however it takes over 50 MB on disk (analyzed dataset is ~ 20MB, with 21 features). Does anybody have idea why? I observe similar behavior for ExtraTreesClassifier.Edit:The RF parameters:As suggested by @dooms I checked the sys.getsizeof and it returns 64 - I assume that this is only pointer size.I tried other way to save a model:By using this way I get 1 *.pkl file and 201 *.npy files with total size 14.9 MB, so smaller than previous 53 MB. There is a pattern in these 201 npy files - there 4 files per tree in Forest:The first file (231 KB) content:The second file (66 kB) content:The third file (88B):The last file from group (96B):Any ideas what it is? I tried to look into the Tree code in sklearn, but it is hard. Any ideas how to save sklearn tree that it store less disk? (just to point that similar size ensemble of xgboost took ~200KB total size)
I've seen the same behavior using pickle dumps. The dump is about 10s times bigger that the size in memory.See if there is a huge difference and if it's the case, see another way to save your model.


Answer URL
https://docs.python.org/3/library/sys.html#sys.getsizeof
