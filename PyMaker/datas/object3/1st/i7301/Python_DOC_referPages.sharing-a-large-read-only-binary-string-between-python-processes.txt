Natural Text
This question already has an answer here:multiprocessing: sharing a large read-only object between processes?                    8 answers                I have a large, read-only bytes object that I need to operate against across several different Python (3) processes, with each one "returning" (adding to a result queue) a list of results based on their work.Since this object is very large and read-only, I'd like to avoid copying it into the address space of each worker process. The research I've done suggests that shared memory is the right way to go about this, but I couldn't find a good resource/example of how exactly to do this with the multiprocessing module.Thanks in advance.
You can use a multiprocessing.Array, which is like ctypes.Array but for shared memory, when given a ctypes type.For example:


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Array
https://docs.python.org/3/library/ctypes.html#ctypes.Array
