Natural Text
I have a dictionary like below:And I want to change it to my desired output like below to calculate score of similarity between two target words:the first line is the target word and its frequency in the whole dictionary. Underneath is the associated words and their frequency in same sentence with target word. Like the first dictionary, the profile associated with "mississippi" will contain references to "worth" and "reading" and their word frequency in sentence is 1, but the word frequency of mississippi is 3 in entire dictionary. And I want to sort the word frequency of target word in descending order. Anyone can help?                   
It's not exactly clear neither from your desired output nor from your code what exactly are you trying to achieve but if it's just counting words in individual sentences then the strategy should be:Read your common.txt into a set for a fast lookup.Read your sample.txt and split on . to get individual sentences.Clear up all non-word characters (you'll have to define them or to use regex \b to capture word boundaries) and replace them with whitespace.Split on whitespace and count the words not present in the set from Step 1.So:NOTE: On Python 2.x use string.maketrans() instead of str.maketrans().This will produce sentences_counter containing a dictionary count for each of the sentences in sample.txt, where the key is an actual word and its associate value is the word count. You can print the result as:Which will produce (for your sample data):Keep in mind that (English) language is more complex than this - for example, "A cat wiggles its tail when it's angry so stay away from it." will vastly differ in dependence on how you treat an apostrophe. Also, a dot doesn't necessarily denote the end of a sentence. You should look into NLP if you want to do serious linguistic analysis.UPDATE: While i don't see the usefulness of reiterating over each word repeating the data (the count won't ever change within a sentence) if you want to print each word and nest all the other counts underneath you can just add an inner loop while printing:Which will give you:Feel free to remove the sentence number printing and reduce one of the tab indentations to get something more of a desired output from your question. You can also build a tree-like dictionary instead of printing everything to the STDOUT if that's more what you fancy.UPDATE 2: If you want, you don't have to use a set for the common_words. In this case it's pretty much interchangeable with a list so you can use list comprehension instead of set comprehension (i.e. replace curly with square brackets) but looking through a list is an O(n) operation whereas set lookup is an O(1) operation and therefore a set is preferred here. Not to mention the collateral benefit of automatic de-duplication in case the common.txt has duplicate words.As for the collections.defaultdict() it's there just to save us some coding/checking by automatically initializing the dictionary to a key whenever it's requested - without it you'd have to do it manually:UPDATE 3: If you just want a raw word list across all sentences as it seems from your last update to the question, you don't even need to consider the sentences themselves - just add a dot to the interpunction list, read the file line by line, split on whitespace and count the words as before:
Hope below code works in the desired way you need 


Answer URL
https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions
https://docs.python.org/3/tutorial/datastructures.html#sets
https://docs.python.org/3/library/collections.html#collections.defaultdict
