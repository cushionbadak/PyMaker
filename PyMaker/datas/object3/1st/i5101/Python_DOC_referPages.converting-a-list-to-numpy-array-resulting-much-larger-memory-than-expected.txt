Natural Text
I have a list with 2940 elements - each element is a (60, 2094) numpy array. results in :However, if I try to turn this in to a numpy array (which should result in a shape of (2940, 60, 2094), the size of the array is much, much larger.Output:Why is this the case?If I try it with a bigger dataset, I end up with the "Memory" error. 
From the sys.getsizeof docs:Only the memory consumption directly attributed to the object is  accounted for, not the memory consumption of objects it refers to.sys.getsizeof returns the memory consumption of the list object itself, not including the objects contained by the list. A single one of your arrays:The python object wrapping the primitive array adds about 100 bytes.Note, there is always overhead for being an object, note:The actual memory consumption, then is about:And if we had 2940 of them, just those objects would be:If I actually put these all in a list:The list object itself is essentially backed by an array of py_object pointers. On my machine (64bit) a pointer will be one machine word, i.e. 64bits or 8 bytes. So:So sys.getsizeof is only accounting for an array of pointers, plus object overhead, but that isn't even close to accounting for the 3 gigabytes consumed by the array objects being pointed to.Lo and behold:


Answer URL
https://docs.python.org/3/library/sys.html#sys.getsizeof
https://docs.python.org/3/library/sys.html#sys.getsizeof
