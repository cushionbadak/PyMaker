Natural Text
The input is an unsorted list of tuples: The goal is to find the last n keys with the least counts, i.e. desired output:I've tried doing this by:first convert the list of tuples to a dictcast the dict into a Counterthen find the [-n:] list of tuples from the Counter.most_common()cast the list of tuples from the [-n:] to a dictget the keys and then convert it into a listi.e. Is there a less convoluted way to get the same output? I could also do this:But now I've merely swapped out the Counter.most_common with sorted and itemgetter. Then I would still need to zip(*list) to extract the keys through unpacking the first value from each list of tuples after the zip.There must be a simpler way.NOTENote that the question is not asking to sort, it's to extract the list first element in the original list of tuples given. And the criterion to extract is based on the last nth items with the lowest value in the 2nd element.The answers from the possible duplicate linked still requires the step to unpack the list of sorted tuples and and the extract the top nth of the list of first elements. 
The goal is to find the last n keys with the least countsGiven this goal's definition neither of your two solutions fit. In one with Counter you use dict which will make the order of keys undefined and you will not get the last keys, but some n keys with least value. The second solution has incorrect slicing, and if it's fixed it returns first n keys with least value.Taking into account that sorted implementation is stable it can be rewritten like this to fit the goal:But it's a better idea to use heapq, which is the stdlib tool for questions like "n smallest/greatest values from an iterable" (as Martijn Pieters pointed out, nlargest and nsmallest are also stable and the docs really say that, but in implicit way). Especially if the real list you have to deal with is big (for small n it should be faster that sorted as docs describe). You can improve performance even further, but at the cost of order (sorting stability), i.e. some n keys with least value instead of last n keys with least value. To do that you need to keep a "heapified" list and use it as your internal data structure instead of plain list (if you don't change the list and need the bottom-n only once, it will not give a performance benefit). You can push and pop from the list, for example:Here's the complete module you can use to benchmark the solutions. And here are the timeit results:But if we make l = l * 1000 the difference will become noticeable:
Just use a heap, it will give you the desired output.heapq.nsmallest(n, iterable, key=None)has a key argument,you can use it inside of using -index like me.
[k for k,v in sorted(x, key=lambda x: x[1])[:n]]Where x is list of key, count tuples and n is desired number of keys.You may also adjust the sort criteria to include the keys themselves- if their order is important[k for k,v in sorted(x, key=lambda x: (x[1], x[0]))[:n]]
Edit@alvas :Will generate the output you desire You can use this:Please refer to this (possible duplicate)Sort a list of tuples by 2nd item (integer value)
You could use pandas if you don't feel like reinventing the wheel.  Performance should be excellent since it's based on NumPy, which uses C under the hood instead of pure Python.Short answerResultExpanded, working example with comments
[i[0] for i in sorted(x.__reversed__(), key=lambda x: x[1])[:n]]Almost exactly the same as @Stacksonstacks answer, just that this actually gives you the 'desired output' (if you put n = 5)
You don't really need any imports for this task, you can also do it the following way: Output:
Here is my suggestion:   
This is a clean, simple approach without using python idioms: It is kind of like a fusion of min-value search plus filtering. m stores the min value up till now, and l stores the list of elements which have that min count. You reset them when you find a lower value.This can be modified to hold only 5 elements, so no splicing would be required in the end.
A Pure Python Solution Since we are trying to find the n elements in order of min to max, we cannot simply filter out those which do not have the smallest second element. We also have the second aim of trying to maintain order - this eliminates merely sorting on the second element of each tuple.My solution has complexity O(n) - which is the best you can do here as we are creating a new list which is dependent on a pre-existing list.It works by creating a set (unordered) of the first n elements of each tuple in x - after x has been reversed ([::-1]) and then sorted based on the second element. This has the neat trick that since we are slicing before we convert to the set, there is still order within those tuples with equivalent second elements.Now, the neatness of using a set is that lookup is O(1) (instant) as the elements are stored in order of their hashes, so calling __contains__ is much faster than with a list.We finally need to use a list-comprehension to carry out the final filtering of x:Also a test to shows that it works with n = 11
Using list comprehension and sorted:  [key for key,value in sorted(x, key=lambda y: y[1], reverse=True)][-n:]or[key for key,value in sorted(reversed(x), key=lambda y: y[1])][:n][::-1]where n is the number of keys you want in the resultant. Note that using the latter, with [::-1], is more expensive because it slices the list once more to reverse it back.Results with n = 5:Results with n = 11:
No Need of sorting in this solution Small Solution:output of above solution:Explanation of solution with commentsoutput of above explaination:


Answer URL
https://docs.python.org/3/library/functions.html#sorted
https://docs.python.org/3/library/heapq.html
https://docs.python.org/3/library/heapq.html#heapq.nsmallest
https://docs.python.org/3/library/functions.html#sorted
