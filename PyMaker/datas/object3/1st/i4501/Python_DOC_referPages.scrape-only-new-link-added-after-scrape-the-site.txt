Natural Text
I have a code that scrape all links, titles and sizes of products with certain keywords. After the first scrape is done i want the script check again and again if new item are added. I try while True: but it seems doesnt work because gives me the same data multiple time. The script is this:
You are missing ? before currPage, it should look like that: https://www.julian-fashion.com/en-US/men/shoes/sneakers?currPage={}.? indicates a start of the query string. Now your code will work.You also can omit page 0, because this site starts pagination from 1 and providing 0 gives 404 Page not found. Besides that, you don't need while True because you want to execute this block of code only once. For loop takes care of changing pages and it is enough.There is a bug here:you break from the loop if a keyword is not in link.a['href']. Notice that if the first keyword from your list is not there, it doesn't mean one of the next ones won't.Your code after a few fixes:Here is my version of the code, I used .select() instead of .find_all(). This is better, because if the creators of the page will add some new classes to the elements you search for, .select() that uses CSS selectors will still be able to target these elements. I also used urljoin to create absolute links, see here why.Perhaps you wanted the keywords to be the brands to filter items by, if so, you can use the code below instead of checking if the keyword is in the link to the item.instead of:Monitor:To make a simple monitor that checks for new items on the website, you can use the code below and adjust it to your needs:You can test that locally by creating an index.html file with several <li class="product in-stock">, you can copy them from the website. Enter Chrome DevTools, find some lis in the Elements tab. Right-click on one -> Copy -> Copy outerHTML, then paste it into the index.html file. Then in console run: python -m http.server 8000 and run the above script. During the execution, you can add some more items and see their href printed.Example output:


Answer URL
https://docs.python.org/3/library/urllib.parse.html#urllib.parse.urljoin
