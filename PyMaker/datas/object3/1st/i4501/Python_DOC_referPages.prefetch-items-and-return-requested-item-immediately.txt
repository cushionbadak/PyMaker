Natural Text
I need to load a lot of large image data from a network-share for processing (which is not very fast). The images are named following a sequence (e.g. 1.png, 2.png, 3.png, etc.).In most cases, loading will happen in this sequence (loading n+1.png after n.png). I would like to have n+1.png in memory before the actual request.I would like to keep a cache (as well), such that going 1 image back does not require disk access.I envision something like this:Request image with index nCheck if n.png is in cache, if the image is not in cache:a. load the image from diskb. put the image in cachePerform steps 1&2 for image with index n+1Do not wait for step 3 to finish, but take the image from cache and return that imageNice to have feature: clean the cache in the backgound such that it only contains the last requested 10 items, or that it removes the first requested items until it contains a max. of 10 items (I can imagine the latter option is easier to implement while being good enough for my case).I am using Python 3.5. I am using PyQt5, but I prefer the function to not rely on PyQt5 functionality (but if this makes the implementation much more clean/easy/readable I will use it).
The simple answer (assuming you're not using coroutines or the like, which you probably aren't given that you're using PyQt5) is to spawn a daemon background thread to load image n+1 into the cache. Like this:The problem with this design is that you're holding a lock around the entire _load operation. If step1 and step2 take significantly longer than _load_image, it may be cheaper to avoid that lock by allowing rare duplicate work:If you're expecting to do lots of processing in parallel, you may want to use a ThreadPoolExecutor to queue up all of your preloads, instead of a daemon thread for each one.If you want to clean old cache values, see lru_cache and its implementation. There are a lot of tuning decisions to make (like: do you actually want background cache garbage collection, or can you just push the oldest item out whenever you add a 10th item the way lru_cache does?), but none of the options are particularly hard to build once you decide what you want.


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
