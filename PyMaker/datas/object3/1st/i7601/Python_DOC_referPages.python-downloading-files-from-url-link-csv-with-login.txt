Natural Text
Currently I have a csv file with a large number of links (900+) to download files from. What I wish to do is download all the files from this csv file however in order to download the files I need to log into the website which is done by navigating to a specific page on the website of interest and logging in from there.I can set up a login session via selenium and use repeated driver.get commands to initiate the downloads but this has a tendency to not work in my experience. Wget is an option to retrieve the files via iterating over the links in the file but it doesn't get around the issue that the website requires a login to work.So in short my question what is the most efficient implementation for iterating over a series of download links located in a csv file, downloading all files from said links and enabling a login session to be able to download these files?EDIT: Currently testing with requests
Use the urllib.request module and its HTTPBasicAuthHandler() class. So you could:However you want to iterate through the CSV to build a list of URLs and make queries is up to you.


Answer URL
https://docs.python.org/3/library/urllib.request.html#urllib.request.HTTPBasicAuthHandler
