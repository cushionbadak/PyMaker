Natural Text
Suppose we have a string, say, "122113" and we are supposed to find all the occurrences of every character in the String.A naive approach will be like this:But, this is quite slow if the length of the String is Large.  So, is there any faster solution?(Consider the string is only made up of lower english alphabets and the length of the string may be $10^12$
You should use a defaultdict (with an empty list as default value) and update the indices list while iterating through the string:Then use a list comprehension to get your list of occurrences:
(Sorry, my earlier answer misunderstood the question.)You could use a collections.defaultdict for this:indices will then be a dict that maps each character into their indices (example obviously not for the very_long_string above, but a shorter one). It takes about 3 seconds to do this for 10 000 000 characters on my machine.
One possible solution is to convert the string characters into numbers and use the number to increment values in an array. The code could be as follows:which gives: [5. 4. 0. 2. 5. 0. 3. 0. 1. 0. 0. 6. 0. 6. 2. 0. 0. 4. 3. 0. 0. 0. 1. 0. 0. 0.]Here I have made the array of length 26 since you know that it is just lowercase english letters. This also means that it is easier to interpret the resulting list. 
No import solution - given that you know it's only lower case alphabet you can precreate a list of lists of size 26, then iterating through just append the index of each character found to the appropriate position.
Assuming Python 2.7, option 1 (I did the dictionary so that one can tell which letter corresponded to the indices):average time for 10000 runs on '122113': 2.55961418152e-06average time for 10000 runs on 'a;lkdsfowquebtgafdnga;llkl;uihnbr,afdh;glakhhehjehrjehjeoguhaberna': 2.39794969559e-05average time for 500 runs on 'alkdsfowquebtgafdngallkl'*1000: 0.00993875598907option 2:average time for 10000 runs on '122113': 7.02269077301e-06average time for 10000 runs on 'a;lkdsfowquebtgafdnga;llkl;uihnbr,afdh;glakhhehjehrjehjeoguhaberna': 2.39794969559e-05average time for 500 runs on 'alkdsfowquebtgafdngallkl'*1000: 0.00974810600281(Test times from repl.it running python 2.7)Edit: Depending on exactly how it's used in the script, defaultdict can be faster or slower than just using dict


Answer URL
https://docs.python.org/3/library/collections.html#collections.defaultdict
