Natural Text
I am scraping tweets from Twitter and saving the text data in a csv file (which is saving as bytes literal b). When looking through the data I have lots of unicode characters like (\xe2\x80\x9c). Is it possible to write a script that can go through the csv and decode all the unicode, or do I have to decode it as I download the messages? If it's possible to go through the csv and decode unicode how do I go about that?Here's an example of the data:EDIT: The text entries in the csv file appear as shown above when looking through the csv file itself, when printing them out it shows they are strings and show the same as above but in "b'\xe2\x80\x9cSwitching Gears: Binance Phishing Scammers Pivot to EOS". When creating the file I appended entries to an existing csv and wrote using x.writerow(text)I am opening my file containing the strings, and then decoding and writing it into another file using the code below.Ive tried various forms of this but none of them are able to show the string correctly.
To decode a bytes object into a string, use it's decode method:Alternatively, you can write the file in binary and read it back in as normal UTF-8 text:Either way your three strings decode to‚ÄúSwitching Gears: Binance Phishing Scammers Pivot to EOS Airdrop Phishing Scam‚Äù by @satnamGo SMB! üíïüç∫@boogymaboi @SMB_DBN Trousers are too sick üò§The key is that your data comes in already in Unicode. You just have to tell python that. Both decode and the write/read do that. The former just reinterprets the bytes as UTF-8 encoding directly in memory. The latter writes the data literally to a file, then interprets it as UTF-8 when the file is read.Just make sure that the b is in your file mode when you write it. Otherwise, the objects you write will end up getting converted to string using str instead of getting decoded properly, which is how you end up with a file containing a bunch of literal bs and escape characters.


Answer URL
https://docs.python.org/3/library/stdtypes.html#bytes.decode
