Natural Text
For part of log parser I need to filter occurrences of baud rate in the log.  First I get all occurrences using re.findall, then I'm trying to remove duplicates in subsequences in its result. Results are like [10000,10000,10000,10000,0,0,0,10000,10000], the list can contain several hundreds of values. So the first baud rate was 10000, then 0, then again 10000.I need to see how the baud rate changed, so I can't use set, as it will lose information of baud rate switching points.  So, once again input: [10000,10000,10000,10000,0,0,0,10000,10000]Desired output: [10000,0,10000]What I have made already:  it works, but it doesn't seem pythonic enough to me. Please advise: is there some more efficient way possible, or do I even not need to invent the wheel again?
Use itertools.groupby:Explanation: If no key function is given, then the elements are just grouped by identity, i.e. groups of consecutive equal elements are collapsed. The result is an iterator of key-elements and the groups (in this case, just repetitions of the key element). We need just the keys.Update: Using IPython's %timeit magic command and a list of 100,000 random baud rates, itertools.groupby seems to be about as fast as the "compare to previous element loop" solutions, and a good deal shorter.

Iterate list m by normal method or by enumerate.Check last element of list n is equal to current element of list m.If not equal then append current element of list m to list 'n`.Used try and expect because first time list n is empty code :Output:
I had to do the same thing, except I needed to save the position of each element. I am a physicist, so this code is probably crap, but it works. One can remove the aesthetic things like "print" and "press any key to continue..." as those were for debugging. Probably will adapt one of the answers on this thread.Final output. Position in array, then the value of that element.


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.groupby
