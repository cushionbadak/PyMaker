Natural Text
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.ArrayWhat I’m trying to doCreate an array in MainProcess and send it through inheritance to any subsequent child processes. The child processes will change the array. The parent process will look out for the changes and act accordingly.The problemThe parent process does not "see" any changes done by the child processes. However the child processes do "see" the changes. Ie if child 1 adds an item then child 2 will see that item etcThis is true for sARRAY and iARRAY, and iVALUE.BUTWhile the parent process seems to be oblivious to the array values it does take notice of the changes done to the iVALUE.I don’t understand what I’m doing wrong. UPDATE 2 https://stackoverflow.com/a/6455704/1267259The main source of confusion is that multiprocessing uses separate processes and not threads. This means that any changes to object state  made by the children aren't automatically visible to the parent.To clarify. What I want to do is possible, right?  https://stackoverflow.com/a/26554759/1267259  I mean that's the purpose with multiprocessing Array and Value, to communicate between children and parent processes? And iVALUE works so...I’ve found this Shared Array not shared correctly in python multiprocessingBut I don’t understand the answer "Assigning to values that have meaning in all processes seems to help:"UPDATE 1  Found  Python : multiprocessing and Array of c_char_p> "the assignment to arr[i] points arr[i] to a memory address that was  only meaningful to the subprocess making the assignment. The other  subprocesses retrieve garbage when looking at that address."As I understand it this doesn't apply to this problem. The assignment  by one subprocess to the array does make sense to the other  subprocesses in this case. But why doesn't it make sense for the main  process?And I am aware of "managers" but it feels like Array should suffice for this use case. I've read the manual but obviously I don't seem to get it. UPDATE 3 Indeed, this worksSo...What am I doing wrong?UPDATE 4ChangingToOrAnd in self. worker() returning self.iARRAY.value or self.sARRAY.value does return a variable that has the updated value. This is not what I want to achieve though, this doesn't event require the use of ARRAY to achive...So I need to clarify. In the self.worker() I'm doing important heavy lifting that can take a long time and I need to send back information to the main process, eg the progress before the return value is finished to be sent to the callback.I don't expect the return of the finished worked result to the main method/that is to be handled by the callback function. I see now that omitting the callback in the code example could've give a different impression sorry.UPDATE 5Re: Use numpy array in shared memory for multiprocessingI've seen that answer and tried a variation of it using initilaizer() with a global var and passed array through initargs with no luck. I don't understand the use of nymphs and with "closing()" but that code doesn't seem to access the "arr" inside main() although shared_arr is used, but only after p.join().As far as I can see the array is declared then turned to a nymph and inherited through init(x). My code should have the same behavior as that code so far.One major difference seems to be how the array is accessed I've only succeeded setting and getting array value using the attribute value, when I triedAnd I can't find a method to access and check the values (the  attribute "value" gives an unknown method error)Another major difference from that code is the prevention of data copying using the get_obj().Isn't this a nymphy issue?Not sure how to make use of that.UPDATE 6I've tried using multiprocessing.Process() instead of Pool() but the result is the same.
correct way to declare the global variable (in this case class attribute)correct way to set valuecorrect way to get valueNot sure why the examples I've seen had used Array(ctypes.c_int, 3) and iARRAY.value[n] but in this case that was wrong
This is your problem:The function pool.apply_async() starts the subprocess running and returns immediately.  You don't appear to be waiting for the workers to finish.  For that, you might consider using a barrier.


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.Array
https://docs.python.org/3/library/multiprocessing.html#sharing-state-between-processes
