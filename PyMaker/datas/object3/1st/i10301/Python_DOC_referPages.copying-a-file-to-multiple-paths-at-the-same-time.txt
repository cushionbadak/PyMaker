Natural Text
I am transferring a 150-200mb file to many locations (shared drives located across the world) daily. The issue is that each transfer (using shutil) takes probably 100-700 seconds and each one has to complete in order for the next one to begin. It now takes like a full hour to transfer some files if I do it that way. My temporary solution was to create a separate .py file to run for each location so they can be done simultaneously, but that is not ideal.How can I dip into multi-thread programming? I'd like to run all of the transfers at once but I have zero experience with this.A simple google search landed me with:https://docs.python.org/3/library/concurrent.futures.html.Can someone point me into the right direction? I have been meaning to learn how to do things in parallel for a while now but never got around to it.
Here's a working example that does what you want. Note that it may not be any faster than one-at-a-time if the bottleneck is network bandwidth.


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
