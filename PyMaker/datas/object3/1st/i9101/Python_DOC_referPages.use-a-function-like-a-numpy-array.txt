Natural Text
I'm dealing with a big array D with which I'm running into memory problems. However, the entries of that big array are in fact just copies of elements of a much smaller array B. Now my idea would be to use something like a "dynamic view" into B instead of constructing the full D. For example, is it possible to use a function D_fun like an array which the reads the correct element of B? I.e. something likeAnd then I could use D_fun to do some matrix and vector multiplications.Of course, anything else that would keep me form copying the elements of B repeatedly into a huge matrix would be appreciated.Edit: I realized that if I invest some time in my other code I can get the matrix D to be a block matrix with the Bs on the diagonal and zeros otherwise.
This is usually done by subclassing numpy.ndarray and overloading __getitem__, __setitem__, __delitem__  (array-like access via []) to remap the indices like D_fun(..) does. Still, I am not sure if this will work in combination with the numpy parts implemented in C. Some concerns:When you're doing calculations on your big matrix D via the small matrix B, numpy might create a copy of D with its real dimensions, thus using more space than wanted.If several (I1,J1), (I2,J2).. are mapped to the same (i,j), D[I1,J1] = newValue will also set D(I2,J2) to newValue.
np.dot uses compiled libraries to perform fast matrix products.  That constrains the data type (integer, floats), and requires that the data be contiguous.  I'd suggest studying this recent question about large dot products, numpy: efficient, large dot productsDefining a class with a custom __getitem__ is a way of accessing a object with indexing syntax.  Look in numpy/lib/index_tricks.py for some interesting examples of this, np.mgrid,np.r_, np.s_ etc.  But this is largely a syntax enhancement.  It doesn't avoid the issues of defining a robust and efficient mapping between your D and B.And before trying to do much with subclassing ndarray take a look at the implementation for np.matrix or np.ma.  scipy.sparse also creates classes that behave like ndarray in many ways, but does not subclass ndarray.In your D_fun are I and J scalars?  If so this conversion would be horribly in efficient.  It would be better if they could be arrays, lists or slices (anything that B[atuple] implements), but that can be a lot of work.What is the mapping from D to B like?  The simplest, and most efficient mapping would be that D is just a higher dimensional collection of B, i.e.Slightly more complicated is the case where D[n1:n2,....] == B0, a sliceBut if the B0 values are scattered around D you chances of efficient, reliable mapping a very small.


Answer URL
https://docs.python.org/3/reference/datamodel.html#object.__getitem__
