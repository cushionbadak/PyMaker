Natural Text
Is it possible to download a large file in chunks using httplib2. I am downloading files from a Google API, and in order to use the credentials from the google OAuth2WebServerFlow, I am bound to use httplib2.At the moment I am doing:But the content variable can get more than 500MB.Any way of reading the response in chunks?
You could consider streaming_httplib2, a fork of httplib2 with exactly that change in behaviour.in order to use the credentials from the google OAuth2WebServerFlow, I am bound to use httplib2.If you need features that aren't available in httplib2, it's worth looking at how much work it would be to get your credential handling working with another HTTP library. It may be a good longer-term investment. (e.g. How to download large file in python with requests.py?.)
About reading response in chunks (works with httplib, must work with httplib2)Note: next() may raise StopIteration exception, you need to handle it. You can avoid calling next() like this
You can apply oauth2client.client.Credentials to a urllib2 request.First, obtain the credentials object. In your case, you're using:Now, use that object to get the auth headers and add them to the urllib2 request:Now resp is a file-like object that you can use to read the contents of the URL


Answer URL
https://docs.python.org/3/library/http.client.html#examples
