Natural Text
I have more than 5000 XML files in multiple sub directories named f1, f2, f3, f4,...Each folder contains more than 200 files. At the moment I want to extract all the files using BeautifulSoup only as I have already tried lxml, elemetTree and minidom but am struggling to get it done through BeautifulSoup. I can extract single file in sub directory but not able to get all the files through BeautifulSoup.I have checked the below posts:XML parsing in Python using BeautifulSoup (Extract Single File)Parsing all XML files in directory and all subdirectories (This is minidom)Reading 1000s of XML documents with BeautifulSoup (Unable to get the files through this post)Here is the code which I have written to extract a single file:When I try to get all files in all folders I am using the below code:Then I am only getting XML Version and nothing else. I know that I have to use a for loop and am not sure how to use it in order to parse all the files through the loop. I know that it will be very very slow but for the sake of learning I want to use beautifulsoup to parse all the files, or if for loop is not recommended then will be grateful if I can get a better solution but only in beautifulsoup only.Regards,
If I understood you correctly, then you do need to loop through the files, as you had already thought:pathlib is just one approach to handling paths, on a higher level using objects. You could achieve the same with glob and string paths.
Use glob.glob to find the XML documents:note: don't shadow the builtin function/class file. Read the BeautifulSoup Quick Start


Answer URL
https://docs.python.org/3/library/pathlib.html
https://docs.python.org/3/library/glob.html
