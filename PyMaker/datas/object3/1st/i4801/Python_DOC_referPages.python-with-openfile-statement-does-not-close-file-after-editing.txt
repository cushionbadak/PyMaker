Natural Text
I am on windows and want to run my multi-threaded python app that saves data to .csv in an async way. As reported here, here and here, I am getting the following error at some point:This proposes a fix that includes with-statements for every file IO operation:However, I am still getting IOError as described above (In a nutshell, none of the SO questions solved my issue). Therefore, the with-statement apparently does not properly close the .csv file after the append operation.First, I now increases the number of open files. This admittedly just delays the crash:Second, my temporary approach is (A) to check for open .csv-files consequtively, and (B) forcefully restart the whole script if the open file count gets anywhere near the threshold allowed for windows:This approach is ugly and inefficient in many ways (loop through all open files in every iteration/thread). At the very least, this needs to work without forcefully restarting the whole code.Q1: How to properly close .csv files using python on windows?Q2: If closing fails after IO operation, how to forcefully close open all .csv files at once?
Those answers are correct.  The with statement is the correct and Pythonic way to open and automatically close files.  It works and is well tested.  I suspect, however, that it's the multiprocessing or threading that's throwing a spanner in the works.In particular, how many of your threads or processes are writing to your CSV?  If more than one, then I'm confident that's the issue.  Instead, have a single writer, and pass what needs to be written to that writing thread or process via a multiprocessing.Queue or regular (thread-safe) queue.  In effect, a funnel, in which all processes that want to add data to the CSV would instead put the data into the queue, and the writing process will take each queue item out and write it the file.Given a lack of working example in the question, I'll simply leave a pointer to Python's documentation on multiprocess communication.
Use ThreadPoolExecutor from https://docs.python.org/3/library/concurrent.futures.html so you can keep a maximum number of threads running at one time to be less than the maximum number of file descriptors.The with statement is the best way to handle the closing of files even when exceptions happen so you don't forget.
Just close normal, not "with"???


Answer URL
https://docs.python.org/3/library/concurrent.futures.html
