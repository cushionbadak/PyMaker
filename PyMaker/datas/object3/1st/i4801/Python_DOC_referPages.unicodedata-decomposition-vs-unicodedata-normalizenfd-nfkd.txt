Natural Text
According to py3 doc:unicodedata.decomposition(chr)Returns the character decomposition mapping assigned to the character chr as string. An empty string is    returned in case no such mapping is defined.Here I don't quite understand how character decomposition mapping is defined and what's the relationship/difference between unicodedata.decomposition() and unicodedata.normalize(NFD/NFKD)?.See following examples:
unicodedata.decomposition returns the decomposition type and mapping of a single code point in the format used in the Unicode Character Database. From UAX #44:Decomposition_Type, Decomposition_Mapping: This field contains both values, with the type in angle brackets.If there's no type in angle brackets, the code point has a canonical decomposition used in NFC and NFD. If there's a type in angle brackets, the code point has a compatibility decomposition which are used by NFKC and NFKD in addition to the canonical decompositions.unicodedata.normalize implements the Unicode Normalization algorithms for whole strings.
The mappings are defined in Unicode standard.K is "compatibility". Unicode had to insert some codes into Unicode, in order to be able to do a round trip, without losing information. The "K" conversion will remove such "extra/unwanted" characters (that should not be in Unicode, by other rules).So subscript numbers, superscript numbers, fractions, and the circled number (in your example) are transformed (they should be standard numbers + markup format (which is outside Unicode, and character).The problem: with subscript, one get just the number, so changing the meaning, e.g. 4² is transformed into 42. K will remove some semantic of the text (which should not be there in first place, but just decomposing is not enough good)So K should not be used, but for specific uses. One of such uses it is for string searches, or to see if one username is too similar (maybe indistinguishable) to other usernames [but just 'K' is not enough].The D is a normalisation: D will decompose characters into components, so ê is transformed into e and the combining character ^.  This was also one target of Unicode: coding all characters into 65366 codes were not realizable, so the character were composed. (This is mostly visible with Chinese characters). Again, for compatibility and round trip, there were added some accented characters and later Unicode expanded to more than 65536 codes.So we have D for the decomposed characters (base + combination codes), and C with the more compact notation (if available with such combination).  Also these transformation are described in Unicode standards (with few historical special cases and "bugs").


Answer URL
https://docs.python.org/3/library/unicodedata.html#module-unicodedata
