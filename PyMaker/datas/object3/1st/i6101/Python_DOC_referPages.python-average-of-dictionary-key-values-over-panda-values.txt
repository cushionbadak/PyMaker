Natural Text
I have a rather complex data structure, namely dictionaries in a panda dataframe. Lets say I have this dataframe.I now want to calculate the median and 25% / 75% quartiles of each key element of my dictionaries in my 'data' column (here peak_voltage and Spikecount) for each stimulus over all trials. One example for the median:I want the median peak_voltage value when stimulus 1 was applied across all trials [30.5, 65, 20.1] -> 30.5. The same for when stimulus two was applied [30.5, 65, 30, NaN] -> 30.5. And of course the same for Spikecount.To be honest, I've no idea where to start. If I only wanted to calculate the median regardless of the simulus, I would simply use.But this is not what I want. Also, if I didn't have dictionaries but only numbers, I would have used something likeBut what can I do in my case with dictionaries in a panda table?EDIT 1I have 10 stimuli with 16 trials each, resulting in 160 rows in total. The dictionaries are the output of a toolbox called EFEL that I use to find certain characteristics of my data traces (e.g. the timing of peaks of neuronal action potentials). I decided to organize the resulting 160 dictionaries in a panda dataframe to keep track of the data, stimuli and trials at the same time. I don't know if this is unfortunate in the first place.
For what you are asking I would advise restructuring your dataframe. Instead of constructing featve with:The result is the following DataFrame:On this DataFrame you can group and compute your medians as you would normally.e.gUpdateI understand the concerns about not having "Nice" data. Given a strict construct that follows the format of data_ you could use defaultdict to get a nicer dataframe.
First, I'm not sure why you're putting your dicionaries in lists, but I would recommend having a version of your data without them. Also, if most of your data is in the form of dictionaries, then I recommend putting missing data in the form of dictionaries as well. Once you do that, you can put data_ in a dataframe. So my_data =  pd.DataFrame([{'peak_voltage': [30.5, 65], 'Spikecount': [2]}, {'peak_voltage': [30.5, 65, 30], 'Spikecount': [3]}, {'peak_voltage': [20.1], 'Spikecount': [1]}, {}]). You can then have a dataframe of stimulus and trial: stimulus_trial_df = pd.DataFrame({'trial': trials_, 'stimulus': stimul_}).  Next, you can slice my_data on properties of stiumulus_trial_df: subset1 = my_data.loc[stimulus_trial_df['stimulus']==1]. Note that you do have to make sure that your two dataframes have consistent indices for this to work. Once you have subset1, you can flatten columns in it: spikecount_agg= [spikecount for row in subset1['Spikecount'] for spikecount in row]. Finally, you can perform whatever operation you want on the flattened column:A final note: you put in your question [30.5, 65, 20.1] -> 30.5, but your data has two copies of 30.5 and 65. In this particular case, this doesn't change what the median is, but you should think about whether you want to take into account multiple copies in your data. My code includes them, so if you don't want them, you'll have to adjust the code.EDIT:Regarding subsetting for different stimuli, a for-loop should suffice. If you have an object containing unique stimuli, you can loop over that; if you don't, you can generate it with unique_stimuli = set(stimul_):


Answer URL
https://docs.python.org/3/library/collections.html#collections.defaultdict
