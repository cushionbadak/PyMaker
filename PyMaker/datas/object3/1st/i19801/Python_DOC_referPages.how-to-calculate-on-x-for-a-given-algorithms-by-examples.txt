Natural Text
I want to calculate the running time O(n, x) = Theta(n, x) for a given algorithm depending on n and x by a big amount (> 100) of examples (how long the algorithm will take for n and x).Is there actually a way to do this?I know that the running time increases as n and x (!) increase, but I think the coherences are too complex to figure out O(n, x) by "hand", since n or x mac increase like n ^ x, or even worse.btw. my most favored languages for solving this problem are Python or PHP.
There's a free tool called Eureqa that might interest you. You can give it data, and it will find candidate equations that fit your data. For example, you run the algo on varying input sizes and record the execution time of each, and then give Eureqa this data. It will then give you math equations that fit your data.Many algorithms have running times that are highly dependant on the specific values in the input data. Because of this, this wont always be a great method to use to do asymptotic analysis, because your just don't know if you data is pushing the algorithm to its bounds. But, we use asymptotic analysis as a means to an end - we often want to choose an algorithm that probably works well in the real world on real world data. And, this is like benchmarking, but you get awesome additional mathematical insight. Also, keep in mind  asymptotic analysis itself is kinda a concession to the fact that we need to simplify and lower our expectations in order to get some answer thats simple enough to be useful.Watch their youtube vid http://www.youtube.com/watch?v=NhC1Qb-PQ5Q
The best way is to have a very close look at the algorithm and analyze each step to calculate average and worst-case runtime class.If that's not feasible, you can run the algorithm with relatively small numbers, and compare them to each other. If the runtime is exponential in order of any of the parameters, it should be blatantly obvious even with a difference of 10 or 20. Simply plotting the runtimes for, sayx = 10 and y in range(50)y = 10 and x in range(50)x in range(50), y=xshould give you a rough idea. You can abort early  when runtime grows to large, say larger than 10000 times the runtime of (1,1).This should give you a rough estimate, but you should be well aware that it's neither precise (your test data may inadvertently follow certain patterns and hit a good case) nor sufficient (The factors involved may be very small - you won't correctly identify, say, x + 0.0001 * 1.05^y). Fortunately, in many cases, the bases in exponential algorithms are significantly larger than 1.In Python, you can use the timeit module to correctly measure the runtime.


Answer URL
