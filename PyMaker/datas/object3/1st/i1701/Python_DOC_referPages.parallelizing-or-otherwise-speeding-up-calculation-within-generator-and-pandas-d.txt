Natural Text
I am doing a calculation on permutations of things from a generator created by itertools. I have a piece of code in this form (this is a dummy example):Except in the real code, there are several hundred thousand permutationsinstead of i+=1 I am opening files and getting results of clf.predict where clf is a classifier trained in scikit-learnin place of i I'm storing a value from that predictionI think the combo[0]+'-'+combo[1] is trivial though.This takes too long. What should I do to make it faster? Such as:1) writing better code (maybe I should initialize results with the proper length instead of using append but how much will that help? and what's the best way to do that when I don't know the length before iterating through combs?)2) initializing a pandas dataframe instead of a list and using apply?3) using cython in pandas? Total newbie to this.4) parallelizing? I think I probably need to do this, but again, total newbie, and I don't know whether it's better to do it within a list or a pandas dataframe. I understand I would need to iterate over the generator and initialize some kind of container before parallelizing.Which combination of these options would be best and how can I put it together?
The append operation in pandas and for loop are slow. This code avoids using it.You can do this for each file and dataframe that you have then use pd.concat to quickly generate results thereafter. You can also add the enumeration of the permutations afterward if you want.


Answer URL
https://docs.python.org/3/library/multiprocessing.html
