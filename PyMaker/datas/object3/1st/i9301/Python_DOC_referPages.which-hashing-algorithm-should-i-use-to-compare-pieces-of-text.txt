Natural Text
I have a large number of pieces of text which I need to compare between themselves to check whether or not they are similar. Each piece is about 10000 words long.Hence I'll pre-calculate a hash of each one and compare hashes. The question is, which hash algorithm would be better for that? md5? sha1? sha256? Or perhaps base64?Or maybe it doesn't even really matter?I'm aware that even a single whitespace can change the value of a hash, that's ok with me.
Use zlib.crc32 then do textual compare of texts with matching hashes to make sure.
When does hashing work?What hashing does is reduce search space so that equivalent items can be found more quickly.  It works whenever there is a reliable way to produce a single canonical value for all members of an equivalence class.Selecting a unique value among equivalent stringsBefore hashing, the strings need to be converted to a canonical value (one unique representation among all equivalent strings).I'm aware that even a single whitespace can change the value of a  hash, that's ok with me.For your application, here is possible canonicalizing function that just removes whitespace:Applying a hash functionA sha256() is fast and has almost no chance of a false positive.In Python 2, you can compute the sha256 directly from a string.  However, in Python 3, the string must first be encoded into bytes:When won't hashing work?If you just want to group by text similarity, hashing doesn't work as well because there isn't a straight-forward way to choose a representative element and because similarity is isn't a transitive relation (a is close to b and b is close to c doesn't imply that a is close to c).


Answer URL
https://docs.python.org/3/library/hashlib.html#hash-algorithms
