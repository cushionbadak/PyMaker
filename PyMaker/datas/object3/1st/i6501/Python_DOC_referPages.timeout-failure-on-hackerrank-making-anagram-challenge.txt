Natural Text
First question ever here on stack,I'm on my first few challenges on hackerrank and am stuck on the "how many deletion to anagramize 2 words". I've seen some other solutions on the web but i can't figure out why mine is that much slower. I seem to have a "correct" algorithm since i computed some test cases and found the corresponding expected outputSo i'm trying to figure out if the general idea of my algorithm is the  bottleneck or if it's some error in it that is. Thanks!
You could use line profiling here.  You can use conda install line_profiler.First incorporate your function in a script and decorate it with @profile.  Here's that script:Then in IPython/JupyterQt call the command below.  You might need to change the path based on what you're directory looks like:The result shows you some useful stats line-for-line.  It looks like for j,letterB in enumerate(b): being nested is your culprit.  You're evaluating the line below 136,000 times.  That is, the operations you're running within the loops take just as long per hit, but they're hardly ever evaluated, so as a whole they're not what's eating up your time.Still, the runtime doesn't seem too bad.  14.7 ms for s1 and s2 on my machine.
You code has O(n3) complexity (n being length of a and b): You loop every character in a, compare those with every character in b, and then check whether that index is in the list of already matched characters, which also has linear complexity.As a quick fix, you could make matchedBs a set, thus reducing the complexity to to O(n²). But you can do better than that: Just count all the individual characters in a and b. Do not use str.count for this, or you will have O(n²) again; instead, use a dict mapping characters to their counts, loop a and b once, and update those counts accordingly. Finally, just sum the difference of those counts for a and b.Or, using Python's libraries, you could just create two collections.Counter for a and b and compare those.


Answer URL
https://docs.python.org/3/library/collections.html#collections.Counter
