Natural Text
I have a python generator that returns lots of items, for example:I then iterate over this and perform various tasks, the issue is that I'm only using one thread/process for this:This works great, I'm getting all my strings, but it's slow. I would like to harness the power of Python multiprocessing to "divide and conquer" this for loop. However, of course, I want each string to be processed only once. While I've found much documentation on multiprocessing, I'm trying to find the most simple solution for this with the least amount of code.I'm assuming each thread should take a big chunk of items every time and process them before coming back and getting another big chunk etc...Many thanks,
Most simple solution with least code? multiprocessing context manager.I assume that you can put "do something with string" into a function called "do_something"If you want to get the results of "do_something" back again, easy!You'll get them in a list.Multiprocessing.dummy is a syntactic wrapper for process pools that lets you use the multiprocessing syntax. If you want threads instead of processes, just do this:
You may use multiprocessing.
Assuming you're using the lastest version of Python, you may want to read something about asyncio module. Multithreading is not easy to implement due to GIL lock: "In CPython, the global interpreter lock, or GIL, is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe."So you can swap on Multiprocessing, or, as reported above, take a look at asycio module.asyncio â€” Asynchronous I/O > https://docs.python.org/3/library/asyncio.htmlI'll integrate this answer with some code as soon as possible.Hope it helps,Hele
As @Hele mentioned, asyncio is best of all, here is an exampleCodeOutputOf course, u need to improve generate_one, this variant is very slow.


Answer URL
https://docs.python.org/3/library/asyncio.html
