Natural Text
I have a very long array (over 2 million values) with repeating value. It looks something like this:With a bunch of different values. I want to create individual arrays for each group of points.  IE: an array for the ones, an array for the twos, and so forth. So something that would look like:
Assuming that repeated values are grouped together (otherwise you simply need to sort the list), you can create a nested list (rather than a new list for every different value) using itertools.groupby:Note that this will be more convenient than creating n new lists created dinamically as shown for instance in this post, as you have no idea of how many lists will be created, and you will have to refer to each list by its name rather by simply indexing a nested list
You can use bisect.bisect_left to find the indices of the first occurence of each element.  This works only if the list is sorted:This avoids scanning the entire list, trading that for a binary search for each value.  Expect this to be more performant where there are very many of each element, and less performant where there are few of each element. 
Well, it seems to be wasteful and redundant to create all those arrays, each of which just stores repeating values.You might want to just create a dictionary of unique values and their respective counts.From this dictionary, you can always selectively create any of the individual arrays easily, whenever you want, and whichever particular one you want.To create such a dictionary, you can use:Once you have this dict, you can get the number of 23's, for example, with my_counts_dict[23].And if this returns 200, you can create your list of 200 23's with:
****Use this code ****
Solution with no helper functions:


Answer URL
https://docs.python.org/3/library/functions.html#sorted
https://docs.python.org/3/library/itertools.html#itertools.groupby
https://docs.python.org/3/library/bisect.html#bisect.bisect_left
