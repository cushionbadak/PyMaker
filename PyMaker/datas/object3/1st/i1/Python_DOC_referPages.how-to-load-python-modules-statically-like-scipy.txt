Natural Text
Under normal circumstance, external python modules such as scipy and numpy are compiled into shared objects when being installed (The part written in C). When python calls import scipy, it will dynamically load these shared objects.Now I am working on a platform which does not support any dynamic loading function. As a result, I have to link those modules statically with python.My current approach is to compile all source code of scipy/numpy with python, and call the module initialization function when python initializes. However, this brings me another problem. I found in many python module initialization functions, especially when they are auto generated from cython, they contain codes to import its parent packages. For example, the cython_special() calls import scipy, but when it is being called, the scipy initialization is not completed yet.My question is, is there an easy way I can linked these modules statically? What is your suggestions to solve this problem?Thanks.
PyImport_AppendInittab - this tells Python in advance of a module initialization function associated with a specific name. You'd identify all the modules you need to use that are compiled, link them statically, and then before Py_Initialize you add them to the Inittab.Nothing happens until the module is imported at runtime when the correct initialization function is run.
If I got you right, what you could do is add a path to a dir where the modules will be located at.etc.


Answer URL
https://docs.python.org/3/c-api/import.html#c.PyImport_AppendInittab
