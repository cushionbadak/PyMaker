Natural Text
I'm reading the data from a csv file into dataframe, the file has 5 columns and has about the 300k rows, now I have build another 3 dataframes which are about 1.2 million, 400k and 500k rows. I need to check for a particular values from these 2 dataframes and depending upon the result from the three I need to pick one. My is code is below. The process is running forever. I'm the reading the source data in chunks and I have even indexed the key columns even then performance is very slow.Here is the pseudo code is below, where do you think the performance issue is.ps: the look up dataframe size are approx 300 ~ 500 MB each.
Vectorize& (date >= lookup_data3['start_dt']) & (lookup_data3['end_dt'] >= date) always stays the same, so why not doLike this the 3 lookups don't have to do that each time, and then you perhaps can even just use .locGroupbyIf there is a limited number of values in the chunk['val1'], a groupby.transform will work faster here than a map


Answer URL
https://docs.python.org/3/library/profile.html
