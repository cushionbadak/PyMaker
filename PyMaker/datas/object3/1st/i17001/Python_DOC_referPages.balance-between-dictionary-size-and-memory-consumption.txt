Natural Text
I'm using a memoized decorator to cache repeated calls. I'm seeing about a 4x execution speedup due to memoization on some moderate-sized test cases.With larger test cases, the memoized dictionary mapping inputs to outputs takes up a considerable amount of memory, to the point where I'm getting "java.lang.OutOfMemoryError: Java heap space" errors (I'm using Jython).I can save some memory by using memoized_cache[hash(key)] = value rather than memoized_cache[key]: value, assuming that hash(key) is fewer bytes than key. As pointed out by @gnibbler, this will cause problems if there are hash collisions.The other memory savings I can introduce is limiting the size of the dictionary to a fixed number of items. Such a SizedDict recipe already exists, but I'd like to truncate elements that are accessed the least often.Here's what I have written:Is there a better data way to implement this with less memory or time overhead? resize is quite expensive: O(n log n)
Use functools.lru_cache@functools.lru_cache(maxsize=128, typed=False)Decorator to wrap a function with a memoizing callable that saves up to the maxsize most recent calls. It can save time when an expensive or I/O bound function is periodically called with the same arguments.Or pylru as described in the answer memoization library for python 2.7


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
