Natural Text
I have a sorted list with duplicate elements likeI need to create a list that removes the adjacent duplicate elements. I can do it like:But I want to do it with list comprehension. I tried the following code:But I get the result like the if condition isn't working.Any help would be appreciated. Thanks!! Edit 1: The wording of the question does seem to be confusing given the data I have provided. The for loop that I am using will remove all duplicates but since I am sorting the list beforehand, that shouldn't a problem when removing adjacent duplicates.
Using itertools.groupby is the simplest approach to remove adjacent (and only adjacent) duplicates, even for unsorted input:Removing all duplicates while maintaining the order of occurence can be efficiently achieved with an OrderedDict. This, as well, works for ordered and unordered input:
I need to create a list that removes the adjacent duplicate elementsNote that your for loop based solution will remove ALL duplicates, not only adjacent ones. Test it with this:according to your spec the result should be:but you'll get instead.A working solution to only remove adjacent duplicates is to use a generator:=> [1, 2, 3, 4, 2, 5, 1]
Python first evaluates the list comprehension and then assigns it to newList, so you cannot refer to it during execution of the list comprehension.  You can remove dublicates in two ways:-1. Using for loopConvert list to set,then again convert set to list,and at last sort the new list.Since set stores values in any order so when we convert set into list you need to sort the list so that you get the item in ascending order     rand_list = [1,2,2,3,3,4,5] sets = set(rand_list) new_list = list(sets) new_list.sort()
Update: Comparison of different ApproachesThere have been three ways of achieving the goal of removing adjacent duplicate elements in a sorted list, i.e. removing all duplicates:using groupby (only adjacent elements, requires initial sorting)using OrderedDict (all duplicates removed)using sorted(list(set(_))) (all duplicaties removed, ordering restored by sorting).I compared the running times of the different solutions using:Note that the set approach is the fastest among all alternatives.Old AnswerPython first evaluates the list comprehension and then assigns it to newList, so you cannot refer to it during execution of the list comprehension. To illustrate, consider the following code:This becomes even more evident if you try:You can remove duplicates by turning randList into a set:Be aware that this does remove all duplicates (not just adjacent ones) and ordering is not preserved. The former also holds true for your proposed solution with the loop.edit: added a sorted clause as to specification of required ordering.
In this line newList = [num for num in randList if num not in newList], at first the list will be created in right side then then it will be assigned to newList. That's why every time you check if num not in newList returns True. Becasue newList remains empty till the assignment.You can try this:
You cannot access the items in a list comprehension as you go along. The items in a list comprehension are only accessible once the comprehension is completed.For large lists, checking for membership in a list will be expensive, albeit with minimal memory requirements. Instead, you can append to a set:This algorithm has been implemented in the 3rd party toolz library. It's also known as the unique_everseen recipe in the itertools docs:
Since your list is sorted, using set will be the fasted way to achieve your goal, as follows:


Answer URL
https://docs.python.org/3/library/itertools.html#itertools.groupby
https://docs.python.org/3/library/collections.html#collections.OrderedDict
