Natural Text
I have two unsorted text files (between 150MB and 1GB in size).I want to find all the lines that are present in a.txt and not in b.txt.a.txt contains-->b.txt contains-->If I combine a.txt and 'b.txtinc.txt` I get:I sort them alphabetically and get:Then I use regx mode to search for (.*)\n(\1)\n and replace them all with null and then I replace all \n\n multiple times with \n to get the "difference" between two files.Now I am unable to do so in python. I am able to do it till the sorting part but regular expressions doesn't seems to be working in multi-lines.Here is my python code
I am able to do it till the sorting part but regular expressions doesn't seems to be working in multi-lines.Your regex is fine. You don't have multi-lines. You have single lines:file.readlines() reads all of a file into memory as a list of lines. You then the iterates over each of those single lines, so line will be 'asd\n' or 'qwe\n', and never 'qwe\nqwe\n'.Given that you are reading all of your merged file into memory, I'm going to presume that your files are not that big. In that case, it'd be much easier to just read one of those files into a set object, then just test each line of the other file to find the differences:If you wanted to write those all out to a file, you could just combine the two sequences and write out the sorted list:Your approach, sorting your lines first, putting them all in a file, and then matching paired lines, is possible too. All you need to do is remember the preceding line. Together with the current line, that's a pair. Note that you don't need a regular expression for this, just an equality test:Note that this never reads the whole file into memory! Iteration directly over the file gives you individual lines, where the file is read in chunks into a buffer. This is a very efficient method of processing lines.You can also iterate over the file two lines at a time using the itertools library to tee off the file object iterator:A third approach is to use itertools.groupby() to group lines that are equal together. You can then decide what to do with those groups:I'm assuming that it doesn't matter if there are 2 or more copies of the same line. In other words, you don't want pairing, you want to only find the unique lines (those only present in a or b).If your files are extremely large but already sorted, you can use a merge sort approach, without having to merge your two files into one manually. The heapq.merge() function gives you lines from multiple files in sorted order provided the inputs are sorted individually. Use this together with groupby():Again, these approaches only read enough data from each file to fill a buffer. The heapq.merge() iterator only holds two lines in memory at a time, as does groupby(). This lets you process files of any size, regardless of your memory constraints.


Answer URL
https://docs.python.org/3/library/itertools.html
https://docs.python.org/3/library/itertools.html#itertools.groupby
https://docs.python.org/3/library/heapq.html#heapq.merge
