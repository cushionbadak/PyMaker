Natural Text
This question already has an answer here:Is floating point math broken?                    28 answers                When study the python built-in float function, I read the floating point doc. And got some understanding.Float's real value is different with their demonstration value, like 0.1's real value is '0.1000000000000000055511151231257827021181583404541015625'Any float in python has a fixed value using IEEE-754 math.fsum give us the closest exactly representable value to the exact mathematical sum of the inputsBut after doing a bunch of experiments, I still encounter some unsolved doubts.Doubt1In the tutorial doc I mentioned in the first paragraph, it gave us an example:With the doc's instructions, I got an impression that math.fsum will give us a more accurate result when doing float summation.But I found a special case within the range(20) where sum([0.1] * 12) == 1.2 evals True, meanwhile math.fsum([0.1] * 12) == 1.2 evals False. Which makes me perplexed.  Why this happened?And what's the mechanism of sum when doing float summation?Doubt2I found for some float computation, plus operation has the same effect as its equivalent multiply operation. Such as 0.1+0.1+0.1+0.1+0.1 is equal to 0.1*5. But on some cases, there are not equivalent, like adding up 0.1 12 times is not equal to 0.1*12. This makes me really confused. As per float is a fixed value calculated by IEEE-754 standard. According to math principle, such kind of addition should be equal to its equivalent multiplication. The only explanation is that python didn't fully applied math principle here, some tricky stuff happens. But what's the mechanism and details of this tricky stuff?
When .1 is converted to 64-bit binary IEEE-754 floating-point, the result is exactly 0.1000000000000000055511151231257827021181583404541015625. When you add this individually 12 times, various rounding errors occur during the additions, and the final sum is exactly 1.1999999999999999555910790149937383830547332763671875.Coincidentally, when 1.2 is converted to floating-point, the result is also exactly 1.1999999999999999555910790149937383830547332763671875. This is a coincidence because some of the rounding errors in adding .1 rounded up and some rounded down, with the net result that 1.1999999999999999555910790149937383830547332763671875 was produced.However, if .1 is converted to floating-point and then added 12 times using exact mathematics, the result is exactly 1.20000000000000006661338147750939242541790008544921875. Pythonâ€™s math.fsum may produce this value internally, but it does not fit in 64-bit binary floating-point, so it is rounded to 1.20000000000000017763568394002504646778106689453125.As you can see, the more accurate value 1.20000000000000017763568394002504646778106689453125 differs from the result of converting 1.2 directly to floating-point, 1.1999999999999999555910790149937383830547332763671875, so the comparison reports they are unequal.In this answer, I step through several additions of .1 to examine the rounding errors in detail.


Answer URL
https://docs.python.org/3/tutorial/floatingpoint.html
