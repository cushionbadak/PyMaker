Natural Text
I'm using the Beautiful Soup library to parse the contents of a web page and print the results into a .txt file. This mostly works but I can't get rid of certain unicode character codes that appear in the text output. For example:"Failed to investigate issue with customer\u2019s terminal."I have been using the "io" library to encode the output as utf-8. I have tried changing the encoding to ascii, but this doesn't work either.I read the article below to try to get a general understanding of how character encoding works. It seems like if I encoded the content in the open_file function, encoding the output in the same standard in the dict_writer function should work.https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/
The reason you're getting non-ASCII characters encoded with \u is that you're using json.dumps. As you can see from the docs, the ensure_ascii parameter defaults to True, and, if true, "the output is guaranteed to have all incoming non-ASCII characters escaped".So, you could just add ensure_ascii=False to all of your dumps calls.But really, why are you using json.dumps in the first place? The format you're outputting isn't a JSON file. In fact, it seems to be something designed for human rather than computer consumption. So why do you want extra quotes, escape characters, etc. to make the parts of it JSON-parseable even though the whole isn't? It would be much simpler, and probably produce nicer output, if you just didn't do that:… or, even better:While we're at it, calling your dict dict is confusing (and means you can't access the dict constructor in the rest of your function without getting one of those errors that will keep you up all night debugging and then feeling like an idiot).Also, why are you using get("content") here?If you don't have to worry about cases where there is no content, just use ["content"]—or, even more simply, just pass the dict to format_map:If you do need to worry about such cases, surely you want some appropriate human-meaningful string, not None. For example:


Answer URL
https://docs.python.org/3/library/json.html#json.dumps
