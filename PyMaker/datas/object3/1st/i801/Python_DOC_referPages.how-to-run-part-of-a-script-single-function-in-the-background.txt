Natural Text
I run a python script on a server that has the following basic structure (pseudocode):The basic constraints are:data_items is a (big) list of dataprocess_data() uses a lot of cpu.upload_result_to_site() takes very little cpu.T0 = 5*T1 (approx.)Now, I have limited server time, and I would like to use all of it for the cpu-intensive process_data(), rather than on upload_result(). Unfortunatelyupload_result_to_site() is necessary.One solution would be to run:in the 'background' in  the same way processes can be run in the background on unix.I can run the whole script in the background (via os.popen3 or subprocess) or I can use a daemon. But I want the simplest solution to this problem. I could not find a way to use subprocess to call only part of a script (a single function)multiprocessing.Pool.map() can  be used, but the process created by it has to be joined and terminated at some point, else the number of subprocesses will keep growing).Is there a simple way to do this?Update: Currently I'm using this workaround:where myscript.py is the name of the script and the appropriate handlers are present in __name__==__main__.The (theoretical) disadvantage is this probably only works on unix. Since my server runs unix, this is fine for me. If someone has a better solution, please answer.
The really long term simply solution is to create yourself the elemental building blocks that you need. Your script is doing two very different things. The "natural" solution would be to turn your script into a module, that simply offers different services. Then you can write one or more scripts that import that module, and then you could use popen3/subprocess to simply call a small script that only does upload a single result for example.  
why not just do something like this?this will cause a number of processes to be launched (Python makes a guess based on how many cores you have) and process_data to be executed in child processes.  results are then returned to the main process where results are uploaded as processing finishesalso note that the "data" is pickled when sent to and retrieved from child jobs, so need to be compatible with this


Answer URL
https://docs.python.org/3/library/pickle.html
