Natural Text
I have 2 matrix 100kx200 and 200x100kif they were small matrix I would just use numpy dot product however the matrix is too big, and also I can't use loops is there a smart way for doing this?
A possible optimization is Computing a @ b requires 10k×200×10k operations, while summing the rows first will reduce the multiplication to 1×200×10k operations, giving a 10k× improvement.This is mainly due to recognizingSimilar for the other axis.(Note: x @ y is equivalent to x.dot(y) for 2D matrixes and 1D vectors on Python 3.5+ with numpy 1.10.0+)Illustration:Now, if we simply do a @ b, we would need 18 multiply and 6 addition ops. On the other hand, if we do np.sum(a, axis=0) @ b we would only need 6 multiply and 2 addition ops. An improvement of 3x because we had 3 rows in a. As for OP's case, this should give 10k times improvement over simple a @ b computation since he has 10k rows in a.
There are two sum-reductions happening - One from the marix-multilication with np.dot, and then with the explicit sum.We could use np.einsum to do both of those in one go, like so -Sample run -Runtime test -Sadly, doesn't look like we are doing any better with np.einsum.For changing to np.sum(a.dot(b), axis = 1), just swap the output string notation there - np.einsum('ij,jk->i',a,b), like so -
Some quick time tests using the idea I added to Divakar's answer:einsum is actually faster than np.sum!For larger arrays the einsum advantage decreases


Answer URL
https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-465
