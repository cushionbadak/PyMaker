Natural Text
Task:Generate a pair of random numbers (i,j) (order doesn't matter: (i,j) is equivalent to (j,i)).The pair must consist of two distinct values: i != jPairs must be uniformly distributed. In other words, the probability is the same for all the possible pairs.Do this at a constant time.1st attemptConstant time? YES. Uniformly distributed? NOVisualizing the samples (by disregarding the order) :Samples visualization (not uniformly distributed)You can easily the effect of restricting the y to be larger than x, meaning higher pairs have higher probability (opacity here expresses density).2nd attemptConstant time? NO. Uniformly distributed? YESVisualizing the samples:Samples visualization (uniformly distributed)PS: it's not a homework, I'm experimenting with stochastic optimization techniques that use random neighbor generation using a swap operation.
How about this?The value for x is equally distributed among all the possible values, and the value for y is equally distributed among all the remaining values, with the current value for x standing in as the maximum value (could also be the minimum value, just use low=1 in this case).Graphical approximation:Random distribution of 1,000,000 pairs in range 0..5Instead of swapping x with max, we could also shift all the values for y if y >= x, i.e. if y >= x: y += 1, yielding the same distribution. This way, the above could also be generalized to more than two values, by comparing the current value to all the previous values and shifting it up accordingly. This requires sorting the drawn values, though, so complexity is a bit higher, about O(kÂ²logk).Tested this again with small values for low and high and 1,000,000 iterations, and the results look correct.Or, you could just use random.sample(range(low, high+1), k). I don't know how exactly this is implemented, but it is very fast, even for large values for upper bound and k close to the maximum number of values.
I extended the method of @tobias_k above to k values.testing:Compared to a method using np.argpartition, this seems to be faster as long as k < 0.4 * n
Starting from Numpy 1.7.0 you can use np.choice with replace=False:Here is the distribution of 10000 samples:


Answer URL
https://docs.python.org/3/library/random.html#random.sample
