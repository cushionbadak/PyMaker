Natural Text
Here is my code:Basically right now it is scraping each "g" one at a time, when this program can benefit massively from scraping each link all at the same time. For example, I want it to have them all scraping at the same time instead of waiting until the one before it is done. Sorry if this is a simple kind of question but I have little experience with asyncio so if anyone could help that would be massively appreciated. Thanks!
To write async program you need:define functions with async defcall it with awaitcreate event loop and run some function in itrun requests concurrently using asyncio.gatherAll other is almost same as usual. Instead of using blocking request module you should use some async one. For example, aiohttp:And use it like this:Here's code with some changes I statrted. I didn't check if it's actually works since I don't have files you use. You should also move logic inside for g in soup.find_all(class_='g'): to seperate function and run multiple of these functions with asyncio.gather to benefit of asyncio.Upd:Main idea is to move logic inside loop that does request into separate coroutine and pass multiple of these coroutines to asyncio.gather. It will parallelize your requests.


Answer URL
https://docs.python.org/3/library/asyncio-task.html#example-parallel-execution-of-tasks
