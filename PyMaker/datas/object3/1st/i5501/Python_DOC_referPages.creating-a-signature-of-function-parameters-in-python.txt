Natural Text
I have a function takes a long time and needs to be able to cache its own results for when it is called again with the same parameters.  See example below which seems to solve the problem.  I'm using Python 3.6My questions revolved around this line:1) is there a more Pythonic way to get a unique signature of the parameters passed to a function?2) Can I rely on Python's insertion order of the function parameters into the locals() map?  Again, this seems to work, but if needed I can just explicitly relist every parameter in a less elegant signature creator like:Example code:
repr(locals()) is quite bad, as it is not intended for this function. It will work, or otherwise can be made to work, and I could dig in some problems other than the semantics of doing that.I will come back to the problem - first, your solution:Python has a cache function just like what you need in the functools module on the stdlib - just import it and use it as a decorator:Now to understand why decorators a better solution there: the logic of caching your results is not mixed with the logic of your function at all, and moreover, whatever method is used for caching can be used for the caching of any function in your program -  no need to copy the caching code inside each function body.You will learn that while Python's own lru_cache  is a match for your case, it is not the best match and not perfect for all cases - in any way, you will be better either installing a 3rd party package for caching or rolling your own caching, but keeping the logic separate.The idea of a certain programing logic that can apply to various similar functions or methods in a system is otherwise known as "aspect oriented programing", and Python decorator syntax is a nice way of using it on the cheap. Other than separating the logic from the function, and using repr(locals()) to serialize the parameters,  your approach is correct:  keeping a (module) global dictionary around with the result for each set of parameters is the usual approach for caching functions. The lru_cache just happens to that in a transparent way.
You get access to your parameters in a deterministic order by providing the arguments using *args (which gives a list of positional arguments) or **kwargs (a dict of "keyword" arguments) syntax.  Consider:orTo use these in a cache, you'll need to convert the args into a dict key.  Rather than format it as a string, I'd recommend using tuples for your cache keys.  Tuples are immutable, so they can be hashed (a requirement for dicts).  Example:


Answer URL
https://docs.python.org/3/library/functools.html#functools.lru_cache
