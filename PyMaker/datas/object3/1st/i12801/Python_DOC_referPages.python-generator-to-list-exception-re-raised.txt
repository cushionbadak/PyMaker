Natural Text
I have a simple poller class (code snippet below) which retrieves files from a number of folders based on a regex.I attempt to catch OSError exceptions and ignore them as files could be moved out/deleted/permissions etc... During some testing (in which i created/deleted a large nr of files) i noticed that when sorting the generator, the exceptions that were raised in the generator function (_get) were re-raised(?), and i had to use an additional try except block to get around this.Any idea why this is happening? All comments/improvements appreciated!ThanksTimmahEDIT: Thanks to @ShadowRanger for pointing out the os.path function that was passed as sortkey param.
Posting an answer for posterity: Per psychic intuition (and confirmation in the comments), self._sortkey was trying to stat the files being sorted. While having read permission on a directory is sufficient to get the filenames contained within it, if you lack read permission on those files, you won't be able to stat them.Since sorted is executing the key function outside the generator scope, nothing in the generator is raising the exception, and therefore it can't catch it. You'd need to pre-filter/pre-compute the stat values for each file (and drop files that can't be stat-ed), sort on that, then drop the (no longer relevant) stat data. For example:It's basically performing the Schwartzian Transform (aka "Decorate-Sort-Undecorate") manually. Normally, Python's key argument for sorted/list.sort hides this complexity from you, but in this case, thanks to the possibility of exceptions, the need to drop the item if one occurs and the desire to minimize race conditions by using EAFP patterns), you have to do the work yourself.Alternate solution with Python 3.5 (or 2.6-2.7 and 3.2-3.4 using the third party scandir package):You could avoid this issue (and on Windows, include unreadable files in your output so long as the directory was readable and on a Windows-like file system that caches file metadata in the directory entry) if you so desired, with far less complexity and likely better performance. os.scandir (or pre-3.5, scandir.scandir) on Windows gets you the stat information cached in the directory entry "for free" (you only pay the RTT cost once per few thousands entries in a directory, not once per file), and on Linux the first call to DirEntry.stat caches the stat data, so doing it in _get means you can catch and handle OSError there, populating the cache so during sorting, self._sortkey can use the cached data with no risk of OSError. So you could do:This requires a small change in usage; self._sortkey must operate on an os.DirEntry instance, not a file path. So instead of self._sortkey = kwargs.get('sortkey', os.path.getmtime), you might have self._sortkey = kwargs.get('sortkey', lambda de: de.stat().st_mtime).But it avoids the complexity of manual Schwartzian Transforms (because access violations can only occur in _get's try/except as long as you don't change prestat, so no OSErrors occur during key computation). It will also likely run faster, by lazily iterating the directory instead of constructing a complete list before iterating (admittedly a small benefit unless the directory is huge) and removing the need to use a stat system call at all for most directory entries on Windows.


Answer URL
https://docs.python.org/3/library/os.html#os.DirEntry
