Natural Text
I recently moved to Python 3.5 and noticed the new matrix multiplication operator (@) sometimes behaves differently from the numpy dot operator. In example, for 3d arrays:The @ operator returns an array of shape:while the np.dot() function returns:How can I reproduce the same result with numpy dot? Are there any other significant differences?
The @ operator calls the array's __matmul__ method, not dot. This method is also present in the API as the function np.matmul.From the documentation:matmul differs from dot in two important ways.Multiplication by scalars is not allowed.Stacks of matrices are broadcast together as if the matrices were elements.The last point makes it clear that dot and matmul methods behave differently when passed 3D (or higher dimensional) arrays. Quoting from the documentation some more:For matmul:If either argument is N-D, N > 2, it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.For np.dot:For 2-D arrays it is equivalent to matrix multiplication, and for 1-D arrays to inner product of vectors (without complex conjugation). For N dimensions it is a sum product over the last axis of a and the second-to-last of b
The answer by @ajcr explains how the dot and matmul (invoked by the @ symbol) differ. By looking at a simple example, one clearly sees how the two behave differently when operating on 'stacks of matricies' or tensors. To clarify the differences take a 4x4 array and return the dot product and matmul product with a 2x4x3 'stack of matricies' or tensor.The products of each operation appear below. Notice how the dot product is, ...a sum product over the last axis of a and the second-to-last of band how the matrix product is formed by broadcasting the matrix together. 
In mathematics, I think the dot in numpy makes more sense dot(a,b)_{i,j,k,a,b,c} = \sum_m a_{i,j,k,m}b_{a,b,m,c}since it gives the dot product when a and b are vectors, or the matrix multiplication when a and b are matricesAs for matmul operation in numpy, it consists of parts of dot result, and it can be defined asmatmul(a,b)_{i,j,k,c} = \sum_m a_{i,j,k,m}b_{i,j,m,c}So, you can see that matmul(a,b) returns an array with a small shape,which has smaller memory consumption and make more sense in applications.In particular, combining with broadcasting, you can get matmul(a,b)_{i,j,k,l} = \sum_m a_{i,j,k,m}b_{j,m,l}for example.From the above two definitions, you can see the requirements to use those two operations. Assume a.shape=(s1,s2,s3,s4) and b.shape=(t1,t2,t3,t4)To use dot(a,b) you needTo use matmul(a,b) you need t3=s4 t2=s2, or one of t2 and s2 is 1t1=s1, or one of t1 and s1 is 1Use the following piece of code to convince yourself. Code sample


Answer URL
https://docs.python.org/3/whatsnew/3.5.html#whatsnew-pep-465
