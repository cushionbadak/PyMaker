Natural Text
I initialize three numpy arrays, because I need to feed some random data into an algorithm.My second array has about a hundred times the values, and takes about a hundred times the time.The third, for some reason, takes almost 1800 times the amount of time as the second does.
Assuming numpy uses dtype('int64') for these arrays, i.e. 8 bytes per element:The 1st array is 2457600 elements (~20 Megabytes)The 2nd array is 245760000 elements (~2 Gigabytes)The 3rd array is 2457600000 elements (~20 Gigabytes)If you have a reasonably average machine, the first and second cases can likely work entirely in RAM.  The third array is huge and will almost surely require swapping data to disk, which is significantly slower.You can check the sizes of an objects in Python by using sys.getsizeof(obj).  Check memory available with free (Linux) or vm_stat (macOS).  


Answer URL
https://docs.python.org/3/library/sys.html#sys.getsizeof
