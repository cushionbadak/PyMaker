Natural Text
I have a program where I need to download files from some source and upload them. But I need to make sure that there are at max 10 files in the download location. Is there way to use Managers() as well?It sounded like a typical Producer - Consumer problem. Below is my program.Below is my implementationBut It does not do what is expected, as you can see from the output belowStarting Producer 623Starting Producer 624Starting Consumer 626Starting Consumer 625Starting Consumer 627626 GOT 4ff551490d6b2eec7c6c0470f4b092fdc34cd521625 GOT 83a53a3400fc83f2b02135ba0cc6c8625ecc7dc4627 GOT 4ff551490d6b2eec7c6c0470f4b092fdc34cd521626 GOT 83a53a3400fc83f2b02135ba0cc6c8625ecc7dc4625 GOT 4e7132301ce9d61445db07910ff90a64474e6a88626 GOT 0efbd413d733b3903e6dee777ace5ef47a2ec144627 GOT 4e7132301ce9d61445db07910ff90a64474e6a88625 GOT 0efbd413d733b3903e6dee777ace5ef47a2ec144626 GOT 0a3fc4bdd56fa2bf52f5f43277f3b4ee0f040937625 GOT eb9c07329a8b5cb66e47f0dd8e56894707a84d94627 GOT 0a3fc4bdd56fa2bf52f5f43277f3b4ee0f040937626 GOT eb9c07329a8b5cb66e47f0dd8e56894707a84d94DONEAs you can see consumer picks up same SHA1s multiple times. So, I need a program to make sure that all the SHA1s put in the queue by producer is picked up by only 1 consumer.P.S I had also thought to make it work using pool. For producer it can work fine as I already have list of SHA1s to be put in the queue, But in case of consumer how would I use any list to make sure that consumer is actually stopping.
Just use a pool from either multiprocessing.Pool or concurrent.futures. The pool allows you to set how many workers you want running at the same time. This means you will have maximum max_workers files downloaded at the same time. As the download/upload is sequential (you cannot start an upload until the download is complete), you gain no value from running them in two separated threads/processes. Just join the two operations in a single job unit and then run multiple jobs concurrently.Moreover, as long as you just need to download/upload files (IO bound operations) you'd better use threads instead of processes as they are more lightweight.    


Answer URL
https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool
https://docs.python.org/3/library/concurrent.futures.html
