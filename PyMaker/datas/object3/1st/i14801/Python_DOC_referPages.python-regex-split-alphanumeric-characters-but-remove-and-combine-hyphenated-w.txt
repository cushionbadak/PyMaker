Natural Text
I am parsing over two million text files for a project and need your help with regex make it faster. I need to split the words so I am able to do it using:However, for hyphenated words, I would like to remove the hyphen but combine the word (i.e. non-profit would be nonprofit instead of "non", "profit"). Currently, I am able to do this with two search and replace (not ideal at all). The end output would be a list of words that will used by collections.Counter() object.Any faster processing tips to do this beyond regex would also be much appreciated. Thanks.
After using lower(), you can use re.sub(r'([a-z])-([a-z])', r'\1\2', s) to remove hyphens. Then re.split(r'[^a-z]'), to split the words. This solution may (or may not) be faster depending on the text it is used on. It does have some probable speed ups though: Ignoring numbers allows usage of [a-z] instead of \w.lower() being called first, allows re.sub() to search for half the letters; that is [a-z] instead of [A-Za-z].Assuming no spaces before and after hyphens (since usually that should be the case) allows replacing of '\s*-\s*' with a faster [a-z]-[a-z]
You could do something like this,ORYou could define a function in the re.sub's replacement part.ORKeep it simple...This code will do the replace for every match founded. That is, after each single match, function m is called. \W+ matches one or more non-word  characters. If a match is found, it will return an empty string if the matchobject.group(0) satisfies this \s*-\s*$ condition else it would return a single space string. That is the match was replaced with the return value.
You can use str.translate method , that is more faster than regex:Answers benchmark :


Answer URL
https://docs.python.org/3/library/stdtypes.html#str.translate
