Natural Text
We have a huge .csv file but it doesn't seem to really be a csv.The line endings are \tl\n.The text between this newline character sometimes has "real" newline characters. We don't want to split on those.We currently do it using awk.  I'm trying to find an efficient way of doing it directly in Python and tried passing a custom newline into the .open() command.  However, I quickly learned newline arg only accepts one of the default characters.How can I efficiently process this file containing the weird line ending?
Here's a function which can handle multi-character newline between chunks correctlyanother version which, although it doesn't make copies of whole chunks didn't prove faster. It will be marginally faster for large chunks. Do not use chunk_size less than newline size :)The caller should be like:
Assuming your csv is a comma or space delimited, not tab, what you were looking for is lineterminator flag, but there's no need for that since it's automatically assumed '\n' is a line break. From the doc:Note: The reader is hard-coded to recognise either '\r' or '\n' as  end-of-line, and ignores lineterminator. This behavior may change in  the future.so what you can do is add string method .replace() to get rid of '\tl' like this
Why not use pandas. Specifically pandas.read_csv using lineterminator and chunksize parameters:


Answer URL
https://docs.python.org/3/library/csv.html#csv.Dialect.lineterminator
