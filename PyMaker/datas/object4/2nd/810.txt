link:
library/re.html#regular-expression-examples

docs:

Regular Expression Examples¶

Checking for a Pair¶
In this example, we’ll use the following helper function to display match
objects a little more gracefully:


Suppose you are writing a poker program where a player’s hand is represented as
a 5-character string with each character representing a card, “a” for ace, “k”
for king, “q” for queen, “j” for jack, “t” for 10, and “2” through “9”
representing the card with that value.
To see if a given string is a valid hand, one could do the following:


That last hand, , contained a pair, or two of the same valued cards.
To match this with a regular expression, one could use backreferences as such:


To find out what card the pair consists of, one could use the
 method of the match object in the following manner:




Simulating scanf()¶
Python does not currently have an equivalent to .  Regular
expressions are generally more powerful, though also more verbose, than
 format strings.  The table below offers some more-or-less
equivalent mappings between  format tokens and regular
expressions.






 Token
Regular Expression












, , , 














, 




To extract the filename and numbers from a string like


you would use a  format like


The equivalent regular expression would be




search() vs. match()¶
Python offers two different primitive operations based on regular expressions:
 checks for a match only at the beginning of the string, while
 checks for a match anywhere in the string (this is what Perl
does by default).
For example:


Regular expressions beginning with  can be used with  to
restrict the match at the beginning of the string:


Note however that in  mode  only matches at the
beginning of the string, whereas using  with a regular expression
beginning with  will match at the beginning of each line.




Making a Phonebook¶
 splits a string into a list delimited by the passed pattern.  The
method is invaluable for converting textual data into data structures that can be
easily read and modified by Python as demonstrated in the following example that
creates a phonebook.
First, here is the input.  Normally it may come from a file, here we are using
triple-quoted string syntax:


The entries are separated by one or more newlines. Now we convert the string
into a list with each nonempty line having its own entry:


Finally, split each entry into a list with first name, last name, telephone
number, and address.  We use the  parameter of 
because the address has spaces, our splitting pattern, in it:


The  pattern matches the colon after the last name, so that it does not
occur in the result list.  With a  of , we could separate the
house number from the street name:




Text Munging¶
 replaces every occurrence of a pattern with a string or the
result of a function.  This example demonstrates using  with
a function to “munge” text, or randomize the order of all the characters
in each word of a sentence except for the first and last characters:




Finding all Adverbs¶
 matches all occurrences of a pattern, not just the first
one as  does.  For example, if a writer wanted to
find all of the adverbs in some text, they might use  in
the following manner:




Finding all Adverbs and their Positions¶
If one wants more information about all matches of a pattern than the matched
text,  is useful as it provides match objects instead of strings.  Continuing with the previous example, if
a writer wanted to find all of the adverbs and their positions in
some text, they would use  in the following manner:




Raw String Notation¶
Raw string notation () keeps regular expressions sane.  Without it,
every backslash () in a regular expression would have to be prefixed with
another one to escape it.  For example, the two following lines of code are
functionally identical:


When one wants to match a literal backslash, it must be escaped in the regular
expression.  With raw string notation, this means .  Without raw string
notation, one must use , making the following lines of code
functionally identical:




Writing a Tokenizer¶
A tokenizer or scanner
analyzes a string to categorize groups of characters.  This is a useful first
step in writing a compiler or interpreter.
The text categories are specified with regular expressions.  The technique is
to combine those into a single master regular expression and to loop over
successive matches:


The tokenizer produces the following output:





[Frie09]Friedl, Jeffrey. Mastering Regular Expressions. 3rd ed., O’Reilly
Media, 2009. The third edition of the book no longer covers Python at all,
but the first edition covered writing good regular expression patterns in
great detail.



