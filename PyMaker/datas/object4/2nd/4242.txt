link:
library/multiprocessing.html#introduction

docs:

Introduction¶
 is a package that supports spawning processes using an
API similar to the  module.  The  package
offers both local and remote concurrency, effectively side-stepping the
Global Interpreter Lock by using subprocesses instead of threads.  Due
to this, the  module allows the programmer to fully
leverage multiple processors on a given machine.  It runs on both Unix and
Windows.
The  module also introduces APIs which do not have
analogs in the  module.  A prime example of this is the
 object which offers a convenient means of
parallelizing the execution of a function across multiple input values,
distributing the input data across processes (data parallelism).  The following
example demonstrates the common practice of defining such functions in a module
so that child processes can successfully import that module.  This basic example
of data parallelism using ,


will print to standard output



The  class¶
In , processes are spawned by creating a 
object and then calling its  method.  
follows the API of .  A trivial example of a
multiprocess program is


To show the individual process IDs involved, here is an expanded example:


For an explanation of why the  part is
necessary, see Programming guidelines.


Contexts and start methods¶
Depending on the platform,  supports three ways
to start a process.  These start methods are


spawn
The parent process starts a fresh python interpreter process.  The
child process will only inherit those resources necessary to run
the process objects  method.  In particular,
unnecessary file descriptors and handles from the parent process
will not be inherited.  Starting a process using this method is
rather slow compared to using fork or forkserver.
Available on Unix and Windows.  The default on Windows.

fork
The parent process uses  to fork the Python
interpreter.  The child process, when it begins, is effectively
identical to the parent process.  All resources of the parent are
inherited by the child process.  Note that safely forking a
multithreaded process is problematic.
Available on Unix only.  The default on Unix.

forkserver
When the program starts and selects the forkserver start method,
a server process is started.  From then on, whenever a new process
is needed, the parent process connects to the server and requests
that it fork a new process.  The fork server process is single
threaded so it is safe for it to use .  No
unnecessary resources are inherited.
Available on Unix platforms which support passing file descriptors
over Unix pipes.




Changed in version 3.4: spawn added on all unix platforms, and forkserver added for
some unix platforms.
Child processes no longer inherit all of the parents inheritable
handles on Windows.

On Unix using the spawn or forkserver start methods will also
start a semaphore tracker process which tracks the unlinked named
semaphores created by processes of the program.  When all processes
have exited the semaphore tracker unlinks any remaining semaphores.
Usually there should be none, but if a process was killed by a signal
there may be some “leaked” semaphores.  (Unlinking the named semaphores
is a serious matter since the system allows only a limited number, and
they will not be automatically unlinked until the next reboot.)
To select a start method you use the  in
the  clause of the main module.  For
example:


 should not be used more than once in the
program.
Alternatively, you can use  to obtain a context
object.  Context objects have the same API as the multiprocessing
module, and allow one to use multiple start methods in the same
program.


Note that objects related to one context may not be compatible with
processes for a different context.  In particular, locks created using
the fork context cannot be passed to processes started using the
spawn or forkserver start methods.
A library which wants to use a particular start method should probably
use  to avoid interfering with the choice of the
library user.

Warning
The  and  start methods cannot currently
be used with “frozen” executables (i.e., binaries produced by
packages like PyInstaller and cx_Freeze) on Unix.
The  start method does work.



Exchanging objects between processes¶
 supports two types of communication channel between
processes:
Queues

The  class is a near clone of .  For
example:


Queues are thread and process safe.

Pipes

The  function returns a pair of connection objects connected by a
pipe which by default is duplex (two-way).  For example:


The two connection objects returned by  represent the two ends of
the pipe.  Each connection object has  and
 methods (among others).  Note that data in a pipe
may become corrupted if two processes (or threads) try to read from or write
to the same end of the pipe at the same time.  Of course there is no risk
of corruption from processes using different ends of the pipe at the same
time.



Synchronization between processes¶
 contains equivalents of all the synchronization
primitives from .  For instance one can use a lock to ensure
that only one process prints to standard output at a time:


Without using the lock output from the different processes is liable to get all
mixed up.


Sharing state between processes¶
As mentioned above, when doing concurrent programming it is usually best to
avoid using shared state as far as possible.  This is particularly true when
using multiple processes.
However, if you really do need to use some shared data then
 provides a couple of ways of doing so.
Shared memory

Data can be stored in a shared memory map using  or
.  For example, the following code


will print


The  and  arguments used when creating  and  are
typecodes of the kind used by the  module:  indicates a
double precision float and  indicates a signed integer.  These shared
objects will be process and thread-safe.
For more flexibility in using shared memory one can use the
 module which supports the creation of
arbitrary ctypes objects allocated from shared memory.

Server process

A manager object returned by  controls a server process which
holds Python objects and allows other processes to manipulate them using
proxies.
A manager returned by  will support types
, , , ,
, , ,
, , ,
,  and .  For example,


will print


Server process managers are more flexible than using shared memory objects
because they can be made to support arbitrary object types.  Also, a single
manager can be shared by processes on different computers over a network.
They are, however, slower than using shared memory.



Using a pool of workers¶
The  class represents a pool of worker
processes.  It has methods which allows tasks to be offloaded to the worker
processes in a few different ways.
For example:


Note that the methods of a pool should only ever be used by the
process which created it.

Note
Functionality within this package requires that the  module be
importable by the children. This is covered in Programming guidelines
however it is worth pointing out here. This means that some examples, such
as the  examples will not work in the
interactive interpreter. For example:


(If you try this it will actually output three full tracebacks
interleaved in a semi-random fashion, and then you may have to
stop the master process somehow.)


