link:
library/itertools.html#itertool-functions

docs:

Itertool functions¶
The following module functions all construct and return iterators. Some provide
streams of infinite length, so they should only be accessed by functions or
loops that truncate the stream.


itertools.accumulate(iterable[, func])¶
Make an iterator that returns accumulated sums, or accumulated
results of other binary functions (specified via the optional
func argument).  If func is supplied, it should be a function
of two arguments. Elements of the input iterable may be any type
that can be accepted as arguments to func. (For example, with
the default operation of addition, elements may be any addable
type including Decimal or
Fraction.) If the input iterable is empty, the
output iterable will also be empty.
Roughly equivalent to:
def accumulate(iterable, func=operator.add):
    'Return running totals'
    # accumulate([1,2,3,4,5]) --> 1 3 6 10 15
    # accumulate([1,2,3,4,5], operator.mul) --> 1 2 6 24 120
    it = iter(iterable)
    try:
        total = next(it)
    except StopIteration:
        return
    yield total
    for element in it:
        total = func(total, element)
        yield total


There are a number of uses for the func argument.  It can be set to
min() for a running minimum, max() for a running maximum, or
operator.mul() for a running product.  Amortization tables can be
built by accumulating interest and applying payments.  First-order
recurrence relations
can be modeled by supplying the initial value in the iterable and using only
the accumulated total in func argument:
>>> data = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
>>> list(accumulate(data, operator.mul))     # running product
[3, 12, 72, 144, 144, 1296, 0, 0, 0, 0]
>>> list(accumulate(data, max))              # running maximum
[3, 4, 6, 6, 6, 9, 9, 9, 9, 9]

# Amortize a 5% loan of 1000 with 4 annual payments of 90
>>> cashflows = [1000, -90, -90, -90, -90]
>>> list(accumulate(cashflows, lambda bal, pmt: bal*1.05 + pmt))
[1000, 960.0, 918.0, 873.9000000000001, 827.5950000000001]

# Chaotic recurrence relation https://en.wikipedia.org/wiki/Logistic_map
>>> logistic_map = lambda x, _:  r * x * (1 - x)
>>> r = 3.8
>>> x0 = 0.4
>>> inputs = repeat(x0, 36)     # only the initial value is used
>>> [format(x, '.2f') for x in accumulate(inputs, logistic_map)]
['0.40', '0.91', '0.30', '0.81', '0.60', '0.92', '0.29', '0.79', '0.63',
 '0.88', '0.39', '0.90', '0.33', '0.84', '0.52', '0.95', '0.18', '0.57',
 '0.93', '0.25', '0.71', '0.79', '0.63', '0.88', '0.39', '0.91', '0.32',
 '0.83', '0.54', '0.95', '0.20', '0.60', '0.91', '0.30', '0.80', '0.60']


See functools.reduce() for a similar function that returns only the
final accumulated value.

New in version 3.2.


Changed in version 3.3: Added the optional func parameter.




itertools.chain(*iterables)¶
Make an iterator that returns elements from the first iterable until it is
exhausted, then proceeds to the next iterable, until all of the iterables are
exhausted.  Used for treating consecutive sequences as a single sequence.
Roughly equivalent to:
def chain(*iterables):
    # chain('ABC', 'DEF') --> A B C D E F
    for it in iterables:
        for element in it:
            yield element





classmethod chain.from_iterable(iterable)¶
Alternate constructor for chain().  Gets chained inputs from a
single iterable argument that is evaluated lazily.  Roughly equivalent to:
def from_iterable(iterables):
    # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
    for it in iterables:
        for element in it:
            yield element





itertools.combinations(iterable, r)¶
Return r length subsequences of elements from the input iterable.
Combinations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the combination tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, there will be no repeat
values in each combination.
Roughly equivalent to:
def combinations(iterable, r):
    # combinations('ABCD', 2) --> AB AC AD BC BD CD
    # combinations(range(4), 3) --> 012 013 023 123
    pool = tuple(iterable)
    n = len(pool)
    if r > n:
        return
    indices = list(range(r))
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != i + n - r:
                break
        else:
            return
        indices[i] += 1
        for j in range(i+1, r):
            indices[j] = indices[j-1] + 1
        yield tuple(pool[i] for i in indices)


The code for combinations() can be also expressed as a subsequence
of permutations() after filtering entries where the elements are not
in sorted order (according to their position in the input pool):
def combinations(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in permutations(range(n), r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)


The number of items returned is n! / r! / (n-r)! when 0 <= r <= n
or zero when r > n.



itertools.combinations_with_replacement(iterable, r)¶
Return r length subsequences of elements from the input iterable
allowing individual elements to be repeated more than once.
Combinations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the combination tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, the generated combinations
will also be unique.
Roughly equivalent to:
def combinations_with_replacement(iterable, r):
    # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
    pool = tuple(iterable)
    n = len(pool)
    if not n and r:
        return
    indices = [0] * r
    yield tuple(pool[i] for i in indices)
    while True:
        for i in reversed(range(r)):
            if indices[i] != n - 1:
                break
        else:
            return
        indices[i:] = [indices[i] + 1] * (r - i)
        yield tuple(pool[i] for i in indices)


The code for combinations_with_replacement() can be also expressed as
a subsequence of product() after filtering entries where the elements
are not in sorted order (according to their position in the input pool):
def combinations_with_replacement(iterable, r):
    pool = tuple(iterable)
    n = len(pool)
    for indices in product(range(n), repeat=r):
        if sorted(indices) == list(indices):
            yield tuple(pool[i] for i in indices)


The number of items returned is (n+r-1)! / r! / (n-1)! when n > 0.

New in version 3.1.




itertools.compress(data, selectors)¶
Make an iterator that filters elements from data returning only those that
have a corresponding element in selectors that evaluates to True.
Stops when either the data or selectors iterables has been exhausted.
Roughly equivalent to:
def compress(data, selectors):
    # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
    return (d for d, s in zip(data, selectors) if s)



New in version 3.1.




itertools.count(start=0, step=1)¶
Make an iterator that returns evenly spaced values starting with number start. Often
used as an argument to map() to generate consecutive data points.
Also, used with zip() to add sequence numbers.  Roughly equivalent to:
def count(start=0, step=1):
    # count(10) --> 10 11 12 13 14 ...
    # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
    n = start
    while True:
        yield n
        n += step


When counting with floating point numbers, better accuracy can sometimes be
achieved by substituting multiplicative code such as: (start + step * i
for i in count()).

Changed in version 3.1: Added step argument and allowed non-integer arguments.




itertools.cycle(iterable)¶
Make an iterator returning elements from the iterable and saving a copy of each.
When the iterable is exhausted, return elements from the saved copy.  Repeats
indefinitely.  Roughly equivalent to:
def cycle(iterable):
    # cycle('ABCD') --> A B C D A B C D A B C D ...
    saved = []
    for element in iterable:
        yield element
        saved.append(element)
    while saved:
        for element in saved:
              yield element


Note, this member of the toolkit may require significant auxiliary storage
(depending on the length of the iterable).



itertools.dropwhile(predicate, iterable)¶
Make an iterator that drops elements from the iterable as long as the predicate
is true; afterwards, returns every element.  Note, the iterator does not produce
any output until the predicate first becomes false, so it may have a lengthy
start-up time.  Roughly equivalent to:
def dropwhile(predicate, iterable):
    # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
    iterable = iter(iterable)
    for x in iterable:
        if not predicate(x):
            yield x
            break
    for x in iterable:
        yield x





itertools.filterfalse(predicate, iterable)¶
Make an iterator that filters elements from iterable returning only those for
which the predicate is False. If predicate is None, return the items
that are false. Roughly equivalent to:
def filterfalse(predicate, iterable):
    # filterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
    if predicate is None:
        predicate = bool
    for x in iterable:
        if not predicate(x):
            yield x





itertools.groupby(iterable, key=None)¶
Make an iterator that returns consecutive keys and groups from the iterable.
The key is a function computing a key value for each element.  If not
specified or is None, key defaults to an identity function and returns
the element unchanged.  Generally, the iterable needs to already be sorted on
the same key function.
The operation of groupby() is similar to the uniq filter in Unix.  It
generates a break or new group every time the value of the key function changes
(which is why it is usually necessary to have sorted the data using the same key
function).  That behavior differs from SQL’s GROUP BY which aggregates common
elements regardless of their input order.
The returned group is itself an iterator that shares the underlying iterable
with groupby().  Because the source is shared, when the groupby()
object is advanced, the previous group is no longer visible.  So, if that data
is needed later, it should be stored as a list:
groups = []
uniquekeys = []
data = sorted(data, key=keyfunc)
for k, g in groupby(data, keyfunc):
    groups.append(list(g))      # Store group iterator as a list
    uniquekeys.append(k)


groupby() is roughly equivalent to:
class groupby:
    # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
    # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
    def __init__(self, iterable, key=None):
        if key is None:
            key = lambda x: x
        self.keyfunc = key
        self.it = iter(iterable)
        self.tgtkey = self.currkey = self.currvalue = object()
    def __iter__(self):
        return self
    def __next__(self):
        self.id = object()
        while self.currkey == self.tgtkey:
            self.currvalue = next(self.it)    # Exit on StopIteration
            self.currkey = self.keyfunc(self.currvalue)
        self.tgtkey = self.currkey
        return (self.currkey, self._grouper(self.tgtkey, self.id))
    def _grouper(self, tgtkey, id):
        while self.id is id and self.currkey == tgtkey:
            yield self.currvalue
            try:
                self.currvalue = next(self.it)
            except StopIteration:
                return
            self.currkey = self.keyfunc(self.currvalue)





itertools.islice(iterable, stop)¶

itertools.islice(iterable, start, stop[, step])
Make an iterator that returns selected elements from the iterable. If start is
non-zero, then elements from the iterable are skipped until start is reached.
Afterward, elements are returned consecutively unless step is set higher than
one which results in items being skipped.  If stop is None, then iteration
continues until the iterator is exhausted, if at all; otherwise, it stops at the
specified position.  Unlike regular slicing, islice() does not support
negative values for start, stop, or step.  Can be used to extract related
fields from data where the internal structure has been flattened (for example, a
multi-line report may list a name field on every third line).  Roughly equivalent to:
def islice(iterable, *args):
    # islice('ABCDEFG', 2) --> A B
    # islice('ABCDEFG', 2, 4) --> C D
    # islice('ABCDEFG', 2, None) --> C D E F G
    # islice('ABCDEFG', 0, None, 2) --> A C E G
    s = slice(*args)
    start, stop, step = s.start or 0, s.stop or sys.maxsize, s.step or 1
    it = iter(range(start, stop, step))
    try:
        nexti = next(it)
    except StopIteration:
        # Consume *iterable* up to the *start* position.
        for i, element in zip(range(start), iterable):
            pass
        return
    try:
        for i, element in enumerate(iterable):
            if i == nexti:
                yield element
                nexti = next(it)
    except StopIteration:
        # Consume to *stop*.
        for i, element in zip(range(i + 1, stop), iterable):
            pass


If start is None, then iteration starts at zero. If step is None,
then the step defaults to one.



itertools.permutations(iterable, r=None)¶
Return successive r length permutations of elements in the iterable.
If r is not specified or is None, then r defaults to the length
of the iterable and all possible full-length permutations
are generated.
Permutations are emitted in lexicographic sort order.  So, if the
input iterable is sorted, the permutation tuples will be produced
in sorted order.
Elements are treated as unique based on their position, not on their
value.  So if the input elements are unique, there will be no repeat
values in each permutation.
Roughly equivalent to:
def permutations(iterable, r=None):
    # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
    # permutations(range(3)) --> 012 021 102 120 201 210
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    if r > n:
        return
    indices = list(range(n))
    cycles = list(range(n, n-r, -1))
    yield tuple(pool[i] for i in indices[:r])
    while n:
        for i in reversed(range(r)):
            cycles[i] -= 1
            if cycles[i] == 0:
                indices[i:] = indices[i+1:] + indices[i:i+1]
                cycles[i] = n - i
            else:
                j = cycles[i]
                indices[i], indices[-j] = indices[-j], indices[i]
                yield tuple(pool[i] for i in indices[:r])
                break
        else:
            return


The code for permutations() can be also expressed as a subsequence of
product(), filtered to exclude entries with repeated elements (those
from the same position in the input pool):
def permutations(iterable, r=None):
    pool = tuple(iterable)
    n = len(pool)
    r = n if r is None else r
    for indices in product(range(n), repeat=r):
        if len(set(indices)) == r:
            yield tuple(pool[i] for i in indices)


The number of items returned is n! / (n-r)! when 0 <= r <= n
or zero when r > n.



itertools.product(*iterables, repeat=1)¶
Cartesian product of input iterables.
Roughly equivalent to nested for-loops in a generator expression. For example,
product(A, B) returns the same as ((x,y) for x in A for y in B).
The nested loops cycle like an odometer with the rightmost element advancing
on every iteration.  This pattern creates a lexicographic ordering so that if
the input’s iterables are sorted, the product tuples are emitted in sorted
order.
To compute the product of an iterable with itself, specify the number of
repetitions with the optional repeat keyword argument.  For example,
product(A, repeat=4) means the same as product(A, A, A, A).
This function is roughly equivalent to the following code, except that the
actual implementation does not build up intermediate results in memory:
def product(*args, repeat=1):
    # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
    # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
    pools = [tuple(pool) for pool in args] * repeat
    result = [[]]
    for pool in pools:
        result = [x+[y] for x in result for y in pool]
    for prod in result:
        yield tuple(prod)





itertools.repeat(object[, times])¶
Make an iterator that returns object over and over again. Runs indefinitely
unless the times argument is specified. Used as argument to map() for
invariant parameters to the called function.  Also used with zip() to
create an invariant part of a tuple record.
Roughly equivalent to:
def repeat(object, times=None):
    # repeat(10, 3) --> 10 10 10
    if times is None:
        while True:
            yield object
    else:
        for i in range(times):
            yield object


A common use for repeat is to supply a stream of constant values to map
or zip:
>>> list(map(pow, range(10), repeat(2)))
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]





itertools.starmap(function, iterable)¶
Make an iterator that computes the function using arguments obtained from
the iterable.  Used instead of map() when argument parameters are already
grouped in tuples from a single iterable (the data has been “pre-zipped”).  The
difference between map() and starmap() parallels the distinction
between function(a,b) and function(*c). Roughly equivalent to:
def starmap(function, iterable):
    # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
    for args in iterable:
        yield function(*args)





itertools.takewhile(predicate, iterable)¶
Make an iterator that returns elements from the iterable as long as the
predicate is true.  Roughly equivalent to:
def takewhile(predicate, iterable):
    # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
    for x in iterable:
        if predicate(x):
            yield x
        else:
            break





itertools.tee(iterable, n=2)¶
Return n independent iterators from a single iterable.
The following Python code helps explain what tee does (although the actual
implementation is more complex and uses only a single underlying
FIFO queue).
Roughly equivalent to:
def tee(iterable, n=2):
    it = iter(iterable)
    deques = [collections.deque() for i in range(n)]
    def gen(mydeque):
        while True:
            if not mydeque:             # when the local deque is empty
                try:
                    newval = next(it)   # fetch a new value and
                except StopIteration:
                    return
                for d in deques:        # load it to all the deques
                    d.append(newval)
            yield mydeque.popleft()
    return tuple(gen(d) for d in deques)


Once tee() has made a split, the original iterable should not be
used anywhere else; otherwise, the iterable could get advanced without
the tee objects being informed.
This itertool may require significant auxiliary storage (depending on how
much temporary data needs to be stored). In general, if one iterator uses
most or all of the data before another iterator starts, it is faster to use
list() instead of tee().



itertools.zip_longest(*iterables, fillvalue=None)¶
Make an iterator that aggregates elements from each of the iterables. If the
iterables are of uneven length, missing values are filled-in with fillvalue.
Iteration continues until the longest iterable is exhausted.  Roughly equivalent to:
def zip_longest(*args, fillvalue=None):
    # zip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
    iterators = [iter(it) for it in args]
    num_active = len(iterators)
    if not num_active:
        return
    while True:
        values = []
        for i, it in enumerate(iterators):
            try:
                value = next(it)
            except StopIteration:
                num_active -= 1
                if not num_active:
                    return
                iterators[i] = repeat(fillvalue)
                value = fillvalue
            values.append(value)
        yield tuple(values)


If one of the iterables is potentially infinite, then the zip_longest()
function should be wrapped with something that limits the number of calls
(for example islice() or takewhile()).  If not specified,
fillvalue defaults to None.

