link:
library/urllib.parse.html#url-parsing

docs:

URL Parsing¶
The URL parsing functions focus on splitting a URL string into its components,
or on combining URL components into a URL string.


urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True)¶
Parse a URL into six components, returning a 6-item named tuple.  This
corresponds to the general structure of a URL:
scheme://netloc/path;parameters?query#fragment.
Each tuple item is a string, possibly empty. The components are not broken up in
smaller parts (for example, the network location is a single string), and %
escapes are not expanded. The delimiters as shown above are not part of the
result, except for a leading slash in the path component, which is retained if
present.  For example:
>>> from urllib.parse import urlparse
>>> o = urlparse('http://www.cwi.nl:80/%7Eguido/Python.html')
>>> o   # doctest: +NORMALIZE_WHITESPACE
ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
>>> o.scheme
'http'
>>> o.port
80
>>> o.geturl()
'http://www.cwi.nl:80/%7Eguido/Python.html'


Following the syntax specifications in RFC 1808, urlparse recognizes
a netloc only if it is properly introduced by ‘//’.  Otherwise the
input is presumed to be a relative URL and thus to start with
a path component.
 >>> from urllib.parse import urlparse
 >>> urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
 ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
            params='', query='', fragment='')
 >>> urlparse('www.cwi.nl/%7Eguido/Python.html')
 ParseResult(scheme='', netloc='', path='www.cwi.nl/%7Eguido/Python.html',
            params='', query='', fragment='')
 >>> urlparse('help/Python.html')
 ParseResult(scheme='', netloc='', path='help/Python.html', params='',
            query='', fragment='')


The scheme argument gives the default addressing scheme, to be
used only if the URL does not specify one.  It should be the same type
(text or bytes) as urlstring, except that the default value '' is
always allowed, and is automatically converted to b'' if appropriate.
If the allow_fragments argument is false, fragment identifiers are not
recognized.  Instead, they are parsed as part of the path, parameters
or query component, and fragment is set to the empty string in
the return value.
The return value is a named tuple, which means that its items can
be accessed by index or as named attributes, which are:








Attribute
Index
Value
Value if not present



scheme
0
URL scheme specifier
scheme parameter

netloc
1
Network location part
empty string

path
2
Hierarchical path
empty string

params
3
Parameters for last path
element
empty string

query
4
Query component
empty string

fragment
5
Fragment identifier
empty string

username
 
User name
None

password
 
Password
None

hostname
 
Host name (lower case)
None

port
 
Port number as integer,
if present
None



Reading the port attribute will raise a ValueError if
an invalid port is specified in the URL.  See section
Structured Parse Results for more information on the result object.
Unmatched square brackets in the netloc attribute will raise a
ValueError.
Characters in the netloc attribute that decompose under NFKC
normalization (as used by the IDNA encoding) into any of /, ?,
#, @, or : will raise a ValueError. If the URL is
decomposed before parsing, no error will be raised.
As is the case with all named tuples, the subclass has a few additional methods
and attributes that are particularly useful. One such method is _replace().
The _replace() method will return a new ParseResult object replacing specified
fields with new values.
 >>> from urllib.parse import urlparse
 >>> u = urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
 >>> u
 ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
             params='', query='', fragment='')
 >>> u._replace(scheme='http')
 ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
             params='', query='', fragment='')



Changed in version 3.2: Added IPv6 URL parsing capabilities.


Changed in version 3.3: The fragment is now parsed for all URL schemes (unless allow_fragment is
false), in accordance with RFC 3986.  Previously, a whitelist of
schemes that support fragments existed.


Changed in version 3.6: Out-of-range port numbers now raise ValueError, instead of
returning None.


Changed in version 3.7.3: Characters that affect netloc parsing under NFKC normalization will
now raise ValueError.




urllib.parse.parse_qs(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None)¶
Parse a query string given as a string argument (data of type
application/x-www-form-urlencoded).  Data are returned as a
dictionary.  The dictionary keys are the unique query variable names and the
values are lists of values for each name.
The optional argument keep_blank_values is a flag indicating whether blank
values in percent-encoded queries should be treated as blank strings. A true value
indicates that blanks should be retained as  blank strings.  The default false
value indicates that blank values are to be ignored and treated as if they were
not included.
The optional argument strict_parsing is a flag indicating what to do with
parsing errors.  If false (the default), errors are silently ignored.  If true,
errors raise a ValueError exception.
The optional encoding and errors parameters specify how to decode
percent-encoded sequences into Unicode characters, as accepted by the
bytes.decode() method.
The optional argument max_num_fields is the maximum number of fields to
read. If set, then throws a ValueError if there are more than
max_num_fields fields read.
Use the urllib.parse.urlencode() function (with the doseq
parameter set to True) to convert such dictionaries into query
strings.

Changed in version 3.2: Add encoding and errors parameters.


Changed in version 3.7.2: Added max_num_fields parameter.




urllib.parse.parse_qsl(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None)¶
Parse a query string given as a string argument (data of type
application/x-www-form-urlencoded).  Data are returned as a list of
name, value pairs.
The optional argument keep_blank_values is a flag indicating whether blank
values in percent-encoded queries should be treated as blank strings. A true value
indicates that blanks should be retained as  blank strings.  The default false
value indicates that blank values are to be ignored and treated as if they were
not included.
The optional argument strict_parsing is a flag indicating what to do with
parsing errors.  If false (the default), errors are silently ignored.  If true,
errors raise a ValueError exception.
The optional encoding and errors parameters specify how to decode
percent-encoded sequences into Unicode characters, as accepted by the
bytes.decode() method.
The optional argument max_num_fields is the maximum number of fields to
read. If set, then throws a ValueError if there are more than
max_num_fields fields read.
Use the urllib.parse.urlencode() function to convert such lists of pairs into
query strings.

Changed in version 3.2: Add encoding and errors parameters.


Changed in version 3.7.2: Added max_num_fields parameter.




urllib.parse.urlunparse(parts)¶
Construct a URL from a tuple as returned by urlparse(). The parts
argument can be any six-item iterable. This may result in a slightly
different, but equivalent URL, if the URL that was parsed originally had
unnecessary delimiters (for example, a ? with an empty query; the RFC
states that these are equivalent).



urllib.parse.urlsplit(urlstring, scheme='', allow_fragments=True)¶
This is similar to urlparse(), but does not split the params from the URL.
This should generally be used instead of urlparse() if the more recent URL
syntax allowing parameters to be applied to each segment of the path portion
of the URL (see RFC 2396) is wanted.  A separate function is needed to
separate the path segments and parameters.  This function returns a 5-item
named tuple:
(addressing scheme, network location, path, query, fragment identifier).


The return value is a named tuple, its items can be accessed by index
or as named attributes:








Attribute
Index
Value
Value if not present



scheme
0
URL scheme specifier
scheme parameter

netloc
1
Network location part
empty string

path
2
Hierarchical path
empty string

query
3
Query component
empty string

fragment
4
Fragment identifier
empty string

username
 
User name
None

password
 
Password
None

hostname
 
Host name (lower case)
None

port
 
Port number as integer,
if present
None



Reading the port attribute will raise a ValueError if
an invalid port is specified in the URL.  See section
Structured Parse Results for more information on the result object.
Unmatched square brackets in the netloc attribute will raise a
ValueError.
Characters in the netloc attribute that decompose under NFKC
normalization (as used by the IDNA encoding) into any of /, ?,
#, @, or : will raise a ValueError. If the URL is
decomposed before parsing, no error will be raised.

Changed in version 3.6: Out-of-range port numbers now raise ValueError, instead of
returning None.


Changed in version 3.7.3: Characters that affect netloc parsing under NFKC normalization will
now raise ValueError.




urllib.parse.urlunsplit(parts)¶
Combine the elements of a tuple as returned by urlsplit() into a
complete URL as a string. The parts argument can be any five-item
iterable. This may result in a slightly different, but equivalent URL, if the
URL that was parsed originally had unnecessary delimiters (for example, a ?
with an empty query; the RFC states that these are equivalent).



urllib.parse.urljoin(base, url, allow_fragments=True)¶
Construct a full (“absolute”) URL by combining a “base URL” (base) with
another URL (url).  Informally, this uses components of the base URL, in
particular the addressing scheme, the network location and (part of) the
path, to provide missing components in the relative URL.  For example:
>>> from urllib.parse import urljoin
>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html', 'FAQ.html')
'http://www.cwi.nl/%7Eguido/FAQ.html'


The allow_fragments argument has the same meaning and default as for
urlparse().

Note
If url is an absolute URL (that is, starting with // or scheme://),
the url’s host name and/or scheme will be present in the result.  For example:

>>> urljoin('http://www.cwi.nl/%7Eguido/Python.html',
...         '//www.python.org/%7Eguido')
'http://www.python.org/%7Eguido'


If you do not want that behavior, preprocess the url with urlsplit() and
urlunsplit(), removing possible scheme and netloc parts.

Changed in version 3.5: Behaviour updated to match the semantics defined in RFC 3986.




urllib.parse.urldefrag(url)¶
If url contains a fragment identifier, return a modified version of url
with no fragment identifier, and the fragment identifier as a separate
string.  If there is no fragment identifier in url, return url unmodified
and an empty string.
The return value is a named tuple, its items can be accessed by index
or as named attributes:








Attribute
Index
Value
Value if not present



url
0
URL with no fragment
empty string

fragment
1
Fragment identifier
empty string



See section Structured Parse Results for more information on the result
object.

Changed in version 3.2: Result is a structured object rather than a simple 2-tuple.


